<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">AR2T: Advanced Realistic Rendering Technique for Biomedical Volumes</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Elena</forename><surname>Denisova</surname></persName>
							<email>elena.denisova@unifi.it</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Engineering</orgName>
								<orgName type="institution">University of Florence</orgName>
								<address>
									<postCode>50139</postCode>
									<settlement>Florence</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Imaginalis S.r.l</orgName>
								<address>
									<postCode>50019</postCode>
									<settlement>Sesto Fiorentino</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<address>
									<settlement>Eidolab, Florence</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Leonardo</forename><surname>Manetti</surname></persName>
							<idno type="ORCID">0000-0002-2783-8722</idno>
							<affiliation key="aff2">
								<orgName type="institution">Imaginalis S.r.l</orgName>
								<address>
									<postCode>50019</postCode>
									<settlement>Sesto Fiorentino</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<address>
									<settlement>Eidolab, Florence</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Leonardo</forename><surname>Bocchi</surname></persName>
							<idno type="ORCID">0000-0001-5109-3399</idno>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Engineering</orgName>
								<orgName type="institution">University of Florence</orgName>
								<address>
									<postCode>50139</postCode>
									<settlement>Florence</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<address>
									<settlement>Eidolab, Florence</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ernesto</forename><surname>Iadanza</surname></persName>
							<idno type="ORCID">0000-0002-7291-4990</idno>
							<affiliation key="aff1">
								<orgName type="department">Department of Medical Biotechnologies</orgName>
								<orgName type="institution">University of Siena</orgName>
								<address>
									<postCode>53100</postCode>
									<settlement>Siena</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">AR2T: Advanced Realistic Rendering Technique for Biomedical Volumes</title>
					</analytic>
					<monogr>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">E55944CBEF1A40A46FE8724C71FC4B1D</idno>
					<idno type="DOI">10.1007/978-3-031-43987-2</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-24T11:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Monte-Carlo Path Tracing</term>
					<term>Realistic Rendering</term>
					<term>Biomedical Volumes Visualization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Three-dimensional (3D) rendering of biomedical volumes can be used to illustrate the diagnosis to patients, train inexperienced clinicians, or facilitate surgery planning for experts. The most realistic visualization can be achieved by the Monte-Carlo path tracing (MCPT) rendering technique which is based on the physical transport of light. However, this technique applied to biomedical volumes has received relatively little attention, because, naively implemented, it does not allow to interact with the data. In this paper, we present our application of MCPT to the biomedical volume rendering-Advanced Realistic Rendering Technique (AR 2 T), in an attempt to achieve more realism and increase the level of detail in data representation. The main result of our research is a practical framework that includes different visualization techniques: iso-surface rendering, direct volume rendering (DVR) combined with local and global illumination, maximum intensity projection (MIP), and AR 2 T. The framework allows interaction with the data in high quality for the deterministic algorithms, and in low quality for the stochastic AR 2 T. A high-quality AR 2 T image can be generated on user request; the quality improves in real-time, and the process is stopped automatically on the algorithm convergence, or by user, when the desired quality is achieved. The framework enables direct comparison of different rendering algorithms, i.e., utilizing the same view/light position and transfer functions. It therefore can be used by medical experts for immediate oneto-one visual comparison between different data representations in order to collect feedback about the usefulness of the realistic 3D visualization in clinical environment.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Now that the hardware performance has achieved a certain level, 3D rendering of biomedical volumes is becoming very popular, above all, with the younger generation of clinicians that uses to use the forefront technologies in their everyday life. 3D representation has proven useful for faster comprehension of traumas in areas of high anatomic complexity, for surgical planning, simulation, and training <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b24">25]</ref>, <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b27">28]</ref>. Also, it improves communication with patients, which understand the diagnosis much better if illustrated in 3D <ref type="bibr" target="#b21">[23]</ref>.</p><p>The most popular techniques for volume data rendering are maximum-intensity projection (MIP), iso-surface rendering, and direct volume rendering (DVR). These techniques have their pros and cons, but essentially, they suffer from a lack of photo realism.</p><p>Our novel Advanced Realistic Rendering Technique (AR 2 T) is based on Monte-Carlo path tracing (MCPT). Historically, MCPT is thought of as a technique suited to (iso)surfaces rendering <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b18">19]</ref>. Applied to biomedical volumes, this technique has received relatively little attention, probably because, if naively implemented, it does not allow interaction with the data in real-time <ref type="bibr" target="#b6">[7]</ref>. However, due to continuous hardware improvement, the problems that can not be resolved in real-time today, will be resolved in real-time tomorrow. For this reason, we have audaciously decided to apply MCPT to the biomedical volumes in attempt to increases the realism and the level of detail in data representation.</p><p>In this paper, we present a practical framework that includes different visualization techniques, including AR 2 T. Our framework allows the user to interact with the data in high quality for the deterministic algorithms (iso-surface, MIP, DVR), and in low quality for the stochastic AR 2 T. Moreover, the framework supports a mixed modality that works as follows. By default, the data is rendered by DVR. It allows to interact with the data, adjust the transfer function, and apply clip planes. However, a high-quality AR 2 T image can be generated at any moment by the user request without explicitly switching between rendering algorithms. The quality improves progressively, and the process can be stopped as soon as the desired quality is achieved. As an alternative, the improvement stops automatically, when the algorithm converged. The framework permits to compare different rendering techniques directly, i.e., using the same view/light position and transfer functions. It, therefore, promotes further research on the importance of realism in visualising biomedical volumes, providing medical experts with an immediate one-to-one visual comparison between different data representations. Related Work. Various deterministic approaches were applied in an attempt to increase the realism of volume rendering. Above all, the direct volume rendering technique has been enriched with local and global illumination, combined with ambient occlusion and shadowing <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b23">24]</ref>. However, these approaches are not able to produce photo-realistic images, being based on a very simplified and far-fetched model.</p><p>One interesting technique for improved DVR, which includes realistic effects and physically based lighting, was proposed by <ref type="bibr">Kroes et al. in 2012 [17]</ref>. They were the first who demonstrated that, if properly optimized, ray tracing of volumetric data can be done interactively. However, their method is based on single scattering and consequently does not produce photo-realistic images. Despite that, this approach still arouses interest <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b29">30]</ref>. In fact, as far as we know, since then no one has presented any different reproducible technique on photo-realistic rendering of biomedical volumetric data.</p><p>Recently, the cinematic rendering (CR) 3D technique was introduced <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b9">10]</ref>. It is available as a part of commercial closed-source software, and the implementation details are not publicly available. Several studies compared DVR and CR images, produced by different software <ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b28">29]</ref>. However, the one-to-one comparison is difficult, because it is not practically possible to align the data by means of visual settings and, above all, positioning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>The entire framework is written from scratch in C++ using Qt. The whole rendering runs on GPU and is implemented in OpenGL Shading Language (GLSL). In the following subsections, we describe the techniques we used within the framework, giving the details only for AR 2 T for the sake of brevity. The quality of the images produced with the different techniques is difficult to assess with a numerical index; following <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b28">29]</ref>, we carried out a survey, based on the visual comparison of the proposed methods (see Results).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Deterministic Rendering Algorithms</head><p>First of all, we implemented the most popular rendering techniques for biomedical volumetric data: iso-surface, MIP, and DVR. They gave us the basis for the direct comparison of proposed methods. Then, we enriched our DVR model with local and global illumination, applying various approaches <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b19">20]</ref> in an attempt to improve realism and receive feedback from clinicians (see Fig. <ref type="figure" target="#fig_0">1</ref>). It was immediately clear that despite these techniques can improve realism by introducing deep shadows, they are not suitable for the visualization of biomedical volumes because hide information in the shadowed areas without increasing anyhow the level of detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Advanced Realistic Rendering Technique</head><p>There are two modalities of AR 2 T visualization: pure AR 2 T and mixed DVR-AR 2 T. When pure AR 2 T is active, the interactivity is achieved by the execution of just one iteration of the algorithm. When the interaction is finished (e.g., the mouse button is released), 10 iterations of AR 2 T are executed. To improve the quality, Gaussian blur filter <ref type="bibr" target="#b0">[1]</ref> is applied during the interactions, so the overall image is understandable. On request, the iterative algorithm improves the quality until the user stops the process or the convergence is achieved (see subsection Convergence). In mixed modality, the interactions are in DVR, and the AR 2 T runs on request. When the interaction restarts, the visualization automatically switches to DVR.</p><p>Our AR 2 T is inspired by MCPT applied to analytically generated surfaces and isotropic volumes <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b25">26]</ref>. In our model, we provide advanced camera settings (aperture, focal distance, see Fig. <ref type="figure" target="#fig_1">2</ref>) and support an unlimited number of light sources of any shape. For practical reasons, we limit the number of ray scatters to 10 (in our experiments, we did not see any improvement in realism for a larger number of scatters). In the following subsections, we step-by-step describe the implementation details of AR 2 T, to allow the reproducibility of our results.</p><p>GPU Implementation. To be independent in the choice of hardware to run our framework, we implement AR 2 T in GLSL. Unfortunately, there are two main issues to resolve for Monte-Carlo path tracing in OpenGL: 1. recursion, and 2. random number generation.</p><p>Recursion. As GLSL memory model does not allow for recursive function calls, which are essential for MCPT, we simulated the recursion by exploiting multiple render targets feature of modern GPUs. This feature allows the rendering pipeline to render images to multiple render target textures at once. Indeed, the information we need after every scatter of a ray is the resulting colour, the position where the scatter occurred, and the direction in which the ray scatters. Therefore, three target textures are necessary for every rendering step. Moreover, two frame buffers are used in a ping pong blending manner (as described in <ref type="bibr" target="#b15">[16]</ref>) to enable the reading of textures filled on the previous step. Thus, in the first step, the ray origin and direction are calculated according to the camera properties and position. In the subsequent steps, the ray origin and direction are read from the corresponding textures.</p><p>On any step, three situations are possible: (1) The ray does not hit the volume or the light source. In this case, a zero-length vector is saved to direction render target -it indicates that the ray scattering finishes here, and the resulting colour components are set to zeros (for ulterior speed up, and considering that the usual background for biomedical visualization is black, we do not model the Cornel box outside the volume). ( <ref type="formula">2</ref>) The ray hits the light source. Then, the resulting colour, accumulated until this moment, is attenuated by the light's colour, and, again, the ray scattering finishes here. <ref type="bibr" target="#b2">(3)</ref> The volume is hit. The scattering continues, until the ray encounters any of the stopping conditions, or the scatter number limit is achieved. In this case, the resulting colour components are set to zeros.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Random Number Generation.</head><p>To provide the uniformly distributed random numbers on the fragment stage of the OpenGL pipeline, we generate a pool of 50 additional two-dimensional textures of viewport size and fill them with uniformly distributed random numbers generated with std::uniform int distribution. In each step, we randomly choose four textures from the pool to provide random numbers: two for advanced Woodcock tracking, one for scattering, and one for sampling direction. Every 100 iterations of the algorithm, we regenerate the pool of random numbers to avoid the quality improvement stuck. On Intel(R) Core(TM) i5-7600K CPU @ 3.80 GHz, the generation of the pool takes ∼ 1600 ms, for viewport size 1727 × 822. It occupies ∼270 Mb of RAM. Advanced Woodcock Tracking. For volume sampling, we implemented the advanced Woodcock tracking technique, described in <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b26">27]</ref>. When the maximum volume density is much larger than the typical density in the volume, the Woodcock tracking can be improved by breaking the original volume into subvolumes, each having a small density variation. For this aim, every time the transfer function changes, we construct a voxel grid that has the local maxima of the density in its nodes. Then, the voxel grid is straightforwardly applied on Woodcock tracking, giving up to 5x speed-up respect to the basic implementation. On NVIDIA GeForce GTX 1060, the voxelization process, implemented in GLSL and executed on a fragment stage, takes up to 500 ms for a voxel grid node size s = 4, and depending on the volume size. The additional memory needed for the voxel grid storage is 1/s 3 of the original volume size.</p><p>Phase Functions. In AR 2 T, we use four well-known phase functions, described in <ref type="bibr" target="#b25">[26]</ref>: Lambertian, metal, dielectric, and isotropic. Every time the ray hits a volume voxel, we choose which phase function to apply based on the density of the voxel: if the density is less than some threshold t 0 , it causes dielectric scatter; when it is higher than some threshold t 1 , it causes metal scatter; otherwise, as proposed in <ref type="bibr" target="#b25">[26]</ref>, we randomly decide if to sample toward the light sources or to pick direction according to the voxel reflection (mixture probability density function). When we decide to sample according to the hit voxel direction, we choose between surface and volumetric scattering. Following <ref type="bibr" target="#b16">[17]</ref>, we switch between Lambertian and isotropic phase functions, basing not only on the voxel density but also on the local gradient. Thus, Lambertian is chosen with the following probability:</p><formula xml:id="formula_0">p = 1 -α( -→ v ) • (1 -e -s•m( - → v ) ),<label>(1)</label></formula><p>where α( -→ v ) ∈ [t 0 , t 1 ] is the voxel density (or opacity), m( -→ v ) is the normalized gradient magnitude, and s is the hybrid scattering factor. Image Generation. When the first iteration of AR 2 T is completed, the result contained in the colour texture (see Recursion for rehearse) is blit into the output rendering frame buffer to be immediately displayed. Moreover, it is saved locally to be summed with the results of the next iterations. On the next iterations, the accumulated result is saved into the local buffer, and then the medium (e.g. the sum divided by the iterations number) is blit into the output frame buffer and displayed.</p><p>Convergence. As a convergence criterion, we use mean square displacement (MSD) between the iterations <ref type="bibr">[22]</ref>. After each iteration, the square displacement between the current and the previous pixel colour components is calculated directly on a fragment stage. When MSD becomes less than = 5 • 10 -7 , the iterations stop, and the method is considered converged (see Fig. <ref type="figure" target="#fig_4">5</ref>). In our experiments, the convergence was achieved within 800 iterations for all images, and it took up to 100 s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>In our experiments, we have used spiral CT (Computed Tomography), MRI (Magnetic Resonance Imaging), and CBCT (Cone-Beam Computed Tomography) publicly available data sets. The CBCT data sets were acquired by SeeFactorCT3 TM (human) and Vimago TM GT30 (vet) Multimodal Medical Imaging Platforms in our layout and are available on https://kaggle.com/ datasets/imaginar2t/cbctdata. To validate the superiority of the AR 2 T over the other methods implemented in our platform, we ask a group of clinicians to participate into the survey. 22 participants (7 orthopedic surgeons, 1 trauma surgeon, 1 neurosurgeon, 7 interventional radiologists, 6 veterinaries) evaluated the data sets on Fig. <ref type="figure" target="#fig_5">6</ref>, visualized  using MIP, iso-surface, DVR with local illumination, DVR with local and global illumination (linear lighting), and AR 2 T, voting the best overall image, the most realistic one, the more diagnostic (if any), and the more valuable in their practice.</p><p>According to Table <ref type="table" target="#tab_0">1</ref>, the AR 2 T provides the best overall, the most realistic, diagnostic, and valuable images. Participants commented that the images produced with AR 2 T "provide better resolution, amazing clarity with less artifacts and noise, better sharpness and contrast, are the closest in colour to real tissue and the most similar to a dissected body deprived of blood, help to understand the anatomy and the pathology of the district, have excellent qualities in general surgery for the definition of the splanchnic organs, for diagnosis and preoperative study". Meanwhile the others are "either glossy, or too colorized or not as sharp, and seem artificial". Some participants stated that DVR images are the sharpest and seem to be more detailed ("peritoneal meso is better detected, subxiphoid is more visible"), but also it was mentioned that "too much sharpening causes misleading images creating artificial findings". Some participants noted the diagnostic usefulness of MIP for vascular issues. Participants who stated that none of the images were diagnostic or useful admitted that they did not deal with the presented anatomical structures in their practice or had never used 3D rendering and could not assess its practical application. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>The main result of our research is the novel advanced realistic rendering technique-AR 2 T (see Fig. <ref type="figure" target="#fig_1">2</ref>, 3, 4), implemented within a practical framework, that allows to compare different rendering techniques directly (Fig. <ref type="figure" target="#fig_5">6</ref>).</p><p>Despite our model supports any number of light sources, all images (except Fig. <ref type="figure" target="#fig_0">1</ref>), presented in this paper, were generated with a single spherical light source, placed right in front of the volume. We plan to dedicate extra time to find the best light configuration from the clinical point of view. Moreover, our future research will be focused on the ulterior improvement of AR 2 T speed and quality, and the comparison metrics.</p><p>At the moment of writing this paper, we are evaluating free access to our framework's executable to share our results, facilitate the comparison with other approaches, and stimulate further research on the usefulness of photo-realistic 3D images in medicine.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Direct Volume Rendering. Human skull CBCT rendered with DVR: a. Local illumination; b. Local and global illumination, linear lighting; c. Local and global illumination, conical lighting; d. Local and global illumination with translucency, conical lighting. For all techniques, Phong local illumination was used.</figDesc><graphic coords="3,58,98,53,90,334,60,85,81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. AR 2 T: Camera Aperture &amp; Focal Distance. a. Human skull CBCT; in focus: nasal bone, infraorbital foramen, vomer. b. Dog abdomen CBCT with contrast; in focus: intrahepatic portocaval shunt, main portal vein, right kidney.</figDesc><graphic coords="4,43,29,443,45,337,39,104,50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. AR 2 T: Hard &amp; Soft Tissues. a. Human brain MRI, https://openneuro.org/ datasets/ds001780/versions/1.0.0: identified pre-central gyrus of frontal lobe, genu of the corpus callosum, lateral ventricle, optic nerve, pons, cerebellum, medulla oblongata, cerebellar tonsil; b. Spiral CT Manix, https://public.sethealth.app/manix.raw.gz; c. Human knee CBCT (post-mortem).</figDesc><graphic coords="5,60,96,405,56,330,37,97,54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. AR 2 T: Translucency. a. Human foot CBCT (post-mortem); well-distinguished distal tibiofibular joint (syndesmosis), talus, navicular, cuboid, middle cuneiform, fifth metatarsal, under the semitransparent skin. b. Cat thorax CBCT; semitransparent lungs and trachea.</figDesc><graphic coords="6,44,79,419,45,334,66,99,91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Convergence Plots (Fig. 2a-4b). Vertical lines indicate the number of iterations needed for convergence (left) and the convergence time in seconds (right). All images were generated on NVIDIA GeForce GTX 1060 6 Gb, Intel(R) Core(TM) i5-7600K CPU @ 3.80 GHz RAM 16 Gb, viewport size 1727 × 822. All data sets are encoded in 16-bit format.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. One-To-One Rendering Comparison. Human knee CBCT post-mortem (top) and dog abdomen CBCT with contrast (bottom): MIP (a), Iso-surface (b), DVR with local (c) and global illumination, linear lighting (d), AR 2 T (e). No light/view or transfer function changes across a-e.</figDesc><graphic coords="8,44,79,54,62,334,57,152,08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Survey Responses Indicating How Many of 22 Participants Voted the Method that Produces: Best Overall, Most Realistic, More Diagnostic (If Any), and More Valuable Images, by evaluating Fig. 6 DVR † -local and global illumination, linear lighting; DVR -local illumination.</figDesc><table><row><cell>Method</cell><cell cols="8">Best Overall Most Realistic More Diagnostic More Valuable</cell></row><row><cell></cell><cell cols="2">Knee Abs</cell><cell cols="2">Knee Abs</cell><cell cols="2">Knee Abs</cell><cell cols="2">Knee Abs</cell></row><row><cell>(e) AR 2 T</cell><cell>18</cell><cell>16</cell><cell>17</cell><cell>17</cell><cell>18</cell><cell>12</cell><cell>19</cell><cell>15</cell></row><row><cell>(d) DVR  †</cell><cell>4</cell><cell>3</cell><cell>3</cell><cell>3</cell><cell>1</cell><cell>2</cell><cell>2</cell><cell>3</cell></row><row><cell>(c) DVR</cell><cell>-</cell><cell>3</cell><cell>1</cell><cell>2</cell><cell>-</cell><cell>2</cell><cell>-</cell><cell>2</cell></row><row><cell cols="2">(b) Iso-surf. -</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>(a) MIP</cell><cell>-</cell><cell>-</cell><cell>1</cell><cell>-</cell><cell>1</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>None</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>2</cell><cell>6</cell><cell>1</cell><cell>2</cell></row><row><cell>Note:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="http://www.gamerendering.com/2008/10/11/gaussian-blur-filter-shader/" />
		<title level="m">Gaussian blur filter shader</title>
		<imprint>
			<date type="published" when="2023-03-08">08 Mar 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">An interactive mixed reality ray tracing rendering mobile application of medical data in minimally invasive</title>
		<author>
			<persName><forename type="first">Abou</forename><surname>El-Seoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mady</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rashed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Improved woodcock tracking on Monte Carlo simulations for medical applications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Behlouli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Visvikis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bert</surname></persName>
		</author>
		<idno type="DOI">10.1088/1361-6560/aae937</idno>
		<ptr target="https://doi.org/10.1088/1361-6560/aae937" />
	</analytic>
	<monogr>
		<title level="j">Phys. Med. Biol</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page">225005</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Cone-beam computed tomography cinematic rendering: clinical, teaching and research applications</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Bueno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Estrela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Granjeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R D A</forename><surname>Estrela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Azevedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Diogenes</surname></persName>
		</author>
		<idno type="DOI">10.1590/1807-3107bor-2021.vol35.0024</idno>
		<ptr target="https://doi.org/10.1590/1807-3107bor-2021" />
	</analytic>
	<monogr>
		<title level="j">Braz. Oral Research</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page">24</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Fast and accurate illumination estimation using LDR panoramic images for realistic rendering</title>
		<author>
			<persName><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2022.3205614</idno>
		<ptr target="https://doi.org/10.1109/TVCG.2022.3205614" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Visual Comput. Graphics</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Cinematic rendering -an alternative to volume rendering for 3D computed tomography imaging</title>
		<author>
			<persName><forename type="first">E</forename><surname>Dappa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Higashigaito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fornaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Leschka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wildermuth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Alkadhi</surname></persName>
		</author>
		<idno type="DOI">10.1007/s13244-016-0518-1</idno>
		<ptr target="https://doi.org/10.1007/s13244-016-0518-1" />
	</analytic>
	<monogr>
		<title level="j">Insights Imaging</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="849" to="856" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Forensic 3D visualization of CT data using cinematic volume rendering: a preliminary study</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Ebert</surname></persName>
		</author>
		<idno type="DOI">10.2214/AJR.16.16499</idno>
		<ptr target="https://doi.org/10.2214/AJR.16.16499" />
	</analytic>
	<monogr>
		<title level="j">Am. J. Roentgenol</title>
		<imprint>
			<biblScope unit="volume">208</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="233" to="240" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Cinematic rendering in CT: a novel, lifelike 3D visualization technique</title>
		<author>
			<persName><forename type="first">M</forename><surname>Eid</surname></persName>
		</author>
		<idno type="DOI">10.2214/AJR.17.17850</idno>
		<ptr target="https://doi.org/10.2214/AJR.17.17850" />
	</analytic>
	<monogr>
		<title level="j">Am. J. Roentgenol</title>
		<imprint>
			<biblScope unit="volume">209</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="370" to="379" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Comparison of cinematic rendering and computed tomography for speed and comprehension of surgical anatomy</title>
		<author>
			<persName><forename type="first">M</forename><surname>Elshafei</surname></persName>
		</author>
		<idno type="DOI">10.1001/jamasurg.2019.1168</idno>
		<ptr target="https://doi.org/10.1001/jamasurg.2019.1168" />
	</analytic>
	<monogr>
		<title level="j">JAMA Surg</title>
		<imprint>
			<biblScope unit="volume">154</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="738" to="744" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Real-time Monte-Carlo path tracing of medical volume data</title>
		<author>
			<persName><forename type="first">K</forename><surname>Engel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">GPU Technology Conference</title>
		<meeting><address><addrLine>San Jose Convention Center, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-04-07">4-7 Apr 2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">GPU Gems: Programming Techniques, Tips, and Tricks for Real-time Graphics</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fernando</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Addison-Wesley Reading</publisher>
			<biblScope unit="volume">590</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Production volume rendering: Siggraph 2017 course</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wrenninge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kulla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Habel</surname></persName>
		</author>
		<idno type="DOI">10.1145/3084873.3084907</idno>
		<ptr target="https://doi.org/10.1145/3084873.3084907" />
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH 2017 Courses</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Local ambient occlusion in direct volume rendering</title>
		<author>
			<persName><forename type="first">F</forename><surname>Hernell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ljung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ynnerman</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2009.45</idno>
		<ptr target="https://doi.org/10.1109/TVCG.2009.45" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Visual Comput. Graphics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="548" to="559" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Monte Carlo ray tracing</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Jensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGGRAPH</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">MDCT angiography with 3D rendering: a novel cinematic rendering algorithm for enhanced anatomic detail</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lugo-Fagundo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Fishman</surname></persName>
		</author>
		<idno type="DOI">10.2214/AJR.17.17903</idno>
		<ptr target="https://doi.org/10.2214/AJR.17.17903" />
	</analytic>
	<monogr>
		<title level="j">Am. J. Roentgenol</title>
		<imprint>
			<biblScope unit="volume">209</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="309" to="312" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A model for volume lighting and modeling</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kniss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Premoze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shirley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mcpherson</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2003.1196003</idno>
		<ptr target="https://doi.org/10.1109/TVCG.2003.1196003" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Visual Comput. Graphics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="150" to="162" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Exposure render: an interactive photo-realistic volume rendering framework</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kroes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">H</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Botha</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0038586</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0038586" />
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">38596</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Computer-assisted surgery and navigation in foot and ankle: state of the art and fields of application</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kutaish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Acker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Drittenbass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Assal</surname></persName>
		</author>
		<idno type="DOI">10.1302/2058-5241.6.200024</idno>
		<ptr target="https://doi.org/10.1302/2058-5241.6" />
	</analytic>
	<monogr>
		<title level="j">EFORT Open Rev</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="531" to="538" />
			<date type="published" when="2021">2021. 200024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Rendering participating media with bidirectional path tracing</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Lafortune</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">D</forename><surname>Willems</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-7091-7484-5_10</idno>
		<ptr target="https://doi.org/10.1007/978-3-7091-7484-510" />
	</analytic>
	<monogr>
		<title level="m">EGSR 1996. E</title>
		<editor>
			<persName><forename type="first">X</forename><surname>Pueyo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Schröder</surname></persName>
		</editor>
		<meeting><address><addrLine>Vienna</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="91" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Local and global illumination in the volume rendering integral</title>
		<author>
			<persName><forename type="first">N</forename><surname>Max</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<pubPlace>Livermore, CA (United States</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Lawrence Livermore National Lab. (LLNL)</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Mean square displacement analysis of single-particle trajectories with localization error: Brownian motion in an isotropic medium</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mcnamara</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevE.82.041914</idno>
		<ptr target="https://doi.org/10.1103/PhysRevE.82.041914" />
	</analytic>
	<monogr>
		<title level="m">The University of Dublin</title>
		<meeting><address><addrLine>Michalet, X.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003. 2010</date>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">41914</biblScope>
		</imprint>
	</monogr>
	<note>Illumination in computer graphics</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Cinematic rendering in rheumatic diseases-photorealistic depiction of pathologies improves disease understanding for patients</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Pachowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Med</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<idno type="DOI">10.3389/fmed.2022.946106</idno>
		<ptr target="https://doi.org/10.3389/fmed.2022.946106" />
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page">946106</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">GPU-based Monte-Carlo volume raycasting</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Salama</surname></persName>
		</author>
		<idno type="DOI">10.1109/PG.2007.27</idno>
		<ptr target="https://doi.org/10.1109/PG.2007.27" />
	</analytic>
	<monogr>
		<title level="m">15th Pacific Conference on Computer Graphics and Applications (PG 2007)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="411" to="414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Accuracy of the preoperative planning for cementless total hip arthroplasty. a randomised comparison between three-dimensional computerised planning and conventional templating</title>
		<author>
			<persName><forename type="first">E</forename><surname>Sariali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mauprivez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Khiami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pascal-Mousselard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Catonné</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.otsr.2011.09.023</idno>
		<ptr target="https://doi.org/10.1016/j.otsr.2011.09.023" />
	</analytic>
	<monogr>
		<title level="j">Orthop. Traumatol. Surg. Res</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="151" to="158" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Realistic Ray Tracing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Shirley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Morley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>AK Peters Ltd</publisher>
			<pubPlace>Natick</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Free path sampling in high resolution inhomogeneous participating media</title>
		<author>
			<persName><forename type="first">L</forename><surname>Szirmay-Kalos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tóth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Magdics</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-8659.2010.01831.x</idno>
		<ptr target="https://doi.org/10.1111/j.1467-8659.2010.01831.x" />
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="85" to="97" />
			<date type="published" when="2011">2011</date>
			<publisher>Wiley Online Library</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Patient-specific instrument-assisted minimally invasive internal fixation of calcaneal fracture for rapid and accurate execution of a preoperative plan: a retrospective study</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12891-020-03439-3</idno>
		<ptr target="https://doi.org/10.1186/s12891-020-03439-3" />
	</analytic>
	<monogr>
		<title level="j">BMC Musculoskelet. Disord</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Interactive, in-browser cinematic volume rendering of medical images</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<idno type="DOI">10.1080/21681163.2022.2145239</idno>
		<ptr target="https://doi.org/10.1080/21681163.2022.2145239" />
	</analytic>
	<monogr>
		<title level="j">Comput. Methods Biomech. Biomed. Eng. Imaging Visual</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Woodcock tracking based fast Monte Carlo direct volume rendering method</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.16182/j.issn1004731x.joss.201705026</idno>
		<ptr target="https://doi.org/10.16182/j.issn1004731x.joss" />
	</analytic>
	<monogr>
		<title level="j">J. Syst. Simul</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1125" to="1131" />
			<date type="published" when="2017">2017. 201705026</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
