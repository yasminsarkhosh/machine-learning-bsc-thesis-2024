<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DARC: Distribution-Aware Re-Coloring Model for Generalizable Nucleus Segmentation</title>
				<funder ref="#_gunxeMg">
					<orgName type="full">Guangdong Basic and Applied Basic Research Foundation</orgName>
				</funder>
				<funder ref="#_3jGsPyj">
					<orgName type="full">Guangdong Provincial Key Laboratory of Human Digital Twin</orgName>
				</funder>
				<funder ref="#_EXTKzPb">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder>
					<orgName type="full">CAAI-Huawei MindSpore Open Fund</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Shengcong</forename><surname>Chen</surname></persName>
							<email>c.shengcong@mail.scut.edu.cn</email>
							<idno type="ORCID">0000-0002-8019-9675</idno>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic and Information Engineering</orgName>
								<orgName type="institution">South China University of Technology</orgName>
								<address>
									<postCode>510000</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Changxing</forename><surname>Ding</surname></persName>
							<email>chxding@scut.edu.cn</email>
							<idno type="ORCID">0000-0001-7232-3181</idno>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic and Information Engineering</orgName>
								<orgName type="institution">South China University of Technology</orgName>
								<address>
									<postCode>510000</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Pazhou Lab</orgName>
								<address>
									<postCode>510330</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
							<idno type="ORCID">0000-0001-7225-5449</idno>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">School of Computer Science</orgName>
								<orgName type="department" key="dep2">The Faculty of Engineering</orgName>
								<orgName type="institution">The University of Sydney</orgName>
								<address>
									<postCode>2008</postCode>
									<settlement>Darlington</settlement>
									<region>NSW</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hao</forename><surname>Chen</surname></persName>
							<idno type="ORCID">0000-0002-8400-3780</idno>
							<affiliation key="aff3">
								<orgName type="department">Department of Computer Science and Engineering and Department of Chemical and Biological Engineering</orgName>
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
								<address>
									<settlement>Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DARC: Distribution-Aware Re-Coloring Model for Generalizable Nucleus Segmentation</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="591" to="601"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">2882F3E71C37B78ACE26DBC5F0EE4D09</idno>
					<idno type="DOI">10.1007/978-3-031-43987-2_57</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-24T11:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Domain Generalization</term>
					<term>Nucleus Segmentation</term>
					<term>Instance Normalization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Nucleus segmentation is usually the first step in pathological image analysis tasks. Generalizable nucleus segmentation refers to the problem of training a segmentation model that is robust to domain gaps between the source and target domains. The domain gaps are usually believed to be caused by the varied image acquisition conditions, e.g., different scanners, tissues, or staining protocols. In this paper, we argue that domain gaps can also be caused by different foreground (nucleus)background ratios, as this ratio significantly affects feature statistics that are critical to normalization layers. We propose a Distribution-Aware Re-Coloring (DARC) model that handles the above challenges from two perspectives. First, we introduce a re-coloring method that relieves dramatic image color variations between different domains. Second, we propose a new instance normalization method that is robust to the variation in foreground-background ratios. We evaluate the proposed methods on two H&amp;E stained image datasets, named CoNSeP and CPM17, and two IHC stained image datasets, called DeepLIIF and BC-DeepLIIF. Extensive experimental results justify the effectiveness of our proposed DARC model. Codes are available at https://github.com/csccsccsccsc/DARC.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Automatic nucleus segmentation has captured wide research interests in recent years due to its importance in pathological image analysis <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref>. However, as shown in Fig. <ref type="figure" target="#fig_0">1</ref>, the variations in image modalities, staining protocols, scanner types, and tissues significantly affect the appearance of nucleus images, resulting in notable gap between source and target domains <ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref>. If a number of target domain samples are available before testing, one can adopt domain adaptation algorithms to transfer the knowledge learned from the source domain to the target domain <ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b9">[9]</ref><ref type="bibr" target="#b10">[10]</ref>. Unfortunately, in real-world applications, it is usually expensive and time-consuming to collect new training sets for the ever changing target domains; moreover, extra computational cost is required, which is usually unrealistic for the end users. Therefore, it is highly desirable to train a robust nucleus segmentation model that is generalizable to different domains.</p><p>In recent years, the research on domain generalization (DG) has attracted wide attention. Most existing DG works are proposed for classification tasks <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b13">13]</ref> and they can be roughly grouped into data augmentation-, representation learning-, and optimization-based methods. The first category of methods <ref type="bibr" target="#b14">[14]</ref><ref type="bibr" target="#b15">[15]</ref><ref type="bibr" target="#b16">[16]</ref><ref type="bibr" target="#b18">[17]</ref> focus on the way to diversify training data styles and expect the enriched styles cover those appeared in target domains. The second category of methods aim to obtain domain-invariant features. This is usually achieved via improving model architectures <ref type="bibr" target="#b19">[18]</ref><ref type="bibr" target="#b20">[19]</ref><ref type="bibr" target="#b21">[20]</ref> or introducing novel regularization terms <ref type="bibr" target="#b22">[21,</ref><ref type="bibr" target="#b23">22]</ref>. The third category of methods <ref type="bibr" target="#b24">[23]</ref><ref type="bibr" target="#b25">[24]</ref><ref type="bibr" target="#b26">[25]</ref><ref type="bibr" target="#b27">[26]</ref> develop new model optimization strategies, e.g., meta-learning, that improve model robustness via artificially introducing domain shifts during training.</p><p>It is a consensus that a generalizable nucleus segmentation model should be robust to image appearance variation caused by the change in staining protocols, scanner types, and tissues, as illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>. In this paper, we argue that it is also desirable to be robust to the ratio between foreground (nucleus) and background pixel numbers. This ratio changes the statistics of each feature map channel, and affects the robustness of normalization layers, e.g., instance normalization (IN). We will empirically justify its impact in Sect. 2.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Overview</head><p>In this paper, we adopt a U-Net-based model similar to that in <ref type="bibr" target="#b0">[1]</ref> as the baseline. It performs both semantic segmentation and contour detection for nucleus instances. The area of each nucleus instance is obtained via subtraction between the segmentation and contour prediction maps <ref type="bibr" target="#b0">[1]</ref>. Details of the baseline model is provided in the supplementary material. To handle domain variations, we adopt IN rather than batch normalization (BN) in the U-Net model.</p><p>Our proposed Distribution-Aware Re-Coloring model (DARC) is illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>. Compared with the baseline, DARC replaces the IN layers with the proposed Distribution-Aware Instance Normalization (DAIN) layers. DARC first re-colors each image to relieve the influence caused by image acquisition conditions. The re-colored image is then fed into the U-Net encoder and the ratio prediction head. This head predicts the ratio between foreground and background pixel numbers. With the predicted ratio, the DAIN layers can estimate feature statistics more robustly and facilitate more accurate nucleus segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Nucleus Image Re-Coloring</head><p>We propose the Re-Coloring (RC) method to overcome the color change in different domains. Specifically, given a RGB image I, e.g., an H&amp;E or IHC stained image, we first obtain its grayscale image I g . We then feed I g into a simple module T that consists of a single residual block and a 1 × 1 convolutional layer with output channel number of 3. In this way, we obtain an initial re-colored image I r .</p><p>However, de-colorization results in the loss of fine-grained textures and may harm the segmentation accuracy. To handle this problem, we compensate I r with the original semantic information contained in I. Recent works <ref type="bibr" target="#b41">[40]</ref> show that semantic information can be reflected via the order of pixels according to their gray value. Therefore, we adopt the Sort-Matching algorithm <ref type="bibr" target="#b42">[41]</ref> to combine the semantic information in I with the color values in I r . Details of RC is presented in Algorithm 1, in which Sort and ArgSort denote channel-wisely sorting the values and obtaining the sorted values and indices respectively, and</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1. Re-Coloring</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input:</head><p>The input RGB image I ∈ R H×W ×3 ; The module T whose input and output channel numbers are 1 and 3, respectively; Output:</p><p>The re-colored image Io ∈ R AssignV alue denotes re-assembling the sorted values according to the provided indices. Details of the module T are included in the supplementary material. Via RC, the original fine-grained structure information from I g is recovered in I r . In this way, the re-colored image is advantageous in two aspects. First, the appearance difference between pathological images caused by the change in scanners and staining protocols is eliminated. Second, the re-colored image preserves fine-grained structure information, enabling precise instance segmentation to be possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Distribution-Aware Instance Normalization</head><p>Due to dramatic domain gaps, feature statistics may differ significantly between domains <ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref>, which means that feature statistics obtained from the source domain may not apply to the target domain. Therefore, existing DG works usually replace BN with IN for feature normalization <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b20">19]</ref>. However, for dense-prediction tasks like semantic segmentation or contour detection, adopting IN alone cannot fully address the feature statistics variation problem. This is because feature statistics are also relevant to the ratio between foreground and background pixel numbers. Specifically, an image with more nucleus instances produces more responses in feature maps and thus higher feature statistic values, and vice versa. The difference in this ratio causes interference to nucleus segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2. Distribution-Aware Instance Normalization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input:</head><p>Original feature maps X ∈ R H×W ×C . The C-dimensional feature vector on its pixel (i, j) is denoted as xij;</p><p>The modules Eμ and E δ that re-estimate feature statistics; Δsra ∈ R 1×1×C that is obtained via running mean of Δs in the training stage;</p><p>The momentum factor α used to update Δsra ; (Optional) Δs = f (ρ); Output:</p><p>Normalized feature maps Y ∈ R H×W ×C ; To verify the above viewpoint, we evaluate the baseline model under different foreground-background ratios. Specifically, we first remove the foreground pixels via in-painting <ref type="bibr" target="#b28">[27]</ref>, and then pad the original testing images with the obtained background patches. We adopt B to denote the ratio between the size of the obtained new image and the original image size. Compared with the original images, the new images have the same foreground regions but more background pixels, and thus have different foreground-background ratios. Finally, we evaluate the performance of the baseline model with different B values. Experimental results are presented in Table <ref type="table" target="#tab_0">1</ref>. It is shown that the value of B affects the model performance significantly.</p><formula xml:id="formula_0">1: μ ← 1 HW H i=1 W j=1 xij 2: δ 2 ← 1 HW H i=1 W j=1 (xij -μ)</formula><p>The above problem is common in nucleus segmentation because pathological images from different organs or tissues tend to have significantly different foreground-background ratios. However, this phenomenon is often ignored in existing research. To handle this problem, we propose the Distribution-Aware Instance Normalization (DAIN) method to re-estimate feature statistics that account for different ratios of foreground and background pixels. Details of DAIN is presented in Algorithm 2. The structures of E μ and E δ are included in the supplemental materials. As shown in Fig. <ref type="figure" target="#fig_1">2</ref>, to obtain the foreground-background ratio ρ of one input image, we first feed it to the model encoder with Δs ra as the additional input. Δs ra acts as pseudo residuals of feature statistics and is obtained in the training stage via averaging Δs in a momentum fashion. The output features by the encoder are used to predict the foreground-background ratio ρ with a Ratio-Prediction Head (RPH). ρ is then utilized to estimate the residuals of feature statistics: Δs = f (ρ). Here, f is a 1 × 1 convolutional layer that transforms ρ to a feature vector whose dimension is the same as the target layer's channel number. After that, the input image is fed into the model again with Δs as additional input and finally makes more accurate predictions.</p><p>The training of RPH requires an extra loss term L rph , which is formulated as bellow:</p><formula xml:id="formula_1">L rph = L BCE (ρ, ρ g ) + L MSE (f (ρ), f(ρ g )),<label>(1)</label></formula><p>where ρ g denotes the ground truth foreground-background ratio, and L BCE and L MSE denote the binary cross entropy loss and the mean squared error, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets</head><p>The proposed method is evaluated on four datasets, including two H&amp;E stained image datasets CoNSeP <ref type="bibr" target="#b2">[3]</ref> and CPM17 <ref type="bibr" target="#b29">[28]</ref> and two IHC stained datasets DeepLIIF <ref type="bibr" target="#b30">[29]</ref> and BC-DeepLIIF <ref type="bibr" target="#b30">[29,</ref><ref type="bibr" target="#b33">32]</ref>. CoNSeP <ref type="bibr" target="#b2">[3]</ref> contains 28 training and 14 validation images, whose sizes are 1000×1000 pixels. The images are extracted from 16 colorectal adenocarcinoma WSIs, each of which belongs to an individual patient, and scanned with an Omnyx VL120 scanner within the department of pathology at University Hospitals Coventry and Warwickshire, UK. CPM17 <ref type="bibr" target="#b29">[28]</ref> contains 32 training and 32 validation images, whose sizes are 500 × 500 pixels. The images are selected from a set of Glioblastoma Multiforme, Lower Grade Glioma, Head and Neck Squamous Cell Carcinoma, and non-small cell lung cancer whole slide tissue images. DeepLIIF <ref type="bibr" target="#b30">[29]</ref> contains 575 training and 91 validation images, whose sizes are 512 × 512 pixels. The images are extracted from the slides of lung and bladder tissues. BC-DeepLIIF <ref type="bibr" target="#b30">[29,</ref><ref type="bibr" target="#b33">32]</ref> contains 385 training and 66 validation Ki67 stained images of breast carcinoma, whose sizes are 512 × 512 pixels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Implementation Details</head><p>In the training stage, patches of size 224 × 224 pixels are randomly cropped from the original samples. During training, the batch size is 4 and the total number of training iterations is 40,000. We use Adam algorithm for optimization, and the learning rate is initialized as 1e -3 , which is gradually decreased to 1e -5 during training. We adopt the standard augmentation, like image color jittering and Gaussian blurring. In all experiments, the segmentation and contour detection predictions are penalized using the binary cross entropy loss. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Experimental Results and Analyses</head><p>In this paper, the models are compared using the AJI <ref type="bibr" target="#b34">[33]</ref> and Dice scores. In the experiments, models trained on one of the datasets will be evaluated on the three unseen ones. To avoid the influence of the different sample numbers of the datasets, we calculate the average scores within each unseen domain respectively and then average them across domains.</p><p>In this paper, we re-implement some existing popular domain generalization algorithms for comparisons under the same training conditions. Specifically, we re-implement the TENT <ref type="bibr" target="#b35">[34]</ref>, BIN <ref type="bibr" target="#b20">[19]</ref>, DSU <ref type="bibr" target="#b21">[20]</ref>, Frequency Amplitude Normalization (AmpNorm) <ref type="bibr" target="#b37">[36,</ref><ref type="bibr" target="#b38">37]</ref>, SAN <ref type="bibr" target="#b36">[35]</ref> and EFDMix <ref type="bibr" target="#b41">[40]</ref>. We also evaluate the stain normalization <ref type="bibr" target="#b39">[38]</ref> and stain mix-up <ref type="bibr" target="#b40">[39]</ref> methods that are popular in pathological image analysis. Their performances are presented in Table <ref type="table" target="#tab_2">2</ref>. DARC all replaces all normalization layers with DAIN, while DARC enc replaces the normalization layers in the encoder with DAIN and uses BN in its decoder. As shown in Table <ref type="table" target="#tab_2">2</ref>, DARC enc achieves the best average performance among all methods. Specifically, DARC enc improves the baseline model's average AJI and Dice scores by 4.81% and 7.04%. Compared with the other domain generalization methods, DAIN, DAIN w/o Ratio, DARC all and DARC enc achieve impressive performances on BC-DeepLIIF, which justify that re-estimating the instancewise statistics is important for improving the domain generalization ability of models trained on BC-DeepLIIF. Qualitative comparisons are presented in Fig. <ref type="figure" target="#fig_2">3</ref>. Moreover, the complexity analysis between the baseline model and DARC enc is presented in Table <ref type="table" target="#tab_3">3</ref>.</p><p>We separately evaluate the effectiveness of RC and DAIN, and present the results in Table <ref type="table" target="#tab_2">2</ref>. Also, we train a variant model without foreground-background ratio prediction, which is denoted as 'DAIN w/o Ratio' in Table <ref type="table" target="#tab_2">2</ref>. Compared with the baseline model, RC improves the average AJI and Dice scores by 1.41% and 2.59%, and DAIN improves the average AJI and Dice scores by 1.13% and 4.08%. Compared with the variant model without foreground-background ratio prediction, DAIN improves the average AJI and Dice scores by 0.90% and 3.74%. Finally, the combinations of RC and DAIN, i.e., DARC all and DARC enc , achieve the best average scores. As shown in Table <ref type="table" target="#tab_2">2</ref>, DARC enc improves DARC all by 1.24% and 0.77% on AJI and Dice scores respectively. This is because after the operations by RC and DAIN in the encoder, the obtained feature maps are much more robust to the domain gaps, which enables the decoder to adopt the fixed statistics maintained during training. Moreover, using the fixed statistics is helpful to prevent the decoder from the influence of varied foreground-background ratios on feature statistics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we propose the DARC model for generalizable nucleus segmentation. To handle the domain gaps caused by varied image acquisition conditions, DARC first re-colors the input image while preserving its fine-grained structures as much as possible. Moreover, we find that the performance of instance normalization is sensitive to the varied ratios in foreground and background pixel numbers. This problem is well addressed by our proposed DAIN. Compared with existing works, DARC achieves significantly better performance on average across four benchmarks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Example image patches from different datasets. Their appearance differs significantly from each other due to variations in image modalities, staining protocols, scanner types, and tissues.</figDesc><graphic coords="2,57,30,54,05,309,13,72,67" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Overview of the DARC model. The whole model is trained in an end-to-end manner. DARC first re-colors each image to relieve the impact caused by different image acquisition conditions. The re-colored image is then fed into the U-Net encoder and the ratio prediction head. This head predicts the foreground-background ratio ρ. Then, the re-colored image is fed into DARC again with ρ for final prediction. For simplicity, we only illustrate the data-flow of the first DA-ResBlock in details.</figDesc><graphic coords="3,55,98,53,87,340,15,83,02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Qualitative comparisons between Different Models.</figDesc><graphic coords="8,41,79,53,69,339,88,171,13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Evaluation on the impact of foreground-background ratio to model performance. Both training and testing samples are obtained from CPM17. B denotes the background expansion factor, which directly affects the foreground-background ratio.</figDesc><table><row><cell cols="3">H×W ×3 ;</cell><cell></cell><cell></cell></row><row><cell>1: De-colorizing I to obtain Ig;</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2: Ir ← T (Ig)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">3: Reshaping I and Ir to R HW ×3</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">4: SortIndex ← ArgSort(ArgSort(I))</cell><cell></cell><cell></cell></row><row><cell>5: SortV alue ← Sort(Ir)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">6: Io ← AssignV alue(SortIndex, SortV alue)</cell><cell></cell></row><row><cell>7: return Io</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>B</cell><cell>1</cell><cell>2</cell><cell>4</cell><cell>6</cell></row><row><cell cols="5">AJI 65.11 59.11 53.41 54.13</cell></row><row><cell cols="5">Dice 86.14 84.05 80.97 79.75</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Comparisons in generalization performance on nucleus segmentation datasets. Results in each column are related to models trained on one domain and evaluated on the other three unseen domains. Methods marked by * are proposed in this paper. Results are in percentages.</figDesc><table><row><cell>Methods</cell><cell>CoNSeP</cell><cell>CPM17</cell><cell>DeepLIIF</cell><cell cols="2">BC-DeepLIIF Average</cell></row><row><cell></cell><cell cols="4">AJI Dice AJI Dice AJI Dice AJI Dice</cell><cell>AJI</cell><cell>Dice</cell></row><row><cell>Baseline (BN)</cell><cell cols="5">16.67 24.10 33.30 61.18 08.42 38.17 21.27 39.92 19.92 40.84</cell></row><row><cell>Baseline (IN)</cell><cell cols="5">32.13 48.67 33.94 65.83 41.48 67.17 21.52 37.49 32.27 54.79</cell></row><row><cell>BIN [19]</cell><cell cols="5">21.54 34.33 37.06 67.63 23.51 49.49 26.15 44.42 27.01 48.97</cell></row><row><cell>DSU [20]</cell><cell cols="5">21.42 34.66 39.12 66.55 27.21 55.10 25.09 41.83 28.21 49.53</cell></row><row><cell>SAN [35]</cell><cell cols="5">27.91 46.72 33.69 65.66 27.57 53.09 22.17 38.38 27.84 50.96</cell></row><row><cell cols="6">AmpNorm [36, 37] 35.52 55.89 33.39 58.69 39.91 66.58 23.79 37.81 33.15 54.74</cell></row><row><cell>StainNorm [38]</cell><cell cols="5">41.06 60.81 32.75 64.68 38.55 63.95 25.41 43.81 34.44 58.11</cell></row><row><cell>StainMix [39]</cell><cell cols="5">34.22 51.07 35.05 65.49 38.48 64.92 26.88 45.62 33.66 56.78</cell></row><row><cell cols="6">TENT (BN) [34] 38.61 58.11 35.04 64.62 33.77 59.76 23.55 40.91 32.74 55.85</cell></row><row><cell>TENT (IN) [34]</cell><cell cols="5">32.34 48.87 33.24 65.73 42.08 66.87 22.38 38.04 32.51 54.88</cell></row><row><cell>EFDMix [40]</cell><cell cols="5">40.13 58.74 33.29 65.25 39.06 64.60 25.92 42.38 34.60 57.74</cell></row><row><cell>RC (IN)*</cell><cell cols="5">37.21 57.53 36.98 67.71 35.53 62.03 24.98 42.25 33.68 57.38</cell></row><row><cell>DAIN*</cell><cell cols="5">33.86 50.08 30.62 64.64 37.93 65.56 31.20 53.15 33.40 58.87</cell></row><row><cell cols="6">DAIN w/o Ratio* 27.37 40.35 33.25 65.05 40.21 66.82 29.16 48.30 32.50 55.13</cell></row><row><cell>DARC all *</cell><cell cols="5">38.18 57.27 34.44 66.11 39.10 67.07 31.64 53.81 35.84 61.06</cell></row><row><cell>DARCenc*</cell><cell cols="5">40.04 58.73 35.60 66.50 40.11 68.23 32.56 53.86 37.08 61.83</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Complexity comparison between the baseline model and DARC.</figDesc><table><row><cell>Models</cell><cell cols="2">#Parameters (M) Inference Time (s/image)</cell></row><row><cell cols="2">Baseline (IN) 5.03</cell><cell>0.0164</cell></row><row><cell>DARCenc</cell><cell>5.47</cell><cell>0.0253</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement. This work was supported in part by <rs type="funder">Guangdong Basic and Applied Basic Research Foundation</rs> under Grant <rs type="grantNumber">2023A1515010007</rs>, in part by the <rs type="funder">Guangdong Provincial Key Laboratory of Human Digital Twin</rs> under Grant <rs type="grantNumber">2022B1212010004</rs>, in part by <rs type="funder">CAAI-Huawei MindSpore Open Fund</rs>, and In part by <rs type="funder">National Natural Science Foundation of China</rs> (No. <rs type="grantNumber">62202403</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_gunxeMg">
					<idno type="grant-number">2023A1515010007</idno>
				</org>
				<org type="funding" xml:id="_3jGsPyj">
					<idno type="grant-number">2022B1212010004</idno>
				</org>
				<org type="funding" xml:id="_EXTKzPb">
					<idno type="grant-number">62202403</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43987-2 57.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">DCAN: deep contour-aware networks for object instance segmentation from histology images</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Cia-net: robust nuclei instance segmentation with contour-aware information aggregation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">F</forename><surname>Onder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tsougenis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="682" to="693" />
		</imprint>
		<respStmt>
			<orgName>IPMI</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Hover-Net: simultaneous segmentation and classification of nuclei in multi-tissue histology images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Graham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page">101563</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Cell detection with star-convex polygons</title>
		<author>
			<persName><forename type="first">U</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Weigert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Broaddus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Myers</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-00934-2_30</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-00934-230" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2018</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Schnabel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Davatzikos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Alberola-López</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Fichtinger</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">11071</biblScope>
			<biblScope unit="page" from="265" to="273" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Adversarial stain transfer for histopathology image analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ben Taieb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hamarneh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="792" to="802" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Measuring domain shift for deep learning in histopathology</title>
		<author>
			<persName><forename type="first">K</forename><surname>Stacke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Eilertsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Unger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lundström</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Biomed. Health Inf</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="325" to="336" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Mitosis domain generalization in histopathology imagesthe MIDOG challenge</title>
		<author>
			<persName><forename type="first">M</forename><surname>Aubreville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page">102699</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Domain adaptive nuclei instance segmentation and classification via category-aware feature alignment and pseudo-labelling</title>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">13437</biblScope>
			<biblScope unit="page" from="715" to="724" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16449-1_68</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16449-168" />
		<imprint>
			<date type="published" when="2022">2022</date>
			<pubPlace>Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">PDAM: a panoptic-level feature alignment framework for unsupervised domain adaptive instance segmentation in microscopy images</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="154" to="165" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Minimizing labeling cost for nuclei instance segmentation and classification with cross-domain images and weak labels</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Lovell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AAAI</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="697" to="705" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">In search of lost domain generalization</title>
		<author>
			<persName><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Domain generalization: a survey</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="4396" to="4415" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Generalizing to unseen domains: a survey on domain generalization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="8052" to="8072" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">FSDR: frequency space domain randomization for domain generalization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="6891" to="6902" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Open domain generalization with domain-augmented meta-learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="9624" to="9633" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Generalizable medical image segmentation via random amplitude mixup and domain-specific image restoration</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<editor>Avidan, S., Brostow, G., Cisse, M., Farinella, G.M., Hassner, T.</editor>
		<imprint>
			<biblScope unit="volume">13681</biblScope>
			<biblScope unit="page" from="420" to="436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-19803-8_25</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-19803-825" />
		<imprint>
			<date type="published" when="2022">2022</date>
			<pubPlace>Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">FedDG: federated domain generalization on medical image segmentation via episodic learning in continuous frequency space</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Heng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1013" to="1023" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Style normalization and restitution for generalizable person reidentification</title>
		<author>
			<persName><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3143" to="3152" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Batch-instance normalization for adaptively style-invariant neural networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-E</forename><surname>Kim</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2563" to="2572" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Uncertainty modeling for out-of-distribution generalization</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Duan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Domain generalization with adversarial feature learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Kot</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="5400" to="5409" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Neuron coverage guided domain generalization</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">X</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1302" to="1311" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Model-based domain generalization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Robey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Pappas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hassani</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="20210" to="20229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Learning to learn single domain generalization</title>
		<author>
			<persName><forename type="first">F</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="12556" to="12565" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Learning to diversify for single domain generalization</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Baktashmotlagh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="834" to="843" />
		</imprint>
		<respStmt>
			<orgName>ICCV</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Gradient matching for domain generalization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">An image inpainting technique based on the fast marching method</title>
		<author>
			<persName><forename type="first">A</forename><surname>Telea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Graph. Tools</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="23" to="24" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Methods for segmentation and classification of digital microscopy tissue images</title>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">D</forename><surname>Vu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Bioeng. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">DeepLIIF: an online platform for quantification of clinical pathology slides</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ghahremani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Marino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dodds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nadeem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="21399" to="21405" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">U-net: convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-24574-4_28</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-24574-428" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2015</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hornegger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">9351</biblScope>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Nuclear staining with alum hematoxylin</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Llewellyn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biotech. Histochem</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="159" to="177" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">BCData: a large-scale dataset and benchmark for cell detection and counting</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59722-1_28</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-59722-128" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12265</biblScope>
			<biblScope unit="page" from="289" to="298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A dataset and a technique for generalizable nuclear segmentation for computational pathology</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bhargava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vahadane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sethi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1550" to="1560" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Tent: fully test-time adaptation by entropy minimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Olshausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Semantic-aware domain generalizable segmentation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hayat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2594" to="2605" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Harmofl: harmonizing local and global drifts in federated learning on heterogeneous medical images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AAAI</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1087" to="1095" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Test-time fourier style calibration for domain generalization</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao1</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sicilia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">A method for normalizing histology slides for quantitative analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Macenko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1107" to="1110" />
		</imprint>
		<respStmt>
			<orgName>ISBI</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Stain mix-up: unsupervised domain generalization for histopathology images</title>
		<author>
			<persName><forename type="first">J.-R</forename><surname>Chang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87199-4_11</idno>
		<idno>978-3-030-87199-4 11</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12903</biblScope>
			<biblScope unit="page" from="117" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Exact feature distribution matching for arbitrary style transfer and domain generalization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="8035" to="8045" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Fast algorithms for histogram matching: application to texture synthesis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Rolland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bloss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Abbey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Electron. Imaging</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="45" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
