<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Assignment Theory-Augmented Neural Network for Dental Arch Labeling</title>
				<funder ref="#_meRrpHW">
					<orgName type="full">Novo Nordisk Foundation</orgName>
				</funder>
				<funder ref="#_Vn7j7S4">
					<orgName type="full">University of Copenhagen</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Tudor</forename><surname>Dascalu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Copenhagen</orgName>
								<address>
									<settlement>Copenhagen</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bulat</forename><surname>Ibragimov</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Copenhagen</orgName>
								<address>
									<settlement>Copenhagen</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Assignment Theory-Augmented Neural Network for Dental Arch Labeling</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="295" to="304"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">69630F9BAE3B79896DB411D494975789</idno>
					<idno type="DOI">10.1007/978-3-031-43898-1_29</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-24T10:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Multi-object recognition</term>
					<term>Assignment theory</term>
					<term>Dental instance classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Identifying and detecting a set of objects that conform to a structured pattern, but may also have misaligned, missing, or duplicated elements is a difficult task. Dental structures serve as a real-world example of such objects, with high variability in their shape, alignment, and number across different individuals. This study introduces an assignment theory-based approach for recognizing objects based on their positional inter-dependencies. We developed a distance-based anatomical model of teeth consisting of pair-wise displacement vectors and relative positional scores. The dental model was transformed into a cost function for a bipartite graph using a convolutional neural network (CNN). The graph connected candidate tooth labels to the correct tooth labels. We reframed the problem of determining the optimal tooth labels for a set of candidate labels into the problem of assigning jobs to workers. This approach established a theoretical connection between our task and the field of assignment theory. To optimize the learning process for specific output requirements, we incorporated a loss term based on assignment theory into the objective function. We used the Hungarian method to assign greater importance to the costs returned on the optimal assignment path. The database used in this study consisted of 1200 dental meshes, which included separate upper and lower jaw meshes, collected from 600 patients. The testing set was generated by an indirect segmentation pipeline based on the 3D U-net architecture. To evaluate the ability of the proposed approach to handle anatomical anomalies, we introduced artificial tooth swaps, missing and double teeth. The identification accuracies of the candidate labels were 0.887 for the upper jaw and 0.888 for the lower jaw. The optimal labels predicted by our method improved the identification accuracies to 0.991 for the upper jaw and 0.992 for the lower jaw.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Object detection and identification are key steps in many biomedical imaging applications <ref type="bibr" target="#b12">[13]</ref>. Digital imaging is essential in dentistry, providing practitioners with detailed internal and surface-level information for the accurate diagnosis and effective treatment planning of endodontic and orthodontic procedures <ref type="bibr" target="#b17">[18]</ref>. Intra-oral scans (IOS) are a specific type of digital dental imagery that produce 3D impressions of the dental arches, commonly referred to as dental casts <ref type="bibr" target="#b11">[12]</ref>. Surface level visualizations can be utilized for the automatic design and manufacturing of aligners and dental appliances <ref type="bibr" target="#b17">[18]</ref>.</p><p>A precursor to fully automated workflows consists of accurate detection and recognition of dental structures <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b10">11]</ref>. The difficulty of the tasks stems from inherent anatomical variability among individuals, as well as the presence of confounding factors such as treatment-related artifacts and noise <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8]</ref>. To date, a limited number of studies have been conducted to experiment with algorithms performing instance segmentation in dental casts <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref>. Tian et al. <ref type="bibr" target="#b16">[17]</ref> proposed a multi-level instance segmentation framework based on CNNs, investigating the impact of incorporating a broad classification stage that classified structures into incisors, canines, premolars, and molars. Xu et al. <ref type="bibr" target="#b18">[19]</ref> adopted a similar broad-to-narrow classification strategy, developing two CNNs for labeling mesh faces based on handcrafted features. Sun et al. <ref type="bibr" target="#b15">[16]</ref> applied the FeaStNet graph CNN algorithm for dental vertex labeling. Cui et al. <ref type="bibr" target="#b2">[3]</ref> developed a tooth detection pipeline that included tooth centroid localization followed by instance segmentation applied on cropped sub-point clouds surrounding the centroids.</p><p>The identification of dental instances is a complex task due to the presence of anatomical variations such as crowding, missing teeth, and "shark teeth" (or double teeth) <ref type="bibr" target="#b6">[7]</ref>. Xu et al. <ref type="bibr" target="#b18">[19]</ref> employed PCA analysis to correct mislabeled pairs of teeth caused by missing or decayed teeth. Sun et al. <ref type="bibr" target="#b15">[16]</ref> analyzed crown shapes and the convexity of the border region to address ambiguous labeling of neighboring dental instances. However, previous studies have not effectively addressed the issue of tooth labeling in the presence of dental abnormalities such as misaligned and double teeth.</p><p>The labeling of dental casts presents a non-trivial challenge of identifying objects of similar shapes that are geometrically connected and may have duplicated or missing elements. This study introduces an assignment theory-based approach for recognizing objects based on their positional inter-dependencies. We developed a distance-based dental model of jaw anatomy. The model was transformed into a cost function for a bipartite graph using a convolutional neural network. To compute the optimal labeling path in the graph, we introduced a novel loss term based on assignment theory into the objective function. The assignment theory-based framework was tested on a large database of dental casts and achieved almost perfect labeling of the teeth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Generation of Candidate Labels</head><p>The database utilized in the present study comprised meshes that represented dental casts, with the lower and upper jaws being depicted as separate entities.</p><p>Each mesh vertex was associated with a label following the World Dental Federation (FDI) tooth numbering system. A large proportion of the samples in the dataset was associated with individuals who had healthy dentition. A subset of patients presented dental conditions, including misaligned, missing, and duplicated teeth. Furthermore, the dataset consisted of patients with both permanent and temporary dentition.</p><p>The dental cast labeling task was divided into two stages: the detection of candidate teeth <ref type="bibr" target="#b0">(1)</ref>, which involved identifying vertices forming instances of teeth, and the assignment of labels to the candidate teeth, with geometric and anatomical considerations <ref type="bibr" target="#b1">(2)</ref>. The process of detecting candidate teeth consisted of indirect instance segmentation. The dental casts were converted to binary volumetric images with a voxel resolution of 1mm; voxels containing vertices were assigned a value of 1, while those without vertices were assigned a value of 0 <ref type="bibr" target="#b4">[5]</ref>. The binary images were then segmented using two separate 3D U-net models, each specifically trained for either the upper or lower dental cast types. The models were trained to segment 17 different structures. When applied to a new volumetric dental cast, the models generated 17 probability maps: one for each of the 16 tooth types, corresponding to the full set of normal adult human teeth present in each jaw, plus an additional one for non-dental structures like gums. The outputs were converted to vertex labels over the input dental cast, by finding spatial correspondences between voxels and vertices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Dental Anatomical Model</head><p>The difficulty of segmenting dental structures stems from the high inter-personal shape and position variability, artifacts (e.g. fillings, implants, braces), embedded, and missing teeth <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b5">6]</ref>. These challenges combined with the tendency for neighboring instances to have similar shapes affect the performance and accuracy of the U-Net models. As a result, the output produced by the segmentors may contain missed or incorrectly assigned labels.</p><p>To address these challenges and build an accurate instance segmentation pipeline, we first generated a dental anatomical model that provided a framework for understanding the expected positions of the teeth within the jaw. The dental model relied on the relative distances between teeth, instead of their actual positions, for robustness against translation and rotation transformations. The initial step in modeling the jaws was calculating the centroids of the dental instances by averaging the coordinates of their vertices. The spatial relationship between two teeth centroids, c 1 and c 2 , was described by the displacement vector, d = c 1 -c 2 . To evaluate the relative position of two instances of types t 1 and t 2 , we calculated the means (μ x , μ y , μ z ) and standard deviations (σ x , σ y , σ z ) for each dimension (x, y, z) of the displacement vectors corresponding to instances of types t 1 and t 2 in patients assigned to the training set. The displacement rating r for the two instances was computed as the average of the univariate Gaussian probability density function evaluated at each dimension (d x , d y , d z ) of the displacement vector d: (1)</p><p>The dental model of a patient consisted of a 3D matrix A of shape m×m×4, where m corresponded to the total number of tooth types. For each pair of dental instances i and j, the elements a ij0 , a ij1 , a ij2 correspond to the x, y, and z coordinates of the displacement vector, respectively, while a ij3 represents the relative position score. The presence of anatomical anomalies, such as missing teeth and double teeth, did not impact the information embedded in the dental model. If tooth i was absent, the values for the displacement vectors and position ratings in both row i and column i of the dental model A were set to zero.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">The Assignment Problem</head><p>The next step was evaluating and correcting the candidate tooth labels generated by the U-net models using the dental anatomical model. We reformulated the task as finding the optimal label assignment. Assignment theory aims to solve the similar task of assigning m jobs to m workers in a way that minimizes expenses or maximizes productivity <ref type="bibr" target="#b13">[14]</ref>. For the purpose of dental cast labeling, the number of jobs m is defined as t teeth types present in a typical healthy individual and d double teeth observed in patients with the "shark teeth" condition, m = t+d. To ensure that the number of jobs matched the number of workers, k "dummy" teeth without specific locations were added to the n teeth candidates generated by the U-net. The dental model was transformed into a cost matrix B of dimensions m × m, where each element b ij represented the cost associated with assigning label j to candidate instance i. We solved the assignment problem using the Hungarian method <ref type="bibr" target="#b9">[10]</ref>. The optimal assignment solution C * for n candidate teeth was not affected by the presence of k "dummy" teeth, provided that all elements b ij in the cost matrix B where either i or j corresponds to a "dummy" instances were assigned the maximum cost value of q. Proposition 1. Let the set of candidate teeth be C and the number of possible candidate teeth m = t + s, such that |C| &lt; m. The optimal label assignment to the candidate instances is C * = f * (C), where f * ∈ F is the optimal assignment function. Let us assume that there exists only one optimal assignment function f * . The sum of costs associated with assigning candidate teeth to their optimal labels according to f * is less than the sum of costs associated with any other assignment function p ∈ F\{f * }, x∈C B x,f * (x) &lt; x∈C B x,p(x) . The inclusion of r dummy teeth, with r = m -|C|, and maximum assignment cost q cannot alter the optimal assignment C * .</p><p>Proof. Let's assume that the addition of one dummy object θ with maximum assignment cost q changes the optimal assignment to g ∈ F\{f * } on the set C ∪ {θ}. The assignment cost of the new candidate set</p><formula xml:id="formula_0">C ∪ {θ} is x∈C∪{θ} B x,g(x) = x∈C B x,g(x) + q (2)</formula><p>considering that B θ,g(θ) = q. The definition of the optimal label assignment function f * states that its cumulative assignment cost is smaller than the cumulative assignment cost of any g ∈ F\{f * } on the set C ∪ {θ}, which indicates that</p><formula xml:id="formula_1">x∈C B x,g(x) + q &gt; x∈C B x,f * (x) + q = x∈C∪{θ} B x,f * (x)<label>(3)</label></formula><p>This contradicts the assumption that g is the optimal assignment for C ∪ {θ}. This proof can be generalized to the case where multiple dummy teeth are added to the candidate set.</p><p>In other words, Proposition 1 states that adding "dummy" instances to the candidate teeth sets does not affect the optimal assignment of the non-dummy objects. The dummy teeth played a dual role in our analysis. On one hand, they could be used to account for the presence of double teeth in patients with the "shark teeth" condition. On the other hand, they could be assigned to missing teeth in patients with missing dentition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">DentAssignNet</head><p>The optimal assignment solution f * ensured that each candidate tooth would be assigned a unique label. We integrated the assignment solver into a convolutional neural network for labeling candidate teeth, entitled DentAssignNet (Fig. <ref type="figure" target="#fig_0">1</ref>).</p><p>The input to the convolutional neural network consisted of a matrix A of shape m × m × 4, which represented a dental model as introduced in Sect. 2.2. For each pair of dental instances i and j, the element a ij included the coordinates of the displacement vector and the relative position score. The architecture of the network was formed of 3 convolutional blocks. Each convolutional block in the model consisted of the following components: a convolutional layer, a rectified linear unit (ReLU) activation function, a max pooling layer, and batch normalization. The convolutional and pooling operations were applied exclusively along the rows of the input matrices because the neighboring elements in each row were positionally dependent. The output of the convolutional neural network was a cost matrix B of shape m × m, connecting candidate instances to potential labels. The assignment solver transformed the matrix B into the optimal label assignment C * . The loss function utilized during the training phase was a weighted sum of two binary cross entropy losses: between the convolutional layer's output Ŷ and the ground truth Y, and between Ŷ multiplied by the optimal assignment solution Ŷ and the ground truth Y.</p><formula xml:id="formula_2">L = (1 -λ)L BCE( Ŷ,Y) + λL BCE( Ŷ ,Y)<label>(4)</label></formula><p>The direct application of the assignment solver on a dental model A with dimensions m × m × 4 was not possible, as the solver required the weights associated with the edges of the bipartite graph connecting candidate instances to labels. By integrating the optimal assignment solution in the loss function, Den-tAssignNet enhanced the signal corresponding to the most informative convolutional layer output cells in the task of labeling candidate teeth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiment and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Database</head><p>The database employed in this study was introduced as part of the 3D Teeth Scan Segmentation and Labeling Challenge held at MICCAI 2022 <ref type="bibr" target="#b1">[2]</ref>. It featured 1200 dental casts, depicting lower and upper jaws separately. The dental structures were acquired using intra-oral scanners (IOS) and modeled as meshes. The average number of vertices per mesh was 117377. The cohort consisted of 600 patients, with an equal distribution of male and female individuals. Approximately 70% of the patients were under 16 years of age, while around 27% were between 16 and 59 years of age, and the remaining 3% were over 60 years old.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experiment Design</head><p>To obtain the candidate tooth labels, we employed the U-net architecture on the volumetric equivalent of the dental mesh. Considering that the majority of the samples in the database featured individuals with healthy dentition, a series of transformations were applied to the U-net results to emulate the analysis of cases with abnormal dentition. To simulate the simultaneous occurrence of both permanent and temporary dental instances of the same type, we introduced artificial centroids with labels copied from existing teeth. They were placed at random displacements, ranging from d min to d max millimeters, from their corresponding true teeth, with an angulation that agreed with the shape of the patient's dental arch. The protocol for constructing the database utilized by our model involved the following steps. Firstly, we calculated the centroids of each tooth using the vertex labels generated by the U-Net model. Subsequently, we augmented the U-net results by duplicating, removing, and swapping teeth. The duplication procedure was performed with a probability of p d = 0.5, with the duplicate positioned at a random distance between d min = 5 millimeters and d max = 15 millimeters from the original. The teeth removal was executed with a probability of p e = 0.5, with a maximum of e = 4 teeth being removed. Lastly, the swapping transformation was applied with a probability of p w = 0.5, involving a maximum of w = 2 tooth pairs being swapped. Given that neighboring dental instances tend to share more similarities than those that are further apart, we restricted the label-swapping process to instances that were located within two positions of each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results</head><p>Each sample in the database underwent 10 augmentations, resulting in 9000 training samples, 1000 validation samples, and 2000 testing samples for both jaws. The total number of possible tooth labels was set to m = 17, consisting of t = 16 distinct tooth types and d = 1 double teeth. The training process involved 100 epochs, and the models were optimized using the RMSprop algorithm with a learning rate of 10 -4 and a weight decay of 10 -8 . The weighting coefficient in the assignment-based loss was λ = 0.8. The metrics reported in this section correspond to the detection and identification of teeth instances. The U-net models achieved detection accuracies of 0.989 and 0.99 for the lower and upper jaws, respectively. The metrics calculated in the ablation study take into account only the dental instances that were successfully detected by the candidate teeth proposing framework. Table <ref type="table" target="#tab_0">1</ref> presents identification rates for the candidate dental instances (prior to and following ablation) and the performance of DentAssignNet. Our framework achieved identification accuracies of 0.992 and 0.991 for the lower and upper jaws, respectively. There was a significant improvement in performance compared to the U-net results (0.972 and 0.971) and the artificially ablated input teeth (0.888 and 0.887). Figure <ref type="figure" target="#fig_1">2</ref> depicts the ability of DentAssignNet to handle patients with healthy dentition (row 1), erupting teeth (row 2), and missing teeth (row 3). For comparison purposes, we refer to the results of the 3D Teeth Scan Segmentation and Labeling Challenge at MICCAI 2022 <ref type="bibr" target="#b1">[2]</ref>. The challenge evaluated the algorithms based on teeth detection, labeling, and segmentation metrics, on a private dataset that only the challenge organizers could access. Hoyeon Lim et al. adapted the Point Group method with a Point Transformer backbone and achieved a labeling accuracy of 0.910. Mathieu Leclercq et al. used a modified 2D Residual U-Net and achieved a labeling accuracy of 0.922. Shaojie Zhuang et al. utilized PointNet++ with cast patch segmentation and achieved a labeling accuracy of 0.924. Our identification accuracies of 0.992 and 0.991 for the lower and upper jaw, respectively, compare favorably to the results from the challenge. However, it must be noted that this is not a direct comparison as the results were achieved on different segments of the dental cast challenge database. Additionally, the metrics used in the challenge were specifically designed to accommodate the dual task of detection and identification, calculating labeling accuracy relative to all dental instances, including those that were not detected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We proposed a novel framework utilizing principles of assignment theory for the recognition of objects within structured, multi-object environments with missing or duplicate instances. The multi-step pipeline consisted of detecting and assigning candidate labels to the objects using U-net (1), modeling the environment considering the positional inter-dependencies of the objects (2), and finding the optimal label assignment using DentAssignNet (3). Our model was able to effectively recover most teeth misclassifications, resulting in identification accuracies of 0.992 and 0.991 for the lower and upper jaws, respectively.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The assignment theory-based object recognition pipeline. The initial phase (A) depicts the process of producing candidate instances and the results, with two pairs of swapped teeth (6-4, 10-9). The subsequent phase (B) presents the cost map and optimal assignment path produced by DentAssignNet.</figDesc><graphic coords="4,41,79,54,23,340,21,213,46" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The axial view of the input dental candidates assigned by the U-net (column 1), the corresponding output produced by DentAssignNet (column 2), and the ground truth (column 3). Each row represents a new patient. Each tooth type is represented by a unique combination of color and label. The color red indicates instances that were mislabeled, while the color green indicates instances that were previously misclassified but were correctly labeled by the framework. (Color figure online)</figDesc><graphic coords="7,55,98,154,28,340,18,257,80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>The performance of the U-net (row 1), ablated candidate teeth (row 2), and DentAssignNet (row 3), for the lower and upper jaws. Column 1 denotes the identification accuracy. Columns 3 and 4 include the number of mislabeled teeth followed by the total number of teeth in parenthesis.</figDesc><table><row><cell>Model</cell><cell>Accuracy</cell><cell></cell><cell cols="2">Swapped teeth errors</cell><cell cols="2">Double teeth errors</cell></row><row><cell></cell><cell cols="3">Lower jaw Upper jaw Lower jaw</cell><cell>Upper jaw</cell><cell cols="2">Lower jaw Upper jaw</cell></row><row><cell>U-net</cell><cell>0.972</cell><cell>0.971</cell><cell>22 (1306)</cell><cell>25 (1276)</cell><cell>0 (2)</cell><cell>0 (2)</cell></row><row><cell cols="2">U-net ablated 0.888</cell><cell>0.887</cell><cell cols="3">1368 (12239) 1345 (11944) 40 (503)</cell><cell>34 (485)</cell></row><row><cell cols="2">DentAssignNet 0.992</cell><cell>0.991</cell><cell cols="4">40 (12239) 43 (11944) 11 (503) 6 (485)</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. This work was supported by <rs type="grantName">Data+ grant DIKU</rs>, the <rs type="funder">University of Copenhagen</rs>, and the <rs type="funder">Novo Nordisk Foundation</rs> grant <rs type="grantNumber">NNF20OC0062056</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Vn7j7S4">
					<orgName type="grant-name">Data+ grant DIKU</orgName>
				</org>
				<org type="funding" xml:id="_meRrpHW">
					<idno type="grant-number">NNF20OC0062056</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An efficient segmentation algorithm for panoramic dental images</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Amer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Aqel</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.procs.2015.09.016</idno>
		<ptr target="https://doi.org/10.1016/j.procs.2015.09.016" />
	</analytic>
	<monogr>
		<title level="j">Procedia Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="718" to="725" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Teeth3DS: a benchmark for teeth segmentation and labeling from intra-oral 3D scans</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ben-Hamadou</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2210.06094</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2210.06094" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">TSegNet: an efficient and accurate tooth segmentation network on 3D dental model</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.media.2020.101949</idno>
		<ptr target="https://doi.org/10.1016/j.media.2020.101949" />
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page">101949</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Benefits of auxiliary information in deep learning-based teeth segmentation</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Dascalu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kuznetsov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ibragimov</surname></persName>
		</author>
		<idno type="DOI">10.1117/12.2610765</idno>
		<ptr target="https://doi.org/10.1117/12.2610765" />
	</analytic>
	<monogr>
		<title level="j">Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">12032</biblScope>
			<biblScope unit="page" from="805" to="813" />
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
	<note>SPIE</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Dawson-Haggerty</forename></persName>
		</author>
		<ptr target="https://trimsh.org/" />
	</analytic>
	<monogr>
		<title level="j">trimesh</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Evaluation of current dental radiographs segmentation approaches in computer-aided applications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ehsani Rad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rahim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Altameem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Saba</surname></persName>
		</author>
		<idno type="DOI">10.4103/0256-4602.113498</idno>
		<ptr target="https://doi.org/10.4103/0256-4602.113498" />
	</analytic>
	<monogr>
		<title level="j">IETE Tech. Rev</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="210" to="222" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">O</forename><surname>Ip</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Azodo</surname></persName>
		</author>
		<title level="m">Shark Teeth&quot; Like Appearance among Paediatric Dental</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Object recognition in medical images via anatomy-guided deep learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Jin</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.media.2022.102527</idno>
		<ptr target="https://doi.org/10.1016/j.media.2022.102527" />
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page">102527</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Tooth segmentation of dental study models using range images</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kondo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Foong</surname></persName>
		</author>
		<idno type="DOI">10.1109/TMI.2004.824235</idno>
		<ptr target="https://doi.org/10.1109/TMI.2004.824235" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="350" to="362" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The Hungarian method for the assignment problem</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Kuhn</surname></persName>
		</author>
		<idno type="DOI">10.1002/nav.3800020109</idno>
		<ptr target="https://doi.org/10.1002/nav.3800020109" />
	</analytic>
	<monogr>
		<title level="j">Naval Res. Logistics Quart</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="83" to="97" />
			<date type="published" when="1955">1955</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">MeshSNet: Deep Multi-scale Mesh Feature Learning for End-to-End Tooth Labeling on 3D Dental Surfaces</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lian</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-32226-7_93</idno>
		<idno>978-3-030-32226-7 93</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2019</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11769</biblScope>
			<biblScope unit="page" from="837" to="845" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Intraoral scanners in dentistry: a review of the current literature</title>
		<author>
			<persName><forename type="first">F</forename><surname>Mangano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gandolfi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Luongo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Logozzo</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12903-017-0442-x</idno>
		<ptr target="https://doi.org/10.1186/s12903-017-0442-x" />
	</analytic>
	<monogr>
		<title level="j">BMC Oral Health</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page">149</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Current methods in medical image segmentation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Prince</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev.bioeng.2.1.315</idno>
		<ptr target="https://doi.org/10.1146/annurev.bioeng.2.1.315" />
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="315" to="337" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A comparative analysis of assignment problem</title>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<idno type="DOI">10.9790/3021-02810115</idno>
		<ptr target="https://doi.org/10.9790/3021-02810115" />
	</analytic>
	<monogr>
		<title level="j">IOSR J. Eng</title>
		<imprint>
			<biblScope unit="volume">02</biblScope>
			<biblScope unit="issue">08</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Automatic Tooth Segmentation and Dense Correspondence of 3D Dental Model</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59719-1_68</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-59719-168" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12264</biblScope>
			<biblScope unit="page" from="703" to="712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Tooth segmentation and labeling from digital dental casts</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
		<idno type="DOI">10.1109/ISBI45749.2020.9098397</idno>
		<ptr target="https://doi.org/10.1109/ISBI45749.2020.9098397" />
	</analytic>
	<monogr>
		<title level="m">2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="669" to="673" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">automatic classification and segmentation of teeth on 3D dental model using hierarchical deep learning networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2019.2924262</idno>
		<ptr target="https://doi.org/10.1109/ACCESS" />
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="84817" to="84828" />
			<date type="published" when="2019">2019. 2019.2924262</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The crucial role of imaging in digital dentistry</title>
		<author>
			<persName><forename type="first">B</forename><surname>Vandenberghe</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.dental.2020.03.001</idno>
		<ptr target="https://doi.org/10.1016/j.dental.2020.03.001" />
	</analytic>
	<monogr>
		<title level="j">Dental Mater</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="581" to="591" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">3D tooth segmentation and labeling using deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2018.2839685</idno>
		<ptr target="https://doi.org/10.1109/TVCG.2018.2839685" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis.Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2336" to="2348" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Two-stream graph convolutional network for intra-oral scanner image segmentation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.1109/TMI.2021.3124217</idno>
		<ptr target="https://doi.org/10.1109/TMI.2021.3124217" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="826" to="835" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">3D Dental model segmentation with graph attentional convolution network</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.patrec.2021.09.005</idno>
		<idno>patrec.2021.09.005</idno>
		<ptr target="https://doi.org/10.1016/j" />
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn. Lett</title>
		<imprint>
			<biblScope unit="volume">152</biblScope>
			<biblScope unit="page" from="79" to="85" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
