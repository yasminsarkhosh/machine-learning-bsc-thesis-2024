<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Towards Frugal Unsupervised Detection of Subtle Abnormalities in Medical Imaging</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Geoffroy</forename><surname>Oudoumanessah</surname></persName>
							<email>geoffroy.oudoumanessah@univ-grenoble-alpes.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">Université Grenoble Alpes</orgName>
								<address>
									<settlement>Inria</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">LJK</orgName>
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">Grenoble INP</orgName>
								<address>
									<postCode>38000</postCode>
									<settlement>Grenoble</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Inserm U1216</orgName>
								<orgName type="department" key="dep2">Institut des Neurosciences</orgName>
								<orgName type="institution" key="instit1">Université Grenoble Alpes</orgName>
								<orgName type="institution" key="instit2">CHU Grenoble Alpes</orgName>
								<address>
									<postCode>38000</postCode>
									<settlement>Grenoble, Grenoble</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Université Lyon</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<settlement>Inserm</settlement>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="laboratory">UMR5220</orgName>
								<orgName type="institution" key="instit1">INSA Lyon</orgName>
								<orgName type="institution" key="instit2">UCBL</orgName>
								<orgName type="institution" key="instit3">CREATIS</orgName>
								<address>
									<postCode>U1294, 69621</postCode>
									<settlement>Villeurbanne</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Carole</forename><surname>Lartizien</surname></persName>
							<email>carole.lartizien@creatis.insa-lyon.fr</email>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Université Lyon</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<settlement>Inserm</settlement>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="laboratory">UMR5220</orgName>
								<orgName type="institution" key="instit1">INSA Lyon</orgName>
								<orgName type="institution" key="instit2">UCBL</orgName>
								<orgName type="institution" key="instit3">CREATIS</orgName>
								<address>
									<postCode>U1294, 69621</postCode>
									<settlement>Villeurbanne</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michel</forename><surname>Dojat</surname></persName>
							<email>michel.dojat@univ-grenoble-alpes.fr</email>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Inserm U1216</orgName>
								<orgName type="department" key="dep2">Institut des Neurosciences</orgName>
								<orgName type="institution" key="instit1">Université Grenoble Alpes</orgName>
								<orgName type="institution" key="instit2">CHU Grenoble Alpes</orgName>
								<address>
									<postCode>38000</postCode>
									<settlement>Grenoble, Grenoble</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Florence</forename><surname>Forbes</surname></persName>
							<email>florence.forbes@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">Université Grenoble Alpes</orgName>
								<address>
									<settlement>Inria</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">LJK</orgName>
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">Grenoble INP</orgName>
								<address>
									<postCode>38000</postCode>
									<settlement>Grenoble</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Towards Frugal Unsupervised Detection of Subtle Abnormalities in Medical Imaging</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="411" to="421"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">A945384C2696B24251DEA1EE0528B8C9</idno>
					<idno type="DOI">10.1007/978-3-031-43898-1_40</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-24T10:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Frugal computing</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Anomaly detection in medical imaging is a challenging task in contexts where abnormalities are not annotated. This problem can be addressed through unsupervised anomaly detection (UAD) methods, which identify features that do not match with a reference model of normal profiles. Artificial neural networks have been extensively used for UAD but they do not generally achieve an optimal trade-off between accuracy and computational demand. As an alternative, we investigate mixtures of probability distributions whose versatility has been widely recognized for a variety of data and tasks, while not requiring excessive design effort or tuning. Their expressivity makes them good candidates to account for complex multivariate reference models. Their much smaller number of parameters makes them more amenable to interpretation and efficient learning. However, standard estimation procedures, such as the Expectation-Maximization algorithm, do not scale well to large data volumes as they require high memory usage. To address this issue, we propose to incrementally compute inferential quantities. This online approach is illustrated on the challenging detection of subtle abnormalities in MR brain scans for the follow-up of newly diagnosed Parkinsonian patients. The identified structural abnormalities are consistent with the disease progression, as accounted by the Hoehn and Yahr scale.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Despite raising concerns about the environmental impact of artificial intelligence <ref type="bibr" target="#b33">[35,</ref><ref type="bibr" target="#b35">37,</ref><ref type="bibr" target="#b36">38]</ref>, the question of resource efficiency has not yet really reached medical imaging studies. The issue has multiple dimensions and the lack of clear metrics for a fair assessment of algorithms, in terms of resource and energy consumption, contrasts with the obvious healthcare benefits of the ever growing performance of machine and statistical learning solutions.</p><p>In this work, we investigate the case of subtle abnormality detection in medical images, in an unsupervised context usually referred to as Unsupervised Anomaly Detection (UAD). This formalism requires only the identification of normal data to construct a normative model. Anomalies are then detected as outliers, i.e. as samples deviating from this normative model. Artificial neural networks (ANN) have been extensively used for UAD <ref type="bibr" target="#b20">[21]</ref>. Either based on standard autoencoder (AE) architectures <ref type="bibr" target="#b2">[3]</ref> or on more advanced architectures, e.g. combining a vector quantized AE with autoregressive transformers <ref type="bibr" target="#b31">[33]</ref>, ANN do not generally achieve an optimal trade-off between accuracy and computational demand. As an alternative, we show that more frugal approaches can be reached with traditional statistical models provided their cost in terms of memory usage can be addressed. Frugal solutions usually refer to strategies that can run with limited resources such as that of a single laptop. Frugal learning has been studied from several angles, in the form of constraints on the data acquired, on the algorithm deployed and on the nature of the proposed solution <ref type="bibr" target="#b8">[9]</ref>. The angle we adopt is that of online or incremental learning, which refers to approaches that handle data in a sequential manner resulting in more efficient solutions in terms of memory usage and overall energy consumption. For UAD, we propose to investigate mixtures of probability distributions whose interpretability and versatility have been widely recognized for a variety of data and tasks, while not requiring excessive design effort or tuning. In particular, the use of multivariate Gaussian or generalized Student mixtures has been already demonstrated in many anomaly detection tasks, see <ref type="bibr" target="#b0">[1,</ref><ref type="bibr">26,</ref><ref type="bibr" target="#b29">31]</ref> and references therein or <ref type="bibr" target="#b20">[21]</ref> for a more general recent review. However, in their standard batch setting, mixtures are difficult to use with huge datasets due to the dramatic increase of time and memory consumption required by their estimation traditionally performed with an Expectation-Maximization (EM) algorithm <ref type="bibr" target="#b24">[25]</ref>. Online more tractable versions of EM have been proposed and theoretically studied in the literature, e.g. <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b11">12]</ref>, but with some restrictions on the class of mixtures that can be handled this way. A first natural approach is to consider Gaussian mixtures that belong to this class. We thus, present improvements regarding the implementation of an online EM for Gaussian mixtures. We then consider more general mixtures based on multiple scale t-distributions (MST) specifically adapted to outlier detection <ref type="bibr" target="#b9">[10]</ref>. We show that these mixtures can be cast into the online EM framework and describe the resulting algorithm.</p><p>Our approach is illustrated with the MR imaging exploration of de novo (just diagnosed) Parkinson's Disease (PD) patients, where brain anomalies are subtle and hardly visible in standard T1-weighted or diffusion MR images.</p><p>The anomalies detected by our method are consistent with the Hoehn and Yahr (HY) scale <ref type="bibr" target="#b15">[16]</ref>, which describes how the symptoms of Parkinson's disease progress. The results provide additional interesting clinical insights by pointing out the most impacted subcortical structures at both HY stages 1 and 2. The use of such an external scale appears to be an original and relevant indirect validation, in the absence of ground truth at the voxel level. Energy and memory consumptions are also reported for batch and online EM to confirm the interesting performance/cost trade-off achieved. The code is available at https://github.com/geoffroyO/onlineEM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">UAD with Mixture Models</head><p>Recent studies have shown that, on subtle lesion detection tasks with limited data, alternative approaches to ANN, such as one class support vector machine or mixture models <ref type="bibr" target="#b0">[1,</ref><ref type="bibr">26]</ref>, were performing similarly <ref type="bibr" target="#b29">[31,</ref><ref type="bibr" target="#b32">34]</ref>. We further investigate mixture-based models and show how the main UAD steps, i.e. the construction of a reference model and of a decision rule, can be designed.</p><p>Learning a Reference Model. We consider a set Y H of voxel-based features for a number of control (e.g. healthy) subjects, Y H = {y v , v ∈ V H } where V H represents the voxels of all control subjects and y v ∈ IR M is typically deduced from image modality maps at voxel v or from abstract representation features provided by some ANN performing a pre-text task <ref type="bibr" target="#b21">[22]</ref>. To account for the distribution of such normal feature vectors, we consider two types of mixture models, mixtures of Gaussian distributions with high tractability in multiple dimensions and mixtures of multiple scale t-distributions (MST) that are more appropriate when the data present elongated and strongly non-elliptical subgroups <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr">26]</ref>. By fitting such a mixture model to the control data Y H , we build a reference model density f H that depends on some parameter</p><formula xml:id="formula_0">Θ H = {θ k , π k , k = 1 : K H }: fH (y; ΘH ) = K H k=1 π k f (y; θ k ),<label>(1)</label></formula><p>with π k ∈ [0, 1], k=1:KH π k = 1 and K H the number of components, each characterized by a distribution f (•; θ k ). The EM algorithm is usually used to estimate Θ H that best fits Y H while K H can be estimated using the slope heuristic <ref type="bibr" target="#b1">[2]</ref>.</p><p>Designing a Proximity Measure. Given a reference model (1), a measure of proximity r(y v ; Θ H ) of voxel v (with value y v ) to f H needs to be chosen. To make use of the mixture structure, we propose to consider distances to the respective mixture components through some weights acting as inverse Mahalanobis distances. We specify below this new proximity measure for MST mixtures. MST distributions are generalizations of the multivariate t-distribution that extend its Gaussian scale mixture representation <ref type="bibr" target="#b18">[19]</ref>. The standard t-distribution univariate scale (weight) variable is replaced by a M -dimensional scale (weight)</p><formula xml:id="formula_1">variable W = (W m ) m=1:M ∈ R M with M the features dimension, f MST (y; θ) = [0,∞] M N M (y; μ, DΔ w AD T ) M m=1 G w m ; νm 2 dw 1 . . . dw M , (2)</formula><p>where G(•, νm  2 ) denotes the gamma density with parameter ( νm 2 , νm 2 ) ∈ R 2 and N M the multivariate normal distribution with mean parameter μ ∈ R M and covariance matrix DΔ w AD T showing the scaling by the W m 's through a diagonal matrix Δ w = diag(w -1 1 , . . . , w -1 M ). The MST parametrization uses the spectral decomposition of the scaling matrix</p><formula xml:id="formula_2">Σ = DAD T , with D ∈ O(M ) ⊂ R M ×M orthogonal and A = diag(A 1 , . . . , A M ) diagonal. The whole set of parameters is θ = {μ, A, D, (ν m ) m=1:M }.</formula><p>The scale variable W m for dimension m can be interpreted as accounting for the weight of this dimension and can be used to derive a measure of proximity. After fitting a mixture <ref type="bibr" target="#b0">(1)</ref> with MST components to Y H , we set r(</p><formula xml:id="formula_3">y v ; Θ H ) = max m=1:M wyv m , with wy m = E[W m |y; Θ H ].</formula><p>The proximity r is typically larger when at least one dimension of y v is well explained by the model. A similar proximity measure can also be derived for Gaussian mixtures, see details in the Supplementary Material Sect. 1.</p><p>Decision Rule. For an effective detection, a threshold τ α on proximity scores can be computed in a data-driven way by deciding on an acceptable false positive rate (FPR) α; τ α is the value such that P (r(Y; Θ H ) &lt; τ α ) = α, when Y follows the f H reference distribution. All voxels v whose proximity r(y v ; Θ H ) is below τ α are then labeled as abnormal. In practice, while f H is known explicitly, the probability distribution of r(Y; Θ H ) is not. However, it is easy to simulate this distribution or to estimate τ α as an empirical α-quantile <ref type="bibr" target="#b0">[1]</ref>. Unfortunately, learning f H on huge datasets may not be possible due to the dramatic increase in time, memory and energy required by the EM algorithm. This issue often arises in medical imaging with the increased availability of multiple 3D modalities as well as the emergence of image-derived parametric maps such as radiomics <ref type="bibr" target="#b13">[14]</ref> that should be analysed jointly, at the voxel level, and for a large number of subjects. A possible solution consists of employing powerful computers with graphics cards or grid-architectures in cloud computing. Here, we show that a more resource-friendly solution is possible using an online version of EM detailed in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Online Mixture Learning for Large Data Volumes</head><p>Online learning refers to procedures able to deal with data acquired sequentially. Online variants of EM, among others, are described in <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b28">30]</ref>. As an archetype of such algorithms, we consider the online EM of <ref type="bibr" target="#b5">[6]</ref> which belongs to the family of stochastic approximation algorithms <ref type="bibr" target="#b3">[4]</ref>. This algorithm has been well theoretically studied and extended. However, it is designed only for distributions that admit a data augmentation scheme yielding a complete likelihood of the exponential family form, see (3) below. This case is already very broad, including Gaussian, gamma, t-distributions, etc. and mixtures of those. We recall below the main assumptions required and the online EM iteration.</p><p>Assume (Y i ) n i=1 is a sequence of n independent and identically distributed replicates of a random variable Y ∈ Y ⊂ IR M , observed one at a time. Extension to successive mini-batches of observations is straightforward <ref type="bibr" target="#b28">[30]</ref>. In addition, Y is assumed to be the visible part of the pair X = Y , Z ∈ X, where Z ∈ IR l is a latent variable, e.g. the unknown component label in a mixture model, and l ∈ IN. That is, each Y i is the visible part of a pair X i = Y i , Z i . Suppose Y arises from some data generating process (DGP) characterised by a probability density function f (y; θ 0 ), with unknown parameters θ 0 ∈ T ⊆ IR p , for p ∈ IN.</p><p>Using the sequence (Y i ) n i=1 , the method of <ref type="bibr" target="#b5">[6]</ref> sequentially estimates θ 0 provided the following assumptions are met:</p><p>(A1) The complete-data likelihood for X is of the exponential family form: </p><formula xml:id="formula_4">f c (x; θ) = h (x) exp [s (x)] φ (θ) -ψ (θ) ,<label>(3)</label></formula><formula xml:id="formula_5">with h : IR M +l → [0, ∞), ψ : IR p → IR, s : IR M +l → IR q , φ : IR p → IR q , for q ∈ IN. (A2) The function s (y; θ) = E [s (X) |Y = y; θ]<label>(4)</label></formula><p>Let (γ i ) n i=1 be a sequence of learning rates in (0, 1) and let θ (0) ∈ T be an initial estimate of θ 0 . For each i = 1 : n, the online EM of <ref type="bibr" target="#b5">[6]</ref> proceeds by computing</p><formula xml:id="formula_7">s (i) = γ i s(y i ; θ (i-1) ) + (1 -γ i ) s (i-1) ,<label>(6)</label></formula><p>and</p><formula xml:id="formula_8">θ (i) = θ(s (i) ),<label>(7)</label></formula><p>where s (0) = s(y 1 ; θ (0) ). It is shown in Thm. 1 of <ref type="bibr" target="#b5">[6]</ref> that when n tends to infinity, the sequence (θ (i) ) i=1:n of estimators of θ 0 satisfies a convergence result to stationary points of the likelihood (cf. <ref type="bibr" target="#b5">[6]</ref> for a more precise statement).</p><p>In practice, the algorithm implementation requires two quantities, s in (4) and θ in <ref type="bibr" target="#b4">(5)</ref>. They are necessary to define the updating of sequences (s (i) ) i=1:∞ and (θ (i) ) i=1:∞ . We detail below these quantities for a MST mixture.</p><p>Online MST Mixture EM. As shown in <ref type="bibr" target="#b27">[29]</ref>, the mixture case can be deduced from a single component case. The exponential form for a MST (2) writes:</p><formula xml:id="formula_9">f c (x; θ) = N M (y; μ, DΔ w AD T ) M m=1 G w m ; ν m 2 , with x = (y, w) (8) = h(y, w) exp [s(y, w)] T φ(μ, D, A, ν) -ψ(μ, D, A, ν)</formula><p>with s(y, w) = w 1 y, w 1 vec(yy ), w 1 , logw 1 , . . . , w M y, w M vec(yy ), w M , logw M , φ(μ, D, A, ν ) = [φ 1 , . . . , φ M ] T with φ m equal to:</p><formula xml:id="formula_10">φ m = d m d T m μ A m , - vec(d m d T m ) 2A m , - vec(d m d T m ) T vec(μμ T ) 2A m - ν m 2 , 1 + ν m 2 and ψ(μ, D, A, ν) = M m=1 log A m 2 + log Γ( ν m 2 ) - ν m 2 log( ν m 2 ) ,</formula><p>where d m denotes the m th column of D and vec(•) the vectorisation operator, which converts a matrix to a column vector. The exact form of h is not important for the algorithm. It follows that θ(s) is defined as the unique maximizer of function Q(s, θ) = s T φ(θ)ψ(θ) where s is a vector that matches the definition and dimension of φ(θ) and can be conveniently written as s = [s 11 , vec(S 21 ), s 31 , s 41 , . . . , s 1M , vec(S 2M ), s 3M , s 4M ] T , with for each m, s 1m is a M -dimensional vector, S 2m is a M ×M matrix, s 3m and s 4m are scalars. Solving for the roots of the Q gradients leads to θ(s) = (μ(s), Ā(s), D(s), ν(s)) whose expressions are detailed in Supplementary Material Sect.  <ref type="formula" target="#formula_7">6</ref>), these expectations need to be computed for y = y i the observation at iteration i. We therefore denote these expectations respectively by</p><formula xml:id="formula_11">u (i-1) im = E[W m |Y = y i ; θ (i-1) ] = α (i-1) m /β (i-1) m (9) and ũ(i-1) im = E[log W m |Y = y i ; θ (i-1) ] = Ψ (0) (α (i-1) m ) -log β (i-1) m</formula><p>, where</p><formula xml:id="formula_12">α (i-1) m = ν (i-1) m +1 2 and β (i-1) m = ν (i-1) m 2 + (d (i-1)T m (yi-μ (i-1) )) 2 2A (i-1) m</formula><p>. The update of s (i) in ( <ref type="formula" target="#formula_7">6</ref>) follows from the update for each m. From this single MST iteration, the mixture case is easily derived, see <ref type="bibr" target="#b27">[29]</ref> or Supplementary Material Sect. 2.</p><p>Online Gaussian Mixture EM. This case can be found in previous work e.g. <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b28">30]</ref> but to our knowledge, implementation optimizations are never really addressed. We propose an original version that saves computations, especially in a multivariate case where θ (s) involves large matrix inverses and determinants. Such inversions are avoided using results detailed in Supplementary Sect. 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Brain Abnormality Exploration in de novo PD Patients</head><p>Data Description and Preprocessing. The Parkinson's Progression Markers Initiative (PPMI) <ref type="bibr" target="#b23">[24]</ref> is an open-access database dedicated to PD. It includes MR images of de novo PD patients, as well as of healthy subjects (HC), all acquired on the same 3T Siemens Trio Tim scanner. For our illustration, we use 108 HC and 419 PD samples, each composed of a 3D T1-weighted image (T1w), Fractional Anisotropy (FA) and Mean Diffusivity (MD) volumes. The two latter are extracted from diffusion imaging using the DiPy package <ref type="bibr" target="#b12">[13]</ref>, registered onto T1w and interpolated to the same spatial resolution with SPM12. Standard T1w preprocessing steps, comprising non-local mean denoising, skull stripping and tissue segmentation are also performed with SPM12. HC and PD groups are age-matched (median age: 64 y.) with the male-female ratio equal to 6:4. We focus on some subcortical structures, which are mostly impacted at the early stage of the disease <ref type="bibr" target="#b6">[7]</ref>, Globus Pallidus external and internal (GPe and GPi), Nucleus Accumbens (NAC), Substantia Nigra reticulata (SNr), Putamen (Pu), Caudate (Ca) and Extended Amygdala (EXA). Their position is determined by projecting the CIT168 atlas <ref type="bibr" target="#b30">[32]</ref> onto each individual image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pipeline and Results</head><p>. We follow Sects. 2 and 3 using T1w, FA and MD volumes as features (M = 3) and a FPR α = 0.02. The pipeline is repeated 10 times for cross-validation. Each fold is composed of 64 randomly selected HC images for training (about 70M voxels), the remaining 44 HC and all the PD samples for testing. For the reference model, we test Gaussian and MST mixtures, with respectively K H = 14 and K H = 8, estimated with the slope heuristic. Abnormal voxels are then detected for all test subjects, on the basis of their proximity to the learned reference model, as detailed in Sect. 2. The PPMI does not provide ground truth information at the voxel level. This is a recurring issue in UAD, which limits validations to mainly qualitative ones. For a more quantitative evaluation, we propose to resort to an auxiliary task whose success is likely to be correlated with a good anomaly detection. We consider the classification of test subjects into healthy and Parkinsonian subjects based on their global (over all brain) percentages of abnormal voxels. We exploit the availability of HY values to divide the patients into two HY = 1 and HY = 2 groups, representing the two early stages of the disease's progression. Classification results yield a median g-mean, for stage 1 vs stage 2, respectively of 0.59 vs 0.63 for the Gaussian mixtures model and 0.63 vs 0.65 for the MST mixture. The ability of both mixtures to better differentiate stage 2 than stage 1 patients from HC is consistent with the progression of the disease. Note that the structural differences between these two PD stages remain subtle and difficult to detect, demonstrating the efficiency of the models. The MST mixture model appears better in identifying stage 2 PD patients based on their abnormal voxels.</p><p>To gain further insights, we report, in Fig. <ref type="figure" target="#fig_2">1</ref>, the percentages of anomalies detected in each subcortical structure, for control, stage 1 and stage 2 groups. For each structure and both mixture models, the number of anomalies increases from control to stage 1 and stage 2 groups. As expected the MST mixture shows a better ability to detect outliers with significant differences between HC and PD groups, while for the Gaussian model, percentages do not depart much from that in the control group. Overall, in line with the know pathophysiology <ref type="bibr" target="#b6">[7]</ref>, MST results suggest clearly that all structures are potential good markers of the disease progression at these early stages, with GPe, GPi, EXA and SNr showing the largest impact.</p><p>Regarding efficiency, energy consumption in kilojoules (kJ) is measured using the PowerAPI library <ref type="bibr" target="#b4">[5]</ref>. In Table <ref type="table" target="#tab_0">1</ref>, we report the energy consumption for the training and testing of one random fold, comparing our online mixtures with AEsupported methods for UAD <ref type="bibr" target="#b2">[3]</ref>, namely the patch-based reconstruction error <ref type="bibr" target="#b2">[3]</ref> and FastFlow <ref type="bibr" target="#b37">[39]</ref>. We implemented both methods with two different AE architectures: a lightweight AE already used for de novo PD detection <ref type="bibr" target="#b32">[34]</ref>, and a larger one, ResNet-18 <ref type="bibr" target="#b14">[15]</ref>. The global g-mean (not taking HY stages into account) is also reported for the chosen fold. The experiments were run on a CPU with Intel Cascade Lake 6248@2.5 GHz (20 cores), and a GPU Nvidia V100-32 GB. Online mixtures exhibit significantly lower energy consumption, both for training and inference. In terms of memory cost, DRAM peak results, as measured by the tracemalloc Python library, also show lower costs for online mixtures, which by design deal with batches of voxels of smaller sizes than the batches of patches used in AE solutions. These results highlight the advantage of online mixtures, which compared to other hardware-demanding methods, can be run on a minimal configuration while maintaining good performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Perspectives</head><p>Despite a challenging medical problematic of PD progression at early stages, we have observed that energy and memory efficient methods could yield interesting and comparable results with other studies performed on the same database <ref type="bibr" target="#b26">[28,</ref><ref type="bibr" target="#b32">34]</ref> and with similar MR modalities <ref type="bibr" target="#b7">[8,</ref><ref type="bibr">26,</ref><ref type="bibr" target="#b25">27,</ref><ref type="bibr" target="#b34">36</ref>]. An interesting future work would be to investigate the possibility to use more structured observations, such as patch-based features <ref type="bibr" target="#b26">[28]</ref> or latent representations from a preliminary pretext task, provided the task cost is reasonable. Overall, we have illustrated that the constraints of Green AI <ref type="bibr" target="#b33">[35]</ref> could be considered in medical imaging by producing innovative results without increasing computational cost or even reducing it.</p><p>We have investigated statistical mixture models for an UAD task and shown that their expressivity could account for multivariate reference models, and their much simpler structure made them more amenable to efficient learning than most ANN solutions. Although very preliminary, we hope this attempt will open the way to the development of more methods that can balance the environmental impact of growing energy cost with the obtained healthcare benefits.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>is well-defined for all y and θ ∈ T, where E [•|Y = y; θ] is the conditional expectation when X arises from the DGP characterised by θ. (A3) There is a convex S ⊆ IR q , satisfying: (i) for all γ ∈ (0, 1), s ∈ S, y ∈ Y, and θ ∈ T, (1γ) s + γs (y; θ) ∈ S; and (ii) for any s ∈ S, the function Q (s; θ) = s φ (θ)ψ (θ) has a unique global maximizer on T denoted by θ (s) = arg max θ ∈T Q (s; θ) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>2. A second important quantity is s(y, θ) = E [s (X) |Y = y; θ]. This quantity requires to compute the following expectations for all m, E [W m |Y = y; θ] and E [log W m |Y = y; θ]. More specifically in the update Eq. (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Left: Median, over 10 folds, percentages of anomalies (0 to 22%) in each subcortical structure (see text for full names) for control subjects (green), stage 1 (blue) and stage 2 (red) patients. Plain and dotted lines indicate respectively results obtained with the MST and Gaussian mixtures. Structure sizes in voxels are indicated in parenthesis. SC refers to the combination of all structures. Right: 3D rendering of the subcortical structures colored according to MST percentages from 0% (green) to 22% (red), for healthy controls (HC), stage 1 and stage 2 groups. (Color figure online)</figDesc><graphic coords="8,41,79,54,14,340,15,97,57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>UAD methods comparison for one fold: online Gaussian (OGMM) and Student (OMMST) mixtures, Lightweight AE and ResNet-18 architectures with reconstruction error (RE) and FastFlow (FF) based detection. Best values in bold font.</figDesc><table><row><cell cols="3">Method Backend Training</cell><cell></cell><cell></cell><cell>Inference</cell><cell></cell><cell></cell><cell cols="2">Gmean Parameters</cell></row><row><cell></cell><cell></cell><cell>Time</cell><cell cols="3">Consumption DRAM peak Time</cell><cell cols="2">Consumption DRAM peak</cell><cell></cell><cell></cell></row><row><cell cols="3">Online Mixtures (ours)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">OGMM CPU</cell><cell>50 s</cell><cell>85 kJ</cell><cell>494 MB</cell><cell cols="2">17 min 23 kJ</cell><cell>92 MB</cell><cell>0.65</cell><cell>140</cell></row><row><cell cols="2">OMMST CPU</cell><cell cols="2">1 min 20 153 kJ</cell><cell>958 MB</cell><cell cols="2">18 min 32 kJ</cell><cell>96 MB</cell><cell>0.67</cell><cell>128</cell></row><row><cell cols="2">Lightweight AE</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>RE</cell><cell>GPU</cell><cell>1 h 26</cell><cell>5040 kJ</cell><cell>26 GB</cell><cell>3 h 30</cell><cell>8350 kJ</cell><cell>22 GB</cell><cell>0.61</cell><cell>5266</cell></row><row><cell>FF</cell><cell>GPU</cell><cell>4 h</cell><cell>6854 kJ</cell><cell>27 GB</cell><cell>3 h 53</cell><cell>13158 kJ</cell><cell>27 GB</cell><cell>0.55</cell><cell>1520</cell></row><row><cell>Resnet-18</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>RE</cell><cell>GPU</cell><cell cols="2">17 h 40 53213 kJ</cell><cell>26 GB</cell><cell>59 h</cell><cell>108593 kJ</cell><cell>28 GB</cell><cell>0.64</cell><cell>23730218</cell></row><row><cell>FF</cell><cell>GPU</cell><cell>4 h 10</cell><cell>7234 kJ</cell><cell>28 GB</cell><cell cols="2">19 h 45 18481 kJ</cell><cell>28 GB</cell><cell>0.61</cell><cell>1520</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43898-1 40.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Fully automatic lesion localization and characterization: application to brain tumors using multiparametric quantitative MRI data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Arnaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Coquery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Collomb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lemasson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Barbier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1678" to="1689" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Slope heuristic: overview and implementation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Baudry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Maugis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Michel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Comp</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="455" to="470" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Autoencoders for unsupervised anomaly segmentation in brain MR images: a comparative study</title>
		<author>
			<persName><forename type="first">C</forename><surname>Baur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Denner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wiestler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Albarqouni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page">101952</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Stochastic Approximation: A Dynamical View Point</title>
		<author>
			<persName><forename type="first">V</forename><surname>Borkar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">PowerAPI: a software library to monitor the energy consumed at the process-level</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bourdon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Noureddine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rouvoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Seinturier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>ERCIM News</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On-line Expectation-Maximization algorithm for latent data models</title>
		<author>
			<persName><forename type="first">O</forename><surname>Cappé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Moulines</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. B</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="593" to="613" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Increased nigral iron content in postmortem Parkinsonian brain</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Dexter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lancet</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1219" to="1220" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Combined R2* and diffusion tensor imaging changes in the substantia Nigra in Parkinson&apos;s disease</title>
		<author>
			<persName><forename type="first">G</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mov. Disord</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1627" to="1632" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Evchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vanschoren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Hoos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schoenauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sebag</surname></persName>
		</author>
		<idno>arXiv:abs/2111.03731</idno>
		<title level="m">Frugal machine learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A new family of multivariate heavy-tailed distributions with variable marginal amounts of tailweights: application to robust clustering</title>
		<author>
			<persName><forename type="first">F</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wraith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Comput</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="971" to="984" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A stochastic path-integrated differential estimator expectation maximization algorithm</title>
		<author>
			<persName><forename type="first">G</forename><surname>Fort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Moulines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Wai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">34th Conference on Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Fast incremental expectation maximization for finite-sum optimization: nonasymptotic convergence</title>
		<author>
			<persName><forename type="first">G</forename><surname>Fort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Moulines</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Comp</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page">48</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dipy, a library for the analysis of diffusion MRI data</title>
		<author>
			<persName><forename type="first">E</forename><surname>Garyfallidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front, Neuroinf</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Radiomics: images are more than pictures, they are data</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Gillies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Kinahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hricak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">278</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="563" to="577" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Parkinsonism: onset, progression, and mortality</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Hoehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Yahr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurology</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="318" to="318" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Non-asymptotic analysis of biased stochastic approximation scheme</title>
		<author>
			<persName><forename type="first">B</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Miasojedow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Moulines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Wai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="1" to="31" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">On the global convergence of (fast) incremental Expectation Maximization methods</title>
		<author>
			<persName><forename type="first">B</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Wai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Moulines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lavielle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">rd Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>NeurIPS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Multivariate t Distributions And Their Applications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kotz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nadarajah</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Properties of the stochastic approximation EM algorithm with mini-batch sampling</title>
		<author>
			<persName><forename type="first">E</forename><surname>Kuhn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Matias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rebafka</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11222-020-09968-0</idno>
		<ptr target="https://doi.org/10.1007/s11222-020-09968-0" />
	</analytic>
	<monogr>
		<title level="j">Stat. Comput</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1725" to="1739" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Unsupervised pathology detection: A deep dive into the state of the art</title>
		<author>
			<persName><forename type="first">I</forename><surname>Lagogiannis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Meissen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kaissis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<idno>arXiv arXiv:abs:2303.00609</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">CutPaste: self-supervised learning for anomaly detection and localization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="9664" to="9674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Online EM for functional data</title>
		<author>
			<persName><forename type="first">F</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Moulines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lefebvre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Stat. Data Anal</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="page" from="27" to="47" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The Parkinson&apos;s progression markers initiative -establishing a PD biomarker cohort</title>
		<author>
			<persName><forename type="first">K</forename><surname>Marek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Clin. Transl. Neurol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1460" to="1477" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Quantitative MRI characterization of brain abnormalities in de novo Parkinsonian patients</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Mclachlan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Munoz-Ramirez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Arbel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Arnaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dojat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE International Symposium on Biomedical Imaging</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<date type="published" when="2007">2007. 2019</date>
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
	<note>The EM Algorithm and Extensions</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Subtle anomaly detection in MRI brain scans: application to biomarkers extraction in patients with de novo Parkinson&apos;s disease</title>
		<author>
			<persName><forename type="first">V</forename><surname>Muñoz-Ramírez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kmetzsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Meoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Moro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dojat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell. Med</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="page">102251</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Patch vs. global image-based unsupervised anomaly detection in MR brain scans of early Parkinsonian Patients</title>
		<author>
			<persName><forename type="first">V</forename><surname>Muñoz-Ramírez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Pinon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lartizen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dojat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning in Clinical Neuroimaging</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Global implicit function theorems and the online expectation-maximisation algorithm</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Forbes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Aust. NZ J. Stat</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="255" to="281" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Mini-batch learning of exponential family finite mixture models</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Mclachlan</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11222-019-09919-4</idno>
		<idno>11222-019-09919-4</idno>
		<ptr target="https://doi.org/10.1007/s" />
	</analytic>
	<monogr>
		<title level="j">Stat. Comput</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="731" to="748" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A multivariate Gaussian mixture model for anomaly detection in transient current signature of control element drive mechanism</title>
		<author>
			<persName><forename type="first">A</forename><surname>Oluwasegun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Jung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucl. Eng. Des</title>
		<imprint>
			<biblScope unit="volume">402</biblScope>
			<biblScope unit="page">112098</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A high-resolution probabilistic in vivo atlas of human subcortical brain nuclei</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Pauli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Nili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Tyszka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Data</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Unsupervised brain imaging 3D anomaly detection and segmentation with transformers</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Pinaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page">102475</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Brain subtle anomaly detection based on auto-encoders latent space analysis: application to de novo Parkinson patients</title>
		<author>
			<persName><forename type="first">N</forename><surname>Pinon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Oudoumanessah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Trombetta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dojat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lartizien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE International Symposium on Biomedical Imaging</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Green AI</title>
		<author>
			<persName><forename type="first">R</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="54" to="63" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Diffusion tensor imaging of nigral degeneration in Parkinson&apos;s disease: a region-of-interest and voxel-based study at 3T and systematic review with meta-analysis</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Abaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gontu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Auer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>NeuroImage Clin</publisher>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="481" to="488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Energy and policy considerations for deep learning in NLP</title>
		<author>
			<persName><forename type="first">E</forename><surname>Strubell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Association for Computational Linguistics</publisher>
		</imprint>
	</monogr>
	<note>In: 57th Meeting of the</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Greenewald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">F</forename><surname>Manso</surname></persName>
		</author>
		<idno>arXiv:abs/2007.05558</idno>
		<title level="m">The computational limits of deep learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<idno>arXiv:abs/2111.07677</idno>
		<title level="m">FastFlow: unsupervised anomaly detection and localization via 2D normalizing flows</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
