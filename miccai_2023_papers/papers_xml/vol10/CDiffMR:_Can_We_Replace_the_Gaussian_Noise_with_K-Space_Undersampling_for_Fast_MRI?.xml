<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CDiffMR: Can We Replace the Gaussian Noise with K-Space Undersampling for Fast MRI?</title>
				<funder ref="#_Z8kx9w7">
					<orgName type="full">ERC IMI</orgName>
				</funder>
				<funder>
					<orgName type="full">Boehringer Ingelheim Ltd</orgName>
				</funder>
				<funder ref="#_mjMN5Wr">
					<orgName type="full">NVIDIA Academic Hardware Grant Program</orgName>
				</funder>
				<funder>
					<orgName type="full">Wellcome Leap Dynamic Resilience</orgName>
				</funder>
				<funder ref="#_VBTdVsb">
					<orgName type="full">MRC</orgName>
				</funder>
				<funder ref="#_fVacqkH">
					<orgName type="full">Royal Society</orgName>
				</funder>
				<funder ref="#_AWNn4Sk">
					<orgName type="full">UKRI</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jiahao</forename><surname>Huang</surname></persName>
							<email>j.huang21@imperial.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">National Heart and Lung Institute</orgName>
								<orgName type="institution" key="instit2">Imperial College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Cardiovascular Research Centre</orgName>
								<orgName type="institution">Royal Brompton Hospital</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Angelica</forename><forename type="middle">I</forename><surname>Aviles-Rivero</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Applied Mathematics and Theoretical Physics</orgName>
								<orgName type="institution">University of Cambridge</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Carola-Bibiane</forename><surname>Sch√∂nlieb</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Applied Mathematics and Theoretical Physics</orgName>
								<orgName type="institution">University of Cambridge</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Guang</forename><surname>Yang</surname></persName>
							<email>g.yang@imperial.ac.uk</email>
							<affiliation key="aff3">
								<orgName type="department">Bioengineering Department and Imperial-X</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<postCode>W12 7SL</postCode>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution" key="instit1">National Heart and Lung Institute</orgName>
								<orgName type="institution" key="instit2">Imperial College London</orgName>
								<address>
									<postCode>SW7 2AZ</postCode>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="department">Cardiovascular Research Centre</orgName>
								<orgName type="institution">Royal Brompton Hospital</orgName>
								<address>
									<postCode>SW3 6NP</postCode>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff6">
								<orgName type="department">School of Biomedical Engineering &amp; Imaging Sciences</orgName>
								<orgName type="institution">King&apos;s College London</orgName>
								<address>
									<postCode>WC2R 2LS</postCode>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">CDiffMR: Can We Replace the Gaussian Noise with K-Space Undersampling for Fast MRI?</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C79B33848A0ACC642A5BEC9613319D78</idno>
					<idno type="DOI">10.1007/978-3-031-43999-51.</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-23T22:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Diffusion Models</term>
					<term>Fast MRI</term>
					<term>Deep Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep learning has shown the capability to substantially accelerate MRI reconstruction while acquiring fewer measurements. Recently, diffusion models have gained burgeoning interests as a novel group of deep learning-based generative methods. These methods seek to sample data points that belong to a target distribution from a Gaussian distribution, which has been successfully extended to MRI reconstruction. In this work, we proposed a Cold Diffusion-based MRI reconstruction method called CDiffMR. Different from conventional diffusion models, the degradation operation of our CDiffMR is based on k -space undersampling instead of adding Gaussian noise, and the restoration network is trained to harness a de-aliaseing function. We also design starting point and data consistency conditioning strategies to guide and accelerate the reverse process. More intriguingly, the pre-trained CDiffMR model can be reused for reconstruction tasks with different undersampling rates. We demonstrated, through extensive numerical and visual experiments, that the proposed CDiffMR can achieve comparable or even superior reconstruction results than state-of-the-art models. Compared to the diffusion model-based counterpart, CDiffMR reaches readily competing results using only 1.6-3.4% for inference time. The code is publicly available at https://github.com/ayanglab/CDiffMR.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Magnetic Resonance Imaging (MRI) is an essential non-invasive technique that enables high-resolution and reproducible assessments of structural and functional information, for clinical diagnosis and prognosis, without exposing the patient to radiation. Despite its widely use in clinical practice, MRI still suffers from the intrinsically slow data acquisition process, which leads to uncomfortable patient experience and artefacts from voluntary and involuntary physiological movements <ref type="bibr" target="#b4">[5]</ref>. Deep learning has achieved considerable success across various research domains in recent years, including the ability to substantially accelerate MRI reconstruction while requiring fewer measurements. Various kinds of deep learning-based models, including Convolutional Neural Networks <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b20">21]</ref>, Recurrent Neural Networks <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b8">9]</ref>, Graph Neural Networks <ref type="bibr" target="#b10">[11]</ref> or Transformers <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>, have been explored for MRI reconstruction and achieved impressive success with a high accelerate factor (AF). However, most of these methods are based on a strong degradation prior, i.e., the undersampling mask, which entails a performance drop when the training and testing undersampling masks mismatch <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b15">16]</ref>. Therefore, additional training is required when applying different undersampling mask condition, leading to a waste of computational resources.</p><p>Diffusion models <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b19">20]</ref> represent a group of unconditional generative methods which sample data points that belong to target distribution from a Gaussian distribution. The earliest diffusion models type was known as Denoising Diffusion Probabilistic Models (DDPMs) <ref type="bibr" target="#b9">[10]</ref> and Score Matching with Langevin Dynamics (SMLD) <ref type="bibr" target="#b17">[18]</ref>, which were later unified into a framework by Score-based Stochastic Differential Equation (SDE) <ref type="bibr" target="#b19">[20]</ref>.</p><p>Diffusion models have been widely applied for inverse problems <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b18">19]</ref> including MRI Reconstruction <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b13">14]</ref>. Peng et al. <ref type="bibr" target="#b13">[14]</ref> proposed a diffusion modelbased MR reconstruction method, called DiffuseRecon, which did not require additional training on specific acceleration factors. Chung et al. <ref type="bibr" target="#b6">[7]</ref> designed a score-based model for MRI reconstruction, which performed the reconstruction task iteratively using a numerical SDE solver and data consistency step. Cao et al. <ref type="bibr" target="#b2">[3]</ref> proposed a complex diffusion probabilistic model for MRI reconstruction for better preservation of the MRI complex-value information. Gungor et al. <ref type="bibr" target="#b7">[8]</ref> introduced an adaptive diffusion prior, namely AdaDiff, for enhancing reconstruction performance during the inference stage. Cao et al. <ref type="bibr" target="#b1">[2]</ref> designed a modified high-frequency DDPM model for high-frequency information preservation of MRI data. However, they do share a commonality-the prolonged inference time due to the iterative nature of diffusion models. Chung et al. <ref type="bibr" target="#b5">[6]</ref> proposed a new reverse process strategy for accelerating the sampling for the reverse problem, Come-Closer-Diffuse-Faster (CCDF), suggesting that starting from Gaussian noise is necessary for diffusion models. CCDF-MRI achieved outstanding reconstruction results with reduced reverse process steps.</p><p>Most existing diffusion models, including the original DDPM, SMLD and their variants, are strongly based on the use of Gaussian noise, which provides the 'random walk' for 'hot' diffusion. Cold Diffusion Model <ref type="bibr" target="#b0">[1]</ref> rethought the role of the Gaussian noise, and generalised the diffusion models using different kinds of degradation strategies, e.g., blur, pixelate, mask-out, rather than the Gaussian noise applied on conventional diffusion models.</p><p>In this work, a novel Cold Diffusion-based MRI Reconstruction method (CDiffMR) is proposed (see Fig. <ref type="figure" target="#fig_0">1</ref>). CDiffMR introduces a novel K-Space Undersampling Degradation (KSUD) module for the degradation, which means CDiffMR does not depend on the Gaussian noise. Instead of building an implicit transform to target distribution by Gaussian noise, CDiffMR explicitly learns the relationship between undersampled distribution and target distribution by KSUD.</p><p>We propose two novel k -space conditioning strategies to guide the reverse process and to reduce the required time steps. 1) Starting Point Conditioning (SPC). The k -space undersampled zero-filled images, which is usually regarded as the network input, can act as the reverse process starting point for conditioning. The number of reverse time steps therefore depends on the undersamping rate, i.e., the higher k -space undersampling rate (lower AF, easier task), the fewer reverse time steps required. 2) Data Consistency Conditioning (DCC). In every step of the reverse process, data consistency is applied to further guide the reverse process in the correct way.</p><p>It is note that our CDiffMR is a one-for-all model. This means that once CDiffMR is trained, it can be reused for all the reconstruction tasks, with any reasonable undersampling rates conditioning, as long as the undersampling rate is larger than the preset degraded images x T at the end of forward process (e.g., 1% undersampling rate). Experiments were conducted on FastMRI dataset <ref type="bibr" target="#b21">[22]</ref>. The proposed CDiffMR achieves comparable or superior reconstruction results with respect to state-of-the-art methods, and reaches a much faster reverse process compared with diffusion model-based counterparts. For the sake of clarity, we use 'sampling' or 'undersampling' to specify the k -space data acquisition for MRI, and use 'reverse process' to represent sampling from target data distribution in the inference stage of diffusion models. Our main contributions are summarised as follows:</p><p>‚Ä¢ An innovative Cold Diffusion-based MRI Reconstruction methods is proposed. To best of our knowledge, CDiffMR is the first diffusion model-based MRI reconstruction method that exploits the k -space undersampling degradation. ‚Ä¢ Two novel k -space conditioning strategies, namely SPC and DCC, are developed to guide and accelerate the reverse process. ‚Ä¢ The pre-trained CDiffMR model can be reused for MRI reconstruction tasks with a reasonable range of undersampling rates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>This section details two key parts of the proposed CDiffMR: 1) the optimisation and training schemes and 2) the k -space conditioning reverse process.  min for LogSR schedule (see Fig. <ref type="figure" target="#fig_1">2</ref>). D(x, t+1) contains less k -space information compared to D(x, t), and when t = 0 we have:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Model Components and Training</head><formula xml:id="formula_0">x = D(x, 0) = F -1 M 0 Fx = F -1 IFx, (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where M t is the undersampling mask at step t corresponding to SR t , and M 0 = I is the fully-sampling mask (identity map). F and F -<ref type="foot" target="#foot_0">1</ref> denote Fourier and inverse Fourier transform.</p><p>The restoration operator R Œ∏ (‚Ä¢, t) is an improved U-Net with time embedding module, following the official implementation 1 of Denoising Diffusion Implicit Models <ref type="bibr" target="#b16">[17]</ref>.</p><formula xml:id="formula_2">An ideal R Œ∏ (‚Ä¢, t) should satisfy x 0 ‚âà R Œ∏ (x t , t).</formula><p>For the training of the restoration operator R Œ∏ (‚Ä¢, t), x true is the fully-sampled images randomly sampled from target distribution X . Practically, time step t is randomly chosen from (1, T ] during the training. The driven optimisation scheme reads:</p><p>min</p><formula xml:id="formula_3">Œ∏ E xtrue‚àºX R Œ∏ (D(x true , t), t) -x , t= 1...T.<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">K-Space Conditioning Reverse Process</head><p>Two k -space conditioning strategies, SPC and DCC, are designed to guide and accelerate the reverse process.</p><p>Starting Point Conditioning enables the reverse process of CDiffMR to start from the half way step T instead of step T (see Fig. <ref type="figure" target="#fig_0">1</ref> and Fig. <ref type="figure" target="#fig_1">2</ref>). The starting point of the reverse process depends on the k -space undersampling rate of the reconstruction task. Specifically, for the reconstruction task with M, T can be checked by comparing the sampling rate of M in the degradation schedule, and the corresponding reverse process start step T can be located, which is expressed as:</p><p>Sampling Rate:</p><formula xml:id="formula_4">M T &lt; M T &lt; M &lt; M T -1 &lt; M 0 = I. (<label>3</label></formula><formula xml:id="formula_5">)</formula><p>With the start step T , the reverse process is conditioned by the reverse process of the initial image x T ‚Üê F -1 y. The framework of the reverse process follows Algorithm 2 in <ref type="bibr" target="#b0">[1]</ref>, whereas we applied DCC strategy for further guiding (Eq. ( <ref type="formula" target="#formula_6">5</ref>)). The result of the reverse process x 0 is the final reconstruction result. The whole reverse process is formulated as:</p><formula xml:id="formula_6">x 0,t = R Œ∏ (x t , t), s.t. t = T ...1. (4) x0,t = F -1 (1 -M)F x 0,t + F -1 MFx T , s.t. t = T ...1. (<label>5</label></formula><formula xml:id="formula_7">)</formula><p>x t-1 = x t -D(x 0,t , t) + D(x 0,t , t -1), s.t. t = T ...1. (6)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Results</head><p>This section describes in detail the set of experiments conducted to validate the proposed CDiffMR. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Implementation Details and Evaluation Methods</head><p>The experiments were conducted on the FastMRI dataset <ref type="bibr" target="#b21">[22]</ref>, which contains single-channel complex-value MRI data. For the FastMRI dataset, we applied 684 proton-density weighted knee MRI scans without fat suppression from the official training and validation sets, which were randomly divided into training set (420 cases), validation set (64 cases) and testing set (200 cases), approximately according to a ratio of 6:1:3. For each case, 20 coronal 2D single-channel complex-value slices near the centre were chosen, and all slices were centrecropped to 320 √ó 320.</p><p>Undersampling mask M and M t were generated by the fastMRI official implementation. We applied AF√ó8 and √ó16 Cartesian mask for all experiments.</p><p>Our proposed CDiffMR was trained on two NVIDIA A100 (80 GB) GPUs, and tested on an NVIDIA RTX3090 (24 GB) GPU. CDiffMR was trained for 100,000 gradient steps, using the Adam optimiser with a learning rate 2e-5 and a batch size 24. We set the total diffusion time step to T = 100 for both LinSR and LogSR degradation schedules. The minimal sampling rate (when t = 100) was set to 1%.</p><p>For comparison, we used CNN-based methods D5C5 <ref type="bibr" target="#b14">[15]</ref>, DAGAN <ref type="bibr" target="#b20">[21]</ref>, Transformers-based method SwinMR <ref type="bibr" target="#b11">[12]</ref>, novel diffusion model-based method DiffuseRecon <ref type="bibr" target="#b13">[14]</ref>. We trained D5C5 and DiffuseRecon following the official setting, while we modified DAGAN and SwinMR for 2-channel input, output and loss function, as they were officially proposed for single-channel reconstruction.</p><p>In the quantitative experiments, Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index Measure (SSIM), Learned Perceptual Image Patch Similarity (LPIPS) <ref type="bibr" target="#b22">[23]</ref> were applied to examine the reconstruction quality. Among them, LPIPS is a deep learning-based perceptual metric, which can match human visual perception well. The inference time was measured on a NVIDIA RTX3090 (24 GB) GPU with an input shape of (1, 1, 320, 320) for ten times. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Comparison and Ablation Studies</head><p>The quantitative results are reported in Table <ref type="table" target="#tab_1">1</ref> and further supported by visual comparisons in Fig. <ref type="figure" target="#fig_2">3</ref>. The proposed CDiffMR achieves promising results compared to the SOTA MRI reconstruction methods. Compared with the diffusion model-based method DiffuseRecon, CDiffMR achieves comparable or better results with only 1.6-3.4% inference time of DiffuseRecon. For ablation studies, we explored how DDC and SPC affect the speed of reverse process and reconstruction quality (see Fig. <ref type="figure" target="#fig_3">4</ref>(A)(B)). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion and Conclusion</head><p>This work has exploited Cold Diffusion-based model for MRI reconstruction and proposed CDiffMR. We have designed the novel KSUD for degradation operator D(‚Ä¢, t) and trained a restoration function R Œ∏ (‚Ä¢, t) for de-aliasing under various undersampling rates. We pioneered the harmonisation of the degradation function in reverse problem (k -space undersampling in MRI reconstruction) and the degradation operator in diffusion model (KSUD). In doing so, CDiffMR is able to explicitly learn the k -space undersampling operation to further improve the reconstruction, while providing the basis for the reverse process acceleration. Two k -space conditioning strategies, SPC and DCC, have been designed to guide and accelerate the reverse process. Experiments have demonstrated that k -space undersampling can be successfully used as degradation in diffusion models for MRI reconstruction. In this study, two KSUD schedules, i.e., have been designed for controlling the k -space sampling rate of every reverse time steps. According to Table <ref type="table" target="#tab_1">1</ref>, LogSR schedule achieves better perceptual score while LinSR has better fidelity score, where the difference is actually not significant. However, the required reverse process steps of LogSR is much fewer than LinSR's, which significantly accelerates the reverse process. This is because for LogSR schedule, a larger proportion steps are corresponding to lower sampling rate (high AF), therefore the starting point of LogSR is closer to step 0 than LinSR (see Fig. <ref type="figure" target="#fig_1">2</ref> and Fig. <ref type="figure" target="#fig_3">4(A)</ref>). For AF√ó16 reconstruction task, CDiffMR-LinSR theoretically requires 95 reverse steps, while CDiffMR-LogSR only requires 61 reverse steps, and for AF√ó8 reconstruction task, CDiffMR-LinSR requires 89 reverse steps, while CDiffMR-LogSR only requires 46 reverse steps. The lower AF of the reconstruction task, the less reverse process steps required. Therefore, we recommend CDiffMR-LogSR as it achieves similiar results of CDiffMR-LinSR with much faster reverse process.</p><p>In the ablation studies, we have further examined the selection of reverse process starting point T . Figure <ref type="figure" target="#fig_3">4</ref>(A) has shown the reconstruction quality using different starting point. Reconstruction performance keeps stable with a range of reverse process starting points, but suddenly drops after a tuning point, which exactly matches the theoretical starting point. This experiment has proven the validity of our starting point selection method (Eq. ( <ref type="formula" target="#formula_4">3</ref>)), and shown that our theoretical starting point keeps optimal balance between the reconstruction process and reverse process speed.</p><p>We also explored the validity of DDC in the ablation studies. Figure <ref type="figure" target="#fig_3">4</ref>(B) has shown the reconstruction quality with or without DDC using different sampling rate schedule with different AF. The improvement by the DDC is significant with a lower AF (√ó4), but limited with a higher AF (√ó8, √ó16). Therefore, CDiffMR keeps the DDC due to its insignificant computational cost.</p><p>The proposed CDiffMR heralds a new kind of diffusion models for solving inverse problems, i.e., applying the degradation model in reverse problem as the degradation module in diffusion model. CDiffMR has proven that this idea performs well for MRI reconstruction tasks. We can envision that our CDiffMR can serve as the basis for general inverse problems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Row 1: The reverse process of conditional DDPM [10]; Row 2: The K-Space Undersampling Degradation Mask for the proposed CDiffMR; Row 3: The reverse process of CDiffMR without DDC and SPC; Row 4: The reverse process of CDiffMR with DDC but without SPC; Row 5: The reverse process of CDiffMR with DDC and SPC; SPC: Starting Point Conditioning; DDC: Data Consistency Conditioning.</figDesc><graphic coords="2,48,81,183,02,326,05,204,64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Linear and Log k -space undersampling degradation schedules of CDiffMR.</figDesc><graphic coords="4,224,10,386,42,145,72,151,00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Visual comparison against the state-of-the-art approaches with accelerate rate (AF) √ó8 and √ó16. The colour bar denotes the difference between the reconstructed result and ground truth. Zoom-in views displays selected fine detailed regions.</figDesc><graphic coords="6,49,80,124,52,324,28,153,64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. (A) The relationship between reconstruction metrics and the reverse process starting point conditioning (SPC); (B) The relationship between reconstruction metrics and the reverse process data consistency conditioning (DDC).</figDesc><graphic coords="8,59,31,54,26,305,56,206,44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>With the support of KSUD, CDiffMR can explicitly learn the relationship between input distribution of k -space undersampled images and target distribution of fully-sampled images that is built implicitly by Gaussian noise in the conventional diffusion model. The KSUD operator D(x, t) = F -1 M t Fx, undersamples input images via different k -space mask of which undersampling rate is controlled by the time step t.Two k -space sampling rate SR t schedule are designed in this study, linear (LinSR) and log (LogSR) sampling rate schedules. We set SR t = 1-(1-SR min ) t</figDesc><table><row><cell>Diffusion models are generally com-posed of a degradation operator D(‚Ä¢, t) and a learnable restoration operator R Œ∏ (‚Ä¢, t) [1]. For standard dif-fusion models, the D(‚Ä¢, t) disturbs the images via Gaussian noise according to a preset noise schedule controlled by time step t. The R Œ∏ (‚Ä¢, t) is a denois-ing function controlled by t for various noise levels. Instead of applying Gaussian noise, CDiffMR provides a new option, namely KSUD operator D(‚Ä¢, t) and de-aliasing restoration operator R Œ∏ (‚Ä¢, t). T t for LinSR schedule, and SR t = SR T</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Quantitative reconstruction results with accelerate rate (AF) √ó8 and √ó16. LinSR (LogSR): linear (log) sampling rate schedule; ( ‚Ä† ): significantly different from CDiffMR-LinSR(LogSR) by Mann-Whitney Test.</figDesc><table><row><cell cols="2">Model (AF √ó8) SSIM ‚Üë</cell><cell>PSNR ‚Üë</cell><cell>LPIPS ‚Üì</cell><cell>Inference Time ‚Üì</cell></row><row><cell>ZF</cell><cell cols="4">0.678 (0.087)  ‚Ä† 22.74 (1.73)  ‚Ä† 0.504 (0.058)  ‚Ä† -</cell></row><row><cell>D5C5 [15]</cell><cell cols="4">0.719 (0.104)  ‚Ä† 25.99 (2.13)  ‚Ä† 0.291 (0.039)  ‚Ä† 0.044</cell></row><row><cell>DAGAN [21]</cell><cell cols="4">0.709 (0.095)  ‚Ä† 25.19 (2.21)  ‚Ä† 0.262 (0.043)  ‚Ä† 0.004</cell></row><row><cell>SwinMR [12]</cell><cell cols="4">0.730 (0.107)  ‚Ä† 26.98 (2.46)  ‚Ä† 0.254 (0.042)  ‚Ä† 0.037</cell></row><row><cell cols="2">DiffuseRecon [14] 0.738 (0.108)</cell><cell cols="3">27.40 (2.40) 0.286 (0.038)  ‚Ä† 183.770</cell></row><row><cell cols="3">CDiffMR-LinSR 0.745 (0.108) 27.35 (2.56)</cell><cell>0.240 (0.042)</cell><cell>5.862</cell></row><row><cell cols="2">CDiffMR-LogSR 0.744 (0.107)</cell><cell>27.26 (2.52)</cell><cell cols="2">0.236 (0.041) 3.030</cell></row><row><cell cols="2">Model (AF √ó16) SSIM ‚Üë</cell><cell>PSNR ‚Üë</cell><cell>LPIPS ‚Üì</cell><cell>Inference Time ‚Üì</cell></row><row><cell>ZF</cell><cell cols="4">0.624 (0.080)  ‚Ä† 20.04 (1.59)  ‚Ä† 0.580 (0.049)  ‚Ä† -</cell></row><row><cell>D5C5 [15]</cell><cell cols="4">0.667 (0.108)  ‚Ä† 23.35 (1.78)  ‚Ä† 0.412 (0.049)  ‚Ä† 0.044</cell></row><row><cell>DAGAN [21]</cell><cell cols="4">0.673 (0.102)  ‚Ä† 23.87 (1.84)  ‚Ä† 0.317 (0.044)  ‚Ä† 0.004</cell></row><row><cell>SwinMR [12]</cell><cell cols="4">0.673 (0.115)  ‚Ä† 24.85 (2.12)  ‚Ä† 0.327 (0.045)  ‚Ä† 0.037</cell></row><row><cell cols="5">DiffuseRecon [14] 0.688 (0.119)  ‚Ä† 25.75 (2.15)  ‚Ä† 0.362 (0.047)  ‚Ä† 183.770</cell></row><row><cell cols="4">CDiffMR-LinSR 0.709 (0.117) 25.83 (2.27) 0.297 (0.042)</cell><cell>6.263</cell></row><row><cell cols="2">CDiffMR-LogSR 0.707 (0.116)</cell><cell>25.77 (2.25)</cell><cell cols="2">0.293 (0.042) 4.017</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://github.com/ermongroup/ddim.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement. This study was supported in part by the <rs type="funder">ERC IMI</rs> (<rs type="grantNumber">101005122</rs>), the <rs type="grantNumber">H2020 (952172</rs>), the <rs type="funder">MRC</rs> (<rs type="grantNumber">MC/PC/21013</rs>), the <rs type="funder">Royal Society</rs> (<rs type="grantNumber">IEC\NSFC\211235</rs>), the <rs type="funder">NVIDIA Academic Hardware Grant Program</rs>, the <rs type="projectName">SABER</rs> project supported by <rs type="funder">Boehringer Ingelheim Ltd</rs>, <rs type="funder">Wellcome Leap Dynamic Resilience</rs>, and the <rs type="funder">UKRI</rs> <rs type="grantName">Future Leaders Fellowship</rs> (<rs type="grantNumber">MR/V023799/1</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Z8kx9w7">
					<idno type="grant-number">101005122</idno>
				</org>
				<org type="funding" xml:id="_VBTdVsb">
					<idno type="grant-number">H2020 (952172</idno>
				</org>
				<org type="funding" xml:id="_fVacqkH">
					<idno type="grant-number">MC/PC/21013</idno>
				</org>
				<org type="funded-project" xml:id="_mjMN5Wr">
					<idno type="grant-number">IEC\NSFC\211235</idno>
					<orgName type="project" subtype="full">SABER</orgName>
				</org>
				<org type="funding" xml:id="_AWNn4Sk">
					<idno type="grant-number">MR/V023799/1</idno>
					<orgName type="grant-name">Future Leaders Fellowship</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Bansal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.09392</idno>
		<title level="m">Cold diffusion: inverting arbitrary image transforms without noise</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">X</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.05481</idno>
		<title level="m">High-frequency space diffusion models for accelerated MRI</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Accelerating multi-echo MRI in k-space with complex-valued diffusion probabilistic model</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 16th IEEE International Conference on Signal Processing (ICSP)</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="479" to="484" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Pyramid convolutional RNN for MRI image reconstruction</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2033" to="2047" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">AI-based reconstruction for fast MRI-A systematic review and meta-analysis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="224" to="245" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Come-closer-diffuse-faster: accelerating conditional diffusion models for inverse problems through stochastic contraction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="12413" to="12422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Score-based diffusion models for accelerated MRI</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page">102479</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Adaptive diffusion priors for accelerated MRI reconstruction</title>
		<author>
			<persName><forename type="first">A</forename><surname>G√ºng√∂r</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.05876</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Over-andunder complete convolutional RNN for MRI reconstruction</title>
		<author>
			<persName><forename type="first">P</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M J</forename><surname>Valanarasu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87231-1_2</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87231-12" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12906</biblScope>
			<biblScope unit="page" from="13" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Denoising diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aviles-Rivero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Schonlieb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.10273</idno>
		<title level="m">ViGU: vision GNN U-net for fast MRI</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Swin transformer for fast MRI</title>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">493</biblScope>
			<biblScope unit="page" from="281" to="304" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Unsupervised MRI reconstruction via zero-shot learned adversarial transformers</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Korkmaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">U H</forename><surname>Dar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yurt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>√ñzbey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1747" to="1763" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Towards performant and reliable undersampled MR reconstruction via diffusion model sampling</title>
		<author>
			<persName><forename type="first">C</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13436</biblScope>
			<biblScope unit="page" from="623" to="633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A deep cascade of convolutional neural networks for MR image reconstruction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schlemper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Hajnal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-59050-9_51</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-59050-951" />
	</analytic>
	<monogr>
		<title level="m">IPMI 2017</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Niethammer</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">10265</biblScope>
			<biblScope unit="page" from="647" to="658" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Implicit data crimes: machine learning bias arising from misuse of public data</title>
		<author>
			<persName><forename type="first">E</forename><surname>Shimron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Tamir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lustig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl. Acad. Sci</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page">2117203119</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.02502</idno>
		<title level="m">Denoising diffusion implicit models</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Generative modeling by estimating gradients of the data distribution</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Solving inverse problems in medical imaging with score-based generative models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.08005</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.13456</idno>
		<title level="m">Scorebased generative modeling through stochastic differential equations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">DAGAN: deep de-aliasing generative adversarial networks for fast compressed sensing MRI reconstruction</title>
		<author>
			<persName><forename type="first">G</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1310" to="1321" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Zbontar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.08839</idno>
		<title level="m">fastMRI: an open dataset and benchmarks for accelerated MRI</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The unreasonable effectiveness of deep features as a perceptual metric</title>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="586" to="595" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
