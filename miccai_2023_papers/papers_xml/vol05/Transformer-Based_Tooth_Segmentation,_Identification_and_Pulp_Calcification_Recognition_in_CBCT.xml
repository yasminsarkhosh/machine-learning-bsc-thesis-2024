<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Transformer-Based Tooth Segmentation, Identification and Pulp Calcification Recognition in CBCT</title>
				<funder ref="#_b68TpnN">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Shangxuan</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Medical Information Engineering</orgName>
								<orgName type="institution">Guangzhou University of Chinese Medicine</orgName>
								<address>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Hanglok-Tech Co., Ltd</orgName>
								<address>
									<settlement>Zhuhai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chichi</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yu</forename><surname>Du</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Hanglok-Tech Co., Ltd</orgName>
								<address>
									<settlement>Zhuhai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Operative Dentistry and Endodontics</orgName>
								<orgName type="institution">Sun Yat-sen University</orgName>
								<address>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Affiliated Stomatological Hospital</orgName>
								<address>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="laboratory">Guangdong Provincial Key Laboratory of Stomatology</orgName>
								<address>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Li</forename><surname>Ye</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Operative Dentistry and Endodontics</orgName>
								<orgName type="institution">Sun Yat-sen University</orgName>
								<address>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Affiliated Stomatological Hospital</orgName>
								<address>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="laboratory">Guangdong Provincial Key Laboratory of Stomatology</orgName>
								<address>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yanshu</forename><surname>Fang</surname></persName>
							<affiliation key="aff5">
								<orgName type="department">First Clinical Medical College</orgName>
								<orgName type="institution">Guangzhou University of Chinese Medicine</orgName>
								<address>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Cheng</forename><surname>Wang</surname></persName>
							<email>cheng.wang@hanglok-tech.cn</email>
							<affiliation key="aff1">
								<orgName type="institution">Hanglok-Tech Co., Ltd</orgName>
								<address>
									<settlement>Zhuhai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wu</forename><surname>Zhou</surname></persName>
							<email>zhouwu@gzucm.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Medical Information Engineering</orgName>
								<orgName type="institution">Guangzhou University of Chinese Medicine</orgName>
								<address>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Transformer-Based Tooth Segmentation, Identification and Pulp Calcification Recognition in CBCT</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="706" to="714"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">C7A3479C05721E8484B4F74BCAC41A86</idno>
					<idno type="DOI">10.1007/978-3-031-43904-9_68</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-25T18:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Pulp calcification recognition</term>
					<term>Transformer</term>
					<term>Instance correlation</term>
					<term>Tooth Segmentation</term>
					<term>CBCT</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The recognition of dental pulp calcification has important value for oral clinic, which determines the subsequent treatment decision. However, the recognition of dental pulp calcification is remarkably difficult in clinical practice due to its atypical morphological characteristics. In addition, pulp calcification is also difficult to be visualized in high-resolution CBCT due to its small area and weak contrast. In this work, we proposed a new method of tooth segmentation, identification and pulp calcification recognition based on Transformer to achieve accurate recognition of pulp calcification in high-resolution CBCT images. First, in order to realize that the network can handle extremely highresolution CBCT, we proposed a coarse-to-fine method to segment the tooth instance in the down-scaled low-resolution CBCT image, and then back to the high-resolution CBCT image to intercept the region of the tooth as the input for the fine segmentation, identification and pulp calcification recognition. Then, in order to enhance the weak distinction between normal teeth and calcified teeth, we proposed tooth instance correlation and triple loss to improve the recognition performance of calcification. Finally, we built a multi-task learning architecture based on Transformer to realize the tooth segmentation, identification and calcification recognition for mutual promotion between tasks. The clinical data verified the effectiveness of the proposed method for the recognition of pulp calcification in high-resolution CBCT for digital dentistry.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Pulp calcification is a type of pulp degeneration, characterized by the deposition of calcified tissue in the root canal. Clinically, pulp calcification usually occurs with pulp periapical diseases, which brings great challenges to root canal therapy. Finding pulp calcification before root canal treatment is very important for dentists to decide treatment strategies <ref type="bibr" target="#b0">[1]</ref>. However, teeth with pulp calcification usually show few clinical symptoms, which are mainly found and diagnosed by radiographic examination. Compared with X-ray, cone beam computed tomography (CBCT) performs better in displaying root canal structure and pulp disease, so it is widely used for pulp calcification detection <ref type="bibr" target="#b1">[2]</ref>. On CBCT images, pulp calcification showed partial or complete high attenuation root canal occlusion as shown in Fig. <ref type="figure" target="#fig_0">1</ref>. Currently, the diagnosis of pulp calcification mainly depends on the image recognition of root canal occlusion by dentists. On the one hand, although high-resolution CBCT is used, the image contrast of calcified area is rather low, and human cannot easily find all calcified tubes. On the other hand, human recognition is time-consuming and laborious, and the agreement between observers is far from satisfactory. Therefore, an intelligent recognition method of pulp calcification is urgently needed for digital dentistry in clinical practice. With the introduction of artificial intelligence into various fields of medical images, research has proposed tooth and root canal segmentation models based on deep learning networks and CBCT images <ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref>, which have achieved good performance in segmentation. However, how to intelligently recognize pulp calcification in small root canals is still very difficult and has not yet been explored. First, the calcified area has no clear morphological characteristics and is difficult for feature representation. Then, the resolution of CBCT image has a high resolution (672 × 688 × 688 in this work), while the tooth calcification areas are relatively small and in low contrast. It is very difficult to directly process such large volume data based on deep learning networks. Reducing the high-resolution of CBCT image will weaken the local tooth calcification area information, which brings certain challenges to the intelligent recognition of pulp calcification in CBCT. In addition, the current digital dentistry needs the whole process from 3D volume input, tooth segmentation, identification, and lesion recognition. However, the current relevant research <ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref> separately focuses on functions such as tooth segmentation, root canal segmentation or lesion detection, and has not yet built an integrated intelligent diagnosis process.</p><p>To this end, we propose a new method of tooth segmentation, identification and pulp calcification recognition based on Transformer to achieve accurate recognition of pulp calcification in high-resolution CBCT images. Specifically, we propose a coarse-to-fine method to segment the tooth instance in the low-resolution CBCT image, and back to the high-resolution CBCT image to intercept the region of the tooth as the input for the fine segmentation, identification and calcification recognition of the tooth instance. In order to enhance the weak distinction between normal teeth and calcified teeth, we put forward tooth instance correlation and triple loss to further improve the recognition performance of calcification. Finally, we introduce transformer to realize the above three tasks in an integrated way, and achieve mutual promotion of task performance. The clinical oral CBCT image data is used to verify the effectiveness of the proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Proposed Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The Proposed Framework</head><p>The network structure designed in this work is shown in Fig. <ref type="figure">2</ref>. It mainly includes two modules: tooth segmentation and identification module, and pulp calcification recognition module. First, we stack the swin-transformer as the backbone of the network, and save the computation of processing high-resolution CBCT images through down-sampling. Then, we introduce shallower features through skip connection. Those features with higher resolution and shallower layers will contain relatively rich low-level information, which is more conducive to accurate tooth segmentation and identification recognition. In addition, through the multi-task learning mechanism based on Transformer, the performance of tooth segmentation, identification and calcification recognition can be mutually improved.</p><p>In the pulp calcification recognition module, we extract the features of each tooth from the deep feature through the results of tooth segmentation, and input them into the pulp calcification recognition module. Specifically, we design an instance correlation transformer (ICT) block. This block allows teeth to learn information from other teeth, so that different teeth can interact, which enables the network itself to explore the relationship between instances, thus improving the recognition performance of calcified teeth. In addition, we introduce a discriminator in the ICT block, which uses triple loss to learn the spatial distribution between categories, so as to learn better classification embedding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Tooth Segmentation and Identification Module</head><p>In order to obtain the features of each tooth from the high-resolution CBCT image, we first recognize the segmented and identificated teeth,and combine the result of them for tooth instance segmentation. We use swin-transformer as the network backbone. Swin-transformer <ref type="bibr" target="#b7">[8]</ref> is based on the idea of ViT model, which innovatively introduces the sliding window mechanism, so that the model can learn cross-window information. Meanwhile, through the down-sampling layer, the model can process super-resolution images, save computation and focus on global and local information. In addition, it has been proved to have advantages in the process of modeling an end-to-end multi-task system <ref type="bibr" target="#b8">[9]</ref>. Unlike the typical swin-transformer, which only uses the Patch Merging layer in the deep layer, we first reduce the resolution of the input feature map through the Patch Merging layer in each stage, and then conduct the next sampling operation. This is conducive to our processing of high-resolution CBCT images. In addition, we have adopted the reverse skip connection (RSC). The information from the deep layer can reversely guide the learning of the shallow details to achieve better segmentation effect, which has been proved effective in segmentation task <ref type="bibr" target="#b9">[10]</ref>. In this way, we can distinguish the edges of adjacent teeth more clearly, thus promoting better segmentation recognition.</p><p>The segmentation loss L seg of the model can be defined as L seg = L cs + γ 1 L dice + γ 2 L bs , where γ 1 ,γ 2 are the balance parameters, where L cs is the 33 categories of pixels (32 teeth classes + background) cross entropy loss. L dice is the dice loss of each tooth instance segmentation. L bs is binary segmentation. We calculate the cross entropy loss between teeth and background. The purpose of this step is to assist the model to distinguish foreground and background Calcified root canals, especially small root canal calcification, are shown on CBCT images as the shadow in the center of the cross section faded and disappeared, and the density of the shadow is close to or the same as that of the surrounding dentin, which is significantly different from the root canal images of other root canals of the same affected tooth and normal adjacent teeth. Based on the above clinical observation, we design the tooth instance correlation block for better calcification recognition. The multi-head attention layer is widely used to build image relationship models in channel and spatial dimensions <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>, so we believe it can be extended to explore the relationship between tooth instances. Specifically, we propose an ICT related to tooth instances to better identify calcified teeth. The ICT module is shown in Fig. <ref type="figure">3</ref>. First, in the input module of ICT, we extract the tooth deep feature from the output feature of the encoder through the prediction of instance segmentation. The specific method is to extract the tooth deep feature one by one according to the tooth id after the prediction label is de-sampled. We splice the extracted tooth instance features in a new dimension I. Then, we reduce the channel dimension to C/16 by convolution operation for this high-dimensional feature (dimensions <ref type="figure">: (B,</ref><ref type="figure">C,</ref><ref type="figure">I,</ref><ref type="figure">D,</ref><ref type="figure">H,</ref><ref type="figure">W</ref>)). The purpose of this step is to reduce the heavy calculation caused by the excessive size of the channel dimension. Then, we divide the reshape into (B, C, I, N), where B is the batch size, I is the number of tooth samples, C and N are the number of channels and pixels, respectively. Through the tooth instance correlation block, we learn the cross attention in the I dimension. Given a CBCT image X i contains multiple tooth instances x i,1 ,x i,2 ,...,x i,n . The tooth instance correlation block is constructed as follows:</p><formula xml:id="formula_0">X 0 i = (x i,class ; f (x i,1 ); f (x i,2 ); ...; f (x i,n )), X 0 i ∈ R(n + 1) × d (<label>1</label></formula><formula xml:id="formula_1">)</formula><formula xml:id="formula_2">X l i = MSA(LN (X l-1 i )) + X l-1 i , l = 1....L<label>(2)</label></formula><formula xml:id="formula_3">X l i = LN (MLP (X l i )) + X l i (<label>3</label></formula><formula xml:id="formula_4">)</formula><p>where MSA is multi-head self attention, L is the layer of MSA, and LN is the standardization layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Triple Loss and Total Loss Function</head><p>In order to make the model more discriminative for the recognition of calcified teeth, a discriminator is designed in this work, which uses triplet loss to make the embedding of the input classifier more discriminative. This process is to make the features of the same category as close as possible, and the features of different categories as far away as possible. Meanwhile, in order to prevent the features of the instance from converging into a very small space, it is required that for two positive cases and one negative case, the negative case should be at least margin away from the positive case <ref type="bibr" target="#b12">[13]</ref>. Specifically, we randomly selected an instance in the I dimension: Anchor (a), and randomly selected an instance that belongs to the same class as Anchor: Positive (p), and randomly selected an instance that belongs to a different class from Anchor: Negative (n). The goal of model learning is to make the distance D(a, p) between Positive and Anchor as small as possible, and the distance D(a, n) between Negative and Anchor as large as possible L t . It is defined as follows:</p><formula xml:id="formula_5">L t = max(D(a, p) -D(a, n) + α), 0)<label>(4)</label></formula><p>where D is the European distance, α is a margin between positive and negative pairs. The classification loss is defined as L cls = L pc + γ 3 L t , where γ 3 is the balance parameter, L pc is the cross entropy loss as the loss of calcified tooth classification. Finally, the total loss function of the network is defined as L total = L seg + L cls .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Implementation</head><p>The initialization setting of the learning rate is 1e-3, with 60000 iterations. The Adam algorithm is used to minimize the objective function. Two RTX3090 GPUs are used, each with 24G memory. The attenuation setting of the learning rate is 0.99 for every 500 iterations. All parameters, including weights and deviations, are initialized using a truncated normal distribution with a standard deviation of 0.1. In the tooth instance segmentation task, we use connected component analysis to extract the maximum area of predicted voxels and remove some small false-positive voxels. Code is available at: https://github.com/Lsx0802/ ToothICT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Clinical Data, Experimental Setup and Evaluation Metric</head><p>This study was performed in line with the principles of the Declaration of Helsinki. In this work, 151 CBCT imaging data from the Imaging department of the local institute were acquired. The image resolution of the CBCT equipment used was 0.2 ∼ 1.0 mm, and the size of the CBCT volume is 672 × 688 × 688. The bulb voltage was 60 ∼ 90 kV, and the bulb current was 1 ∼ 10 mA. 151 cases of dental symptoms were identified as CBCT oral indications by two dentists with 10 years of clinical experience. Among them, 60 patients had dental pulp calcification. In addition, each tooth was also marked for calcification. One dentist is responsible for the data label, and two doctors review it. When they disagree, they will reach an agreement through negotiation.</p><p>The CBCT data is preprocessed as follows. First, considering the balance between computational efficiency and instance segmentation accuracy, all CBCT images are normalized to 0.4 × 0.4 × 0.4 mm 3 . Then, in order to reduce the impact of extreme values, especially in the metal artifact area, we cut the voxellevel intensity value of each CBCT scan to [0, 2500], and finally normalized the pixel value to the interval [0,1]. For Pulp calcification recognitionin, the adopted evaluation metrics include: Accuracy, Precision, Recall, F1, Dice. The measurement results were conducted with 10 times of four-fold cross validation. In addition, we have compared the performance of the proposed method with the relevant tooth segmentation methods, we used typical segmentation metrics for performance evaluation: Dice, Jaccard similarity coefficient (Jaccard), 95% Hausdorff distance (HD95), Average surface distance (ASD) and have conducted the ablation study of the proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Performance Evaluation</head><p>As shown in Table <ref type="table" target="#tab_0">1</ref>, Dice is based on the instance segmentation performance of each tooth. Backbone1 uses the swin transformer with skip connection to segment the teeth. w/o RSC is a model for eliminating reverse skip connection design. The segmentation results of tooth instance show that the proposed method is superior to other relevant segmentation methods. The main reason is that the proposed method uses the transformer structure. Its multi-head attention mechanism can capture global information, which is superior to the U-net structure based on CNN local features in the relevant methods. In addition, the ablation study for instance segmentation also shows the effectiveness of the proposed module.</p><p>Our model adopts a network based on swin transformer. Through its powerful global and local modeling ability, while retaining the jumping connection in UNet to retain the shallow features, the performance of Backbone1 is better than the previous segmentation model. In particular, we use reverse skip connection and use deep features to guide shallow feature learning, which has achieved obvious improvement in segmentation performance. After combining the task of calcification classification, the segmentation network has been improved a little, which benefits from the ICT module we adopted, because it not only learns the correlation characteristics between calcified teeth and normal teeth, but also learns the morphological correlation between teeth, which is beneficial to tooth segmentation.</p><p>Table <ref type="table" target="#tab_1">2</ref> shows the ablation experimental results of calcified tooth recognition. Backbone 2 is the calcified tooth recognition of the whole module of tooth instance segmentation+classifier. w/o ICT is to remove the tooth instance correlation block, and w/o L t is to remove the discriminator. We can find that the proposed two modules can effectively improve the performance of calcification recognition.</p><p>The accuracy of the model is only 74.62% when only swin transformer is used to classify tooth samples, while our proposed model can improve the performance of pulp calcification recognition by 3.85%. Especially, in the ablation experiment, when the ICT module is removed, the model performance drops obviously, which proves that our proposed ICT module can effectively learn the relationship between dental examples. In addition, after the loss Lt of the discriminant module is removed, the accuracy of the model decreases by about 1.16%, which proves that this method can effectively reduce the distance between similar samples and increase the distance between different samples. (See the supplementary materials for more visualization results) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this study, we proposed a calcified tooth recognition method based on transformer, which can detect calcified teeth in high-resolution CBCT images while achieving tooth instance segmentation and identification. Specifically, we proposed a coarse-to-fine processing method to make it possible to process highresolution CBCT with deep network for calcification recognition. In addition, the design of instance correlation and triple loss further improved the accuracy of calcification detection. The validation of clinical data showed the effectiveness and advantages of the proposed method. We believe that this research will bring help to the intellectualization of oral imaging diagnosis and the navigation of oral surgery.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Representative tooth images in CBCT. (a) Normal teeth; (b) Diffuse calcified teeth with a few root canal residues; (c) Calcified teeth with pulpal stones; (d) Calcified teeth with difficulty in recognition. The red box corresponds to the pulp area. (Color figure online)</figDesc><graphic coords="2,55,98,347,18,340,12,91,66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .Fig. 3 .</head><label>23</label><figDesc>Fig. 2. The proposed framework. The orange arrow indicates the RSC process. (Color figure online)</figDesc><graphic coords="4,56,46,424,67,339,55,119,62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Performance comparison of instance segmentatio) ToothNet [4] 90.84 ± 1.10 82.67 ± 1.59 3.13 ± 1.31 0.36 ± 0.17 CGDNet [5] 92.07 ± 0.91 84.93 ± 1.34 2.61 ± 1.011 0.31 ± 0.13 ToothSeg [6] 92.68 ± 0.86 87.39 ± 0.88 2.13 ± 0.47 0.27 ± 0.11</figDesc><table><row><cell>Method</cell><cell cols="2">Dice (%) ↑ Jaccard (%) ↑ HD95 ↓</cell><cell>ASD ↓</cell></row><row><cell>Backbone1</cell><cell>93.90 ± 0.51 88.67 ± 0.82</cell><cell cols="2">1.66 ± 0.26 0.25 ± 0.09</cell></row><row><cell>w/o RSC</cell><cell>93.99 ± 0.46 88.77 ± 0.93</cell><cell cols="2">1.72 ± 0.31 0.25 ± 0.05</cell></row><row><cell>Proposed</cell><cell>94.23 ± 0.61 89.64 ± 0.86</cell><cell cols="2">1.50 ± 0.27 0.23 ± 0.06</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Performance of pulp calcification recognitionMethodAccuracy (%) ↑ Precision (%) ↑ Recall (%) ↑ F1 (%) ↑</figDesc><table><row><cell cols="2">Backbone2 74.62 ± 0.41</cell><cell>72.67 ± 0.34</cell><cell>77.31 ± 0.43 76.79 ± 0.37</cell></row><row><cell>w/o ICT</cell><cell>75.31 ± 0.29</cell><cell>74.48 ± 0.36</cell><cell>78.13 ± 0.31 78.31 ± 0.33</cell></row><row><cell>w/o Lt</cell><cell>77.31 ± 0.36</cell><cell>75,81 ± 0.27</cell><cell>82.06 ± 0.27 81.15 ± 0.41</cell></row><row><cell cols="2">Proposed 78.47 ± 0.25</cell><cell>77.31 ± 0.37</cell><cell>82.08 ± 0.23 82.41 ± 0.32</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement. This research is supported by the school-enterprise cooperation project (No.<rs type="grantNumber">6401-222-127-001</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_b68TpnN">
					<idno type="grant-number">6401-222-127-001</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">CBCT-aided microscopic and ultrasonic treatment for upper or middle thirds calcified root canals</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">M</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BioMed Res. Int</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Cone beam computed tomography in endodontics -a review of the literature</title>
		<author>
			<persName><forename type="first">S</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pimental</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Abella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Durack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. Endodont. J</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Refined tooth and pulp segmentation using u-net in CBCT image</title>
		<author>
			<persName><forename type="first">W</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dentomaxillofacial Radiol</title>
		<imprint>
			<biblScope unit="page">20200251</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Toothnet: automatic tooth instance segmentation and identification from cone beam CT images</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Long Beach</addrLine></address></meeting>
		<imprint>
			<publisher>Computer Vision Foundation/IEEE</publisher>
			<date type="published" when="2019-06">2019. 16-20 June 2019. 2019</date>
			<biblScope unit="page" from="6368" to="6377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Center-sensitive and boundary-aware tooth instance segmentation and classification from cone-beam CT</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="939" to="942" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hierarchical morphology-guided tooth instance segmentation from CBCT images</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-78191-0_12</idno>
		<idno>978-3-030-78191-0_12</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">IPMI 2021</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Feragen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Sommer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Schnabel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Nielsen</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12729</biblScope>
			<biblScope unit="page" from="150" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A fully automatic AI system for tooth and alveolar bone segmentation from cone-beam CT images</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">2096</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Swin transformer: hierarchical vision transformer using shifted windows</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="10012" to="10022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Mult: an end-to-end multitask learning transformer</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Süsstrunk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="12031" to="12041" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">3d vessel-like structure segmentation in medical images by an edgereinforced network</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page">102581</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Transmil: transformer based correlated multiple instance learning for whole slide image classification</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="2136" to="2147" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Batchformer: learning to explore sample relationships for robust representation learning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="7256" to="7266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Hermans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Leibe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.07737</idno>
		<title level="m">defense of the triplet loss for person reidentification</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
