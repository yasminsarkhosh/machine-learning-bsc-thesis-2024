Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images Hyeonsoo Lee(B), Junha Kim, Eunkyung Park, Minjeong Kim, Taesoo Kim, and Thijs Kooi Lunit Inc., Seoul, Republic of Korea {hslee,junha.kim,ekpark,mjkim0918,taesoo.kim,tkooi}@lunit.io Abstract. Recently, deep learning models have shown the potential to predict breast cancer risk and enable targeted screening strategies, but current models do not consider the change in the breast over time. In this paper, we present a new method, PRIME+, for breast cancer risk prediction that leverages prior mammograms using a transformer decoder, outperforming a state-of-the-art risk prediction method that only uses mammograms from a single time point. We validate our approach on a dataset with 16,113 exams and further demonstrate that it eﬀectively captures patterns of changes from prior mammograms, such as changes in breast density, resulting in improved short-term and long-term breast cancer risk prediction. Experimental results show that our model achieves a statistically signiﬁcant improvement in performance over the state-ofthe-art based model, with a C-index increase from 0.68 to 0.73 (p < 0.05) on held-out test sets. Keywords: Breast Cancer · Mammogram · Risk Prediction 1 Introduction Breast cancer impacts women globally [15] and mammographic screening for women over a certain age has been shown to reduce mortality [7,10,23]. However, studies suggest that mammography alone has limited sensitivity [22]. To mitigate this, supplemental screening like MRI or a tailored screening interval have been explored to add to the screening protocol [1,13]. However, these imaging techniques are expensive and add additional burdens for the patient. Recently, several studies [8,32,33] revealed the potential of artiﬁcial intelligence (AI) to develop a better risk assessment model to identify women who may beneﬁt from supplemental screening or a personalized screening interval and these may lead to improved screening outcomes. In clinical practice, breast density and traditional statistical methods for predicting breast cancer risks such as the Gail [14] and the Tyrer-Cuzick models [27] have been used to estimate an individual’s risk of developing breast cancer. However, these models do not perform well enough to be utilized in practical screening settings [3] and require the collection of data that is not always available. Recently, deep neural network based models that predict a patient’s risk score c The Author(s), under exclusive license to Springer Nature Switzerland AG 2023 H. Greenspan et al. (Eds.): MICCAI 2023, LNCS 14224, pp. 389–398, 2023. https://doi.org/10.1007/978-3-031-43904-9_38 directly from mammograms have shown promising results [3,8,9,20,33]. These models do not require additional patient information and have been shown to outperform traditional statistical models. When prior mammograms are available, radiologists compare prior exams to the current mammogram to aid in the detection of breast cancer. Several studies have shown that utilizing past mammograms can improve the classiﬁcation performance of radiologists in the classiﬁcation of benign and malignant masses [11,25,26,29], especially for the detection of subtle abnormalities [25]. More recently, deep learning models trained on both prior and current mammograms have shown improved performance in breast cancer classiﬁcation tasks [24]. Integrating prior mammograms into deep learning models for breast cancer risk prediction can provide a more comprehensive evaluation of a patient’s breast health. In this paper, we introduce a deep neural network that makes use of prior mammograms, to assess a patient’s risk of developing breast cancer, dubbed PRIME+ (PRIor Mammogram Enabled risk prediction). We hypothesize that mammographic parenchymal pattern changes between current and prior allow the model to better assess a patient’s risk. Our method is based on a transformer model that uses attention [30], similar to how radiologists would compare current and prior mammograms. The method is trained and evaluated on a large and diverse dataset of over 9,000 patients and shown to outperform a model based on state-of-the art risk prediction techniques for mammography [33]. Although previous models such as LRP-NET and RADIFUSION [5,34] have utilized prior mammograms, PRIME+ sets itself apart by employing an attention mechanism to extract information about the prior scan. 2 Method 2.1 Risk Prediction Survival analysis is done to predict whether events will occur sometime in the future. The data comprises three main elements: features x, time of the event t, and the occurrence of the event e [18]. For medical applications, x typically represents patient information like age, family history, genetic makeup, and diagnostic test results (e.g., a mammogram). If the event has not yet occurred by the end of the study or observation period, the data is referred to as right-censored (Fig.1). We typically want to estimate the hazard function h(t), which measures the rate at which patients experience the event of interest at time t, given that they have survived up to that point. The hazard function can be expressed as the limit of the conditional probability of an event T occurring within a small time interval [t, t + Δt), given that the event has not yet occurred by time t: P (T ∈ [t, t + Δt) | T ≥ t)h(t) = lim (1)Δt→0 Δt Fig. 1. We present an improved method for breast cancer risk prediction (PRIME+)by leveraging prior mammograms. A common backbone network extracts features from the prior and current images, resulting in xprior and xcurr. We ﬁnd that the transformer decoder eﬀectively fuses relevant information from xprior and xcurr to produce xCPC . The base hazard θb and time-dependent hazard prediction heads θu use the concatenated feature to predict the cumulative hazard function Hˆ . (a) illustrates the interaction between xprior and xcurr in the cross-attention module of the transformer decoder. The cumulative hazard function H(t) is another commonly used function in survival analysis, which gives the accumulated probability of experiencing the event of interest up to time t. This function is obtained by integrating the hazard &#2; tfunction over time from 0 to t: H(t)= h(s)ds.0 2.2 Architecture Overview We build on the current state-of-the art MIRAI [33] architecture, which is trained to predict the cumulative hazard function. We use an ImageNet pretrained ResNet-34 [12] as the image feature backbone. The backbone network extracts features from the mammograms, and the fully connected layer produces the ﬁnal feature vector x. We make use of two additional fully connected layers to calculate base hazard θb and time-dependent hazard θu, respectively. The predicted cumulative hazard is obtained by adding the base hazard and time-dependent hazard, according to: t ˆH(t|x)=θb(x)+&#3; θuτ (x) (2) τ=1 When dealing with right-censored data, we use an indicator function δi(t)to determine whether the information for sample i at time t should be included in the loss calculation or not. This helps us exclude unknown periods and only use the available information. It is deﬁned as follows: δi(t)= ⎧⎪⎨ ⎪⎩ 1, if the event of interest occurs for sample i(ei =1) 1, if sample iis right-censored at time t(ei =0 and t<Ci) (3) 0, otherwise Here, ei is a binary variable indicating whether the event of interest occurs for sample i(i.e., ei =1) or not (i.e., ei =0), and Ci is the censoring time for sample i, which is the last known time when the sample was cancer-free. We deﬁne the ground-truth His a binary vector of length Tmax,where Tmax is the maximum observation period. Speciﬁcally, H(t) is 1 if the patient is diagnosed with cancer within tyears and 0 otherwise. We use binary cross entropy to calculate the loss at time t for sample i: i(t)= −Hi(t) log Hˆ i(t) − (1 − Hi(t)) log(1 − Hˆi(t)). The total loss is deﬁned as: L= N Tmax δi(t)i(t) (4) i=1 t=1 Here, N is the number of exams in the training set. The goal of training the model is to minimize this loss function, which encourages the model to make accurate predictions of the risk of developing breast cancer over time. 2.3 Incorporating Prior Mammograms To improve the performance of the breast cancer risk prediction model, we incorporate information from prior mammograms taken with the same view, using a transformer decoder structure [30]. This structure allows the current and prior mammogram features to interact with each other, similar to how radiologists check for changes between current and prior mammograms. During training, we randomly select one prior mammogram, regardless of when they were taken. This allows the model to generalize to varying time intervals. To pair each current mammogram during inference with the most relevant prior mammogram, we ﬁrst select the prior mammogram taken at the time closest to the current time. This approach is based on research showing that radiologists often use the closest prior mammogram to aid in the detection of breast cancer [26]. Next, a shared backbone network is used to output the current feature xcurr and the prior feature xprior. These features are then ﬂattened and fed as input to the transformer decoder, where multi-head attention is used to ﬁnd information related to the current feature in the prior feature. The resulting output is concatenated and passed through a linear layer to produce the current-prior comparison feature xCPC . The current-prior comparison feature and current fea∗ture are concatenated to produce the ﬁnal feature x = xCPC ⊕ xcurr,which is then used by the base hazard network and time-dependent hazard network to predict the cumulative hazard function Hˆ . 3 Experiments 3.1 Dataset We compiled an in-house mammography dataset comprising 16,113 exams (64,452 images) from 9,113 patients across institutions from the United States, gathered between 2010 and 2021. Each mammogram includes at least one prior mammogram. The dataset has 3,625 biopsy-proven cancer exams, 5,394 biopsyproven benign exams, and 7,094 normal exams. Mammograms were captured using Hologic (72.3%) and Siemens (27.7%) devices. We partitioned the dataset by patient to create training, validation, and test sets. The validation set contains 800 exams (198 cancer, 210 benign, 392 normal) from 400 patients, and the test set contains 1,200 exams (302 cancer, 290 benign, 608 normal) from 600 patients. All data was de-identiﬁed according to the U.S HHS Safe Harbor Method. Therefore, the data has no PHI (Protected Health Information) and IRB (Institutional Review Board) approval is not required. 3.2 Evaluation We make use of Uno’s C-index [28] and the time-dependent AUC [16]. The C-index measures the performance of a model by evaluating how well it correctly predicts the relative order of survival times for pairs of individuals in the dataset. The C-index ranges from 0 to 1, with a value of 0.5 indicating random predictions and a value of 1 indicating that the model is perfect. Time-dependent ROC analysis generates an ROC curve and the area under the curve (AUC) for each speciﬁc time point in the follow-up period, enabling evaluation of the model’s performance over time. To compare the C-index of two models, we employ the compareC [17] test, and make use of the DeLong test [6] to compare the timedependent AUC values. Conﬁdence bounds are generated using bootstrapping with 1,000 bootstrap samples. We evaluate the eﬀectiveness of PRIME+ by comparing it with two other models: (1) baseline based on MIRAI, a state-of-the art risk prediction method from [33], and (2) PRIME, a model that uses prior images by simply summing xcurr and xprior without the use of the transformer decoder. 3.3 Implementation Details Our model is implemented in Pytorch and trained on four V100 GPUs. We trained the model using stochastic gradient descent (SGD) for 20K iterations with a learning rate of 0.005, weight decay of 0.0001, and momentum of 0.9. We use a cosine annealing learning rate scheduling strategy [21]. We resize the images to 960 × 640 pixels and use a batch size of 96. To augment the training data, we apply geometric transformations such as vertical ﬂipping, rotation and photometric transformations such as brightness/contrast adjustment, Gaussian noise, sharpen, CLAHE, and solarize. Empirically, we ﬁnd that strong photometric augmentations improved the risk prediction model’s Table 1. Ablation analysis on the eﬀectiveness of prior information and transformer decoder. Additional result in bottom row aims to predict unseen risks beyond visible cancer patterns by excluding early diagnosed cancer cases. The ± refers to the 95% conﬁdence bound. All Cases Prior  Decoder  C-index  Time-dependent AUC  1-year  2-year  3-year  4-year  ✗ ✓ ✓  ✗ ✗ ✓  0.68±0.03 0.70±0.03 0.73±0.03  0.70±0.05 0.72±0.05 0.75±0.05  0.71±0.04 0.73±0.05 0.75±0.04  0.70±0.04 0.74±0.04 0.77±0.04  0.71±0.09 0.75±0.07 0.76±0.08  Excluding Cancer Cases with Event Time < 180 Days Prior  Decoder  C-index  Time-dependent AUC  1-year  2-year  3-year  4-year  ✗ ✓ ✓  ✗ ✗ ✓  0.63±0.04 0.68±0.05 0.70±0.04  0.64±0.10 0.64±0.14 0.68±0.13  0.66±0.08 0.73±0.08 0.76±0.07  0.64±0.06 0.70±0.05 0.73±0.05  0.64±0.11 0.71±0.09 0.71±0.10  performance, while strong geometric transformations had a negative impact. This is consistent with prior work [20] showing that risk prediction models focus on overall parenchymal pattern. 3.4 Results Ablation Study. To better understand the merit of the transformer decoder, we ﬁrst performed an ablation study on the architecture. Our ﬁndings, summarized in Table 1, include two sets of results: one for all exams in the test set and the other by excluding cancer exams within 180 days of cancer diagnosis which are likely to have visible symptoms of cancer, by following a previous study [33]. This latter set of results is particularly relevant as risk prediction aims to predict unseen risks beyond visible cancer patterns. We also compare our method to two other models, the state-of-the-art baseline and PRIME models. As shown in the top rows in Table 1, the baseline obtained a C-index of 0.68 (0.65 to 0.71). By using the transformer decoder to jointly model prior images, we observed improved C-index from 0.70 (0.67 to 0.73) to 0.73 (0.70 to 0.76). The C-index as well as all AUC diﬀerences between the baseline and the PRIME+ are all statistically signiﬁcant (p < 0.05) except the 4-year AUC where we had a limited number of test cases. We observe similar performance improvements when evaluating cases with at least 180 days to cancer diagnosis. Interestingly, the C-index as well as timedependent AUCs of all three methods decreased compared to when evaluating using all cases. The intuition behind this result is that mammograms taken near the cancer diagnosis (<180 days) likely contain visible signs of cancer and thus the task of risk prediction is easier. The model must learn patterns of risk, not Table 2. To better understand why the addition of prior images works, we split our test set into two groups based on the mammographic density: change and no change. The ﬁrst and second row corresponds to performance of the baseline and PRIME+ model, respectively. Empty cell indicates an insuﬃcient number of cases available for evaluation. Density chg  C-index  Time-dependent AUC  1-year  2-year  3-year  4-year  Change  0.63±0.14 0.75±0.10  0.74±0.17 0.82±0.13  0.66±0.18 0.76±0.14  0.56±0.16 0.74±0.14  -- No change  0.69±0.03 0.73±0.03  0.70±0.05 0.74±0.05  0.72±0.05 0.75±0.05  0.72±0.04 0.77±0.04  0.71±0.09 0.76±0.08  visible signs of cancer, in order to perform well under this evaluation setting. Our results support this intuition as the performance improvements over the baseline are much more pronounced for longer term risk (3, 4-year AUC) than short term risk (1year). The PRIME and PRIME+ models, which incorporate prior mammograms, show high performance for long-term risk prediction (3, 4-year AUC), indicating that considering changes in breast over time contain useful information for breast cancer risk prediction. Lastly, we empirically conﬁrm that a transformer decoder eﬀectively models spatial relations between prior and current mammograms by demonstrating consistent performance improvements of PRIME+ across both short-term and longterm risk prediction settings. Our results suggest that incorporating changes in patients using prior mammograms and a transformer decoder improves the performance of breast cancer risk prediction models. Analysis Based on Density. To better understand why adding prior images improves performance, we divided our test set into subgroups to examine the performance of the baseline model and the PRIME+ modeloneachofthese groups. Mammographic breast density is one of the most important risk factor to predict breast cancer [19,31]. Women with dense breasts have a four-to six-fold higher risk of breast cancer [2]. The addition of mammographic breast density has improved the performance traditional breast cancer risk models [4]and can therefore help us understand why the addition of prior images works. Mammographic breast density was determined using the Breast Imaging Reporting and Data System (BI-RADS) composition classiﬁcation. BI-RADS category A, B are deﬁned as fatty breasts and BI-RADS category C, D are classiﬁed as dense breasts. To determine the density category, we employed an internally developed density prediction model, as most exams lack BI-RADS ground truth. This model achieved an accuracy of 0.81 on the internal density validation set. We categorized the exams into two groups based on changes in density: “change” and “no change”. Density change was deﬁned according to whether the BI-RADS category changed in the current image as compared to the prior Table 3. In order to assess the performance of the models on varying levels of breast density, a critical risk factor, we divided our test set into two groups based on mammographic density: fatty and dense. Density  C-index  Time-dependent AUC  1-year  2-year  3-year  4-year  Fatty  0.70±0.04 0.74±0.04  0.73±0.06 0.76±0.06  0.74±0.05 0.76±0.05  0.70±0.05 0.78±0.05  0.70±0.10 0.76±0.08  Dense  0.68±0.06 0.71±0.05  0.66±0.09 0.72±0.08  0.68±0.09 0.73±0.08  0.71±0.08 0.72±0.08  0.65±0.21 0.72±0.25  image. As shown in Table 2, the baseline model performs poorly for “change”, with a C-index of 0.63 (0.49 to 0.77), especially for long-term risk prediction, with 3-year AUC of 0.56 (0.40 to 0.72). This suggests that the baseline model has limitations in accurately predicting long-term risk when there is a density change from the prior exam. However, PRIME+ is able to predict long-term risk accurately even when a density change has occurred (3-year AUC = 0.74 (0.60 to 0.88)), by learning to refer previous exams properly. This demonstrates the potential usefulness of incorporating past mammogram information into breast cancer risk prediction models. Thus, we believe that incorporating prior exams is important to identify changes in texture which are important for long term risk prediction (Table 3). Lastly, we divided the exams based on the level of breast density, with a fatty group consisting of density A and B, and a dense group consisting of density C and D. Both the baseline and PRIME+ performs better in fatty group than dense group. We suspect this is because deep neural networks generally work better on low density images given that visual cues of cancer in images with lower breast density are more clearly visible. 4 Conclusion In this paper, we introduce a novel breast cancer risk prediction method, PRIME+, which incorporates prior mammograms with a transformer decoder to capture changes in breast tissue over time. By doing so, we achieve high performance for both short-term and long-term risk prediction. Our extensive experiments on a dataset of 16,113 exams show that PRIME+ outperformed a model based on the state-of-the-art for breast cancer risk prediction [33]. Our method performed particularly well in cases where there was a change in breast density from the previous exam. We believe that our method has the potential to improve breast cancer risk prediction and ultimately contribute to earlier detection of the disease. References 1. Bakker, M.F., et al.: Supplemental MRI screening for women with extremely dense breast tissue. N. Engl. J. Med. 381(22), 2091–2102 (2019) 2. Boyd, N.F.: Mammographic density and risk of breast cancer. Am. Soc. Clin. Oncol. Educ. Book 33(1), e57–e62 (2013) 3. Brentnall, A.R., Cuzick, J.: Risk models for breast cancer and their validation. Stat. Sci. Rev. J. Inst. Math. Stat. 35(1), 14 (2020) 4. Brentnall, A.R., et al.: Mammographic density adds accuracy to both the Tyrer-Cuzick and Gail breast cancer risk models in a prospective UK screening cohort. Breast Cancer Res. 17, 1–10 (2015) 5. Dadsetan, S., Arefan, D., Berg, W.A., Zuley, M.L., Sumkin, J.H., Wu, S.: Deep learning of longitudinal mammogram examinations for breast cancer risk prediction. Pattern Recogn. 132, 108919 (2022) 6. DeLong, E.R., DeLong, D.M., Clarke-Pearson, D.L.: Comparing the areas under two or more correlated receiver operating characteristic curves: a nonparametric approach. Biometrics, 837–845 (1988) 7. Duﬀy, S.W., et al.: Eﬀect of mammographic screening from age 40 years on breast cancer mortality (UK age trial): ﬁnal results of a randomised, controlled trial. Lancet Oncol. 21(9), 1165–1172 (2020) 8. Eriksson, M., et al.: A risk model for digital breast tomosynthesis to predict breast cancer and guide clinical care. Sci. Transl. Med. 14(644), eabn3971 (2022) 9. Gastounioti, A., Desai, S., Ahluwalia, V.S., Conant, E.F., Kontos, D.: Artiﬁcial intelligence in mammographic phenotyping of breast cancer risk: a narrative review. Breast Cancer Res. 24(1), 1–12 (2022) 10. Hakama, M., Coleman, M.P., Alexe, D.M., Auvinen, A.: Cancer screening: evidence and practice in Europe 2008. Eur. J. Cancer 44(10), 1404–1413 (2008) 11. Hayward, J.H., et al.: Improving screening mammography outcomes through comparison with multiple prior mammograms. AJR Am. J. Roentgenol. 207(4), 918 (2016) 12. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770–778 (2016) 13. Hussein, H., et al.: Supplemental breast cancer screening in women with dense breasts and negative mammography: a systematic review and meta-analysis. Radiology 306(3), e221785 (2023) 14. National Cancer Institute: Breast cancer risk assessment tool (2011). https://www. cancer.gov/bcrisktool/. Accessed 13 Aug 2017 15. World Cancer Research Fund International: Breast cancer statistics. https://www. wcrf.org/cancer-trends/breast-cancer-statistics/ 16. Kamarudin, A.N., Cox, T., Kolamunnage-Dona, R.: Time-dependent ROC curve analysis in medical research: current methods and applications. BMC Med. Res. Methodol. 17(1), 1–19 (2017) 17. Kang, L., Chen, W., Petrick, N.A., Gallas, B.D.: Comparing two correlated C indices with right-censored survival outcome: a one-shot nonparametric approach. Stat. Med. 34(4), 685–703 (2015) 18. Katzman, J.L., Shaham, U., Cloninger, A., Bates, J., Jiang, T., Kluger, Y.: Deep-Surv: personalized treatment recommender system using a Cox proportional hazards deep neural network. BMC Med. Res. Methodol. 18(1), 1–12 (2018) 19. Lee, C.I., Chen, L.E., Elmore, J.G.: Risk-based breast cancer screening: implications of breast density. Med. Clin. 101(4), 725–741 (2017) 20. Liu, Y., Azizpour, H., Strand, F., Smith, K.: Decoupling inherent risk and early cancer signs in image-based breast cancer risk models. In: Martel, A.L., et al. (eds.) MICCAI 2020. LNCS, vol. 12266, pp. 230–240. Springer, Cham (2020). https:// doi.org/10.1007/978-3-030-59725-2_23 21. Loshchilov, I., Hutter, F.: SGDR: stochastic gradient descent with warm restarts. arXiv preprint arXiv:1608.03983 (2016) 22. Ontario, H.Q., et al.: Screening mammography for women aged 40 to 49 years at average risk for breast cancer: an evidence-based analysis. Ont. Health Technol. Assess. Ser. 7(1), 1–32 (2007) 23. Paci, E.: Summary of the evidence of breast cancer service screening outcomes in Europe and ﬁrst estimate of the beneﬁt and harm balance sheet. J. Med. Screen. 19(1_suppl), 5–13 (2012) 24. Park, J., et al.: Screening mammogram classiﬁcation with prior exams. arXiv preprint arXiv:1907.13057 (2019) 25. Roelofs, A.A., et al.: Importance of comparison of current and prior mammograms in breast cancer screening. Radiology 242(1), 70–77 (2007) 26. Sumkin, J.H., et al.: Optimal reference mammography: a comparison of mammograms obtained 1 and 2 years before the present examination. Am. J. Roentgenol. 180(2), 343–346 (2003) 27. Tyrer, J., Duﬀy, S.W., Cuzick, J.: A breast cancer prediction model incorporating familial and personal risk factors. Stat. Med. 23(7), 1111–1130 (2004) 28. Uno, H., Cai, T., Pencina, M.J., D’Agostino, R.B., Wei, L.J.: On the C-statistics for evaluating overall adequacy of risk prediction procedures with censored survival data. Stat. Med. 30(10), 1105–1117 (2011) 29. Varela, C., Karssemeijer, N., Hendriks, J.H., Holland, R.: Use of prior mammograms in the classiﬁcation of benign and malignant masses. Eur. J. Radiol. 56(2), 248–255 (2005) 30. Vaswani, A., et al.: Attention is all you need. In: Advances in Neural Information Processing Systems, vol. 30 (2017) 31. Veronesi, U., Boyle, P., Goldhirsch, A., Orecchia, R., Viale, G.: Breast cancer. Lancet 365, 1727–1741 (2005) 32. Yala, A., et al.: Multi-institutional validation of a mammography-based breast cancer risk model. J. Clin. Oncol. 40(16), 1732–1740 (2022) 33. Yala, A., et al.: Toward robust mammography-based models for breast cancer risk. Sci. Transl. Med. 13(578), eaba4373 (2021) 34. Yeoh, H.H., et al.: RADIFUSION: a multi-radiomics deep learning based breast cancer risk prediction model using sequential mammographic images with image attention and bilateral asymmetry reﬁnement. arXiv preprint arXiv:2304.00257 (2023) 