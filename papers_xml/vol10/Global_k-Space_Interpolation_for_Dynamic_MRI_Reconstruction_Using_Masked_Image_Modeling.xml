<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Global k-Space Interpolation for Dynamic MRI Reconstruction Using Masked Image Modeling</title>
				<funder ref="#_CmDYrR3 #_xmPeghq">
					<orgName type="full">European Research Council</orgName>
					<orgName type="abbreviated">ERC</orgName>
				</funder>
				<funder ref="#_WGF2eB7">
					<orgName type="full">Nvidia</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jiazhen</forename><surname>Pan</surname></persName>
							<email>jiazhen.pan@tum.de</email>
							<affiliation key="aff0">
								<orgName type="department">School of Medicine</orgName>
								<orgName type="institution" key="instit1">Klinikum Rechts der Isar</orgName>
								<orgName type="institution" key="instit2">Technical University of Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Suprosanna</forename><surname>Shit</surname></persName>
							<email>suprosanna.shit@tum.de</email>
							<affiliation key="aff0">
								<orgName type="department">School of Medicine</orgName>
								<orgName type="institution" key="instit1">Klinikum Rechts der Isar</orgName>
								<orgName type="institution" key="instit2">Technical University of Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Özgün</forename><surname>Turgut</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Medicine</orgName>
								<orgName type="institution" key="instit1">Klinikum Rechts der Isar</orgName>
								<orgName type="institution" key="instit2">Technical University of Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wenqi</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Medicine</orgName>
								<orgName type="institution" key="instit1">Klinikum Rechts der Isar</orgName>
								<orgName type="institution" key="instit2">Technical University of Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hongwei</forename><forename type="middle">Bran</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Medicine</orgName>
								<orgName type="institution" key="instit1">Klinikum Rechts der Isar</orgName>
								<orgName type="institution" key="instit2">Technical University of Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Quantitative Biomedicine</orgName>
								<orgName type="institution">University of Zurich</orgName>
								<address>
									<settlement>Zürich</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nil</forename><surname>Stolt-Ansó</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Computation, Information and Technology</orgName>
								<orgName type="institution">Technical University of Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Küstner</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Medical Image and Data Analysis</orgName>
								<orgName type="institution">University Hospital of Tübingen</orgName>
								<address>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kerstin</forename><surname>Hammernik</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Computation, Information and Technology</orgName>
								<orgName type="institution">Technical University of Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Rueckert</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Medicine</orgName>
								<orgName type="institution" key="instit1">Klinikum Rechts der Isar</orgName>
								<orgName type="institution" key="instit2">Technical University of Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">School of Computation, Information and Technology</orgName>
								<orgName type="institution">Technical University of Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Global k-Space Interpolation for Dynamic MRI Reconstruction Using Masked Image Modeling</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="228" to="238"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">1763E9EDED892161A63081CC0C411722</idno>
					<idno type="DOI">10.1007/978-3-031-43999-5_22</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-23T22:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Cardiac MR Imaging Reconstruction</term>
					<term>k-space Interpolation</term>
					<term>Masked Image Modeling</term>
					<term>Masked Autoencoders</term>
					<term>Transformers</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In dynamic Magnetic Resonance Imaging (MRI), k-space is typically undersampled due to limited scan time, resulting in aliasing artifacts in the image domain. Hence, dynamic MR reconstruction requires not only modeling spatial frequency components in the x and y directions of k-space but also considering temporal redundancy. Most previous works rely on image-domain regularizers (priors) to conduct MR reconstruction. In contrast, we focus on interpolating the undersampled k-space before obtaining images with Fourier transform. In this work, we connect masked image modeling with k-space interpolation and propose a novel Transformer-based k-space Global Interpolation Network, termed k-GIN. Our k-GIN learns global dependencies among low-and high-frequency components of 2D+t k-space and uses it to interpolate unsampled data. Further, we propose a novel k-space Iterative Refinement Module (k-IRM) to enhance the high-frequency components learning. We evaluate our approach on 92 in-house 2D+t cardiac MR subjects and compare it to MR reconstruction methods with image-domain regularizers. Experiments show that our proposed k-space interpolation method quantitatively and qualitatively outperforms baseline methods. Importantly, the proposed approach achieves substantially higher robustness and generalizability in cases of highly-undersampled MR data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>CINE Cardiac Magnetic Resonance (CMR) imaging is widely recognized as the gold standard for evaluating cardiac morphology and function <ref type="bibr" target="#b18">[19]</ref>. Raw data for CMR is acquired in the frequency domain (k-space). MR reconstruction from k-space data with high spatio-temporal resolutions throughout the cardiac cycle is an essential step for CMR. Short scan times, ideally within a single breathhold, are preferable to minimize patient discomfort and reduce potential image artifacts caused by patient motion. Typically, due to the restricted scanning times, only a limited amount of k-space data can be obtained for each temporal frame. Note that while some k-space data are unsampled, the sampled ones are reliable sources of information. However, the Fourier transform of undersampled k-space corrupts a broad region of pixels in the image domain with aliasing artifacts because of violating the Nyquist-Shannon sampling theorem. Previous works <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b29">30]</ref> have attempted to remove the image artifacts primarily by regularizing on the image domain using conventional/learning-based image priors. However, after the Fourier transform the artifacts may completely distort and/or obscure tissues of interest before the image-domain regularizers kick in, making these methods challenging to recover true tissue structures.</p><p>On a different principle, k-space interpolation methods first attempt to estimate the full k-space leveraging redundancy in sampled frequency components before Fourier transform. Image domain methods rely on artifacts-specific image priors to denoise the corrupted pixels, making them susceptible to variability in artifact types arising from different undersampling factors. Unlike image domain methods, k-space-based methods have a consistent task of interpolating missing data from reliable sampled ones, even though the undersampling factor may vary. This makes k-space interpolation methods simple, robust and generic over multiple undersampling factors.</p><p>In this work, we are interested in learning an entirely k-space-based interpolation for the Cartesian undersampled dynamic MR data. An accurate learnable k-space interpolator can be achieved via (1) a rich representation of the sampled k-space data, which can facilitate the exploitation of the limited available samples, and (2) global dependency modeling of k-space to interpolate unsampled data from the learned representation. Modeling global dependencies are beneficial because a local structure in the image domain is represented by a wide range of frequency components in k-space. Furthermore, in the context of dynamic MR, the interpolator also has to exploit temporal redundancies.</p><p>In the recent past, masked image modeling <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b33">34]</ref> has emerged as a promising method for learning rich generalizable representation by reconstructing the whole image from a masked (undersampled) input. Masked Autoencoders (MAE) <ref type="bibr" target="#b10">[11]</ref> are one such model that leverages the global dependencies of the undersampled input using Transformers and learns masked-based rich feature representation. Despite sharing the same reconstruction principle, MAE has not been explored in k-space interpolation of Cartesian undersampled data. In this work, we cast 2D+t k-space interpolation as a masked signal reconstruction problem and propose a novel Transformer-based method entirely in k-space. Further, we intro-duce a refinement module on k-space to boost the accuracy of high-frequency interpolation. Our contributions can be summarized as follows:</p><p>1. We propose a novel k-space Global Interpolation Network, termed k-GIN, leveraging masked image modeling for the first time in k-space. To the best of our knowledge, our work enables the first Transformer-based k-space interpolation for 2D+t MR reconstruction. 2. Next, we propose k-space Iterative Refinement Module, termed k-IRM that refines k-GIN interpolation by efficiently gathering spatio-temporal redundancy of the MR data. Crucially, k-IRM specializes in learning high-frequency details with the aid of customized High-Dynamic-Range (HDR) loss. 3. We evaluate our approach on 92 in-house CMR subjects and compare it to model-based reconstruction baselines using image priors. Our experiments show that the proposed k-space interpolator outperforms baseline methods with superior qualitative and quantitative results. Importantly, our method demonstrates improved robustness and generalizability regarding varying undersampling factors than the model-based counterparts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Reconstruction with image priors is broadly used with either image-only denoising <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b35">36]</ref> or with model-based approaches to incorporate the kspace consistency by solving an inverse problem. For the latter, the physicsbased model can be formulated as a low-rank and a sparse matrix decomposition in CMR <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b25">26]</ref>, or a motion-compensated MR reconstruction problem <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28]</ref>, or data consistency terms with convolution-based <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b29">30]</ref> or Transformers-based <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b17">18]</ref> image regularizers.</p><p>k-space-Domain Interpolation. Methods include works <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b21">22]</ref>, which have introduced auto-calibration signals (ACS) in the multi-coil k-space center of Cartesian sampled data. RAKI <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b15">16]</ref> uses convolutional networks for optimizing imaging and scanner-specific protocols. Nevertheless, these methods have limited flexibility during the scanning process since they all require a fixed set of ACS data in k-space. <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b31">32]</ref> introduced k-space interpolation methods which do not require calibration signals. <ref type="bibr" target="#b9">[10]</ref> proposed a k-space U-Net under residual learning setting. However, these methods heavily rely on local operators such as convolution and may overlook non-local redundancies. <ref type="bibr" target="#b6">[7]</ref> uses Transformers applicable only on radial sampled kspace data. However, using masked image modeling with Transformers in k-space for dynamic MR imaging e.g. 2D+t CMR data has not been studied yet.</p><p>Hybrid Approaches. Combine information from both k-space and imagedomain. KIKI-Net <ref type="bibr" target="#b5">[6]</ref> employs an alternating optimization between the image domain and k-space. <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b32">33]</ref> use parallel architectures for k-space and imagedomain simultaneously. However, their ablation shows limited contribution coming from the k-space compared to the image domain, implying an underexploitation of the k-space. Concurrently, <ref type="bibr" target="#b36">[37]</ref> use Transformers in k-space but their performance is heavily dependent on the image domain fine-tuning at the final stage. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>Fully sampled complex 2D+t dynamic MR k-space data can be expressed as y ∈ C XY T , X and Y are the height (k x ) and the width (k y ) of the k-space matrix, and T is the number of frames along time. In this work, we express k-space as 2 channels (real and imaginary) data y ∈ R 2XY T . For the MR acquisition, a binary Cartesian sampling mask M ∈ Z Y T |M ij ∈ {0, 1} is applied in the k y -t plane, i.e. all k-space values along the k x (readout direction) are sampled if the mask is 1, and remains unsampled if the mask is 0. Figure <ref type="figure" target="#fig_0">1</ref> shows a pictorial undersampled k-space data. Let us denote the collection of sampled k-space lines as y s and unsampled lines as y u . The dynamic MR reconstruction task is to estimate y u and reconstruct y using y s only. In this work, we propose a novel Transformer-based reconstruction framework consisting of 1) k-GIN to learn global representation and 2) k-IRM to achieve refined k-space interpolation with a focus on high-frequency components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">k-space Global Interpolation Network (k-GIN)</head><p>In our proposed approach, we work on the k y -t plane and consider k x as the channel dimension. Further, we propose each point in the k y -t plane to be an individual token. In total, we have Y T number of tokens, out of which Y T/R are sampled tokens for an undersampling factor of R. Our objective is to contextualize global dependencies among every sampled token. For that, we use a ViT/MAE <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b10">11]</ref> encoder E consisting of alternating blocks of multi-head self-attention and multi-layer-perceptrons. The encoder takes advantage of each token's position embedding to correctly attribute its location. Following ViT, we use LayerNorm and GELU activation. We obtain rich feature representation f E = E(y s ) of the sampled k-space from the encoder. Next, we want a preliminary estimate of the undersampled k-space data from the learned feature representation. To this end, we employ a decoder D of similar architecture as the encoder. We initialize all the unsampled tokens y u with a single learnable token shared among them. Subsequently, we add their corresponding position embedding to these unsampled tokens. During the decoding process, the unsampled tokens attend to the well-contextualized features f E and produce an estimate of the whole k-space ŷr = D ([f E , y u ]). Since our masking pattern includes more sampled data in low-frequency than high-frequency components, we observe k-GIN gradually learn from low-frequency to high-frequency. Note that the imbalance of magnitude in k-space results in more emphasis on low-frequency when 1 loss is applied between estimation and ground-truth. We leverage this property into the learning behavior of k-GIN and deliberately use 1 loss between ŷr and y, read as L 1 = ŷr -y 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">k-space Iterative Refinement Module (k-IRM)</head><p>Using 1 loss in k-GIN makes it focus more on the low-frequency components learning but the high-frequency estimation is still sub-optimal. Inspired by the iterative refinement strategy <ref type="bibr" target="#b37">[38]</ref> which is widely used to improve estimation performance, we propose to augment k-GIN's expressive power, especially in highfrequency components, with k-space Iterative Refinement Module. This consists of three Transformer blocks that operate on three orthogonal planes. All three blocks are identical in architecture. The first block operates on k y -t plane and treats k x as channel dimension. The second block operates on k x -t plane and considers k y as channels, while the final block operates on k x -k y plane with t as channel dimension. Note that for the final refinement block uses 4 × 4 size token while the previous two blocks consider each point as a single token. These configurations enable scalable exploration of the spatio-temporal redundancy present in the output of the k-GIN. We denote ŷ1 , ŷ2 and ŷ3 as the estimation after each block in the k-IRM. We apply the skip connection between each refinement block and iteratively minimize the residual error at each stage.</p><p>Inspired by <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b23">24]</ref>, we applied an approximated logarithm loss function called High-Dynamic Range (HDR) loss for all the stages of k-IRM. HDR loss handles the large magnitude difference in the k-space data and makes the network pay more attention to high-frequency learning. The HDR loss function is defined as:</p><formula xml:id="formula_0">L HDR = 3 i=1 ŷi-y s(ŷ)+ 2 2</formula><p>where s(•) is the stop-gradient operator preventing the network back-propagation of estimation in the denominator and controls the operational range of the logarithmic approximation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Inference</head><p>The inference is identical to the training till obtaining the refined output from the k-IRM. Then we replace k-space estimation at the sampled position with ground-truth k-space values, ensuring the data-consistency. Note that this step is not done during the training as it deteriorates learning k-space representation.</p><p>Once full k-space has been estimated, we use Fourier transform to obtain the image reconstruction during the inference. Note that image reconstruction is not needed during the training since our framework is entirely based in k-space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Data and Experiments</head><p>Dataset. The training was performed on 81 subjects (a mix of patients and healthy subjects) of in-house acquired short-axis 2D CINE CMR, whereas testing was carried out on 11 subjects. Data were acquired with 30/34 multiple receiver coils and 2D balanced steady-state free precession sequence on a 1.5T MR (Siemens Aera with TE=1.06 ms, TR=2.12 ms, resolution=1.9×1.9mm 2 with 8mm slice thickness, 8 breath-holds of 15 s duration). The MR data were acquired with a matrix size of 192×156 with 25 temporal cardiac phases (40ms temporal resolution). Afterwards, these data were converted to single-coil MR imaging and k-space data using coil sensitivity maps, simulating a fully sampled single-coil acquisition. A stack of 12 slices along the long axis was collected, resulting in 415/86 image sequence (2D+t) for training/test.</p><p>Implementation Details. We use an NVIDIA A6000 GPU to train our framework. The batch size was set to 1 with a one-cycle learning-rate scheduler (max. learning rate 0.0001). We use 8 layers, 8 heads and 512 embedding dimensions for all of our Transformer blocks. We train our network with joint 1 and HDR-loss with tuned to 0.5. Training and inference were carried out on retrospectively undersampled images with masks randomly generated by VISTA <ref type="bibr" target="#b0">[1]</ref>. We train the network with R = 4 undersampled data while we test our method on an undersampled factor R = 4, 6 and 8 during the inference. We can use this inference strategy to test our model's generalizability and robustness to different undersampling factors in comparison to the following baseline methods.</p><p>Baseline Methods and Metrics. We compare the proposed framework with three single-coil MR reconstruction methods that apply image priors: TVnorm Optimization (TV-Optim) which is widely used in reconstruction <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b22">23]</ref>, L+S <ref type="bibr" target="#b25">[26]</ref> and DcCNN <ref type="bibr" target="#b29">[30]</ref>. TV-Optim reconstructs the image using TV-norm <ref type="bibr" target="#b28">[29]</ref> as the image regularizer. L+S leverages compressed sensing techniques and addresses the reconstruction using low rankness and sparsity of the CMR as the image prior, whilst DcCNN employs 3D convolutional neural networks in the image domain together with data-consistency terms. We use the same training and inference strategy for DcCNN to test its model robustness. We Fourier transform our interpolated full k-space to obtain the image reconstruction and utilize Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM) and Normalized Mean Squared Error (NMSE) to evaluate the reconstruction performance with the baseline quantitatively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Discussion</head><p>The quantitative results in Table <ref type="table" target="#tab_0">1</ref> show consistent superior performance of the proposed method across every single undersampling factor compared to all other baseline methods. Figure <ref type="figure" target="#fig_2">3</ref> shows a qualitative comparison for a typical test sample. It can be seen that the reconstruction methods with image priors can still provide comparable results at R = 4, however, suffer from a large performance drop when acceleration rates get higher, especially at R = 8. The non-trivial hyper-parameters tuning has to be carried out for L+S and TV-Optim to adapt to the specific image prior at different acceleration factors. It is also noteworthy that the proposed method and DcCNN are both trained only on R = 4 undersampled CMR. DcCNN demonstrates inferior reconstruction for R = 8 since there is a mismatch in artifact characteristics between R = 4 and R = 8. On the contrary, the task of interpolating k-space for R = 4 and R = 8 remains the same, i.e., to estimate missing data from sampled data. We efficiently leverage rich contextualized representation of k-GIN to interpolate full k-space even when a lesser number of sampled k-space data are given as input than seen during training. The observation confirms the superior robustness and generalizability of our proposed framework. Next, we conduct an ablation study to validate our architectural design. We carry out experiments to investigate the impact of applying k-IRM. We conduct the interpolation using 1) only k-GIN, 2) k-GIN + k y -t plane refinement, 3) k-GIN + k x -t plane refinement, 4) k-GIN + k x -k y plane refinement and 5) k-GIN with all three refinement blocks. Table <ref type="table">2</ref> in supplementary presents quantitative comparisons amongst five configurations as above. We observe k-IRM offers the best performance when all 3 refinement blocks are used together. In the second ablation, Table <ref type="table">3</ref> in supplementary shows the usefulness of applying 1 in k-GIN and HDR in k-IRM. HDR makes k-GIN's learning inefficient since HDR deviates from its learning principle of "first low-frequency then high-frequency". On the other hand, 1 + 1 combination hinders high-frequency learning.</p><p>Outlook. Previous works <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b24">25]</ref> have speculated limited usefulness coming from k-space in a hybrid setting. However, our work presents strong evidence of kspace representation power which can be leveraged in future work with hybrid reconstruction setup. Furthermore, one can utilize our work as a pre-training task since the image reconstruction itself is an "intermediate step" for downstream tasks e.g. cardiac segmentation and disease classification. In the future, one can reuse the learned encoder representation of k-GIN to directly solve downstream tasks without requiring image reconstruction.</p><p>Limitation. We also acknowledge some limitations of the work. First, we have not evaluated our method on prospectively collected data, which would be our focus in future work. Second, the current study only investigates the single coil setup due to hardware memory limitations. In the future, we will address the multi-coil scenario by applying more memory-efficient Transformers backbones e.g. <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b34">35]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this work, we proposed a novel Transformer-based method with mask image modeling to solve the dynamic CMR reconstruction by only interpolating the kspace without any image-domain priors. Our framework leverages Transformers' global dependencies to exploit redundancies in all three k x -, k y -and t-domain. Additionally, we proposed a novel refinement module (k-IRM) to boost highfrequency learning in k-space. Together, k-GIN and k-IRM not only produce high-quality k-space interpolation and superior CMR reconstruction but also generalize significantly better than baselines for higher undersampling factors.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The proposed k-space-based dynamic MR reconstruction framework consists of k-space Global Interpolation Network (k-GIN) (see 3.1) and k-space Iterative Refinement Module (k-IRM) for refining the k-GIN interpolation (see 3.2). In the final stage for the inference, we replace k-space estimation at the sampled position with groundtruth k-space values, ensuring the data consistency.</figDesc><graphic coords="4,55,98,54,50,340,12,68,20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. k-space Iterative Refinement Module (k-IRM) refines high-frequency components of the k-space data (see 3.1). Its refinement Transformer blocks extract the spatio-temporal redundancy by operating the on ky-t, kx-t and kx-ky plane.</figDesc><graphic coords="5,57,30,54,35,309,88,70,36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Qualitative comparison of the proposed method with TV-Optim, L+S and DcCNN in the R = 4 and 8 undersampled data. Reference images, undersampling masks, reconstructed (x-y and y-t plane) images and their corresponding error maps are showcased. The selected y-axis is marked with a yellow line in the reference image.</figDesc><graphic coords="8,55,98,54,62,340,24,215,08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Quantitative analysis of reconstruction for accelerated CINE CMR (R=4, 6 and 8) using TV-Optim, L+S<ref type="bibr" target="#b25">[26]</ref>, DcCNN<ref type="bibr" target="#b29">[30]</ref> and the proposed method. PSNR (sequence based), SSIM and NMSE are used to evaluate the reconstruction performance. The mean value with the standard deviations are shown. The best results are marked in bold.</figDesc><table><row><cell cols="2">Acc R Methods</cell><cell>NMSE ↓</cell><cell>SSIM ↑</cell><cell>PSNR ↑</cell></row><row><cell>4</cell><cell cols="4">TV-Optim 0.120 ± 0.031 0.922 ± 0.026 36.743 ± 3.233</cell></row><row><cell></cell><cell>L+S [26]</cell><cell cols="3">0.097 ± 0.026 0.949 ± 0.021 39.346 ± 2.911</cell></row><row><cell></cell><cell cols="4">DcCNN [30] 0.087 ± 0.022 0.957 ± 0.019 40.293 ± 2.891</cell></row><row><cell></cell><cell>Proposed</cell><cell cols="3">0.088 ± 0.022 0.958 ± 0.019 40.368 ± 3.030</cell></row><row><cell>6</cell><cell cols="4">TV-Optim 0.161 ± 0.047 0.887 ± 0.040 34.066 ± 3.605</cell></row><row><cell></cell><cell>L+S</cell><cell cols="3">0.154 ± 0.042 0.901 ± 0.036 34.921 ± 3.174</cell></row><row><cell></cell><cell>DcCNN</cell><cell cols="3">0.116 ± 0.029 0.932 ± 0.026 37.666 ± 2.768</cell></row><row><cell></cell><cell>Proposed</cell><cell cols="3">0.109 ± 0.029 0.940 ± 0.026 38.461 ± 3.095</cell></row><row><cell>8</cell><cell cols="4">TV-Optim 0.289 ± 0.078 0.808 ± 0.067 29.052 ± 3.817</cell></row><row><cell></cell><cell>L+S</cell><cell cols="3">0.245 ± 0.061 0.826 ± 0.047 30.413 ± 2.888</cell></row><row><cell></cell><cell>DcCNN</cell><cell cols="3">0.276 ± 0.047 0.821 ± 0.040 29.778 ± 2.822</cell></row><row><cell></cell><cell>Proposed</cell><cell cols="3">0.151 ± 0.041 0.904 ± 0.036 35.674 ± 3.293</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement. This work is partly supported by the <rs type="funder">European Research Council (ERC)</rs> with Grant Agreement no. <rs type="grantNumber">884622</rs>. <rs type="person">Suprosanna Shit</rs> is supported by <rs type="funder">ERC</rs> with the <rs type="programName">Horizon 2020 research and innovation program</rs> (<rs type="grantNumber">101045128-iBack-epic-ERC2021-COG</rs>). <rs type="person">Hongwei Bran Li</rs> is supported by an <rs type="funder">Nvidia</rs> <rs type="grantName">GPU research grant</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_CmDYrR3">
					<idno type="grant-number">884622</idno>
				</org>
				<org type="funding" xml:id="_xmPeghq">
					<idno type="grant-number">101045128-iBack-epic-ERC2021-COG</idno>
					<orgName type="program" subtype="full">Horizon 2020 research and innovation program</orgName>
				</org>
				<org type="funding" xml:id="_WGF2eB7">
					<orgName type="grant-name">GPU research grant</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43999-5_22.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Variable density incoherent spatiotemporal acquisition (VISTA) for highly accelerated cardiac MRI</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Giri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Craft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">P</forename><surname>Simonetti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1266" to="1278" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Scan-specific robust artificial-neural-networks for k-space interpolation (RAKI) reconstruction: database-free deep learning for fast imaging</title>
		<author>
			<persName><forename type="first">M</forename><surname>Akçakaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moeller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Weingärtner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Uğurbil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="439" to="453" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Matrix description of general motion correction applied to multishot images</title>
		<author>
			<persName><forename type="first">P</forename><surname>Batchelor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Atkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Irarrazaval</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="1273" to="1280" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">FlashAttention: fast and memoryefficient exact attention with IO-awareness</title>
		<author>
			<persName><forename type="first">T</forename><surname>Dao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rudra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ré</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="16344" to="16359" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">An image is worth 16x16 words: transformers for image recognition at scale</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.11929</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">KIKI-Net: cross-domain convolutional neural networks for reconstructing undersampled magnetic resonance images</title>
		<author>
			<persName><forename type="first">T</forename><surname>Eo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hwang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2188" to="2201" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A projection-based K-space transformer network for undersampled radial MRI reconstruction with limited training subjects</title>
		<author>
			<persName><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhong</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16446-0_69</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16446-0_69" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13436</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Generalized autocalibrating partially parallel acquisitions (GRAPPA)</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Griswold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1202" to="1210" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning a variational network for reconstruction of accelerated MRI data</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hammernik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Klatzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kobler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3055" to="3071" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">k-space deep learning for accelerated MRI</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sunwoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TMI</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="377" to="386" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Masked autoencoders are scalable vision learners</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.06377</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Swin transformer for fast MRI</title>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">493</biblScope>
			<biblScope unit="page" from="281" to="304" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Neural implicit k-space for binning-free non-cartesian cardiac MR imaging</title>
		<author>
			<persName><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cruz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hammernik</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-34048-2_42</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-34048-2_42" />
	</analytic>
	<monogr>
		<title level="m">IPMI 2023</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Frangi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Wassermann</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">13939</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep low-rank plus sparse network for dynamic MR imaging</title>
		<author>
			<persName><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">X</forename><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page">102190</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep convolutional neural network for inverse problems in imaging</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Froustey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Unser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TIP</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4509" to="4522" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">LORAKI: autocalibrated recurrent neural networks for autoregressive MRI reconstruction in k-space</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Haldar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.09390</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Spatio-temporal deep learning-based undersampling artefact reduction for 2D radial cine MRI with limited training data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kofler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dewey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schaeffter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kolbitsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TMI</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="703" to="717" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Unsupervised MRI reconstruction via zero-shot learned adversarial transformers</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Korkmaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TMI</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1747" to="1763" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The growth and evolution of cardiovascular magnetic resonance: a 20-year history of the society for cardiovascular magnetic resonance (SCMR) annual scientific sessions</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cardiovasc. Magn. Reson</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Reference-free single-pass EPI Nyquist ghost correction using annihilating filter-based low rank Hankel matrix (ALOHA)</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1775" to="1789" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Accelerated dynamic MRI exploiting sparsity and low-rank structure: k-t SLR</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Lingala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dibella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jacob</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TMI</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1042" to="1054" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">SPIRiT: iterative self-consistent parallel imaging reconstruction from arbitrary k-space</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lustig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Pauly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="457" to="471" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Sparse MRI: the application of compressed sensing for rapid MR imaging</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lustig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Pauly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1182" to="1195" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">NeRF in the dark: high dynamic range view synthesis from noisy raw images</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mildenhall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Martin-Brualla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Barron</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="16169" to="16178" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">CDF-Net: cross-domain fusion network for accelerated MRI reconstruction</title>
		<author>
			<persName><forename type="first">O</forename><surname>Nitski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mcintosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59713-9_41</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-59713-9_41" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12262</biblScope>
			<biblScope unit="page" from="421" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Low-rank plus sparse matrix decomposition for accelerated dynamic MRI with separation of background and dynamic components</title>
		<author>
			<persName><forename type="first">R</forename><surname>Otazo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Candès</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Sodickson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1125" to="1136" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Reconstructiondriven motion estimation for motion-compensated MR cine imaging</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Küstner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hammernik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.02504</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning-based and unrolled motion-compensated reconstruction for cardiac MR CINE imaging</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kustner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hammernik</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16446-0_65</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16446-0_65" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13436</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Nonlinear total variation based noise removal algorithms</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">I</forename><surname>Rudin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fatemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica D</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="259" to="268" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A deep cascade of convolutional neural networks for dynamic MR image reconstruction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schlemper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TMI</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="491" to="503" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Super-resolution reconstruction of MR image with a novel residual learning network algorithm</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Med. Biol</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">85011</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Calibrationless parallel imaging reconstruction based on structured lowrank matrix completion</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="959" to="970" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Joint frequency-and image-space learning for fourier imaging</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Iglesias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Adalsteinsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Dalca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Golland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn. Biomed. Imaging</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">SimMIM: a simple framework for masked image modeling</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Nyströmformer: a nyström-based algorithm for approximating self-attention</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AAAI</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="14138" to="14148" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">DAGAN: deep de-aliasing generative adversarial networks for fast compressed sensing MRI reconstruction</title>
		<author>
			<persName><forename type="first">G</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Slabaugh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TMI</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1310" to="1321" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">K-space transformer for undersampled MRI reconstruction</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>BMVC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.04159</idno>
		<title level="m">Deformable DETR: deformable transformers for end-to-end object detection</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
