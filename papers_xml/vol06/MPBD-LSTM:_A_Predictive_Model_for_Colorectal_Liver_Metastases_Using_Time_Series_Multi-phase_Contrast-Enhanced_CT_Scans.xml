<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xueyang</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Notre Dame</orgName>
								<address>
									<settlement>Notre Dame</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Han</forename><surname>Xiao</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">The First Affiliated Hospital of Sun Yat-sen University</orgName>
								<address>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Weixiang</forename><surname>Weng</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">The First Affiliated Hospital of Sun Yat-sen University</orgName>
								<address>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaowei</forename><surname>Xu</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Guangdong Provincial People&apos;s Hospital</orgName>
								<address>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yiyu</forename><surname>Shi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Notre Dame</orgName>
								<address>
									<settlement>Notre Dame</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="379" to="388"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">77F5F5EDF876377013C85D2CC61FD7B0</idno>
					<idno type="DOI">10.1007/978-3-031-43987-2_37</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-24T11:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Colorectal cancer liver metastasis</term>
					<term>Liver cancer prediction</term>
					<term>Contrast-enhanced CT scan</term>
					<term>Bi-directional LSTM</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Colorectal cancer is a prevalent form of cancer, and many patients develop colorectal cancer liver metastasis (CRLM) as a result. Early detection of CRLM is critical for improving survival rates. Radiologists usually rely on a series of multi-phase contrast-enhanced computed tomography (CECT) scans done during follow-up visits to perform early detection of the potential CRLM. These scans form unique fivedimensional data (time, phase, and axial, sagittal, and coronal planes in 3D CT). Most of the existing deep learning models can readily handle four-dimensional data (e.g., time-series 3D CT images) and it is not clear how well they can be extended to handle the additional dimension of phase. In this paper, we build a dataset of time-series CECT scans to aid in the early diagnosis of CRLM, and build upon state-of-the-art deep learning techniques to evaluate how to best predict CRLM. Our experimental results show that a multi-plane architecture based on 3D bi-directional LSTM, which we call MPBD-LSTM, works best, achieving an area under curve (AUC) of 0.79. On the other hand, analysis of the results shows that there is still great room for further improvement. Our code is available at https://github.com/XueyangLiOSU/MPBD-LSTM.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Colorectal cancer is the third most common malignant tumor, and nearly half of all patients with colorectal cancer develop liver metastasis during the course of the disease <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b15">16]</ref>. Liver metastases after surgery of colorectal cancer is the major cause of disease-related death. Colorectal cancer liver metastases (CRLM) have therefore become one of the major focuses in the medical field. Patients with colorectal cancer typically undergo contrast-enhanced computed tomography (CECT) scans multiple times during follow-up visits after surgery for early detection of CRLM, generating a 5D dataset. In addition to the axial, sagittal, and coronal planes in 3D CT scans, the data comprises contrast-enhanced multiple phases as its 4th dimension, along with different timestamps as its 5th dimension. Radiologists heavily rely on this data to detect the CRLM in the very early stage <ref type="bibr" target="#b14">[15]</ref>.</p><p>Extensive existing works have demonstrated the power of deep learning on various spatial-temporal data, and can potentially be applied towards the problem of CRLM. For example, originally designed for natural data, several mainstream models such as E3D-LSTM <ref type="bibr" target="#b11">[12]</ref>, ConvLSTM <ref type="bibr" target="#b10">[11]</ref> and PredRNN <ref type="bibr" target="#b12">[13]</ref> use Convolutional Neural Networks (CNN) to capture spatial features and Long Short-Term Memory (LSTM) to process temporal features. Some other models, such as SimVP <ref type="bibr" target="#b3">[4]</ref>, replace LSTMs with CNNs but still have the capability of processing spatiotemporal information. These models can be adapted for classification tasks with the use of proper classification head.</p><p>However, all these methods have only demonstrated their effectiveness towards 3D/4D data (i.e., time-series 2D/3D images), and it is not clear how to best extend them to work with the 5D CECT data. Part of the reason is due to the lack of public availability of such data. When extending these models towards 5D CECT data, some decisions need to be made, for example: 1) What is the most effective way to incorporate the phase information? Simply concatenating different phases together may not be the optimal choice, because the positional information of the same CT slice in different phases would be lost.</p><p>2) Shall we use uni-directional LSTM or bi-direction LSTM? E3D-LSTM <ref type="bibr" target="#b11">[12]</ref> shows uni-directional LSTM works well on natural videos while several other works show bi-directional LSTM is needed in certain medical image segmentation tasks <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b6">7]</ref>.</p><p>In this paper, we investigate how state-of-art deep learning models can be applied to the CRLM prediction task using our 5D CECT dataset. We evaluate the effectiveness of bi-directional LSTM and explore the possible method of incorporating different phases in the CECT dataset. Specifically, we show that the best prediction accuracy can be achieved by enhancing E3D-LSTM <ref type="bibr" target="#b11">[12]</ref> with a bi-directional LSTM and a multi-plane structure.  When patients undergo CECT scans to detect CRLM, typically three phases are captured: the unenhanced plain scan phase (P), the portal venous phase (V), and the arterial phase (A). The P phase provides the basic shape of the liver tissue, while the V and A phases provide additional information on the liver's normal and abnormal blood vessel patterns, respectively <ref type="bibr" target="#b9">[10]</ref>. Professional radiologists often combine the A and V phases to determine the existence of metastases since blood in the liver is supplied by both portal venous and arterial routes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Dataset and Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Dataset</head><p>Our dataset follows specific inclusion criteria:</p><p>-No tumor appears on the CT scans. That means patients have not been diagnosed as CRLM when they took the scans.</p><p>-Patients were previously diagnosed with colorectal cancer TNM stage I to stage III, and recovered from colorectal radical surgery. -Patients have two or more times of CECT scans.</p><p>-We already determined whether or not the patients had liver metastases within 2 years after the surgery, and manually labeled the dataset based on this. -No potential focal infection in the liver before the colorectal radical surgery.</p><p>-No metastases in other organs before the liver metastases.</p><p>-No other malignant tumors.</p><p>Our retrospective dataset includes two cohorts from two hospitals. The first cohort consists of 201 patients and the second cohort includes 68 patients. Each scan contains three phases and 100 to 200 CT slices with a resolution of 512×512. Patients may have different numbers of CT scans, ranging from 2 to 6, depending on the number of follow-up visits. CT images are collected with the following acquisition parameters: window width 150, window level 50, radiation dose 120 kV, slice thickness 1 mm, and slice gap 0.8 mm. All images underwent manual quality control to exclude any scans with noticeable artifacts or blurriness and to verify the completeness of all slices. Additional statistics on our dataset are presented in Table <ref type="table" target="#tab_0">1</ref> and examples of representative images are shown in Fig. <ref type="figure" target="#fig_0">1</ref>. The dataset is available upon request. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Methods</head><p>Numerous state-of-the-art deep learning models are available to effectively process 4D data. In this paper, we will evaluate some of the most popular ones:</p><p>1) SaConvLSTM, introduced by Lin et al. <ref type="bibr" target="#b8">[9]</ref>, incorporates the self-attention mechanism into the ConvLSTM <ref type="bibr" target="#b10">[11]</ref> structure, which improves the ability to capture spatiotemporal correlations compared to traditional LSTM. 2) E3D-LSTM, introduced by Wang et al. <ref type="bibr" target="#b11">[12]</ref>, integrates 3D CNNs into LSTM cells to capture both short-and long-term temporal relations. They used 3D-CNNs to handle the 3D data at each timestamp and LSTMs to compute information at different timestamps. 3) PredRNN-V2, introduced by Wang et al. <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref>, uses Spatiotemporal LSTM (ST-LSTM) by stacking multiple ConvLSTM units and connecting them in a zigzag pattern to handle spatiotemporal data of 4 dimensions. 4) SimVP <ref type="bibr" target="#b3">[4]</ref>, introduced by Gao et al., uses CNN as the translator instead of LSTM.</p><p>All of these models need to be modified to handle 5D CECT datasets. A straightforward way to extend them is simply concatenating the A phase and V phase together, thus collapsing the 5D dataset to 4D. However, such an extension may not be the best way to incorporate the 5D spatiotemporal information, because the positional information of the same CT slice in different phases would be lost. Below we explore an alternative modification multi-plane bi-directional LSTM (MPBD-LSTM), based on E3D-LSTM, to handle the 5D data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MPBD-LSTM.</head><p>The most basic building block in MPBD-LSTM is the 3D-LSTM modules. Each 3D-LSTM module is composed of two E3D-LSTM cells <ref type="bibr" target="#b11">[12]</ref>. Additionally, inspired by the bi-directional LSTM used in medical image segmentation task <ref type="bibr" target="#b1">[2]</ref>, we replace the uni-directional connections with bidirectional connections by using the backward pass in the 2nd E3D-LSTM cell in each 3D-LSTM module. This allows us to further jointly compute information from different timestamps and gives us more accurate modeling of temporal dynamics. The inner structure of one such module is shown in Fig. <ref type="figure" target="#fig_1">2(b)</ref>. Aside from the two E3D-LSTM cells, it also includes an output gate σ. Each 3D-LSTM module will generate an output y v,t , which can be calculated as <ref type="bibr" target="#b2">[3]</ref>:</p><formula xml:id="formula_0">y v,t = σ( -→ h v,t , ← - h v,t )<label>(1)</label></formula><p>where -→ h v,t and ←h v,t are the output hidden state of the forward pass and backward pass of phase v at timestamp t, and σ is the function which is used to combine these two outputs, which we choose to use a summation function to get the summation product of these two hidden states. Therefore, the output of the bi-directional LSTM module presented in Fig. <ref type="figure" target="#fig_1">2(b</ref>) can be represented as:</p><formula xml:id="formula_1">y v,t0 = -→ h v,t0 ⊕ ← - h v,t0<label>(2)</label></formula><p>in which ⊕ stands for summation. After this, the output y v,t0 is passed into the bi-directional LSTM module in the next layer and viewed as input for this module.</p><p>Figure <ref type="figure" target="#fig_1">2</ref>(a) illustrates how MPBD-LSTM uses these 3D-LSTM building blocks to handle the multiple phases in our CT scan dataset. We use two planes, one for the A phase and one for the V phase, each of which is based on a backbone of E3D-LSTM <ref type="bibr" target="#b11">[12]</ref> with the same hyperparameters. We first use three 3D-CNN encoders (not displayed in Fig. <ref type="figure" target="#fig_1">2(a)</ref>) as introduced in E3D-LSTM to extract the features. Each encoder is followed by a 3D-LSTM stack (the "columns") that processes the spatiotemporal data for each timestamp. The stacks are bidirectionally connected, as we described earlier, and consist of two layers of 3D-LSTM modules that are connected by their hidden states. When the spatiotemporal dataset enters the model, it is divided into smaller groups based on timestamps and phases. The 3D-LSTM stacks process these groups in parallel, ensuring that the CT slices from different phases are processed independently and in order, preserving the positional information. After the computation of the 3D-LSTM modules in each plane, we use an average function to combine the output hidden states from both planes.</p><p>An alternative approach is to additionally connect two planes by combining the hidden states of 3D-LSTM modules and taking their average if a module receives two inputs. However, we found that such design actually resulted in a worse performance. This issue will be demonstrated and discussed later in the ablation study.</p><p>In summary, the MPBD-LSTM model comprises two planes, each of which contains three 3D-LSTM stacks with two modules in each stack. It modifies E3D-LSTM by using bi-directional connected LSTMs to enhance communication between different timestamps, and a multi-plane structure to simultaneously process multiple phases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Augmentation and Selection</head><p>We selected 170 patients who underwent three or more CECT scans from our original dataset, and cropped the images to only include the liver area, as shown in Fig. <ref type="figure" target="#fig_0">1</ref>. Among these cases, we identified 49 positive cases and 121 negative cases. To handle the imbalanced training dataset, we selected and duplicated 60% of positive cases and 20% of negative cases by applying Standard Scale Jittering (SSJ) <ref type="bibr" target="#b4">[5]</ref>. For data augmentation, we randomly rotated the images from -30 • to 30 • and employed mixup <ref type="bibr" target="#b16">[17]</ref>. We applied the same augmentation technique consistently to all phases and timestamps of each patient's data. We also used Spline Interpolated Zoom (SIZ) <ref type="bibr" target="#b17">[18]</ref> to uniformly select 64 slices. For each slice, the dimension was 256 × 256 after cropping. We used the A and V phases of CECT for our CRLM prediction task since the P phase is only relevant when tumors are significantly present, which is not the case in our dataset. The dimension of our final input is (3 × 2 × 64 × 64 × 64), representing (T × P × D × H × W ), where T is the number of timestamps, P is the number of different phases, D is the slice depth, H is the height, and W is the width.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experiment Setup</head><p>As the data size is limited, 10-fold cross-validation is adopted, and the ratio of training and testing dataset is 0.9 and 0.1, respectively. Adam optimizer <ref type="bibr" target="#b7">[8]</ref> and Binary Cross Entropy loss function <ref type="bibr" target="#b0">[1]</ref> are used for network training. For MPBD-LSTM, due to GPU memory constraints, we set the batch size to one and the number of hidden units in LSTM cells to 16, and trained the model till converge with a learning rate of 5e-4. Each training process required approximately 23 GB of memory and took about 20 h on an Nvidia Titan RTX GPU. We ran the 10 folds in parallel on five separate GPUs, which allowed us to complete the entire training process in approximately 40 h. We also evaluated E3D-LSTM <ref type="bibr" target="#b11">[12]</ref>, PredRNN-V2 <ref type="bibr" target="#b13">[14]</ref>, SaConvLSTM <ref type="bibr" target="#b8">[9]</ref>, and SimVP <ref type="bibr" target="#b3">[4]</ref>. As this is a classification task, we evaluate all models' performance by their AUC scores. Table <ref type="table" target="#tab_1">2</ref> shows the AUC scores of all models tested on our dataset. Additional data on accuracy, sensitivity specificity, etc. can be found in the supplementary material. The MPBD-LSTM model outperforms all other models with an AUC score of 0.790. Notably, SimVP <ref type="bibr" target="#b3">[4]</ref> is the only CNN-based model we tested, while all other models are LSTM-based. Our results suggest that LSTM networks are more effective in handling temporal features for our problem compared with CNN-based models. Furthermore, PredRNN-V2 <ref type="bibr" target="#b13">[14]</ref>, which passes memory flow in a zigzag manner of bi-directional hierarchies, outperforms the uni-directional LSTM-based SaConvLSTM <ref type="bibr" target="#b8">[9]</ref>. Although the architecture of PredRNN-V2 is different from MPBD-LSTM, it potentially supports the efficacy of jointly computing spatiotemporal relations in different timestamps. Ablation Study on Model Structures. As shown in Table <ref type="table" target="#tab_2">3</ref>, to evaluate the effectiveness of multi-plane and bi-directional connections, we performed ablation studies on both structures. First, we removed the multi-plane structure and concatenated the A and V phases as input. This produced a one-dimensional bi-directional LSTM (Fig. <ref type="figure" target="#fig_1">2</ref>(a), without the gray plane) with an input dimension of 3 × 128 × 64 × 64, which is the same as we used on other models. The resulting AUC score of 0.774 is lower than the original model's score of 0.790, indicating that computing two phases in parallel is more effective than simply concatenating them. After this, we performed an ablation study to assess the effectiveness of the bi-directional connection. By replacing the bi-directional connection with a uni-directional connection, the MPBD-LSTM model's performance decreased to 0.768 on the original dataset. This result indicates that the bi-directional connection is crucial for computing temporal information effectively, and its inclusion is essential for achieving high performance in MPBD-LSTM. Also, as mentioned previously, we initially connected the 3D-LSTM modules in two planes with their hidden states. However, as shown in Table <ref type="table" target="#tab_2">3</ref>, we observed that inter-plane connections actually decreased our AUC score to 0.786 compared to 0.790 without the connections. This may be due to the fact that when taking CT scans with contrast, different phases have a distinct focus, showing different blood vessels as seen in Fig. <ref type="figure" target="#fig_0">1</ref>. Connecting them with hidden states in the early layers could disrupt feature extraction for the current phase. Therefore, we removed the inter-plane connections in the early stage, since their hidden states are still added together and averaged after they are processed by the LSTM layers. Ablation Study on Timestamps and Phases. We conducted ablation studies using CT images from different timestamps and phases to evaluate the effectiveness of time-series data and multi-phase data. The results, as shown in Table <ref type="table" target="#tab_3">4</ref>, indicate that MPBD-LSTM achieves AUC scores of 0.660, 0.676, and 0.709 if only images from timestamps T0, T1, and T2 are used, respectively. These scores suggest that predicting CRLM at earlier stages is more challenging since the features about potential metastases in CT images get more significant over time. However, all of these scores are significantly lower than the result using CT images from all timestamps. This confirms the effectiveness of using a time-series predictive model. Additionally, MPBD-LSTM obtains AUC scores of 0.653 and 0.752 on single A and V phases, respectively. These results suggest that the V phase is more effective when predicting CRLM, which is consistent with medical knowledge <ref type="bibr" target="#b14">[15]</ref>. However, both of these scores are lower than the result of combining two phases, indicating that a multi-phase approach is more useful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Discussion</head><p>Error Analysis. In Fig. <ref type="figure" target="#fig_0">1</ref>, Patients B and C are diagnosed with positive CRLM later. MPBD-LSTM correctly yields a positive prediction for Patient B with a confidence of 0.82, but incorrectly yields a negative prediction for Patient C with a confidence of 0.77. With similar confidence in the two cases, the error is likely due to the relatively smaller liver size of Patient C. Beyond this case, we find that small liver size is also present in most of the false negative cases. A possible explanation would be that smaller liver may provide less information for accurate prediction of CRLM. How to effectively address inter-patient variability in the dataset, perhaps by better fusing the 5D features, requires further research from the community in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we put forward a 5D CECT dataset for CRLM prediction. Based on the popular E3D-LSTM model, we established MPBD-LSTM model by replacing the uni-directional connection with the bi-directional connection to better capture the temporal information in the CECT dataset. Moreover, we used a multiplane structure to incorporate the additional phase dimension. MPBD-LSTM achieves the highest AUC score of 0.790 among state-of-the-art approaches. Further research is still needed to improve the AUC.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Representative slices from 3D CT images of different patients in our dataset, at A/V phases and timestamps T0, T1, T2 (cropped to 256 × 256 for better view).</figDesc><graphic coords="3,58,98,118,61,334,51,156,61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. (a) The general structure of MPBD-LSTM. The yellow plane is the 1st plane which is used to process the portal venous phase CT scans, and the gray plane is the second one used to process the arterial phase CT scans. μ is the average function. (b) The inner structure of a 3D-LSTM module. Blue arrow stands for the forward pass which generates the output of -→ h v,t 0 and red arrow indicates the backward pass generating the output of ←h v,t 0 . σ is the function used to combine two hidden-state outputs. yv,t 0 is the output of this 3D-LSTM module after processed by σ. (Color figure online)</figDesc><graphic coords="4,49,14,317,93,330,64,158,92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Characreristics of our dataset</figDesc><table><row><cell cols="5">Cohort # of positive cases # of negative cases total cases positive rate</cell></row><row><cell>1st</cell><cell>60</cell><cell>141</cell><cell>201</cell><cell>0.299</cell></row><row><cell>2nd</cell><cell>9</cell><cell>59</cell><cell>68</cell><cell>0.132</cell></row><row><cell cols="2">Total 69</cell><cell>200</cell><cell>269</cell><cell>0.257</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>AUC scores of different models on our dataset</figDesc><table><row><cell>Model</cell><cell>AUC score</cell></row><row><cell>E3D-LSTM [12]</cell><cell>0.755</cell></row><row><cell cols="2">SaConvLSTM [9] 0.721</cell></row><row><cell cols="2">PredRNN-V2 [14] 0.765</cell></row><row><cell>SimVP [4]</cell><cell>0.662</cell></row><row><cell>MPBD-LSTM</cell><cell>0.790</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Ablation study on bi-directional connection and multi-planes</figDesc><table><row><cell>Model</cell><cell>AUC score</cell></row><row><cell>MPBD-LSTM w/o multi-plane</cell><cell>0.774</cell></row><row><cell cols="2">MPBD-LSTM w/o bi-directional connection 0.768</cell></row><row><cell>MPBD-LSTM w/inter-plane connections</cell><cell>0.786</cell></row><row><cell>MPBD-LSTM</cell><cell>0.790</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Ablation study on timestamps and phases</figDesc><table><row><cell>Model structure</cell><cell>AUC score</cell></row><row><cell>MPBD-LSTM @ T0</cell><cell>0.660</cell></row><row><cell>MPBD-LSTM @ T1</cell><cell>0.676</cell></row><row><cell>MPBD-LSTM @ T2</cell><cell>0.709</cell></row><row><cell cols="2">MPBD-LSTM @ all timestamps w/only A phase 0.653</cell></row><row><cell cols="2">MPBD-LSTM @ all timestamps w/only V phase 0.752</cell></row><row><cell>MPBD-LSTM @ All 3 timestamps</cell><cell>0.790</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43987-2 37.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Do deep nets really need to be deep?</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Combining fully convolutional and recurrent neural networks for 3D biomedical image segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Z</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Deep bidirectional and unidirectional LSTM recurrent neural network for network-wide traffic speed prediction</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.02143</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">SimVP: simpler yet better video prediction</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="3170" to="3180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Simple copy-paste is a strong data augmentation method for instance segmentation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Ghiasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2918" to="2928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Predicting metachronous liver metastasis in patients with colorectal cancer: development and assessment of a new nomogram</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">World J. Surg. Oncol</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">80</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Bidirectional RNN-based few shot learning for 3D medical image segmentation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chikontwe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1808" to="1816" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: a method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Self-attention ConvLSTM for spatiotemporal prediction</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="11531" to="11538" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Ct scan</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesus</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">StatPearls</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>StatPearls Publishing</publisher>
		</imprint>
	</monogr>
	<note>Internet</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Convolutional lstm network: a machine learning approach for precipitation nowcasting</title>
		<author>
			<persName><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Y</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">C</forename><surname>Woo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Eidetic 3D LSTM: a model for video prediction and beyond</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">PreDRNN: recurrent neural networks for predictive learning using spatiotemporal LSTMs</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">PredRNN: a recurrent neural network for spatiotemporal predictive learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Imaging diagnosis of colorectal liver metastases</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">X</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">World J. Gastroenterol: WJG</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">42</biblScope>
			<biblScope unit="page">4654</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Emerging role of immunotherapy for colorectal cancer with liver metastasis</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Onco. Targets. Ther</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">11645</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.09412</idno>
		<title level="m">mixup: beyond empirical risk minimization</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Uniformizing techniques to process CT scans with 3D CNNs for tuberculosis prediction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zunair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mohammed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59354-4_15</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-59354-415" />
	</analytic>
	<monogr>
		<title level="m">PRIME 2020</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Rekik</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Adeli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Park</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Valdés Hernández</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12329</biblScope>
			<biblScope unit="page" from="156" to="168" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
