<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Transferability-Guided Multi-source Model Adaptation for Medical Image Segmentation</title>
				<funder ref="#_2XrDJTH #_3UVuch9">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Chen</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution">City University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">SAR</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yifan</forename><surname>Liu</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Electronic Engineering</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">SAR</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Yixuan</forename><surname>Yuan</surname></persName>
							<email>yxyuan@ee.cuhk.edu.hk</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Electronic Engineering</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">SAR</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Transferability-Guided Multi-source Model Adaptation for Medical Image Segmentation</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="703" to="712"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">756F46BAE3F14587C9FC7D1D00DA6DE8</idno>
					<idno type="DOI">10.1007/978-3-031-43895-0_66</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-24T10:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Source-free Domain Adaptation</term>
					<term>Multi-source</term>
					<term>Label-free transferability metric</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Unsupervised domain adaptation has drawn sustained attentions in medical image segmentation by transferring knowledge from labeled source data to unlabeled target domain. However, most existing approaches assume the source data are collected from a single client, which cannot be successfully applied to explore complementary transferable knowledge from multiple source domains with large distribution discrepancy. Moreover, they require access to source data during training, which is inefficient and unpractical due to privacy preservation and memory storage. To address these challenges, we study a novel and practical problem, named multi-source model adaptation (MSMA), which aims to transfer multiple source models to the unlabeled target domain without any source data. Since no target label and source data is provided to evaluate the transferability of each source model or domain gap between the source and the target domain, we may encounter negative transfer by those less related source domains, thus hurting target performance.</p><p>To solve this problem, we propose a transferability-guided model adaptation (TGMA) framework to eliminate negative transfer. Specifically, 1) A label-free transferability metric (LFTM) is designed to evaluate transferability of source models without target annotations for the first time.</p><p>2) Based on the designed metric, we compute instance-level transferability matrix (ITM) for target pseudo label correction and domain-level transferability matrix (DTM) to achieve model selection for better target model initialization. Extensive experiments on multi-site prostate segmentation dataset demonstrate the superiority of our framework.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Deep neural networks have greatly advanced medical image analysis in recent years <ref type="bibr" target="#b11">[12]</ref>. However, a large amount of annotated data is required for training, which is time-consuming and error-prone, especially in medical image segmentation task that needs pixel-wise annotations. Moreover, a segmentation model trained on one clinical centre (source domain) often fails to generalize well when deployed in a new centre (target domain) due to the discrepancy in the data distribution <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b15">16]</ref>. Unsupervised domain adaptation (UDA) <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b16">17]</ref> seeks to tackle this dilemma by transferring the knowledge from label-rich source domain to label-rare target domain. However, the source data may become inaccessible due to storage and privacy concerns in medical settings, which hinders the wide applications of domain adaptation. Towards this obstacle, great interests have been invoked to explore source-free domain adaptation (SFDA) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b15">16]</ref>, where a model pre-trained on the labeled source data are adapted to the unlabeled target domain without accessing source data. Though great successes, how to achieve adaptation to the unlabeled target domain with the knowledge from multiple source domains under privacy protection is still an open question to be solved.</p><p>To this end, we study a practical and challenging domain adaptation problem which explores transferable knowledge from multiple source domains to target domain with only pre-trained source models rather than the source data, namely multi-source model adaptation (MSMA). Although MSMA methods <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b6">7]</ref> have made great progress for natural object recognition, there is still a blank in the multi-source-free domain adaptive medical image segmentation. Directly applying existing MSMA methods on medical image segmentation by optimizing all source segmentation models are time-consuming and inefficient due to larger model capacity of segmentation model than classification model. Another trivial solutions to tackle MSMA via SFDA methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b17">18]</ref> are to adapt each source model individually and simply take an average prediction of adapted models. However, this strategy does not take into account the varying contributions of different source models to the target domain, which can result in negative transfer from less related source domains. To rank pre-trained models, transferability metrics <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b19">20]</ref> have been widely applied to measure the domain relevance or task relevance for transfer learning, but all of them need target annotations, which is not accessible for multi-source model adaptation. Automatically select an optimal subset of the source models without requiring source data and target annotations in an unsupervised fashion is of far-reaching significance for MSMA.</p><p>To address this problem, we develop a novel Transferability-Guided Model Adaptation (TGMA) model, which represents the first attempt to solve MSMA in medical image segmentation. Specifically, a label-free transferability metric (LFTM) is designed to evaluate the relevance between source and target domain without access to the source data. Based on the designed LFTM, we can compute instance-level transferability matrix (ITM) to achieve pseudo-label correction for precise supervision, and domain-level transferability matrix (DTM) to accomplish model selection for better target initialization. To this end, we can achieve adaptation to unlabeled target domain with clean pseudo label and proper model initialization. The main contributions are summarized as: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>In MSMA scenario, we address the problem of jointly adapting multiple segmentation models, trained on a variety domains, to a new unlabeled target domain. Formally, let us consider we have a set of source models {F sj } M j=1 , where the j th model {F sj } is a segmentation model learned using the source dataset</p><formula xml:id="formula_0">D j s = {x i sj , y i sj } Nj i=1</formula><p>, with N j data points, where x i sj and y i sj denote the i-th source image and the corresponding segmentation label respectively. Now, given a target unlabeled dataset D t = {x t i } Nt i=1 , the problem is to learn a segmentation model F t , using only the learned source models, without any access to the source dataset. Figure <ref type="figure" target="#fig_0">1</ref> gives an overview of our proposed TGMA framework.</p><p>To eliminate negative transfer by domain-dissimilar source models, we design a label-free transferability metric to evaluate the transferability of source models in an unsupervised manner for the first time. Before target training, an instancelevel transferability matrix (ITM) is computed to rectify target pseudo labels, and a domain-level transferability matrix (DTM) is calculated to achieve model selection for better model initialization. Based on the rectified pseudo labels and selected models, target segmentation model is trained with dice loss to achieve model adaptation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Label-Free Transferability Metric</head><p>Most of multi-source model adaptation approaches <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b6">7]</ref> treat all source models equally, leading to negative transfer from irrelevant source domains. To avoid this type of negative transfer, it is important to critically evaluate the relevance of prior knowledge from each source domain to the target domain, and to focus on the most relevant source domains for learning in the target domain. However, it's challenging to evaluate the domain relevance in the absence of source data and target ground truths. To identify the transferability of source models, we develop a label-free transferability metric (LFTM) on the basis of attentive masking consistency to prevent negative transfer for the first time. Our metric is designed based on two assumptions: 1) Sample relevance: similar samples should hold identical predictions; 2) Model stability: if a source model makes accurate decision on this sample, little permutation on irrelevant regions will not influence the prediction. We follow these two assumptions to construct augmented sample by attentive masking, and compute the consistency as the transferability.</p><p>Given unlabeled target data D t = {x i t } N i=1 and a pre-trained source segmentation model F s k , we import them to the LFTM estimator and compute the transferability metric LF T M (x t , F s k ) with only twice forwards as shown in Fig. <ref type="figure" target="#fig_0">1</ref>. In the first forward process, the original target sample x t is passed into the source model F s k to generate segmentation map P s k = F s k (x t ). Based on the assumption that masking the normal regions from the diseased image will not affect the lesion regions, we preserve the segmentation region of the original image and randomly mask the other regions to generate masked image x m k t . Since the segmentation results may be affected by receptive field, we enlarge the segmentation map P s k to D(P s k ) by dilation. Then masked image x mt t is generated by combination of enlarged lesion regions and masked normal regions:</p><formula xml:id="formula_1">x m k t = M (x t ) * (1 -D(P s k )) + x t * D(P s k ),<label>(1)</label></formula><p>where M (x t ) is the masking operation to randomly remove pixels. In the second forward process, the masked target sample x m k t is passed into the source model</p><formula xml:id="formula_2">F s k to generate segmentation map Ps k = F s k (x m k t ).</formula><p>Then we calculate the dice score between these two predictions as transferability metric:</p><formula xml:id="formula_3">LF T M (x t , F s k ) = 2 * P s k ∩ Ps k P s k + Ps k . (<label>2</label></formula><formula xml:id="formula_4">)</formula><p>The larger the LFTM is, the more stable the source model is on the target sample. With M source models and N t target samples, we can compute the instance-level transferability matrix (ITM) T instance ∈ R M ×Nt , which can be utilized to correct target pseudo labels. Averaging T instance on the domain-space can generate domain-level transferability matrix (DTM) T domain ∈ R M ×1 , which represents the contribution of each source model to the target domain. The detailed process is illustrated in Transferability Matrix Estimation of Fig. <ref type="figure" target="#fig_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Transferability-Guided Model Adaptation</head><p>The basic pipeline for target training needs accurate pseudo labels and suitable model initialization. While there are multiple pseudo labels and source models, simply averaging them as target supervision and model initialization is trivial solution, which ignores the contribution differences of these source domains.</p><p>To tackle this problem, we propose a transferability-guided model adaptation (TGMA) framework on the basis of LFTM, which consists of two modules: Label Correction and Model Selection. Based on the instance-level transferability matrix T instance , we re-weight the pseudo labels generated by multiple source models to achieve pseudo label correction. With the domain-level transferability matrix T domain , we select the most portable source model as the main model initialization and make full use of other source models by weighted optimization strategy.</p><p>Transferability-Guided Label Correction. In MSMA, we generate pseudo labels as supervision because no target ground truth is available. However, with multiple pseudo labels predicted by source models for a target sample, prior works <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b6">7]</ref> typically average these labels equally to obtain the final pseudo label. However, negative source models that are poorly suited to the target domain may generate inaccurate pseudo labels, resulting in noisy or unreliable training data. To eliminate negative transfer and improve pseudo-label correction, we can re-weight model predictions from all source models using the calculated instance-level transferability matrix T instance .</p><p>Taking a target sample x t for example, we pass this sample to source models {F s1 , F s2 , ..., F sM } to obtain corresponding predictions {P s1 , P s2 , ..., P sM }. We take argmax operation on these predictions to generate one-hot pseudo labels {y s1 , y s2 , ..., y sM }, where y = argmax(P ). The instance-level transferability matrix T instance is applied on these pseudo labels to achieve noise correction by contribution re-weighting:</p><formula xml:id="formula_5">y t = argmax( M i=1 LF T M (x t , F si ) * y si ),<label>(3)</label></formula><p>where each pseudo label is weighted by the corresponding LFTM score for better combination. This strategy largely prevents the negative transfer problem caused by noisy labels of those domain-irrelevant source models.</p><p>Transferability-Guided Model Selection. Previous MSMA methods <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b6">7]</ref> usually treat all models equally and optimize all source models parameters to achieve adaptation to the target domain. On the one hand, they ignore the negative transfer problem led by some less related domains. On the other hand, optimizing all source parameters is time-consuming and inefficient. To better make full use of the source models, we utilize the calculated domain-level transferability matrix T domain to rank all source models. With T domain representing the transferability of source models, we choose the best source model as main network F main and the second best model as auxiliary network F aux . Only initialing the target model from F main may ignore complementary knowledge of other source models, while optimizing all source models are inefficient. To obtain a compromise solution, we take the second model as auxiliary parameter knowledge. Then a weighted optimization strategy is utilized on the best model and the auxiliary model with weight W main and W aul respectively:</p><formula xml:id="formula_6">F t = min F ∩W L dice (y t , W main * F main (x t ) + W aux * F aux (x t )),<label>(4)</label></formula><p>where L dice is calculated on the combined target prediction and corresponding pseudo label. This loss optimizes model parameter W main * F main + W aux * F aux . The model selection strategy choose optimal source model while makes full use of those sub-optimal source models for better model initialization, thus avoiding the negative transfer by those domain-irrelevant domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset</head><p>Extensive experiments are conducted to verify the effectiveness of our proposed framework on Prostate MR (PMR) dataset which is collected and labeled from six different public data sources for prostate segmentation <ref type="bibr" target="#b14">[15]</ref>. All of the MRI images have been re-sampled to the same spacing and centercropped with the size of 384 × 384. We divide them into six sites, each of which contains {261, 384, 158, 468, 421, 175} slices. We denote these six sites as {A, B, C, D, E, F } for convenience. At each adaptation process, five sites are selected as source domains and the rest one is set as the target domain. We conduct leave-one-domain-out experiments by selecting one domain to hold out as the target. For example, → A denotes adapting source models from {B, C, D, E, F } to unlabeled images of A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Implementation Details and Evaluation Metrics</head><p>The framework is implemented with Pytorch 1.7.0 using an NVIDIA RTX 2080Ti GPU. Following <ref type="bibr" target="#b14">[15]</ref>, we adopt UNet as our segmentation backbone. We train the target model for 200 epochs with the batch size of 6. Adam optimizer is adopted with the momentum of 0.9 and 0.999, and the learning rate is set to 0.001. We adopt the well-known metrics Dice score for segmentation evaluation.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Comparison with State-of-the-Arts</head><p>We compare our methods to several domain adaptation frameworks, including the single source-free domain adaptation (SFDA) <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b17">18]</ref>, multi-source domain adaptation (MSDA) <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b20">21]</ref> and multi-source model adaptation (MSMA) <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b6">7]</ref> methods. For implementation, as most of these methods are originally designed for the image classification task, we try out best to keep their design principle and adapt them to our image segmentation task. Specifically, SFDA methods are performed on each source model and averaging the adapted model predictions as the final results. The results on prostate segmentation is listed in Table <ref type="table" target="#tab_0">1</ref>. As observed, MSDA methods shows superior performance than MSMA approaches due to access to the source data. Notably, compared with SFDA and MSMA approaches, our TGMA achieves higher performance on nearly all metrics with 67.32% on Average Dice. These clear improvements benefit from our LFTM metric which considers the different contributions of each source model, and largely eliminate negative transfer from the perspective of pseudo label generation and model initialization. Without the rectification by instance-level transferability matrix (Ours w/o ITM), the pseudo labels are simply generated by average combination of predictions from source models. The significant decrease in performance by 4.38% on Average Dice highlights the criticality of weighting pseudo labels with scores that reflect the relevance of the source domains. Without the model selection by domain-level transferability matrix (Ours w/o DTM), the target models are initialized from each source pre-trained network and trained separately, leading to 2.61% performance drop on Average Dice. It demonstrates that model initialization is also essential to the transfer learning. Moreover, Fig. <ref type="figure" target="#fig_1">2</ref> shows the segmentation results of different methods on two typical cases.</p><p>We observe that our model with transferability guidance can well eliminate the negative transfer interference by some domain-irrelevant domains. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Ablation Analysis</head><p>The performance improvement mainly comes from our designed LFTM to detect negative transfer. There are some other unsupervised metrics that can evaluate model stability, such as entropy, rotation-consistency and crop-consistency. To better evaluate the effectiveness of LFTM, we apply these unsupervised metrics to estimate ITM and DTM for label correction and model selection. The comparison results are shown in Table <ref type="table" target="#tab_1">2</ref>. It's obvious that our proposed LFTM outperforms other unsupervised metrics with a large margin. Entropy may make overconfident decisions on model predictions, thus leading to high transferability on those domain-irrelevant source models. Rotation and Cropping are simple data augmentation methods, which can only evaluate the model stability. Our proposed LFTM makes full use of the segmentation mask to construct featurenearest sample, thus applying sample relevance to evaluate model transferability.</p><p>Removing dilation operation leads to 1.71% performance degradation on Average Dice, revealing the effect of receptive field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we study a practical domain adaptation problem, named multisource model adaptation where only multiple pre-trained source segmentation models rather than the source data are provided for adaptation to unlabeled target domain. To eliminate the negative transfer by domain-dissimilar source models, we design a label-free transferability metric based on the attentive masking consistency to evaluate the transferability of each source segmentation model with only target images. Using this metric, we calculate two types of transferability matrices: an instance-level matrix to adjust the target pseudo label, and a domain-level matrix to choose an optimal subset for improved model initialization.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Illustration of Transferability-Guided multi-source Model Adaptation (TGMA) framework, including (a) label-free transferability metric (LFTM) estimator, (b) transferability-guided model selection and (c) transferability-guided label correction.</figDesc><graphic coords="3,58,98,54,56,334,12,171,16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Qualitative comparison on the PMR dataset of different DA methods.</figDesc><graphic coords="7,81,51,260,99,298,90,99,25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Comparison with state-of-the-art domain adaptation approaches on PMR dataset, measured by dice score.</figDesc><table><row><cell>Type</cell><cell>Method</cell><cell>Source Data → A → B → C → D → E → F Average</cell></row><row><cell></cell><cell>SHOT (20') [6]</cell><cell>28.76 34.32 50.57 31.55 33.60 28.70 34.58</cell></row><row><cell>SFDA</cell><cell>NRC (21') [18]</cell><cell>32.44 38.05 59.39 28.03 40.47 27.35 37.62</cell></row><row><cell></cell><cell>FSM (22') [16]</cell><cell>33.57 38.56 70.72 29.40 36.76 32.52 40.25</cell></row><row><cell></cell><cell>KD3A (21') [4]</cell><cell>38.05 55.78 64.16 31.77 37.69 49.36 46.13</cell></row><row><cell>MSDA</cell><cell>CWAN (21') [19]</cell><cell>51.18 61.96 71.62 75.45 55.88 60.11 62.69</cell></row><row><cell></cell><cell>PTMDA (22') [11]</cell><cell>65.16 68.37 79.05 77.23 61.58 69.42 70.13</cell></row><row><cell></cell><cell>Source only</cell><cell>31.26 39.80 66.95 9.86 14.93 32.77 32.59</cell></row><row><cell></cell><cell>DECISION (22') [1]</cell><cell>48.03 60.72 69.85 71.34 52.94 63.16 61.01</cell></row><row><cell>MSMA</cell><cell>DINE (22') [7] TGMA (Ours)</cell><cell>54.20 62.82 74.11 72.59 53.46 64.78 63.66 62.76 65.73 76.14 75.10 58.59 65.63 67.32</cell></row><row><cell></cell><cell>Ours w/o ITM</cell><cell>56.41 60.65 72.83 71.29 54.42 62.04 62.94</cell></row><row><cell></cell><cell>Ours w/o DTM</cell><cell>59.48 61.56 73.16 73.97 56.85 63.24 64.71</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Comparison with different unsupervised metrics on PMR dataset.</figDesc><table><row><cell>Entropy</cell><cell>57.84 59.03 74.29 72.56 52.37 65.20 63.54</cell></row><row><cell>Rotation</cell><cell>60.46 61.35 73.74 71.82 53.92 62.13 63.90</cell></row><row><cell>Cropping</cell><cell>61.14 62.37 74.59 73.83 55.44 63.05 65.07</cell></row><row><cell>LFTM</cell><cell>62.76 65.73 76.14 75.10 58.59 65.63 67.32</cell></row><row><cell>LFTM w/o Dilation</cell><cell>61.69 63.08 73.95 74.17 56.22 64.54 65.61</cell></row></table><note><p><p><p>Method</p>Source Data</p>→ A → B → C → D → E → F Average</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>c The Author(s), under exclusive license to Springer Nature Switzerland AG 2023 H. Greenspan et al. (Eds.): MICCAI 2023, LNCS 14221, pp. 703-712, 2023. https://doi.org/10.1007/978-3-031-43895-0_66</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This work was supported by <rs type="funder">National Natural Science Foundation of China</rs> <rs type="grantNumber">62001410</rs>, <rs type="grantName">Hong Kong Research Grants Council (RGC) Early Career Scheme grant</rs> <rs type="grantNumber">21207420</rs>, <rs type="programName">General Research Fund 11211221</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_2XrDJTH">
					<idno type="grant-number">62001410</idno>
					<orgName type="grant-name">Hong Kong Research Grants Council (RGC) Early Career Scheme grant</orgName>
				</org>
				<org type="funding" xml:id="_3UVuch9">
					<idno type="grant-number">21207420</idno>
					<orgName type="program" subtype="full">General Research Fund 11211221</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Unsupervised multi-source domain adaptation without access to source data</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Raychaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Oymak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Roy-Chowdhury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="10103" to="10112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Source-free domain adaptation for image segmentation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bateson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kervadec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dolz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lombaert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">B</forename><surname>Ayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page">102617</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Confident anchor-induced multi-source free domain adaptation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural. Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="2848" to="2860" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">KD3A: Unsupervised multi-source decentralized domain adaptation via knowledge distillation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Feng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3274" to="3283" />
		</imprint>
		<respStmt>
			<orgName>ICML</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Domain-adversarial training of neural networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2030" to="2096" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Do we really need to access the source data? source hypothesis transfer for unsupervised domain adaptation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6028" to="6039" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Dine: Domain adaptation from single and multiple black-box predictors</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="8003" to="8013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A source-free domain adaptive polyp detection framework with style diversification flow</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1897" to="1908" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Source-free domain adaptation for semantic segmentation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1215" to="1224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Leep: A new measure to evaluate transferability of learned representations</title>
		<author>
			<persName><forename type="first">C</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hassner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Seeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Archambeau</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7294" to="7305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multi-source unsupervised domain adaptation via pseudo target domain</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="2122" to="2135" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">U-Net: convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-24574-4_28</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-24574-4_28" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2015</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hornegger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">9351</biblScope>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Transferability and hardness of supervised classification tasks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hassner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1395" to="1405" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Adversarial discriminative domain adaptation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="7167" to="7176" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Personalizing federated medical image segmentation via local calibration</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-19803-8_27</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-19803-8_27" />
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2022: 17th European Conference</title>
		<meeting><address><addrLine>Tel Aviv, Israel</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">October 23-27, 2022. 2022</date>
			<biblScope unit="page" from="456" to="472" />
		</imprint>
	</monogr>
	<note>Proceedings, Part XXI</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Source free domain adaptation for medical image segmentation with Fourier style mining</title>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page">102457</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Mutual-prototype adaptation for cross-domain polyp segmentation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ibragimov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<idno type="DOI">10.1109/JBHI.2021.3077271</idno>
		<ptr target="https://doi.org/10.1109/JBHI.2021.3077271" />
	</analytic>
	<monogr>
		<title level="j">IEEE J. Biomed. Health Inform</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3886" to="3897" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Exploiting the intrinsic neighborhood structure for source-free domain adaptation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Van De Weijer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Herranz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural. Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="29393" to="29405" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Multisource heterogeneous domain adaptation with conditional weighting adversarial network</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Logme: practical assessment of pre-trained models for transfer learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="12133" to="12143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Multi-source distilling domain adaptation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="12975" to="12983" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
