title,extracted_keyword_sent
Anatomy-Driven Pathology Detection on Chest X-rays,training dataset.
Anatomy-Driven Pathology Detection on Chest X-rays,"we train on the chest imagenome dataset [4,21,22]1 ,
consisting of roughly 240 000 frontal chest x-ray images with corresponding
scene graphs automatically constructed from free-text radiology reports."
Anatomy-Driven Pathology Detection on Chest X-rays,"it is
derived from the mimic-cxr dataset [9,10], which is based on imaging studies
from 65 079 patients performed at beth israel deaconess medical center in
boston, us."
Anatomy-Driven Pathology Detection on Chest X-rays,"we consider the image-level label for a pathology to be positive if
any region is positively labeled with that pathology.we use the provided
jpg-images [11] 2 and follow the official mimic-cxr training split but only keep
samples containing a scene graph with at least five valid region bounding boxes,
resulting in a total of 234 307 training samples.during training, we use random
resized cropping with size 224 × 224, apply contrast and brightness jittering,
random affine augmentations, and gaussian blurring.evaluation dataset and class
mapping."
Anatomy-Driven Pathology Detection on Chest X-rays,"we evaluate our method on the subset of 882 chest x-ray images with
pathology bounding boxes, annotated by radiologists, from the nih chestxray-8
(cxr8) dataset [20] 3 from the national institutes of health clinical center in
the us."
Anatomy-Driven Pathology Detection on Chest X-rays,"all images are center-cropped
and resized to 224 × 224.the dataset contains bounding boxes for 8 unique
pathologies."
Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET,the dataset is composed of 23 oncological patients with different tumor types.
Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET,"the dataset included the label maps of 7 organs
(bones, lungs, heart, liver, kidneys, spleen, aorta) and one image-derived input
function a(t) [bq/ml] from the descending aorta per patient."
Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET,"further details on
the dataset are presented elsewhere [16].the pet frames and the label map were
resampled to an isotropic voxel size of 2.5 mm."
Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET,"then, the dataset was split
patient-wise into training, validation, and test set, with 10, 4, and 9 patients
respectively."
Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET,"details on the dataset split are available in the supplementary
material (table 1)."
AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor,"we then use an
attention model to hierarchically aggregate these activation maps, learning
pixel-wise weighted sums.experimental results on the four modalities of the 2021
brats dataset demonstrate the superiority of our approach compared with other
cam-based weakly-supervised segmentation methods."
AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor,"specifically, ame-cam achieves
the highest dice score for all patients in all datasets and modalities."
Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"this is the public lihc
dataset from the cancer genome atlas [9], which presents a histological score,
the ishak score, designated as y 2 histo , that differs from the metavir score
present in d 1 histo ."
Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"similarly to the metavir score in d 1 histo
, we also binarize the ishak score, as proposed in [16,20], which results in two
cohorts of 34 healthy and 15 pathological patients.in all datasets, we select
the slices based on the liver segmentation of the patients."
Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"for the
latter pretraining dataset, it presents an average slice spacing of 3.23 mm with
a standard deviation of 1.29 mm."
Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"then, we train a regularized logistic regression on the frozen
representations of the datasets d 1 histo and d 2 histo ."
Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"as a baseline, we train a classification algorithm from
scratch (supervised) for each dataset, d 1 histo and d 2 histo , using both
backbone encoders and the same 5-fold crossvalidation strategy."
Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"finally, we report the
cross-validated results for each model on the aggregated dataset we present in
table 1 the results of all our experiments."
Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"first, we can
notice that our method outperforms all other pretraining methods in d 1 histo
and d 1+2 histo , which are the two datasets with more patients."
Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"for the second dataset d 2 histo , our method
is on par with byol and supcon when using a small encoder and outperforms the
other methods when using a larger backbone.to illustrate the impact of the
proposed method, we report in fig."
S 2 ME: Spatial-Spectral Mutual Teaching and Ensemble Learning for Scribble-Supervised Polyp Segmentation,datasets.
S 2 ME: Spatial-Spectral Mutual Teaching and Ensemble Learning for Scribble-Supervised Polyp Segmentation,"we employ the sun-seg [10] dataset with scribble annotations for
training and assessing the in-distribution performance."
S 2 ME: Spatial-Spectral Mutual Teaching and Ensemble Learning for Scribble-Supervised Polyp Segmentation,"this dataset is based on
the sun database [16], which contains 100 different polyp video cases."
S 2 ME: Spatial-Spectral Mutual Teaching and Ensemble Learning for Scribble-Supervised Polyp Segmentation,"for out-of-distribution evaluation, we utilize
three public datasets, namely kvasir-seg [9], cvc-clinicdb [2], and polypgen [1]
with 1000, 612, and 1537 polyp frames, respectively."
S 2 ME: Spatial-Spectral Mutual Teaching and Ensemble Learning for Scribble-Supervised Polyp Segmentation,"these datasets are
collected from diversified patients in multiple medical centers with various
data acquisition systems."
Tracking Adaptation to Improve SuperPoint for 3D Reconstruction in Endoscopy,none
Black-box Domain Adaptative Cell Segmentation via Multi-source Distillation,"dataset and setting: we collect four pathology image datasets to validate our
proposed approach."
Black-box Domain Adaptative Cell Segmentation via Multi-source Distillation,"[10] publish a dataset of nucleus segmentation containing 5,060
segmented slides from 10 tcga cancer types."
Black-box Domain Adaptative Cell Segmentation via Multi-source Distillation,"we have also included 463 images of
kidney renal clear cell carcinoma (kirc) in our dataset, which are made publicly
available by irshad et al [11]."
Black-box Domain Adaptative Cell Segmentation via Multi-source Distillation,"[2] publicly release a dataset
containing tissue slide images and associated clinical data on colorectal cancer
(crc), from which we randomly select 200 patches for our study."
Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning,"yet, acquiring large training datasets and
their corresponding labels, especially from a cohort of patients, can be costly
or even infeasible, which poses a significant challenge in developing a dl model
with high performance [7]."
Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning,"second, even when large-scale datasets are available
through collaborative research from multiple sites, dl models trained on such
datasets may yield sub-optimal solutions due to domain gaps caused by
differences in images acquired from different sites [20]."
Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning,"third, due to the
small number of datasets from each domain, the images for each individual domain
may not capture representative features, limiting the ability of dl models to
generalize across domains [3].domain adaptation (da) has been extensively
studied to alleviate the aforementioned limitations, the goal of which is to
reduce the domain gap caused by the diversity of datasets from different domains
[12,20,26,29,33]."
3D Arterial Segmentation via Single 2D Projections and Depth Supervision in Contrast-Enhanced CT Images,dataset.
3D Arterial Segmentation via Single 2D Projections and Depth Supervision in Contrast-Enhanced CT Images,"we use an in-house dataset of contrast-enhanced abdominal computed
tomography images (cts) in the arterial phase to segment the peripancreatic
arteries [6]."
3D Arterial Segmentation via Single 2D Projections and Depth Supervision in Contrast-Enhanced CT Images,"the dataset contains binary 3d
annotations of the peripancreatic arteries carried out by two radiologists, each
having annotated half of the dataset."
3D Arterial Segmentation via Single 2D Projections and Depth Supervision in Contrast-Enhanced CT Images,"for more information about
the dataset, see [6].image augmentation and transformation."
Mesh2SSM: From Surface Meshes to Statistical Shape Models of Anatomy,"dataset: we use the publicly available decath-pancreas dataset of 273
segmentations from patients who underwent pancreatic mass resection [24]."
Mesh2SSM: From Surface Meshes to Statistical Shape Models of Anatomy,"although the dgcnn mesh autoencoder used in mesh2ssm does not require
the same number of vertices, uniformity across the dataset makes it
computationally efficient; hence, we pad the smallest mesh by randomly repeating
the vertices (akin to padding image for convolutions)."
Infusing Physically Inspired Known Operators in Deep Models of Ultrasound Elastography,"we use publicly available data collected from a breast phantom (model 059, cirs:
tissue simulation & phantom technology, norfolk, va) using an alpinion e-cube
r12 research us machine (bothell, wa, usa)."
Infusing Physically Inspired Known Operators in Deep Models of Ultrasound Elastography,"we selected 600 rf frame
pairs of this dataset for the training of the networks.two well-known metrics of
contrast to noise ratio (cnr) and strain ratio (sr) are utilized to evaluate the
compared methods."
SLPD: Slide-Level Prototypical Distillation for WSIs,"meanwhile, this clustering strategy ignores the
hierarchical structure ""region→wsi→whole dataset"" underlying the data, where the
id of the wsi can be served as an extra learning signal."
SLPD: Slide-Level Prototypical Distillation for WSIs,"specifically, for a region embedding z belonging to the slide w and
assigned to the prototype c, we first search the top-k nearest neighbors of w in
the dataset based on the semantic similarity, denoted as { ŵk } k k=1 ."
Many Tasks Make Light Work: Learning to Localise Medical Anomalies from Multiple Synthetic Tasks,none
VesselVAE: Recursive Variational Autoencoders for 3D Blood Vessel Synthesis,"we trained our networks using a subset of the open-access intra
dataset1 published by yang et al."
VesselVAE: Recursive Variational Autoencoders for 3D Blood Vessel Synthesis,"by using these metrics,
we can determine how well the generated 3d models of blood vessels match the
original dataset distribution, as well as the diversity of the generated output."
DAS-MIL: Distilling Across Scales for MIL Classification of Histological WSIs,"our proposal has proven its
effectiveness on two well-known histological datasets, camelyon16 and tcga lung
cancer, obtaining state-of-the-art results on wsi classification."
Spectral Adversarial MixUp for Few-Shot Unsupervised Domain Adaptation,"to solve this problem, many unsupervised domain
adaptation (uda) methods [6] have been developed for adapting a model to a new
site with only unlabeled data (target domain) by transferring the knowledge
learned from the original dataset (source domain)."
Spectral Adversarial MixUp for Few-Shot Unsupervised Domain Adaptation,"previous studies [7,10,24,25] have demonstrated that transferring
the amplitude spectrum of target domain images to a source domain can
effectively convey image style information and diversify training dataset."
Gall Bladder Cancer Detection from US Images with only Image Level Labels,"this makes it expensive and
non-viable for curating large datasets for training large dnn models."
Gall Bladder Cancer Detection from US Images with only Image Level Labels,"gallbladder cancer detection in ultrasound images: we use the public gbc us
dataset [3] consisting of 1255 image samples from 218 patients."
Gall Bladder Cancer Detection from US Images with only Image Level Labels,"the dataset
contains 990 non-malignant (171 patients) and 265 malignant (47 patients) gb
images (see fig."
Gall Bladder Cancer Detection from US Images with only Image Level Labels,"the dataset contains image labels as
well as bounding box annotations showing the malignant regions.note that, we use
only the image labels for training."
Gall Bladder Cancer Detection from US Images with only Image Level Labels,"polyp detection in colonoscopy images: we use the publicly available kvasir-seg
[17] dataset consisting of 1000 white light colonoscopy images showing polyps
(see fig."
Gall Bladder Cancer Detection from US Images with only Image Level Labels,"since kvasir-seg does not contain any control images, we add 600
non-polyp images randomly sampled from the polypgen [1] dataset.since the
patient information is not available with the data, we use random stratified
splitting for 5-fold cross-validation."
Structured State Space Models for Multiple Instance Learning in Digital Pathology,"extensive experiments on three publicly available datasets show the potential of
such models for the processing of gigapixel-sized images, under both weakly and
multi-task schemes."
Structured State Space Models for Multiple Instance Learning in Digital Pathology,"camelyon16 [16] is a dataset that consists of resections of lymph nodes, where
each wsi is annotated with a binary label indicating the presence of tumour
tissue in the slide, and all slides containing tumors have a pixel-level
annotation indicating the metastatic region."
Structured State Space Models for Multiple Instance Learning in Digital Pathology,"in our experiments, the average patch sequence length
arising from camelyon16 is 6129 (ranging from 127 to 27444).tcga-luad is a tcga
lung adenocarcinoma dataset that contains 541 wsis along with genetic
information about each patient."
Structured State Space Models for Multiple Instance Learning in Digital Pathology,"the average sequence length is 10557 (ranging from 85 to
34560).tcga-rcc is a tcga dataset for three kidney cancer subtypes (denoted
kich, kirc, and kirp)."
Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision,"this information can be leveraged to assess treatment response, e.g., by
analyzing the evolution of size and morphology for a given tumor [1], but also
for adaptation of (re-)treatment radiotherapy plans that take into account new
tumors.in practice, the development of automatic and reliable lesion tracking
solutions is hindered by the complexity of the data (over different modalities),
the absence of large, annotated datasets, and the difficulties associated with
lesion identification (i.e., varying sizes, poses, shapes, and sparsely
distributed locations)."
Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision,"furthermore, a significant focus and contribution of our research is
the experimental study at a very large scale: we (1) train a pixel-wise
self-supervised system using a very large and diverse dataset of 52,487 ct
volumes and (2) evaluate on two publicly available datasets."
Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision,"notably, one of the
datasets, nlst, presents challenging cases with 68% of lesions being very small
(i.e., radius < 5 mm)."
Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision,"datasets: we train the universal and fine-grained anatomical point matching
model using an in-house ct dataset (variousct)."
Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision,"the training dataset contains
52,487 unlabeled 3d ct volumes capturing various anatomies, including chest,
head, abdomen, pelvis, and more.the evaluation is based on two datasets, the
publicly released deep longitudinal study (dls) dataset [8] and the national
lung screening trial (nlst) dataset [12]."
Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision,"the dls dataset is a subset of the
deeplesion [11] medical imaging dataset, containing 3891 pairs of lesions with
information on their location and size."
Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision,"the dataset covers various types of
lesions across different organs."
Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision,"we follow the official data split for dls
dataset and perform evaluation on the testing dataset which comprises 480 lesion
pairs."
Geometry-Invariant Abnormality Detection,none
Interpretable Medical Image Classification Using Prototype Learning and Privileged Information,"the proposed approach is evaluated using the publicly available lidc-idri
dataset consisting of 1018 clinical thoracic ct scans from patients with
non-small cell lung cancer (nsclc) [2,3]."
Interpretable Medical Image Classification Using Prototype Learning and Privileged Information,"the code is publicly
available at https://github.com/xrad-ulm/proto-caps.besides pure performance,
the effect of reduced availability of attribute annotations was investigated."
Longitudinal Multimodal Transformer Integrating Imaging and Latent Clinical Signatures from Routine EHRs for Pulmonary Nodule Classification,datasets.
Longitudinal Multimodal Transformer Integrating Imaging and Latent Clinical Signatures from Routine EHRs for Pulmonary Nodule Classification,"next, ehr-pulmonary was the
unlabeled dataset used to learn clinical signatures in an unsupervised manner."
Longitudinal Multimodal Transformer Integrating Imaging and Latent Clinical Signatures from Routine EHRs for Pulmonary Nodule Classification,"additionally, image-ehr was a labeled dataset
with paired imaging and ehrs."
Centroid-Aware Feature Recalibration for Cancer Grading in Pathology Images,"the experimental results
demonstrate that cafenet achieves the state-of-the-art cancer grading
performance in colorectal cancer grading datasets."
Explaining Massive-Training Artificial Neural Networks in Medical Image Analysis Task Through Visualizing Functions Within the Models,"each slice of the ct volumes in
the dataset has a matrix size of 512 × 512 pixels, with in-plane pixel sizes of
0.60-1.00 mm and thicknesses of 0.20-0.70 mm."
Explaining Massive-Training Artificial Neural Networks in Medical Image Analysis Task Through Visualizing Functions Within the Models,"the dataset consists of the
original hepatic ct image with the liver mask and the ""gold-standard"" liver
tumor region manually segmented by a radiologist, as illustrated in fig."
Explaining Massive-Training Artificial Neural Networks in Medical Image Analysis Task Through Visualizing Functions Within the Models,"also, the patches were extracted from input images from
both channels: a 5 × 5 × 5 sized patch in the same spatial position was
extracted to form a training patch with a size of 2 × 5 × 5 × 5 pixels.seven
cases and 24 cases in the dynamic contrast-enhanced ct scans dataset were used
for training and testing, respectively."
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"meanwhile, vision
transformers (vit) [4] have been shown to replace cnn with a transformer encoder
in computer vision tasks and can achieve obvious advantages on large-scale
datasets."
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"second, no complete open liver lesion classification
datasets exist."
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"most relevant studies are based on private datasets, which tend
to be small in size and cause overfitting in learning models.in this paper, we
construct a hybrid framework with vit backbone for liver lesion classification,
transliver."
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"while most
multi-phase liver lesion classification studies use datasets with no more than
three phases (without dl phase for its difficulty of collection) or no more than
six lesion classes, we validate the whole framework on an in-house dataset with
four phases of abdominal ct and seven classes of liver lesions."
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"considering the
disproportion of axial lesion slice number and the relatively small scale of the
dataset, we adopt a 2-d network in classification part instead of 3-d in
pre-processing part and achieve a 90.9% accuracy."
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,dataset.
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"the employed single-phase annotated dataset is collected from sir run
run shaw hospital (srrsh), affiliated with the zhejiang university school of
medicine, and has received the ethics approval of irb."
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"to
handle the imbalance of dataset, we randomly select 586 lesions as the training
and validation set with no more than 700 axial slices in each lesion type, and
the rest 175 lesions constitute the test set."
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"in the results of our method, hm has a relatively low performance of 62.5%,
mainly due to its low proportion in our dataset."
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"the details can be found in
supplementary materials.because the sources of data are different among the
methods compared above and to the best of our knowledge, no relevant study based
on transformers was found, we further train some sota normal classification
models on our dataset."
Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation,dataset.
Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation,"the developed explainability framework has been validated on an in vivo
and ex vivo pcle dataset of meningioma, glioblastoma and metastases of an
invasive ductal carcinoma (idc)."
Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation,"our dataset includes 38 meningioma
videos, 24 glioblastoma and 6 idc."
Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation,"this resulted in a training dataset of 2500
frames per class (7500 frames in total) and a testing dataset of the same size."
Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation,"the dataset is split into a training and testing subset, with the division done
on the patient level.implementation."
Localized Region Contrast for Enhancing Self-supervised Learning in Medical Image Segmentation,"during the fine-tuning stage, we perform extensive experiments on three datasets
with respect to different regions of the human body."
Localized Region Contrast for Enhancing Self-supervised Learning in Medical Image Segmentation,"abd-110 is an abdomen
dataset from [25] that contains 110 ct images from patients with various
abdominal tumors and these ct images were taken during the treatment planning
stage."
Localized Region Contrast for Enhancing Self-supervised Learning in Medical Image Segmentation,"we report the average dsc on 11 abdominal organs (large bowel, duodenum,
spinal cord, liver, spleen, small bowel, pancreas, left kidney, right kidney,
stomach and gallbladder).thorax-85 is a thorax dataset from [5] that contains 85
thoracic ct images."
Faithful Synthesis of Low-Dose Contrast-Enhanced Brain MRI Scans Using Noise-Preserving Conditional GANs,"as
with all deep learning-based approaches, the availability of large datasets is
essential, which is problematic in the considered case since the additional ce
low-dose scan is not acquired in clinical routine exams."
Faithful Synthesis of Low-Dose Contrast-Enhanced Brain MRI Scans Using Noise-Preserving Conditional GANs,"hence, there are no
public datasets to easily benchmark and compare different algorithms or evaluate
their performance."
Faithful Synthesis of Low-Dose Contrast-Enhanced Brain MRI Scans Using Noise-Preserving Conditional GANs,"the generator learns a non-linear transformation of a predefined
noise distribution to fit the distribution of a target dataset, while the
discriminator provides feedback by simultaneously approximating a distance or
divergence between the generated and the target distribution."
Faithful Synthesis of Low-Dose Contrast-Enhanced Brain MRI Scans Using Noise-Preserving Conditional GANs,"using this dataset, we aim at the semantic
interpolation of the gbca signal at various fractional dose levels."
Faithful Synthesis of Low-Dose Contrast-Enhanced Brain MRI Scans Using Noise-Preserving Conditional GANs,"to this end,
we use gans to learn the contrast enhancement behavior from the dataset
collective and thereby enable the synthesis of contrast signals at various dose
levels for individual cases."
SFusion: Self-attention Based N-to-One Multimodal Fusion Block,"-we provide qualitative and quantitative performance
evaluations on activity recognition with the shl [22] dataset and brain tumor
segmentation with the brats2020 [1] dataset."
Unpaired Cross-Modal Interaction Learning for COVID-19 Segmentation on Limited CT Images,"we used the public covid-19 segmentation benchmark [15] to verify the proposed
uci."
Unpaired Cross-Modal Interaction Learning for COVID-19 Segmentation on Limited CT Images,"it is collected from two public resources [5,8] on chest ct images
available on the cancer imaging archive (tcia) [4]."
Unpaired Cross-Modal Interaction Learning for COVID-19 Segmentation on Limited CT Images,"we also
used two chest x-ray-based classification datasets including chestx-ray14 [18]
and chestxr [1] to assist the uci training."
Unpaired Cross-Modal Interaction Learning for COVID-19 Segmentation on Limited CT Images,"the chestx-ray14 dataset comprises
112,120 x-ray images showing positive cases from 30,805 patients, encompassing
14 disease image labels pertaining to thoracic and lung ailments."
Unpaired Cross-Modal Interaction Learning for COVID-19 Segmentation on Limited CT Images,"the chestxr dataset consists of 21,390 samples,
with each sample classified as healthy, pneumonia, or covid-19."
Pre-trained Diffusion Models for Plug-and-Play Medical Image Enhancement,"however, their applicability to medical images has not been fully explored due
to the absence of publicly available pre-trained diffusion models tailored for
the medical imaging community."
Pre-trained Diffusion Models for Plug-and-Play Medical Image Enhancement,"for example,
openai's improved diffusion models [21] took 1600-16000 a100 hours to be trained
on the imagenet dataset with one million images, which is prohibitively
expensive."
Pre-trained Diffusion Models for Plug-and-Play Medical Image Enhancement,"the pre-trained diffusion models and
pytorch code of the present method are publicly available at
https://github.com/bowang-lab/ dpm-medimgenhance."
Guiding the Guidance: A Comparative Analysis of User Guidance Signals for Interactive Segmentation of Volumetric Images,"we
implemented our experiments with monai label [23] and will release our code.we
trained and evaluated all of our models on the openly available autopet [1] and
msd spleen [2] datasets."
Scale-Aware Test-Time Click Adaptation for Pulmonary Nodule and Mass Segmentation,"(b): statistics of the number of nodules at different scales in three
datasets."
Scale-Aware Test-Time Click Adaptation for Pulmonary Nodule and Mass Segmentation,"the main reason is that the lesion scale in the
two public datasets are relatively small, which matches the fact few patients
have very large nodule or mass."
Scale-Aware Test-Time Click Adaptation for Pulmonary Nodule and Mass Segmentation,"experimental results on two public datasets and one
in-house dataset demonstrate that the proposed method outperforms existing
methods with different backbones."
Shifting More Attention to Breast Lesion Segmentation in Ultrasound Videos,none
Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,"the camus dataset [20] contains cardiac ultrasounds from 500 patients,
for which two-chamber and four-chamber sequences were acquired.manual
annotations for the endocardium and epicardium borders of the left ventricle
(lv) and the left atrium were obtained from a cardiologist for the end-diastolic
(ed) and end-systolic (es) frames."
Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,"the dataset is split into 400 training
patients, 50 validation patients, and 50 testing patients."
Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,"each contour contains 21
points.private cardiac us."
Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,"this is a proprietary multi-site multi-vendor dataset
containing 2d echocardiograms of apical two and four chambers from 890 patients."
Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,"the dataset is split into a training/validation set (80/20)
and an independent test set from different sites, comprised of 994
echocardiograms from 684 patients and 368 echocardiograms from 206 patients,
respectively."
Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,"the japanese society of radiological technology (jsrt) dataset
consists of 247 chest x-rays [26]."
HENet: Hierarchical Enhancement Network for Pulmonary Vessel Segmentation in Non-contrast CT Images,none
Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels,"following [23,41],
we use qubiq 2020, which contains 7 segmentation tasks in 4 different ct and mr
datasets: prostate (55 cases, 2 tasks, 6 raters), brain growth (39 cases, 1
task, 7 raters), brain tumor (32 cases, 3 tasks, 3 raters), and kidney (24
cases, 1 task, 3 raters)."
Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels,"for each dataset, we calculate the average dice score
between each rater and the majority votes in table 1."
Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels,"in some datasets, such as
brain tumor t2, the inter-rater disagreement can be quite substantial."
Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels,"as the ground-truth labels for the test set are not publicly
accessible, we only use the training set."
Semi-supervised Domain Adaptive Medical Image Segmentation Through Consistency Regularized Disentangled Contrastive Learning,"datasets: we evaluate our work on two different da tasks to evaluate its
generalizability: (1) polyp segmentation from colonoscopy images in kvasir-seg
[11] and cvc-endoscene still [20], and (2) brain tumor segmentation in mri
images from brats2018 [16]."
BerDiff: Conditional Bernoulli Diffusion Model for Medical Image Segmentation,dataset and preprocessing.
BerDiff: Conditional Bernoulli Diffusion Model for Medical Image Segmentation,"the data used in this experiment are obtained from
lidc-idri [2,7] and brats 2021 [4] datasets."
Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk,image datasets.
Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk,"the proposed methodology was evaluated on two publicly available
datasets: our recently released han-seg dataset [14] and the pddca dataset [15]."
Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk,"the han-seg dataset comprises ct and t1-weighted mr images of 56 patients, which
were deformably registered with the simpleelastix registration tool, and
corresponding curated manual delineations of 30 oars (for details, please refer
to [14])."
Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk,"although only a subset of images is publicly available1 due to the
ongoing han-seg challenge2 , both the publicly available training as well as the
privately withheld test images were used in our 4-fold cross-validation
experiments."
Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk,"on the other hand, to evaluate the generalization ability of our
method, we also conducted experiments on the ct-only pddca dataset (for details,
please refer to [15]), from which we collected 15 images from the offand on-site
test sets of the corresponding challenge for our evaluation."
Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk,"as this dataset is
widely used for evaluating the performance of automatic han oar segmentation
methods, it serves as a valuable benchmark for comparison with other
state-of-the-art methods."
Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk,"note that none of the images from the ct-only pddca
dataset were used for training, and as our model expects two inputs, we
substituted the missing mr modality with an empty matrix (i.e."
Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk,"to address the challenge of a relatively small dataset, we adopted a
4-fold cross-validation strategy without using any external training images."
Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network,"all bus images in the
dataset were zero-padded and reshaped to form square images."
Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network,"the proposed approach utilizes the building blocks of resnet50 and
swin-transformer-v2, pretrained on imagenet dataset."
SimPLe: Similarity-Aware Propagation Learning for Weakly-Supervised Breast Cancer Segmentation in DCE-MRI,"the method obtained a dice value
of 83% using the interval-slice annotation, on a testing dataset containing only
28 patients.in this study, we propose a simple yet effective weakly-supervised
strategy, by using extreme points as annotations (see fig."
SimPLe: Similarity-Aware Propagation Learning for Weakly-Supervised Breast Cancer Segmentation in DCE-MRI,"we
evaluate our method on a collected dce-mri dataset containing 206 subjects."
Uncertainty-Informed Mutual Learning for Joint Medical Image Classification and Segmentation,dataset and implementation.
Uncertainty-Informed Mutual Learning for Joint Medical Image Classification and Segmentation,"we evaluate the our uml network on two datasets
refuge [14] and ispy-1 [13]."
Uncertainty-Informed Mutual Learning for Joint Medical Image Classification and Segmentation,"a total of 157 patients who suffer
the breast cancer are considered -43 achieve pcr and 114 non-pcr.for each case,
we cut out the slices in the 3d image and totally got 1,570 2d images, which are
randomly divided into the train, validation, and test datasets with 1,230, 170,
and 170 slices, respectively."
DBTrans: A Dual-Branch Vision Transformer for Multi-Modal Brain Tumor Segmentation,"and for semantic segmentation tasks, many methods, such as setr
[20] and segformer [21], use vit as the direct backbone network and combine it
with a taskspecific segmentation head for prediction results, reaching excellent
performance on some 2d natural image datasets."
Edge-Aware Multi-task Network for Integrating Quantification Segmentation and Uncertainty Prediction of Liver Tumor on Multi-modality Non-contrast MRI,none
Certification of Deep Learning Models for Medical Image Segmentation,"by extension, we
show that current diffusion models, trained on 'classical images' generalize
well to medical datasets for denoising tasks."
Certification of Deep Learning Models for Medical Image Segmentation,"extensive experiments on five
public medical datasets of chest x-rays [21,31], skin lesions [10], and
colonoscopies [6], and different popular segmentation models, prove the
potential of our method."
Category-Level Regularized Unlabeled-to-Labeled Learning for Semi-supervised Prostate Segmentation with Multi-site Unlabeled Data,none
Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,"more
specifically, we use the classic unet [17] as the cnn backbone and evaluate our
kspc-net on the publicly available miccai hecktor (head and neck tumor
segmentation) challenge 2021 dataset."
Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,"the dataset is from the hecktor challenge in miccai 2021 (head and neck tumor
segmentation challenge)."
Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,"the hecktor training dataset consists of 224 patients
diagnosed with oropharyngeal cancer [1]."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"in this way, inconsistency between the augmented features and the corresponding
labels can be effectively reduced.our method is evaluated using pre-operative
multimodal mr brain images of 1726 diffuse glioma patients collected from
cooperation hospitals and a public dataset brats2019 [12] containing multimodal
mr brain images of 210 patients."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"assume that d = {x 1 , ...,
x n } is the dataset containing pre-operative multimodal mr brain images of
diffuse glioma patients, and n is the number of patients."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"in the in-house dataset, the proportions of the three tumor types are
20.9% (oligodendroglioma), 28.7% (astrocytoma), and 50.4% (glioblastoma), which
is consistent with the statistical report in [13]."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"in our experiment, both in-house and public datasets are used to evaluate our
method."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"specifically, the in-house dataset collected in cooperation hospitals
contains pre-operative multimodal mr images, including t1, t1 contrast enhanced
(t1c), t2, and flair, of 1726 patients (age 49.7 ± 13.1) with confirmed diffuse
glioma types."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"besides the inhouse
dataset, a public dataset brats2019, including pre-operative multimodal mr
images of 210 non-censored patients (age 61.4 ± 12.2), is adopted as the
external independent testing dataset."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"all images of the in-house and brats2019
datasets go through the same pre-processing stage, including image normalization
and affine transformation to mni152 [17]."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"concordance index (c-index) is adopted to quantify the
prediction accuracy:where d = {x 1 , ..., x n } is the dataset containing all
patients, t i and t j are ground truth of survival times of the i-th and j-th
patients, r i and r j are the days predicted by rf, mcsp, and pgsp or risks
predicted by the deep cox proportional hazard models (i.e., deepconvsurv and our
method), 1 x<y = 1 if x < y, else 0, and δ i = 0 or 1 when the i-th patient is
censored or non-censored."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"as rf, mcsp, and pgsp cannot use the censored data in
the in-house dataset, 80% of the non-censored data (594 patients) are randomly
selected as the training data, and the rest 20% non-censored data (149 patients)
are for testing."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"so besides the 80%
non-censored patients, all censored data (983 patients) are also included in the
training data.table 1 shows the evaluation results of the in-house and the
external independent (brats2019) testing datasets using all methods under
evaluation."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"both in-house and public
datasets containing 1936 patients were used in the experiment."
H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation,"hecktor21 is a dualmodality dataset
for head and neck tumor segmentation, containing 224 pet-ct image pairs."
H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation,"we randomly select 180 samples
for each dataset as the training set and the rest as the independent test set
(44 cases for hecktor21 and 40 cases for pi-cai22)."
TransNuSeg: A Lightweight Multi-task Transformer for Nuclei Segmentation,dataset.
TransNuSeg: A Lightweight Multi-task Transformer for Nuclei Segmentation,"we evaluated the applicability of our approach across multiple
modalities by conducting evaluations on microscopy and histology datasets."
TransNuSeg: A Lightweight Multi-task Transformer for Nuclei Segmentation,"the
private dataset contains 300 images sized at 512 × 512 tessellated from 50 wsis
scanned at 20×, and meticulously labeled by five pathologists according to the
labeling guidelines of the monuseg [10]."
TransNuSeg: A Lightweight Multi-task Transformer for Nuclei Segmentation,"for both datasets, we randomly split
80% of the samples on the patient level as the training set and the remaining
20% as the test set."
TransNuSeg: A Lightweight Multi-task Transformer for Nuclei Segmentation,"more
importantly, our method can outperform swinunet and the previous methods on both
datasets."
TransNuSeg: A Lightweight Multi-task Transformer for Nuclei Segmentation,"for example, in the histology image dataset, transnuseg improves the
dice score, f1 score, accuracy, and iou by 2.08%, 3.41%, 1.25%, and 2.70%
respectively, over the second-best models."
TransNuSeg: A Lightweight Multi-task Transformer for Nuclei Segmentation,"similarly, in the fluorescence
microscopy image dataset, our proposed model improves dsc by 0.96%, while also
leading to 1.65%, 1.03% and 1.91% increment in f1 score, accuracy, and iou to
the second-best performance."
TransNuSeg: A Lightweight Multi-task Transformer for Nuclei Segmentation,"to further show the effectiveness of these schemes, as well as
consistency self distillation, we conduct a comprehensive ablation study on both
datasets."
Diffusion Kinetic Model for Breast Cancer Segmentation in Incomplete DCE-MRI,"in this manner, our latent kinetic code can be interpreted to
provide tic information and hemodynamic characteristics for accurate cancer
segmentation.we verify the effectiveness of our proposed diffusion kinetic model
(dkm) on dce-mri-based breast cancer segmentation using breast-mri-nact-pilot
dataset [13]."
Diffusion Kinetic Model for Breast Cancer Segmentation in Incomplete DCE-MRI,"dataset: to demonstrate the effectiveness of our proposed dkm, we evaluate our
method on 4d dce-mri breast cancer segmentation using the breast-mri-nact-pilot
dataset [13], which contains a total of 64 patients with the contrastenhanced
mri protocol: a pre-contrast scan, followed by 2 consecutive postcontrast time
points (as shown in fig."
Diffusion Kinetic Model for Breast Cancer Segmentation in Incomplete DCE-MRI,"we divided the
original dataset into training (70%) and test set (30%) based on the scans."
Diffusion Kinetic Model for Breast Cancer Segmentation in Incomplete DCE-MRI,"ground truth segmentations of the data are provided in the dataset for tumor
annotation."
EoFormer: Edge-Oriented Transformer for Brain Tumor Segmentation,"in order to validate the performance of eoformer, we conduct extensive
experiments on both the publicly available brats 2020 dataset and a private
medulloblastoma segmentation dataset (medseg)."
EoFormer: Edge-Oriented Transformer for Brain Tumor Segmentation,"the brats 2020 dataset [14]
consists of mri image data from 369 patients, with each patient having four
modalities (t1, t1ce, t2 and t2-flair) of skull-striped mri, which are aligned
to a standard brain template."
EoFormer: Edge-Oriented Transformer for Brain Tumor Segmentation,"the training/validation/test split follows
315/16/37 according to recent works [10,23].the medseg dataset includes mri
images of t1, t1ce, t2, and t2 flair modalities from 255 patients with
medulloblastoma."
EoFormer: Edge-Oriented Transformer for Brain Tumor Segmentation,"the dataset includes manual annotations of the wt and et
regions."
EoFormer: Edge-Oriented Transformer for Brain Tumor Segmentation,four-fold cross-validation is performed on this dataset.
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"first, there lacks of a well-segmented
dataset with manual labels on lyme disease."
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"on one hand, some datasets-such as
ham10000 [10] and isbi challenges [11]-have manual annotated segmentations for
diseases like melanoma, but they do not have lyme disease lesions."
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"on the other
hand, some datasets-such as groh et al."
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"therefore, existing skin disease segmentation [13] as
well as existing general segmentation works, such as u-net [14], polar training
[15], vit-adapter [16], and mfsnet [17], usually suffer from relatively low
performance and reduced fairness [2,18,19].in this paper, we present the first
lyme disease dataset that contains labeled segmentation and skin tones."
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"our lyme
disease dataset contains two parts: (i) a classification dataset, composed of
more than 3,000 diseased skin images that are either obtained from public
resources or clinicians with patient-informed consent, and (ii) a segmentation
dataset containing 185 samples that are manually annotated for three
regions-i.e., background, skin (light vs."
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"our
dataset with manual labels is available at this url [20].secondly, we design a
simple yet novel data preprocessing and alternation method, called edgemixup, to
improve lyme disease segmentation and diagnosis fairness on samples with
different skin-tones."
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"we present two datasets: (i) a dataset collected and annotated by us (called
skin), and (ii) a subset of sd-198 [23] with our annotation (called sd-sub)."
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"first, we collect and annotate a dataset with 3,027 images containing three
types of disease/lesions, i.e., tinea corporis (tc), herpes zoster (hz), and
erythema migrans (em)."
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"all skin images are either collected from publicly
available sources or from clinicians with patient informed consent."
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"second, we select five classes from sd-198
[23], a benchmark dataset for skin disease classification, as another dataset
for both segmentation and classification tasks."
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"we choose 30 samples in each class for segmentation task, and we
split them into 0.7, 0.1, and 0.2 ratio for training, validation, and testing,
respectively.table 1 show the characteristics of these two datasets for both
classification and segmentation tasks broken down by the disease type and skin
tone, as calculated by the individual typology angle (ita) [24]."
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"one
prominent observation is that ls images are more abundant than ds images due to
a disparity in the availability of ds imagery found from either public sources
or from clinicians with patient consent."
Factor Space and Spectrum for Medical Hyperspectral Image Segmentation,"we conducted experiments on the public multi-dimensional choledoch (mdc) dataset
[31] with 538 scenes and hyperspectral gastric carcinoma (hgc) dataset [33]
(data provided by the author) with 414 scenes, both with highquality labels for
binary mhsi segmentation tasks."
Factor Space and Spectrum for Medical Hyperspectral Image Segmentation,"following [23,27], we partition the datasets into training, validation, and
test sets using a patient-centric hard split approach with a ratio of 3:1:1."
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,"experimental results on lung (83 cts, 19 patients) and liver (77 cects, 18
patients) datasets show that our method yields high classification accuracy.to
the best of our knowledge, ours is the first method to perform longitudinal
lesion matching and lesion changes pattern detection."
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,"similarity-based methods pair two lesions
with similar features, e.g., intensity, shape, location [13][14][15][16] with an
84-96% accuracy on the deeplesion dataset [14]."
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,"we evaluated our method with two studies on retrospectively collected patient
datasets that were manually annotated by an expert radiologist.dataset: lung and
liver ct studies were retrospectively obtained from two medical centers
(hadassah univ hosp jerusalem israel) during the routine clinical examination of
patients with metastatic disease."
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,"dliver consists of
77 abdominal cect scans from 18 patients with a mean 4.3 ± 2.0 scans/patient, a
mean time interval between consecutive scans of 109.7 ± 93.5 days, and voxel
sizes of 0.6-1.0 × 0.6-1.0 × 0.8-5.0 mm 3 .lesions in both datasets were
annotated by an expert radiologist, yielding a total of 1,178 lung and 800 liver
lesions, with a mean of 14.2 ± 19.1 and 10.4 ± 7.9 lesions/scan (lesions with
<20 voxels were excluded)."
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,"ground-truth lesion matching graphs and lesion
changes labeling were produced by running the method on the datasets and then
having the radiologist review and correct the resulting node labels and
edges.study 1: lesion changes labeling, lesion matching, evaluation of patterns
of lesion changes."
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,"for the dlungs dataset, 25 visible
and 5 faintly visible or surmised to be present unmarked lesions were found for
27 nonconsecutive edges."
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,"for the dliver dataset, 20 visible and 21 faintly
visible or surmised to be present unmarked lesions were found for 25
non-consecutive edges.after reviewing the 42 and 37 lesions labeled as lone in
dlungs and dliver with > 5mm diameter, the radiologist determined that 1 and 8
of them had been wrongly identified as a cancerous lesion."
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,"in total, 45 and 62 missing lesions were added to the
ground truth dlungs and dliver datasets, respectively."
Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"the experimental results on a benchmark npsle dataset demonstrate the
proposed method outperforms comparing methods in terms of early noninvasive
biomarker discovery and early diagnosis."
Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"dataset and preprocessing: the t2-weighted mr images of 39 participants
including 23 patients with npsle and 16 hcs were gathered from our affiliated
hospital."
Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"the
classification performances of the npsle dataset contaminated by attribute noise
are shown in fig."
CARL: Cross-Aligned Representation Learning for Multi-view Lung Cancer Histology Classification,"our dataset nsclc-tcia for lung cancer histological subtype classification is
sourced from two online resources of the cancer imaging archive (tcia) [5]:
nsclc radiomics [1] and nsclc radiogenomics [2]."
CARL: Cross-Aligned Representation Learning for Multi-view Lung Cancer Histology Classification,"we evaluate the performance of nsclc classification in
five-fold cross validation on the nsclc-tcia dataset, and measure accuracy
(acc), sensitivity (sen), specificity (spe), and the area under the receiver
operating characteristic (roc) curve (auc) as evaluation metrics."
Self- and Semi-supervised Learning for Gastroscopic Lesion Detection,"although deep neural network-based object detectors
achieve tremendous success within the domain of natural images, directly
training generic object detectors on gld datasets performs below expectations
for two reasons: 1) the scale of labeled data in gld datasets is limited in
comparison to natural images due to the annotation costs."
Self- and Semi-supervised Learning for Gastroscopic Lesion Detection,"moreover, we propose the first large-scale gld datasets (lgldd),
which contains 10,083 gastroscopic images with 12,292 well-annotated lesion
bounding boxes of four categories of lesions (polyp, ulcer, cancer, and
sub-mucosal tumor)."
Self- and Semi-supervised Learning for Gastroscopic Lesion Detection,"-a large-scale gastroscopic lesion detection
datasets (lgldd) -experiments on lgldd demonstrate that ssl can bring
significant enhancement compared with baseline methods."
Self- and Semi-supervised Learning for Gastroscopic Lesion Detection,"we contribute the first large-scale gstroscopic lesion detection datasets
(lgldd) in the literature."
Self- and Semi-supervised Learning for Gastroscopic Lesion Detection,"for map, we
follow the popular object detection datasets coco [11] and calculate the mean of
11 aps of iou from 0.5 to 0.95 with stepsize 0.05 (map @[.5:.05:.95]).we also
report ap under some specific iou threshold (ap 50 for .5, ap 75 for .75) and ap
of different scale lesions (ap s , ap m , ap l ) like coco [11]."
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","we train and validate
our methods on two retrospective rectal cancer datasets, grampian and aristotle."
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","grampian and aristotle are used in both
training and validation, with a 70/30% training-validation split, keeping any
wsis from a single patient in the same dataset."
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","the datasets are unbalanced, since in grampian only 61/244 slides have
complete response, and in aristotle only 24/121 slides have complete response."
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","there are 365 slides total in our dataset, from 249
patients."
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","the
prediction performance of the model could be improved by utilising a larger
training dataset and performing more exhaustive parameter searches, however the
current performance of the model is sufficient to demonstrate the impact of this
approach.the predicted response to radiotherapy can now be viewed in the context
of disease biology as captured by cms4."
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","the focus of this research is not to achieve the best possible
metrics, but to develop robust methods which can add context and explanation to
clinical black box deep learning model predictions, with the view to ease
clinical translation of such models.to explore the effects of the noisy cms4
ground truth labels, we remove from our dataset any wsis classified as
'unmatched' for the cms call, which for the main results of this paper we
defined as 'not cms4'."
Automatic Bleeding Risk Rating System of Gastric Varices,"in
cram, the varices features are extracted using the segmentation results and
combined with an attention mechanism to learn the intra-class correlation and
cross-region correlation between the target area and the context.to learn from
experienced endoscopists, gv datasets with bleeding risks annotation is needed."
Automatic Bleeding Risk Rating System of Gastric Varices,"while most works and public datasets focus on colonoscopy [13,15] and esophagus
[5,9], with a lack of study on gastroscopy images."
Automatic Bleeding Risk Rating System of Gastric Varices,"in the public dataset of
endocv challenge [2], the majority are colonoscopies while only few are
gastroscopy images."
Automatic Bleeding Risk Rating System of Gastric Varices,"in this work, we collect a gv bleeding risks rating dataset
(gvbleed) that contains 1678 gastroscopy images from 411 patients with different
levels of gv bleeding risks."
Automatic Bleeding Risk Rating System of Gastric Varices,"three senior clinical endoscopists are invited to
grade the bleeding risk of the retrospective data in three levels and annotated
the corresponding segmentation masks of gv areas.in sum, the contributions of
this paper are: 1) a novel gv bleeding risk rating framework that constructively
introduces segmentation to enhance the robustness of representation learning; 2)
a region-constraint module for better feature localization and a cross-region
attention module to learn the correlation of target gv with its context; 3) a gv
bleeding risk rating dataset (gvbleed) with high-quality annotation from
multiple experienced endoscopists."
Automatic Bleeding Risk Rating System of Gastric Varices,"baseline methods have been evaluated on the
newly collected gvbleed dataset."
Automatic Bleeding Risk Rating System of Gastric Varices,"the gvbleed dataset contains 1678 endoscopic
images with gastric varices from 527 cases."
Automatic Bleeding Risk Rating System of Gastric Varices,"to ensure the quality of our dataset, senior endoscopists are
invited to remove duplicates, blurs, active bleeding, chromoendoscopy, and nbi
pictures.criterion of gv bleeding risk level rating."
Automatic Bleeding Risk Rating System of Gastric Varices,"based on the clinical
experience in practice, the gv bleeding risks in our dataset are rated into
three levels, i.e., mild, moderate, and severe."
Automatic Bleeding Risk Rating System of Gastric Varices,"note that the diameter is only one reference for the final risk rating since the
gv is with 1 please refer to the supplementary material for more detailed
information about our dataset."
Automatic Bleeding Risk Rating System of Gastric Varices,"to
ensure the accuracy of our annotation, three senior endoscopists with more than
10 years of clinical experience are invited to jointly label each sample in our
dataset."
Automatic Bleeding Risk Rating System of Gastric Varices,"the gvbleed dataset is partitioned into training and testing sets for
evaluation, where the training set contains 1337 images and the testing set has
341 images."
Automatic Bleeding Risk Rating System of Gastric Varices,"the dataset is planned to be released in the
future."
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"survival
analysis is often used in pe to assess how survival is affected by different
variables, using a statistical method like kaplan-meier method and cox
proportional-hazards regression model [7,12,14].however, one issue with
traditional survival analysis is bias from single modal data that gets
compounded when curating multimodal datasets, as different combinations of modes
and datasets create with a unified structure."
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"multimodal data sets are useful
for fair ai model development as the bias complementary from different sources
can make de-biased decisions and assessments."
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"in that process, the biases of
each individual data set will get pooled together, creating a multimodal data
set that inherits multiple biases, such as racial bias [1,15,23]."
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"in addition,
it has been found that creating multimodal datasets without any debiasing
techniques does not improve performance significantly and does increase bias and
reduce fairness [5]."
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"overall, a holistic approach to model development would be
beneficial in reducing bias aggregation in multimodal datasets."
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"we then implemented methods
to remove racial bias in our dataset and model and output unbiased pe outcomes
as a result."
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"we will first introduce our pulmonary embolism multimodal
datasets, including survival and race labels."
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"then, we evaluate the baseline
survival learning framework without de-biasing in the various racial
groups.dataset."
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the pulmonary embolism dataset used in this study from 918
patients (163 deceased, median age 64 years, range 13-99 years, 52% female),
including 3978 ctpa images and 918 clinical reports, which were identified via
retrospective review across three institutions."
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the penet is
pre-trained on large-scale ctpa studies and shows excellent pe detection
performance with an auroc of 0.85 on our entire dataset."
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"we detected indications of racial bias in our dataset and
conducted an analysis of the multimodal diversity."
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"our
method is based on a transformer model that uses attention [30], similar to how
radiologists would compare current and prior mammograms.the method is trained
and evaluated on a large and diverse dataset of over 9,000 patients and shown to
outperform a model based on state-of-the art risk prediction techniques for
mammography [33]."
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"we compiled an in-house mammography dataset comprising 16,113 exams (64,452
images) from 9,113 patients across institutions from the united states, gathered
between 2010 and 2021."
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"the
dataset has 3,625 biopsy-proven cancer exams, 5,394 biopsyproven benign exams,
and 7,094 normal exams."
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"we partitioned the dataset by patient to create
training, validation, and test sets."
Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"to fulfill both ldct and ncct screening needs, we curate a large-scale
lung nodule dataset with pathology-or follow-up-confirmed benign/malignant
labels."
Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"for the ldct, we annotate more than 12,852 nodules from 8,271 patients
from the nlst dataset [14]."
Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"experimental results on
several datasets demonstrate that our method achieves outstanding performance on
both ldct and ncct screening scenarios.our contributions are summarized as
follows: (1) we propose context parsing to extract and aggregate rich contextual
information for each nodule."
Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"(3) we curate the largest-scale lung nodule dataset with
high-quality benign/malignant labels to fulfill both ldct and ncct screening
needs."
Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"data collection and curation: nlst is the first large-scale ldct dataset for
low-dose ct lung cancer screening purpose [14]."
Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"unlike nlst, this dataset
is noncontrast chest ct, which is used for routine clinical care."
Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"we additionally evaluate our method on the lungx [2] challenge
dataset, which is usually used for external validation in previous work
[6,11,24]."
Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"segmentation: we also evaluate the
segmentation performance of our method on the public nodule segmentation dataset
lidc-idri [3], which has 2,630 nodules with nodule segmentation mask."
Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"due to the lack of manual annotation of nodule masks for the nlst dataset, we
can only optimize the segmentation task using our in-house dataset, which has
manual nodule masks."
M&M: Tackling False Positives in Mammography with a Multi-view and Multi-instance Learning Sparse Detector,"we employ a 1:1 sampling
ratio between unannotated and annotated images.datasets."
M&M: Tackling False Positives in Mammography with a Multi-view and Multi-instance Learning Sparse Detector,"we utilize three 2d
digital mammography datasets: (1) optimam : a development dataset derived from
the optimam database [7], which is funded by cancer research uk."
M&M: Tackling False Positives in Mammography with a Multi-view and Multi-instance Learning Sparse Detector,"we split the
data into train/val/test with an 80:10:10 ratio at the patient level; (2)
inhouse-a: an evaluation dataset collected from a u.s."
M&M: Tackling False Positives in Mammography with a Multi-view and Multi-instance Learning Sparse Detector,"multi-site mammography
operator; (3) inhouse-b : an evaluation dataset collected from a u.s."
M&M: Tackling False Positives in Mammography with a Multi-view and Multi-instance Learning Sparse Detector,2.2 for more details on the inhouse datasets).
M&M: Tackling False Positives in Mammography with a Multi-view and Multi-instance Learning Sparse Detector,"we also
utilize two film mammography datasets: (4) ddsm: a dataset maintained at the
university of south florida [8]."
M&M: Tackling False Positives in Mammography with a Multi-view and Multi-instance Learning Sparse Detector,"dataset statistics are reported
in table 1.metrics."
M&M: Tackling False Positives in Mammography with a Multi-view and Multi-instance Learning Sparse Detector,"table 3a reports
m&m's breast-level and exam-level classification results on optimam and the two
inhouse datasets."
M&M: Tackling False Positives in Mammography with a Multi-view and Multi-instance Learning Sparse Detector,"both baseline models suffer large
generalization drops of approximately 3b compares m&m with recent literature
reporting on the public cbis-ddsm dataset."
Reversing the Abnormal: Pseudo-Healthy Generative Networks for Anomaly Detection,"our method can use both expert
annotatedor unsupervised generated masks to reverse and segment anomalies
annotated datasets for training and tend to generalize poorly beyond the learned
labels [21]."
Reversing the Abnormal: Pseudo-Healthy Generative Networks for Anomaly Detection,"adapting the noise distribution to the diversity
and heterogeneity of pathology is inherently difficult, and even if achieved,
the noising process disrupts the structure of both healthy and anomalous regions
throughout the entire image.in related computer vision areas, such as industrial
inspection [3], the topperforming methods do not focus on reversing anomalies,
but rather on detecting them by using large nominal banks [7,20], or pre-trained
features from large natural imaging datasets like imagenet [4,22]."
Reversing the Abnormal: Pseudo-Healthy Generative Networks for Anomaly Detection,"they include the variability
and complexity of normal data, subtlety of anomalies, limited size of datasets,
and domain shifts.this work aims to combine the advantages of constrained latent
restoration for understanding healthy data distribution with generative
in-painting networks."
SHISRCNet: Super-Resolution and Classification Network for Low-Resolution Breast Cancer Histopathology Image,none
Text-Guided Foundation Model Adaptation for Pathological Image Classification,dataset.
Text-Guided Foundation Model Adaptation for Pathological Image Classification,"we adopt the patchgastric [25] dataset, which includes
histopathological image patches extracted from h&e stained whole slide images
(wsi) of stomach adenocarcinoma endoscopic biopsy specimens."
Text-Guided Foundation Model Adaptation for Pathological Image Classification,"the
dataset contains 9 subtypes of gastric adenocarcinoma."
Distributionally Robust Image Classifiers for Stroke Diagnosis in Accelerated MRI,"our results show that on a real-world dataset, drl can
significantly improve the stroke classification performance of erm and other
baseline defensive training methods, when the signal sparsity and noise in
accelerated mri are generated by the cartesian undersampling (cu) method [20]
and white gaussian noise (wgn)."
Distributionally Robust Image Classifiers for Stroke Diagnosis in Accelerated MRI,"our dataset included mri brain scans from 226 patients performed at an urban
tertiary referral academic medical center that is a comprehensive stroke center."
Distributionally Robust Image Classifiers for Stroke Diagnosis in Accelerated MRI,"while the whole dataset includes 4,883 (74.7%) normal slices and 1,650 (25.3%)
stroke slices, we further randomly split them into training/validation/test sets
using the ratio 80%/10%/10%."
Distributionally Robust Image Classifiers for Stroke Diagnosis in Accelerated MRI,"for the cnn model, we used a
resnet-18 [9] architecture, while for the vit model, we first pre-trained a
4-layer vit using a self-supervised pre-training method called masked
autoencoder (mae) [8], using the t1/t2-weighted brain mr images in the ixi
dataset [1]."
Distributionally Robust Image Classifiers for Stroke Diagnosis in Accelerated MRI,"as our
dataset is unbalanced, we also considered the area under precision-recall curve
(auprc)."
MUVF-YOLOX: A Multi-modal Ultrasound Video Fusion Network for Renal Tumor Diagnosis,none
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"we conducted rigorous experiments on two
datasets and demonstrated the effectiveness of our method."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"this innovative approach not only improves the classification
performance at the patient level but also at the slide level, showcasing its
effectiveness and versatility; 3) conducting extensive experiments on two
separate datasets."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,cd-itb dataset.
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"cd-itb is a private dataset consisting of 853 slides from 163
patients, with binary patient-level labels of cd or itb in a ratio of 103:60 and
tri-class slide-level labels of cd, itb, and normal slides in a ratio of
436:121:296, respectively."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"the dataset comprises an average
of 2.3k instances per bag, with the largest bag containing over 16k
instances.camelyon17 dataset."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"camelyon17 [1] is a publicly dataset, and its
training set comprises 500 slides from 100 breast cancer patients with lymph
node metastases."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"the data folding method is the
same as the cd-itb dataset."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"abmil with p&sre improves the f1 score from 0.565 to 0.579 for the
cd-itb dataset and from 0.529 to 0.571 for the camelyon17 dataset at the
slide-level, and improves the f1 score from 0.522 to 0.599 for the cd-itb
dataset and from 0.842 to 0.861 for the camelyon17 dataset at the patient-level."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"by
introducing a transformer, the framework enables iterative interaction and
correction of information between patients and slides, resulting in better
performance at both the patient level and slide level compared to existing
state-of-the-art algorithms on two validation datasets."
What Do AEs Learn? Challenging Common Assumptions in Unsupervised Anomaly Detection,"however, since it is more
feasible to obtain large data sets with normal samples, it is common to detect
outliers by detecting patterns that deviate from the expected normative
distribution.reconstruction-based aes have emerged as a very popular framework
for unsupervised anomaly detection and are widely adopted in medical imaging
[2]."
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,dataset.
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,dataset and ground truth.
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"our study analyzed a dataset of ct scans collected
from guangdong province people's hospital between years 2018 and 2020, with
2,139 patients consisting of 787 gastric cancer and 1,352 normal cases."
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"readers were
informed that the dataset might contain more tumor cases than the standard
prevalence observed in screening, but the proportion of case types was not
disclosed."
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"we obtain the 95% confidence interval of auc,
sensitivity, and specificity values from 1000 bootstrap replicas of the test
dataset for statistical analysis."
Text-Guided Cross-Position Attention for Segmentation: Case of Medical Image,medical datasets.
Text-Guided Cross-Position Attention for Segmentation: Case of Medical Image,"we evaluated cp am t g using three datasets: monuseg [8]
dataset, qata-cov19 [6] dataset, and sacroiliac joint (sij) dataset."
Text-Guided Cross-Position Attention for Segmentation: Case of Medical Image,"the first
two datasets are the same benchmark datasets used in [10]."
Text-Guided Cross-Position Attention for Segmentation: Case of Medical Image,"sij is the dataset privately prepared for this study
which consists of 804 mri slices of nineteen healthy subjects and sixty patients
diagnosed with axial spondyloarthritis."
Text-Guided Cross-Position Attention for Segmentation: Case of Medical Image,"we randomly rotated images by -20 • ∼ +20
• and conducted a horizontal flip with 0.5 probability for only the monuseg and
qata-cov19 datasets."
Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fréchet Domain Distance,"hence, it is important
to provide indications of the expected performance on a target dataset without
requiring annotations [5,25]."
Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fréchet Domain Distance,"another related topic is out-of-distribution (ood)
detection [33] which aims to detect individual samples that are ood, in contrast
to our objective of estimating a difference of expected performances between
some datasets."
Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fréchet Domain Distance,"alternatively, a drop in performance can be estimated by comparing the model's
softmax outputs [8] or some hidden features [24,28] acquired on in-domain and
domain shift datasets."
Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fréchet Domain Distance,"68 wsis with lobular carcinoma
(28 wsis with metastases): potentially large shift as it is a rare type of
carcinoma and relatively difficult to diagnose.the datasets of lobular and
ductal carcinomas each contain 50 % of wsis from sentinel and axillary lymph
node procedures."
Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fréchet Domain Distance,"all datasets are
publicly available to be used in legal and ethical medical diagnostics research."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"for
example, public datasets such as the liver tumor segmentation benchmark (lits)
[1] fostered a series of works aiming to segment liver tumors with improved
convolutional neural network (cnn) backbones [9,13] and lesion edge information
[15]."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"we collect a large-scale dataset with both tumor and
non-tumor subjects, where the non-tumor subjects includes not only healthy ones,
but also patients with various diffuse liver diseases such as steatosis and
hepatitis to improve the robustness of the algorithm."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"it contains three branches with bottomup cooperation: the segmentation map from
the pixel branch helps to initialize the lesion branch, which is an improved
mask transformer aiming to segment and classify each lesion; the patient branch
aggregates information from the whole image and predicts image-level labels of
each lesion type, with regularization terms to encourage consistency with the
lesion branch.we collected a large-scale multi-phase dataset containing 810
non-tumor subjects and 939 tumor patients."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"our codes will be made public
upon institutional approval."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"our dataset contains 810 normal subjects and 939 patients with liver
tumors."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"we first train an nnu-net on public datasets to segment
liver and surrounding organs (gallbladder, hepatic vein, spleen, stomach, and
pancreas), and then crop the liver region to train plan."
Self-supervised Learning for Endoscopic Video Analysis,"ai solutions have shown remarkable
performance in recognizing surgical phases of cholecystectomy procedures
[17,18,32]; however, they typically require large labelled training datasets."
Self-supervised Learning for Endoscopic Video Analysis,"a recent work [27] presented an extensive
analysis of modern ssl techniques for surgical computer vision, yet on
relatively small laparoscopic datasets.optical polyp characterization."
Self-supervised Learning for Endoscopic Video Analysis,"however,
training such automatic optical biopsy systems relies on a large body of
annotated data, while ssl has not been investigated in this context, to the best
of our knowledge.3 self-supervised learning for endoscopy ssl approaches have
produced impressive results recently [5][6][7][8], relying on two key factors:
(i) effective algorithms for unsupervised learning and (ii) training on
large-scale datasets."
Self-supervised Learning for Endoscopic Video Analysis,"4, we show that training
msns on these substantial datasets unlocks their potential, yielding effective
representations that transfer well to public laparoscopy and colonoscopy
datasets."
Self-supervised Learning for Endoscopic Video Analysis,"we compiled a dataset of laparoscopic procedures videos exclusively
performed on patients aged 18 years or older."
Self-supervised Learning for Endoscopic Video Analysis,"the dataset consists of 7,877
videos recorded at eight different medical centers in israel."
Self-supervised Learning for Endoscopic Video Analysis,"the dataset
predominantly consists of the following procedures: cholecystectomy (35%),
appendectomy (20%), herniorrhaphy (12%), colectomy (6%), and bariatric surgery
(5%)."
Self-supervised Learning for Endoscopic Video Analysis,"the remaining 21% of the dataset encompasses various standard laparoscopic
operations."
Self-supervised Learning for Endoscopic Video Analysis,"each video recording was sampled at a rate of 1 frame
per second (fps), resulting in an extensive dataset containing 23.3 million
images."
Self-supervised Learning for Endoscopic Video Analysis,"we
have curated a dataset comprising 13,979 colonoscopy videos of patients aged 18
years or older."
Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"extensive
experiments on the public dataset of hecktor 2022 [7] demonstrate that our xsurv
outperforms state-of-the-art survival prediction methods, including the
top-performing methods in hecktor 2022."
Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"we adopted the training dataset of hecktor 2022 (refer to
https://hecktor.grand-cha llenge.org/), including 488 h&n cancer patients
acquired from seven medical centers [7], while the testing dataset was excluded
as its ground-truth labels are not released."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"therefore, the
contributions of this work can be summarized as: 1) a novel graph-based model
for predicting survival that extracts both local and global properties by
identifying morphological super-nodes; 2) introducing a fine-coarse feature
distillation module with 3 various strategies to aggregate interactions at
different scales; 3) outperforming sota approaches in both risk prediction and
patient stratification scenarios on two datasets; 4) publishing two large and
rare prostate cancer datasets containing more than 220 graphs for active
surveillance and 240 graphs for brachytherapy cases."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"the code and graph
embeddings are publicly available at https://github.com/pazadimo/all-in 2
related works for p n , which is the n-th patient, a set of patches {patch j } m
j=1 is
extracted from the related whole slide images."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"we utilize two prostate cancer (pca) datasets to evaluate the performance of our
proposed model."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"although majority of patients in our cohort are classified as low-risk based on
nccn guidelines [21], a significant subset of them experienced disease upgrade
that triggered definitive therapy (range: 6.2 to 224 months after diagnosis).the
second dataset (pca-bt) includes 105 pca patients with low to high risk disease
who went through brachytherapy."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"we also utilized the prostate
cancer grade assessment (panda) challenge dataset [7] that includes more than
10,000 pca needle biopsy slides (no outcome data) as an external dataset for
training the encoder of our model."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"while none of the baselines are capable of assigning patients into
risk groups with statistical significance, our distillation policies achieve
significant separation in both pca-as and pca-bt datasets; suggesting that
global histo-morphological properties improve patient stratification
performance."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"however, the best baseline with vit still has poorer performance
compared to our model in both datasets, while the number of parameters (reported
for vit embeddings' size in table 1) in our full-model is about half of this
baseline."
DARC: Distribution-Aware Re-Coloring Model for Generalizable Nucleus Segmentation,"the proposed method is evaluated on four datasets, including two h&e stained
image datasets consep [3] and cpm17 [28] and two ihc stained datasets deepliif
[29] and bc-deepliif [29,32]."
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"this is also a
big cause of concern for publicly available h&e/ihc cell segmentation datasets
with immune cell annotations from single pathologists."
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"this requires only affine registration to align the digitized
restained images to obtain non-occluded signal intensity profiles for all the
markers, similar to mif staining/scanning.in this paper, we introduce a new
dataset that can be readily used out-ofthe-box with any artificial intelligence
(ai)/deep learning algorithms for spatial characterization of tumor immune
microenvironment and several other use cases.to date, only two denovo stained
datasets have been released publicly: bci h&e and singleplex ihc her2 dataset
[7] and deepliif singleplex ihc ki67 and mif dataset [2], both without any
immune or tumor markers."
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"in contrast, we release the first denovo mif/mihc
stained dataset with tumor and immune markers for more accurate characterization
of tumor immune microenvironment."
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"the complete staining protocols for this dataset are given in the accompanying
supplementary material."
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"we
extracted 268 tiles of size 512×512 from this final segmented and co-registered
dataset."
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"we randomly extracted tiles from
the lyon19 challenge dataset [14] to use as style ihc images."
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"using these
images, we created a dataset of synthetically generated ihc images from the
hematoxylin and its marker image as shown in fig."
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"3.we evaluated the
effectiveness of our synthetically generated dataset (stylized ihc images and
corresponding segmented/classified masks) using our generated dataset with the
nuclick training dataset (containing manually segmented cd3/cd8 cells) [6]."
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"we
randomly selected 840 and 230 patches of size 256 × 256 from the created dataset
for training and validation, respectively."
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"nuclick training and validation sets
[6] comprise 671 and 200 patches, respectively, of size 256 × 256 extracted from
lyon19 dataset [14]."
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"only the total number of
lymphocytes in each image patch are reported in this dataset."
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"to evaluate the
performance of trained models on this dataset, we counted the total number of
marked lymphocytes in a predicted mask and calculated the difference between the
reported number of lymphocytes in each image with the total number of
lymphocytes in the predicted mask by the model."
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"in table 2, the average
difference value (diffcount) of lymphocyte number for the whole dataset is
reported for each model."
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"as seen, the trained models on our dataset outperform
the models trained solely on nuclick data."
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"we have released the first ai-ready restained and co-registered mif and mihc
dataset for head-and-neck squamous cell carcinoma patients."
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"this dataset can be
used for virtual phenotyping given standard clinical hematoxylin images, virtual
clinical ihc dab generation with ground truth segmentations (to train
highquality segmentation models across multiple cancer types) created from
cleaner mif images, as well as for generating standardized clean mif images from
neighboring h&e and ihc sections for registration and 3d reconstruction of
tissue specimens."
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"in the future, we will release similar datasets for additional
cancer types as well as release for this dataset corresponding whole-cell
segmentations via impartial https://github.com/nadeemlab/impartial."
Detection of Basal Cell Carcinoma in Whole Slide Images,"3 experiments the dataset, comprised of 194 skin slides acquired from the
southern sun pathology laboratory, includes 148 bcc cases and 46 other types
(common nevus, scc), all manually annotated by a dermatopathologist."
IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis,we evaluate our model with three datasets.
IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis,"(1) luad-gm dataset: the objective is
to predict the epidermal growth factor receptor (egfr) gene mutations in
patients with lung adenocarcinoma (luad) using 723 whole slide image (wsi)
slices, where 47% of cases have egfr mutations."
IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis,"(2) tcga-nsclc and tcga-rcc
datasets: cancer type classification is performed using the cancer genome atlas
(tcga) dataset."
IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis,"the tcga-nsclc dataset comprised two subtypes, lung squamous
cell carcinoma (lusc) and lung adenocarcinoma (luad), while the tcga-rcc dataset
included three subtypes: renal chromophobe cell carcinoma (kich), renal clear
cell carcinoma (kirc), and renal papillary cell carcinoma (kirp)."
Multi-scale Prototypical Transformer for Whole Slide Image Classification,"a wsi dataset t can be defined as:where x i denotes a
patient, y i the label of x i , i j i is the j-th instance of x i , n is the
number of patients and n is the number of instances."
Thyroid Nodule Diagnosis in Dynamic Contrast-Enhanced Ultrasound via Microvessel Infiltration Awareness,dataset.
Thyroid Nodule Diagnosis in Dynamic Contrast-Enhanced Ultrasound via Microvessel Infiltration Awareness,"our dataset contained 282 consecutive patients who underwent thyroid
nodule examination at nanjing drum tower hospital."
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"triangil source code is publicly available at
http://github.com/sarayar/triangil."
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"(3) the
proposed diffdp is extensively evaluated on a clinical dataset consisting of 130
rectum cancer patients, and the results demonstrate that our approach
outperforms other state-of-the-art methods."
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,dataset and evaluations.
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"we measure the performance of our model on an in-house
rectum cancer dataset which contains 130 patients who underwent volumetric
modulated arc therapy (vmat) treatment at west china hospital."
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"extensive experiments on
an in-house dataset with 130 rectum cancer patients demonstrate the superiority
of our method."
Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning,"the proposed approach was evaluated on a public tcga-lung dataset and an
in-house endometrial dataset and compared with 6 state-of-the-art methods."
Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning,"(3) the
experiments on two datasets show our pama can achieve competitive performance
compared with sota mil methods and ssl methods."
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"patients with colorectal cancer typically undergo contrast-enhanced computed
tomography (cect) scans multiple times during follow-up visits after surgery for
early detection of crlm, generating a 5d dataset."
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"part of the reason is due to the
lack of public availability of such data."
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"e3d-lstm [12] shows
uni-directional lstm works well on natural videos while several other works show
bi-directional lstm is needed in certain medical image segmentation tasks
[2,7].in this paper, we investigate how state-of-art deep learning models can be
applied to the crlm prediction task using our 5d cect dataset."
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"we evaluate the
effectiveness of bi-directional lstm and explore the possible method of
incorporating different phases in the cect dataset."
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"our dataset follows specific inclusion criteria:-no tumor appears on the ct
scans."
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"-patients have two or
more times of cect scans.-we already determined whether or not the patients had
liver metastases within 2 years after the surgery, and manually labeled the
dataset based on this."
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"-no potential focal infection in the liver before the
colorectal radical surgery.-no metastases in other organs before the liver
metastases.-no other malignant tumors.our retrospective dataset includes two
cohorts from two hospitals."
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"additional statistics on our dataset are presented in table 1 and examples of
representative images are shown in fig."
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"the dataset is available upon
request."
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"we selected 170 patients who underwent three or more cect scans from our
original dataset, and cropped the images to only include the liver area, as
shown in fig."
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"to handle the imbalanced training dataset, we selected and
duplicated 60% of positive cases and 20% of negative cases by applying standard
scale jittering (ssj) [5]."
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"we used the a and v
phases of cect for our crlm prediction task since the p phase is only relevant
when tumors are significantly present, which is not the case in our dataset."
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"how to effectively address
inter-patient variability in the dataset, perhaps by better fusing the 5d
features, requires further research from the community in the future."
An Anti-biased TBSRTC-Category Aware Nuclei Segmentation Framework with a Multi-label Thyroid Cytology Benchmark,image dataset.
An Anti-biased TBSRTC-Category Aware Nuclei Segmentation Framework with a Multi-label Thyroid Cytology Benchmark,"we construct a clinical thyroid cytopathology dataset with images
of both image-wise and pixel-wise labels as a benchmark (appear in github upon
acceptance) some representative images are presented in fig."
An Anti-biased TBSRTC-Category Aware Nuclei Segmentation Framework with a Multi-label Thyroid Cytology Benchmark,"2, together with
the profile of the dataset."
An Anti-biased TBSRTC-Category Aware Nuclei Segmentation Framework with a Multi-label Thyroid Cytology Benchmark,"the dataset comprises 4,965 h&e stained image
patches and labels of tbsrtc, where a subset of 1,473 images was densely
annotated for nuclei boundaries by three experienced cytopathologists and
reached a total number of 31,064 elaborately annotated nuclei."
An Anti-biased TBSRTC-Category Aware Nuclei Segmentation Framework with a Multi-label Thyroid Cytology Benchmark,"we divided the dataset with image-wise labels into 80%
training samples and the remaining 20% testing samples."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"meanwhile, the size of multimodal
medical datasets is not as large as natural vision-language datasets, which
necessitates the need for data-efficient analytics to address the training
difficulty.to tackle above challenges, we propose a pathology-and-genomics
multimodal framework (i.e., pathomics) for survival prediction (fig."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"as a result, the task-specific finetuning
broadens the dataset usage (fig 1b andc), which is not limited by data modality
(e.g., both singleand multi-modal data)."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"our approach could achieve comparable performance even with fewer
finetuned data (e.g., only use 50% of the finetuned data) when compared with
using the entire finetuning dataset."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,datasets.
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,all image and genomics data are publicly available.
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"we collected wsis
from the cancer genome atlas colon adenocarcinoma (tcga-coad) dataset
(cc-by-3.0) [8,21] and rectum adenocarcinoma (tcga-read) dataset (cc-by-3.0)
[8,20], which contain 440 and 153 patients."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"we implement two types of
settings that involve internal and external datasets for model pretraining and
finetuning."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"as shown in fig 2a, we pretrain and finetune the model on the same
dataset (i.e., internal setting)."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"for the external setting, we implement pretraining and
finetuning on the different datasets, as shown in fig 2b ; we use tcga-coad for
pretraining; then, we only use tcga-read for finetuning and final evaluation."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"in table 1, our approach shows improved survival prediction performance on both
tcga-coad and tcga-read datasets."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"in
table 1, our method could yield better performance compared with baselines on
the small dataset across the combination of images and multiple types of
genomics data."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"approach broadens the scope of dataset inclusion, particularly
for model finetuning and evaluation, while enhancing model efficiency on
analyzing multimodal clinical data in real-world settings."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"for
tcga-coad dataset, we include 50%, 25%, and 10% of the finetuning data."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"for the
tcga-read dataset, as the number of uncensored patients is limited, we use 75%,
50%, and 25% of the finetuning data to allow at least one uncensored patient to
be included for finetuning."
Robust Cervical Abnormal Cell Detection via Distillation from Local-Scale Consistency Refinement,none
MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"the data set
utilized in the experiments consists of 80 wsis overall."
MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"one half (40) of the
data set consists of frozen and the other half (40) of paraffin sections [5]),
representing the different modalities."
MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"the
data set comprised 13 male and 27 female patients, corresponding to a slight
gender imbalance."
MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"q q q q q q q q 0 25 % 50 % 75 % 100 %
0.4 the data set was randomly separated into training (80 %) and test data (20
%)."
MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"data and source code
are publicly accessible via https://gitlab.com/mgadermayr/mixupmil."
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,datasets.
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"we conducted our experiments on the breast invasive carcinoma (brca)
dataset from the cancer genome atlas (tcga)."
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"specifically, the brca dataset
includes 661 patients with hematoxylin and eosin (he)-stained pathological
imaging and corresponding survival information."
Gene-Induced Multimodal Pre-training for Image-Omic Classification,"we use a simple multi-layer perceptron (mlp) head to map
cls pat to the final class predictions p , which can be written as p =
softmax(mlp(cls pat )).3 experiments datasets."
Gene-Induced Multimodal Pre-training for Image-Omic Classification,"we verify the effectiveness of our method on the caner genome atlas
(tcga) non-small cell lung cancer (nsclc) dataset, which contains two cancer
subtypes, i.e., lung squamous cell carcinoma (lusc) and lung adenocarcinoma
(luad)."
Gene-Induced Multimodal Pre-training for Image-Omic Classification,"firstly, we compare our proposed patch aggregator with the current
state-of-the-art deep mil models on unimodal tcga-nsclc dataset, i.e., only
pathological wsis are included as input."
Gene-Induced Multimodal Pre-training for Image-Omic Classification,"we can
observe in the table that, our gimp raises acc from 91.05% to 99.47% on
tcga-nsclc dataset."
Histopathology Image Classification Using Deep Manifold Contrastive Learning,"the dataset for the former task was collected from 168 patients
with 332 wsis from seoul national university hospital."
Histopathology Image Classification Using Deep Manifold Contrastive Learning,"the liver cancer dataset for the latter task was composed of 323 wsis,
in which the wsis can be further classified into hepatocellular carcinomas
(hccs) (collected from pathology ai platform [1]) and ihccs."
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"-we developed a comprehensive
pipeline for constructing tumor-associated stroma datasets across multiple data
sources, and employed adversarial training and neighborhood consistency
regularization techniques to learn robust multimodal-invariant image
representations."
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"in our study, we utilized three datasets for tumor-associated stroma
analysis.(1) dataset a comprises 513 tiles extracted from the whole mount slides
of 40 patients, sourced from the archives of the pathology department at
cedars-sinai medical center (irb# pro00029960)."
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"the tiles were
annotated at the pixel-level by expert pathologists to generate stroma tissue
segmentation masks and were cross-evaluated and normalized to account for stain
variability.(2) dataset b included 97 whole mount slides with an average size of
over 174,000×142,000 pixels at 40x magnification."
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"(3) dataset c comprised 6134 negative biopsy slides obtained from 262
patients' biopsy procedures, where all samples were diagnosed as negative."
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"dataset a was utilized for
training the stroma segmentation model."
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"this model was then applied to generate stroma
masks for all slides in datasets b and c."
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"to precisely isolate stroma tissues
and avoid data bleeding from epithelial tissues, we only extracted patches where
over 99.5% of the regions were identified as stroma at 40x magnification to
construct the stroma classification dataset.for positive tumor-associated stroma
patches, we sampled patches near tumor glands within annotated tumor region
boundaries, as we presumed that tumor regions represent zones in which the
greatest amount of damage has progressed."
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"to
incorporate multi-modal information, we randomly sampled negative stroma patches
from all biopsy slides in dataset c."
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"future research can focus on validating our
approach on larger and more diverse datasets and expanding the method to a
patient-level prediction system, ultimately improving prostate cancer diagnosis
and treatment."
Multi-scope Analysis Driven Hierarchical Graph Transformer for Whole Slide Image Based Cancer Survival Prediction,none
Thinking Like Sonographers: A Deep CNN Model for Diagnosing Gout from Musculoskeletal Ultrasound,none
Scribble-Based 3D Multiple Abdominal Organ Segmentation via Triple-Branch Multi-Dilated Network with Pixel- and Class-Wise Consistency,"we used the publicly available abdomen ct dataset word [17] for experiments,
which consists of 150 abdominal ct volumes from patients with rectal cancer,
prostate cancer or cervical cancer before radiotherapy."
Scribble-Based 3D Multiple Abdominal Organ Segmentation via Triple-Branch Multi-Dilated Network with Pixel- and Class-Wise Consistency,"following
the default settings in [17], the dataset was split into 100 for training, 20
for validation and 30 for testing, respectively, where the scribble annotations
for foreground organs and background in the axial view of the training volumes
had been provided and were used in model training."
Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"• we demonstrate the effectiveness of
our approach through experiments using mammography datasets, which show the
superiority of mammo-net.2 proposed method transformer-based mutualization
model."
CTFlow: Mitigating Effects of Computed Tomography Acquisition and Reconstruction with Normalizing Flows,"this study used two unique datasets: (1) the ucla low-dose chest ct dataset, a
collection of 186 exams acquired using siemens ct scanners at an equivalent dose
of 2 mgy following an institutional review board-approved protocol."
CTFlow: Mitigating Effects of Computed Tomography Acquisition and Reconstruction with Normalizing Flows,"the dataset was split into 80 scans for training, 20 for validation,
and 86 for testing."
CTFlow: Mitigating Effects of Computed Tomography Acquisition and Reconstruction with Normalizing Flows,"(2) aapm-mayo clinic low-dose ct ""grand challenge"" dataset,
a publicly available grand challenge dataset consisting of 5,936 abdominal ct
images from 10 patient cases reconstructed at 1.0 mm slice thickness."
CTFlow: Mitigating Effects of Computed Tomography Acquisition and Reconstruction with Normalizing Flows,"this dataset was only
used for evaluating image quality against other harmonization techniques."
DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,this study reports experiments on four mammography datasets.
DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,"the inbreast
dataset [7] consists of 115 exams with bi-rads labels and pixel-wise
anno-tations, comprising a total of 87 normal (bi-rads = 1) and 342 abnormal
(bi-rads = 1) images."
DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,"the ddsm dataset [3] consists of 2,620 cases, encompassing
6,406 normal and 4,042 (benign and malignant) images with outlines generated by
an experienced mammographer."
DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,"the vindr-mammo dataset [8] includes 5,000 cases
with bi-rads assessments and bounding box annotations, consisting of 13,404
normal (bi-rads = 1) and 6,580 abnormal (bi-rads = 1) images."
DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,"the in-house
dataset comprises 43,258 mammography exams from 10,670 women between 2004-2020,
collected from a hospital with irb approvals."
DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,"in this study, we randomly select
20% women of the full dataset, comprising 6,000 normal (bi-rads = 1) and 28,732
abnormal (bi-rads = 1) images."
DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,"due to a lack of annotations, the in-house
dataset is only utilized for classification tasks."
DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,"each dataset is randomly
split into training, validation, and testing sets at the patient level in an
8:1:1 ratio, respectively (except for that inbreast which is split with a ratio
of 6:2:2, to keep enough normal samples for the test).table 1."
DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,"comparison of
asymmetric and abnormal classification tasks on four mammogram datasets."
Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,"to achieve this goal, we
create a synthetic dataset, which has separate annotations for normal kidneys
and protruded regions, and train a segmentation network to separate the
protruded regions from the normal kidney regions."
Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,"verify
that the proposed framework achieves a higher dice score compared to the
standard 3d u-net using a publicly available dataset."
Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,"the release of two public ct image datasets with kidney and tumor masks from the
2019/2021 kidney and kidney tumor segmentation challenge [8] (kits19, kits21)
attracted researchers to develop various methods for segmentation.looking at the
top 3 teams from each challenge [6,11,13,17,21], all teams utilized 3d u-net [3]
or v-net [16], which bears a similar architecture."
Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,we train this network using synthetic datasets.
Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,"the details of the
dataset and training procedures are described in sect."
Skin Lesion Correspondence Localization in Total Body Photography,none
Anatomy-Informed Data Augmentation for Enhanced Prostate Cancer Detection,"it plays a crucial role in
medical image analysis [8] where annotated datasets are only available with
limited size."
Anatomy-Informed Data Augmentation for Enhanced Prostate Cancer Detection,"this technique allows us
to simulate different physiological states during the training and enrich our
dataset with a wider range of organ and lesion shapes."
Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,none
Radiomics-Informed Deep Learning for Classification of Atrial Fibrillation Sub-Types from Left-Atrium CT Volumes,dataset.
Radiomics-Informed Deep Learning for Classification of Atrial Fibrillation Sub-Types from Left-Atrium CT Volumes,"we use a dataset of 172 patients containing 94 paaf and 78 peaf cases
collected from the sun yat-sen memorial hospital in china."
Radiomics-Informed Deep Learning for Classification of Atrial Fibrillation Sub-Types from Left-Atrium CT Volumes,"cross-validation is implemented by
splitting the dataset into five equal subsets and using three subsets for
training, one subset for validation, and one subset for testing."
Radiomics-Informed Deep Learning for Classification of Atrial Fibrillation Sub-Types from Left-Atrium CT Volumes,"experiments on larger
datasets or alternative tasks can also be done to provide more empirical
support, since current results show only slight improvements over baseline."
Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-Based Hierarchical Fusion Network with Attention Mechanism,none
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"this dataset included 303 biopsy-proven (stage i-ivb) npc patients who
received radiation treatment during 2012-2016."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"the use of this dataset was approved by the institutional review board
of the university of hong kong/hospital authority hong kong west cluster (hku/ha
hkw irb) with reference number uw21-412, and the research ethics committee
(kowloon central/kowloon east) with reference number kc/ke-18-0085/er-1."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"the details of patient
characteristics and the number split for training and testing of each dataset
were illustrated in table 1."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"prior to model training, mri images were resampled
to 256*224 by bilinear interpolation [14] due to the inconsistent matrix sizes
of the three datasets."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"different from the original
study, which used single institutional data for model development and utilized
min-max value of the whole dataset for data normalization, in this work, we used
mean and standard deviation of each individual patient to normalize mri
intensities due to the heterogeneity of the mri intensities across institutions
[15]."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"ji measures
similarity of two datasets, which ranges from 0% to 100%."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"due to both real patients and synthetic
patients were involved in delineation, to erase the delineation memory of the
same patient, we separated the patients to two datasets, each with the same
number of patients, both two datasets with mixed real patients and synthetic
patients without overlaps (i.e., the ce-mri and vce-mri from the same patient
are not in the same dataset).when finished the first dataset delineation, there
was a one-month interval before the delineation of the second dataset."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"the average ji obtained from institution-1,
institution-2, and institution-3 dataset were similar with a result of 71.54%,
74.78% and 75.85%, respectively."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"our ct scan dataset consists of 62, 420 patients from 16 different sites across
north america, asia and europe."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"our 3d camera dataset consists of 2, 742 pairs
of depth image and ct scan from 2, 742 patients from 6 different sites across
north america and europe acquired using a ceiling-mounted kinect 2 camera."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"we trained our autodecoder model on our unpaired ct scan dataset of 62, 420
patients with a latent vector of size 32."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"the encoder was trained on our paired
ct scan and depth image dataset of 2, 742 patients."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"our method finds common patterns of disease progression in datasets of
longitudinal images."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"clinicians
suspect that this is due to the grading system's reliance on static biomarkers
that are unable to capture temporal dynamics which contain critical information
for assessing progression risk.in their search for new biomarkers, clinicians
have annotated known biomarkers in longitudinal datasets that monitor patients
over time and mapped them against disease progression [2,16,19]."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"however, these
approaches neglect temporal relationships between images and the obtained
biomarkers are by definition static and cannot capture the dynamic nature of the
disease.our contribution: in this work, we present a method to automatically
propose biomarkers that capture temporal dynamics of disease progression in
longitudinal datasets (see fig."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,we use two retinal oct datasets curated in the scope of the pinnacle study [20].
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"we first design and test our method on a development dataset, which was
collected from the southampton eye unit."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"afterwards, we test our method on a
second independent unseen dataset, which was obtained from moorfields eye
hospital."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"after strict quality control, the development
dataset consists of 46,496 scans of 6,236 eyes from 3,456 patients."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"the
unseen dataset is larger, containing 114,062 scans of 7,253 eyes from 3,819
patients."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"initially, we tune the hyperparameters, λ, φ and k, on the development dataset
by heuristically selecting values that result in higher uniformity between
subtrajectories within each cluster."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"next, using the
same hyperparameters we apply the method directly to the unseen dataset."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"the
ophthalmologists then review these clusters and confirm whether they capture the
same temporal biomarkers observed in the development dataset.in addition to the
qualitative evaluation, we also validate the utility of our clusters as
biomarkers that stratify risk of disease progression."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"sub-trajectory clusters are candidate temporal biomarkers: by first applying our
method to the development dataset we found that using λ = 0.75, φ = 0.75 and k =
30 resulted in the most uniform and homogeneous clusters while still limiting
the total number of clusters to a reasonable amount."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"using the same
hyperparameters our method generalised to the unseen dataset which yielded
clusters with equivalent dynamics and quality (see fig."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"ophthalmologists
identified clusters capturing the same variants of temporal progression in both
datasets."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"we applied our method to two large longitudinal datasets, cataloguing 3,218
total years of disease progression."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"as late stage patients were overrepresented in our datasets, we
also intend to apply our method to datasets with greater numbers of patients
progressing from earlier disease stages."
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"moreover, the automatic delineation of the gtv in the esophagus poses a
significant difficulty, primarily attributable to the low contrast between the
esophageal gtv and the neighboring tissue, as well as the limited
datasets.recently, advances in deep learning [21] have promoted research in
automatic esophageal gtv segmentation from computed tomography (ct) [18,19]."
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"meanwhile, an ideal method
for automatic esophageal gtv segmentation in the second course of rt should
consider three key aspects: 1) changes in tumor volume after the first course of
rt, 2) the proliferation of cancerous cells from a tumor to neighboring healthy
cells, and 3) the anatomical-dependent our training approach leverages
multi-center datasets containing relevant annotations, that challenges the
network to retrieve information from e1 using the features from e2."
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"our training strategy leverages three datasets that introduce prior
knowledge to the network of the following three key aspects: 1) tumor volume
variation, 2) cancer cell proliferation, and 3) reliance of gtv on esophageal
anatomy.nature of gtv on esophageal locations."
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"to achieve this, we efficiently
exploit knowledge from multi-center datasets that are not tailored for
second-course gtv segmentation."
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"we utilize the 3d dice [14] loss function, datasets."
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"the paired first-second course dataset, s p , is collected from sun
yat-sen university cancer center (ethics approval number: b2023-107-01),
comprising paired ct scans of 69 distinct patients from south china."
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"we
collected the gtv dataset s v from medmind technology co., ltd., which has ct
scans from 179 patients."
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"to demonstrate the presence of a domain gap between the first and second
courses, we train sota methods with datasets s train p and s v , by feeding the
data sequentially into the network."
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"notably, the paired first-second course dataset s test p pertains
to the same group of patients, thereby ensuring that any performance drop can be
attributed solely to differences in courses of rt, rather than variations across
different patients.figure 2 illustrates the reduction in the gtv area after the
initial course of rt, where the transverse plane is taken from the same location
relative to the vertebrae (yellow lines)."
CLIP-Lung: Textual Knowledge-Guided Lung Nodule Malignancy Prediction,dataset.
CLIP-Lung: Textual Knowledge-Guided Lung Nodule Malignancy Prediction,"lidc-idri [1] is a dataset for pulmonary nodule classification or
detection based on low-dose ct, which involves 1,010 patients."
CLIP-Lung: Textual Knowledge-Guided Lung Nodule Malignancy Prediction,"in this paper, we construct
three sub-datasets: lidc-a contains three classes of nodules both in training
and test sets; according to [11], we construct the lidc-b, which contains three
classes of nodules only in the training set, and the test set contains benign
and malignant nodules; lidc-c includes benign and malignant nodules both in
training and test sets.experimental settings."
Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"most cad studies were developed on regular and selected
datasets in the laboratory environment, which avoided the problems (data noise,
missing data, etc.) in the clinical scenarios [3,6,9,13,18]."
Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"the former implicitly interacts with
multi-label information, making it difficult to fully utilize the correlation
among labels; and the latter requires the use of word embeddings pre-trained on
public databases, which is not friendly to many medical domain proper nouns."
Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"in addition, none of the current multi-label cad studies have
considered the problem of missing labels and noisy labels.considering these
real-world challenges, we propose a multi-label model named self-feedback
transformer (sft), and validate our method on a realworld pnens dataset."
Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,real-world pnens dataset.
Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"we validated our method on a real-world pnens dataset
from two centers."
Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"the dataset contained 264 and 28 patients in center 1 and
center 2, and a senior radiologist annotated the bounding boxes for all 408 and
28 lesions."
Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"it is
obvious that the real-world dataset has a large number of labels with randomly
missing data, thus, we used an adjusted 5-fold cross-validation."
Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"taking a
patient as a sample, we chose the dataset from center 1 as the internal dataset,
of which the samples with most of the main labels were used as dataset 1 (219
lesions) and was split into 5 folds, and the remaining samples are randomly
divided into the training set dataset 2 (138 lesions) and the validation set
dataset 3 (51 lesions), the training set and the validation set of the
corresponding folds were added during cross-validation, respectively."
Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"details of each dataset are in
the supplementary material."
Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,dataset evaluation metrics.
Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"we evaluate the
performance of our method on the 10 main tasks for internal dataset, and due to
missing labels and too few sstr2 labels, only the performance of predicting rt,
pfs, os, gd, mtf are evaluated for external dataset."
Physics-Informed Conditional Autoencoder Approach for Robust Metabolic CEST MRI at 7T,none
Deep Unsupervised Clustering for Conditional Identification of Subgroups Within a Digital Pathology Image Set,"however, there is a practical need to be
able to guide the deep clustering model towards the identification of grouping
structures in a given dataset that have not been already annotated."
A Texture Neural Network to Predict the Abnormal Brachial Plexus from Routine Magnetic Resonance Imaging,"this paper constructed a bp dataset with the most commonly used bp
mris in our clinical practice."
A Texture Neural Network to Predict the Abnormal Brachial Plexus from Routine Magnetic Resonance Imaging,"the major contributions of this study include 1) directed
triangle construction idea for tpp, 2) huge number of tpp matrices as the
heterogeneity representations of bp, 3) tppnet with 15 layers and huge number of
channels, 4) the bp dataset containing mr images and their corresponding roi
masks."
A Texture Neural Network to Predict the Abnormal Brachial Plexus from Routine Magnetic Resonance Imaging,"the final dataset for radiomic analysis was
constructed by merging the datasets for each sequence type."
A Texture Neural Network to Predict the Abnormal Brachial Plexus from Routine Magnetic Resonance Imaging,"only patients that
had all three sequences segmented (t2, t1 and post-gadolinium) were included in
the dataset."
A Texture Neural Network to Predict the Abnormal Brachial Plexus from Routine Magnetic Resonance Imaging,table 1 shows a breakdown of the final dataset.
Prompt-Based Grouping Transformer for Nucleus Detection and Classification,"consep 1 [10] is a colorectal nuclear dataset with three types, consisting of 41
h&e stained image tiles from 16 colorectal adenocarcinoma whole-slide images
(wsis)."
Prompt-Based Grouping Transformer for Nucleus Detection and Classification,"we split them following the official partition [1,10].is a breast cancer
dataset with three types and consists of 120 image tiles from 113 patients."
Prompt-Based Grouping Transformer for Nucleus Detection and Classification,"we follow the work [1] to apply the slic [2] algorithm to generate
superpixels as instances and split them into 80/10/30 slides for
training/validation/testing.lizard 3 [9] has 291 histology images of colon
tissue from six datasets, containing nearly half a million labeled nuclei in h&e
stained colon tissue."
Prompt-Based Grouping Transformer for Nucleus Detection and Classification,"our method is trained with
pytorch on a 48 gb gpu (nvidia a100) for 12-24 h (depending on the dataset
size)."
Simulation of Arbitrary Level Contrast Dose in MRI Using an Iterative Global Transformer Model,"acquiring such a dataset requires
modification of the standard imaging protocol and involves additional training
of the mr technicians."
Simulation of Arbitrary Level Contrast Dose in MRI Using an Iterative Global Transformer Model,"to this effect, we introduce a vision transformer based dl model1
that can synthesize brain 2 mri images that correspond to arbitrary dose levels,
by training on a highly imbalanced dataset with only t1w pre-contrast, t1w 10%
low-dose, and t1w ce standard dose images."
Simulation of Arbitrary Level Contrast Dose in MRI Using an Iterative Global Transformer Model,"dataset: with irb approval and informed consent, we retrospectively used 126
clinical cases (113 training, 13 testing) from a internal private dataset3 using
gadoterate meglumine contrast agent (site a)."
TractCloud: Registration-Free Tractography Parcellation with a Novel Local-Global Streamline Point Cloud Representation,"in the challenging btp (tumor patients) dataset, tractcloud reg-free
obtains significantly lower tda values than sota methods and comparable
performance to tractcloud regist ."
Relaxation-Diffusion Spectrum Imaging for Probing Tissue Microarchitecture,none
Brain Anatomy-Guided MRI Analysis for Assessing Clinical Progression of Cognitive Impairment with Structural MRI,"while it
is often challenging to annotate mris in practice, there are a large number of
mris (without task-specific category labels) in existing large-scale datasets."
Brain Anatomy-Guided MRI Analysis for Assessing Clinical Progression of Cognitive Impairment with Structural MRI,"this implies
that the brain anatomical mri features learned by our pretext model on
large-scale datasets would be more discriminative, compared with those used in
the competing methods."
atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning,"the method is implemented as the tool attractive in
mitk diffusion1 , enabling researchers to quickly and intuitively segment tracts
in pathological datasets or other situations not covered by automatic
techniques, simply by annotating a few but informative streamlines."
atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning,"the proposed technique was tested on a healthy-subject dataset and on a dataset
containing tumor cases."
atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning,"we focused on the left optic radiation (or), the left
cortico-spinal tract (cst), and the left arcuate-fasciculus (af), representing a
variety of established tracts.to test the proposed method on pathological data,
we used an in-house dataset containing ten presurgical scans of patients with
brain tumors."
Single-subject Multi-contrast MRI Super-resolution via Implicit Neural Representations,"we extensively evaluate our method on multiple
brain mri datasets and show that it achieves high visual quality for different
contrasts and views and preserves pathological details, highlighting its
potential clinical usage.related work."
Single-subject Multi-contrast MRI Super-resolution via Implicit Neural Representations,"however, all current mcsr approaches are limited by their need
for a large training dataset."
Single-subject Multi-contrast MRI Super-resolution via Implicit Neural Representations,datasets.
Single-subject Multi-contrast MRI Super-resolution via Implicit Neural Representations,"we
conduct experiments on two public datasets, brats [16], and msseg [4], and an
in-house clinical ms dataset (cms)."
Single-subject Multi-contrast MRI Super-resolution via Implicit Neural Representations,"in each dataset, we select 25 patients that
fulfill the isotropic acquisition criteria for both ground truth hr scans."
Single-subject Multi-contrast MRI Super-resolution via Implicit Neural Representations,"for mcsr from single-subject scans, we achieve
encouraging results across all metrics for all datasets, contrasts, and views."
Single-subject Multi-contrast MRI Super-resolution via Implicit Neural Representations,"lastly, given their similar physical acquisition
and lesion sensitivity, we note that dir/flair benefit to the same degree in the
cms dataset.qualitative analysis."
Single-subject Multi-contrast MRI Super-resolution via Implicit Neural Representations,"figure 2 shows the typical behavior of our
models on cms dataset, where one can qualitatively observe that the split-head
inr pre-serves the lesions and anatomical structures shown in the yellow boxes,
which other models fail to capture."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"second, resting-state fmri data are not routinely collected for gbm clinical
practices, which restricts the size of annotated datasets such that it is
infeasible to train a reliable prediction model based on deep learning for
survival prediction."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"similar to data augmentation schemes, we can artificially
boost data volume (i.e., fln maps) up to m times through producing m fln maps
for each patient in the a-lnm, which helps to mitigate the risk of over-fitting
and improve the performance of overall survival time prediction when learning a
deep neural network from a small sized dataset.for this reason, we propose the
name ""augmented lnm (a-lnm)"", compared to the traditional lnm where only one fln
map is generated per patient by averaging all the n fdc maps."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"to evaluate the predictive
power of the fln maps generated by our a-lnm, we conduct extensive experiments
on 235 gbm patients in the training dataset of brats 2020 [18] to classify the
patients into three overall survival time groups viz."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"it publicly released preprocessed
restingstate fmri data of 1000 healthy right-handed subjects with an average age
21.5 ± 2.9 years and approximately equal numbers of males and females from the
brain genomics superstruct project (gsp) [5], where the concrete image
acquisition parameters and preprocessing procedures can be found as well."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"it provided an open-access pre-operative imaging training dataset to
segment brain tumors of glioblastoma (gbm, belonging to high grade glioma) and
low grade glioma (lgg) patients, as well as to predict overall survival time of
gbm patients [18]."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"this training dataset contained 133 lgg and 236 gbm patients,
and each patient had four mri modalities, including t1, post-contrast
t1-weighted, t2-weighted, and t2 fluid attenuated inversion recovery."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"in this paper, we propose to investigate the feasibility of the novel
neuroimaging features, i.e., fln maps, for overall survival time prediction of
gbm patients in the training dataset of the brats 2020, in which one patient
alive was excluded, and the remaining 235 patients consisted of 89 short-term
survivors (less than 10 months), 59 mid-term survivors (between 10 and 15
months), and 87 long-term survivors (more than 15 months)."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"we evaluated
the classification performance of our proposed method using 235 gbm patients in
the brats 2020 training dataset, because only these 235 patients had both
overall survival time and manual expert segmentation labels of lesions."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"experimental results on the brats 2020 training dataset validated the
effectiveness of the a-lnm derived fln maps for gbm survival prediction."
A Multi-task Network for Anatomy Identification in Endoscopic Pituitary Surgery,none
Intraoperative CT Augmentation for Needle-Based Liver Interventions,"we note that public data sets
such as deeplesion [24], 3dircadb-01 [25] and others do not fit our problem
since they do not include the ncct images."
Optical Coherence Elastography Needle for Biomechanical Characterization of Deep Tissue,none
Pelvic Fracture Segmentation Using a Multi-scale Distance-Weighted Neural Network,"although large-scale datasets on pelvic segmentation have been studied in some
research [13], to the best of our knowledge, currently there is no
well-annotated fractured pelvic dataset publicly available."
Pelvic Fracture Segmentation Using a Multi-scale Distance-Weighted Neural Network,"therefore, we
curated a dataset of 100 preoperative ct scans covering all common types of
pelvic fractures."
Towards Multi-modal Anatomical Landmark Detection for Ultrasound-Guided Brain Tumor Resection with Contrastive Learning,"we developed and validated the proposed technique with the
public resect database [10] and compared its landmark detection accuracy against
the popular scale-invariant feature transformation (sift) algorithm in 3d [11]."
Towards Multi-modal Anatomical Landmark Detection for Ultrasound-Guided Brain Tumor Resection with Contrastive Learning,"table 1 lists the mean and standard deviation of landmark identification errors
(in mm) between the predicted position and the ground truth in intra-operative
us for each patient of the resect dataset."
Surgical Video Captioning with Mutual-Modal Concept Alignment,neurosurgery video captioning dataset.
Surgical Video Captioning with Mutual-Modal Concept Alignment,"to evaluate the effectiveness of surgical
video captioning, we collect a large-scale dataset with 41 surgical videos of
endonasal skull base neurosurgery."
Surgical Video Captioning with Mutual-Modal Concept Alignment,"we split these video
clips at patientlevel, where the video clips of 31 patients are used for
training and the rest of 10 patients are utilized for test.endovis image
captioning dataset."
Surgical Video Captioning with Mutual-Modal Concept Alignment,"we further compare our method with state-of-the-arts on the
public endovis-2018 image captioning dataset [1,23]."
Surgical Video Captioning with Mutual-Modal Concept Alignment,"this dataset reveals
robotic nephrectomy procedures acquired by the da vinci x or xi system, and is
annotated with surgical actions between 9 possible tools and surgical targets
[23]."
Surgical Video Captioning with Mutual-Modal Concept Alignment,"in this way, these two datasets can comprehensively evaluate
the captioning tasks under both surgical videos and images.implementation
details."
Surgical Video Captioning with Mutual-Modal Concept Alignment,"we optimize the sca-net and compared captioning
methods using adam with the batch size of 12 for both captioning datasets."
Surgical Video Captioning with Mutual-Modal Concept Alignment,"all
models are trained for 20 and 50 epochs in neurosurgery and endovis datasets,
respectively."
Regularized Kelvinlet Functions to Model Linear Elasticity for Image-to-Physical Registration of the Breast,"establishing point cloud correspondences using machine learning has
been demonstrated on liver and prostate datasets [8,9]."
Regularized Kelvinlet Functions to Model Linear Elasticity for Image-to-Physical Registration of the Breast,"sensitivity to
regularized kelvinlet function hyperparameters is explored on a supine mr breast
imaging dataset."
Regularized Kelvinlet Functions to Model Linear Elasticity for Image-to-Physical Registration of the Breast,"the first explores sensitivity
to regularized kelvinlet function hyperparameters k grab , k twist , ε grab ,
and ε twist and establishes optimal hyperparameters in a training dataset of 11
breast deformations."
Regularized Kelvinlet Functions to Model Linear Elasticity for Image-to-Physical Registration of the Breast,"this dataset consists of supine breast mr images simulating surgical
deformations from one breast cancer patient."
Regularized Kelvinlet Functions to Model Linear Elasticity for Image-to-Physical Registration of the Breast,"the image-to-image registration method was a symmetric
diffeomorphic method with explicit b-spline regularization publicly available in
the advanced normalization toolkit (ants) repository [19,20]."
Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"we choose to use a neural image analogy method that combines
the texture of a source image with a high-level content representation of a
target image without the need for a large dataset [1]."
Learning Expected Appearances for Intraoperative Registration During Neurosurgery,dataset.
Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"we tested our method retrospectively on 6 clinical datasets from 6
patients (cases) (see fig."
Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"we generated 100 poses for each 3d mesh (i.e.: each
case) and used a total of 15 unique textures from human brain surfaces
(different from our 6 clinical datasets) for synthesis using s θ ."
Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"because a conventional train/validation/test split would lead to texture
contamination, we created our validation dataset so that at least one texture is
excluded from the training set."
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"we present results on a clinical
dataset comprising fifty post-operative glioblastoma (gbm) patients."
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"the dose prediction model was trained on an in-house dataset comprising a total
of 50 subjects diagnosed with post-operative gbm."
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"we
divided the dataset into training (35 cases), validation (5 cases), and testing
(10 cases)."
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"we refer the reader to [9] for further details.segmentation models:
to develop and test the proposed approach, we employed a separate in-house
dataset (i.e., different cases than those used to train the dose predictor
model) of 50 cases from post-operative gmb patients receiving standard rt
treatment."
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"we divided the dataset into training (35 cases), validation (5
cases), and testing (10 cases)."
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"3 the tumor presents a non-convex
shape alongside the skull's parietal lobe, which was not adequately modeled by
the training dataset used to train the segmentation models."
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"these first results on a dataset of post-operative gbm
patients show the ability of the proposed doselo to deliver improved
dosimetric-compliant segmentation results."
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,none
FocalErrorNet: Uncertainty-Aware Focal Modulation Network for Inter-modal Registration Error Estimation in Ultrasound-Guided Neurosurgery,"for methodological development and assessment, we used the resect
(retro-spective evaluation of cerebral tumors) dataset [16], which has
pre-operative mri, and ius scans at different surgical stages from 23 subjects
who underwent low-grade glioma resection surgeries."
FocalErrorNet: Uncertainty-Aware Focal Modulation Network for Inter-modal Registration Error Estimation in Ultrasound-Guided Neurosurgery,"to create the silver registration ground truths, we
used the homologous landmarks between mri and ius in the resect dataset to
perform landmark-based 3d b-spline nonlinear registration to register ius to the
corresponding mri for all 22 cases."
FocalErrorNet: Uncertainty-Aware Focal Modulation Network for Inter-modal Registration Error Estimation in Ultrasound-Guided Neurosurgery,"the two dl models were trained with the same dataset and
procedure, and their prediction accuracies, measured as the absolute error
between the predicted and ground truths mis-registration on the test set were
compared with two-sided pairedsamples t-tests to confirm the superiority of the
proposed method, in addition to correlations between their estimated and ground
truth errors."
FocalErrorNet: Uncertainty-Aware Focal Modulation Network for Inter-modal Registration Error Estimation in Ultrasound-Guided Neurosurgery,"one limitation of our work
lies in the limited patient data, as public ius datasets are scarce, while the
settings and properties of us scanners can vary, potentially affecting the dl
model designs."
Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"cancer remains a significant public health challenge worldwide, with a new
diagnosis occurring every two minutes in the uk (cancer research uk 1 )."
Unified Brain MR-Ultrasound Synthesis Using Multi-modal Hierarchical Representations,"we evaluated our method on a dataset of 66
consecutive adult patients with brain gliomas who were surgically treated at the
brigham and women's hospital, boston usa, where both pre-operative 3d t2-space
and pre-dural opening intraoperative us (ius) reconstructed from a tracked
handheld 2d probe were acquired."
Unified Brain MR-Ultrasound Synthesis Using Multi-modal Hierarchical Representations,"the dataset was randomly split into a
training set (n = 56) and a testing set (n = 10)."
StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,dataset and preprocessing.
StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"our clinical dataset consists of 108 patients for
whom were acquired both a pre-operative h&n ct scan and 4 to 11 wsis after
laryngectomy (with a total amount of 849 wsis)."
StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"we split the dataset patient-wise into three
groups for training (64), validation (20), and testing (24)."
StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"to demonstrate the
performance of our model on another application, we also retrieved the datasets
from [14] for pelvis 3d ct/2d mr."
StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"according to the mr/ct application in rt, we compared our model against
the state-of-the-art results of msv-regsynnet which were computed on the same
dataset."
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"we trained our model with a large dataset of 3500 cts of
patients with head-and-neck cancer, more exactly 2297 patients from the publicly
available the cancer imaging archive (tcia) [1,6,16,17,28,32] and 1203 from
private internal data, after obtention of ethical approbations."
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"to
evaluate our approach, we used an external private cohort of 80 patients who had
undergone radiotherapy for head-and-neck cancer, with their consent."
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"for
reference, compared to 3dstylegan [10], our model achieved half their fid score
on another brain mri dataset, with comparable ms-ssim."
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"additionally, no public
implementation is available."
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"this approach may provide coarse
reconstructions for patients with rare abnormalities, as most learning methods,
but a larger dataset or developing a prior including tissue abnormalities could
improve robustness."
Structure-Preserving Synthesis: MaskGAN for Unpaired MR-CT Translation,the dataset comprises brain mr and ct volumes from 262 subjects.
Structure-Preserving Synthesis: MaskGAN for Unpaired MR-CT Translation,"the dataset is divided into
249, 1 and 12 subjects for training, validating and testing set."
FreeSeed: Frequency-Band-Aware and Self-guided Network for Sparse-View CT Reconstruction,"we conduct experiments on the dataset of ""the 2016 nih-aapm mayo clinic low dose
ct grand challenge"" [8], which contains 5,936 ct slices in 1 mm image thickness
from 10 anonymous patients, where a total of 5,410 slices from 9 patients,
resized to 256 × 256 resolution, are randomly selected for training and the 526
slices from the remaining one patient for testing without patient overlap."
Co-learning Semantic-Aware Unsupervised Segmentation for Pathological Image Registration,"to create
such a mapping, we created a pseudo dataset by utilizing images from the oasis-1
and brats2020."
Co-learning Semantic-Aware Unsupervised Segmentation for Pathological Image Registration,"from the resulting t1 sequences, a pseudo dataset of 300 images
was randomly selected for further analysis."
Co-learning Semantic-Aware Unsupervised Segmentation for Pathological Image Registration,"appendix b provides a detailed
process for creating the pseudo dataset.real data with landmarks."
Co-learning Semantic-Aware Unsupervised Segmentation for Pathological Image Registration,"after creating the pseudo dataset, we warped brain mr images without tumors to
the atlas and used the resulting deformation field as the gold standard for
evaluation."
Fast Reconstruction for Deep Learning PET Head Motion Correction,"multi-subject studies were conducted on a dataset of 20 subject and its results
were quantitatively and qualitatively evaluated by molar reconstruction studies
and corresponding brain region of interest (roi) standard uptake values (suv)
evaluation."
Revealing Anatomical Structures in PET to Generate CT for Attenuation Correction,"the data used in our experiments are collected from the cancer image archive
(tcia) [4] (https://www.cancerimagingarchive.net/collections/), where a series
of public datasets with different types of lesions, patients, and scanners are
open-access."
Revealing Anatomical Structures in PET to Generate CT for Attenuation Correction,"we use
these samples in hnscc for training and in other three datasets for
evaluation.each sample contains co-registered (acquired with pet-ct scans) ct,
pet, and nac-pet whole-body scans."
DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"note that the network will be trained
only once, on a fixed dataset that is fully independent of the datasets that
will be used in the evaluation (see sect."
DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,4).dataset.
DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"our neural network is
trained using patches from the ""gold atlas -male pelvis -gentle radiotherapy""
[14] dataset, which is comprised of 18 patients each with a ct, mr t1, and mr t2
volumes."
DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"we would like to report that, initially, we also made use of a
proprietary dataset including us volumes."
DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"consequently, for
the purpose of ensuring reproducibility, all evaluations presented in this paper
exclusively pertain to the model trained solely on the public mr-ct
dataset.patch sampling from unregistered datasets."
DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"the dataset comprises 8 sets of mr and ct volumes, both depicting the
abdominal region of a single patient and exhibiting notable deformations."
DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"as the most challenging experiment, we finally use our method to achieve
deformable registration of abdominal 3d freehand us to a ct or mr volume.we are
using a heterogeneous dataset of 27 cases, comprising liver cancer patients and
healthy volunteers, different ultrasound machines, as well as optical vs."
DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"all 3d ultrasound data sets are accurately calibrated, with overall
system errors in the range of commercial ultrasound fusion options."
Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"to illustrate the efficiency of our proposed approach, we conduct
rigorous experiments on several real clinical datasets; the experimental results
reveal the advantages of our approach over several state-of-the-art ct
reconstruction methods."
Solving Low-Dose CT Reconstruction via GAN with Local Coherence,datasets.
Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"first, our proposed approaches are evaluated on the ""mayo-clinic
low-dose ct grand challenge"" (mayo-clinic) dataset of lung ct images [19].the
dataset contains 2250 two dimensional slices from 9 patients for training, and
the remaining 128 slices from 1 patient are reserved for testing."
Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"to evaluate the
generalization of our model, we also consider another dataset rider with
nonsmall cell lung cancer under two ct scans [36] for testing."
Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"we randomly
select 4 patients with 1827 slices from the dataset."
Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"to evaluate the stability and generalization of our model and the
baselines trained on mayo-clinic dataset, we also test them on the rider
dataset."
Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"due to the bias in the datasets
collected from different facilities, the performances of all the models are
declined to some extents."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"this was not the case for noise2aliasing, and
historical clinical data sufficed for training.we validated our method on
publicly available data [15] against a supervised approach [6] and applied it to
an internal clinical dataset of 30 lung cancer patients."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"we explore different
dataset sizes to understand their effects on the reconstructed images."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"first, we used the spare varian dataset to study whether noise2aliasing can
match the performance of the supervised baseline and if it can outperform it
when adding noise to the projections."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"then, we use the internal dataset to
explore the requirements for the method to be applied to an existing clinical
dataset."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"given two volumes (x, y), the
training pairs (x i (k) , y i (k) ) are the same i-th slice along the k-th
dimension of each volume chosen to be the axial plane.the datasets used in this
study are two:1."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"the spare varian dataset was used to provide performance
results on publicly available patient data."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"to more closely resemble normal
respiratory motion per projection image, the 8 min scan has been used from each
patient (five such scans are available in the dataset)."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"the hyperparameters are
optimized over the training dataset.2."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"an internal dataset (irb approved) of 30
lung cancer patients' 4dcbcts from 2020 to 2022, originally used for igrt, with
25 patients for training and 5 patients for testing."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"the
data were anonymized prior to analysis.projection noise was added using the
poisson distribution to the spare varian dataset to evaluate the ability of the
unsupervised method to reduce it."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"for the spare varian dataset, we use the rois defined provided
[15] and used the 3d reconstruction using all the projections available as a
ground truth."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"for the internal dataset, we deformed the planning ct to each of
the phases reconstructed using the fdk algorithm and evaluate the metric over
only the 4dcbct volume boundaries."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"1,
noise2aliasing matches the visual quality of the supervised approach on the
low-noise dataset on both soft tissue and bones."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"1 and table 1, the supervised approach reproduces the noise
that was seen during training, while noise2aliasing manages to remove it
consistently, outperforming the supervised approach, especially in the soft
tissue area around the lungs, where the noise affects attenuation coefficients
the most.noise2aliasing is capable of reducing the artifacts present in
reconstructions caused by stochastic noise in the projections used,
outperforming the supervised baseline.internal dataset."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"reconstruction using
noise2aliasing with different-sized datasets."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"however, the model also tends to remove small
anatomical structures as high-frequency objects that cannot be distinguished
from the noise.when applied to a clinical dataset, noise2aliasing benefits from
more patients being included in the dataset, however, qualitatively good
performance is already achieved with 5 patients."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"we have empirically demonstrated its performance on a publicly available
dataset and on an internal clinical dataset."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"noise2aliasing can be trained on
existing historical datasets and does not require changing current clinical
practices."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"the method removes noise more reliably when the dataset size is
increased, however further analysis is required to establish a good quantitative
measurement of this phenomenon."
DULDA: Dual-Domain Unsupervised Learned Descent Algorithm for PET Image Reconstruction,none
Low-Dose CT Image Super-Resolution Network with Dual-Guidance Feature Distillation and Dual-Path Content Communication,none
Non-iterative Coarse-to-Fine Transformer Networks for Joint Affine and Deformable Image Registration,"extensive experiments with seven public datasets show that our
nice-trans outperforms state-of-the-art registration methods on both
registration accuracy and runtime."
Non-iterative Coarse-to-Fine Transformer Networks for Joint Affine and Deformable Image Registration,"we followed the dataset settings
in [18]: 2,656 brain mri images acquired from four public datasets (adni [27],
abide [28], adhd [29], and ixi [30]) were used for training; two public brain
mri datasets with anatomical segmentation (mindboggle [31] and buckner [32])
were used for validation and testing."
Non-iterative Coarse-to-Fine Transformer Networks for Joint Affine and Deformable Image Registration,"the mindboggle dataset contains 100 mri
images and were randomly split into 50/50 images for validation/testing."
Non-iterative Coarse-to-Fine Transformer Networks for Joint Affine and Deformable Image Registration,"the
buckner dataset contains 40 mri images and were used for testing only."
Non-iterative Coarse-to-Fine Transformer Networks for Joint Affine and Deformable Image Registration,"in
addition to the original settings of [18], we adopted an additional public brain
mri dataset (lpba [33]) for testing, which contains 40 mri images.we performed
brain extraction and intensity normalization for each mri image with freesurfer
[32]."
Trackerless Volume Reconstruction from Intraoperative Ultrasound Images,"clips were created by sliding a window of 7
frames (corresponding to a value of k = 2) with a stride of 1 over each
continuous sequence, yielding a data set that contains a total of 13734 clips."
CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,datasets and baselines.
CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,"we evaluated cola-diff on two multi-contrast brain mri
datasets: brats 2018 and ixi datasets."
CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,"the ixi1 dataset consists of 200 multi-contrast mris from healthy
brains, plit them into (140:25:35) for training/validation/testing."
CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,our code is publicly available at https://github.
CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,"seven cases were tested
in two datasets (table 1)."
