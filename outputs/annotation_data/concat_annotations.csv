title,paper name,vol,Does the article contain any of these keywords: cancer/tumor/tumour?,notes,Study subject labelled as ‘patient/patients’ in dataset(s),age,sex/gender,ethnicity,geographical location ,dataset quantity,quantity of public datasets,quantity of private datasets,image type in datasets,organ/body part in datasets,sex-specific cancer/organ,location ,location as a healthcare facility,name of healthcare facility,location as other (center/department/laboratory/university/institution/online),name of location as other (center/department/laboratory/university/institution/online),location as large-scale geographical entity,name of location as large-scale geographical entity,location as subnational geographical entity,name of  location as subnational geographical entity,Information found outside article (such as sup material and/or by references,links/sup material 
3D Arterial Segmentation via Single 2D Projections and Depth Supervision in Contrast-Enhanced CT Images,14,1,1,"""We use an in-house dataset""

The clinical and imaging data were collected according to the principles set in Declaration of Helsinki and Good Clinical Practice. Written conformed consent was waived and the study approved by the institutional ethics review board of the Technical University of Munich, Faculty of Medicine ",1,0,1,0,1,1,0,0,contrast-enhanced abdominal computed tomography images (cts),abdomen ,0,1,1,0,0,0,0.0,0,0.0,0,1.0,https://link.springer.com/chapter/10.1007/978-3-030-87589-3_61#Sec2
A Multi-task Network for Anatomy Identification in Endoscopic Pituitary Surgery,45,9,1,Participant demographics collected included training grade and country of practice. The collected data regarding the surgical workflow were quantitative (whether participants agree it is complete and accurate) and qualitative (additional suggestions or comments). Summary statistics (e.g. frequencies) were generated for participants demographics.,1,0,0,0,1,1,0,0,endoscope,pituitary gland,0,1,1,national hospital of neurology and neurosugery,0,0,1.0,united kingdom,1.0,london,1.0,https://link.springer.com/article/10.1007/s11102-021-01162-3#Sec2
A Texture Neural Network to Predict the Abnormal Brachial Plexus from Routine Magnetic Resonance Imaging,46,8,1,0,1,1,1,0,1,1,0,0,mri,breast,0,1,1,anonymous,0,0,0.0,0,0.0,0,0.0,0
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,74,3,1,0,1,0,1,0,0,3,1,0,PCa,prostate,1,0,0,0,0,0,0.0,0,0.0,0,1.0,"public dataset:
https://www.kaggle.com/c/prostate-cancer-grade-assessment/data"
AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor,17,1,1,"mention patient in conclusion:
""Experimental results on the four modalities of the 2021 BraTS dataset
demonstrate the superiority of our approach compared with other CAM-based
weakly-supervised segmentation methods. Specifically, AME-CAM achieves the
highest dice score for all patients in all datasets and modalities. These results
indicate the effectiveness of our proposed approach in accurately segmenting
brain tumors from MRI images using only class labels""

The BraTS dataset describes a collection of brain tumor MRI scans acquired from multiple different
centers under standard clinical conditions, but with different equipment and imaging protocols,
resulting in a vastly heterogeneous image quality reflecting diverse clinical practice across different
institutions. However, we designed the following tumor annotation protocol, in order to make it
possible to create similar ground truth delineations across various annotators.",1,0,0,0,1,1,1,0,mri,brain,0,1,1,0,0,0,0.0,0,0.0,0,1.0,https://arxiv.org/pdf/1811.02629.pdf
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,68,6,1,"For the purpose of training and testing all the models, we extract four images of size 256 × 256 from each tile due to the size of the external IHC images, resulting in a total of 1072 images. We randomly extracted tiles from the LYON19 challenge dataset [14] to use as style IHC images. Using these images, we created a dataset of synthetically generated IHC images from
the hematoxylin and its marker image as shown in Fig. 3.",1,1,1,1,1,1,1,0,"ihc, if, multiplex staining",head and neck,0,1,0,0,1,moffitt cancer center,0.0,0,0.0,0,0.0,0
An Anti-biased TBSRTC-Category Aware Nuclei Segmentation Framework with a Multi-label Thyroid Cytology Benchmark,56,6,1,,1,0,0,0,0,1,0,0,h&e,thyroid,0,0,0,0,0,0,0.0,0,0.0,0,0.0,
Anatomy-Driven Pathology Detection on Chest X-rays,6,1,1,"Training Dataset.
 We train on the Chest ImaGenome dataset [4,21,22] consisting of roughly 240 000 frontal chest X-ray images with corresponding scenegraphs automatically constructed from free-text radiology reports. It is derived from the MIMIC-CXR dataset [9,10], which is based on imaging studies from 65 079 patients performed at Beth Israel Deaconess Medical Center in Boston,
US.

Evaluation Dataset and Class Mapping. 
We evaluate our method on the subset of 882 chest X-ray images with pathology bounding boxes, annotated by radiologists, from the NIH ChestXray-8 (CXR8) dataset [20]3 from the National Insti tutes of Health Clinical Center in the US.",1,0,0,0,1,3,3,0,x-ray,chest,0,1,1,"national institutes of health clinical center, beth israel deaconess medical center",1,"national institutes of health clinical center, beth israel deaconess medical center",1.0,us,1.0,boston,1.0,"https://physionet.org/content/chest-imagenome/1.0.0

https://physionet.org/content/mimic-cxr-jpg/2.0.0/

https://www.kaggle.com/datasets/nih-chest-xrays/data"
Anatomy-Informed Data Augmentation for Enhanced Prostate Cancer Detection,50,7,1,"774 consecutive bi-parametric prostate MRI examinations are included in this
study, which were acquired in-house during the clinical routine.

All experiments were performed in accordance with the declaration of Helsinki

",1,0,0,0,1,1,0,0,mri,prostate,1,1,1,medical faculty heideberg,0,0,1.0,helskini,1.0,heidelberg,0.0,0
atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning,23,8,1,"The proposed technique was tested on a healthy-subject dataset and on a dataset containing tumor cases. The first comprises 21 subjects of the human connectome project (HCP) that were used for testing the automated methods TractSeg and Classifyber [3,18].

To test the proposed method on pathological data, we used an in-house
dataset containing ten presurgical scans of patients with brain tumors. ",1,0,0,0,0,2,1,1,tractography,brain,0,1,1,0,0,0,0.0,0,0.0,0,1.0,https://pdf.sciencedirectassets.com/272508/1-s2.0-S1053811913X00151/1-s2.0-S105381191300551X/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjENn%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIFyE0kxcJCYtCVec8GIZWCo%2FqswIZKasNPPjr85bjuJZAiArUMkvOXIaakMw0%2BeL9T3uGxYejpDoZ6h%2Bzoi1xSHfpiqzBQgSEAUaDDA1OTAwMzU0Njg2NSIMBscULTCwofTIB86zKpAFwEBhFNczb8dLeGrpdhqjphPiiKWnjJWOzjFo4JqSWb4%2FOngvVUaTIOgf%2F52xr%2F83tvEbLAdkfDbbI0fQMQXFDNWjbqMtENQsx8A96dGEvxnaFeO24T%2Fxm58fkUohyQ%2FbCxipeatF53ot3j9LRFQmpETWw64njUMRz32WaKW%2FnJ%2FHSoWhEEofMrLxTZIb2x6RroS%2Br%2FUETEDQiJz9Me1sjd1W9TKJINU46xKTbBZE69jZFHGsgQf%2FN%2B9YPYBlfjctKwr6nunXJeK77icrwTzU2jAhWuNbWE3V62ePEDTXFspNT8EiAokf7p4Bw3Ty8wcv8bjYomO5kqMKcNqzEZMyiSrjiHY55ro85irJeWY45SM62WjrKE4wyInm8P2qQZNDHPJ6mTbIoQjMgArEcCBAFLtiPAbjaRyyvfOIbgnP2xg2JCZKh7XP3ctPc7wNDmnkf%2FvStkogkwYO%2FGyUaxK0YRoFCPJmGhZUmtUMDjLGDTxtFOXJjB814MRINxWBd1WKP81sLDHf2o8Uu4jrYCua92s5tl6PrGY%2FfvzUgF%2Bj8Ef3uHqdKj5YjtYJCmYfx3bZN1%2F7%2Bvfeqp28zVfYv8VmfJ7zKdevIssqsEfDzzYdh8I46hRqLvJUjNOyGmgW%2FKOlArqAkS7NN%2Bt17vNI3HUPNeY%2FCZbNnqq6t1xwWsNHeC1HdCY%2BhoJo9Qi8IQC0Wu%2FKDcJucgjgMTcgI91w49kAyMEganjm0t1EyLvQbNZ0BMKka3mVg2T6yNV60Bp8UJPP0zTIhLaAPMMv4Rw8b2iMlo%2BvI7J8hcNpYxVBQsmMAdK37Go%2BoozF2VkYYymjrN3cVb%2FkZkdQkh9DGPAc0fCdrqP6XSGxlDfN1qElIzFFX54w1%2FzTsAY6sgGyCsphQxVkTUFDnX2sUZd4XothWgMtzxvChmdsHOGswGbvtgxPhzXLAXDFa9PbUzprys8LZy%2B2etbGCZOSF4KaHxBcvOtUGTNXy4%2FX8n9r0mg%2BidusFqo0G7G2EiyWZsVqEBXFMsEjWnrZkzqyV6axcHB50xvDMb6f85wINFNlO69L77jaS1bOax2WdBlxso9EZ4t1fA0N5BngtDpf9Cx8RskafomHPMy3zJfdDMlJro2m&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20240409T100743Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTY6XY2OAIV%2F20240409%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=766015d0b8659e71d80a4c9a06d40a560c1c3b6d0856d6031f925ea9a39eabb3&hash=866c7070a37f124da0eb26592f5a19cce8ed2c119cae96ca752f40cb403042ef&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S105381191300551X&tid=spdf-279f0031-3a6e-4e05-b067-7e3cf1f45660&sid=069c60407f4132401a1b3459c59a3a378755gxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=020d585650580d5f5505&rr=8719b11a0c1d92e8&cc=dk
Automatic Bleeding Risk Rating System of Gastric Varices,1,5,1,"Dataset details such as gender and age in supplementary material (outside of paper, however references to it in paper for more dataset details)",1,1,1,0,1,1,1,0,"gastroscopy, endoscopy",gastric/stomach/abdomen,0,1,1,grade-III class-A hospital,0,0,0.0,0,0.0,0,1.0,https://static-content.springer.com/esm/chp%3A10.1007%2F978-3-031-43904-9_1/MediaObjects/554074_1_En_1_MOESM1_ESM.pdf
Centroid-Aware Feature Recalibration for Cancer Grading in Pathology Images,20,2,1,"the dataset (that is referred to in the paper) labels subjects as patients.

location and location information from sup. material.

the article say there are two publicly available colorectal cancer datasets, however the referred article (that contain the details of dataset does not show they are public. However, the referred article talks about 2 other publicly prostate datasets)",0,0,0,0,1,2,2,0,"wsi, wsis,  tissue microarrays (TMAs) ",colorectal ,1,1,1,kangbuk samsung hospital,0,0,0.0,0,0.0,0,1.0,https://www.sciencedirect.com/science/article/pii/S1361841521002516#sec0006
Certification of Deep Learning Models for Medical Image Segmentation,58,4,1,"demographic information such as age, gender and location details  were outside paper's content, and study subjects labelled as patients. 
Chest X-rays Datasets:
JSRT dataset
Original posteroanterior chest films for this database were collected from 13 medical centers in Japan and one institution in the United States under the following conditions: only one nodule on an image for nodule cases; confirmation of presence or absence of a lung nodule by CT examination; and nodule classification as malignant based on histologic and cytologic examination or as benign based on histology, definitive isolation of a pathogenic organism, shrinkage and disappearance with the use of antibiotics, or no change observed during a follow-up period of 2 year.
Of the patients with nodules, 68 were men and 86 were women, whereas patients without nodules included 51 men and 42 women. The average age of patients with nodules was 60 years old. Two patients were 21-30 years old, seven were 31-40 years old, 24 were 41-50 years old, 37 were 51-60 years old, 53 were 61-70 years old, and 29 were 71 years old or older. Two patients' ages were unknown.

MC dataset
The MC set has been collected in collaboration with the Department of Health and Human Services, Montgomery County, Maryland, USA. The set contains 138 frontal chest X-rays from Montgomery County’s Tuberculosis screening program, of which 80 are normal cases and 58 are cases with manifestations of TB.
Each reading contains the patient’s age, gender, and abnormality seen in the lung, if any.

The Shenzhen dataset 
was collected in collaboration with Shenzhen No.3 People’s Hospital, Guangdong Medical College, Shenzhen, China. The chest X-rays are from outpatient clinics and were captured as part of the daily hospital routine within a 1-month period.
Each reading contains the patient’s age, gender, and abnormality seen in the lung, if any.

ISIC 2018:
Unknown

CVC-ClinicDB database 
We introduce in this paper the CVC-ClinicDB database built in collaboration with Hospital Clinic of Barcelona, Spain.","0, {chest x-rays datasets:1,  ISIC 2018: 0,  cvc-clinicDB dataset:0}","0, {chest x-rays datasets: 1, ISIC 2018: 0,  cvc-clinicDB dataset:0}","0, {chest x-rays datasets:1,  ISIC 2018: 0,  cvc-clinicDB dataset:0}","0, {chest x-rays datasets:1,  ISIC 2018: 0,  cvc-clinicDB dataset:0}","0, {chest x-rays datasets:1,  ISIC 2018: 0,  cvc-clinicDB dataset:1}",5,5,0,"{chest x-rays datasets: x-rays,  ISIC 2018: rgb dermatocopy,  cvc-clinicDB dataset: colonoscopy}","{chest x-rays datasets: chest, lung, heart, ISIC 2018: skin, cvc-clinicDB dataset: colon}


",0,1,1,"{chest x-rays datasets: Shenzhen No.3 People’s Hospital, ISIC 2018: unknown, cvc-clinicDB dataset:  Hospital Clinic of Barcelona} ",1,"{chest x-rays datasets:
Department of Health and Human Services}",1.0,"{chest x-rays datasets:
usa, japan, china , ISIC 2018: unknown, cvc-clinicDB dataset: spain}",1.0,"{chest x-rays datasets:
montgomery county maryland, shenzhen, ISIC 2018: unknown,  cvc-clinicDB dataset: barcelona}",1.0,"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4256233/

http://mv.cvc.uab.es/projects/colon-qa"
Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fréchet Domain Distance,16,5,1,"location details dervied outside paper:

The data set for CAMELYON17 is collected from 5 medical centres in the Netherlands. 

AIDA BRLN dataset:
The cases are anonymised and exported from the digital archive at the Department of Clinical Pathology in Linköping, Region Östergötland.",1,0,0,0,1,2,1,1,"wsi, wsis, h&e",lymp nodes,0,1,0,0,1,{AIDA BRLN dataset: department of clinical pathology} ,1.0,{CAMELYON17:netherlands},1.0,{AIDA BRLN dataset: Linköping Region Östergötland},1.0,https://camelyon17.grand-challenge.org/Data/
Detection of Basal Cell Carcinoma in Whole Slide Images,26,6,1,,0,0,0,0,1,1,0,0,wsi,skin,0,1,0,0,1,south sun pathology laboratory,0.0,0,0.0,0,0.0,0
Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels,46,3,1,"location details of  data collection outside the paper's content.

qubiq dataset: prostate, brain, kidney
we use QUBIQ 2020, which contains 7 segmentation tasks in 4 differen CT and MR datasets: Prostate (55 cases, 2 tasks, 6 raters), Brain Growth (39 cases, 1 task, 7 raters), Brain Tumor (32 cases, 3 tasks, 3 raters), and Kidney 24 cases, 1 task, 3 raters).

lits dataset: private, liver
LiTS contains 201 high-quality CT scans of liver tumors

info outside the paper
The image data for the LiTS challenge are collected from seven clinical sites all over the world, including a) Rechts der Isar Hospital, the Technical University of Munich in Germany, b) Radboud University Medical Center, the Netherlands, c) Polytechnique Montr´eal and CHUM Research Center in Canada, d) Sheba Medical Center in Israel, e) the Hebrew University of Jerusalem in Israel, f) Hadassah University Medical Center in Israel, and g) IRCAD in France. The distribution of the number of scans per institution is described in Table 2. The LiTS benchmark dataset contains 201 computed tomography images of the abdomen, of which 194 CT scans contain lesions. All data are anonymized, and the images have been reviewed visually to preclude the presence of personal identifiers

kits dataset: public,  kidney (abdominal cts)
KiTS includes 210 annotated CT scans of kidney tumors from different patients",1,0,0,0,0,3,1,1,"ct, mr","prostate, brain, {abdomen: kidney, live}",1,1,1,{lits: Rechts der Isar Hospital),1,"{lits: the Technical University of Munich, Polytechnique Montreal and CHUM Research Center,  Sheba Medical Center, the Hebrew University of Jerusalem, Hadassah University Medical Center,  IRCAD}",1.0,"{lits: Germany, Netherlands, Canada, Israel, France}",1.0,"{lits: munich, jerusalem)",1.0,"https://qubiq.grand-challenge.org/

https://arxiv.org/pdf/2108.09987.pdf

https://arxiv.org/pdf/1901.04056.pdf

https://competitions.codalab.org/competitions/17094"
Diffusion Kinetic Model for Breast Cancer Segmentation in Incomplete DCE-MRI,10,4,1,"age and race provided outside paper's content

Breast-MRI-NACT-Pilot
Recurrence-free survival (RFS) was assessed for each patient at 6-month or 1-year intervals following surgery. Other clinical and endpoint data includes patient age, lesion characteristics including pretreatment tumor size, histologic type, pathologic size, tumor subtype, and lymph node involvement. These data are included as supplemental information for the collection in the accompanying clinical information workbook.

Clinical and DFS Metadata shows:
race and age",1,1,0,1,0,1,1,0,"dce-mri, mri",breast,0,0,0,0,0,0,0.0,0,0.0,0,1.0,"Clinical and DFS Metadata (XLS, 103 kB) in
https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=22513764

https://www.kaggle.com/datasets/alexnguyen10/breast-mri-nact-pilot"
DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,72,10,1,"gender/sex info, location details of data collection  found outside article, 

dataset 1: public
Our neural network is trained using patches from the “Gold Atlas- Male Pelvis - Gentle Radiotherapy” [14] dataset, which is comprised of 18 patients each with a CT, MR T1, and MR T2 volumes. 
Info outside article:
Magnetic resonance images (MRI) (T1w and T2w) with flat table top, and CT images of 19 male patients. The imaging was performed over the pelvic region.
The patients were recruited and included from three different Swedish radiotherapy departments. Male patients with prostate or rectal cancer referred for curative radiotherapy were eligible for inclusion. Patients with locally advanced tumors (prostate cT3-4 and rectal cT4) were not included.

dataset 2: public
Evaluation of Cerebral Tumors (RESECT) MICCAI challenge dataset [23]. This dataset consists of 22 pairs of pre operative brain MRs and intra-operative ultrasound volumes.
info outside article:
All medical images used for the challenge were acquired for routine clinical care at St Olavs University Hospital (Trondheim, Norway), after patients gave their informed consent.

dataset 3: public
Our second application is the Abdomen MR-CT task of the Learn2Reg challenge 2021 [8]. The dataset comprises 8 sets of MR and CT volumes, both depicting the abdominal region of a single patient and exhibiting notable deformations

We are using a heterogeneous dataset of 27 cases, comprising liver cancer patients and healthy volunteers, different ultrasound machines, as well as optical",1,0,"1, {gold atlas: male}",0,"0, {gold atlas: 1, RESECT: 1}",3,3,0,"ct, mr, mr t1 volumes, mr t2 volumes, ultrasound volumes, us volumes,  intra-operative ultrasound volumes, mr-ct","{RESECT: brain, Learn2Reg: abdomen, gold atlas: pelvic region, prostate}, liver","1, {gold atlas: prostate cancer}",1,"{gold atlas: 1, RESECT: 1}","{gold atlas: unknown, RESECT: st olavs university hospital}",0,0,1.0,"{gold atlas: sweden, RESECT: norway}",1.0,{RESECT: trondheim},1.0,"https://zenodo.org/records/583096

https://aapm.onlinelibrary.wiley.com/doi/full/10.1002/mp.12748

https://curious2018.grand-challenge.org/Data/

https://aapm.onlinelibrary.wiley.com/doi/full/10.1002/mp.12268

https://learn2reg.grand-challenge.org/Learn2Reg2021/"
Distributionally Robust Image Classifiers for Stroke Diagnosis in Accelerated MRI,74,5,1*,"*(not sure if dataset contain cancer-related data such as tumor (which was the search word), the paper has healthy data and stroke data)

dataset 1:
Our dataset included MRI brain scans from 226 patients performed at an urban
tertiary referral academic medical center that is a comprehensive stroke center.
Clinical scans of adult patients aged 18–89 years with recent (acute or subacute)
strokes were identified between 1/1/2013 and 1/1/2021 for inclusion in this study
via a search of the Philips Performance Bridge.
No patient demographic information was retained for the scans, as it was considered to represent an unnecessary risk for accidental release of protected health information.

As our dataset is unbalanced, we also considered the Area Under Precision-Recall Curve (AUPRC)

dataset 2:
using the T1/T2-weighted brain MR images in the IXI dataset [1].

Info outside the article
IXI dataset:
In this project we have collected nearly 600 MR images from normal, healthy subjects. The MR image acquisition protocol for each subject includes:

T1, T2 and PD-weighted images MRA images Diffusion-weighted images (15 directions)
The data has been collected at three different hospitals in London:
Hammersmith Hospital using a Philips 3T system. Guy’s Hospital using a Philips 1.5T system. Institute of Psychiatry using a GE 1.5T system 

Demographic information <spreadsheet-link> (link not working)",1,1,0,0,1,2,1,1,"mri, mr",brain,0,1,1,"{ixi dataset: hammersmith hospital, guy's hospital, institute of psychiatry}",1, {ixi dataset:  institute of psychiatry},1.0,0,1.0,{ixi data: london},1.0,https://brain-development.org/ixi-dataset/
FocalErrorNet: Uncertainty-Aware Focal Modulation Network for Inter-modal Registration Error Estimation in Ultrasound-Guided Neurosurgery,66,9,1,"location details of data collection found outside paper's content.

we used the RESECT (REtro-Spective Evaluation of Cerebral Tumors) dataset [16], MRI and iUS scans at different surgical stages from 23 subjects who underwent low-grade glioma resection surgeries.

One limitation of our work lies in the limited patient data, as public iUS datasets are scarce, while the settings and properties of US scanners can vary, potentially affecting the DL model designs

Info outside the paper:
Pre-operative magnetic resonance images (MRI), and intra-operative ultrasound (US) scans were acquired from 23 patients with low-grade gliomas who underwent surgeries at St. Olavs University Hospital between 2011 and 2016",1,0,0,0,0,1,1,0,"mri, ius","brain, cerebral",0,1,"1, {RESECT: 1}",{RESECT: st olavs university hospital},0,0,1.0,{ RESECT: norway},1.0,{RESECT: trondheim},1.0,https://pubmed.ncbi.nlm.nih.gov/28391601/
Gene-Induced Multimodal Pre-training for Image-Omic Classification,49,6,1,"We verify the effectiveness of our method on The Caner Genome Atlas (TCGA) non-small cell lung cancer (NSCLC) dataset, which contains two cancer subtypes, i.e., Lung Squamous Cell Carcinoma (LUSC) and Lung Adeno carcinoma (LUAD).
 TCGA-NSCLC dataset, i.e., only pathological WSIs are included as input.",1,0,0,0,0,1,0,0,"wsis, wsi",lung,0,0,0,0,0,0,0.0,0,0.0,0,0.0,0
Geometry-Invariant Abnormality Detection,29,1,1,"demographics and data collection details (location) found outside paper's content

For this work we leveraged whole-body PET/CT data from different sources to explore the efficacy of our approach for varying image geometries. 211 scans from NSCLC Radiogenomics [2,3,10,16] combined with 83 scans from a proprietary dataset constitute our lower resolution dataset.

For evaluation, we use four testing sets: a lower resolution set derived from both the NSCLC and the private dataset

The models were trained on the NVIDIA Cambridge-1. Private dataset was obtained through King’s College London (14/LO/0220 ethics application number). 

Info outside article: NSCLC
Between 2008 and 2012, we collected clinical and imaging data for 211 subjects referred for surgical treatment and obtained tissue samples from the excised tumors, where available. Tissue samples were analyzed to produce molecular phenotypes using gene microarrays, RNA sequencing technology, or both, in addition to standard-of-care NSCLC mutational testing. We also collected clinical data, such as: age, gender, weight, ethnicity, smoking status, TNM stage, histopathological grade. 

The R01 cohort consisted of 162 NSCLC subjects (38 females, 124 males, age at scan: mean 68, range 42–86) from Stanford University School of Medicine (69) and Palo Alto Veterans Affairs Healthcare System (93). Subjects were recruited between April 7th, 2008 and September 15th, 2012.

",0,1,1,1,0,2,1,1,"pet, ct",whole body,,1,0,0,1,"{nsclc: standford university school of medicine, palo alto veterans affairs healtcare system}",0.0,0,0.0,0,1.0,https://www.nature.com/articles/sdata2018202
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,11,5,1,"We evaluated our method with two studies on retrospectively collected patient datasets
that were manually annotated by an expert radiologist.

DLIVER dataset, DLUNG dataset.

Lung and liver CT studies were retrospectively obtained from two medical
centers (Hadassah Univ Hosp Jerusalem Israel) during the routine clinical examination
of patients with metastatic disease. Each patient study consists of at least 3 scans.

",1,0,0,0,1,2,0,0,"mri, ct","lung, liver",0,1,1,Hassadah University Hospital,0,0,1.0,Israel,1.0,Jerusalem,0.0,0
Guiding the Guidance: A Comparative Analysis of User Guidance Signals for Interactive Segmentation of Volumetric Images,61,3,1,"sex, age was found outside the paper's content, and the location details of data collections.

We conduct our study on the MSD Spleen and the AutoPET datasets to explore the segmentation of both anatomy (spleen) and pathology (tumor lesions).

We trained and evaluated all of our models on the openly available AutoPET [1] and MSD Spleen [2] datasets.

Info outside the paper
MSD spleen
Task09_Spleen The spleen dataset was comprised of patients undergoing
chemotherapy treatment for liver metastases at Memorial Sloan Kettering Cancer Center (New York, NY, USA) and previously reported [32]. 
AutoPet
Publication of anonymized data was approved by the institutional ethics committee of the Medical Faculty of the University of Tübingen as well as the institutional data security and privacy review board. Data from 1,014 whole-body FDG-PET/CT examinations of 900 patients acquired between 2014 and 2018 as part of a prospective registry study9 were included in this dataset.

The selection criteria for positive and negative samples were: age >18 years
patient characteristics: https://www.nature.com/articles/s41597-022-01718-3/tables/2",1,1,1,0,0,2,2,0,"ct, computed tomography, pet/ct, pet, Positron Emission Tomography, ","splen, lung",0,1,0,0,1,"{msd spleen: memorial sloan kettering cancer center, autopet: unknown ´}",1.0,usa,1.0,new york,1.0,"https://arxiv.org/pdf/1902.09063.pdf

https://www.nature.com/articles/s41597-022-01718-3

https://www.nature.com/articles/s41597-022-01718-3/tables/2"
Histopathology Image Classification Using Deep Manifold Contrastive Learning,66,6,1,"We tested our proposed method on two different tasks: (1) intrahepatic cholangiocarcinomas(
IHCCs) subtype classification and (2) liver cancer type classification. 

The dataset for the former task was collected from 168 patients with 332 WSIs from Seoul National University hospital. IHCCs can be further categorized into small duct type (SDT) and large duct type (LDT). Using gene mutation information as prior knowledge, we collected WSIs with wild KRAS and mutated IDH genes for use as training samples in SDT, and WSIs with mutated KRAS and wild IDH genes for use in LDT. The rest of the WSIs were used as testing samples. 
The liver cancer dataset for the latter task was composed of 323 WSIs, in which the WSIs can be further classified into hepatocellular carcinomas (HCCs) (collected from Pathology AI Platform [1]) and IHCCs.We collected 121 WSIs for the training set, and the remaining WSIs were used as the testing set.",1,0,0,0,1,2,0,0,"wsis, wsi",liver,0,1,1,seoul national university hospital,0,0,1.0,south korea,1.0,seoul,0.0,http://wisepaip.org/paip
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,8,5,1,"We collect a large-scale dataset with both tumor and non-tumor subjects, where the non-tumor subjects includes not only healthy ones, but also patients with various diffuse liver diseases such as steatosis and hepatitis to improve the robustness of the algorithm

Our dataset contains 810 normal subjects and 939 patients with liver tumors. Each normal subject has a non-contrast (NC) CT, while each patient has a dynamic contrast-enhanced (DCE) CT scan with NC, arterial, and venous phases.

We first train an nnU-Net on public datasets to segment liver and surrounding organs (gallbladder, hepatic vein, spleen, stomach, and pancreas), and then crop the liver region to train PLAN.

The NC test set contains 198 tumor cases, 202 completely normal cases, and 100 “hard” non-tumor cases which may have larger image noise, artifact, ascites, diffuse liver diseases such as hepatitis and steatosis. These cases are used to test the robustness of the model in real-world screening scenario with diverse tumor-free images.",1,0,0,0,0,2,1,1,"nc-ct, dce-ct, ct","liver, gallbladder, hepatic vein, spleen, stomach, pancreas",0,0,0,0,0,0,0.0,0,0.0,0,0.0,0
Localized Region Contrast for Enhancing Self-supervised Learning in Medical Image Segmentation,45,2,1,"During both global and local pre-training stages, we pre-train the encoders on the Abdomen-1K [17] dataset. It contains over one thousand CT images which equates to roughly 240,000 2D slices. The CT images have been curated from 12 medical centers and include multi-phase, multi-vendor, and multi-disease cases.Although segmentation masks for liver, kidney, spleen, and pancreas are provided
in this dataset, we ignore these labels during pre-training since we are following the self-supervised protocol.

During the fine-tuning stage, we perform extensive experiments on three datasets
with respect to different regions of the human body:
abd-110 dataset: abdomen, thorax-85 dataset: thorax, HaN dataset: head and neck

ABD-110 is an abdomen dataset from [25] that contains 110 CT images from patients with various abdominal tumors and these CT images were taken during the treatment planning stage. We report the average DSC on 11 abdominal organs (large bowel, duodenum, spinal cord, liver, spleen, small bowel, pancreas, left kidney, right kidney, stomach and gallbladder).
Thorax-85 is a thorax dataset from [5] that contains 85 thoracic CT images. We report the average DSC on 6 thoracic organs (esophagus, trachea, spinal cord, left lung, right lung, and heart).
HaN is from [24] and contains 120 CT images covering the head and neck region. We report the average DSC on 9 organs (brainstem, mandible, optical chiasm, left optical nerve, right optical nerve, left parotid, right parotid, left submandibular gland, and right submandibular gland).

Info outside paper
AbdomenCT-1K
Most existing abdominal organ segmentation datasets have limitations in diversity and scale. In this paper, we present a large-scale dataset that is closer to real-world applications
and has more diverse abdominal CT cases.
consists of 1112 3D CT scans from five existing datasets: LiTS (201 cases) [16], KiTS (300 cases) [17], MSD Spleen (61 cases) and Pancreas (420 cases) [20], NIH Pancreas (80 cases) [21], [22], [23],
and a new dataset from Nanjing University (50 cases). The 50 CT scans in the Nanjing University dataset are from 20 patients with pancreas cancer, 20 patients with colon cancer, and 10 patients with liver cancer. The number of plain phase, artery phase, and portal phase scans are 18, 18, and 14 respectively

Thorax-85
The data sources included in-house CT images (540 cases) and public data derived from the Cancer Image Archive (TCIA [21], 215 cases).",1,0,0,0,1,4,1,0,ct,"abdomen, thorax, head and neck ",0,1,1,0,0,0,0.0,0,0.0,0,1.0,"https://arxiv.org/pdf/2010.14808.pdf

https://arxiv.org/pdf/2012.09279.pdf

https://www.sciencedirect.com/science/article/pii/S0167814021062174"
Many Tasks Make Light Work: Learning to Localise Medical Anomalies from Multiple Synthetic Tasks,16,1,1,"Idemographic info such as age, gender, details of location of data collection provided outside of paper's content. study subjects are labelled as patients outside paper's content.

We evaluate our method on T2-weighted brain MR and chest X-ray datasets to provide direct comparisons to state-of-the-art methods over a wide range of real anomalies. 
For brain MRI we train on the Human Connectome Project (HCP) dataset [28] which consists of 1113 MRI scans of healthy, young adults acquired as part of a scientific study. 
To evaluate, we use the Brain Tumor Segmentation Challenge 2017 (BraTS) dataset [1], containing 285 cases with either high or low grade glioma, and the ischemic stroke lesion segmentation challenge 2015 (ISLES) dataset [13], containing 28 cases with ischemic stroke lesions. The data from both test sets was acquired as part of clinical routine. The HCP dataset was resampled to have 1mm isotropic spacing to match the test datasets. 
For chest X-rays we use the VinDr-CXR dataset [18] including 22 differen local labels.

Info outside paper
HCP
Our decision to acquire data from twins and non-twin siblings will enable analyses of the heritability of brain circuits and will greatly increasethe power of genetic analyses. However, due to the relatively small size and localized geography of the subject population, HCP faces some extra challenges with respect to subject confidentiality and privacy, especially regarding sensitive data. One likely scenario is that the publicly released HCP dataset will include all neuroimagingdata and most behavioral data, along with subject sex and age range (e.g., 5-year grouping). Information about family relationships, ethnic and racial identity, exact age (year), and potentially sensitive behavioral measures would be restricted to qualified investigators who agree to appropriate limits on storage and distribution of sensitive data. The publicly released data could also include a dataset consisting of only one individual per family, thereby allowing analyses not confounded by unspecified family relationships.

Brats
In 2017, thanks to additional contributions to the BraTS dataset, from CBICA@UPenn and the
University of Alabama in Birmingham (UAB), a validation set was included to facilitate algorithm
fine-tuning following a ML paradigm of training, validation, and testing datasets. Notably, in 2017
the number of cases was doubled with respect to the previous year, amounting to 477 cases, which
was further increased in 2018 with 542 cases, thanks to contributions from MD Anderson Cancer
Center in Texas, the Washington University School of Medicine in St. Louis, and the Tata Memorial
Center in India

VinDr-CXR
The building of VinDr-CXR dataset, as visualized in Fig. 1, is divided into three main steps: (1) data collection, (2) data filtering, and (3) data labeling. Between 2018 and 2020, we retrospectively collected more than 100,000 CXRs in DICOM format from local PACS servers of two hospitals in Vietnam, HMUH and H108. Imaging data were acquired from a wide diversity of scanners from well-known medical equipment manufacturers, including Phillips, GE, Fujifilm, Siemens, Toshiba, Canon, Samsung, and Carestream. The ethical clearance of this study was approved by the Institutional Review Boards (IRBs) of the HMUH and H108 before the study started. The need for obtaining informed patient consent was waived because this retrospective study did not impact clinical care or workflow at these two hospitals and all patient-identifiable information in the data has been removed.

dataset provides info about patient's sex, age, size, weights",1,1,1,0,1,4,3,0,"mri,  x-rays, mr","brain, chest",0,1,1,"{vin-dr cxr: HMUH, H108}",0,0,1.0,{vin-dr cxr: vietnam},0.0,0,1.0,"https://www.sciencedirect.com/science/article/pii/S1053811912001954?via%3Dihub

https://arxiv.org/abs/1811.02629

https://www.sciencedirect.com/science/article/pii/S1361841516301268?via%3Dihub

https://www.nature.com/articles/s41597-022-01498-w

https://static-content.springer.com/esm/art%3A10.1038%2Fs41597-022-01498-w/MediaObjects/41597_2022_1498_MOESM1_ESM.pdf"
Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,39,6,1,"demographic information provided in supplementary information.

We adopted the training dataset of HECKTOR 2022 (refer to https://hecktor.grand-cha llenge.org/), including 488 H&N cancer patients acquired from seven medical centers [7], while the testing dataset was excluded as its ground-truth labels are not released. Each patient underwent pretreatment PET/CT and has clinical indicators. We present the distributions of all clinical indicators in the supplementary materials. Recurrence- Free Survival (RFS), including time-to-event in days and censored-or-not status, was provided as ground truth for survival prediction, while PT and MLN annotations were provided for segmentation. The patients from two centers (CHUM and CHUV) were used for testing and other patients for training, which split the data into 386/102 patients in training/testing sets. We trained and validated models using 5-fold cross-validation within the training set and evaluated them in the testing set.

HECKTOR 2022
The data used in this challenge is multi-centric (9 centers in total), including four centers in Canada [Vallières et al. 2017], two centers in Switzerland [Castelli et al. 2017; Bogowicz et al. 2017], two centers in France [Hatt et al. 2019; Legot et al. 2018], and one center in USA [Ger et al. 2019] for a total of XXX patients with annotated GTVp and GTVn.

The clinical information for each patient is contained in the hecktor2022_clinical_info_training.csv, including center, gender, age, weight, tobacco and alcohol consumption, performance status (Zubrod), HPV status, treatment (surgery and/or chemotherapy in addition to the radiotherapy that all patients underwent).  Note that some information may be missing for some patients. 

Data were collected from 9 centers :
Hôpital général juif, Montréal, CA (HGJ)
Centre hospitalier universitaire de Sherbooke, Sherbrooke, CA (CHUS)
Hôpital Maisonneuve-Rosemont, Montréal, CA (HMR)
Centre hospitalier de l’Université de Montréal, Montréal, CA (CHUM)
Centre Hospitalier Universitaire Vaudois, CH (CHUV)
Centre Hospitalier Universitaire de Poitiers, FR (CHUP)
MD Anderson Cancer Center, Houston, Texas, USA (MDA)
UniversitätsSpital Zürich, CH (USZ)
Centre Henri Becquerel, Rouen, FR (CHB)
",1,1,1,0,1,1,1,0,"pet/ct, ","head and neck, h&n",0,1,1,"chum, chuv",0,0,1.0,"canada, switzerland, france, usa",0.0,0,1.0,"https://static-content.springer.com/esm/chp%3A10.1007%2F978-3-031-43987-2_39/MediaObjects/554075_1_En_39_MOESM1_ESM.pdf

https://hecktor.grand-challenge.org/"
Mesh2SSM: From Surface Meshes to Statistical Shape Models of Anatomy,59,1,1,"We use the publicly available Decath-Pancreas dataset of 273 segmentations from patients who underwent pancreatic mass resection [24].

Info outside the paper
Images were provided by Memorial Sloan Kettering Cancer Center (New York, NY, USA) and
were previously reported in radiomic applications [24, 25, 26]. Four hundred and twenty portal venous phase CT scans were obtained with the following reconstruction and acquisition parameters: pitch/table speed 0.984–1.375/39.37–27.50 mm; automatic tube current modulation range, 220–380 mA; noise index, 12.5–14;20 kVp; tube rotation speed, 0.7–0.8 ms; scan delay, 80–85 s; and axial slices reconstructed at 2.5 mm intervals. The pancreatic parenchyma and pancreatic mass (cyst or tumour) were manually segmented in each slice by an expert abdominal radiologist using the Scout application [27].

",1,0,0,0,0,1,1,0,segmentations,pancreas,0,1,0,0,1,memorial sloan kettering cancer center,1.0,usa,1.0,new york,1.0,https://arxiv.org/abs/1902.09063
MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,46,6,1,"Based on stateof- the-art multiple instance learning architectures and two thyroid cancer data
sets, an exhaustive study was conducted considering a range of common data augmentation strategies.
In this work, we aimed at distinguishing different nodular lesions of the thyroid, focusing especially on benign follicular nodules (FN) and papillary carcinomas (PC).
The data set utilized in the experiments consists of 80 WSIs overall. One half (40) of the data set consists of frozen and the other half (40) of paraffin sections [5]), representing the different modal
ities. All images were acquired during clinical routine at the Kardinal Schwarzenberg Hospital. Procedures were approved by the ethics committee of the county of Salzburg (No. 1088/2021). The mean and median age of patients at the date of dissection was 47 and 50 years, respectively. The data set comprised 13 male and 27 female patients, corresponding to a slight gender imbalance. They were labeled by an expert pathologist
with over 20 years experience.",1,1,1,0,1,2,0,0,"wsis, wsi",thyroid,0,1,1,kardinal schwarzenberg hospital,0,0,0.0,0,1.0,salzburg,0.0,0
Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision,55,1,1,"We train our approach at large scale with more than 50,000 computed tomography (CT) scans and validate it on two different applications: 1) Tracking of generic lesions based on the DeepLesion dataset, including liver tumors, lung nodules, enlarged lymph-nodes, for which we report highest matching accuracy of 92%, with localization accuracy that is nearly 10% higher than the state-ofthe-
art; and 2) Tracking of lung nodules based on the NLST dataset for which we achieve similarly high performance.

we (1) train a pixel-wise self-supervised system using a very large and diverse dataset of 52,487 CT volumes and (2) evaluate on two publicly available datasets.

We train the universal and fine-grained anatomical point matching model using an in-house CT dataset (VariousCT). The training dataset contains 52,487 unlabeled 3D CT volumes capturing various anatomies, including chest, head, abdomen, pelvis, and more.

For NLST, we randomly selected a subset of 1045 test images coming from 420 patients with up to 3 studies

The authors thank the National Cancer Institute for access to NCI’s data collected by the National Lung Screening Trial (NLST). The statements contained herein are solely those of the authors and do not represent or imply concurrence or endorsement by NCI.",1,0,0,0,0,3,2,1,"tomography, ct","liver, lung, lymp nodes",0,0,0,0,0,0,0.0,0,0.0,0,0.0,0
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,29,8,1,"GSP1000 Processed Connectome. It publicly released preprocessed restingstate fMRI data of 1000 healthy right-handed subjects with an average age 21.5±2.9 years and approximately equal numbers of males and females from the Brain Genomics Superstruct Project (GSP) [5], where the concrete image acquisition parameters and preprocessing procedures can be found as well. Specifically, a slightly modified version of Yeo’s Computational Brain Imaging Group (CBIG) fMRI preprocessing pipeline (https://github.com/bchcohenlab/CBIG) was employed to obtain either one or two preprocessed resting-state fMRI runs of each subject that had 120 time points per run and were spatially normalized
into the MNI152 template with 2mm3 voxel size. We downloaded and used the first-run preprocessed resting-state fMRI of each subject for the following analysis.

BraTS 2020. It provided an open-access pre-operative imaging training dataset to segment brain tumors of glioblastoma (GBM, belonging to high grade glioma) and low grade glioma (LGG) patients, as well as to predict overall survival time of GBM patients [18]. This training dataset contained 133 LGG and 236 GBM patients, and each patient had four MRI modalities, including T1, post-contrast T1-weighted, T2-weighted, and T2 Fluid Attenuated Inversion Recovery",1,1,1,0,0,2,2,0,"fmri, mri, t1, t2",brain,0,0,0,0,0,0,0.0,0,0.0,0,0.0,0
Prompt-Based Grouping Transformer for Nucleus Detection and Classification,55,8,1,"CoNSeP1 [10] is a colorectal nuclear dataset with three types, consisting of 41H&E stained image tiles from 16 colorectal adenocarcinoma whole-slide images (WSIs). 
BRCA-M2C2 [1] is a breast cancer dataset with three types and consists of 120 image tiles from 113 patients. 
Lizard3 [9] has 291 histology images of colon tissue from six datasets, containing nearly half a million labeled nuclei in H&E stained colon tissue. ",1,0,0,0,0,3,3,0,"h&e, wsis, wsi, image titles, stained image tiles, histology images,","colorectal, breast, colon  ",0,0,0,0,0,0,0.0,0,0.0,0,0.0,"https://warwick.ac.uk/fac/cross_fac/tia/data/hovernet/.
 https://github.com/TopoXLab/Dataset-BRCA-M2C/.
 https://warwick.ac.uk/fac/cross_fac/tia/data/lizard/."
Regularized Kelvinlet Functions to Model Linear Elasticity for Image-to-Physical Registration of the Breast,33,9,1,"This dataset consists of supine breast MR images simulating surgical deformations of 11 breasts from 7 healthy volunteers. Volunteers (ages 23–57) were enrolled in a study approved by the Institutional Review Board at Vanderbilt University.

This dataset consists of supine breastMR images simulating surgical deformations from one breast cancer patient. A 71-year-old patient with invasive mammary carcinoma in the left breast was enrolled in a study approved by the Institutional Review Board at Vanderbilt University.",1,1,0,0,1,2,0,0,mr,breast,0,1,0,0,0,0,0.0,0,0.0,0,0.0,0
Reversing the Abnormal: Pseudo-Healthy Generative Networks for Anomaly Detection,29,5,1,"We trained our model using two publicly available brain T1w MRI datasets, including FastMRI+ (131 train, 15 val, 30 test) and IXI (581 train samples), to capture the healthy distribution. Performance evaluation was done on a large stroke T1-weighted MRI dataset, ATLAS v2.0 [14], containing 655 images",0,0,0,0,0,2,2,0,"mri, t1",brain,0,0,0,0,0,0,0.0,0,0.0,0,0.0,0
Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,13,5,,"Dataset and Preprocessing: The T2-weighted MR images of 39 participants including 23 patients with NPSLE and 16 HCs were gathered from our affiliated hospital. All images were acquired at an average age of 30.6 years on a SIGNA 3.0T scanner with an eight-channel standard head coil.

",1,1,0,0,1,1,0,0,"mr, t2",no organ mentioned,0,1,1,,0,0,,,,,,
SLPD: Slide-Level Prototypical Distillation for WSIs,25,1,0,"We conduct experiments on two public WSI datasets2. TCGANSCLC dataset includes two subtypes in lung cancer, Lung Squamous Cell Carcinoma and Lung Adenocarcinoma, with a total of 1,054 WSIs. TCGA-BRCA dataset includes two subtypes in breast cancer, Invasive Ductal and Invasive
Lobular Carcinoma, with a total of 1,134 WSIs",0,0,0,0,0,2,2,0,wsi,"lung, breast",0,0,0,0,0,0,,,,0,0.0,0
Spectral Adversarial MixUp for Few-Shot Unsupervised Domain Adaptation,69,1,0,"We evaluated SAMix on two medical image datasets. Fundus [5,14] is an optic disc and cup segmentation task. Following [21], we consider images collected from different scanners as distinct domains. The source domain contains 400 images of the REFUGE [14] training set.We took 400 images from the REFUGE validation set and 159 images of RIM-One [5] to form the target domain 1 & 2. We center crop and resize the disc region to 256 × 256 as network input. Camelyon [1] is a tumor tissue binary classification task across 5 hospitals. We use the training set of Camelyon as the source domain (302, 436 images from hospitals 1 − 3) and consider the validation set (34, 904 images from hospital 4) and test set (85, 054 images from the hospital 5) as the target domains 1 and 2, respectively. 
",0,0,0,0,1,4,0,0,"segmentations, ",tissue,0,1,0,0,0,0,,,,0,0.0,0
Structure-Preserving Synthesis: MaskGAN for Unpaired MR-CT Translation,6,10,0,"We collected 270 volumetric T1-weighted MRI and 267 thinslice CT head scans with bony reconstruction performed in pediatric patients under routine scanning protocols1. We targeted the age group from 6–24 months since pediatric patients are more susceptible to ionizing radiation and experience a greater cancer risk (up to 24% increase) from radiation exposure [7].

The dataset comprises brain MR and CT volumes from 262 subjects. 13 MRICT volumes from the same patients that were captured less than three months apart are registered using rigid registration algorithms. The dataset is divided into 249, 1 and 12 subjects for training, validating and testing se",1,1,0,0,0,1,0,0,"mri, t1, ct, mr, ct volumes",brain,0,0,0,0,0,0,,,,0,0.0,0
Thyroid Nodule Diagnosis in Dynamic Contrast-Enhanced Ultrasound via Microvessel Infiltration Awareness,17,6,0,"Our dataset contained 282 consecutive patients who underwent thyroid nodule examination at Nanjing Drum Tower Hospital. All patients performed dynamic CEUS examination by an experienced sonographer using an iU22 scanner (Philips Healthcare, Bothell, WA) equipped with a linear transducer
L9-3 probe. These 282 cases included 147 malignant nodules and 135 benign nodules. On the one hand, the percutaneous biopsy based pathological examination was implemented to determine the ground-truth of malignant and benign. On the other hand, a sonographer with more than 10 years of experience manually annotated the nodule lesion mask to obtain the pixel-level groundtruth
of thyroid nodules segmentation. All data were approved by the Institutional Review Board of Nanjing Drum Tower Hospital, and all patients signed the informed consent before enrollment into the study.",1,0,0,0,1,1,0,0,"ultrasound, ceus",thyroid,0,1,1,Nanjing drum tower hospital,0,0,0.0,0,0.0,0,0.0,0
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,32,2,0,"Extensive experiments are conducted, in which we achieve an overall accuracy of 90.9% on an in-house dataset of four CT phases and seven liver lesion classes. 
The employed single-phase annotated dataset is collected from Sir Run Run Shaw Hospital (SRRSH), affiliated with the Zhejiang University School of Medicine, and has received the ethics approval of IRB. The collection process can be found in supplementary materials

After the pre-processing unit with window Dice threshold of 0.3, we screen 761 lesions from 444 patients with four phases of CTs, seven types of lesions (13.2% of HCC, 5.3% of HM, 11.3% of ICC, 22.6%of HH, 31.1% of HC, 8.7% of FNH, and 7.8% of HA), and totally 4820 slices. To handle the imbalance of dataset, we randomly select 586 lesions as the training and validation set with no more than 700 axial slices in each lesion type, and the rest 175 lesions constitute the test set. Lesions from the same patient are either assigned to the training and validation set or the test set, but not both.",1,0,0,0,1,1,0,1,ct,liver,0,1,1,"sir run run shaw hospital (srrsh), zhejiang university school of medicine",1, zhejiang university school of medicine,0.0,0,0.0,0,0.0,0
Uncertainty-Informed Mutual Learning for Joint Medical Image Classification and Segmentation,4,4,0,"The experiments on the public datasets demonstrate that our UML outperforms existing methods in terms of both accuracy and robustness.

We evaluate the our UML network on two datasets REFUGE [14] and ISPY-1 [13]. REFUGE contains two tasks, classification of glaucoma and segmentation of optic disc/cup in fundus images. The overall 1200 images were equally divided for training, validation, and testing.
 The tasks of ISPY-1 are the pCR prediction and the breast tumor segmentation. A total of 157 patients who suffer the breast cancer are considered - 43 achieve pCR and 114 non-pCR. 

Info outside the paper
REFUGE dataset
The REFUGE challenge database consists of 1200 retinal CFPs stored in JPEG format, with 8 bits per color channel, acquired by ophthalmologists or technicians from patients sitting upright and using one of two devices- These pictures correspond to Chinese patients (52% and 55% female in offline and online test sets, respectively) visiting eye clinics, and were retrieved retrospectively from multiple sources, including several hospitals and clinical studies. Only high-quality images were selected to ensure a proper labelling, and any personal and/or device information was removed for anonymization.

ISPY-1 dataset
Clinical and MRI data from the ISPY1 clinical trial of patients with breast cancer. 
Clinical Data as a XLS file with the following fields:

Age (Years)
Race, encoded as:
1 = Caucasian
3 = African American
4 = Asian
5 = Native Hawaiian
6 = American Indian
50 = Multiple race",1,0,0,0,0,2,2,0,"fundus, segmentation, ","breast, eye",0,0,0,0,0,0,0.0,0,0.0,0,0.0,0
Unpaired Cross-Modal Interaction Learning for COVID-19 Segmentation on Limited CT Images,58,3,0,"note: paper refs to wrong dataset (look further down)

We used the public COVID-19 segmentation benchmark [15] to verify the proposed UCI. It is collected from two public resources [5,8] on chest CT images available on The Cancer Imaging Archive (TCIA) [4]. All CT images were acquired without intravenous contrast enhancement from patients with positive Reverse Transcription Polymerase Chain Reaction (RT-PCR) for SARSCoV-2. In total, we used 199 CT images including 149 training images and 50 test images. We also used two chest x-ray-based classification datasets including
ChestX-ray14 [18] and ChestXR [1] to assist the UCI training. The ChestXray14 dataset comprises 112,120 X-ray images showing positive cases from 30,805 patients, encompassing 14 disease image labels pertaining to thoracic and lung ailments. An image may contain multiple or no labels. The ChestXR dataset consists of 21,390 samples, with each sample classified as healthy, pneumonia, or COVID-19.

Info outside the paper
Two public resources[5,8]
Cinical data: age, sex, race, zip, weight.
The average age in the cohort was 54.3 years old (range 19–91) with an even sex distribution (52 Male, 53 Female). The worldwide incidence is reported to be close to 1:1, with a 50% increase in hospitalizations, ICU stays, and mortality among males10. The racial characteristics of the cohort are presented in Fig. 1 in comparison to the total population of Arkansas and the current characteristics of the state-wide infected population. The average BMI in the cohort is 33.1 (18.7–64.9), well within obese range (30.0 or higher). Key Comorbidities include burns (2%), malnutrition (3%), pregnancy (4%), chronic kidney disease (11%), diabetes (21%), organ transplant (3%), and cancer (24%).
The overall ICU admission rate was 28% (29/105). The Average age among those admitted to the ICU was 58 (range 25–89), slightly higher than the average for the cohort as a whole. The racial breakdown of ICU admissions included 28% of the white patients, 25% of the black, 50% of other, and 100% of Pacific islanders. The ICU population was 66% male and 33% female and included 1 pregnant patient. Forty three percent of patients admitted to the ICU had BMI greater than 30. Of the black patients, 21% had diabetes and 29% chronic renal disease, while among white patients the highest percentage comorbidities were cancer (10%) and diabetes (10%). The ICU mortality rate was 34.4% (10/29) which is 1.5 times the national average of 23.6%11. The overall mortality rate was 10% (10/105) and all 10 patients in the mortality group were first admitted to ICU. Arkansan males were 1.95 times more likely to go to ICU (19/52 vs. 10/53). Our data shows an almost even overall mortality rate among males (5/53) and females (5/52). The data also suggest that once in the ICU, female mortality occurs at a rate 1.9 times that of males (5/19 vs. 5/10). 
COVID-19-AR image collection: Image data were extracted from the clinical PACS (Sectra AB, Linkoping, Sweden) at the University of Arkansas for Medical Sciences using Digital Imaging and Communications in Medicine (DICOM) query/retrieve software. All image data were de-identified and stored in DICOM standard format17 on TCIA as collection COVID-19-AR18. All clinical data were obtained from the Arkansas Clinical Data Repository (AR-CDR)19. The AR-CDR is a research data warehouse that provides a single and secure source of data for use in clinical and translational research; housing data for this project that are extracted from the EPIC (Epic Systems Inc, Verona, WI) electronic health record (EHR) system and legacy systems.

https://www.nature.com/articles/s41467-020-17971-2/tables/1
Patient cohorts in model development and testing: demographic values, center/location, age, gender, demographic distribution pr training, validation and testing 

TCIA
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3824915/
ChestX-ray14 and ChestXR
ChestX-ray14 refs to Chestx-ray8 in the paper and not ray14. Ray8 contains (taken from ref): In this paper, we present a new chest X-ray database, namely “ChestX-ray8”, which comprises 108,948 frontalview X-ray images of 32,717 unique patients with the textmined eight disease image labels (where each image can have multi-labels), from the associated radiological reports
using natural language processing

The link to ray 14 describes the dataset as: ChestX-ray14 is a medical imaging dataset which comprises 112,120 frontal-view X-ray images of 30,805 (collected from the year of 1992 to 2015) unique patients with the text-mined fourteen common disease labels, mined from the text radiological reports via NLP techniques. It expands on ChestX-ray8 by adding six additional thorax diseases: Edema, Emphysema, Fibrosis, Pleural Thickening and Hernia.
ChestXR ",1,0,0,0,0,"3 (4, since one dataset is collected from two public datasets)",4,0,"ct, x-rays, segmentations",chest,0,0,0,0,0,0,0.0,0,0.0,0,0.0,0
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,66,10,0,"Manifold Learning. We trained our model with a large dataset of 3500 CTs of
patients with head-and-neck cancer, more exactly 2297 patients from the publicly
available The Cancer Imaging Archive (TCIA) [1,6,16,17,28,32] and 1203 from
private internal data, after obtention of ethical approbations. We split this data
into 3000 cases for training, 250 for validation, and 250 for testing. We focused
CT scans on the head and neck region above shoulders, with a resolution of
80×96×112, and centered on the mouth after automatic segmentation using a
pre-trained U-Net [22]. The CTs were preprocessed by min-max normalization
after clipping between -1024 and 2000 Hounsfield Units (HU).

3D Reconstruction. To evaluate our approach, we used an external private cohort
of 80 patients who had undergone radiotherapy for head-and-neck cancer, with
their consent. Planning CT scans were obtained for dose preparation, and CBCT
scans were obtained at each treatment fraction for positioning with full gantry
acquisition. As can be seen in Fig. 3 and the supplementary material, all these
cases are challenging as there are large changes between the original CT scan
and the CBCT scans. We identified these cases automatically by comparing the
CBCTs with the planning CTs",1,0,0,0,0,3,1,2,"ct, mri, cbct","head, neck, brain ",0,0,0,0,0,0,0.0,0,0.0,0,0.0,0
Deep Unsupervised Clustering for Conditional Identification of Subgroups Within a Digital Pathology Image Set,64,8,1,"The Colored MNIST is an extension to the classic MNIST dataset [3], which contains binary images of handwritten digits. The Colored MNIST includes colored images of the same digits, where each number and background have a color assignment. We present results of the experiments with five distinct colors and five digits of MNIST (0–4). To enhance computational efficiency and expedite experiments, we utilized only 1% of the MNIST images, which were sampled at random.

HER2 Dataset. Human epidermal growth factor receptor 2 (HER2 or HER2/neu) is a protein involved in normal cell growth, which plays an important role in the diagnosis and treatment of breast cancer [8]. The dataset consists
of 241 patches extracted from 64 digitized slides of breast cancer tissue which were stained with HER2 antibody. Each tissue slide has been digitized at three
different sites using three different whole slide imaging systems, evaluated by 7 pathologists on a 0–100 scale, and following clinical practice labeled as HER2 Class 1, 2, or 3 (based on mean pathologists’ scores with cut-points at 33 and 66). 
We use a subset of this dataset consisting of 672 images (the remainder is held out for future research). Because the intended purpose is finding subgroupsin the given dataset only, a separate test set is not used.  We refer to [4,8] for more details about this dataset.
This retrospective human subject dataset has been made available to us by the authors of the prior studies [4,8], who are not associated with this paper. Appropriate ethical approval for the use of this material in research has been obtained.

The authors would like to thank Dr. Marios Gavrielides for providing access to the HER2 dataset and for helpful discussion. This project was supported n part by an appointment to the Research Participation Program at the U.S. Food and Drug Administration administered by the Oak Ridge Institute for Science and Education through an interagency agreement between the U.S. Department of Energy and the U.S. Food and Drug Administration. XS acknowledges support from
the Hightech Agenda Bayern.

Info outside paper
MNIST dataset (referenced link was not accessable)
",0,0,0,0,0,2,1,1,wsi,breast,0,0,0,0,0,0,0.0,0,0.0,0,1.0,https://www.sciencedirect.com/science/article/pii/S0262885604000721?via%3Dihub
Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,25,9,1,"To further validate the proposed solution, we acquired and publicly released two datasets captured using a custom-designed, portable stereo laparoscope system.

our first newly acquired dataset, named Jerry, contains 1200 sets
of images. Since it is important to report errors in 3D and in millimeters, we recorded another dataset similar to Jerry but also including ground truth depth map for all frames by using structured-lighting system [8]—namely the Coffbee dataset.

[8] https://arxiv.org/pdf/2208.08407.pdf
Provides info about 2 datasets: SCARED and LATTE, not Coffbee.",0,0,0,0,0,2,0,0,"laparoscopy, 3d, 2d",0,0,0,0,0,0,0,0.0,0,0.0,0,0.0,0
Multi-scale Prototypical Transformer for Whole Slide Image Classification,58,6,1,"To evaluate the effectiveness ofMSPT, we conducted experiments on two public dataset, namely Camelyon16 [24] and TCGA-NSCLC. Camelyon16 is a WSI dataset for the automated detection of metastases in lymph node tissue slides. It includes 270 training
samples and 129 testing samples. 
The TCGA-NSCLC dataset includes two sub-types of lung cancer, i.e., Lung Squamous Cell Carcinoma (TGCA-LUSC) and Lung Adenocarcinoma (TCGA-LUAD). We collected a total of 854 diagnostic slides from the National Cancer Institute Data Portal (https:// portal.gdc.cancer.gov). ",0,0,0,0,1,2,2,0,"wsi, ","lymp nodes, lung",0,1,0,0,1,national cancer institute data portal ,0.0,0,0.0,0,0.0,0
MUVF-YOLOX: A Multi-modal Ultrasound Video Fusion Network for Renal Tumor Diagnosis,62,5,1,"We collect a renal tumor US dataset of 179 cases from two medical centers, which is split into the training and validation sets. We further collect 36 cases from the two medical centers mentioned above (14 benign cases) and another center (Fujian Provincial Hospital, 22 malignant cases) to form the test set. Each case has a video with simultaneous imaging of B-mode and CEUS-mode.

Note: the two medical centers mentioned above are not to be found in the content of the paper (unless they mean in the section under title name, which isnt obvious)",0,0,0,0,1,1,0,1,"us, ultrasound",rental,0,1,1,fujian provincial hospital,0,0,0.0,0,0.0,0,0.0,0
Pre-trained Diffusion Models for Plug-and-Play Medical Image Enhancement,1,3,1,"Experiments on low-dose CT and heart MR datasets.

We conducted experiments on two common image enhancement tasks: denoising and SR. To mimic the real-world setting, the diffusion models weretrained on a diverse dataset, including images from different centers and scanners.
The testing set (e.g., MR images) is from a new medical center that has not appeared in the training set. Experiments show that our model can generalize to these unseen images. Specifically, the denoising task is based on the AAPM Low Dose CT Grand Challenge abdominal dataset [19], which can be also used for SR [33]. The heart MR SR task is based on three datasets: ACDC [1], M&Ms1-2 [3], and CMRxMotion [27]. Notably, the presented framework eliminates the requirement of paired data. For the CT image enhancement task, we trained a diffusion model [21] based on the full-dose dataset that contains 5351 images, and the hold-out quarter-dose images were used for testing. For the MR enhancement task, we used the whole ACDC [1] and M&Ms1-2 [3] for training the diffusion model and the CMRxMotion [27] dataset for testing. The testing images were downsampled by operator H with factors of 4× and 8× to produce low-resolution images, and the original images served as the ground truth.

testing dataset, aapm low dose ct grand challenge abdominal dataset, acdc, m&ms1-2, cmrxmotion, full-dose dataset

We also thank the organizers of AAPM Low Dose CT Grand Challenge [20], ACDC [1], M&Ms1-2 [3], and CMRxMothion [27] for making the datasets publicly available.",0,0,0,0,1,6,4,0,"mr, ct","abodomen, heart",0,1,1,0,0,0,0.0,0,0.0,0,0.0,0
Relaxation-Diffusion Spectrum Imaging for Probing Tissue Microarchitecture,15,8,1,"We evaluate RDSI using both ex vivo monkey and in vivo human brain MTE data.
We used an ex vivo monkey dMRI dataset2 collected with a 7T MRI
scanner [19].
One healthy subject and three patients with gliomas were scanned using a Philips Ingenia CX 3T MRI scanner with a gradient strength of 80mT/m and switching rates of 200 mT/m/ms.

Info outside paper
Data was collected from an ex vivo fixed Vervet (Chlorocebus aethiops) monkey brain, obtained from the Montreal Monkey Brain Bank. The monkey, cared for on the island of St. Kitts, had been treated in line with a protocol approved by The Caribbean Primate Center of St. Kitts. The brain had previously been stored and prepared according to Dyrby et al. [1]. The data was collected with a Bruker Biospec 70/20 7.0 T scanner (Billerica, Massachusetts, USA) using a quadrature RF coil (300 MHz). The brain was let to reach room temperature and to mechanically stabilize prior the start of the acquisition.",1,0,0,0,0,2,1,0,"mte, dmri, mri, ","human brain, monkey brain",0,0,0,0,0,0,0.0,0,0.0,0,1.0,https://resources.drcmr.dk/MAPdata/axon-relaxation/README.txt
SHISRCNet: Super-Resolution and Classification Network for Low-Resolution Breast Cancer Histopathology Image,3,5,1,"This work uses the breast cancer histopathological image database
(BreaKHis)1 [20]. This dataset includes four distinct histological types of benign breast tumors: adenosis (A), fibroadenoma (F), phyllodes tumor (PT), and tubular adenona (TA); and four malignant
tumors (breast cancer): carcinoma (DC), lobular carcinoma (LC), mucinous carcinoma (MC) and papillary carcinoma (PC). The original dataset is randomly divided into training set and testing set for each magnification at a ratio of 7:3 following previous work

Info outside paper
BreakHis
The BreaKHis database contains microscopic biopsy images
of benign and malignant breast tumors. Images were collected
through a clinical study from January 2014 to December 2014.
All patients referred to the P&D Laboratory, Brazil, during this
period of time, with a clinical indication of BC were invited to
participate in the study. The institutional review board approved
the study and all patients  gave written informed consent. All the
data were anonymized. Samples are generated from breast tissue biopsy slides, stained with hematoxylin and eosin (HE). The samples are collected by SOB, prepared for histological study, and labeled by
pathologists of the P&D Lab.
",0,0,0,0,0,1,1,0,histopathology,breast,0,0,0,0,0,0,0.0,0,0.0,0,1.0,https://www.inf.ufpr.br/lesoliveira/download/TBME-00608-2015-R2-preprint.pdf
Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-Based Hierarchical Fusion Network with Attention Mechanism,8,7,1,"This study was approved by Institutional Review Board of our cancer institute with a waiver of informed consent.We retrospectively collected 765 patients with breast cancer presenting at our cancer institute from January 2015 to November 2020, all patients had biopsy-proven breast cancers (all cancers included in this study were invasive breast cancers, and ductal carcinoma in situ had been excluded). The MRIs were acquired with Philips Ingenia 3.0-T scanners, and overall, three sequences were present in the in-house dataset, including T1- weighted fat-suppressed MRI, contrast enhanced T1-weighted MRI and DWI

Based on the ratio of 8:2, the training set and independent test set of the in-house dataset have 612 and 153 cases, respectively.",1,0,0,0,1,1,0,1,"mri, t1, dwi",breast,0,1,0,0,1,1,0.0,0,0.0,0,0.0,0
Towards Multi-modal Anatomical Landmark Detection for Ultrasound-Guided Brain Tumor Resection with Contrastive Learning,64,9,1,"We employed the publicly available EASY-RESECT (REtroSpective Evaluation of Cerebral Tumors) dataset [10 (https://archive.sigma2.no/pages/ public/dataset Detail.jsf?id 10.11582/2020.00025) to train and evaluate our proposed method. This dataset is a deep-learning-ready version of the original RESECT database, and was released as part of the 2020 Learn2Reg Challenge [24]. Specifically, EASY-RESECT contains MRI and intra-operative US scans (before resection) of 22 subjects who have undergone low grade glioma resection surgeries. 

To train our DL model, we made subject-wise division of the entire dataset into 70%:15%:15% as the training, validation, and testing sets, respectively.

Table 1 lists the mean and standard deviation of landmark identification errors (in mm) between the predicted position and the ground truth in intra-operative US for each patient of the RESECT dataset.",1,0,0,0,0,1,1,0,"mri, intra-operative us, us, ultrasound","cerebral, brain ",0,0,0,0,0,0,0.0,0,0.0,0,0.0,0
Trackerless Volume Reconstruction from Intraoperative Ultrasound Images,29,10,cancer,"To validate our method, six tracked sequences were acquired from an ex vivo swine liver. A manually manipulated IVUS catheter was used (8 Fr lateral firing AcuNavTM 4–10 MHz) connected to an ultrasound system (ACUSON S3000 HELX Touch, Siemens Healthineers, Germany), both commercially available. An electromagnetic tracking system (trakSTARTM, NDI, Canada) was used along with a 6 DoF sensor (Model 130) embedded close to the tip of the catheter, and the PLUS toolkit [17] along with 3D Slicer [18] were used to record the sequences.",0,0,0,0,0,1,0,0,"intra-operative us, ultrasound, intraoperative ultrasound",swine liver,0,0,0,0,0,0,0.0,0,0.0,0,0.0,0
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,77,6,1,"The cohort employed in this study was composed of pre-treatment tumor biopsy specimens from patients with NSCLC from five centers (two centers for training (St) and three centers for independent validation (Sv)). The entire analysis was carried out using 122 patients in Experiment 1 (73 in St, and 49 in Sv) and 135 patients in Experiment 2 (81 in St, and 54 in Sv). Specimens were analyzed with a multiplexed quantitative immunofluorescence (QIF) panel using the method described in [22]. From each whole slide image, 7 representative tiles were obtained and used to train the software InForm to define background, tumor and stromal compartments. Then, individual cells were segmented based on nuclear DAPI staining and the segmentation performance was controlled by direct visualization of samples by a trained observer. Next, the software was trained to identify cell subtypes based on marker expression (CD8, CD4, CD20, CK for tumor epithelial cells and absence of these markers for stromal cells).

NSCLC: non-small cell lung cancer",1,0,0,0,1,5,0,5,wsi,lung,0,1,0,0,1,0,0.0,0,0.0,0,0.0,0
Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,21,3,1,"Note: The Japanese Society of Radiological Technology (JSRT) - a location?

The CAMUS dataset [20] contains cardiac ultrasounds from 500
patients.Manual annotations for the endocardium and epicardium borders of the left
ventricle (LV) and the left atrium were obtained from a cardiologist for the
end-diastolic (ED) and end-systolic (ES) frames. The dataset is split into 400
training patients, 50 validation patients, and 50 testing patients. 

Private Cardiac US. This is a proprietary multi-site multi-vendor dataset containing
2D echocardiograms of apical two and four chambers from 890 patients.
Data comes from patients diagnosed with coronary artery disease, COVID, or
healthy volunteers. The dataset is split into a training/validation set (80/20) and
an independent test set from different sites, comprised of 994 echocardiograms
from 684 patients and 368 echocardiograms from 206 patients, respectively.

JSRT. The Japanese Society of Radiological Technology (JSRT) dataset consists of 247 chest X-Rays [26]. We used the 120 points for the lungs and heart annotation made available by [10]. The set of points contains specific anatomical points for each structure (4 for the right lung, 5 for the left lung, and 4 for the heart) and equally spaced points between each anatomical point. We reconstructed the segmentation map with 3 classes (background, lungs, heart) with these points and used the same train-val-test split of 70%–10%–20% as [10].",1,0,0,0,1,4,2,2,"ultrasounds, 2d echocardigrams, echocardiograms, x-rays","heart, chest, lung",0,0,0,0,1,different sites',0.0,0,0.0,0,0.0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,40,7,1,"Note: difficult to determine the quantity of datasets used

CT scan dataset, 3D camera dataset and CT scan, CT scan from seperate site in Europe

Our CT scan dataset consists of 62, 420 patients from 16 different sites across
North America, Asia and Europe. Our 3D Camera dataset consists of 2, 742 pairs of depth image and CT scan from 2, 742 patients from 6 different sites across
North America and Europe acquired using a ceiling-mounted Kinect 2 camera.
Our evaluation set consists of 110 pairs of depth image and CT scan from 110
patients from a separate site in Europe.

We trained our AutoDecoder model on our unpaired CT scan dataset of 62, 420
patients with a latent vector of size 32. The encoder was trained on our paired
CT scan and depth image dataset of 2, 742 patients.",1,0,0,0,1,3,0,0,"ct, 3d camera",lung,0,1,0,0,0,0,1.0,"north america, asia, europe",1.0,"unknown, referred to as ""different sites""",0.0,0
BerDiff: Conditional Bernoulli Diffusion Model for Medical Image Segmentation,47,4,1,"Extensive experimental results on two medical image segmentation datasets.

The data used in this experiment are obtained from LIDC-IDRI [2,7] and BRATS 2021 [4] datasets. LIDC-IDRI contains 1,018 lung CT scans with plausible segmentation masks annotated by four radiologists.

BRATS 2021 consists of four different sequence (T1, T2, FlAIR, T1CE) MRI images for each patient.

Our training set includes 55,174 2D images scanned from 1,126 patients, and the test set comprises 3,991 2D images scanned from 125 patients",1,0,0,0,0,2,0,0,"mri, t1, t2, flair, t1ce, ct, 2d",lung,0,0,0,0,0,0,0.0,0,0.0,0,0.0,0
Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,53,7,1,"Ex-vivo: Data is collected from fresh breast tissue samples from the patients
referred to BCS at Kingston Health Sciences Center over two years. The study
is approved by the institutional research ethics board and patients consent to be
included. Peri-operatively, a pathologist guides and annotates the ex-vivo pointburns, referred to as spectra, from normal or cancerous breast tissue immediately after excision. In addition to spectral data, clinicopathological details such as the status of hormone receptors is also provided post-surgically. In total 51 cancer and 149 normal spectra are collected and stratified into five folds (4 for cross validation and 1 prospectively) with each patient restricted to one fold only.

Intra-operative: A stream of iKnife data is collected during a BCS case
(27 min) at Kingston Health Sciences Center. At the sampling rate of 1Hz, a
total of 1616 spectra are recorded. Each spectrum is then labeled based both on
surgeons comments during the operation and post-operative pathology report.

",1,0,0,0,1,2,0,0,intra-operative spectrometry,breast,0,1,0,0,1,BSC kingston health sciences center,0.0,0,0.0,0,0.0,0
CARL: Cross-Aligned Representation Learning for Multi-view Lung Cancer Histology Classification,35,5,1,"Note: dataset collected from two different online resources

Our dataset NSCLC-TCIA for lung cancer histological subtype classification is sourced from two online resources of The Cancer Imaging Archive (TCIA) [5]: NSCLC Radiomics [1] and NSCLC Radiogenomics [2]. Exclusion criteria involves patients diagnosed with large cell carcinoma or not otherwise specified, along with cases that have contouring inaccuracies or lacked tumor delineation [9, 13]. Finally, a total of 325 available cases (146 ADC cases and 179 SCC cases) are used for our study. We evaluate the performance of NSCLC classification in five-fold cross validation on the NSCLC-TCIA dataset, and measure accuracy (Acc), sensitivity (Sen), specificity (Spe), and the area under the receiver operating characteristic (ROC) curve (AUC) as evaluationmetrics.We also conduct analysis including standard deviations and 95% CI, and DeLong statistical test for further AUC comparison.

For preprocessing, given that the CT data from NSCLC-TCIA has an in-plane resolutionof 1mm×1mmand a slice thickness of 0.7–3.0 mm, we resample the CT images using trilinear interpolation to a common resolution of 1mm × 1mm × 1mm.",1,0,0,0,0,1,1,0,ct,lung,0,1,0,0,1,the cancer imaging archive,0.0,0,0.0,0,0.0,0
Category-Level Regularized Unlabeled-to-Labeled Learning for Semi-supervised Prostate Segmentation with Multi-site Unlabeled Data,1,4,1,"To efficiently enrich the unlabeled pool, seeking support from other centers is a viable solution, as illustrated in Fig. 1. Yet, due to differences in imaging protocols and variations in patient demographics, this solution usually introduces data heterogeneity, leading to a quality problem. Such heterogeneity may impede the performance of SSL which typically assumes that the distributions of labeled data and unlabeled data are independent and identically distributed (i.i.d.) [16]. Thus, proper mechanisms are called for this practical but challenging SSL scenario.

We utilize prostate T2-weighted MR images from six different clinical centers (C1–6) [1,4,5] to perform a retrospective evaluation. 
The heterogeneity comes from the differences in scanners, field strengths,
coil types, disease and in-plane/through-plane resolution. Compared to C1 and
C2, scans from C3 to C6 are taken from patients with prostate cancer, either for
detection or staging purposes, which can cause inherent semantic differences in
the prostate region to further aggravate heterogeneity.",1,0,0,0,1,6,0,6,t2 mr,prostate,1,1,1,0,0,0,0.0,0,0.0,0,0.0,0
