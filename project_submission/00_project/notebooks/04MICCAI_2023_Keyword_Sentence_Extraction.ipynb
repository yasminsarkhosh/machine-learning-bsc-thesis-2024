{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Objective of the Notebook**\n",
    "***\n",
    "The notebook's primary goal is to extract sentences from preprocessed MICCAI 2023 research papers based on specific keywords. These sentences are categorized by paper titles and focus on gathering text that potentially contains crucial information regarding demographics and other significant areas.\n",
    "\n",
    "#### Input Data Expected\n",
    "- **CSV File**: The notebook uses a CSV file containing preprocessed text from research papers. This data includes columns for paper titles and text content, which has been prepared in advance, ready for extraction.\n",
    "\n",
    "#### Output Data/Files Generated\n",
    "- **CSV Files**: The notebook outputs CSV files for each category of interest (e.g., age, gender, ethnicity, dataset information), containing extracted sentences or keywords. These outputs are intended for further analysis or use in machine learning tasks.\n",
    "- **Directories**: Extracted data will be organized into specific directories, like those for cancer-related content, patient demographics, etc., to facilitate easy access and subsequent processing.\n",
    "\n",
    "#### Assumptions or Important Notes\n",
    "- **Preprocessing Requirement**: This notebook assumes that all necessary data cleaning, formatting, and preliminary analysis have been completed prior to sentence extraction.\n",
    "- **Keyword Relevance**: The success of the extraction process is highly dependent on the relevance and completeness of the keywords list used. Inaccurate or incomplete keyword lists may result in incomplete or biased data collections.\n",
    "- **Text Structure**: Assumes that the text in the input CSV is well-structured and appropriately segmented into sentences. Any deviations in text structure may impact the accuracy of the extraction process.\n",
    "- **Error Handling**: Minimal error handling is noted for file reading and writing, which might lead to issues if input files are missing or directories are not set up correctly. It is vital to verify that all file paths are correct and accessible.\n",
    "- **Scalability**: The computational intensity of the process may vary based on the amount of data being processed (number of papers and volume of text). Optimization may be required to handle large datasets effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Input and Output Files**\n",
    "\n",
    "| Type  | Description                                      | Details                                                       |\n",
    "|-------|--------------------------------------------------|---------------------------------------------------------------|\n",
    "| Input | **CSV File**                                     | Preprocessed text from research papers stored in a CSV file.  |\n",
    "|       |                                                  | Includes columns for paper titles and text content.           |\n",
    "| Output| **CSV Files for Each Category**                  | Contains extracted sentences or keywords for specific topics. |\n",
    "|       | **Directories**                                  | Organized storage for extracted data by category.             |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Keyword-Based Sentence Extraction from Selected MICCAI 2023 Research Articles**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Third-party library imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '00MICCAI_total_outputs/03MICCAI_all_outputs/03MICCAI_notebook_df_paper_extractions_patients_and_cancer.csv'\n",
    "\n",
    "#03MICCAI_all_outputs/03MICCAI_notebook_df_paper_extractions_patients_and_cancer.csv\n",
    "selected_papers = pd.read_csv(filename)\n",
    "len(selected_papers['title'].unique()) # 155 unique papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract keyword-related sentences from selected papers\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Short keywords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of keywords\n",
    "keywords_age        = ['age', 'young', 'old']\n",
    "\n",
    "keywords_gender     = ['gender', 'sex', 'women', 'woman', 'female', 'male']\n",
    "\n",
    "keywords_etnicity   = ['etnicity', 'etnicities', 'race', 'white patients', 'black patients']\n",
    "\n",
    "keywords_geoloc     = ['geolocation', 'geographical', 'geographic', 'country', 'countries', 'city', 'cities', \n",
    "                       'hospital', 'hospitals', 'clinic', 'clinics', 'continent','province', 'state', 'region', \n",
    "                       'town', 'village', 'area', 'district']\n",
    "\n",
    "keywords_bias       = ['bias', 'biases', 'fairness']\n",
    "\n",
    "keywords_patients   = ['patient', 'patients']\n",
    "\n",
    "keywords_data       = ['dataset', 'datasets', 'data set', 'data sets', 'publicly', 'public', 'private', 'open access', 'open-access']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {\n",
    "    'age'           : ['age', 'young', 'old'],\n",
    "    'gender'        : ['gender', 'sex', 'women', 'woman', 'female', 'male'],\n",
    "    'ethnicity'     : ['ethnicity', 'ethnicities', 'race', 'white patients', 'black patients'],\n",
    "    'location_info' : ['geolocation', 'geographical', 'geographic', 'country', 'countries', \n",
    "                       'city', 'cities', 'hospital', 'hospitals', 'clinic', 'clinics', 'continent',\n",
    "                       'province', 'state', 'region', 'town', 'village', 'area', 'district'],\n",
    "    'dataset_info'  : ['dataset', 'datasets', 'data set', 'data sets', 'publicly', 'public', 'private', 'open access', 'open-access'],\n",
    "    'bias_info'     : ['bias', 'biases', 'fairness']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Split the text into words and extract keyword-matches. Group each keyword-match by relatd paper \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_text(text, width=100):\n",
    "    \"\"\"\n",
    "    A simple function to wrap text at a given width.\n",
    "    \"\"\"\n",
    "    if pd.isnull(text):\n",
    "        return text  # Handle NaN values\n",
    "    \n",
    "    wrapped_lines = []\n",
    "    for paragraph in text.split('\\n'):  # Splitting by existing newlines to preserve paragraph breaks\n",
    "        line = ''\n",
    "        for word in paragraph.split():\n",
    "            if len(line) + len(word) + 1 > width:\n",
    "                wrapped_lines.append(line)\n",
    "                line = word\n",
    "            else:\n",
    "                line += (' ' + word if line else word)\n",
    "        wrapped_lines.append(line)\n",
    "    return '\\n'.join(wrapped_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords search only\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text into sentences and search for the keywords\n",
    "\n",
    "def extract_keywords(df, keywords):\n",
    "    # Search for the whole word in the text\n",
    "    pattern = r'\\b(' + '|'.join(re.escape(keyword) for keyword in keywords) + r')\\b'\n",
    "\n",
    "    # Initialize a dictionary to hold sentences organized by paper title\n",
    "    sentences_by_paper = {}\n",
    "\n",
    "    # Loop through each row in the dataframe\n",
    "    for index, row in df.iterrows():\n",
    "        # Find all sentences that contain any of the keywords\n",
    "        sentences = re.findall(pattern, row['text'], flags=re.IGNORECASE | re.DOTALL)\n",
    "        \n",
    "        # If there are matching sentences, add them to the dictionary under the paper title\n",
    "        if sentences:\n",
    "            paper_title = row['title']\n",
    "            if paper_title not in sentences_by_paper:\n",
    "                sentences_by_paper[paper_title] = []\n",
    "            sentences_by_paper[paper_title].extend(sentences)\n",
    "\n",
    "    # Sentences_by_paper contains all the sentences that contain keywords, organized by paper title\n",
    "\n",
    "    # Convert this dictionary into a DataFrame:\n",
    "    # Create a list of tuples (paper title, sentence)        \n",
    "    keywords_data = [(title, keyword_sentence) for title, related_group in sentences_by_paper.items() for keyword_sentence in related_group]\n",
    "    keywords_df = pd.DataFrame(keywords_data, columns=['title', 'keyword'])\n",
    "    keywords_df['keyword'] = keywords_df['keyword'].apply(lambda x: wrap_text(x, width=100))\n",
    "\n",
    "    # Store data in output directory if it does not exist\n",
    "    output_dir = '04MICCAI_notebook_extracted_keywords'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Save the DataFrame to a CSV file in the output directory\n",
    "    keywords_df.to_csv(f'{output_dir}/keywords_{keywords}.csv', index=False)\n",
    "\n",
    "    return keywords_df       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the keywords from the selected papers and save them to CSV files in the output directory\n",
    "keywords_age_df = extract_keywords(selected_papers, keywords_age)\n",
    "keywords_gender_df = extract_keywords(selected_papers, keywords_gender)\n",
    "keywords_etnicity_df = extract_keywords(selected_papers, keywords_etnicity)\n",
    "keywords_geoloc_df = extract_keywords(selected_papers, keywords_geoloc)\n",
    "keywords_bias_df = extract_keywords(selected_papers, keywords_bias)\n",
    "keywords_patients_df = extract_keywords(selected_papers, keywords_patients)\n",
    "keywords_data_df = extract_keywords(selected_papers, keywords_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Sentence search only by list of keywords\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudo code\n",
    "# regex to split the text into sentences. A sentence is defined as a sequence of characters that ends with a period, question mark, or exclamation mark.\n",
    "# iterate through the sentences to find those with a keyword from the list of keywords. \n",
    "# for each match\n",
    "    # option 1) concatentinate the previous and next sentences to the sentence with the keyword (if they haven't been added already)\n",
    "    # option 2) extract sentence with keyword only\n",
    "# keep track of the sentences already added for each paper title.\n",
    "# if no matches are found for a paper title, add 'none'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT SENTS WITH KEYWORDS    \n",
    "# Option 2) Storing keyword sentence only \n",
    "\n",
    "def extract_keyword_sentences(df, keywords):\n",
    "    \"\"\"\n",
    "    Extract sentences containing specified keywords from DataFrame and organize by paper title.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the text to search through.\n",
    "    - keywords: List of keywords to search for in the text.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with paper titles as keys and lists of sentences containing the keywords as values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compile the regular expression for matching sentences containing the keywords\n",
    "    keyword_pattern = re.compile(r'\\b(?:' + '|'.join(keywords) + r')\\b', flags=re.IGNORECASE)\n",
    "\n",
    "    # Initialize a dictionary to hold sentences organized by paper title\n",
    "    sentences_by_paper = {}\n",
    "\n",
    "    # Loop through each paper title in the DataFrame\n",
    "    for title in df['title'].unique():\n",
    "        # Get the full text for the current title\n",
    "        text = ' '.join(df[df['title'] == title]['text'])\n",
    "        # Split the text into sentences\n",
    "        sentences = re.split(r'(?<=[.?!])\\s+', text)\n",
    "\n",
    "        # List to store sentences that contain the keyword\n",
    "        keyword_sentences_buffer = []\n",
    "\n",
    "        # Iterate through sentences to find and store sentences that contain the keyword\n",
    "        for sentence in sentences:\n",
    "            if keyword_pattern.search(sentence):\n",
    "                # Add only the sentence with the keyword to the buffer\n",
    "                keyword_sentences_buffer.append(sentence)\n",
    "\n",
    "        # Add the sentences to the dictionary, use 'none' if there are no matches\n",
    "        sentences_by_paper[title] = keyword_sentences_buffer if keyword_sentences_buffer else ['none']\n",
    "    \n",
    "    extracted_data = [(title, keyword_sentence) for title, related_group in sentences_by_paper.items() for keyword_sentence in related_group]\n",
    "    extracted_df = pd.DataFrame(extracted_data, columns=['title', 'extracted_keyword_sent'])\n",
    "    \n",
    "    # Wrap title and the extracted sentences to a maximum width of n-characters for better readability\n",
    "    extracted_df['extracted_keyword_sent'] = extracted_df['extracted_keyword_sent'].apply(wrap_text, width=80)\n",
    "\n",
    "    output_dir = '04MICCAI_notebook_extracted_sentences'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    extracted_df.to_csv(f'{output_dir}/extracted_sentences_{keywords}.csv', index=False)\n",
    "\n",
    "    return extracted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sentences containing keywords and save the results to a CSV file in the output directory\n",
    "age_extracted_sents_df = extract_keyword_sentences(selected_papers, keywords_age) \n",
    "age_extracted_sents_df = extract_keyword_sentences(selected_papers, keywords_age)\n",
    "gender_extracted_sents_df = extract_keyword_sentences(selected_papers, keywords_gender)\n",
    "ethnicity_extracted_sents_df = extract_keyword_sentences(selected_papers, keywords_etnicity)\n",
    "location_extracted_sents_df = extract_keyword_sentences(selected_papers, keywords_geoloc)\n",
    "bias_extracted_sents_df = extract_keyword_sentences(selected_papers, keywords_bias)\n",
    "patients_extracted_sents_df = extract_keyword_sentences(selected_papers, keywords_patients)\n",
    "data_extracted_sents_df = extract_keyword_sentences(selected_papers, keywords_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
