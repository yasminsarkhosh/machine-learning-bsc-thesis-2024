<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Retinal Age Estimation with Temporal Fundus Images Enhanced Progressive Label Distribution Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zhen</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Central Clinical School</orgName>
								<orgName type="department" key="dep2">Faculty of Medicine, Nursing and Health Sciences</orgName>
								<orgName type="institution">Monash University</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">AIM for Health Lab</orgName>
								<orgName type="institution">Monash University</orgName>
								<address>
									<settlement>Victoria</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Monash Medical AI</orgName>
								<orgName type="institution">Monash University</orgName>
								<address>
									<settlement>Victoria</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ruiye</forename><surname>Chen</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Centre for Eye Research Australia</orgName>
								<orgName type="institution">University of Melbourne</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="department">Department of Surgery</orgName>
								<orgName type="institution">University of Melbourne</orgName>
								<address>
									<settlement>Ophthalmology, Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Peng</forename><surname>Gui</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Monash Medical AI</orgName>
								<orgName type="institution">Monash University</orgName>
								<address>
									<settlement>Victoria</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Wuhan University</orgName>
								<address>
									<settlement>Hubei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lie</forename><surname>Ju</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xianwen</forename><surname>Shang</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Centre for Eye Research Australia</orgName>
								<orgName type="institution">University of Melbourne</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="department">Department of Surgery</orgName>
								<orgName type="institution">University of Melbourne</orgName>
								<address>
									<settlement>Ophthalmology, Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhuoting</forename><surname>Zhu</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Centre for Eye Research Australia</orgName>
								<orgName type="institution">University of Melbourne</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="department">Department of Surgery</orgName>
								<orgName type="institution">University of Melbourne</orgName>
								<address>
									<settlement>Ophthalmology, Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mingguang</forename><surname>He</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Centre for Eye Research Australia</orgName>
								<orgName type="institution">University of Melbourne</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="department">Department of Surgery</orgName>
								<orgName type="institution">University of Melbourne</orgName>
								<address>
									<settlement>Ophthalmology, Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Zongyuan</forename><surname>Ge</surname></persName>
							<email>zongyuan.ge@monash.edu</email>
							<affiliation key="aff1">
								<orgName type="laboratory">AIM for Health Lab</orgName>
								<orgName type="institution">Monash University</orgName>
								<address>
									<settlement>Victoria</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Monash Medical AI</orgName>
								<orgName type="institution">Monash University</orgName>
								<address>
									<settlement>Victoria</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff7">
								<orgName type="department">Faculty of IT</orgName>
								<orgName type="institution">Monash University</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Retinal Age Estimation with Temporal Fundus Images Enhanced Progressive Label Distribution Learning</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="629" to="638"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">FAE79CDB9E103B5F11F1A82DA8850233</idno>
					<idno type="DOI">10.1007/978-3-031-43990-2_59</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-01T10:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Retinal age estimation</term>
					<term>label distribution learning</term>
					<term>temporal fundus image</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Retinal age has recently emerged as a reliable ageing biomarker for assessing risks of ageing-related diseases. Several studies propose to train deep learning models to estimate retinal age from fundus images. However, the limitation of these studies lies in 1) both of them only train models on snapshot images from single cohorts; 2) they ignore label ambiguity and individual variance in the modeling part. In this study, we propose a progressive label distribution learning (LDL) method with temporal fundus images to improve the retinal age estimation on snapshot fundus images from multiple cohorts. First, we design a two-stage LDL regression head to estimate adaptive age distribution for individual images. Then, we eliminate cohort variance by introducing ordinal constraints to align image features from different data sources. Finally, we add a temporal branch to model sequential fundus images and use the captured temporal evolution as auxiliary knowledge to enhance the model's predictive performance on snapshot fundus images. We use a large retinal fundus image dataset which consists of ∼130k images from multiple cohorts to verify our method. Extensive experiments provide evidence that our model can achieve lower age prediction errors than existing methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Population ageing is a huge health burden worldwide as the risk of morbidity and mortality increases exponentially with age <ref type="bibr" target="#b1">[2]</ref>. However, great heterogeneity exists across individuals with the same chronological age, indicating chronological age poorly reflects intra-individual variation <ref type="bibr" target="#b10">[10]</ref>. A quest for biomarkers that can accurately determine individual-specific, age-related risk of adverse outcomes has been embarked upon. Among the countless potential candidate ageing biomarkers <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b12">12]</ref>, retinal age has been verified to be one of the most reliable indicators with the advantages of being rapid, non-invasive, and cost-effective <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b16">16,</ref><ref type="bibr" target="#b17">17]</ref>.</p><p>With the advent of technology, deep learning (DL) algorithms have found great applications in retinal age prediction. For example, Liu et al. <ref type="bibr" target="#b8">[9]</ref> developed a convolutional neural network (CNN) to estimate retinal age with label distribution learning (LDL) on 12k fundus images from healthy Chinese populations. Zhu et al. <ref type="bibr" target="#b17">[17]</ref> trained a CNN regression model on the UK Biobank cohort consisting of ∼70k fundus images. The limitations of these studies include: 1) the use of a single source of data in these studies has underestimated the complexity of data variance in real-world scenarios, which limits the generalizability of retinal age prediction. 2) only snapshot databases are used in these studies and failure track a detailed trail of age-specific changes. 3) outputting a single value with direct regressions <ref type="bibr" target="#b17">[17]</ref> ignores the ambiguity of age labels, and using fixed label distribution <ref type="bibr" target="#b8">[9]</ref> as ground truth did not consider individual variations. Tackling these shortcomings will improve the generalizability as well as reduce technical errors in the age prediction algorithm, providing a more reliable retinal age estimate.</p><p>Therefore, in this study, we present an attempt to provide a novel accurate estimate of retinal age by learning adaptive age distribution from multiple cohorts with temporal fundus images available. Instead of learning a model using fixed label distribution as ground truth, we formulate the age estimation as a two-stage LDL task and give an adaptive distribution estimate for individual fundus images. As learning the LDL model with images from different data sources can harm the consistency and ordinality of embedding space, we introduce ordinal constraints to align the image features from different domains. Moreover, to leverage the temporal knowledge from the fundus image sequence, we add a temporal branch to capture the temporal evolution and use this auxiliary information to enhance the predictive performance of our model on snapshot images. We verify our method on a large retinal fundus dataset which consists of approximately 130k images of healthy subjects from the UKB cohort and Chinese cohorts. Extensive experiments prove that our model can achieve lower age prediction errors on multiple cohorts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Progressive Label Distribution Learning</head><p>As shown in Fig. <ref type="figure" target="#fig_0">1</ref>, we formulate the retinal age estimation as a two-stage label distribution learning process. In the first stage, the model uses global features to predict a coarse age distribution on roughly discretized age labels. Each coarse age prediction is associated with a query vector corresponding to an age group. Then, the model performs class attention <ref type="bibr" target="#b13">[13]</ref> between the age group query and spatial features to generate fine-level features which are further combined with the coarse age prediction to give refined age predictions.</p><p>Formally, given a dataset with N images</p><formula xml:id="formula_0">X = {x i } N i=1 , the corresponding age labels Y = {y i } N i=1 range in [a, b].</formula><p>The image encoder first transforms an input image x i into a spatial feature F i ∈ R H×W ×C , then a convolutional projection layer maps F i into the base representation F i ∈ R H×W ×D and the averaged feature f i ∈ R 1×D for the following age distribution learning. We discretize the age classes as ŷi = R (y i /δ d ) * δ d , where R (•) denotes the round operator and δ d is the age bin for tuning the discretization degree. Therefore, the total discretized age class number is</p><formula xml:id="formula_1">C δ d = R |b-a| δ d</formula><p>. For the coarse-level age estimation, we set a large δ d = 10 which determines the age group queries as</p><formula xml:id="formula_2">Q coarse ∈ R C δ d ×D .</formula><p>Then, we use an FC layer with softmax applied on the f i to calculate the coarse age distribution p i ∈ R 1×C δ d . Different from the previous study <ref type="bibr" target="#b8">[9]</ref> using fixed label distribution as ground truth, we directly learn the distribution from training data with discretized age labels:</p><formula xml:id="formula_3">L lds = 1 N N i=1 -log (p i,ŷ i ) + α 2N N i=1 (yi -mi) 2 + β N N i=1 C δ d c=1 pi,c * (yi -mi) 2<label>(1)</label></formula><p>where</p><formula xml:id="formula_4">m i = C δ d c=1 p i,c</formula><p>* ŷc is the expected value of the learned distribution p i , The first term is the cross-entropy loss which helps the model converges in an early training stage, the last two terms encourage the learned distribution to be centered and concentrated at the true age labels.</p><p>In the refining stage, the mean value of coarse age distribution m i is used to select the age group query from Q coarse to involve the computation of fine-level feature:</p><formula xml:id="formula_5">f = GAP A Qcoarse[R mi δ d ], Fi; θa (2)</formula><p>where GAP (•) is the global averaged pooling and A (•) denote the attention function with θ a as the parameters. The key and value vectors in the atten- tion function come from F i . Finally, we concatenate the f with the mapped coarse age distribution as the final feature embedding to predict the fine-level age distribution on a small age bin of δ d = 1:</p><formula xml:id="formula_6">z = concat f , f pi ŷ1,...,C δ d ; θ f (<label>3</label></formula><formula xml:id="formula_7">)</formula><formula xml:id="formula_8">p i = softmax (mlp (z; θm)) (<label>4</label></formula><formula xml:id="formula_9">)</formula><p>where f (•) denotes an FC layer with parameters θ f , mlp (•) represents a multilayer perceptron with one hidden layer and the parameter is θ m . The training loss is the same with Eq. 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Cross-Domain Ordinal Feature Alignment</head><p>Although existing studies <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b14">14]</ref> show that formulating regression as a classification task to learn the label distribution yields better performance, the ordinal information of age relations is lost in feature space. Moreover, when the training data comes from distinct data sources, the domain variance further damages the coherence of the learned features. In Fig. <ref type="figure" target="#fig_1">2</ref> (b) and Fig. <ref type="figure" target="#fig_1">2</ref> (c), we visualize the intermediate feature learned on our fundus image dataset. As can be seen, in Fig. <ref type="figure" target="#fig_1">2</ref> (c) the original model produces scattered and inconsistent features for ordinal age labels, while in 2 (b) the features exhibit a clear gap for different data sources. To address the above issues, we propose to introduce ordinal constraints in the label distribution learning and perform feature alignment to eliminate the domain variance. The key idea of imposing ordinal constraints in embedding space is to construct a set of triplets and enforce the feature distance to be consistent with the relative age gap. Specifically, for each batch of input data {x 1 , ..., x B }, we first compute their pairwise feature distance which outputs a distance matrix D ∈ R B×B . Then, we construct feature triplets and calculate the distance gap by subtracting shifted distance matrix D from the original D. In this case, each sample will have a chance to serve as the anchor to be compared with other samples. We formulate the ordinal constraint as following margin loss:</p><formula xml:id="formula_10">L ord = B i=1 B j=1 max 0, D [i, j] -D [i, j] + m , s.t.i = j, andŷi = ŷj (5)</formula><p>where D [•] denotes metric of Euclidean distance, m is a dynamic margin depends on the relative age difference gap between |ŷ i -ŷj | and |ŷ i -ŷj |. To align features from different data domains, we directly select samples from same class and push them closer in the embedding space by minimizing the intra-class distance on both coarse-level features and fine-level features:</p><formula xml:id="formula_11">L align = C δ 10 c=1 Ic (i, j) d (fi, fj) + C δ 1 c=1 Ic (i, j) d f i , f j (6)</formula><p>where the I c (i, j) is an indicator function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Co-Learning with Temporal Fundus Images</head><p>Compared to merely learning from single snapshot images, temporal data capturing more aging information can further boost retinal age prediction. However, in practice, temporal fundus data can be limited because the individuals are often lost to follow-up. Directly learning a temporal model on these small data usually cause poor generalization. Therefore, we propose to co-train our model on limited temporal imaging data and large-scale snapshot imaging data. Our aim is to use the auxiliary knowledge from temporal data to enhance the performance of our model tested on snapshot images.</p><p>As illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>, the temporal branch consists of an image encoder, a time dimensional attention module (TDA), and a regression head. The temporal image encoder and the regression head are the same as that of the snapshot branch. We first input a fundus image sequence into the temporal branch and extract temporal features F t ∈ R T ×D from the TDA module which performs time dimensional attention to capturing the correlation of local regions across temporal images. At the same time, we input augmented sequential fundus images into the snapshot branch which outputs feature F s<ref type="foot" target="#foot_0">1</ref> . Inspired by <ref type="bibr" target="#b15">[15]</ref>, we encourage the snapshot features to preserve similar relations in temporal features by optimizing the distance correlation loss:</p><formula xml:id="formula_12">L dist = 1 -R 2 (Fs, Ft) (7)</formula><p>where R 2 (•) denotes the distance correlation and the detailed definition refers to <ref type="bibr" target="#b15">[15]</ref>. We simple sum L lds , L ord , L align and L dist as the final loss.  Training details : As the biological age is normally developed and assessed in healthy populations where biological age is considered equal to chronological age, the model here is trained on 133895 selected snapshot images of healthy subjects without any report of systemic diseases from the four datasets (shown in Fig. <ref type="figure" target="#fig_3">3</ref>). The temporal data is a subset of the snapshot data and consists of 2937 sequences with an average length of 5. We split the dataset into training, validation, and testing set with a ratio of 7:1:2. The standard data augmentation techniques such as random resized cropping, color transformation, and flipping are equally used in all experiments. Each image is resized to a fixed input size of 320 × 320. We use ReseNet-50 <ref type="bibr" target="#b2">[3]</ref> as the image encoder for all models and train them using ADAM optimizer with a batch size of 100 and a training epoch of 45 with early stopping. The initial learning rates are set to 1 × 10 -5 and 3 × 10 -4 for the backbone layers and newly added layers, respectively. We divide the learning rate by 10 every 15 epochs. Evaluation metrics : Consistent with previous studies, we consider the mean absolute error (MAE) and the Pearson correlation as measures for assessing the performance of models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiment and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Quantitative Results</head><p>Comparative Study: We then compare our model with existing popular regression methods which include both direct regression method, classification-Fig. <ref type="figure">5</ref>. Result of ablation study on the proposed method. based methods <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b11">11]</ref>, and ranking-based method <ref type="bibr" target="#b0">[1]</ref>. The Mean-var improves the classification model by adding concentration regularization, the ranking-based method explicitly introduces ordinal information by combing a set of binary classifiers, and the POE methods model uncertainty with probabilistic embeddings. Table <ref type="table" target="#tab_0">1</ref> shows the detailed comparison results. We denote our method as PLDL. It can be seen that the classification model outperforms the direct regression method on all the data cohorts. This observation is consistent with previous studies <ref type="bibr" target="#b11">[11,</ref><ref type="bibr" target="#b14">14]</ref>. The POE-CLS is the best-performed model in all baselines, however, the performance is inferior to our model. When trained only with the snapshot images, our method achieves an MAE of 3.08 and Pearson's R of 0.942.</p><p>Ablation Study: Here, we give the ablation results of our model to illustrate how different components affect the final performance. Figure <ref type="figure">5b</ref> shows how the performance changed when adding different components in the proposed method. As can be seen, with only the coarse stage prediction, the model produces an MAE of 3.23 and Pearson's R of 0.939. Performing the refined age stage improves the MAE by ∼ 0.1. Introducing ordinal feature alignment gives a margin improvement in age prediction performance, but the feature space shows a clear improvement (see Fig. <ref type="figure" target="#fig_1">2</ref>). At last, modelling the temporal fundus images improves the MAE from 3.08 to 3.03. In Fig. <ref type="figure">5a</ref>, we give the learning curve of distance correlation and the MAE results on the validation set. As we can see, the snapshot features show a high correlation with the feature from the temporal branch and the MAE also becomes lower when optimizing the L dist . In Fig. <ref type="figure">4</ref>, we give the detailed MAE distribution over different age labels on each cohort.</p><p>The results indicate that the model produces high MAE on the tail ages in each cohort. Therefore, a future step to improve our model would be to consider the imbalanced learning techniques or group-wise analysis to reduce the MAE bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Visualization Results</head><p>In Fig. <ref type="figure" target="#fig_4">6</ref>, we illustrate the estimated age distribution for some fundus image samples by our model and the baseline classification model. It can be seen that the refined age distributions are more accurate than the coarse prediction due to more precise discretization. Compared to the estimated age distributions from the baseline model, our method shows a more concentrated age distribution. In Fig. <ref type="figure">5a</ref>, we visualize the similarity matrix by computing the pair-wise cosine distance between the age group queries. It can be seen that the query vectors for age groups 40∼50, 50∼60, and 60∼70 exhibit a very high similarity which implies that these groups may share more common ageing features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this study, we present a novel accurate modeling of retinal age prediction.</p><p>Our model is capable of learning adaptive age distribution from multiple cohorts and leveraging temporal knowledge learned from sequencing images to improve age prediction on snapshot image modeling. Our model demonstrated improved performance in four independent datasets, with an overall MAE much lower than previously proposed algorithms.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Overview of the proposed method. The regression is formulated as a two-stage label distribution learning problem and the model further uses temporal knowledge to improve the snapshot learning.</figDesc><graphic coords="3,58,47,54,11,335,32,109,60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Illustration of domain-aware ordinal feature alignment. The left figure shows the constraint for the inter-age class and intra-age class; The right two figures denote the feature visualization result.</figDesc><graphic coords="4,50,46,53,99,328,96,76,72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>3. 1</head><label>1</label><figDesc>Dataset and Implementation Dataset : We include four datasets in our experiment: the UK Biobank cohort, CN-A, CN-B and CN-C. The UK Biobank is a publicly available prospective cohort with over 50,000 UK residents recruited in 2006 2 45-degree fundus images were introduced in 2009 for the study subjects. CN-A was a cross-sectional study recruiting participants in eye hospitals. Another database was from the historical data collected in general hospitals, named CN-B. CN-C is an ongoing prospective cohort study that enrolled a total of 4,939 participants in 2009-2010. Participants were invited to take part in annual follow-up assessments including fundus images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Summary of retinal datasets used in this study.</figDesc><graphic coords="6,44,79,228,59,150,64,77,32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Show cases of estimated age distributions. For each sample, the left two distributions are coarse prediction and refined prediction from our model, respectively. The rightmost figure denotes the result from the baseline classification model.</figDesc><graphic coords="8,50,13,54,38,329,20,68,32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Comparison of the proposed method with existing stuides. Error distribution and MAE result on different cohorts.</figDesc><table><row><cell>Method</cell><cell>UKB cohort</cell><cell>Chinese cohort</cell><cell>All data</cell></row><row><cell></cell><cell cols="3">MAE Pearson's R MAE Pearson's R MAE Pearson's R</cell></row><row><cell>Direct regression</cell><cell>3.64 0.820</cell><cell>3.44 0.921</cell><cell>3.47 0.918</cell></row><row><cell>Classification</cell><cell>3.51 0.831</cell><cell>3.37 0.923</cell><cell>3.39 0.921</cell></row><row><cell cols="2">Mean-Variance [11] 3.44 0.829</cell><cell>3.13 0.941</cell><cell>3.28 0.936</cell></row><row><cell>Ranking-coral [1]</cell><cell>3.41 0.831</cell><cell>3.21 0.939</cell><cell>3.24 0.935</cell></row><row><cell>POE-Reg [8]</cell><cell>3.56 0.836</cell><cell>3.14 0.941</cell><cell>3.20 0.936</cell></row><row><cell>POE-CLS</cell><cell>3.23 0.818</cell><cell>3.13 0.942</cell><cell>3.18 0.937</cell></row><row><cell>PLDL</cell><cell>3.15 0.854</cell><cell>3.07 0.945</cell><cell>3.08 0.942</cell></row><row><cell cols="2">PLDL (with temp) 3.14 0.859</cell><cell>3.01 0.946</cell><cell>3.03 0.943</cell></row><row><cell>Fig. 4.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We omit the i in feature notions for simplicity.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://biobank.ndph.ox.ac.uk/showcase/browse.cgi.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Using ranking-CNN for age estimation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5183" to="5192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Population ageing and mortality during 1990-2017: a global decomposition analysis</title>
		<author>
			<persName><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Med</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">1003138</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">DNA methylation-based biomarkers and the epigenetic clock theory of ageing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Horvath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Raj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Genet</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="371" to="384" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Retinal age gap as a predictive biomarker of future risk of Parkinson&apos;s disease</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Age and Ageing</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">62</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep learning-based brain age prediction in normal aging and dementia</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Aging</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="412" to="424" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Unimodal-concentrated loss: Fully adaptive label distribution learning for ordinal regression</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="20513" to="20522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning probabilistic ordinal embeddings for uncertainty-aware regression</title>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="13896" to="13905" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Biological age estimated from retinal imaging: a novel biomarker of aging</title>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI 2019</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">11764</biblScope>
			<biblScope unit="page" from="138" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Cham</forename><surname>Springer</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-32239-7_16</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-32239-7_16" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Heterogeneity in healthy aging</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Lowsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Olshansky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Goldman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Gerontol. Series A: Biomed. Sci. Med. Sci</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="640" to="649" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Mean-variance loss for deep age estimation from a face</title>
		<author>
			<persName><forename type="first">H</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="5285" to="5294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deviation of physiological from chronological age is associated with health</title>
		<author>
			<persName><forename type="first">L</forename><surname>Peretz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Rappoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Challenges of Trustable AI and Added-Value on Health</title>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="224" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Going deeper with image transformers</title>
		<author>
			<persName><forename type="first">H</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="32" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.08915</idno>
		<title level="m">Improving deep regression with ordinal entropy</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">On the versatile uses of partial distance correlation in deep learning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Singh</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-19809-0_19</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-19809-0_19" />
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2022: 17th European Conference</title>
		<meeting><address><addrLine>Tel Aviv, Israel</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">October 23-27, 2022. 2022</date>
			<biblScope unit="page" from="327" to="346" />
		</imprint>
	</monogr>
	<note>Proceedings, Part XXVI</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Association of retinal age gap with arterial stiffness and incident cardiovascular disease</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stroke</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3320" to="3328" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Retinal age gap as a predictive biomarker for mortality risk</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British J. Ophthalmol</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="547" to="554" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
