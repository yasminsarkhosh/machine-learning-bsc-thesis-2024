<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Twelve-Lead ECG Reconstruction from Single-Lead Signals Using Generative Adversarial Networks</title>
				<funder>
					<orgName type="full">NRF</orgName>
				</funder>
				<funder>
					<orgName type="full">Artificial Intelligence Convergence Innovation Human Resources Development (Ewha Womans University)</orgName>
				</funder>
				<funder ref="#_F5NvbSR #_YTSH8tP #_2ZsJkA2">
					<orgName type="full">Korea government (MSIT)</orgName>
				</funder>
				<funder>
					<orgName type="full">&quot;Regional Innovation Strategy</orgName>
					<orgName type="abbreviated">RIS</orgName>
				</funder>
				<funder ref="#_qr4bE8d">
					<orgName type="full">Ministry of Education (MOE)</orgName>
				</funder>
				<funder>
					<orgName type="full">National Research Foundation of Korea</orgName>
					<orgName type="abbreviated">NRF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jinho</forename><surname>Joo</surname></persName>
							<idno type="ORCID">0009-0009-6592-3934</idno>
							<affiliation key="aff0">
								<orgName type="institution">Kangwon National University</orgName>
								<address>
									<postCode>24341</postCode>
									<settlement>Chuncheon</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gihun</forename><surname>Joo</surname></persName>
							<idno type="ORCID">0000-0003-4376-5356</idno>
						</author>
						<author>
							<persName><forename type="first">Yeji</forename><surname>Kim</surname></persName>
							<idno type="ORCID">0009-0005-4185-9342</idno>
							<affiliation key="aff0">
								<orgName type="institution">Kangwon National University</orgName>
								<address>
									<postCode>24341</postCode>
									<settlement>Chuncheon</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Ewha Womans University Medical Center</orgName>
								<address>
									<postCode>07985</postCode>
									<settlement>Seoul</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Moo-Nyun</forename><surname>Jin</surname></persName>
							<idno type="ORCID">0000-0001-5482-4441</idno>
							<affiliation key="aff1">
								<orgName type="institution">Ewha Womans University Medical Center</orgName>
								<address>
									<postCode>07985</postCode>
									<settlement>Seoul</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Junbeom</forename><surname>Park</surname></persName>
							<email>parkjb@ewha.ac.kr</email>
							<idno type="ORCID">0000-0003-2192-9401</idno>
							<affiliation key="aff1">
								<orgName type="institution">Ewha Womans University Medical Center</orgName>
								<address>
									<postCode>07985</postCode>
									<settlement>Seoul</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hyeonseung</forename><surname>Im</surname></persName>
							<email>hsim@kangwon.ac.kr</email>
							<idno type="ORCID">0000-0002-3901-0834</idno>
							<affiliation key="aff0">
								<orgName type="institution">Kangwon National University</orgName>
								<address>
									<postCode>24341</postCode>
									<settlement>Chuncheon</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Twelve-Lead ECG Reconstruction from Single-Lead Signals Using Generative Adversarial Networks</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="184" to="194"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">A612F1A6409472B10BD8D08D21BA5490</idno>
					<idno type="DOI">10.1007/978-3-031-43990-2_18</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-01T10:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>ECG reconstruction</term>
					<term>Biosignal synthesis</term>
					<term>Generative model</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent advances in wearable healthcare devices such as smartwatches allow us to monitor and manage our health condition more actively, for example, by measuring our electrocardiogram (ECG) and predicting cardiovascular diseases (CVDs) such as atrial fibrillation in real-time. Nevertheless, most smart devices can only measure single-lead signals, such as Lead I, while multichannel ECGs, such as twelve-lead signals, are necessary to identify more intricate CVDs such as left and right bundle branch blocks. In this paper, to address this problem, we propose a novel generative adversarial network (GAN) that can faithfully reconstruct 12-lead ECG signals from single-lead signals, which consists of two generators and one 1D U-Net discriminator. Experimental results show that it outperforms other representative generative models. Moreover, we also validate our method's ability to effectively reconstruct CVD-related characteristics by evaluating reconstructed ECGs with a highly accurate 12-lead ECG-based prediction model and three cardiologists.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Although these days smart healthcare devices such as smartwatches can be used to monitor a single-lead electrocardiogram (ECG) for Lead I and detect cardiovascular diseases (CVDs) such as atrial fibrillation (AF), multichannel ECGs such as twelve-lead signals are still required to diagnose more complex CVDs such as left and right bundle branch blocks (LBBBs and RBBBs) or myocardial infarction. To proactively deal with such intricate CVDs, therefore, one may need to undergo a 12-lead ECG measurement at a hospital and utilize 12-lead ECG-based deep learning algorithms for predicting CVDs <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b17">18]</ref>, which can be a cumbersome process in everyday life. It is neither plausible to train a prediction model using only single-lead ECGs measured by smart devices as it is not possible to correctly label complex CVDs for them in the first place. To address this problem, in this paper, we propose a novel generative adversarial network (GAN) <ref type="bibr" target="#b12">[13]</ref>, called EKGAN, that can faithfully reconstruct 12-lead ECGs only from single-lead ones.</p><p>Although the ECG synthesis problem is not new, most previous studies have focused on utilizing it for data augmentation purpose as it is difficult to collect a sufficient amount of labeled ECGs (with CVDs) for developing prediction models. For example, many researchers have focused on synthesizing realistic ECGs using variants of autoencoders and GANs <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23]</ref>. These methods can be useful for training prediction models, but it is unclear how they can be leveraged with commonly available wearable devices that can measure only single-lead ECGs. Meanwhile, another line of work has focused on reconstructing the corresponding (missing) ECGs from only a few actual lead signals <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b20">21]</ref>, usually generating 12 leads from three leads including Lead I and II. We note here that if we know Lead I and II, then all six limb leads can be derived by Willem Einthoven's law <ref type="bibr" target="#b7">[8]</ref> and Goldberger's law <ref type="bibr" target="#b11">[12]</ref>. Thus, their reconstruction problem indeed reduces to the problem of reconstructing six precordial leads.</p><p>Our work differs significantly from previous studies, as we generate all 11 remaining leads simultaneously from only a single lead. Thus, our method can be used to bridge commonly available wearable devices that can measure only Lead I and high-performance deep learning-based prediction models using 12lead ECGs. To the best of our knowledge, our work is the first to reconstruct all 12 leads simultaneously from a real single lead. By using the approach in <ref type="bibr" target="#b5">[6]</ref>, one can also generate all 12 leads, but only incrementally. Our proposed method EKGAN employs two generators and one 1D U-Net <ref type="bibr" target="#b18">[19]</ref> discriminator to capture CVD-specific characteristics and correlation patterns between Lead I and the remaining leads from ECG training data. Experimental results show that the reconstruction performance of EKGAN outperforms other representative generative models such as Pix2Pix <ref type="bibr" target="#b15">[16]</ref>, CycleGAN <ref type="bibr" target="#b23">[24]</ref> and CardioGAN <ref type="bibr" target="#b19">[20]</ref> under various metrics. We also evaluated the practical applicability of our method by applying an existing 12-lead ECG-based CVD prediction model <ref type="bibr" target="#b17">[18]</ref> to the reconstructed ECGs. To this end, we consider AF, LBBB, and RBBB, among which LBBB and RBBB require multichannel ECGs to detect. Moreover, three cardiologists examined reconstructed ECGs to see if they accurately reflected the important CVD-related characteristics of the original ECGs. All the results confirm the effectiveness and usefulness of our method, thus enabling preventive healthcare with smart wearable devices for CVDs. For reproducibility, the source code of EKGAN is available at https://github.com/knu-plml/ecg-recon.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>In this section, we introduce a novel conditional GAN for ECG reconstruction, called EKGAN, which is based on Pix2Pix <ref type="bibr" target="#b15">[16]</ref> but employs an additional label generator G L and uses a 1D U-Net discriminator instead of a PatchGAN discriminator. Its overall structure is shown in Fig. <ref type="figure" target="#fig_0">1</ref>. The inference generator G I takes a Lead I signal and generates corresponding 12-lead signals, while the label generator G L takes the same input as G I and simply returns the same signal. The whole purpose of G L is to enable G I 's encoder to learn the important characteristics of Lead I. To this end, the latent vector produced by G I 's encoder is approximated to that of G L 's encoder so that G I 's decoder can produce more detailed ECGs that are closely correlated with the input Lead I signals. The discriminator D distinguishes 12-lead ECGs generated by G I and the original ECGs. The whole process is repeated, adversarially learning G I and D. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Generator</head><p>Inference Generator. The inference generator G I is based on Pix2Pix's 2D U-Net generator and consists of an encoder and a decoder (Fig. <ref type="figure" target="#fig_0">1</ref>). It takes an input of size (16, 512, 1): 16 for 12 replicated signals of the input single lead plus 4 zero padding, 512 for the length of the ECG signal, and 1 for the channel size. More specifically, to generate 12-lead signals from single-lead signals, an input single-lead signal of length 512 is copied 12 times and two rows of zeros are added to both the top and bottom. Each original 12-lead ECG is arranged in the order of Lead I, II, III, aVR, aVL, aVF, and V1-V6, and is also zero padded. The encoder consists of five blocks each of which consists of convolution, batch normalization, and Leaky ReLU layers (an exception is the first block which excludes batch normalization). The numbers of convolution filters are 64, 128, 256, 512, 1024, while the kernel size is set to <ref type="bibr" target="#b1">(2,</ref><ref type="bibr" target="#b3">4)</ref>. The stride size is (2, 2) except for the last block whose stride size is <ref type="bibr" target="#b0">(1,</ref><ref type="bibr" target="#b1">2)</ref>. The decoder is the inverse of the encoder and takes the encoder output as input. It also consists of five blocks each of which consists of concatenation, deconvolution, batch normalization, and ReLU layers (exceptions are the first block, which excludes concatenation, and the last block, which only uses concatenation and deconvolution). The numbers of deconvolution filters are 512, 256, 128, 64, 1, while the kernel size is set to <ref type="bibr" target="#b1">(2,</ref><ref type="bibr" target="#b3">4)</ref>. The stride size is (2, 2) except for the first block whose stride size is <ref type="bibr" target="#b0">(1,</ref><ref type="bibr" target="#b1">2)</ref>. From the second block, the output of the previous decoder block and that of the corresponding encoder block are concatenated and used as input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Label</head><p>Generator. An autoencoder-based model like U-Net <ref type="bibr" target="#b18">[19]</ref> should create a latent vector in the encoder that represents the features of input data well. Then, the decoder should be learned to generate a target-like output from the latent vector. When training a U-Net, however, as we only use the reconstruction loss between the original and generated data, we cannot accurately determine how well the latent vector captures the essential features of the input (because there is no ground truth for the latent vector). In this paper, as a workaround, we use a label generator G L which takes Lead I signals and returns the same signals. Accordingly, the latent vector produced by G L 's encoder would represent the features of the input accurately and thus can be used as ground truth for G I 's encoder. By doing so, G I 's decoder can produce a 12-lead ECG that is not only realistic but also closely associated with the input Lead I signal. The structure of G L is similar to that of G I , but it does not incorporate concatenation between the encoder and decoder. We experimentally validate the effectiveness of the label generator in Sect. 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Discriminator</head><p>In 12-lead ECGs, each lead has its own characteristics and thus it is important for a discriminator to analyze each lead signal individually at the pixel level. If a standard 2D convolution-based discriminator is used, as for image-to-image translation, which uses 2D patches, then the unique characteristics of each lead signal may be intermixed with others, which may in turn degrade the reconstruction quality. To prevent this problem, instead, we use a 1D U-Net discriminator D, which has the same layer architecture as G L . D takes as input either G I 's output or an original 12-lead ECG, which is concatenated with G I 's input. In the encoder, the numbers of convolution filters are 32, 64, 128, 256, 512, kernel sizes are 64, 32, 16, 8, 4, and stride sizes are 4, 4, 4, 2, 2. The decoder has the inverse structure of the encoder as in the two generators, except that it uses a sigmoid activation function at the last layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Loss</head><p>The objective of EKGAN is similar to that of other conditional GANs except that it uses the label generator G L to train the inference generator G I . Let us write e i for 12 replicated ECG segments from the input single-lead ECG for G I and e o for the corresponding ground-truth 12-lead ECG segments. In addition, let z i and z l be the latent vectors produced by the encoders of G I and G L , respectively. We use the following adversarial loss and L1 losses:</p><formula xml:id="formula_0">L adv (G I , D) = E ei,eo [log D(e i , e o )] + E ei [log(1 -D(e i , G I (e i )))] L L1 (G I ) = E ei,eo [||e o -G I (e i )|| 1 ] L L1 (G L ) = E ei [||e i -G L (e i )|| 1 ] L LV (G I , G L ) = E zi,z l [||z i -z l || 1 ]</formula><p>where the last one is the latent vector loss for the inference generator.</p><p>Then, the objective of EKGAN is defined as:</p><formula xml:id="formula_1">G * I = arg min GI ,GL max D {L adv (G I , D) + λL L1 (G I ) + αL LV (G I , G L )}</formula><p>where λ and α control the relative importance of each function. Note that L L1 (G L ) is used solely for training G L and thus not included in the objective equation. Through a grid search, we determined λ = 50 and α = 1, and these values have been used in the following experiments unless otherwise stated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head><p>This section introduces our dataset and its preprocessing. Then, we extensively evaluate EKGAN in terms of its reconstruction performance. We also assess its applicability using an existing prediction model with proven performance <ref type="bibr" target="#b17">[18]</ref> and with three cardiologists.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Setup</head><p>Datasets. To develop and evaluate EKGAN, we used about 326,000 ECGs collected from Ewha Womans University Mokdong and Seoul Hospitals between May 23, 2017, and November 30, 2022. Specifically, we first selected ECGs with LBBB, RBBB, and AF from the dataset and randomly selected normal sinus rhythm (NSR) ECGs in a 1:1 ratio to reduce the bias of the generative models.</p><p>For the label information, we simply used the interpretation result of the ECG machine. Next, for a test set for CVD multi-label classification and cardiologists' examination, we randomly chose 100 ECGs for each disease and 300 NSR ECGs. Then, the remaining dataset was randomly divided into train and validation sets in an 8:2 ratio. Table <ref type="table" target="#tab_0">1</ref> shows the configuration of the final dataset. We note here that since AF and NSR may coexist with LBBB and RBBB, the number of classes is different from the total number of data. The generative models were trained using the train set and evaluated using the validation set. The CVD prediction model was trained using the train and validation sets where the latter was used for hyperparameter tuning. Finally, 12-lead ECGs were generated by using both the validation and test sets, and their quality was evaluated by using the predictive model, i.e., by comparing the classification performance with the original 12-lead ECGs and the generated ones, and examined by three cardiologists. amplitudes may be ignored when predicting CVD. More specifically, for each signal, we first apply min-max normalization to [-1, 1] and then a band-pass filter with lower and upper cutoff frequencies [0.05, 150] as some fine details and important characteristics disappear when using a high lower cutoff frequency or a low upper cutoff frequency <ref type="bibr" target="#b0">[1]</ref>. Finally, we downsample 4,096 lengths to 512 lengths.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training and Test.</head><p>All experiments were conducted on a workstation with an NVIDIA RTX 8000 and using TensorFlow 2.8. For comparisons, we implemented not only EKGAN but also Pix2Pix <ref type="bibr" target="#b15">[16]</ref>, CycleGAN <ref type="bibr" target="#b23">[24]</ref>, and CardioGAN <ref type="bibr" target="#b19">[20]</ref> with minor modifications so that they can be applied to ECG data. In particular, for unpaired training of CycleGAN and CardioGAN, the input and label data were separated and shuffled independently. Moreover, due to the cycle consistency loss, Lead I of the label data was replaced with zero padding. All models were trained for 10 epochs, with the learning rate of 1e-4 until 5 epochs after which weight decay of 0.95 was applied per epoch. The kernel-initializer was sampled from a normal distribution N (0, 0.02 2 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Reconstruction Performance</head><p>Table <ref type="table" target="#tab_1">2</ref> shows the reconstruction performance of EKGAN and other methods for the validation data in terms of root mean square error (RMSE), mean absolute error (MAE), percentage root mean square difference (PRD), maximum mean discrepancy (MMD), and mean absolute error for heart rates (MAE HR ). For all metrics, EKGAN significantly outperforms other methods, confirming the effectiveness of its label generator and 1D U-Net discriminator for pixel-level learning of ECG signals. Meanwhile, CycleGAN and CardioGAN, which are based on unpaired training, are not suitable for 12-lead ECG reconstruction.</p><p>Figure <ref type="figure" target="#fig_1">2</ref> shows examples of reconstructed 12-lead ECGs by various methods from the Lead I, where EKGAN produces the most faithful reconstruction of the original ECG.  Table <ref type="table" target="#tab_2">3</ref> shows the performance of different variants of EKGAN, that is, showing the effectiveness of our 1D discriminator and label generator. 'EKGAN w/o 1D discriminator' uses Pix2Pix's PatchGAN discriminator instead of our 1D U-Net discriminator. 'EKGAN w/o label generator' excludes a label generator and uses only an inference generator. We observe that the use of 1D discriminator is more effective than the use of a label generator, but using both results in a greater improvement over Pix2Pix for reconstructing 12-lead ECG signals. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Reconstruction Quality Evaluation</head><p>To evaluate the applicability and quality of ECG signals reconstructed by EKGAN, we use a highly accurate prediction model for CVDs <ref type="bibr" target="#b17">[18]</ref>. The model can predict six diseases by analyzing a 12-lead ECG, among which we choose LBBB, RBBB, and AF. We choose LBBB and RBBB as they require analysis of multi-lead ECGs and AF as it can be already predicted using commonly available wearable devices. This allows us to indirectly check if EKGAN is able to generate diverse ECG signals capturing different characteristics for each disease. Table <ref type="table" target="#tab_3">4</ref> shows the multi-label classification results for the test set. Since the dataset used in <ref type="bibr" target="#b17">[18]</ref> differs from ours, the performances using their datasets and ours are also slightly different, but both seem to perform well. We observe that the F1-scores when using the dataset reconstructed by EKGAN are comparable to those when using the original dataset and consistently better than those when using the ones reconstructed by Pix2Pix.</p><p>Table <ref type="table" target="#tab_4">5</ref> shows the concordance rate between the test ECGs and the corresponding reconstructed ones by EKGAN, evaluated by three cardiologists. We randomly shuffled the original and reconstructed ECGs, and each cardiologist reviewed every ECG if it exhibited LBBB, RBBB, AF, or NSR. Then, for each case, the concordance rate is calculated as the ratio of pairs of original and corresponding reconstructed ECGs such that a cardiologist's read result coincides among all data pairs. We note here that since each ECG must exclusively include either AF or NSR, their concordance rates are the same. The results confirm that the reconstructed ECGs by EKGAN effectively capture the important characteristics of the original ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>This paper studies a novel problem of reconstructing 12-lead ECGs from singlelead ECGs. To address this problem, we propose a novel conditional GAN, called EKGAN, based on Pix2Pix, which consists of two generators and one 1D U-Net discriminator. Experimental results show that EKGAN significantly outperforms other representative generative models such as Pix2Pix, CycleGAN, and Car-dioGAN, and is able to reconstruct 12-lead ECGs that faithfully capture the essential characteristics of the original 12-lead ECGs useful for predicting CVDs. Therefore, we expect that numerous deep learning models based on 12-lead ECGs with proven performance could be applied to smart healthcare devices that can measure only single-lead signals. It would be also interesting to investigate if our method is applicable to more complex CVDs such as acute myocardial infarction, which require a more detailed analysis of 12-lead ECGs by cardiologists.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Overall structure of EKGAN. GI , inference generator; GL, label generator; D, discriminator.</figDesc><graphic coords="3,67,29,243,74,289,12,145,96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Qualitative comparisons of various methods. The first column shows a sample original 12-lead ECG with RBBB and AF, while the rest was reconstructed from the original Lead I signal.</figDesc><graphic coords="7,42,30,148,70,339,40,193,36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Summary of the dataset. LBBB, Left Bundle Branch Block; RBBB, Right Bundle Branch Block; AF, Atrial Fibrillation; NSR, Normal Sinus Rhythm. The 12-lead ECG data used in this study were measured for 10 s and the sampling rate is 500 Hz. To reduce the measurement noise, for each ECG signal, we remove the first 1 s and use only approximately the next 8.2 s (length of 4,096), while excluding the remaining part. In addition, for each 12lead ECG, we normalize each lead signal individually, because if the amplitudes of 12-lead signals are significantly different from each other, the ones with small</figDesc><table><row><cell></cell><cell cols="3">LBBB RBBB AF</cell><cell cols="3">NSR Total Classes Total Data</cell></row><row><cell>Train</cell><cell cols="5">1,635 9,537 20,287 29,746 61,205</cell><cell>59,492</cell></row><row><cell cols="2">Validation 421</cell><cell cols="4">2,409 5,075 7,437 15,342</cell><cell>14,874</cell></row><row><cell>Test</cell><cell>102</cell><cell>108</cell><cell>140</cell><cell>460</cell><cell>810</cell><cell>600</cell></row><row><cell cols="2">Data Preparation.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Reconstruction performance of each method for the validation data.</figDesc><table><row><cell>Method</cell><cell cols="2">RMSE MAE PRD MMD</cell><cell>MAEHR</cell></row><row><cell>Pix2Pix</cell><cell>0.38</cell><cell cols="2">0.30 8.43 0.07 × 10 -3 27.68</cell></row><row><cell>CycleGAN</cell><cell>0.62</cell><cell cols="2">0.49 13.18 0.46 × 10 -3 24.16</cell></row><row><cell>CardioGAN</cell><cell>0.52</cell><cell cols="2">0.43 11.32 0.21 × 10 -3 24.09</cell></row><row><cell>EKGAN (</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>proposed) 0.32 0.25 6.95 0.04 × 10 -3 20.51Table 3 .</head><label>3</label><figDesc>Performance of different variants of EKGAN for the validation data.</figDesc><table><row><cell>Method</cell><cell cols="2">RMSE MAE PRD MMD</cell><cell>MAEHR</cell></row><row><cell>Pix2Pix</cell><cell>0.38</cell><cell cols="2">0.30 8.43 0.07 × 10 -3 27.68</cell></row><row><cell cols="2">EKGAN w/o 1D discriminator 0.37</cell><cell cols="2">0.29 8.13 0.06 × 10 -3 24.06</cell></row><row><cell>EKGAN w/o label generator</cell><cell>0.35</cell><cell cols="2">0.28 7.73 0.05 × 10 -3 25.83</cell></row><row><cell>EKGAN (proposed)</cell><cell>0.32</cell><cell cols="2">0.25 6.95 0.04 × 10 -3 20.51</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>CVD multi-label classification results for the test data (F1-score). All results were obtained by using the algorithm proposed in<ref type="bibr" target="#b17">[18]</ref>.</figDesc><table><row><cell>Dataset</cell><cell cols="3">LBBB RBBB AF</cell></row><row><cell>Results reported in [18]</cell><cell>1.00</cell><cell>0.94</cell><cell>0.87</cell></row><row><cell>Original ECGs</cell><cell>0.92</cell><cell>0.97</cell><cell>0.92</cell></row><row><cell cols="2">Reconstructed ECGs by Pix2Pix 0.81</cell><cell>0.92</cell><cell>0.82</cell></row><row><cell cols="2">Reconstructed ECGs by EKGAN 0.94</cell><cell>0.96</cell><cell>0.88</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Concordance rate of three cardiologists for the test and reconstructed ECGs.</figDesc><table><row><cell></cell><cell>LBBB RBBB AF</cell><cell>NSR</cell></row><row><cell cols="3">Cardiologist 1 96.32 92.31 93.65 93.65</cell></row><row><cell cols="3">Cardiologist 2 91.53 91.69 92.54 92.54</cell></row><row><cell cols="3">Cardiologist 3 94.77 92.24 91.06 91.06</cell></row><row><cell>Average</cell><cell cols="2">94.21 92.08 92.42 92.42</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. This research was supported by <rs type="funder">"Regional Innovation Strategy (RIS)</rs>" through the <rs type="funder">National Research Foundation of Korea (NRF)</rs> funded by the <rs type="funder">Ministry of Education (MOE)</rs> (<rs type="grantNumber">2022RIS-005</rs>). This work was also supported by the <rs type="funder">NRF</rs> grant funded by the <rs type="funder">Korea government (MSIT)</rs> (No. <rs type="grantNumber">RS-2023-00208094</rs> and <rs type="grantNumber">RS-2023-00242528</rs>) and by <rs type="institution">Institute of Information &amp; communications Technology Planning &amp; Evaluation (IITP)</rs> grant funded by the <rs type="funder">Korea government (MSIT)</rs> (No. <rs type="grantNumber">RS-2022-00155966</rs>, <rs type="funder">Artificial Intelligence Convergence Innovation Human Resources Development (Ewha Womans University)</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_qr4bE8d">
					<idno type="grant-number">2022RIS-005</idno>
				</org>
				<org type="funding" xml:id="_F5NvbSR">
					<idno type="grant-number">RS-2023-00208094</idno>
				</org>
				<org type="funding" xml:id="_YTSH8tP">
					<idno type="grant-number">RS-2023-00242528</idno>
				</org>
				<org type="funding" xml:id="_2ZsJkA2">
					<idno type="grant-number">RS-2022-00155966</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43990-2 18.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Algorithm Physician&apos;s Guide. 2nd Edn</title>
		<author>
			<persName><forename type="first">Dxl</forename><surname>Philips</surname></persName>
		</author>
		<author>
			<persName><surname>Ecg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page">453564106411</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A novel neural-network model for deriving standard 12-lead ECGs from serial three-lead ECGs: application to self-care</title>
		<author>
			<persName><forename type="first">H</forename><surname>Atoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fayn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rubel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Technol. Biomed</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="883" to="890" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An artificial intelligence-enabled ECG algorithm for the identification of patients with atrial fibrillation during sinus rhythm: a retrospective analysis of outcome prediction</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">I</forename><surname>Attia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Lancet</title>
		<imprint>
			<biblScope unit="volume">394</biblScope>
			<biblScope unit="page" from="861" to="867" />
			<date type="published" when="2019">10201. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Use of artificial intelligence and deep neural networks in evaluation of patients with electrocardiographically concealed long QT syndrome from the surface 12-lead electrocardiogram</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">I</forename><surname>Attia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Noseworthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Ackerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMA Cardiol</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="532" to="538" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">ME-GAN: learning panoptic electrocardio representations for multi-view ECG synthesis conditioned on heart diseases</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th International Conference on Machine Learning. Proceedings of Machine Learning Research</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Chaudhuri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Szepesvari</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Niu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Sabato</surname></persName>
		</editor>
		<meeting>the 39th International Conference on Machine Learning. Machine Learning Research</meeting>
		<imprint>
			<date type="published" when="2022-07">July 2022</date>
			<biblScope unit="volume">162</biblScope>
			<biblScope unit="page" from="17" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Electrocardio panorama: synthesizing new ECG views with self-supervision</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21</title>
		<editor>
			<persName><forename type="first">Z</forename><forename type="middle">H</forename><surname>Zhou</surname></persName>
		</editor>
		<meeting>the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21</meeting>
		<imprint>
			<date type="published" when="2021">8 2021</date>
			<biblScope unit="page" from="3597" to="3605" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Artificial intelligence algorithm for detecting myocardial infarction using six-lead electrocardiography</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">20495</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">The different forms of the human electrocardiogram and their signification. The Lancet</title>
		<author>
			<persName><forename type="first">W</forename><surname>Einthoven</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1912">1912</date>
			<biblScope unit="volume">179</biblScope>
			<biblScope unit="page" from="853" to="861" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Improving ECG classification using generative adversarial networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Golany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lavee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tejman Yarden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Radinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI Conf</title>
		<meeting>AAAI Conf</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="13280" to="13285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">PGANs: personalized generative adversarial networks for ECG synthesis to improve patient-specific deep ECG classification</title>
		<author>
			<persName><forename type="first">T</forename><surname>Golany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Radinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI Conf</title>
		<meeting>AAAI Conf</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="557" to="564" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">SimGANs: simulator-based generative adversarial networks for ECG synthesis to improve deep ECG classification</title>
		<author>
			<persName><forename type="first">T</forename><surname>Golany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Radinsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Freedman</surname></persName>
		</author>
		<idno>PMLR</idno>
		<ptr target="https://proceedings.mlr.press/v119/golany20a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning. Proceedings of Machine Learning Research</title>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Iii</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Singh</surname></persName>
		</editor>
		<meeting>the 37th International Conference on Machine Learning. Machine Learning Research</meeting>
		<imprint>
			<date type="published" when="2020-07">July 2020</date>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="13" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Chapter 4 -ECG Leads</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">D</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shvilkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Goldberger&apos;s Clinical Electrocardiography</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Goldberger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><forename type="middle">D</forename><surname>Goldberger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Shvilkin</surname></persName>
		</editor>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="21" to="31" />
		</imprint>
	</monogr>
	<note>Ninth Edition</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Lawrence</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Weinberger</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">ECG-Adv-GAN: detecting ECG adversarial examples with conditional generative adversarial networks</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">F</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Kamran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tavakkoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rajasegarar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Karmaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 20th IEEE International Conference on Machine Learning and Applications (ICMLA)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="50" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Performance of a convolutional neural network and explainability technique for 12-lead electrocardiogram interpretation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Hughes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMA Cardiol</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1285" to="1295" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Image-to-image translation with conditional adversarial networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2017.632</idno>
		<ptr target="https://doi.org/10.1109/CVPR.2017.632" />
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5967" to="5976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Reconstruction of precordial lead electrocardiogram from limb leads using the state-space model</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Biomed. Health Inform</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="818" to="828" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Automatic diagnosis of the 12-lead ECG using a deep neural network</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Ribeiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">1760</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">U-Net: convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-24574-4_28</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-24574-428" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2015</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hornegger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">9351</biblScope>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Cardiogan: Attentive generative adversarial network with dual discriminators for synthesis of ECG from PPG</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Etemad</surname></persName>
		</author>
		<ptr target="https://ojs.aaai.org/index.php/AAAI/article/view/16126" />
	</analytic>
	<monogr>
		<title level="m">Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event, February</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2021">2-9, 2021. 2021</date>
			<biblScope unit="page" from="488" to="496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A novel method based on convolutional neural networks for deriving standard 12-lead ECG from serial 3-lead ECG</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Movahedipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Inf. Technol. Electron. Eng</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="405" to="413" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Synthesis of standard 12-lead electrocardiograms using two-dimensional generative adversarial networks</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Babaeizadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Electrocardiol</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="6" to="14" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Electrocardiogram generation with a bidirectional LSTM-CNN generative adversarial network</title>
		<author>
			<persName><forename type="first">F</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Unpaired image-to-image translation using cycle-consistent adversarial networks</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICCV.2017.244</idno>
		<ptr target="https://doi.org/10.1109/ICCV.2017.244" />
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2242" to="2251" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
