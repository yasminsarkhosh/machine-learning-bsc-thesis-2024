<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Black-box Domain Adaptative Cell Segmentation via Multi-source Distillation</title>
				<funder ref="#_TMnHJ66">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_kJrC4rG">
					<orgName type="full">Natural Science Basic Research Program of Shaanxi, China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xingguang</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Software Engineering</orgName>
								<orgName type="institution">Xian Jiaotong University</orgName>
								<address>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Zhongyu</forename><surname>Li</surname></persName>
							<email>zhongyuli@xjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Software Engineering</orgName>
								<orgName type="institution">Xian Jiaotong University</orgName>
								<address>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiangde</forename><surname>Luo</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Mechanical and Electrical Engineering</orgName>
								<orgName type="institution">University of Electronic Science and Technology of China</orgName>
								<address>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jing</forename><surname>Wan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Software Engineering</orgName>
								<orgName type="institution">Xian Jiaotong University</orgName>
								<address>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jianwei</forename><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Software Engineering</orgName>
								<orgName type="institution">Xian Jiaotong University</orgName>
								<address>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ziqi</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Software Engineering</orgName>
								<orgName type="institution">Xian Jiaotong University</orgName>
								<address>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Meng</forename><surname>Yang</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Hunan Frontline Medical Technology Co., Ltd</orgName>
								<address>
									<settlement>Changsha</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Cunbao</forename><surname>Xu</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Pathology</orgName>
								<orgName type="institution" key="instit1">Quanzhou First Hospital</orgName>
								<orgName type="institution" key="instit2">Fujian Medical University</orgName>
								<address>
									<settlement>Quanzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Black-box Domain Adaptative Cell Segmentation via Multi-source Distillation</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="749" to="758"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">B1527355826A35DD8755C9A24B70486B</idno>
					<idno type="DOI">10.1007/978-3-031-43907-0_71</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-01T10:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Multi-source domain adaptation</term>
					<term>Black-box model</term>
					<term>Cell segmentation</term>
					<term>Knowledge distillation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Cell segmentation plays a critical role in diagnosing various cancers. Although deep learning techniques have been widely investigated, the enormous types and diverse appearances of histopathological cells still pose significant challenges for clinical applications. Moreover, data protection policies in different clinical centers and hospitals limit the training of data-dependent deep models. In this paper, we present a novel framework for cross-tissue domain adaptative cell segmentation without access both source domain data and model parameters, namely Multi-source Black-box Domain Adaptation (MBDA). Given the target domain data, our framework can achieve the cell segmentation based on knowledge distillation, by only using the outputs of models trained on multiple source domain data. Considering the domain shift cross different pathological tissues, predictions from the source models may not be reliable, where the noise labels can limit the training of the target model. To address this issue, we propose two practical approaches for weighting knowledge from the multi-source model predictions and filtering out noisy predictions. First, we assign pixel-level weights to the outputs of source models to reduce uncertainty during knowledge distillation. Second, we design a pseudo-label cutout and selection strategy for these predictions to facilitate the knowledge distillation from local cells to global pathological images. Experimental results on four types of pathological tissues demonstrate that our proposed black-box domain adaptation approach can achieve comparable and even better performance in comparison with state-of-the-art white-box approaches. The code and dataset are released at: https://github.com/NeuronXJTU/MBDA-CellSeg.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Semantic segmentation plays a vital role in pathological image analysis. It can help people conduct cell counting, cell morphology analysis, and tissue analysis, which reduces human labor <ref type="bibr" target="#b18">[19]</ref>. However, data acquisition for medical images poses unique challenges due to privacy concerns and the high cost of manual annotation. Moreover, pathological images from different tissues or cancer types often show significant domain shifts, which hamper the generalization of models trained on one dataset to others. Due to the abovementioned challenges, some researchers have proposed various white-box domain adaptation methods to address these issues.</p><p>Recently, <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b15">16]</ref> propose to use generative adversarial networks to align the distributions of source and target domains and generate source-domain lookalike outputs for target images. Source-free domain adaptation methods have been also widely investigated due to the privacy protection. <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b13">14]</ref> explore how to implicitly align target domain data with the model trained on the source domain without accessing the source domain data. There are also many studies on multi-source white-box domain adaptation. Ahmed et al. <ref type="bibr" target="#b0">[1]</ref> propose a novel algorithm which automatically identifies the optimal blend of source models to generate the target model by optimizing a specifically designed unsupervised loss. Li et al. <ref type="bibr" target="#b12">[13]</ref> extend the above work to semantic segmentation and proposed a method named model-invariant feature learning, which takes full advantage of the diverse characteristics of the source-domain models.</p><p>Nonetheless, several recent investigations have demonstrated that the domain adaptation methods for source-free white-box models still present a privacy risk due to the potential leakage of model parameters <ref type="bibr" target="#b3">[4]</ref>. Such privacy breaches may detrimental to the privacy protection policies of hospitals. Moreover, the target domain uses the same neural network as the source domain, which is not desirable for low-resource target users like hospitals <ref type="bibr" target="#b14">[15]</ref>. We thus present a more challenging task of relying solely on black-box models from vendors to avoid parameter leakage. In clinical applications, various vendors can offer output interfaces for different pathological images. While black-box models are proficient in specific domains, their performances greatly degrade when the target domain is updated with new pathology slices. Therefore, how to leverage the existing knowledge of black-box models to effectively train new models for the target domain without accessing the source domain data remains a critical challenge.</p><p>In this paper, we present a novel source-free domain adaptation framework for cross-tissue cell segmentation without accessing both source domain data and model parameters, which can seamlessly integrate heterogeneous models from different source domains into any cell segmentation network with high generality. To the best of our knowledge, this is the first study on the exploration of multi-source black-box domain adaptation for cross-tissue cell segmentation. In this setting, conventional multi-source ensemble methods are not applicable due to the unavailability of model parameters, and simply aggregating the black-box outputs would introduce a considerable amount of noise, which can be detrimental to the training of the target domain model. Therefore, we develop two strategies within this new framework to address this issue. Firstly, we propose a pixel-level multi-source domain weighting method, which reduces source domain noise by knowledge weighting. This method effectively addresses two significant challenges encountered in the analysis of cellular images, namely, the uncertainty in source domain output and the ambiguity in cell boundary semantics. Secondly, we also take into account the structured information from cells to images, which may be overlooked during distillation, and design an adaptive knowledge voting strategy. This strategy enables us to ignore low-confidence regions, similar to Cutout <ref type="bibr" target="#b5">[6]</ref>, but with selective masking of pixels, which effectively balances the trade-off between exploiting similarities and preserving differences of different domains. As a result, we refer to the labels generated through the voting strategy as pseudo-cutout labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>Overview: Figure <ref type="figure" target="#fig_0">1</ref> shows a binary cell segmentation task with three source models trained on different tissues and a target model, i.e., the student model in Fig. <ref type="figure" target="#fig_0">1</ref>. We only use the source models' predictions on the target data for knowledge transfer without accessing the source data and parameters. The η and η indicate that different perturbations are added to the target images. Subsequently, we feed the perturbed images into the source domain predictor to generate the corresponding raw segmentation outputs. These outputs are then processed by two main components of our framework: a pixel-level weighting method that takes into account the prediction uncertainty and cell boundary ambiguity, and an adaptive knowledge voter that utilizes confidence gates and a dynamic ensemble strategy. These components we designed are to extract reliable knowledge from the predictions of source domain models and reduce noise during distillation. Finally, we obtain a weighted logit for knowledge distillation from pixel level and a high-confidence pseudo-cutout label for further structured distillation from cell to global pathological image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Knowledge Distillation by Weighted Logits Map:</head><p>We denote D N S = {X s , Y s } N as a collection of N source domains and D T = {X i t , Y j t } as single target domain, where the number of labeled instances Y j t X i t . We are only provided with black-box models {f n s } N n=1 trained on multiple source domains {x i s , y i s } N n=1 for knowledge transfer. The parameters {θ n s } N n=1 of these source domain predictors are not allowed to participate in gradient backpropagation as a result of the privacy policy. Thus, our ultimate objective is to derive a novel student model f t : X t → Y t that is relevant to the source domain task. Accordingly, direct knowledge transfer using the output of the source domain predictor may lead to feature bias in the student model due to the unavoidable covariance <ref type="bibr" target="#b19">[20]</ref> between the target and source domains. Inspired by <ref type="bibr" target="#b20">[21]</ref>, we incorporate prediction uncertainty and cell boundary impurity to establish pixel-level weights for multi-source outputs. We assume that k-square-neighbors of a pixel as a cell region, i.e., for a logits map with height H and width W , we define the region as follow:</p><formula xml:id="formula_0">N k {(i, j) | (i, j) ∈ (H, W )} = {(u, v) | |u -i| ≤ k, |v -j| ≤ k} (1)</formula><p>where (i, j) denotes centre of region, and k denotes the size of k-square-neighbors. Firstly, we develop a pixel-level predictive uncertainty algorithm to aid in assessing the correlation between multiple source domains and the target domain. For a given target image x t ∈ X i t , we initially feed it into the source predictors {f n s } N n=1 to obtain their respective prediction {p n s } N n=1 . To leverage the rich semantic information from the source domain predictor predictions, we utilize predictive entropy of the softmax outputs to measure the prediction uncertainty scores. In the semantic segmentation scenario of C-classes classification, we define the pixel-level uncertainty score U (i,j) n as follow:</p><formula xml:id="formula_1">U (i,j) n = - C c=1 O n(i,j,c) s log O n(i,j,c) s (2)</formula><p>where O n s denotes softmax output,i.e.,O n s = softmax(p n s ) from nth source predictor.</p><p>Due to the unique characteristics of cell morphology, merely relying on uncertainty information is insufficient to produce high-quality ensemble logits map that accurately capture the relevance between the source and target domains. The target pseudo-label for the nth predictor f n s can be obtained by applying the softmax function to the output and selecting the category with the highest probability score, i.e., Y t = arg max c∈{1,...,C} (softmax(p n s )). Then according to C-classes classification tasks, we divide the cell region into C subsets,</p><formula xml:id="formula_2">N c k (i, j) = {(u, v) ∈ N k (i, j) | Y t = c}.</formula><p>After that, we determine the degree of impurity in an area of interest by analyzing the statistics of the boundary region, which represents the level of semantic information ambiguity. Specifically, the number of different objects within the area is considered a proxy for its impurity level, with higher counts indicating higher impurity.The boundary impurity P (i,j) can be calculated as:</p><formula xml:id="formula_3">P (i,j) n = - C c=1 |N c k (i, j)| |N k (i, j)| log |N c k (i, j)| |N k (i, j)| (<label>3</label></formula><formula xml:id="formula_4">)</formula><p>where | • | denotes the number of pixels in the area. By assigning lower weights to the pixels with high uncertainty and boundary ambiguity, we can obtain pixel-level weight scores W n for each p n s , i.e.,</p><formula xml:id="formula_5">W n = -log exp (U n P n ) N n=1 exp (U n P n )<label>(4)</label></formula><p>where denotes element-wise matrix multiplication. According to the pixellevel weight, we will obtain an ensemble logits map M = N n=1 W n • p n s . And the object of the knowledge distillation is a classical regularization term <ref type="bibr" target="#b8">[9]</ref>:</p><formula xml:id="formula_6">L kd (f t ; X t , M) = E xt∈Xt D kl (M || f t (x t ))<label>(5)</label></formula><p>where D kl denotes the Kullback-Leibler (KL) divergence loss.</p><p>Adaptive Pseudo-Cutout Label: As previously mentioned, the outputs from the source domain black-box predictors have been adjusted by the pixel-level weight. However, they are still noisy and only pixel-level information is considered while ignoring structured information in the knowledge distillation process. Thus, we utilize the output of the black-box predictor on the target domain to produce an adaptive pseudo-cutout label, which will be employed to further regularize the knowledge distillation process. We have revised the method in <ref type="bibr" target="#b6">[7]</ref> to generate high-quality pseudo labels that resemble the Cutout augmentation technique. For softmax outputs {O n s } N n=1 from N source predictors, we first set a threshold α to filter low-confidence pixels. To handle pixels with normalized probability values below the threshold, we employ a Cutout-like operation and discard these pixels. Subsequently, we apply an adaptive voting strategy to the N source domain outputs. Initially, during the training of the target model, if at least one source domain output exceeds the threshold, we consider the pixel as a positive or negative sample, which facilitates rapid knowledge acquisition by the model. As the training progresses, we gradually tighten the voting strategy and only retain regional pixels that have received adequate votes. The strategy can be summarised as follow:</p><formula xml:id="formula_7">V ((i,j) | (i,j)∈(H,W )) n = 1, O n s (i, j) &gt; α, 0, otherwise. (<label>6</label></formula><formula xml:id="formula_8">)</formula><p>where α is empirically set as 0.9.</p><p>Then we will aggregate the voting scores, i.e., V (i,j) = N n=1 V (i,j) n and determine whether to retain each pixel using an adaptive vote gate G ∈ {1, 2, 3, etc.}. By filtering with a threshold and integrating the voting strategy, we generate high-confidence pseudo-labels that remain effective even when the source and target domains exhibit covariance. Finally, we define the ensemble result as a pseudo-cutout label Ps and employ consistency regularization as below:</p><formula xml:id="formula_9">L pcl (f t ; X t , Ps ) = E xt∈Xt l ce ( Ps || f t (x t )) (<label>7</label></formula><formula xml:id="formula_10">)</formula><p>where l ce denotes cross-entropy loss function.</p><p>Loss Functions: Finally, we incorporate global structural information about the predicted outcome of the target domain into both distillation and semisupervised learning. To mitigate the noise effect of the source domain predictors, we introduce maximize mutual information targets to facilitate discrete representation learning by the network. We define E(p) =i p i log p i as conditional entropy. The object can be described as follow:</p><formula xml:id="formula_11">L mmi (f t ; X t ) = H(Y t ) -H(Y t |X t ) = E (E xt∈Xt f t (x t )) -E xt∈Xt E (f t (x t )) , (<label>8</label></formula><formula xml:id="formula_12">)</formula><p>where the increasing H(Y t ) and the decreasing H(Y t |X t ) help to balances class separation and classifier complexity <ref type="bibr" target="#b14">[15]</ref>. We adopt the classical and effective mean-teacher framework as a baseline for semi-supervised learning and update the teacher model parameters by exponential moving average. Also, we apply two different perturbations (η, η ) to the target domain data and feed them into the student model and the mean-teacher model respectively. The consistency loss of unsupervised learning can be defined as below:</p><formula xml:id="formula_13">L cons (θ t , θ t ) = E xt∈Xt ||f t (x t , θ t , η ) -f t (x t , θ t , η)|| 2 (9)</formula><p>Finally, we get the overall objective:</p><formula xml:id="formula_14">L all = L kd + L pcl + L cons -L mmi + L sup (<label>10</label></formula><formula xml:id="formula_15">)</formula><p>where L sup denotes the ordinary cross-entropy loss for supervised learning and we set the weight of each loss function to 1 in the training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>Dataset and Setting: We collect four pathology image datasets to validate our proposed approach. Firstly, we acquire 50 images from a cohort of patients with Triple Negative Breast Cancer (TNBC), which is released by Naylor et al <ref type="bibr" target="#b17">[18]</ref>. Hou et al. <ref type="bibr" target="#b9">[10]</ref> publish a dataset of nucleus segmentation containing 5,060 segmented slides from 10 TCGA cancer types. In this work, we use 98 images from invasive carcinoma of the breast (BRCA). We have also included 463 images of Kidney Renal Clear cell carcinoma (KIRC) in our dataset, which are made publicly available by Irshad et al <ref type="bibr" target="#b10">[11]</ref>. Awan et al. <ref type="bibr" target="#b1">[2]</ref> publicly release a dataset containing tissue slide images and associated clinical data on colorectal cancer (CRC), from which we randomly select 200 patches for our study. In our experiments, we transfer knowledge from three black-box models trained on different source domains to a new target domain model (e.g.,from CRC, TNBC, KIRC to BRCA). The backbone network for the student model and source domain black-box predictors employ the widely adopted residual U-Net <ref type="bibr" target="#b11">[12]</ref>, which is commonly used for medical image segmentation. For each source domain network, we conduct full-supervision training on the corresponding source domain data and directly evaluate its performance on target domain data. The upper performance metrics (Source-only upper) are shown in the Table <ref type="table" target="#tab_0">1</ref>. To ensure the reliability of the results, we use the same data for training, validation, and testing, which account for 80%, 10%, and 10% of the original data respectively. For the target domain network, we use unsupervised and semi-supervised as our task settings respectively. In semi-supervised domain adaptation, we only use 10% of the target domain data as labeled data.</p><p>Experimental Results: To validate our method, we compare it with the following approaches: (1) CellSegSSDA <ref type="bibr" target="#b7">[8]</ref>, an adversarial learning based semisupervised domain adaptation approach. (2) US-MSMA <ref type="bibr" target="#b12">[13]</ref>, a multi-source model domain aggregation network. (3) SFDA-DPL <ref type="bibr" target="#b4">[5]</ref>, a source-free unsupervised domain adaptation approach. (4) BBUDA <ref type="bibr" target="#b16">[17]</ref>, an unsupervised black-box model domain adaptation framework. A point worth noting is that most of the methods we compared with are white-box methods, which means they can obtain more information from the source domain than us. For single-source domain adaptation approach, CellsegSSDA and SFDA-DPL, we employ two strategies to ensure the fairness of the experiments: (1) single-source, i.e. performing adaptation on each single source, where we select the best results to display in the Table <ref type="table" target="#tab_0">1;</ref><ref type="table"></ref> (2) source-combined, i.e. all source domains are combined into a traditional single source. The Table <ref type="table" target="#tab_0">1</ref> and Fig. <ref type="figure" target="#fig_1">2</ref> demonstrate that our proposed method exhibits superior performance, even when compared to these white-box methods, surpassing them in various evaluation metrics and visualization results.</p><p>In addition, the experimental results also show that simply combining multiple source data into a traditional single source will result in performance degradation in some cases, which also proves the importance of studying multi-source domain adaptation methods.</p><p>Ablation Study: To evaluate the impact of our proposed methods of weighted logits(WL), pseudo-cutout label(PCL) and maximize mutual information(MMI) on the model performance, we conduct an ablation study. We compare the baseline model with the models that added these three methods separately. We chose CRC, KIRC and BRCA as our source domains, and TNBC as our target domain. The results of these experiments, presented in the Table <ref type="table" target="#tab_1">2</ref>, show that our proposed modules are indeed useful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>Our proposed multi-source black-box domain adaptation method achieves competitive performance by solely relying on the source domain outputs, without the need for access to the source domain data or models, thus avoiding information leakage from the source domain. Additionally, the method does not assume the same architecture across domains, allowing us to learn lightweight target models from large source models, improving learning efficiency. We demonstrate the effectiveness of our method on multiple public datasets and believe it can be readily applied to other domains and adaptation scenarios. Moving forward, we plan to integrate our approach with active learning methods to enhance annotation efficiency in the semi-supervised setting. By leveraging multi-source domain knowledge, we aim to improve the reliability of the target model and enable more efficient annotation for better model performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. Overview of our purposed framework, where logits maps denote the raw predictions from source models and ω denotes pixel-level weight for each prediction. The semi-supervised loss, denoted as L ssl , encompasses the supervised loss, consistency loss, and maximize mutual information loss.</figDesc><graphic coords="3,69,78,83,93,297,97,112,36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Visualized segmentation on the BRCA and KIRC target domains respectively.</figDesc><graphic coords="7,61,50,63,14,334,54,57,22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Quantitative comparison with unsupervised and semi-supervised domain adaptation methods under 3 segmentation metrics.</figDesc><table><row><cell>Source</cell><cell></cell><cell cols="3">CRC&amp;TNBC&amp;KIRC</cell><cell cols="3">CRC&amp;TNBC&amp;BRCA</cell></row><row><cell>Target</cell><cell></cell><cell>BRCA</cell><cell></cell><cell></cell><cell>KIRC</cell><cell></cell><cell></cell></row><row><cell>Standards</cell><cell>Methods</cell><cell>Dice</cell><cell>HD95</cell><cell>ASSD</cell><cell>Dice</cell><cell>HD95</cell><cell>ASSD</cell></row><row><cell>Source-only</cell><cell>Source(upper)</cell><cell cols="6">0.6991 41.9604 10.8780 0.7001 34.5575 6.7822</cell></row><row><cell cols="2">Single-source(upper) SFDA-DPL [5]</cell><cell cols="6">0.6327 43.8113 11.6313 0.6383 26.3252 4.6023</cell></row><row><cell></cell><cell>BBUDA [17]</cell><cell cols="6">0.6620 39.6950 11.3911 0.6836 42.9875 7.4398</cell></row><row><cell>Source-Combined</cell><cell>SFDA-DPL [5]</cell><cell cols="6">0.6828 46.5393 12.1484 0.6446 25.4274 4.2998</cell></row><row><cell></cell><cell>BBUDA [17]</cell><cell cols="6">0.6729 41.8879 11.5375 0.6895 46.7358 8.7463</cell></row><row><cell>Multi-source</cell><cell cols="7">US-MSMA [13] 0.7334 37.1309 8.7817 0.7161 18.7093 3.0187</cell></row><row><cell>Multi-source</cell><cell>Our(UDA)</cell><cell cols="6">0.7351 39.4103 8.7014 0.7281 30.9221 6.2080</cell></row><row><cell cols="8">Single-source(upper) CellSegSSDA [8] 0.6852 45.2595 9.9133 0.6937 58.7221 12.5176</cell></row><row><cell>Source-Combined</cell><cell cols="7">CellSegSSDA [8] 0.7202 43.9251 8.0944 0.6699 55.1768 10.3623</cell></row><row><cell>Multi-source</cell><cell>Our(SSDA)</cell><cell cols="6">0.7565 39.0552 9.3346 0.7443 31.7582 6.0873</cell></row><row><cell cols="2">fully-supervised upper bounds</cell><cell cols="6">0.7721 35.1449 7.2848 0.7540 23.53767 4.1882</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Ablation study of three modules in our proposed method.</figDesc><table><row><cell cols="5">CRC&amp;KIRC&amp;BRCA to TNBC</cell></row><row><cell cols="3">WL PCL MMI</cell><cell>Dice</cell><cell>HD95</cell><cell>ASSD</cell></row><row><cell>×</cell><cell>×</cell><cell>×</cell><cell cols="2">0.6708 56.9111 16.3837</cell></row><row><cell></cell><cell>×</cell><cell>×</cell><cell cols="2">0.6822 54.3386 14.9817</cell></row><row><cell></cell><cell></cell><cell>×</cell><cell cols="2">0.6890 57.0889 12.9512</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">0.7075 58.8798 10.7247</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This work is partially supported by the <rs type="funder">National Natural Science Foundation of China</rs> under grant No. <rs type="grantNumber">61902310</rs> and the <rs type="funder">Natural Science Basic Research Program of Shaanxi, China</rs> under grant <rs type="grantNumber">2020JQ030</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_TMnHJ66">
					<idno type="grant-number">61902310</idno>
				</org>
				<org type="funding" xml:id="_kJrC4rG">
					<idno type="grant-number">2020JQ030</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Unsupervised multi-source domain adaptation without access to source data</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Raychaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Oymak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Roy-Chowdhury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="10103" to="10112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Glandular morphometrics for objective grading of colorectal adenocarcinoma histology images</title>
		<author>
			<persName><forename type="first">R</forename><surname>Awan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">16852</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Source-relaxed domain adaptation for image segmentation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bateson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kervadec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dolz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lombaert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ben Ayed</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59710-8_48</idno>
		<idno>978-3-030-59710-8 48</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12261</biblScope>
			<biblScope unit="page" from="490" to="499" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Extracting training data from large language models</title>
		<author>
			<persName><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Security Symposium</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Source-free domain adaptive fundus image segmentation with denoised pseudo-labeling</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Heng</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87240-3_22</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87240-322" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12905</biblScope>
			<biblScope unit="page" from="225" to="235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Improved regularization of convolutional neural networks with cutout</title>
		<author>
			<persName><forename type="first">T</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04552</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Kd3a: unsupervised multi-source decentralized domain adaptation via knowledge distillation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Feng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3274" to="3283" />
		</imprint>
		<respStmt>
			<orgName>ICML</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Adversarial domain adaptation for cell segmentation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Haq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="j">Medical Imaging with Deep Learning</title>
		<imprint>
			<biblScope unit="page" from="277" to="287" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<title level="m">Distilling the knowledge in a neural network</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dataset of segmented nuclei in hematoxylin and eosin stained histopathology images of ten cancer types</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Data</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">185</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Crowdsourcing image annotation for nucleus detection and segmentation in computational pathology: evaluating experts, automated methods, and the crowd</title>
		<author>
			<persName><forename type="first">H</forename><surname>Irshad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific Symposium on Biocomputing Co-chairs</title>
		<imprint>
			<publisher>World Scientific</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="294" to="305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Left-ventricle quantification using residual U-Net</title>
		<author>
			<persName><forename type="first">E</forename><surname>Kerfoot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Oksuz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Schnabel</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-12029-0_40</idno>
		<idno>978-3-030-12029-0 40</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">STACOM 2018</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Pop</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11395</biblScope>
			<biblScope unit="page" from="371" to="380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Union-set multi-source model adaptation for semantic segmentation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Togo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ogawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Haseyama</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-19818-2_33</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-19818-2" />
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2022: 17th European Conference</title>
		<meeting><address><addrLine>Tel Aviv, Israel; Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022-10-27">23-27 October 2022. 2022</date>
			<biblScope unit="page">33</biblScope>
		</imprint>
	</monogr>
	<note>Proceedings, Part XXIX</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Do we really need to access the source data? source hypothesis transfer for unsupervised domain adaptation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6028" to="6039" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dine: domain adaptation from single and multiple black-box predictors</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="8003" to="8013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Adversarial unsupervised domain adaptation with conditional and label shift: Infer, align and iterate</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="10367" to="10376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Unsupervised black-box model domain adaptation for brain tumor segmentation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Neurosci</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">837646</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Segmentation of nuclei in histopathology images by deep regression of the distance map</title>
		<author>
			<persName><forename type="first">P</forename><surname>Naylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Laé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Reyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Walter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="448" to="459" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Cell segmentation and tracking using cnn-based distance predictions and a graph-based matching strategy</title>
		<author>
			<persName><forename type="first">T</forename><surname>Scherr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Löffler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Böhland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mikut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Plos One</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">243219</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Improving predictive inference under covariate shift by weighting the log-likelihood function</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shimodaira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Stat. Plan. Infer</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="227" to="244" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Towards fewer annotations: active learning via region impurity and prediction uncertainty for domain adaptive semantic segmentation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="8068" to="8078" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
