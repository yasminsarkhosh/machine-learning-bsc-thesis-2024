<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">TractCloud: Registration-Free Tractography Parcellation with a Novel Local-Global Streamline Point Cloud Representation</title>
				<funder ref="#_pMEZ5Rn #_QVxCCBa #_Rnfsb7q #_e3Racb7 #_TAN7pr5">
					<orgName type="full">National Institutes of Health</orgName>
					<orgName type="abbreviated">NIH</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Tengfei</forename><surname>Xue</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Harvard Medical School</orgName>
								<address>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">The University of Sydney</orgName>
								<address>
									<settlement>Sydney</settlement>
									<region>NSW</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuqian</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Harvard Medical School</orgName>
								<address>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">The University of Sydney</orgName>
								<address>
									<settlement>Sydney</settlement>
									<region>NSW</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chaoyi</forename><surname>Zhang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">The University of Sydney</orgName>
								<address>
									<settlement>Sydney</settlement>
									<region>NSW</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexandra</forename><forename type="middle">J</forename><surname>Golby</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Harvard Medical School</orgName>
								<address>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nikos</forename><surname>Makris</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Harvard Medical School</orgName>
								<address>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yogesh</forename><surname>Rathi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Harvard Medical School</orgName>
								<address>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Weidong</forename><surname>Cai</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">The University of Sydney</orgName>
								<address>
									<settlement>Sydney</settlement>
									<region>NSW</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Fan</forename><surname>Zhang</surname></persName>
							<email>zhangfanmark@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Harvard Medical School</orgName>
								<address>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lauren</forename><forename type="middle">J</forename><surname>Oâ€™donnell</surname></persName>
						</author>
						<title level="a" type="main">TractCloud: Registration-Free Tractography Parcellation with a Novel Local-Global Streamline Point Cloud Representation</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="409" to="419"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">AFBFBC57DD155840705DA888AF6AA032</idno>
					<idno type="DOI">10.1007/978-3-031-43993-3_40</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-01T10:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Diffusion MRI</term>
					<term>Tractography</term>
					<term>Registration-free white matter parcellation</term>
					<term>Deep learning</term>
					<term>Point cloud</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Diffusion MRI tractography parcellation classifies streamlines into anatomical fiber tracts to enable quantification and visualization for clinical and scientific applications. Current tractography parcellation methods rely heavily on registration, but registration inaccuracies can affect parcellation and the computational cost of registration is high for large-scale datasets. Recently, deep-learning-based methods have been proposed for tractography parcellation using various types of representations for streamlines. However, these methods only focus on the information from a single streamline, ignoring geometric relationships between the streamlines in the brain. We propose TractCloud, a registration-free framework that performs wholebrain tractography parcellation directly in individual subject space. We propose a novel, learnable, local-global streamline representation that leverages information from neighboring and whole-brain streamlines to describe the local anatomy and global pose of the brain. We train our framework on a large-scale labeled tractography dataset, which we augment by applying synthetic transforms including rotation, scaling, and translations. We test our framework on five independently acquired datasets across populations and health conditions. TractCloud significantly outperforms several state-of-the-art methods on all testing datasets. TractCloud achieves efficient and consistent whole-brain white matter parcellation across the lifespan (from neonates to elderly subjects, including brain tumor patients) without the need for registration. The robustness and high inference speed of TractCloud make it suitable for large-scale tractography data analysis. Our project page is available at https://tractcloud.github.io/.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Diffusion MRI (dMRI) tractography is the only non-invasive method capable of mapping the complex white matter (WM) connections within the brain <ref type="bibr" target="#b1">[2]</ref>. Tractography parcellation <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b42">42]</ref> classifies the vast numbers of streamlines resulting from whole-brain tractography to enable visualization and quantification of the brain's WM connections. (Here a streamline is defined as a set of ordered points in 3D space resulting from tractography <ref type="bibr" target="#b45">[45]</ref>). In recent years, deep-learning-based methods have been proposed for tractography parcellation <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b14">14,</ref><ref type="bibr" target="#b15">15,</ref><ref type="bibr" target="#b17">17,</ref><ref type="bibr" target="#b20">20,</ref><ref type="bibr" target="#b33">33,</ref><ref type="bibr" target="#b34">34,</ref><ref type="bibr" target="#b36">36,</ref><ref type="bibr" target="#b37">37,</ref><ref type="bibr" target="#b39">39,</ref><ref type="bibr" target="#b44">44]</ref>, of which many methods are designed to classify streamlines <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b15">[15]</ref><ref type="bibr" target="#b16">[16]</ref><ref type="bibr" target="#b17">[17]</ref><ref type="bibr" target="#b37">37,</ref><ref type="bibr" target="#b39">39,</ref><ref type="bibr" target="#b44">44]</ref>. However, multiple challenges exist when using streamline data as deep network input. One well-known challenge is that streamlines can be equivalently represented in forward or reverse order <ref type="bibr" target="#b11">[11,</ref><ref type="bibr" target="#b39">39]</ref>, complicating their direct representation as vectors <ref type="bibr" target="#b6">[7]</ref> or images <ref type="bibr" target="#b44">[44]</ref>. Another challenge is that the geometric relationships between the streamlines in the brain have previously been ignored: existing parcellation methods <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b15">[15]</ref><ref type="bibr" target="#b16">[16]</ref><ref type="bibr" target="#b17">[17]</ref><ref type="bibr" target="#b37">37,</ref><ref type="bibr" target="#b39">39,</ref><ref type="bibr" target="#b44">44]</ref> train and classify each streamline independently. Finally, computational cost can pose a challenge for the parcellation of large tractography datasets that can include thousands of subjects with millions of streamlines per subject.</p><p>In this work, we propose a novel point-cloud-based strategy that leverages neighboring and whole-brain streamline information to learn local-global streamline representations. Point clouds have been shown to be efficient and effective representations for streamlines <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b15">15,</ref><ref type="bibr" target="#b18">18,</ref><ref type="bibr" target="#b39">39]</ref> in applications such as tractography filtering <ref type="bibr" target="#b0">[1]</ref>, clustering <ref type="bibr" target="#b6">[7]</ref>, and parcellation <ref type="bibr" target="#b15">[15,</ref><ref type="bibr" target="#b18">18,</ref><ref type="bibr" target="#b38">38,</ref><ref type="bibr" target="#b39">39]</ref>. One benefit of using point clouds is that streamlines with equivalent forward and reverse point orders (e.g., from cortex to brainstem or vice versa) can be represented equally. However, these existing methods focus on a single streamline (one point cloud) and ignore other streamlines (other point clouds) in the same brain that may provide important complementary information useful for tractography parcellation. In computer vision, point clouds are commonly used to describe scenes and objects (e.g., cars, tables, airplanes, etc.). However, point cloud segmentation methods from computer vision, which assign labels to points, cannot translate directly to the tractography field, where the task of interest is to label entire streamlines. Computer vision studies <ref type="bibr" target="#b21">[21,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b32">32,</ref><ref type="bibr" target="#b35">35,</ref><ref type="bibr" target="#b40">40,</ref><ref type="bibr" target="#b41">41,</ref><ref type="bibr" target="#b46">46]</ref> have shown that point interactions within one point cloud can yield more effective features for downstream tasks. However, in tractography parcellation we are interested in the relationship between multiple point clouds (streamlines) in the brain. These other streamlines can provide detailed information about the local WM geometry surrounding the streamline to be classified, as well as global information about the location and pose of the brain that can reduce the need for image registration.</p><p>Affine or even nonrigid registration is needed for current tractography parcellation methods <ref type="bibr" target="#b13">[13,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b42">42]</ref>. Recently, registration-free techniques have been proposed for tractography parcellation to handle computational challenges resulting from large inter-subject variability and to increase robustness to image registration inaccuracies <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b29">29]</ref>. Avoiding image registration can also reduce computational time and cost when processing very large tractography datasets with thousands of subjects. While other registration-free tractography parcellation techniques require Freesurfer input <ref type="bibr" target="#b29">[29]</ref> or work with rigidly MNI-aligned Human Connectome Project data <ref type="bibr" target="#b19">[19]</ref>, our method can directly parcellate tractography in individual subject space.</p><p>In this study, we propose TractCloud, a registration-free tractography parcellation framework, as illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>. This paper has three main contributions. First, we propose a novel, learnable, local-global streamline representation that leverages information from neighboring and whole-brain streamlines to describe the local anatomy and global pose of the brain. Second, we leverage a training strategy using synthetic transformations of labeled tractography data to enable registration-free parcellation at the inference stage. Third, we implement our framework using two compared point cloud networks and demonstrate fast, registration-free, whole-brain tractography parcellation across the lifespan.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Training and Testing Datasets</head><p>We utilized a high-quality and large-scale dataset of 1 million labeled streamlines for model training and validation. The dataset was obtained from a WM tractography atlas <ref type="bibr" target="#b42">[42]</ref> that was curated and annotated by a neuroanatomist. The atlas was derived from 100 registered tractography of young healthy adults in the Human Connectome Project (HCP) <ref type="bibr" target="#b30">[30]</ref>. The training data includes 43 tract classes: 42 anatomically meaningful tracts from the whole brain and one tract category of "other streamlines," including, most importantly, anatomically implausible outlier streamlines. On average, the 42 anatomical tracts have 2539 streamlines with a standard deviation of 2693 streamlines.</p><p>For evaluation, we used a total of 120 subjects from four public datasets and one private dataset. These five datasets were independently acquired with different imaging protocols across ages and health conditions. (1) developing HCP (dHCP) <ref type="bibr" target="#b9">[9]</ref>  <ref type="table" target="#tab_0">S1</ref>. The twotensor Unscented Kalman Filter (UKF) <ref type="bibr" target="#b22">[22,</ref><ref type="bibr" target="#b25">25,</ref><ref type="bibr" target="#b27">27]</ref> method, which is consistent across ages, health conditions, and image acquisitions <ref type="bibr" target="#b42">[42]</ref>, was utilized to create whole-brain tractography for all subjects across the datasets mentioned above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">TractCloud Framework</head><p>Synthetic Transform Data Augmentation. To enable tractography parcellation without registration, we augmented the training data by applying synthetic transform-based augmentation (STA) including rotation, scaling, and translations. These transformations have been used in voxel-based WM segmentation <ref type="bibr" target="#b34">[34]</ref>, but no study has applied these transformations to study tractography, to our knowledge. In detail, we applied 30 random transformations to each subject tractography in the training dataset to obtain 3000 transformed subjects and 30 million streamlines. Transformations included: rotation from -45 to 45 â€¢ C along the left-right axis, from -10 to 10 â€¢ C along the anterior-posterior axis, and from -10 to 10 â€¢ C along the superior-inferior axis; translation from -50 to 50 mm along all three axes; scaling from -45% to 5% along all three axes. These transformations were selected based on typical differences between subjects due to variability in brain anatomy and volume, head position, and image acquisition protocol. Many methods are capable of tractography parcellation after affine registration <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b42">42]</ref>; therefore, with STA applied to the training dataset, our framework has the potential for registration-free parcellation.</p><p>Module for Local-Global Streamline Representation Learning. We propose a module (Fig. <ref type="figure" target="#fig_2">2</ref>) to learn the proposed local-global representation, which benefits from information about the anatomy of the neighboring WM and the overall pose of the brain. We construct the input for the learning module by concatenating the coordinates of the original streamline (the one to be classified), its local neighbor streamlines, and global whole-brain streamlines. In detail, assume a brain has n streamlines, denoted by S = {s 1 , s 2 , . . . , s n }, s i âˆˆ R mÃ—3 , where 3 is the dimensionality of the point coordinates and m is the number of points for each streamline (m = 15 as in <ref type="bibr" target="#b42">[42,</ref><ref type="bibr" target="#b44">44]</ref>). For streamline s i , we obtain a set of k nearest streamlines, local(s i ) = {s j1 , s j2 , . . . , s jk }, using a pairwise streamline distance <ref type="bibr" target="#b11">[11]</ref>. From the whole brain, we also randomly select a set of w streamlines, global(s i ) = {s q1 , s q2 , . . . , s qw }. Then s i , local(s i ), and global(s i ) are concatenated as shown in Fig. <ref type="figure" target="#fig_2">2</ref> to obtain the input of the module, t i âˆˆ R mÃ—6Ã— (k+w) . The proposed module begins with a shared fully connected (FC) layer with ReLU activation function (h Î˜ ): (k+w) , where h is the output dimension of h Î˜ (h=64 <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b32">32]</ref>). Finally, the local-global representation r i is obtained through max-pooling  <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b32">32,</ref><ref type="bibr" target="#b46">46]</ref>. Here, we explore two widely used networks: PointNet <ref type="bibr" target="#b2">[3]</ref> and Dynamic Graph Convolutional Neural Network (DGCNN) <ref type="bibr" target="#b32">[32]</ref>. PointNet (see Fig. <ref type="figure" target="#fig_0">S1</ref> for network details) encodes point-wise features individually, but DGCNN (see Fig. <ref type="figure" target="#fig_2">S2</ref> for network details) encodes point-wise features by interacting with other points on a streamline. Both PointNet and DGCNN then aggregate features of all points through pooling to get a single streamline descriptor, which is input into fully connected layers for classification.</p><formula xml:id="formula_0">f i = h Î˜ (t i ), f i âˆˆ R mÃ—hÃ—</formula><formula xml:id="formula_1">r i = pool(f i ) âˆˆ R mÃ—h</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Implementation Details</head><p>To learn r i , we used 20 local streamlines (selected from 10, 20, 50, 100) and 500 global streamlines (selected from 100, 300, 500, 1000). Our framework was trained with the Adam optimizer with a learning rate of 0.001 using cross-entropy loss. The epoch was 20, and the batch size was 1024. Training of our registrationfree framework (TractCloud reg-free ) with the large STA dataset took about 22 h and 10.9 GB GPU memory with Pytorch (v1.13) on an NVIDIA RTX A5000 3 Experiments and Results</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Performance on the Labeled Atlas Dataset</head><p>We evaluated our method on the original labeled training dataset (registered and aligned) and its synthetic transform augmented (STA) data (unregistered and unaligned). We divided both the original and STA data into train/validation/test sets with the distribution of 70%/10%/20% by subjects (such that all streamlines from an individual subject were placed into only one set, either train or validation or test). For experimental comparison, we included two deep-learning-based state-of-the-art (SOTA) tractography parcellation methods: DCNN++ <ref type="bibr" target="#b37">[37]</ref> and DeepWMA <ref type="bibr" target="#b44">[44]</ref>. They were both designed to perform deep WM parcellation using CNNs, with streamline spatial coordinate features as input. We trained the networks based on the recommended settings in their papers and code. Two widely used point-cloud-based networks (PointNet <ref type="bibr" target="#b2">[3]</ref> and DGCNN <ref type="bibr" target="#b32">[32]</ref>), with a single streamline as input, were included as baseline methods. To evaluate the effectiveness of the local-global representation in TractCloud, we performed experiments using only local neighbor features (PointNet +loc and DGCNN +loc ) and both local neighbor and whole-brain global features (PointNet +loc+glo and DGCNN +loc+glo ). For all methods, we report two metrics (accuracy and macro F1) that are widely used for tractography parcellation <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b37">37,</ref><ref type="bibr" target="#b39">39,</ref><ref type="bibr" target="#b44">44]</ref>. The accuracy is reported as the overall accuracy of streamline classification, and the macro F1 score is reported as the mean across 43 tract classes (Table <ref type="table" target="#tab_0">1</ref>). Table <ref type="table" target="#tab_0">1</ref> shows that the TractCloud framework achieves the best performance on data with and without synthetic transformations (STA). Especially on STA data, TractCloud yields a large improvement in accuracy (up to 9.9%) and F1 (up to 13.8%), compared to PointNet and DGCNN baselines as well as SOTA methods. In addition, including local (PointNet +loc and DGCNN +loc ) and global (PointNet +loc+glo and DGCNN +loc+glo ) features both improve the performance compared to baselines (PointNet and DGCNN) with a single streamline as input. This demonstrates the effectiveness of our local-global representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Performance on the Independently Acquired Testing Datasets</head><p>We performed experiments on five independently acquired, unlabeled testing datasets (dHCP, ABCD, HCP, PPMI, BTP) to evaluate the robustness and generalization ability of our TractCloud reg-free framework on unseen and unregistered data. All compared SOTA methods (DeepWMA, DCNN++) and TractCloud regist were tested on registered tractography, and only TractCloud reg-free was tested on unregistered tractography. Tractography was registered to the space of the training atlas using an affine transform produced by registering the baseline (b = 0) image of each subject to the atlas population mean T2 image using 3D Slicer <ref type="bibr" target="#b10">[10]</ref>. For each method, we quantified the tract identification rate (TIR) and calculated the tract-to-atlas distance (TAD), and statistical significance tests were performed for results of TIR and TAD (Table <ref type="table">2</ref>). TIR measures if the tract is identified successfully when labels are not available <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b42">42,</ref><ref type="bibr" target="#b44">44]</ref>. Here, we chose 50 as the minimum number of streamlines for a tract to be considered as identified (The threshold of 50 is more strict than 10 or 20 in <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b42">42,</ref><ref type="bibr" target="#b44">44]</ref>). As a complementary metric for TIR, TDA measures the geometric similarity between identified tracts and corresponding tracts from the training atlas. For each testing subject's tract, we calculated the streamline-specific minimum average direct-flip distance <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b11">11,</ref><ref type="bibr" target="#b42">42]</ref> to the atlas tract and then computed the average across subjects and tracts to obtain TDA. We also recorded the computation time for tractography parcellation for every method (Table <ref type="table">2</ref>). The computation time was tested on a Linux workstation with an NVIDIA RTX A4000 GPU using tractography (0.28 million streamlines) from a randomly selected subject. To evaluate if differences in result values between our registration-free method (TractCloud reg-free ) and other methods are significant, we implemented a repeated measure ANOVA test for all methods across subjects, and then we performed multiple paired Student's t-tests between TractCloud reg-free method and each compared method. In addition, in order to evaluate how well our framework can perform without registration, we converted identified tracts into volume space and calculated the spatial overlap (weighted Dice) <ref type="bibr" target="#b8">[8,</ref><ref type="bibr" target="#b43">43]</ref> between results of TractCloud regist and TractCloud reg-free (Table <ref type="table" target="#tab_1">3</ref>). Furthermore, we also provide a visualization of identified tracts in an example individual subject for every dataset across methods (Fig. <ref type="figure" target="#fig_2">2</ref>).</p><p>As shown in Table <ref type="table">2</ref>, all methods achieve high TIRs on all datasets, and the TIR metric does not have significant differences across methods. This demonstrates that most tracts can be identified by all methods robustly. However, our registration-free framework (TractCloud reg-free ) obtains significantly lower TDA values (better quality of identified tracts) than all compared methods on ABCD, HCP, and PPMI datasets, where ages of test subjects are from 9 to 75 years old. On the very challenging dHCP (baby brain) dataset, TractCloud reg-free still significantly outperforms two SOTA methods. Note that TractCloud reg-free directly Table <ref type="table">2</ref>. Results of tract identification rate (TIR) and tract distance to atlas (TDA) on five independently acquired testing datasets as well as computation time on a randomly selected subject. TIR results show no significant differences across methods (ANOVA p &gt; 0.05), while TDA results do (ANOVA p &lt; 1 Ã— 10 -10 ). Asterisks show that the difference between TractCloud reg-free and other methods is significant using a paired Student's t-test. ( * p &lt; 0.05, * * p &lt; 0.001). Abbreviations: TC -TractCloud.  The tract spatial overlap (wDice) is over 0.965 on all datasets, except for the challenging dHCP (wDice is 0.932) (Table <ref type="table" target="#tab_1">3</ref>). Overall, our registration-free framework is comparable to (or better than) our framework with registration.</p><p>Figure <ref type="figure" target="#fig_4">3</ref> shows visualization results of example tracts. All methods can successfully identify these tracts across datasets. It is visually apparent that the TractCloud reg-free framework obtains results with fewer outlier streamlines, especially on the challenging dHCP dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion and Conclusion</head><p>We have demonstrated TractCloud, a registration-free tractography parcellation framework with a novel, learnable, local-global representation of streamlines. Experimental results show that TractCloud can achieve efficient and consistent tractography parcellation results across populations and dMRI acquisitions, with and without registration. The fast inference speed and robust ability to parcellate data in original subject space will allow TractCloud to be useful for analysis of large-scale tractography datasets. Future work can investigate additional data augmentation using local deformations to potentially increase robustness to pathology. Overall, TractCloud demonstrates the feasibility of registration-free tractography parcellation across the lifespan.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. TractCloud framework overview: (a) tractography with synthetic transformations, (b) module for learning local-global representation, (c) training on labeled data with synthetic transformations, (d) testing on unregistered tractography from real data.</figDesc><graphic coords="3,55,98,53,84,340,18,155,86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>: 20 neonates (1 to 27 days); (2) Adolescent Brain Cognitive Development (ABCD) dataset [31]: 25 adolescents (9 to 11 years); (3) HCP dataset [30]: 25 young healthy adults (22 to 35 years, subjects not part of the training atlas); (4) Parkinson's Progression Markers Initiative (PPMI) dataset [23]: 25 older adults (51 to 75 years), including Parkinson's disease (PD) patients and healthy individuals; (5) Brain Tumor Patient (BTP) dataset: dMRI data from 25 brain tumor patients (28 to 70 years) were acquired at Brigham and Women's Hospital. dMRI acquisition parameters of datasets are shown in Supplementary Table</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The proposed module for learning local-global representation.</figDesc><graphic coords="5,55,98,53,90,340,18,152,80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>. The network is trained in an end-to-end fashion where the local-global representation r i is learned during training of the overall point-cloud-based classification network. Network Structure for Streamline Classification. The local-global representation learning module can replace the first layer or module of typical pointcloud-based networks</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Visualization of example tracts (corticospinal tract and corpus callosum IV) from each method, in the subject with the median TDA for each testing dataset.</figDesc><graphic coords="8,41,79,401,90,340,21,156,88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Results on the labeled training dataset with and without synthetic transformations. Bold and italic text indicates the best-performing method and the secondbest-performing method, respectively. Abbreviations: Orig -Original, Acc -Accuracy.GPU machine. For training and inference using TractCloud reg-free , tractography was centered at the mass center of the training atlas. TractCloud reg-free directly annotates tract labels at the inference stage without requiring the registration of an atlas.</figDesc><table><row><cell>Feature</cell><cell cols="2">Single Streamline</cell><cell></cell><cell></cell><cell>Local</cell><cell></cell><cell>Local + Global</cell></row><row><cell>Data &amp;</cell><cell>SOTA</cell><cell></cell><cell cols="2">Point Cloud</cell><cell>TractCloud</cell><cell></cell><cell></cell></row><row><cell>Metric</cell><cell>Methods</cell><cell></cell><cell>Networks</cell><cell></cell><cell>Effectiveness</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Study</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="5">Deep WMA DCNN++ PointNet DGCNN PointNet</cell><cell>DGCNN</cell><cell>PointNet</cell><cell>DGCNN</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>+loc</cell><cell>+loc</cell><cell>+loc+glo</cell><cell>+loc+glo</cell></row><row><cell cols="2">Orig data Acc 90.29</cell><cell>91.26</cell><cell>91.36</cell><cell>91.85</cell><cell>91.51</cell><cell>91.91</cell><cell>92.28</cell><cell>91.99</cell></row><row><cell></cell><cell>F1 88.12</cell><cell>89.14</cell><cell>89.12</cell><cell>89.78</cell><cell>89.25</cell><cell>90.03</cell><cell>90.36</cell><cell>90.10</cell></row><row><cell cols="2">STA data Acc 82.35</cell><cell>84.14</cell><cell>81.83</cell><cell>83.70</cell><cell>86.56</cell><cell>87.14</cell><cell>91.57</cell><cell>91.69</cell></row><row><cell></cell><cell>F1 76.55</cell><cell>79.16</cell><cell>75.89</cell><cell>78.55</cell><cell>82.08</cell><cell>82.95</cell><cell>89.40</cell><cell>89.65</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 .</head><label>3</label><figDesc>Tract spatial overlap (wDice) between TractCloudregist and TractCloud reg-free</figDesc><table><row><cell>Method</cell><cell cols="10">TIR (%) â†‘ dHCP ABCD HCP PPMI BTP dHCP ABCD HCP PPMI BTP TDA (mm) â†“</cell><cell>Run Time</cell></row><row><cell>DeepWMA</cell><cell>98.8 Â±1.4</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>99.9 Â±0.5</cell><cell>6.81  *  Â±1.1</cell><cell>5.66  *  *  Â±0.9</cell><cell>5.09  *  *  Â±0.7</cell><cell>5.94  *  *  Â±1.0</cell><cell>6.24  *  Â±1.2</cell><cell>113 s</cell></row><row><cell>DCNN++</cell><cell>98.7 Â±1.9</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>99.8 Â±0.9</cell><cell>6.90  *  Â±1.4</cell><cell>5.69  *  *  Â±0.9</cell><cell>5.08  *  *  Â±0.7</cell><cell>5.95  *  *  Â±0.9</cell><cell>6.43  *  *  Â±1.8</cell><cell>102 s</cell></row><row><cell>TCregist</cell><cell>99.2 Â±1.6</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>99.9 Â±0.5</cell><cell>6.53  *  Â±1.1</cell><cell>5.60  *  *  Â±0.9</cell><cell>5.06  *  *  Â±0.7</cell><cell>5.87  *  Â±1.0</cell><cell>6.09 Â±1.1</cell><cell>97 s</cell></row><row><cell>TCreg-free</cell><cell>97.7 Â±3.1</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>99.9 Â±0.5</cell><cell>6.71 Â±1.3</cell><cell>5.52 Â±0.8</cell><cell>5.02 Â±0.6</cell><cell>5.85 Â±0.9</cell><cell>6.11 Â±1.0</cell><cell>58 s</cell></row><row><cell></cell><cell>dHCP</cell><cell></cell><cell>ABCD</cell><cell></cell><cell>HCP</cell><cell></cell><cell cols="2">PPMI</cell><cell>BTP</cell><cell></cell><cell></cell></row><row><cell cols="12">TSO 0.932 Â± 0.14 0.965 Â± 0.04 0.980 Â± 0.02 0.977 Â± 0.03 0.970 Â± 0.05</cell></row></table><note><p><p><p>works on unregistered tractography from neonate brains (much smaller than adult brains). In the challenging BTP (tumor patients) dataset, TractCloud reg-free obtains significantly lower TDA values than SOTA methods and comparable performance to TractCloud regist . As shown in Table</p>2</p>, our registration-free framework is much faster than other compared methods.</p></note></figure>
		</body>
		<back>

			<div type="funding">
<div><p>This work was supported by the following <rs type="funder">NIH</rs> grants: <rs type="grantNumber">R01MH125860</rs>, <rs type="grantNumber">R01MH119222</rs>, <rs type="grantNumber">R01MH132610</rs>, <rs type="grantNumber">R01MH074794</rs>, and <rs type="grantNumber">R01NS125781</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_pMEZ5Rn">
					<idno type="grant-number">R01MH125860</idno>
				</org>
				<org type="funding" xml:id="_QVxCCBa">
					<idno type="grant-number">R01MH119222</idno>
				</org>
				<org type="funding" xml:id="_Rnfsb7q">
					<idno type="grant-number">R01MH132610</idno>
				</org>
				<org type="funding" xml:id="_e3Racb7">
					<idno type="grant-number">R01MH074794</idno>
				</org>
				<org type="funding" xml:id="_TAN7pr5">
					<idno type="grant-number">R01NS125781</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43993-3_40.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tractogram filtering of anatomically non-plausible fibers with geometric deep learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Astolfi</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59728-3_29</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-59728-3_29" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12267</biblScope>
			<biblScope unit="page" from="291" to="301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">In vivo fiber tractography using DT-MRI data</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Basser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pajevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pierpaoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Duda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aldroubi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="625" to="632" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">PointNet: Deep learning on point sets for 3D classification and segmentation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Q</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kaichun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="77" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">White matter tracts are point clouds: neuropsychological score prediction and critical region localization via geometric deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16431-6_17</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16431-6_17" />
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer Assisted Intervention-MICCAI 2022. MICCAI 2022</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13431</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep fiber clustering: anatomically informed fiber clustering with self-supervised deep learning for fast and effective tractography parcellation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">273</biblScope>
			<biblScope unit="page">120086</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">TractGeoNet: A geometric deep learning framework for pointwise analysis of tract microstructure to predict language assessment performance</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<idno>arXiv 2307.0398</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deep fiber clustering: anatomically informed unsupervised deep learning for fast and effective white matter parcellation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87234-2_47</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87234-2_47" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12907</biblScope>
			<biblScope unit="page" from="497" to="507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">T</forename><surname>Xue</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A test-retest study on parkinson&apos;s PPMI dataset yields statistically significant white matter fascicles</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cousineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage Clin</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="222" to="233" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The developing human connectome project neonatal data release</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Edwards</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Neurosci</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">886772</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">3D slicer as an image computing platform for the quantitative imaging network</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fedorov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Imaging</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1323" to="1341" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">QuickBundles, a method for tractography simplification</title>
		<author>
			<persName><forename type="first">E</forename><surname>Garyfallidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Neurosci</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">175</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Recognition of white matter bundles using local and global streamline-based registration and clustering</title>
		<author>
			<persName><forename type="first">E</forename><surname>Garyfallidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">170</biblScope>
			<biblScope unit="page" from="283" to="295" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Robust and efficient linear registration of white-matter fascicles in the space of streamlines</title>
		<author>
			<persName><forename type="first">E</forename><surname>Garyfallidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ocegueda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wassermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Descoteaux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="124" to="140" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">FiberNET: an ensemble deep learning framework for clustering white matter fibers</title>
		<author>
			<persName><forename type="first">V</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">I</forename><surname>Thomopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Rashid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Thompson</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-66182-7_63</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-66182-7_63" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2017</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Descoteaux</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Maier-Hein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Franz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Jannin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Collins</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Duchesne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">10433</biblScope>
			<biblScope unit="page" from="548" to="555" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Segmentation of whole-brain tractography: a deep learning algorithm based on 3D raw curve points</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kumaralingam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Thanikasalam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sotheeswaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mahadevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ratnarajah</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16431-6_18</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16431-6_18" />
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer Assisted Intervention-MICCAI 2022. MICCAI 2022</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13431</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Filtering in tractography using autoencoders (FINTA)</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Legarreta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page">102126</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Clustering in tractography using autoencoders (CINTA)</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Legarreta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Diffusion MRI</title>
		<imprint>
			<biblScope unit="page" from="125" to="136" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">DeepRGVP: A novel Microstructure-Informed supervised contrastive learning framework for automated identification of the retinogeniculate pathway using dMRI tractography</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISBI</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">DeepBundle: fiber bundle parcellation with graph convolution neural networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Graph Learning in Medical Imaging</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="88" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">One-shot segmentation of novel white matter tracts via extensive data augmentation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ye</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16431-6_13</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16431-6_13" />
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer Assisted Intervention-MICCAI 2022. MICCAI 2022</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13431</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Rethinking network design and local geometry in point cloud: a simple residual MLP framework</title>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Filtered multitensor tractography</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Malcolm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1664" to="1675" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The parkinson progression marker initiative (PPMI)</title>
		<author>
			<persName><forename type="first">K</forename><surname>Marek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Prog. Neurobiol</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="629" to="635" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">TRAFIC: Fiber tract classification using deep learning</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Ngattai Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. SPIE Int. Soc. Opt. Eng</title>
		<imprint>
			<biblScope unit="volume">10574</biblScope>
			<biblScope unit="page">1057412</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">SlicerDMRI: open source diffusion MRI software for brain cancer research</title>
		<author>
			<persName><forename type="first">I</forename><surname>Norton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer Res</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">21</biblScope>
			<biblScope unit="page" from="101" to="e103" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">PointNet++: deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>NeurIPS</publisher>
			<biblScope unit="page" from="5105" to="5114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Joint Multi-Fiber NODDI parameter estimation and tractography using the unscented information filter</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rathi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Neurosci</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">166</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Superficial white matter bundle atlas based on hierarchical fiber clustering over probabilistic tractography data</title>
		<author>
			<persName><forename type="first">C</forename><surname>RomÃ¡n</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">262</biblScope>
			<biblScope unit="page">119550</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Registration-free analysis of diffusion MRI tractography data across subjects through the human lifespan</title>
		<author>
			<persName><forename type="first">V</forename><surname>Siless</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">214</biblScope>
			<biblScope unit="page">116703</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The WU-Minn human connectome project: an overview</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Van Essen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="62" to="79" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The conception of the ABCD study: from substance use to a broad NIH collaboration</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Volkow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dev. Cogn. Neurosci</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="4" to="7" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Dynamic graph CNN for learning on point clouds</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Solomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Accurate corresponding fiber tract segmentation via FiberGe-oMap learner</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Computing and Computer Assisted Intervention</title>
		<imprint>
			<biblScope unit="page" from="143" to="152" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">TractSeg -fast and accurate white matter tract segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wasserthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Neher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Maier-Hein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">183</biblScope>
			<biblScope unit="page" from="239" to="253" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Walk in the cloud: learning curves for point clouds shape analysis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A registration-and uncertainty-based framework for white matter tract segmentation with only one annotated subject</title>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISBI</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Objective detection of eloquent axonal pathways to minimize postoperative deficits in pediatric epilepsy surgery using diffusion tractography and convolutional neural networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1910" to="1922" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">SupWMA: Consistent and efficient tractography parcellation of superficial white matter with deep learning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISBI</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Superficial white matter analysis: an efficient point-cloud-based deep learning framework with supervised contrastive learning for consistent tractography parcellation across populations and dMRI acquisitions</title>
		<author>
			<persName><forename type="first">T</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page">102759</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">PointASNL: robust point clouds processing using nonlocal neural networks with adaptive sampling</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">3D medical point transformer: Introducing convolution to attention networks for medical point cloud analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<idno>arXiv 2112.04863</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">An anatomically curated fiber clustering white matter atlas for consistent white matter tract parcellation across the lifespan</title>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">179</biblScope>
			<biblScope unit="page" from="429" to="447" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Test-retest reproducibility of white matter parcellation using diffusion MRI tractography fiber clustering</title>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hum. Brain Mapp</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3041" to="3057" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Deep white matter analysis (DeepWMA): fast and consistent tractography segmentation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page">101761</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Quantitative mapping of the brain&apos;s structural connectivity using diffusion MRI tractography: a review</title>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">249</biblScope>
			<biblScope unit="page">118870</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Point transformer</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE/CVF International Conference on Computer Vision (ICCV</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
