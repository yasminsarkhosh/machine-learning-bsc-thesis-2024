<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Partial Vessels Annotation-Based Coronary Artery Segmentation with Self-training and Prototype Learning</title>
				<funder ref="#_MkmxusY">
					<orgName type="full">Intergovernmental Cooperation Project of the National Key Research and Development Program of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ministry of Education</orgName>
								<orgName type="laboratory">Key Laboratory of New Generation Artificial Intelligence Technology and Its Interdisciplinary Applications (Southeast University)</orgName>
								<address>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaolei</forename><surname>Zhang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Diagnostic Radiology</orgName>
								<orgName type="department" key="dep2">Medical School</orgName>
								<orgName type="institution" key="instit1">Jinling Hospital</orgName>
								<orgName type="institution" key="instit2">Nanjing University</orgName>
								<address>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yaolei</forename><surname>Qi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ministry of Education</orgName>
								<orgName type="laboratory">Key Laboratory of New Generation Artificial Intelligence Technology and Its Interdisciplinary Applications (Southeast University)</orgName>
								<address>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Guanyu</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ministry of Education</orgName>
								<orgName type="laboratory">Key Laboratory of New Generation Artificial Intelligence Technology and Its Interdisciplinary Applications (Southeast University)</orgName>
								<address>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Jiangsu Provincial Joint International Research Laboratory of Medical Information Processing</orgName>
								<orgName type="institution">Southeast University</orgName>
								<address>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory">Centre de Recherche en Information Biomédicale sino-français (CRIBs)</orgName>
								<address>
									<settlement>Strasbourg</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Partial Vessels Annotation-Based Coronary Artery Segmentation with Self-training and Prototype Learning</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="297" to="306"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">9EE643AC99B3867C03F6B11FCFAED74C</idno>
					<idno type="DOI">10.1007/978-3-031-43895-0_28</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-01T10:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Coronary artery segmentation</term>
					<term>Label-efficient learning</term>
					<term>Weakly supervised learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Coronary artery segmentation on coronary-computed tomography angiography (CCTA) images is crucial for clinical use. Due to the expertise-required and labor-intensive annotation process, there is a growing demand for the relevant label-efficient learning algorithms. To this end, we propose partial vessels annotation (PVA) based on the challenges of coronary artery segmentation and clinical diagnostic characteristics. Further, we propose a progressive weakly supervised learning framework to achieve accurate segmentation under PVA. First, our proposed framework learns the local features of vessels to propagate the knowledge to unlabeled regions. Subsequently, it learns the global structure by utilizing the propagated knowledge, and corrects the errors introduced in the propagation process. Finally, it leverages the similarity between feature embeddings and the feature prototype to enhance testing outputs. Experiments on clinical data reveals that our proposed framework outperforms the competing methods under PVA (24.29% vessels), and achieves comparable performance in trunk continuity with the baseline model using full annotation (100% vessels).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Coronary artery segmentation is crucial for clinical coronary artery disease diagnosis and treatment <ref type="bibr" target="#b3">[4]</ref>. Coronary-computed tomography angiography (CCTA), as a non-invasive technique, has been certified and recommended as established technology in the cardiological clinical arena <ref type="bibr" target="#b14">[15]</ref>. Thus, automatic coronary artery segmentation on CCTA images has become increasingly sought after as a means to enhance diagnostic efficiency for clinicians. In recent years, the performance of deep learning-based methods have surpassed that of conventional machine learning approaches (e.g. region growing) in coronary artery segmentation <ref type="bibr" target="#b3">[4]</ref>. Nevertheless, most of these deep learning-based methods highly depend on accurately labeled datasets, which need labor-intensive annotations. Therefore, there is a growing demand for relevant label-efficient learning algorithms for automatic coronary artery segmentation on CCTA images.</p><p>Label-efficient learning algorithms have garnered considerable interest and research efforts in natural and medical image processing <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b15">16]</ref>, while research on label-efficient coronary artery segmentation for CCTA images is slightly lagging behind. Although numerous label-efficient algorithms for coronary artery segmentation in X-ray angiograms have been proposed <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref>, only a few researches focus on CCTA images. Qi et al. <ref type="bibr" target="#b12">[13]</ref> proposed an elabrately designed EE-Net to achieve commendable performance with limited labels. Zheng et al. <ref type="bibr" target="#b21">[22]</ref> transformed nnU-Net into semi-supervised segmentation field as the generator of Gan, having achieved satisfactory performance on CCTA images. Most of these researches use incomplete supervision, which labels a subset of data. However, other types of weak supervision (e.g. inexact supervision), which are widely used in natural image segmentation <ref type="bibr" target="#b15">[16]</ref>, are seldom applied to coronary artery segmentation on CCTA images.</p><p>Different types of supervision are utilized according to the specific tasks. The application of various types of weak supervision are inhibited in coronary artery segmentation on CCTA images by the following challenges. 1) Difficult labeling (Fig. <ref type="figure" target="#fig_0">1(a)</ref>). The target regions are scattered, while manual annotation is drawn slice by slice on the planes along the vessels. Also, boundaries of branches and peripheral vessels are blurred. These make the annotating process timeconsuming and expertise-required. 2) Complex topology (Fig. <ref type="figure" target="#fig_0">1(b)</ref>). Coronary artery shows complex and slender structures, diameter of which ranges from 2 mm to 5 mm. The tree-like structure varies individually. Based on these challenges and the insight that vessels share local feature (Fig. <ref type="figure" target="#fig_0">1(b</ref>)), we propose partial vessels annotation and our framework as following.</p><p>Given the above, we propose partial vessels annotation (PVA) (Fig. <ref type="figure" target="#fig_0">1(c</ref>)) for CCTA images. While PVA is a form of partial annotation (PA) which has been adopted by a number of researches <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b17">18]</ref>, our proposed PVA differs from the commonly used PA methods. More specifically, PVA labels vessels continuously from the proximal end to the distal end, while the labeled regions of PA are typically randomly selected. Thus, our proposed PVA has two merits. 1) PVA balances efficiency and informativity. Compared with full annotation, PVA only requires clinicians to label vessels within restricted regions in adjacent slices, rather than all scattered target regions in each individual slice. Compared with PA, PVA keep labeled vessels continuous to preserve local topology information.</p><p>2) PVA provides flexibility for clinicians. Given that clinical diagnosis places greater emphasis on the trunks rather than the branches, PVA allows clinicians to focus their labeling efforts on vessels of particular interest. Therefore, our proposed PVA is well-suited for clinical use.</p><p>In this paper, we further propose a progressive weakly supervised learning framework for PVA. Our proposed framework, using PVA (only 24.29% vessels labeled), achieved better performance than the competing weakly supervised methods, and comparable performance in trunk continuity with the full annotation (100% vessels labeled) supervised baseline model. The framework works in two stages, which are local feature extraction (LFE) stage and global structure reconstruction (GSR) stage. 1) LFE stage extracts the local features of coronary artery from the limited labeled vessels in PVA, and then propagates the knowledge to unlabeled regions. 2) GSR stage leverages prediction consistency during the iterative self-training process to correct the errors, which are introduced inevitably by the label propagation process. The code of our method is available at https://github.com/ZhangZ7112/PVA-CAS.</p><p>To summarize, the contributions of our work are three-fold:</p><p>-To the best of our knowledge, we proposed partial vessels annotation for coronary artery segmentation for the first time, which is in accord with clinical use. First, it balances efficiency and informativity. Second, it provides flexibility for clinicians to annotate where they pay more attention. -We proposed a progressive weakly supervised learning framework for partial vessels annotation-based coronary artery segmentation. It only required 24.29% labeled vessels, but achieved comparable performance in trunk continuity with the baseline model using full annotation. Thus, it shows great potential to lower the label cost for relevant clinical and research use.</p><p>-We proposed an adaptive label propagation unit (LPU) and a learnable plugand-play feature prototype analysis (FPA) block in our framework. LPU integrates the functions of pseudo label initialization and updating, which dynamically adjusts the updating weights according to the calculated confidence level. FPA enhances vessel continuity by leveraging the similarity between feature embeddings and the feature prototype.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>As shown in Fig. <ref type="figure" target="#fig_1">2</ref>, our proposed framework for partial vessels annotation (PVA) works in two stages. 1) The LFE stage(Sect. 2.1) extracts and learns vessel features from PVA locally. After the learning process, it infers on the training set to propagate the learned knowledge to unlabeled regions, outputs of which are integrated with PVA labels to initialize pseudo labels.</p><p>2) The GSR stage (Sect. 2.2) utilizes pseudo labels to conduct self-training, and leverages prediction consistency to improve the pseudo labels. In our proposed framework, we also designed an adaptive label propagation unit (LPU) and a learnable plug-and-play feature prototype analysis (FPA) block. LPU initialize and update the pseudo labels; FPA block learns before testing and improves the final output during testing. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Local Feature Extraction Stage</head><p>In LFE stage, our hypothesis is that the small areas surrounding the labeled regions hold valid information. Based on this, a light segmentation model S l is trained to learn vessel features locally, with small patches centering around the labeled regions as input and output. In this manner, the negative impact of inaccurate supervision information in unlabeled regions is also reduced.</p><p>Pseudo Label Initialization in LPU. After training, S l propagates the learned knowledge of local feature to unlabeled regions. For each image of shape H × W × D, the corresponding output logit ŷ1 ∈ [0, 1] H×W ×D of S l provides a complete estimate of the distribution of vessels, albeit with some approximation. Meanwhile, the PVA label y P V A ∈ {0, 1} H×W ×D provides accurate information on the distribution of vessels, but only to a limited extent. Therefore, LPU integrate ŷ1 and y P V A to initialize the pseudo label y P L (Eq. 1), which will be utilized in GSR stage and updated during iterative self-training.</p><formula xml:id="formula_0">y (t=0) P L (h, w, d) ∀(h,w,d)∈R H×W ×D = 1, y P V A (h, w, d) = 1, ŷ1 (h, w, d), otherwise.</formula><p>(1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Global Structure Reconstruction Stage</head><p>The GSR stage mainly consists of three parts: 1) The segmentation model S g to learn the global tree-like structure; 2) LPU to improve pseudo labels; 3) FPA block to improve segmentation results at testing. Through initialization (Eq. 1), the initial pseudo label y (t=0) P L contains the information of both PVA labels and the knowledge of local features in S l . Therefore, at the beginning of this stage, S g learns from y (t=0) P L to warm up. After this, logits of S g are utilized to update the pseudo labels during iterative self-training.</p><p>Pseudo Label Updating in LPU. The principle of this process is that more reliable logit influences more the distribution of the corresponding pseudo label. Based on this principle, first we calculate the confidence degree η (t) ∈ [0, 1] for ŷ(t)</p><p>2 . Defined by Eq. 2, η (t) numerically equals to the average of the logits in labeled regions. This definition makes sense since the expected logit equals to ones in vessel regions and zeros in background regions. The closer ŷ(t) 2 gets to the expected logit, the higher η (t) (confidence degree) will be.</p><formula xml:id="formula_1">η (t) = h w d y P V A (h, w, d) • ŷ(t) 2 (h, w, d) h w d y P V A (h, w, d)<label>(2)</label></formula><p>Then, a quality control test is performed to avoid negative optimization as far as possible. As the confidence degree η (t) assesses the quality of predictions, which means low-confidence predictions are more likely to generate errors, our quality control test rejects low-confidence predictions to reduce the risk of error accumulation. If η (t) is higher than all elements in the set {η (i) } t-1 i=1 , the current logit is trustworthy to pass the test to improve the pseudo label. Then, y (t) P L is updated by the exponentially weighted moving average (EWMA) of the logits and the pseudo labels (Eq. 3). This process is similar to prediction ensemble <ref type="bibr" target="#b10">[11]</ref>, which hase been adopted to filter pseudo labels <ref type="bibr" target="#b8">[9]</ref>. However, different from their methods, where the factor η (t) is a fixed hyperparameter coefficient and the pseudo labels are updated each or every several epoches, η (t) in our method is adaptive. Our EWMA gradually diminishes the negative influence of existing errors through the weighted average of predictions across multiple phases.</p><formula xml:id="formula_2">y (t) P L = η (t) ŷ(t) 2 + (1 -η (t) )y (t-1) P L , η (t) = max{{η (i) } t i=1 } y (t-1) P L , otherwise. (<label>3</label></formula><formula xml:id="formula_3">)</formula><p>Feature Prototype Analysis Block. Inspired by <ref type="bibr" target="#b20">[21]</ref>, which generates class feature prototype ρ c (Eq. 4) from the embeddings z l i of labeled points in class c, we inherit the idea but further transform the mechanism into the proposed learnable plug-and-play block, FPA block. Experimental experience finds that the output of FPA block has good continuity, for which the FPA output are utilized to enhance the continuity of convolution output at testing.</p><formula xml:id="formula_4">ρ c = 1 |I c | z l i ∈Ic z l i (4)</formula><p>In the penultimate layer of the network, which is followed by a 1 × 1 × 1 convolutional layer to output logits, we parallelly put the feature map Z ∈ R C×H×W ×D into FPA. The output similarity map O ∈ R 1×H×W ×D is calculated by Eq. 5, where Z(h, w, d) ∈ R C denotes the feature embeddings of voxel (h, w, d), and ρ θ ∈ R C the kernel parameters of FPA.</p><formula xml:id="formula_5">O(h, w, d) = exp(-Z(h, w, d) -ρ θ 2 )<label>(5)</label></formula><p>The learning process of FPA block is before testing, during which the whole model except FPA gets frozen. To reduce the additional overhead, ρ θ is initialized by one-time calculated ρ c and fine-tuned with loss L fpa (Eq. 6), where only labeled voxels will take effect in updating the kernel.</p><formula xml:id="formula_6">L fpa = h w d y P V A (h, w, d) • log(O(h, w, d)) h w d y P V A (h, w, d)<label>(6)</label></formula><p>3 Experiments and Results</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset and Evaluation Metrics</head><p>Experiments are implemented on a clinical dataset, which includes 108 subjects of CCTA volumes (2:1 for training and testing). The volumes share the size of 512 × 512 × D, with D ranging from 261 to 608. PVA labels of the training set are annotated by clinicians, where only 24.29% vessels are labeled. The metrics used to quantify the results include both integrity and continuity assessment indicators. Integrity assessment indicators are Mean Dice Coefficient (Dice), Relevant Dice Coefficient (RDice) <ref type="bibr" target="#b12">[13]</ref>, Overlap (OV) <ref type="bibr" target="#b7">[8]</ref>; continuity assessment indicators are Overlap util First Error (OF) <ref type="bibr" target="#b13">[14]</ref> on the three main trunks (LAD, LCX and RCA).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Implementation Details</head><p>3D U-Net <ref type="bibr" target="#b2">[3]</ref> is set as our baseline model. Experiments were implemented using Pytorch on GeForce RTX 2080Ti. Adam optimizer was used to train the models with an initial learning rate of 10 -4 . The patch sizes were set as 128 × 128 × 128 and 512 × 512 × 256 respectively for S l and S g . When testing, sliding windows were used with a half-window width step to cover the entire volume.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Comparative Test</head><p>To verify the effectiveness of our proposed method, it is compared with both classic segmentation models (3D U-Net <ref type="bibr" target="#b2">[3]</ref>, HRNet <ref type="bibr" target="#b16">[17]</ref>, Transunet <ref type="bibr" target="#b0">[1]</ref>) and partial annotation-related weakly supervised frameworks (EWPA <ref type="bibr" target="#b11">[12]</ref>, DMPLS <ref type="bibr" target="#b9">[10]</ref>). The quantitative results of different methods are summarized in Table <ref type="table" target="#tab_0">1</ref>, which shows that our proposed method outperforms the competing methods under PVA. The competing frameworks (EWPA and DMPLS) had achieved the best results in their respective tasks under partial annotation, but our proposed method achieved better results for PVA-based coronary artery segmentation. It is worth mentioning that the performance in trunk continuity (measured by the indicator OF) of our proposed method using PVA (24.29% vessels labeled) is comparable to that of the baseline model using full annotation (100% vessels labeled).</p><p>The qualitative visual results verify that our proposed method outperforms the competing methods under PVA. Three cases are shown in Fig. <ref type="figure" target="#fig_2">3</ref>. All the cases show that the segmentation results of our method have good overall topology integrity, especially on trunk continuity. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Ablation Study</head><p>Ablation experiments were conducted to verify the importance of the components in our proposed framework (summarized in Table <ref type="table" target="#tab_1">2</ref>). The performance improvement verifies the effectiveness of pseudo label initialization (PLI) and updating (PLU) mechanisms in the label propagation unit (LPU). PLI integrates the information of PVA labels with the propagated knowledge, and PLU improves the pseudo labels during self-training. With the help of FPA block, the segmentation results gain further improvement, especially on the continuity of trunks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we proposed partial vessels annotation (PVA) for coronary artery segmentation on CCTA images. The proposed PVA is convenient for clinical use for the two merits, providing flexibility as well as balancing efficiency and informativity. Under PVA, we proposed a progressive weakly supervised learning framework, which outperforms the competing methods and shows comparable performance in trunk continuity with the full annotation supervised baseline model. In our framework, we also designed an adaptive label propagation unit (LPU) and a learnable plug-and-play feature prototype analysis(FPA) block. LPU integrates the functions of pseudo label initialization and updating, and FPA improves vessel continuity by leveraging the similarity between feature embeddings and the feature prototype. To conclude, our proposed framework under PVA shows great potential for accurate coronary artery segmentation while requiring significantly less annotation effort.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Motivation. (a) and (b) shows the two challenges of coronary artery segmentation, while (c) shows our proposed partial vessels annotation (PVA) according to the challenges. a) Coronary artery has blurred boundaries and scattered target regions. b) Coronary artery has complex overall topology but similar local feature. c) Partial vessels annotation (red) labels less regions than full annotation (overall). (Color figure online)</figDesc><graphic coords="3,55,98,54,53,340,18,117,19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Two-stage framework. LFE stage: 1) S l learns local features from the labeled vessels in PVA labels. 2) S l propagates the knowledge to unlabeled regions and LPU initializes the pseudo labels. GSR stage: 3) Sg learns the global structure from the pseudo labels. 4) LPU updates the pseudo labels if a quality control test is passed. 5) FPA improves the testing output after the iterative self-training process of (3) and (4).</figDesc><graphic coords="4,41,79,321,71,340,21,214,69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Visual comparison of the segmentation results under PVA. Green symbols (arrows and dotted frames) indicate higher-quality regions than yellow symbols. (Color figure online)</figDesc><graphic coords="8,42,30,122,30,339,82,177,55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Quantitative results of different methods under partial vessels annotation (PVA, 24.29% vessels labeled) or full annotation (FA, 100% vessels labeled).</figDesc><table><row><cell cols="2">Label Method</cell><cell>Dice(%)↑</cell><cell>RDice(%)↑ OV(%)↑</cell><cell>OF↑</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>LAD</cell><cell>LCX</cell><cell>RCA</cell></row><row><cell cols="5">PVA 3D U-Net [3] 60.60±7.09 69.45±7.82 62.24±6.43 0.647±0.335 0.752±0.266 0.747±0.360</cell></row><row><cell></cell><cell>HRNet [17]</cell><cell cols="3">48.72±7.16 52.31±7.96 37.81±6.61 0.490±0.297 0.672±0.301 0.717±0.356</cell></row><row><cell></cell><cell cols="4">Transunet [1] 63.08±6.42 71.97±7.38 61.21±6.40 0.669±0.274 0.762±0.243 0.728±0.362</cell></row><row><cell></cell><cell>EWPA [12]</cell><cell cols="3">55.41±6.15 61.54±6.83 60.48±5.17 0.659±0.334 0.759±0.286 0.749±0.364</cell></row><row><cell></cell><cell cols="4">DMPLS [10] 59.12±7.69 65.81±8.15 59.99±5.80 0.711±0.292 0.775±0.284 0.711±0.358</cell></row><row><cell></cell><cell>Ours</cell><cell cols="3">71.45±6.07 83.14±6.72 75.40±6.15 0.895±0.226 0.915±0.190 0.879±0.274</cell></row><row><cell>FA</cell><cell>3D U-Net</cell><cell cols="3">83.14±3.52 90.91±4.18 89.00±4.75 0.913±0.231 0.843±0.301 0.873±0.265</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Quantitative results of ablation analysis of different components. 43±7.20 81.70±6.92 72.13±5.94 0.873±0.227 0.860±0.223 0.808±0.334 71.45±6.07 83.14±6.72 75.40±6.15 0.895±0.226 0.915±0.190 0.879±0.274</figDesc><table><row><cell>Sl LPU</cell><cell>Sg FPA Dice(%)↑</cell><cell>RDice(%)↑ OV(%)↑</cell><cell>OF↑</cell></row><row><cell>PLI PLU</cell><cell></cell><cell></cell><cell>LAD</cell><cell>LCX</cell><cell>RCA</cell></row><row><cell></cell><cell cols="4">60.60±7.09 69.45±7.82 62.24±6.43 0.647±0.335 0.752±0.266 0.747±0.360</cell></row><row><cell></cell><cell cols="4">64.23±6.44 73.81±6.89 66.19±5.63 0.751±0.328 0.813±0.231 0.784±0.349</cell></row><row><cell></cell><cell>71.</cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements.. This research was supported by the <rs type="funder">Intergovernmental Cooperation Project of the National Key Research and Development Program of China</rs>(<rs type="grantNumber">2022YFE0116700</rs>). We thank the <rs type="institution">Big Data Computing Center of Southeast University</rs> for providing the facility support.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_MkmxusY">
					<idno type="grant-number">2022YFE0116700</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43895-0_28.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">TransUNet: transformers make strong encoders for medical image segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.04306</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Self-similarity student for partial label histopathology image segmentation</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-58595-2_8</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-58595-2_8" />
	</analytic>
	<monogr>
		<title level="m">ECCV 2020</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Bischof</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J.-M</forename><surname>Frahm</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12370</biblScope>
			<biblScope unit="page" from="117" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">3D U-Net: learning dense volumetric segmentation from sparse annotation</title>
		<author>
			<persName><forename type="first">Ö</forename><surname>Çiçek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abdulkadir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Lienkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-46723-8_49</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-46723-8_49" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2016</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Ourselin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Joskowicz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Sabuncu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Unal</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Wells</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">9901</biblScope>
			<biblScope unit="page" from="424" to="432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Towards automated coronary artery segmentation: a systematic review</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gharleghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sowmya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Beier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Methods Programs Biomed</title>
		<imprint>
			<biblScope unit="page">107015</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning better registration to learn better few-shot medical image segmentation: Authenticity, diversity, and robustness</title>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Dense biased networks with deep priori anatomy and hard region adaptation: semi-supervised learning for fine renal artery segmentation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page">101722</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deep multi-magnification networks for multi-class breast cancer image segmentation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Med. Imaging Graph</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page">101866</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Standardized evaluation framework for evaluating coronary artery stenosis detection, stenosis quantification and lumen segmentation algorithms in computed tomography angiography</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kirişli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="859" to="876" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Scribble2Label: scribble-supervised cell segmentation via self-generating pseudo-labels with consistency</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-K</forename><surname>Jeong</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59710-8_2</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-59710-8_2" />
	</analytic>
	<monogr>
		<title level="m">MIC-CAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12261</biblScope>
			<biblScope unit="page" from="14" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Scribble-supervised medical image segmentation via dual-branch network and dynamically mixed pseudo labels supervision</title>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16431-6_50</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16431-6_50" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13431</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Self: Learning to filter noisy labels with self-ensembling</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Mummadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P N</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Beggel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.01842</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Semi-supervised learning for semantic segmentation of emphysema with partial annotations</title>
		<author>
			<persName><forename type="first">L</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Biomed. Health Inform</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2327" to="2336" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Examinee-examiner network: weakly supervised accurate coronary lumen segmentation using centerline constraint</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="9429" to="9441" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Standardized evaluation methodology and reference database for evaluating coronary artery centerline extraction algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schaap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="701" to="714" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Coronary computed tomographic angiography for complete assessment of coronary artery disease: JACC state-of-the-art review</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Serruys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Coll. Cardiol</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="713" to="736" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A survey on label-efficient deep image segmentation: Bridging the gap between weak supervision and dense prediction</title>
		<author>
			<persName><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPAMI.2023.3246102</idno>
		<ptr target="https://doi.org/10.1109/TPAMI.2023.3246102" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep high-resolution representation learning for human pose estimation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5693" to="5703" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">PA-Seg: learning from point annotations for 3D medical image segmentation using contextual regularization and cross knowledge distillation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1109/TMI.2023.3245068</idno>
		<ptr target="https://doi.org/10.1109/TMI.2023.3245068" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="2235" to="2246" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">SS-CADA: a semi-supervised crossanatomy domain adaptation for coronary artery segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1227" to="1231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Weakly supervised vessel segmentation in x-ray angiograms by self-paced learning from noisy labels with suggestive annotation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">417</biblScope>
			<biblScope unit="page" from="114" to="127" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Weakly supervised semantic segmentation for large-scale point cloud</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="3421" to="3429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">UGAN: semi-supervised medical image segmentation using generative adversarial network</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 15th International Congress on Image and Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
		<respStmt>
			<orgName>CISP-BMEI</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
