<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">NeuroExplainer: Fine-Grained Attention Decoding to Uncover Cortical Development Patterns of Preterm Infants</title>
				<funder ref="#_GVfmV6H">
					<orgName type="full">NSFC</orgName>
				</funder>
				<funder ref="#_EqvhN2f">
					<orgName type="full">STI 2030-Major Projects</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Chenyu</forename><surname>Xue</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Mathematics and Statistics</orgName>
								<orgName type="institution">Xi&apos;an Jiaotong University</orgName>
								<address>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fan</forename><surname>Wang</surname></persName>
							<email>fan.wang@xjtu.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="department">School of Life Science and Technology</orgName>
								<orgName type="laboratory">Key Laboratory of Biomedical Information Engineering of Ministry of Education</orgName>
								<orgName type="institution">Xi&apos;an Jiaotong University</orgName>
								<address>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuanzhuo</forename><surname>Zhu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Life Science and Technology</orgName>
								<orgName type="laboratory">Key Laboratory of Biomedical Information Engineering of Ministry of Education</orgName>
								<orgName type="institution">Xi&apos;an Jiaotong University</orgName>
								<address>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hui</forename><surname>Li</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Neonatology</orgName>
								<orgName type="institution">The First Affiliated Hospital of Xi&apos;an Jiaotong University</orgName>
								<address>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Deyu</forename><surname>Meng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Mathematics and Statistics</orgName>
								<orgName type="institution">Xi&apos;an Jiaotong University</orgName>
								<address>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dinggang</forename><surname>Shen</surname></persName>
							<email>dgshen@shanghaitech.edu.cn</email>
							<affiliation key="aff3">
								<orgName type="department">School of Biomedical Engineering</orgName>
								<orgName type="institution">ShanghaiTech University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chunfeng</forename><surname>Lian</surname></persName>
							<email>chunfeng.lian@xjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Mathematics and Statistics</orgName>
								<orgName type="institution">Xi&apos;an Jiaotong University</orgName>
								<address>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">NeuroExplainer: Fine-Grained Attention Decoding to Uncover Cortical Development Patterns of Preterm Infants</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="202" to="211"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">1AC483DDD1BEDA853BDBA0DF84B4614D</idno>
					<idno type="DOI">10.1007/978-3-031-43895-0_19</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-01T10:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In addition to model accuracy, current neuroimaging studies require more explainable model outputs to relate brain development, degeneration, or disorders to uncover atypical local alterations. For this purpose, existing approaches typically explicate network outputs in a post-hoc fashion. However, for neuroimaging data with high dimensional and redundant information, end-to-end learning of explanation factors can inversely assure fine-grained explainability while boosting model accuracy. Meanwhile, most methods only deal with gridded data and do not support brain cortical surface-based analysis. In this paper, we propose an explainable geometric deep network, the NeuroExplainer, with applications to uncover altered infant cortical development patterns associated with preterm birth. Given fundamental cortical attributes as network input, our NeuroExplainer adopts a hierarchical attention-decoding framework to learn fine-grained attention and respective discriminative representations in a spherical space to accurately recognize preterm infants from term-born infants at term-equivalent age. NeuroExplainer learns the hierarchical attention-decoding modules under subject-level weak supervision coupled with targeted regularizers deduced from domain knowledge regarding brain development. These prior-guided constraints implicitly maximize the explainability metrics (i.e., fidelity, sparsity, and stability) in network training, driving the learned network to output detailed explanations and accurate classifications. Experimental results on the public dHCP benchmark suggest that NeuroExplainer led to quantitatively reliable explanation results that are qualitatively consistent with representative neuroimaging studies. The source code will be released on https://github.com/ladderlab-xjtu/NeuroExplainer.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>One important task for the neuroscience community is to study atypical alterations in cortices associated with brain development, degeneration, or disorders. For this aim, recent approaches, namely interpretable and explainable deep learning, rely on the training of diagnostic or predictive deep learning models <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b11">12]</ref> with interpretable computations and explainable results. For the aspect of preterm birth, the classification task to differentiate between preterm and term-born infants can help distinguish fine-grained differences on brain cortical surfaces, providing valuable factors for better understanding featured infantile brain development patterns related to different factors.</p><p>Although explainable deep learning methods are being actively studied in the machine learning community, they have two challenges when applying to neuroimaging data. First, existing methods typically adopt post-hoc techniques to explain a deep network <ref type="bibr" target="#b12">[13]</ref>, which is first trained for a specific classification task, and then the underlying (sparse) correlations between its input and output are analyzed offline, e.g., by backpropagating prediction gradients to the shallow layers <ref type="bibr" target="#b7">[8]</ref>. Notably, such post-hoc approaches are established upon a common assumption that reliable explanations are the results caused by accurate predictions. This assumption could work in general applications that have largescale training data, while cannot always hold for neuroimaging and neuroscience research, where available data are typically small-sized and much more complex (e.g., high-resolution cortical surfaces containing noisy, highly redundant, and task-irrelevant information). Second, most of these methods works on gridded data (e.g., images) <ref type="bibr" target="#b1">[2]</ref>, and does not handle 3D meshes (e.g., brain cortical surfaces) <ref type="bibr" target="#b12">[13]</ref>. For these type of data, advanced geometric deep learning methods or mapping original meshes onto a spherical surface <ref type="bibr" target="#b13">[14]</ref> suggested promising accuracies in multiple tasks (e.g., parcellation <ref type="bibr" target="#b13">[14]</ref>, registration <ref type="bibr" target="#b8">[9]</ref>, and longitudinal prediction <ref type="bibr" target="#b3">[4]</ref>), yet the learned models typically lack explainability.</p><p>This paper presents an explainable geometric deep network, called NeuroExplainer, with applications to uncover altered infant cortical development patterns associated with preterm birth. NeuroExplainer adopts high-resolution cortical attributes as the input to develop a hierarchical attention-decoding architecture working in the sperical space. Distinct to existing post-hoc methods, the NeuroExplainer is constructed as an end-to-end framework, where finegrained explanation factors can be identified in a fully learnable fashion. Our network take advantage of the explainability to boost classification for the highdimensional neuroimaging data. Specifically, in the framework of weakly supervised discriminative localization, our NeuroExplainer is trained by minimizing general classification losses coupled with a set of constraints designed according to prior knowledge regarding brain development. These targeted regularizers drive the network to implicitly optimize the explainability metrics from multiple aspects (i.e., fidelity, sparsity, and stability), thus capturing fine-grained explanation factors to explicitly improve classification accuracies. Experimental results on the public dHCP benchmark suggest that our NeuroExplainer led to quantitatively reliable explanation results that are qualitatively consistent with representative neuroimaging studies, implying that it could be a practically useful AI tool for other related cortical surface-based neuroimaging studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>As the schematic diagram shown in Fig. <ref type="figure" target="#fig_0">1</ref>, our NeuroExplainer works on the highresolution spherical surfaces of both brain hemispheres (each with 10, 242 vertices). The inputs are fundamental vertex-wise cortical attributes, i.e., thickness, mean curvature, and convexity. The architecture has two main parts, including an encoding branch to produce initial task-related attentions on down-sampled hemispheric surfaces, and a set of attention decoding blocks to hierarchically propagate such vertex-wise attentions onto higher-resolution spheres, finally capturing fine-grained explanation factors on the input high-resolution surfaces to boost the prediction task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Spherical Attention Encoding</head><p>The starting components of the encoding branch are four spherical convolution blocks (i.e., EB-1 to EB-4 in Fig. <ref type="figure" target="#fig_0">1</ref>), with the learnable parameters shared across two hemispheric surfaces. Each EB adopts 1-ring hexagonal convolution <ref type="bibr" target="#b13">[14]</ref> followed by batch normalization (BN) and ReLU activation to extract vertexwise representations, which are then downsampled by hexagonal max pooling <ref type="bibr" target="#b13">[14]</ref> (except in EB-4) to serve as the input of the subsequent layer. Based on the outputs from EB, we propose a learnable spherical attention mechanism to conduct weakly-supervised discriminative localization.</p><p>Specifically, let F l and F r ∈ R 162×M0 be the vertex-wise representations (produced by EB-4) for the left and right hemispheres, respectively. We first concatenate them as a 324 × M 0 matrix, on which a self-attention operation <ref type="bibr" target="#b10">[11]</ref> is applied to capturing cross-hemisphere long-range dependencies to refine the vertex-wise representations from both hemispheric surfaces, resulting in a unified feature matrix denoted as F 0 = [ Fl ; Fr ] ∈ R 324×M0 . As shown in Fig. <ref type="figure" target="#fig_0">1</ref>, F 0 is further global average pooled (GAP) across all vertices to be a holistic feature vector f 0 ∈ R 1×M0 representing the whole cerebral cortex. Both F 0 and f 0 are then mapped by a same vertex-wise 1D convolution (i.e., W 0 ∈ R M0×2 , without bias) into the categorical space, denoted as A 0 = [A l 0 ; A r 0 ] ∈ R 324×2 and s 0 , respectively. Notably, s o is supervised by the one-hot code of subject's categorical label, by which A l 0 and A r 0 highlight discriminative vertices on the (down-sampled) left and right surfaces, respectively, considering that</p><formula xml:id="formula_0">s 0 [i] ∝ 1 T F 0 W 0 [:, i] = 1 T [ Fl ; Fr ]W 0 [:, i] = 1 T A l 0 [:, i] + 1 T A r 0 [:, i],</formula><p>(1) where s o [i] (i = 0 or 1) in our study denote the prediction scores of preterm and fullterm, respectively, and 1 is an unit vector having the same row size with the subsequent matrix. Finally, we define the hemispheric attentions as</p><formula xml:id="formula_1">Āl 0 = 1 i=0 s 0 [i]A l 0 [:, i] and Ār 0 = 1 i=0 s 0 [i]A r 0 [:, i] ∈ R 324×1</formula><p>, respectively, with values spatially varying and depending on the relevance to subject's category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Hierarchically Spherical Attention Decoding</head><p>The explanation factors captured by the encoding branch are relatively coarse, as the receptive field of a cell on the downsampled surfaces (with 162 vertices after three pooling operations) is no smaller than a hexagonal region of 343 cells on the input surfaces (with 10, 242 vertices). To tackle this challenge, we design a spherical attention decoding strategy to hierarchically propagate coarse attentions (from lower-resolution spheres) onto higher-resolution spheres, based on which fine-grained attentions are finally produced to improve classification. Specifically, NeuroExplainer contains three consecutive decoding blocks (i.e., DB-1 to DB-3 in Fig. <ref type="figure" target="#fig_0">1</ref>). Each DB adopts both the attention-gated discriminative representations from the preceding DB (except DB-1 that uses EB-4 outputs) and the local-detailed representations from the symmetric EB (at the same resolution) as the input. Let the attention-gated representations from the preceding DB be</p><formula xml:id="formula_2">F l G = Āl in 1 1×Min Fl in and F r G = Ār in 1 1×Min</formula><p>Fr in , respectively, where each row of Fin has M in channels, and denotes element-wise dot product. We first upsample F l G and F r G to the spatial resolution of the current DB, by using hexagonal transposed convolutions <ref type="bibr" target="#b13">[14]</ref> with learnable weights shared across hemispheres. Then, the upsampled discriminative representations from each hemisphere (say Fl G and Fr G ) are channel-wisely concatenated with the local representations from the corresponding EB (say F l E and F r E ), followed by an 1-ring convolution to produce a unified feature matrix, such as</p><formula xml:id="formula_3">F D = [C θ ( Fl G ⊕ F l E ); C θ ( Fr G ⊕ F r E )],<label>(2)</label></formula><p>where C θ (•) denotes 1-ring conv parameterized by θ, and ⊕ stands for channel concatenation. In terms of F D , the attention mechanism described in (1) is further applied to producing refined spherical attentions and classification scores.</p><p>Finally, as shown in Fig. <ref type="figure" target="#fig_0">1</ref>, based on the fine-grained attentions over the input surfaces (each with 10, 242 vertices), we use GAP to aggregate the attentiongated representations and apply an 1D conv to output the classification score. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Domain Knowledge-Guided Explanation Enhancement</head><p>To perform task-oriented learning of explanation factors, we design a set of targeted regularization strategies by considering fundamental domain knowledge regarding infant brain development. Specifically, according to existing studies, we assume that human brains in infancy have generally consistent developments, while the structural/functional discrepancies between different groups (e.g., preterm and term-born) are typically rationalized <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b9">10]</ref>. Accordingly, we require the preterm-altered cortical development patterns captured by our NeuroExplainer to be discriminative, spatially sparse, and robust, which suggests the design of the following constraints that concurrently optimize fidelity, sparsity, and stability metrics <ref type="bibr" target="#b12">[13]</ref> in deploying an explainable deep network.</p><p>Explanation Fidelity-Aware Contrastive Learning. Given the spherical attention block at a specific resolution, we have A + i and A - j ∈ R V ×1 as the output attentions for a positive and negative subjects (i.e., preterm and fullterm infants in our study), respectively, and F + i and F - j ∈ R V ×M are the corresponding representation matrices. Based on the prior knowledge regarding infant brain development, it is reasonable to assume that A + i highlights atypically-developed cortical regions caused by preterm birth. In contrast, the remaining part of the cerebral cortex of a preterm infant (corresponding to 1 -A + i ) still growths normally, i.e., looking globally similar to the cortex of a term-born infant.</p><p>Accordingly, as the illustration shown in Fig. <ref type="figure" target="#fig_1">2</ref>(a), we design a fidelityaware contrastive penalty to regularize the learning of the attention maps and associated representations to improve their discriminative power. Let</p><formula xml:id="formula_4">f + i = 1 T A + i 1 1×M F + i and f + i = 1 T {1 -A + i }1 1×M F + i</formula><p>be the holistic feature vector and its inverse for the ith (positive) sample, respectively. Similarly,</p><formula xml:id="formula_5">f - j = 1 T A - j 1 1×M F - j</formula><p>denotes the holistic feature vector for the compared jth (negative) sample. By pushing f + i away from both f + i and f - j , while pulling f + i close to f - j , we define the respective loss as</p><formula xml:id="formula_6">L contra = N i =j || f + i -f - j ||+max(m-|| f + i -f + i ||, 0)+max(m-||f - j -f + i ||, 0),<label>(3)</label></formula><p>where i and j indicate any a pair of positive and negative cases from totally N training samples, and m is a margin setting as 1 in our implementation.</p><p>Explanation Sparsity-Aware Regularization. According to the specified prior knowledge regarding infant brain development, the attention maps produced by our NeuroExplainer should have two featured properties in terms of sparsity. That is, the attention map for a preterm infant (e.g., A + i ) should be sparse, considering that altered cortical developments are assumed to be localized. In contrast, the attention map for a healthy term-born infant (e.g., A - j ) should not be spatially informative, as all brain regions growth typically without abnormality. To this end, we design a straightforward entropy-based regularization to enhance results' explainability, such as</p><formula xml:id="formula_7">L entropy = N i =j 1 T A + i log(A + i ) -A - j log(A - j ) , (<label>4</label></formula><formula xml:id="formula_8">)</formula><p>where i and j indicate a positive and a negative cases from totally N training samples, respectively, and 1 is an unit vector to sum up the values of all vertices.</p><p>Explanation Stability-Aware Regularization. We enhance the explanation stability of our NeuroExplainer from two aspects. First, we require the spherical attention mechanisms to robustly decode from complex cortical-surface data finegrained explanation factors to produce accurate predictions. To this end, we randomize the surface coarsening step by quantifying a vertex's cortical attributes (on the downsampled surface) as the average of a random subset of the vertices from the respective hexagonal region of the highest-resolution surface, such as the examples summarized in Fig. <ref type="figure" target="#fig_1">2(b</ref>). Considering that the network is trained to produce consistently accurate predictions for all these variants with perturbations, it inversely enhances the stability of learned explanation factors.</p><p>Second, as described in Sect. 2.2, we design a cross-scale consistency regularization to refine the decoding branch. Specifically, let A l i and A h i be the spherical attentions from two different DB blocks. We simply minimize</p><formula xml:id="formula_9">L consistent = N i=1 A l i -A h i 2 ,<label>(5)</label></formula><p>which encourages spherical attentions at different resolutions to be consistent.</p><p>Implementation Details. In our implementation, the feature representations produced by EB-1 to EB-4 in Fig. <ref type="figure" target="#fig_0">1</ref> have 32, 64, 128, and 256 channels, respectively. Correspondingly, DB-1 to DB-3, and the final classification layer have 256, 128, 64, and 32 channels, respectively. The network was trained end-to-end by minimizing the cross-entropy classification losses defined at three different spatial resolutions (overall denoted as L CE ), coupled with the regularization terms introduced in Sec. 2.3, such as</p><formula xml:id="formula_10">L = L CE + λ 1 L contrast + λ 2 L entropy + λ 3 L consistent ,<label>(6)</label></formula><p>where the tuning parameters were empirically set as λ 1 = 0.2, λ 3 = 0.5, and λ 3 = 0.1. The network parameters were updated by using Adam optimizer for 500 epochs, with the initial learning rate setting as 0.001 and bath size as 20.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>Dataset and Experimental Setup. We conducted experiments on the dHCP benchmark <ref type="bibr" target="#b4">[5]</ref>.   For classification, our NeuroExplainer was compared with three representative geometric networks, including a spherical network based on 1-ring convolution (SphericalCNN) <ref type="bibr" target="#b13">[14]</ref>, a MoNet reimplementation working on spherical surfaces (SphericalMoNet) <ref type="bibr" target="#b8">[9]</ref>, and SubdivNet <ref type="bibr" target="#b2">[3]</ref> working on original meshes. The classification performance was quantified in terms of accuracy (ACC), area under the ROC curve (AUC), sensitivity (SEN), and specificity (SPE).</p><p>On the other hand, the explanation performance of our NeuroExplainer was compared with two representative feature-based explanation approaches, i.e., CAM <ref type="bibr" target="#b14">[15]</ref> and Grad-CAM <ref type="bibr" target="#b6">[7]</ref>. The explanation performance was quantitatively evaluated in terms of three metrics <ref type="bibr" target="#b12">[13]</ref>, i.e., Fidelity, Sparsity, and Stability. Please refer to <ref type="bibr" target="#b12">[13]</ref> for more details regarding these metrics.</p><p>Classification Results. The classification results obtained by different competing methods are summarized in Table <ref type="table" target="#tab_0">1</ref>, from which we can have at least two observations. 1) Our NeuroExplainer consistently led to better classification accuracies in terms of all metrics (especially SEN and AUC), suggesting that it can reliably identify featured development patterns associated with preterm birth to make accurate predictions in such an imbalanced learning task. 2) These results imply that our idea to capture fine-grained explanation factors in an endto-end fashion to boost discriminative representation extraction is beneficial for deploying an accurate classification model. 3) To check the efficacy of the prior-induced regularization strategies, we orderly removed them from the loss function (6) to quantify the respective influences. From Table <ref type="table" target="#tab_0">1</ref>, we can see that all the three regularizations demonstrated significant but different improvements on classification, implying their complementary roles in boosting explainable representation learning.</p><p>Explanation Results. The quantitative explanation results are summarized in Table <ref type="table">2</ref>. Notably, the three metrics should be analyzed concurrently in evaluating a network's explainability <ref type="bibr" target="#b12">[13]</ref>, as the isolated quantification of a single metric could be biased. From Table <ref type="table">2</ref>, we can observe that our NeuroExplainer led to significantly better Fidelity and Stability, under reasonable Sparsity, suggesting that it can robustly identify rationalized preterm-altered cortical patterns from high-dimensional inputs for preterm infant recognition. Also, we visually compared the attention maps produced by different competing methods, with two typical examples presented in Fig. <ref type="figure" target="#fig_2">3</ref>. From Fig. <ref type="figure" target="#fig_2">3</ref>, we can see that, compared with post-hoc explanation methods, our end-to-end NeuroExplainer stably produced more reasonable attentions. For example, our NeuroExplainer led to group-wisely more consistent explanations across subjects. Also, it produced more consistent results across hemispheres, without using any related training constraints.</p><p>Finally, we compared the individualized preterm-altered cortical development patterns uncovered by our NeuroExplainer with representative group-wise multimodal (dMRI and sMRI) quantitative analyses presented in <ref type="bibr" target="#b0">[1]</ref>. As shown in Fig. <ref type="figure" target="#fig_3">4</ref>, we can see that our observations in this paper are consistent with <ref type="bibr" target="#b0">[1]</ref>. The discriminative cortical regions captured by our NeuroExplainer (using solely morphological features) are largely overlapped with the group-wise significantly different regions identified by <ref type="bibr" target="#b0">[1]</ref> in terms of the mean diffusivity, neurite density, and cortical thickness, respectively. For example, they both highlighted some specific regions in the inferior parietal, medial occipital, and superior temporal lobe, and posterior insula, which is worth deeper evaluations in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In the paper, we have proposed an geometric deep network, i.e., NeuroExplainer, to learn fine-grained explanation factors from complex cortical-surface data to boost discriminative representation extraction and accurate classification model construction. On the benchmark dHCP database, our NeuroExplainer achieved better performance than existing post-hoc approaches in terms of both explainability and prediction accuracy, in uncovering preterm-altered infant cortical development patterns. The proposed method could be a promising AI tool applied to other similar cortical surface-based neuroimage and neuroscience studies.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The schematic diagram of our NeuroExplainer architecture and Spherical attention mechanism. Our NeuroExplainer learns to capture fine-grained by Spherical attention mechanism explanation factors to boost discriminative representation extraction.</figDesc><graphic coords="3,44,79,53,84,334,57,107,86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Brief illustrations of (a) the explanation fidelity-aware contrastive learning strategy, and (b) explanation stability-aware data augmentation strategy.</figDesc><graphic coords="5,56,79,54,26,310,36,85,45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Typical examples of the explanation factors captured by different methods. Higher values indicate larger links to preterm birth.</figDesc><graphic coords="8,62,10,69,86,331,48,80,50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Comparison of the individualized preterm-altered developments uncovered by NeuroExplainer with the group-wise multi-modal studies [1].</figDesc><graphic coords="8,69,96,212,66,310,57,67,09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>The structural MRIs of 700 infants scanned at term-equivalent ages (35-44 weeks postmenstrual age) were studied, including 143 preterm and 557 term-born infants. These subjects were randomly split as a training set of 500 infants (89 preterm and 411 fullterm), and a test set of the remaining 200 infants (54 preterm and 146 fullterm), where test and training sets were from different subjects. Using the data-augmentation strategy described in Sect. 2.3, the training set was augmented to have roughly 1, 250 subjects from each category for balanced network training. The input spherical surfaces contain 10, 242 vertices, and each of them has three morphological attributes, i.e., cortical thickness, mean curvature, and convexity. Classification results obtained by the competing geometric deep networks and different variants of our NeuroExplainer.</figDesc><table /></figure>
		</body>
		<back>

			<div type="funding">
<div><p>Funding. This work was supported in part by <rs type="funder">NSFC</rs> Grants (Nos. <rs type="grantNumber">62101431 &amp; 62101430</rs>), and <rs type="funder">STI 2030-Major Projects</rs> (No. <rs type="grantNumber">2022ZD0209000</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_GVfmV6H">
					<idno type="grant-number">62101431 &amp; 62101430</idno>
				</org>
				<org type="funding" xml:id="_EqvhN2f">
					<idno type="grant-number">2022ZD0209000</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Competing Mehtods</head><p>ACC AUC SEN SPE SphericalCNN <ref type="bibr" target="#b13">[14]</ref> 0.93 0.92 0.76 0.98 SphericalMoNet <ref type="bibr" target="#b8">[9]</ref> 0.85 0.93 0.65 0.92 SubdivNet <ref type="bibr" target="#b2">[3]</ref> 0 </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Preterm birth alters the development of cortical microstructure and morphology at term-equivalent age</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dimitrova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">243</biblScope>
			<biblScope unit="page">118488</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Techniques for interpretable machine learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="68" to="77" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Subdivision-based mesh convolution networks</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph. (TOG)</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep modeling of growth trajectories for longitudinal prediction of missing infant cortical surfaces</title>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-T</forename><surname>Yap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-20351-1_21</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-20351-1_21" />
	</analytic>
	<monogr>
		<title level="m">IPMI 2019</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">C S</forename><surname>Chung</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Gee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Yushkevich</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Bao</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11492</biblScope>
			<biblScope unit="page" from="277" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The developing human connectome project: a minimal processing pipeline for neonatal cortical surface reconstruction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Makropoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="page" from="88" to="112" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Self-supervised learning of neighborhood embedding for longitudinal MRI</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Adeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zaharchuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Pohl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page">102571</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Gradcam: Visual explanations from deep networks via gradient-based localization</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Selvaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cogswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vedantam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="618" to="626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Smilkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Thorat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Viégas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.03825</idno>
		<title level="m">Smoothgrad: removing noise by adding noise</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A deep-discrete learning framework for spherical surface registration</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Suliman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Z</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fawaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Robinson</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16446-0_12</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16446-0_12" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13436</biblScope>
			<biblScope unit="page" from="119" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Tracking regional brain growth up to age 13 in children born term and very preterm</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A deep learning framework identifies dimensional representations of Alzheimers disease from brain structure</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Explainability in graph neural networks: a taxonomic survey</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5782" to="5799" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<author>
			<persName><forename type="first">F</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-20351-1_67</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-20351-1_67" />
	</analytic>
	<monogr>
		<title level="m">Spherical U-net on cortical surfaces: methods and applications</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">C S</forename><surname>Chung</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Gee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Yushkevich</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Bao</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11492</biblScope>
			<biblScope unit="page" from="855" to="866" />
		</imprint>
	</monogr>
	<note>IPMI 2019</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning deep features for discriminative localization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2921" to="2929" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
