<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Content-Preserving Diffusion Model for Unsupervised AS-OCT Image Despeckling</title>
				<funder ref="#_UpesE2A">
					<orgName type="full">Shenzhen Natural Science Fund</orgName>
				</funder>
				<funder ref="#_WQqJz2c">
					<orgName type="full">General Program of National Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_HFwgDnP">
					<orgName type="full">A*STAR Advanced Manufacturing and Engineering</orgName>
					<orgName type="abbreviated">AME</orgName>
				</funder>
				<funder ref="#_mk7PY6U">
					<orgName type="full">Guangdong Provincial Department of Education</orgName>
				</funder>
				<funder ref="#_E3WezsQ">
					<orgName type="full">A*STAR Central Research Fund</orgName>
					<orgName type="abbreviated">CRF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Sanqian</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution" key="instit1">Research Institute of Trustworthy Autonomous Systems</orgName>
								<orgName type="institution" key="instit2">Southern University of Science and Technology</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Risa</forename><surname>Higashita</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution" key="instit1">Research Institute of Trustworthy Autonomous Systems</orgName>
								<orgName type="institution" key="instit2">Southern University of Science and Technology</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Tomey Corporation</orgName>
								<address>
									<settlement>Nagoya</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Huazhu</forename><surname>Fu</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Agency for Science, Technology and Research</orgName>
								<orgName type="institution">Institute of High-Performance Computing</orgName>
								<address>
									<country>Singapore, Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Heng</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution" key="instit1">Research Institute of Trustworthy Autonomous Systems</orgName>
								<orgName type="institution" key="instit2">Southern University of Science and Technology</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jingxuan</forename><surname>Niu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution" key="instit1">Research Institute of Trustworthy Autonomous Systems</orgName>
								<orgName type="institution" key="instit2">Southern University of Science and Technology</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Jiang</forename><surname>Liu</surname></persName>
							<email>liuj@mail.sustech.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution" key="instit1">Research Institute of Trustworthy Autonomous Systems</orgName>
								<orgName type="institution" key="instit2">Southern University of Science and Technology</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Content-Preserving Diffusion Model for Unsupervised AS-OCT Image Despeckling</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">15EED8432F8DAB0FE09C2B75AE631B9C</idno>
					<idno type="DOI">10.1007/978-3-031-43990-262.</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-13T19:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>ASOCT</term>
					<term>Unsupervised despeckling</term>
					<term>Diffusion model</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Anterior segment optical coherence tomography (AS-OCT) is a non-invasive imaging technique that is highly valuable for ophthalmic diagnosis. However, speckles in AS-OCT images can often degrade the image quality and affect clinical analysis. As a result, removing speckles in AS-OCT images can greatly benefit automatic ophthalmology analysis. Unfortunately, challenges still exist in deploying effective AS-OCT image denoising algorithms, including collecting sufficient paired training data and the requirement to preserve consistent content in medical images. To address these practical issues, we propose an unsupervised AS-OCT despeckling algorithm via Content Preserving Diffusion Model (CPDM) with statistical knowledge. At the training stage, a Markov chain transforms clean images to white Gaussian noise by repeatedly adding random noise and removes the predicted noise in a reverse procedure. At the inference stage, we first analyze the statistical distribution of speckles and convert it into a Gaussian distribution, aiming to match the fast truncated reverse diffusion process. We then explore the posterior distribution of observed images as a fidelity term to ensure content consistency in the iterative procedure. Our experimental results show that CPDM significantly improves image quality compared to competitive methods. Furthermore, we validate the benefits of CPDM for subsequent clinical analysis, including ciliary muscle (CM) segmentation and scleral spur (SS) localization.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Anterior segment optical coherence tomography (AS-OCT) is a widely used noninvasive imaging modality for ocular disease <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. It produces high-resolution views of superficial anterior segment structures, such as the cornea, iris, and ciliary body. However, speckle noise inherently exists in AS-OCT imaging systems <ref type="bibr" target="#b2">[3]</ref>, which can introduce uncertainty in clinical observations and increase the risk of misdiagnosis. AS-OCT despeckling has become an urgent pre-processing task that can benefit clinical studies.</p><p>To suppress speckle noise in AS-OCT images, commercial scanners <ref type="bibr" target="#b3">[4]</ref> generally average repeated scans at the same location. However, this approach can result in artifacts due to uncontrollable movement. As a result, several postprocessing denoising approaches have been developed to reduce speckles, such as wavelet-modified block-matching and 3D filters <ref type="bibr" target="#b4">[5]</ref>, anisotropic non-local means filters <ref type="bibr" target="#b5">[6]</ref>, and complex wavelets combined with the K-SVD method <ref type="bibr" target="#b6">[7]</ref>. However, these algorithms can lead to edge distortion depending on the aggregation of similar patches. Deep learning has recently been employed for medical image processing, especially, with promising performance for image denoising tasks <ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref>. To overcome the limitations caused by the requirement for vast supervised paired data, unsupervised algorithms explore some promising stages to loosen the paired clinical data collection, including cycle consistency loss <ref type="bibr" target="#b10">[11]</ref>, contrast learning strategies <ref type="bibr" target="#b11">[12]</ref>, simulated schemes <ref type="bibr" target="#b12">[13]</ref>, or the Bayesian model <ref type="bibr" target="#b13">[14]</ref>. Alternatively, the denoising diffusion probabilistic model (DDPM) can use the averaged image of repeated collections to train the model with excellent performance due to its focus on the noise pattern rather than the signal <ref type="bibr" target="#b14">[15]</ref>. Given the prominent pixel-level representational ability for low-level tasks, diffusion models have also been introduced to medical image denoising based on the Gaussian assumption of the noise pattern <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>.</p><p>Although previous studies have achieved outstanding performances, deploying AS-OCT despeckling algorithms remains challenging due to several reasons: (1). Gathering massive paired data for supervised learning is difficult because clinical data acquisition is time-consuming and expensive. (2). Speckle noise in AS-OCT images strongly correlates with the real signal, making the additive Gaussian assumption on the speckle pattern to remove noise impractically.</p><p>(3). Unsupervised algorithms can easily miss inherent content, and structural content consistency are vital for clinical intervention in AS-OCT <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref>. (4). Existing algorithms focus on suppressing speckles while ignoring the performance improvement of clinical analysis from despeckling results.</p><p>To address these challenges, we propose a Content-Preserving Diffusion Model for AS-OCT despeckling, named CPDM, which removes speckle noise in AS-OCT images while preserving the inherent content simultaneously. Firstly, we efficiently remove noise via a conditioned noise predictor by truncated diffusion model <ref type="bibr" target="#b15">[16]</ref> in the absence of supervised data. We convert the speckle noise into an additive Gaussian pattern by considering the statistical distribution of speckles in AS-OCT to adapt to the reverse diffusion procedure. Secondly, we incorporate the posterior probability distribution in observed AS-OCT images into an iterative reverse stage to avoid getting trapped in artificial artifacts and preserve consistent content. The posterior distribution is regarded as a data fidelity term to constrain the iterative reverse procedure for despeckling. Finally, experiments on the AS-Casia and CM-Casia datasets demonstrate the effectiveness of CPDM compared to state-of-the-art (SOTA) algorithms. Further experiments on ciliary muscle (CM) segmentation and scleral spur (SS) localization verify that the CPDM can benefit clinical analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Statistical Characteristic of Speckles</head><p>Speckle noise is inherent in coherent imaging systems <ref type="bibr" target="#b2">[3]</ref>, as it results from the destructive interference of multiple-scattered waves. As shown in Fig. <ref type="figure" target="#fig_0">1</ref>, unlike the additive Gaussian noise Y i = x i + N i (i = 1, ..., n), the multiplicative speckle noise is modeled as Y i = x i N i <ref type="bibr" target="#b19">[20]</ref>, where Y denotes the noisy image, x is the noise-free image, N is the speckle noise, and i is the pixel index. Moreover, N consists of independent and identically distributed random variables with unit mean, following a gamma probability density function p N <ref type="bibr" target="#b20">[21]</ref>:</p><formula xml:id="formula_0">p N (n) = M M Γ (M ) n M -1 e -nM ,<label>(1)</label></formula><p>where Γ (•) is the Gamma function and M is the number of multilook <ref type="bibr" target="#b20">[21]</ref>.</p><p>To transform the multiplicative noise into an additive one, logarithmic transform <ref type="bibr" target="#b21">[22]</ref> is employed on both sides of Eq. 1, as: log</p><formula xml:id="formula_1">Y G = log x z + log N W . There- fore, the density of the random variable W = log N is p W (w) = p N (e w )e w = M M Γ (M )</formula><p>e Mw e -e w M . According to the central limit theorem and analyzing the statistical distribution of transformed one in <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref>, W approximately follows a Gaussian distribution. Besides, we can obtain the prior distribution:</p><formula xml:id="formula_2">p G|z (g |z ) = pW (g -z).</formula><p>(2) Diffusion Model. The diffusion model can subtly capture the semantic knowledge of the input image and prevails in the pixel-level representation <ref type="bibr" target="#b14">[15]</ref>. As shown in Fig. <ref type="figure" target="#fig_1">2</ref>(a), it defines a Markov chain that transforms an image x 0 to white Gaussian noise x T ∼ N (0, 1) by adding random noise in T steps. During inference, a random noise x T is sampled and gradually denoised until it reaches the desired image x 0 . To perfectly recover the image in the reverse sampling procedure, a practicable constraint D KL (q(x t-1 |x t , x 0 ) p θ (x t-1 |x t )) was proposed to minimize the distance between p θ (x t-1 |x t ) and q(x t |x t-1 ) <ref type="bibr" target="#b14">[15]</ref>. Thus x t-1 can be sampled as follows:</p><formula xml:id="formula_3">x t-1 = 1 √ α t (x t - β t √ 1 -ᾱt ε θ (x t , t)) + σ t I, (<label>3</label></formula><formula xml:id="formula_4">)</formula><p>where ε θ is an approximator intended to predict noise ε from x t and I ∼ N (0,1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Truncated Diffusion Model.</head><p>As mentioned in the previous section, speckle noise follows a gamma distribution and can be transformed into a Gaussian distribution via a logarithmic function. This transformation enables matching the Markov chain procedure in the reverse diffusion process. To speed up the sampling process, this work introduces a truncated reverse procedure that can directly obtain satisfying results from posterior sampling <ref type="bibr" target="#b15">[16]</ref>. Figure <ref type="figure" target="#fig_1">2</ref>(c) illustrates that only the last few reverse diffusion iterations calculated by parameter estimation technique <ref type="bibr" target="#b24">[25]</ref> are used to obtain the desired result during despeckling inference. Specifically, following <ref type="bibr" target="#b14">[15]</ref>, a Markov chain adds Gaussian noise to the data until it becomes pure noise and then gradually removes it by the reverse procedure at the training stage shown in Fig. <ref type="figure" target="#fig_1">2</ref>(a). At the despeckling inference stage shown in Fig. <ref type="figure" target="#fig_1">2</ref>(b), speckled images are converted into additive Gaussian ones by applying a logarithmic function. Then, the iteration number is determined by estimating the noise levels <ref type="bibr" target="#b15">[16]</ref> to achieve an efficient and effective truncated reverse diffusion procedure. Therefore, AS-OCT despeckling can start from noisy image distributions rather than pure noise.</p><p>CPDM Integrated Fidelity Term. Inspired by the fact that the score-based reverse diffusion process is a stochastic contraction mapping so that as long as the data consistency imposing mapping is non-expansive, data consistency incorporated into the reverse diffusion results in a stochastic contraction to a fixed point <ref type="bibr" target="#b25">[26]</ref>. This work adopts the theory into the inverse AS-OCT image despeckling problems, as the iteration steps which impose fidelity term can be easily cast as non-expansive mapping. Accordingly, we can design a fidelity term to achieve data consistency by modeling image despeckling inverse problem. Specifically, invoking the conditional independence assumption, the prior distribution with Eq. 2 can be rewritten as:</p><formula xml:id="formula_5">log p G|z (g |z ) = n s=1 log pW (g s -z s ) = C -M n s=1 (z s + e gs-zs ). (<label>4</label></formula><formula xml:id="formula_6">)</formula><p>The Bayesian maximum a posteriori (MAP) formulation leads to the image despeckling optimization with data fidelity and regularization terms.</p><p>arg min</p><formula xml:id="formula_7">z M n s=1 (z s + e gs-zs ) + λR(z),<label>(5)</label></formula><p>where R() is the regularization term, and λ is the regularization parameter.</p><p>The unconstrained minimization optimization problem can be defined as a constrained formulation by variable splitting method <ref type="bibr" target="#b26">[27]</ref>:</p><formula xml:id="formula_8">(ẑ, û) = arg min z,u M n s=1 (z s + e gs-zs ) + λR(u) s.t. z = u. (<label>6</label></formula><formula xml:id="formula_9">)</formula><p>Motivated by the iterative restoration methods with prior information to tackle various tasks become mainstream, we explore the fidelity term Eq. 4 from the posterior distribution of observed images into the iterative reverse diffusion procedure. The fidelity can guarantee data consistency with original images and avoid falling into artificial artifacts. Moreover, we learn reasonable prior from DDPM reverse recover procedure, which can ensure the flexibility with iterative fidelity term incorporated into the loop of prior generation procedure. As shown in Fig. <ref type="figure" target="#fig_1">2</ref>(b), the recovery result obtained from the reverse sampling of DDPM (Eq. 3) can be considered as regularization information of the image despeckling optimization model, and the fidelity term in Eq. 5 can ensure the consistency of the reverse diffusion process with the original image content. Therefore, we can achieve AS-OCT image despeckling by solving Eq. 6 with the ADMM method using variable splitting technique <ref type="bibr" target="#b20">[21]</ref>:</p><formula xml:id="formula_10">u t-1 = 1 √ α t (z t+1 - β t √ 1 -ᾱt ε θ (z t+1 , t)) + σ t I, (<label>7</label></formula><formula xml:id="formula_11">)</formula><formula xml:id="formula_12">z t-1 ← arg min z n s=1 (z t s + e gs-z t s ) + μ 2M z t -u t-1 2 , (<label>8</label></formula><formula xml:id="formula_13">)</formula><p>where the hyperparameter u control the degree of freedom. It is worth mentioning that Eq. 7 is obtained with the trained CPDM model, and Eq. 8 can be solved by the Newton method <ref type="bibr" target="#b27">[28]</ref>. Finally, we design an AS-OCT image despeckling scheme by adopting a fidelity term integrated statistical priors to preserve content in the iterative reverse procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment</head><p>To evaluate the performance of the proposed CPDM for AS-OCT image despeckling, we conduct the comparative experiment and a ablation study in despeckling three evaluations, including despeckling evaluation, subsequent CM segmentation or SS localization.</p><p>Dataset Preparation. A series of unsupervised methods including generative adversarial networks (GAN) and diffusion models aim at learning the noise distribution rather than the signal. Therefore, we collect images by averaging 16 repeated B-scans as noisy-free data collected from AS-OCT, the CASIA2 (Tomey, Japan). This study obeyed the tenets of the Declaration of Helsinki and was approved by the local ethics committee. AS-Casia dataset contains 432 noisy image and 400 unpaired clean image with the size of 2131 × 1600, which are views of the AS structure, including lens, cornea, and iris. 400 noisy data and 400 clean images were used for training, and the rest were for testing. The SS location in the noisy image is annotated by ophthalmologists.</p><p>CM-Casia dataset consists of 184 noisy images and 184 unpaired clean data with the size of 1065 × 1465 that show the scope of CM tissue. 160 noisy images and 160 clean data are utilized for training network, with the remaining images reserved for testing. Moreover, ophthalmologists annotated the CM regions on the noisy images.  Implementation Settings. The backbone of our model is a simplified version of that in <ref type="bibr" target="#b14">[15]</ref>. The CPDM network was trained on an NVIDIA RTX 2080TI 48GB GPU for 500 epochs, with a batch size of 2, using Adam optimizer. The variance schedule is set to linearly increase from 10 -4 to 6 -3 in T = 1000 steps and the starting learning rate is 10 Comparison on AS-Casia Dataset. We first evaluate the despeckling performance by parameterless index, including contrast-to-noise ratio (CNR) <ref type="bibr" target="#b7">[8]</ref>, the equivalent number of looks (ENL) <ref type="bibr" target="#b7">[8]</ref>, and natural image quality evaluator (NIQE) <ref type="bibr" target="#b30">[31]</ref>. Then we compare the despeckling results with the SOTA methods by using the SS localization task with trained models in <ref type="bibr" target="#b31">[32]</ref>. Concretely, we calculate a euclidean distance (ED) value between the reference and the predicted SS position with despeckled images via trained models. As shown in Table <ref type="table" target="#tab_0">1</ref>, the proposed CPDM achieves promising despeckling results in terms of the best CNR, ENL, NIQE values and the minimum ED error in the SS localization task among all approaches. The visual comparison for denoised images with competing approaches is shown in Fig. <ref type="figure" target="#fig_2">3</ref>: the green region has been enlarged to highlight the structure of the anterior lens capsule, which can assist in diagnosing congenital cataracts. It can be observed that the CUT and CycleGAN models oversmooths structures close to flat, the UINT method results in ringing effects while the WBM3D, ANLM and DRDM algorithms retain speckles in the lens structure. Obviously, the proposed CPDM acquires satisfactory quality with fine structure details and apparent grain.</p><p>Comparison on CM-Casia Dataset. We conduct the experiment of image despeckling and the following CM segmentation task to validate the clinical benefit with CPDM. Specifically, we train a U-Net segmentation model <ref type="bibr" target="#b32">[33]</ref> on the CM-Casia dataset and then test the despeckled images of various methods. F1-Score and intersection over union (IoU) index for segmentation were calculated between the despeckled images and reference as reported in Table <ref type="table" target="#tab_0">1</ref>. It can be seen that the proposed CPDM achieves the superior despeckling performance by the highest CNR, ENL, NIQE values and segmentation metrics. Moreover, the segmented CM example of competitive methods is depicted in Fig. <ref type="figure" target="#fig_3">4</ref>, in which the CM boundaries reference with the red line, and the yellow line means the segmented results. We can see that NLM, ANLM, CUT, and Speckle2void methods fail to the continuous segmentation results due to insufficient speckle suppres-sion or excessive content loss while the CPDM captures a distinct CM boundary and obtains the highest IoU score. Notably, as a type of smooth muscle, CM has ambiguous boundaries, which are easily affected by speckles, resulting in difficulty distinguishing CM from the adjacent sclera and negative CNR values. Despite these challenges, the proposed CPDM can achieve the best segmentation owing to the speckle reduction while preserving the inconspicuous edge content.</p><p>Ablation Study. Table <ref type="table" target="#tab_0">1</ref> shows the ablation study of the proposed CPDM. We compare our method with two variants: ODDM <ref type="bibr" target="#b16">[17]</ref> and logDM. The ODDM only considers removing the speckles by hijacking the reverse diffusion process with the Gaussian assumption on speckles. Based on the ODDM, the logDM further transforms speckles to Gaussian distribution by analyzing the statistical characteristics of speckles. Additionally, the CPDM adopts the data fidelity term to regulate the despeckling reverse process by integrating content consistency.</p><p>From Table <ref type="table" target="#tab_0">1</ref>, we can see that both the logarithmic function and data fidelity term can improve the quality of despeckled images and benefit the subsequent clinical analysis. Consequently, a prominent unsupervised CPDM to AS-OCT image despeckling is acquired with the proposed strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>Due to the impact of speckles in AS-OCT images, monitoring and analyzing the anterior segment structure is challenging. To improve the quality of AS-OCT images and overcome the difficulty of supervised data acquisition, we propose a content-preserving diffusion model to achieve unsupervised AS-OCT image despeckling. We first analyze the statistical characteristic of speckles and transform it into Gaussian distribution to match the reverse diffusion procedure.</p><p>Then the posterior distribution knowledge of AS-OCT image is designed as a fidelity term and incorporated into the iterative despeckling process to guarantee data consistency. Our experiments show that the proposed CPDM can efficiently suppress the speckles and preserve content superior to the competing methods. Furthermore, we validate that the CPDM algorithm can benefit medical image analysis based on subsequent CM segmentation and SS localization task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Distributions of Gaussian and speckle noises.</figDesc><graphic coords="3,98,79,54,11,226,93,81,61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Illustration of proposed CPDM algorithm. CPDM follows the training network in block(a), and learns the regularization knowledge from the trained network for image despeckling shown in block(b). Moreover, we adopt the truncated strategy shown in block(c) into the despeckling process.</figDesc><graphic coords="4,55,98,54,44,340,30,262,27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The visual comparison of image despeckling results (Color figure online)</figDesc><graphic coords="7,41,79,277,37,340,33,158,92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Comparisons of CM segmented results (Color figure online)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Quantitative evaluation of different methods.</figDesc><table><row><cell>Dataset</cell><cell cols="2">AS-Casia</cell><cell></cell><cell></cell><cell>CM-Casia</cell><cell></cell><cell></cell></row><row><cell>Task</cell><cell cols="2">Despeckling</cell><cell></cell><cell cols="2">Localization Despeckling</cell><cell></cell><cell cols="2">Segmentation</cell></row><row><cell>Method</cell><cell cols="4">CNR↑ ENL↑ NIQE↓ ED↓ (um)</cell><cell cols="3">CNR↑ ENL↑ NIQE↓ F1↑</cell><cell>IoU↑</cell></row><row><cell>Noisy</cell><cell>0.52</cell><cell>5.12</cell><cell>7.05</cell><cell>57.09</cell><cell>-6.66 2.50</cell><cell>11.50</cell><cell cols="2">0.579 0.424</cell></row><row><cell>WBM3D [5]</cell><cell>1.15</cell><cell>6.74</cell><cell>6.31</cell><cell>56.57</cell><cell>-3.25 3.28</cell><cell>6.80</cell><cell cols="2">0.602 0.447</cell></row><row><cell>NLM [29]</cell><cell>1.76</cell><cell>22.94</cell><cell>6.54</cell><cell>96.85</cell><cell>-0.54 42.37</cell><cell>7.39</cell><cell cols="2">0.657 0.508</cell></row><row><cell>ANLM [6]</cell><cell>1.64</cell><cell>10.14</cell><cell>6.63</cell><cell>91.97</cell><cell>-2.18 4.18</cell><cell>6.52</cell><cell cols="2">0.627 0.474</cell></row><row><cell>WKSVD [7]</cell><cell>1.05</cell><cell>6.70</cell><cell>7.94</cell><cell>79.60</cell><cell>-4.98 5.36</cell><cell>8.33</cell><cell cols="2">0.681 0.531</cell></row><row><cell>UINT [30]</cell><cell>2.14</cell><cell>6.45</cell><cell>9.04</cell><cell>121.98</cell><cell>-1.60 12.98</cell><cell>9.03</cell><cell cols="2">0.641 0.492</cell></row><row><cell>CUT [12]</cell><cell>1.94</cell><cell>5.47</cell><cell>6.23</cell><cell>83.05</cell><cell>-4.61 5.99</cell><cell>6.92</cell><cell cols="2">0.553 0.404</cell></row><row><cell>CycleGAN [11]</cell><cell>1.82</cell><cell>5.13</cell><cell>5.58</cell><cell>65.42</cell><cell>-3.12 11.17</cell><cell>7.44</cell><cell cols="2">0.667 0.516</cell></row><row><cell cols="2">Speckle2void [14] 0.51</cell><cell>5.07</cell><cell>7.06</cell><cell>59.79</cell><cell>-5.47 4.71</cell><cell>7.86</cell><cell cols="2">0.665 0.514</cell></row><row><cell>DRDM [16]</cell><cell>1.28</cell><cell>21.23</cell><cell>5.86</cell><cell>37.96</cell><cell>-4.98 33.09</cell><cell>9.18</cell><cell cols="2">0.670 0.524</cell></row><row><cell>ODDM [17]</cell><cell>0.14</cell><cell>31.33</cell><cell>6.11</cell><cell>38.18</cell><cell>-7.06 91.50</cell><cell>9.70</cell><cell cols="2">0.330 0.224</cell></row><row><cell>LogDM</cell><cell>1.63</cell><cell>21.16</cell><cell>5.27</cell><cell>38.04</cell><cell cols="2">-2.08 139.25 7.70</cell><cell cols="2">0.679 0.535</cell></row><row><cell>CPDM</cell><cell cols="3">2.16 143.68 4.84</cell><cell>37.43</cell><cell cols="2">-0.53 396.35 6.42</cell><cell cols="2">0.703 0.561</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>. This work was supported in part by <rs type="funder">General Program of National Natural Science Foundation of China</rs> (Grant No. <rs type="grantNumber">82272086</rs>), <rs type="funder">Guangdong Provincial Department of Education</rs> (Grant No. <rs type="grantNumber">2020ZDZX3043</rs>), <rs type="funder">Shenzhen Natural Science Fund</rs> (<rs type="grantNumber">JCYJ20200109140820699</rs> and the <rs type="programName">Stable Support Plan Program</rs> <rs type="grantNumber">20200925174052004</rs>), <rs type="funder">A*STAR Advanced Manufacturing and Engineering (AME) Programmatic Fund</rs> (<rs type="grantNumber">A20H4b0141</rs>) and <rs type="funder">A*STAR Central Research Fund (CRF)</rs> "<rs type="programName">Robust and Trustworthy AI system for Multi-modality Healthcare</rs>".</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_WQqJz2c">
					<idno type="grant-number">82272086</idno>
				</org>
				<org type="funding" xml:id="_mk7PY6U">
					<idno type="grant-number">2020ZDZX3043</idno>
				</org>
				<org type="funding" xml:id="_UpesE2A">
					<idno type="grant-number">JCYJ20200109140820699</idno>
					<orgName type="program" subtype="full">Stable Support Plan Program</orgName>
				</org>
				<org type="funding" xml:id="_HFwgDnP">
					<idno type="grant-number">20200925174052004</idno>
				</org>
				<org type="funding" xml:id="_E3WezsQ">
					<idno type="grant-number">A20H4b0141</idno>
					<orgName type="program" subtype="full">Robust and Trustworthy AI system for Multi-modality Healthcare</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Real-time optical coherence tomography of the anterior segment at 1310 nm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Radhakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Arch. Ophthalmol</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1179" to="1185" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Anterior chamber angle imaging with optical coherence tomography</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K S</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Weinreb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eye</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="261" to="267" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Speckle in optical coherence tomography</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Schmitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Yung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomed. Opt</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="95" to="105" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Modeling of retinal optical coherence tomography based on stochastic differential equations: application to denoising</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tajmirriahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hamidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rabbani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2129" to="2141" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Speckle reduction in optical coherence tomography images of human finger skin by wavelet modified BM3D filter</title>
		<author>
			<persName><forename type="first">B</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-K</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Opt. Commun</title>
		<imprint>
			<biblScope unit="volume">291</biblScope>
			<biblScope unit="page" from="461" to="469" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Effective speckle noise suppression in optical coherence tomography images using nonlocal means denoising filter with double gaussian anisotropic kernels</title>
		<author>
			<persName><forename type="first">J</forename><surname>Aum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jeong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Opt</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="43" to="D50" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Three dimensional data-driven multi scale atomic representation of optical coherence tomography</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kafieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rabbani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Selesnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1042" to="1062" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Speckle noise reduction in optical coherence tomography images based on edge-sensitive cGAN</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomed. Opt. Express</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="5129" to="5146" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An annotation-free restoration network for cataractous fundus images</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1699" to="1710" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">MRI denoising using progressively distributionbased neural network</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Imaging</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="55" to="68" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Unpaired image-to-image translation using cycle-consistent adversarial networks</title>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2223" to="2232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Contrastive learning for unpaired image-to-image translation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-58545-7_19</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-58545-719" />
	</analytic>
	<monogr>
		<title level="m">ECCV 2020</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Bischof</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J.-M</forename><surname>Frahm</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12354</biblScope>
			<biblScope unit="page" from="319" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Speckle2speckle: Unsupervised learning of ultrasound speckle filtering without clean data</title>
		<author>
			<persName><forename type="first">R</forename><surname>Göbl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hennersperger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Speckle2void: deep selfsupervised sar despeckling with blind-spot convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Molini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Valsesia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fracastoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Magli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Denoising diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural. Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6840" to="6851" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">MR image denoising and super-resolution using regularized reverse diffusion</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. imaging</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="922" to="934" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Unsupervised denoising of retinal oct with diffusion probabilistic model</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">K</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Oguz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Processing</title>
		<imprint>
			<biblScope unit="volume">2022</biblScope>
			<biblScope unit="page" from="25" to="34" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Medical Imaging</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Attention to region: region-based integration-and-recalibration networks for nuclear cataract classification using as-oct images</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page">102499</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Anterior segment optical coherence tomography</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Prog. Retinal Eye Res</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="132" to="156" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Statistical modeling of retinal optical coherence tomography</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rabbani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1544" to="1554" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Multiplicative noise removal using variable splitting and constrained optimization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A T</forename><surname>Figueiredo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1720" to="1730" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A directional multiscale approach for speckle reduction in optical coherence tomography images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Forouzanfar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Moghaddam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2007 International Conference on Electrical Engineering</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Automatic recovery of the optic nervehead geometry in optical coherence tomography</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Boyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Herzog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Roberts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="553" to="570" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Statistical models of signal and noise and fundamental limits of segmentation accuracy in retinal optical coherence tomography</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Dubose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cunefare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Milanfar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Izatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Farsiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1978" to="1988" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An efficient statistical method for image noise level estimation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="477" to="485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Come-closer-diffuse-faster: Accelerating conditional diffusion models for inverse problems through stochastic contraction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="12413" to="12422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Multiplier and gradient methods</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Hestenes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optim. Theor. Appl</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="303" to="320" />
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A newton solver for micromorphic computational homogenization enabling multiscale buckling analysis of pattern-transforming metamaterials</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E H M</forename><surname>Van Bree</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Rokoš</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H J</forename><surname>Peerlings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Doškář</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G D</forename><surname>Geers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Methods Appl. Mech. Eng</title>
		<imprint>
			<biblScope unit="volume">372</biblScope>
			<biblScope unit="page">113333</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A non-local algorithm for image denoising</title>
		<author>
			<persName><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE computer society conference on computer vision and pattern recognition (CVPR 2005)</title>
		<imprint>
			<date type="published" when="2005">2005. 2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="60" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Unsupervised image-to-image translation networks</title>
		<author>
			<persName><forename type="first">M.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Breuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Making a &quot;completely blind&quot; image quality analyzer</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Soundararajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Lett</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="209" to="212" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Reproducibility of deep learning based scleral spur localisation and anterior chamber angle measurements from anterior segment optical coherence tomography images</title>
		<author>
			<persName><forename type="first">Peng</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Br. J. Ophthalmol</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="802" to="808" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">U-net: convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit. Image Process</title>
		<imprint>
			<biblScope unit="volume">9351</biblScope>
			<biblScope unit="page" from="234" to="241" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
