<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ModusGraph: Automated 3D and 4D Mesh Model Reconstruction from Cine CMR with Improved Accuracy and Efficiency</title>
				<funder ref="#_Rgt62AF">
					<orgName type="full">National Institutes of Health</orgName>
				</funder>
				<funder ref="#_HJRGK3J">
					<orgName type="full">The Chief Scientist Office of the Scottish Government Health and Social Care Directorates</orgName>
				</funder>
				<funder>
					<orgName type="full">Edinburgh and Lothian&apos;s Health Foundation Trust and the Heart Diseases Research Fund</orgName>
				</funder>
				<funder ref="#_E92qkVJ">
					<orgName type="full">Innovate UK</orgName>
				</funder>
				<funder ref="#_xuYRqHu">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yu</forename><surname>Deng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Biomedical Engineering and Imaging Sciences</orgName>
								<orgName type="institution">King&apos;s College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hao</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Biomedical Engineering and Imaging Sciences</orgName>
								<orgName type="institution">King&apos;s College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sashya</forename><surname>Rodrigo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Biomedical Engineering and Imaging Sciences</orgName>
								<orgName type="institution">King&apos;s College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Steven</forename><forename type="middle">E</forename><surname>Williams</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Biomedical Engineering and Imaging Sciences</orgName>
								<orgName type="institution">King&apos;s College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">University/BHF Centre for Cardiovascular Science</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
								<address>
									<settlement>Edinburgh</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michelle</forename><forename type="middle">C</forename><surname>Williams</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Steven</forename><forename type="middle">A</forename><surname>Niederer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Biomedical Engineering and Imaging Sciences</orgName>
								<orgName type="institution">King&apos;s College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">University/BHF Centre for Cardiovascular Science</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
								<address>
									<settlement>Edinburgh</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kuberan</forename><surname>Pushparajah</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Biomedical Engineering and Imaging Sciences</orgName>
								<orgName type="institution">King&apos;s College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Alistair</forename><surname>Young</surname></persName>
							<email>alistair.young@kcl.ac.nz</email>
							<affiliation key="aff0">
								<orgName type="department">School of Biomedical Engineering and Imaging Sciences</orgName>
								<orgName type="institution">King&apos;s College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">ModusGraph: Automated 3D and 4D Mesh Model Reconstruction from Cine CMR with Improved Accuracy and Efficiency</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CD418127CBF114E91356445A1F34EAA8</idno>
					<idno type="DOI">10.1007/978-3-031-43990-217.</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-13T19:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Cardiovascular Magnetic Resonance</term>
					<term>3D heart model</term>
					<term>Motion Artefacts</term>
					<term>Super-resolution</term>
					<term>Graph Neural Network</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Anatomical heart mesh models created from cine cardiac images are useful for the evaluation and monitoring of cardiovascular diseases, but require challenging and time-consuming reconstruction processes. Errors due to reduced spatial resolution and motion artefacts limit the accuracy of 3D models. We proposed ModusGraph to produce a higher quality 3D and 4D (3D+time) heart models automatically, employing i) a voxel processing module with Modality Handles and a super-resolution decoder to define low-resolution and high-resolution segmentations and correct motion artefacts with multi-modal unpaired data, ii) a Residual Spatial-temporal Graph Convolution Network to generate mesh models by controlled and progressive spatial-temporal deformation to better capture the cardiac motion, and iii) a Signed Distance Sampling process to bridge those two parts for end-to-end training. Modus-Graph was trained and evaluated on CT angiograms and cardiovascular MRI cines, showing superior performance compared to other mesh reconstruction methods. It creates well-defined meshes from sparse MRI cines, enabling vertex tracking across cardiac cycle frames. This process aids in analyzing myocardium function and conducting biomechanical analyses from imaging data https://github.com/MalikTeng/ModusGraph.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Multi-slice cine cardiovascular magnetic resonance (CMR) scanning is a common method for the accurate diagnosis and evaluation of cardiovascular diseases <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b25">25]</ref>. Although this provides a series of images of the heart and blood vessels over time, it is often a lengthy process that obtains only certain slices of the heart which limit the visualization of certain structures, and has breath-hold motion artefacts resulting in misalignment between slices</p><p>To better evaluate heart disease, plan interventions, and monitor heart disease, a 3D heart model can be created from cine CMRs, which is a digitized heart object visualized as triangular meshes <ref type="bibr" target="#b9">[9]</ref>. This reconstruction is accomplished in several steps: segmentation, registration, reconstruction, refinement, and visualisation. Because of the time cost and expert knowledge required for this task, it is desirable to create 3D or 4D (3D+time) heart models automatically for every patient <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b23">23]</ref>. However, it is challenging to create accurate 3D heart models, because of the impact of low spatial resolution and motion artefacts <ref type="bibr" target="#b11">[11,</ref><ref type="bibr" target="#b18">18]</ref>.</p><p>To this end, we proposed a Recurrent Graph Neural Network based method, ModusGraph, to fully automate the reconstruction of 4D heart models from cine CMR. This includes i) a voxel processing module with Modality Handles (Modhandle) and ResNet decoder for super-resolution and correction of motion artefacts from the acquired cine CMR, ii) a Residual Spatial-temporal Graph Convolution module (R-StGCN) for 4D mesh models generation by hierarchically spatial deformation and temporal motion estimation, and iii) a Signed Distance Sampling process bridge voxel features from segmentation and vertex features from deformation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Works</head><p>Surface meshing involves constructing polygonal representations of geometric objects or surfaces, and creating high-quality and feature-aware surface meshes for medical imaging applications it is of particular interest.</p><p>With available large-volume training data and advanced computational resources, more studies harness the strength of deep learning and traditional methods to avoid user supervision. Aubert et al. <ref type="bibr" target="#b1">[2]</ref> use convolutional neural networks to automatically detect anatomical landmarks for spine reconstruction. Ma et al. <ref type="bibr" target="#b22">[22]</ref> propose a dense SLAM technique for colon surface reconstruction. Gopinath et al. <ref type="bibr" target="#b7">[7]</ref> presented SegRecon, an end-to-end deep learning approach that for simultaneous reconstruction and segmentation of cortical surfaces directly from an MRI volume. Wang et al. <ref type="bibr" target="#b26">[26]</ref> reconstructed 3D surfaces from 2D images using a neural network that learns a Signed Distance Function (SDF) representation from 2D images. Ma et al. <ref type="bibr" target="#b21">[21]</ref> proposed a deep learning framework that uses neural ordinary differential equations (ODEs) for efficient cortical surface reconstruction from brain MRI scans. Similarly, Lebrat et al. <ref type="bibr" target="#b17">[17]</ref> presents CorticalFlow, a geometric deep learning model that learns to deform a reference template mesh towards a targeted object in a 3D image, by solving ODEs from stationary velocity fields.</p><p>In contrast to those methods applying directly to the surface manifold, others, similar to our method, combine image segmentation with explicit surface representations and mesh deformation with coarse to fine controls. Wickramasinghe et al. <ref type="bibr" target="#b27">[27]</ref> introduced Voxel2Mesh, a two-stage method that uses a CNN for voxel labelling and a GCN for mesh generation. Bongratz et al. <ref type="bibr" target="#b3">[4]</ref> presented a deep learning algorithm that reconstructs explicit meshes of cortical surfaces from brain MRI scans using a convolutional and graph neural network, resulting in four meshes. Kong et al. <ref type="bibr" target="#b14">[14]</ref> proposed a method that generates simulation-ready meshes of cardiac structures using atlas-based registration and shape-preserving interpolation. They also introduced a deep learning approach that constructs whole heart meshes by learning to deform a small set of deformation handles on a whole heart template <ref type="bibr" target="#b15">[15]</ref>. Here, we utilize sparse CMRs to generate temporally coherent dynamic meshes for the cardiac cycle, leveraging unpaired high-resolution CT datasets (Fig. <ref type="figure" target="#fig_0">1</ref>). These meshes are geometrically and topologically well-defined, with trackable vertices across consecutive frames. Such features enhance the analysis of myocardium function and enable biomechanical computational analysis (e.g., for stiffness or contractility estimation from finite element analysis of imaging data). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Voxel Processing Module</head><p>Modality Handles. Compared to cine CMRs, CT imaging provides higher spatial resolution and enables easier high-resolution segmentation of the heart. The developed network to generate such segmentation is transferable to process cine CMRs, allowing for comparable cardiac structural information to be extracted from similar patient populations. The following module is thus proposed to estimate high-resolution segmentations from unpaired CT and cine CMR image volumes. An input image volume X CT ∈ R H×W×D is cropped around the anatomy of interest to the size of 128 × 128 × 128, and then down-sampled following bilinear interpolation method to X' CT ∈ R 16×16×16 , which enables a common low-resolution segmentation space for cine CMRs. Its predicted segmentation Ỹ' CT ∈ R 16×16×16 is generated by a CT Modality Handle (CT Mod-handle, h(X CT )), using ResNet blocks followed by ReLU non-linear activity and a oneby-one convolution layer. A MR Modality Handle (MR Mod-handle, h(X MR )) generates predicted segmentation ỸMR from cine CMRs in the same way.</p><p>Super-Resolution Decoder. Ỹ' CT is passed to a decoder for super-resolution reconstruction to a size of 128×128×128. The decoder ψ includes three layers of up convolution followed by ResNet blocks. The high-resolution segmentation of cine CMR is generated similarly through ỸMR = W ψ W h X MR , where W ψ and W h are trainable weights of decoder and Mod-handle, respectively. To include heart morphological features in the graph convolution process, the signed distance is calculated from the decoder's output. This signed distance is computed as geodesic distances from each voxel to the surface boundary <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">5]</ref>. The mesh is then scaled to the output size and each mesh surface vertex is assigned a signed distance based on the output channel and vertex's coordinates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Residual Spatial-Temporal Graph Convolution Module (R-StGCN)</head><p>Graph convolution networks can be utilized to reshape a heart mesh model, but regressing the surface near sharp edges or areas with aggressive Laplacian changes is challenging due to the networks' lack of awareness of the position relationships. We borrowed the idea of graph construction from human joints to overcome this issue <ref type="bibr" target="#b30">[30]</ref>. The area of the 1-connected neighbourhood near sharp edges is divided into 3 subsets k: one subset includes vertices on the valves' edges, and the other two subsets include vertices on different sides of the myocardium surfaces. This defines the robust position relationships of sharp edges and other convex areas of the mesh, allowing us to use Adaptive Graph Convolutional (AGC) layers <ref type="bibr" target="#b24">[24]</ref> to learn such relationships.</p><p>Spatial Deformation. Given a dynamic mesh at level l and frame t, i.e. M l t = (V l t , E l t ), where V l t and E l t are N vertices and M edges, respectively. A dense adjacency matrix A k ∈ R N ×N denotes the edges between every two vertices.</p><p>A data-dependent matrix C k ∈ R N ×N determines the similarity of every two vertices as normalized Gaussian function,</p><formula xml:id="formula_0">C k = sof tmax(f T in W T θk W φk f in )</formula><p>. W θk and W φk are the parameters of the 1 × 1 convolution layer θ and φ, respectively. f in ∈ R 3×T ×N is input feature matrix of the convolution layer, where T is the number of frames for each cardiac cycle. The sampling area of convolution is a 1-connected neighbourhood includes 3 subsets, which conforms with the aforementioned mesh topology. It is described as</p><formula xml:id="formula_1">f out = Σ K=3 k W k f in (A k + C k ).</formula><p>f out is output feature of the convolution layer, W k is trainable weights for the convolution. Following the AGC layer, we used graph convolution with first-order Chebyshev polynomial approximation. It is formalized as</p><formula xml:id="formula_2">f out = σ(W θ0 f in + W θ1 f in L)</formula><p>, where W θ0 , W θ1 are trainable weights and L = 2L norm /λ max -I, L ∈ R N ×N is the scaled and normalized Laplacian matrix <ref type="bibr" target="#b6">[6]</ref>. The signed distance was added to mesh vertices prior to the graph convolution, and a straightforward Loop method <ref type="bibr" target="#b19">[19]</ref> for surface subdivision is applied to refine the coarse mesh.</p><p>Temporal Deformation. The deformation field vector V t-1→t and V t→t-1 are learnt through temporal convolutions, where the sampling neighbourhood is defined as a vertex in consecutive frames. It is a T × 1 convolution performed on the output feature matrix f out in a bidirectional manner. V is regularized following the principle of motion estimation. With vertices of meshes at consecutive frames V 0 and V 1 , the vertices of intermediate mesh V t , 0 &lt; t &lt; 1 is approximated under symmetric assumption <ref type="bibr" target="#b28">[28]</ref>, as Ṽt = 0.5</p><formula xml:id="formula_3">• (t • (V 0 + t • V 0→1 ) + (1 - t) • (V 1 + (1 -t) • V 1→0</formula><p>), and we measure the L1 difference between Ṽt and V t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Training Scheme</head><p>Generally, the MR Mod-handle was trained on cine CMRs and down-sampled segmentation, described as L seg,MR (h(X MR ), Y' MR ). The CT Mod-handle and ResNet decoder were trained on CT image volumes, segmentation and their down-sampled counterparts using dice loss and cross-entropy loss, i.e. L seg,CT (ψ• h(X CT ), Y CT , Y' CT ). Supervised by the ground-truth point clouds from CT segmentation, meshes were predicted from the R-StGCN module, where Chamfer distance is minimized together with surface regularization <ref type="bibr" target="#b27">[27]</ref> and deformation field vector regularization as</p><formula xml:id="formula_4">L mesh,CT = Σ T =1 t=0 Σ L=2 l=0 dCD( Ml t , P t ) + λ reg • (L regular (M l t ) + Ṽl t -V l t 1</formula><p>). P t was generated via Marching Cubes <ref type="bibr" target="#b20">[20]</ref> and uniform surface sampling applied to the ground-truth segmentation. Similarly, pseudo point clouds Pt from super-resolved cine CMRs segmentation were used for fine-tuning the R-StGCN module, i.e. L mesh,MR . The total loss is L total = λ seg • (L seg,CT + L seg,MR ) + λ mesh • (L mesh,CT + L mesh,MR ), where λ seg = 0.5, λ mesh = 1.0 and λ reg = 0.1 were selected by extensive experiments from [0, 1]. Find a detailed training/testing scheme in Appendix V. ModusGraph is implemented with PyTorch 1.12.1 and the experiment was conducted on an RTX 3090 GPU, with Adam optimizer and a learning rate of 1e-4. The training and validation losses converge after 200 epochs in less than 2 h.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>The training and validation data consisted of CT image volumes from the SCOT-HEART study <ref type="bibr" target="#b12">[12]</ref> and cine CMRs from the Cardiac Atlas Project (CAP) tetralogy of Fallot <ref type="bibr" target="#b8">[8]</ref> database. CT data were included to provide high-resolution geometry information while tetralogy of Fallot CMR cases were used because functional analyses are important for these patients. The SCOT-HEART dataset provided 400 and 200 image volumes for training and testing, while the CAP dataset provided 84 and 48 time-series image volumes for training and testing. Data augmentation techniques included random intensity shifting, scaling, contrast adjustment, random rotation, and intensity normalization. Groundtruth segmentations of four heart chambers, left ventricle myocardium, and aorta artery from a previously validated method <ref type="bibr" target="#b29">[29]</ref> was used for the whole heart meshing on the SCOT-HEART dataset while left and right ventricle and myocardium manual segmentations were used for the dynamic meshing with the CAP dataset. 0.25 ± 0.86 0.20 ± 0.32 0.18 ± 0.13 RES (14k) 0.00 ± 0.00 0.00 ± 0.00 0.00 ± 0.00 0.00 ± 0.00 0.00 ± 0.00 0.00 ± 0.00 MG (6k)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation of Whole Heart Meshes Quality</head><p>1.79 ± 0.68 2.39 ± 0.49 1.17 ± 0.14 0.43 ± 0.29 0.18 ± 0.10 1.50 ± 1.80</p><p>We evaluated the quality of meshes generated by ModusGraph, by comparing them to those produced by other state-of-the-art methods using the SCOT-HEART dataset. ModusGraph, Voxel2Mesh <ref type="bibr" target="#b27">[27]</ref>, and CorticalFlow <ref type="bibr" target="#b17">[17]</ref> started from the same template mesh and progressively deformed it to a finer mesh using 128 × 128 × 128, while nnU-Net <ref type="bibr" target="#b13">[13]</ref> segmentation and Point2Mesh <ref type="bibr" target="#b10">[10]</ref> reconstruction used a user controlled, differentiable refinement process to warp the segmentation boundary point clouds to meshes. These methods produce meshes with around 6,000 vertices for each anatomy. The Marching Cubes method was also applied to the ResNet decoder's segmentation to generate a finer mesh with around 14,000 vertices for evaluation. All methods for generating meshes had training times ranging from 2-5 hours.</p><p>Regarding the Dice score and Average Surface Distance (ASD) in Table <ref type="table" target="#tab_0">1</ref>, RES is a high benchmark since it was straightforward to reconstruct a highresolution marching cubes mesh from the well-defined morphologies in the segmentations, but this is not suitable for tracking or computational models. Modus-Graph's mesh accuracy is compromised due to information loss in the QuickHullderived template mesh (Appendix I), alignment issues with deformed meshes and segmentation in different coordinate systems, and difficulties in capturing patient-specific geometric variations. However, refining the template mesh and registration process could potentially enhance the results. Figure <ref type="figure" target="#fig_1">2</ref> and the intersection scores in Table <ref type="table" target="#tab_0">1</ref> that measure the ratio of surface collision show that ModusGraph can generate accurate whole-heart meshes with less surface distortion and collision when compared to its closest result from CorticalFlow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Dynamic Mesh for Biomechanical Simulation</head><p>We evaluated ModusGraph and other methods on the task of creating dynamic ventricle myocardium meshes. When them to ground-truth short-axis slices segmentation, the Average Surface Distance (ASD) at end-diastole (ED) and  Mesh quality for biomechanical simulations, including aspect ratio, min and max angle, and Jacobian of surface mesh triangular cells, was also evaluated. ModusGraph showed less distorted cells, leading to faster convergence for mechanical simulations, as shown in Table <ref type="table" target="#tab_2">2</ref>. Changes in mesh surface from ED to ES phase were compared to a reference dynamic mesh, Bi-ventricle <ref type="bibr" target="#b8">[8]</ref>, and ModusGraph was found to more accurately describe the deformation in areas surrounding valves and the displacement of the myocardium surface, as shown in Fig <ref type="figure" target="#fig_2">3-b</ref>. The dynamic mesh generated by ModusGraph is included in supplementary materials, along with details for creating template meshes for the two tasks and reference Bi-ventricle mesh.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>Our proposed method, ModusGraph, automates 4D heart model reconstruction from cine CMR using a voxel processing module, a Residual Spatial-temporal Graph Convolution module and a Signed Distance Sampling process. Modus-Graph outperforms other state-of-the-art methods in reconstructing accurate 3D heart models from high-resolution segmentations on computed tomography images, and generates 4D heart models suitable for biomechanical analysis, which will aid in the understanding of congenital heart disease. This approach offers an efficient and automated solution for creating 3D and 4D heart models, with potential benefits for heart disease assessment, intervention planning, and monitoring.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Schematic of ModusGraph. It consists of two main components: a voxel processing module to generate high-resolution segmentations from image volumes, and an R-StGCN module based on a graph convolution network that deforms an initial coarse mesh progressively and dynamically by frames. A Signed Distance Sampling procedure bridges those two parts for end-to-end training.</figDesc><graphic coords="3,59,46,334,28,333,40,175,12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Visualized meshes for a SCOT-HEART case. Arrows pointing to intersection structures in CorticalFlow</figDesc><graphic coords="7,65,46,53,99,321,64,181,72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Visualization of generated dynamic meshes' a) silhouette on short-and longaxis b) surface displacement between end-diastole and end-systole.</figDesc><graphic coords="8,59,31,154,49,305,92,170,68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Comparison of accuracy of generated mesh on SCOT-HEART test cases. Dice (decimal) and INTersection (percentage) scores were derived on voxelized meshes and ASD (decimal) is evaluated on meshes. Compared methods include Voxel2Mesh (VM), CorticalFlow (CF), nnU-Net3D+Point2Mesh (NNP), ResNet Decoder+Marching Cubes (RES) and ModusGraph (MG).</figDesc><table><row><cell cols="2">Metrics Methods</cell><cell>LV</cell><cell>LV-MYO</cell><cell>RV</cell><cell>LA</cell><cell>RA</cell><cell>AV</cell></row><row><cell>Dice</cell><cell>VM (6k)</cell><cell cols="3">0.66 ± 0.11 0.35 ± 0.13 0.63 ± 0.12</cell><cell cols="3">0.54 ± 0.16 0.58 ± 0.13 0.47 ± 0.17</cell></row><row><cell></cell><cell>CF (6k)</cell><cell cols="3">0.75 ± 0.08 0.50 ± 0.12 0.73 ± 0.08</cell><cell cols="3">0.67 ± 0.12 0.72 ± 0.10 0.61 ± 0.13</cell></row><row><cell></cell><cell cols="4">NNP (6k) 0.75 ± 0.05 0.49 ± 0.08 0.72 ± 0.07</cell><cell cols="3">0.66 ± 0.04 0.70 ± 0.05 0.58 ± 0.06</cell></row><row><cell></cell><cell cols="2">RES (14k) 0</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>.92 ± 0.02 0.82 ± 0.05 0.91 ± 0.03 0.89 ± 0.03 0.90 ± 0.04 0.87 ± 0.05</head><label></label><figDesc></figDesc><table><row><cell></cell><cell>MG (6k)</cell><cell cols="3">0.77 ± 0.08 0.51 ± 0.13 0.75 ± 0.09</cell><cell cols="3">0.68 ± 0.11 0.73 ± 0.09 0.65 ± 0.14</cell></row><row><cell>ASD</cell><cell>VM (6k)</cell><cell>3.20e-01</cell><cell>5.88e-01</cell><cell>1.14e-01</cell><cell>1.89e-01</cell><cell>3.21e-01</cell><cell>1.31e+00</cell></row><row><cell></cell><cell>CF (6k)</cell><cell>1.13e-02</cell><cell>8.24e-03</cell><cell>1.17e-02</cell><cell>1.64e-02</cell><cell>1.27e-02</cell><cell>1.40e-02</cell></row><row><cell></cell><cell cols="2">NNP (6k) 1.16e-02</cell><cell>9.78e-03</cell><cell>1.21e-02</cell><cell>1.75e-02</cell><cell>1.46e-02</cell><cell>1.57e-02</cell></row><row><cell></cell><cell cols="2">RES (14k) 1.01e-03</cell><cell>8.65e-04</cell><cell>1.45e-03</cell><cell>1.76e-03</cell><cell>1.81e-03</cell><cell>1.48e-03</cell></row><row><cell></cell><cell>MG (6k)</cell><cell>1.06e-02</cell><cell>8.60e-03</cell><cell>1.09e-02</cell><cell>1.64e-02</cell><cell>1.18e-02</cell><cell>1.16e-02</cell></row><row><cell>INT</cell><cell>VM (6k)</cell><cell cols="3">15.74 ± 7.62 16.25 ± 5.82 9.16 ± 8.09</cell><cell cols="3">6.00 ± 8.41 7.57 ± 9.95 5.16 ± 8.86</cell></row><row><cell></cell><cell>CF (6k)</cell><cell cols="6">12.34 ± 5.45 15.29 ± 9.81 11.77 ± 10.22 9.35 ± 6.38 6.42 ± 6.47 8.61 ± 7.31</cell></row><row><cell></cell><cell cols="4">NNP (6k) 1.85 ± 0.96 2.24 ± 1.27 0.62 ± 0.42</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Comparison of quality of generated mesh on CAP test cases. Numbers are decimal except for Angle in degree. ASD Aspect Ratio Angle (min, max) Jacobian Voxel2Mesh 1.08e-1 1.55 ± 0.08 (37.21, 91.01) 0.72 ± 0.03 CorticalFlow 8.21e-2 1.62 ± 0.15 (31.77, 94.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements. YD was funded by the</head><p>Kings-China Scholarship Council PhD Scholarship Program. HX was funded by <rs type="funder">Innovate UK</rs> (<rs type="grantNumber">104691</rs>) <rs type="projectName">London Medical Imaging &amp; Artificial Intelligence Centre for Value Based Healthcare. SCOT-HEART</rs> was funded by <rs type="funder">The Chief Scientist Office of the Scottish Government Health and Social Care Directorates</rs> (<rs type="grantNumber">CZH/4/588</rs>), with supplementary awards from <rs type="funder">Edinburgh and Lothian's Health Foundation Trust and the Heart Diseases Research Fund</rs>. AAY and KP acknowledge funding from the <rs type="funder">National Institutes of Health</rs> <rs type="grantNumber">R01HL121754</rs> and <rs type="institution">Welcome ESPCR Centre</rs> for Medical Engineering at King's College London <rs type="grantNumber">WT203148/Z/16/Z</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_E92qkVJ">
					<idno type="grant-number">104691</idno>
					<orgName type="project" subtype="full">London Medical Imaging &amp; Artificial Intelligence Centre for Value Based Healthcare. SCOT-HEART</orgName>
				</org>
				<org type="funding" xml:id="_HJRGK3J">
					<idno type="grant-number">CZH/4/588</idno>
				</org>
				<org type="funding" xml:id="_Rgt62AF">
					<idno type="grant-number">R01HL121754</idno>
				</org>
				<org type="funding" xml:id="_xuYRqHu">
					<idno type="grant-number">WT203148/Z/16/Z</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Fastgeodis: fast generalised geodesic distance transform</title>
		<author>
			<persName><forename type="first">M</forename><surname>Asad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dorent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Vercauteren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Open Sourc. Softw</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">79</biblScope>
			<biblScope unit="page">4532</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Toward automated 3d spine reconstruction from biplanar radiographs using CNN for statistical spine model fitting</title>
		<author>
			<persName><forename type="first">B</forename><surname>Aubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vazquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Cresson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Parent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>De Guise</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2796" to="2806" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A completely automated pipeline for 3d reconstruction of human heart from 2d cine magnetic resonance slices</title>
		<author>
			<persName><forename type="first">A</forename><surname>Banerjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phil. Trans. R. Soc. A</title>
		<imprint>
			<biblScope unit="volume">379</biblScope>
			<biblScope unit="page">20200257</biblScope>
			<date type="published" when="2021">2212. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Vox2cortex: fast explicit reconstruction of cortical surfaces from 3d mri scans with geometric deep neural networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bongratz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rickmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pölsterl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wachinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="20773" to="20783" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">GeoS: geodesic image segmentation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sharp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV 2008</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Forsyth</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Torr</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">5302</biblScope>
			<biblScope unit="page" from="99" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-540-88682-2_9</idno>
		<ptr target="https://doi.org/10.1007/978-3-540-88682-29" />
		<imprint>
			<date type="published" when="2008">2008</date>
			<pubPlace>Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName><forename type="first">M</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">SegRecon: learning joint brain surface reconstruction and segmentation from images</title>
		<author>
			<persName><forename type="first">K</forename><surname>Gopinath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Desrosiers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lombaert</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87234-2_61</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87234-261" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12907</biblScope>
			<biblScope unit="page" from="650" to="659" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A deep learning approach for fully automated cardiac shape modeling in tetralogy of Fallot</title>
		<author>
			<persName><forename type="first">S</forename><surname>Govil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cardiovasc. Magn. Reson</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">15</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Cine and multicontrast late enhanced MRI registration for 3D heart model construction</title>
		<author>
			<persName><forename type="first">F</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pop</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-12029-0_6</idno>
		<idno>978-3-030-12029-0 6</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">STA-COM 2018</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Pop</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11395</biblScope>
			<biblScope unit="page" from="49" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Point2mesh: a self-prior for deformable meshes</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hanocka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Metzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Giryes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.11084</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Are movement artifacts in magnetic resonance imaging a real problem?a narrative review</title>
		<author>
			<persName><forename type="first">I</forename><surname>Havsteen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ohlhues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Madsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Nybing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Christensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Christensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Neurol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">232</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Coronary CT angiography and 5-year risk of myocardial infarction</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Investigators</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">N. Engl. J. Med</title>
		<imprint>
			<biblScope unit="volume">379</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="924" to="933" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">NNU-net: a self-configuring method for deep learning-based biomedical image segmentation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Isensee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Kohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Maier-Hein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="211" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Whole heart mesh generation for image-based computational simulations by learning free-from deformations</title>
		<author>
			<persName><forename type="first">F</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Shadden</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87202-1_53</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87202-153" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12904</biblScope>
			<biblScope unit="page" from="550" to="559" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning whole heart mesh generation from patient images for computational simulations</title>
		<author>
			<persName><forename type="first">F</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Shadden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="533" to="545" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Standardized cardiovascular magnetic resonance imaging (CMR) protocols, society for cardiovascular magnetic resonance: board of trustees task force on standardized protocols</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Kramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Barkhausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Flamm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Nagel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cardiovasc. Magn. Reson</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">CorticalFlow: a diffeomorphic mesh transformer network for cortical surface reconstruction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lebrat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural. Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="29491" to="29505" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Reduction of motion artifacts in cine MRI using variable-density spiral trajectories</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Pauly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Brosnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Pelc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="569" to="575" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Loop</surname></persName>
		</author>
		<title level="m">Smooth subdivision surfaces based on triangles</title>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Marching cubes: a high resolution 3d surface construction algorithm</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Lorensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Cline</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGGRAPH Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="163" to="169" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">CortexODE: learning cortical surface reconstruction by neural odes</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kainz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alansary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="430" to="443" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Realtime 3D reconstruction of colonoscopic surfaces for determining missing regions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pizer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rosenman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Mcgill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Frahm</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-32254-0_64</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-32254-064" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2019</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11768</biblScope>
			<biblScope unit="page" from="573" to="582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Reconstruction techniques for cardiac cine MRI</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Menchón-Lara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Simmross-Wattenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Casaseca-De-La Higuera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martín-Fernández</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Alberola-López</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Insights Imaging</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Two-stream adaptive graph convolutional networks for skeleton-based action recognition</title>
		<author>
			<persName><forename type="first">L</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="12026" to="12035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Imaging biomarkers for cardiovascular diseases</title>
		<author>
			<persName><forename type="first">A</forename><surname>Suinesiaputra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pontre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Medical Image Computing and Computer Assisted Intervention</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="401" to="428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">NEUS: learning neural implicit surfaces by volume rendering for multi-view reconstruction</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Theobalt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Komura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.10689</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Voxel2Mesh: 3D mesh model generation from volumetric data</title>
		<author>
			<persName><forename type="first">U</forename><surname>Wickramasinghe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Remelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Knott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59719-1_30</idno>
		<idno>978-3-030-59719-1 30</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12264</biblScope>
			<biblScope unit="page" from="299" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">One-dimensional resampling with inverse and forward mapping functions</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wolberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sueyllam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ismail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ahmed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Graphics Tools</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="11" to="33" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Whole heart anatomical refinement from CCTA using extrapolation and parcellation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-78710-3_7</idno>
		<idno>978-3-030-78710-3 7</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">FIMH 2021</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Ennis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Perotti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12738</biblScope>
			<biblScope unit="page" from="63" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Spatial temporal graph convolutional networks for skeleton-based action recognition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
