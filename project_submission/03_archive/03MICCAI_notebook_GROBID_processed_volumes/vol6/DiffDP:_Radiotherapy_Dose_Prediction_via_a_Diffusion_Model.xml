<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DiffDP: Radiotherapy Dose Prediction via a Diffusion Model</title>
				<funder ref="#_CegcXUj">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_NMVXk2t #_BxjjveZ #_fP2vz3K #_p2SbRmS">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zhenghao</forename><surname>Feng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Sichuan University</orgName>
								<address>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lu</forename><surname>Wen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Sichuan University</orgName>
								<address>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Peng</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Sichuan University</orgName>
								<address>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Binyu</forename><surname>Yan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Sichuan University</orgName>
								<address>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xi</forename><surname>Wu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Chengdu University of Information Technology</orgName>
								<address>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiliu</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Sichuan University</orgName>
								<address>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Chengdu University of Information Technology</orgName>
								<address>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Yan</forename><surname>Wang</surname></persName>
							<email>wangyanscu@hotmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Sichuan University</orgName>
								<address>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DiffDP: Radiotherapy Dose Prediction via a Diffusion Model</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="191" to="201"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">E0B73A2304F9272BB1194A4673C316AB</idno>
					<idno type="DOI">10.1007/978-3-031-43987-2_19</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-13T19:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Radiotherapy Treatment</term>
					<term>Dose Prediction</term>
					<term>Diffusion Model</term>
					<term>Deep Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Currently, deep learning (DL) has achieved the automatic prediction of dose distribution in radiotherapy planning, enhancing its efficiency and quality. However, existing methods suffer from the over-smoothing problem for their commonly used L 1 or L 2 loss with posterior average calculations. To alleviate this limitation, we innovatively introduce a diffusion-based dose prediction (DiffDP) model for predicting the radiotherapy dose distribution of cancer patients. Specifically, the DiffDP model contains a forward process and a reverse process. In the forward process, DiffDP gradually transforms dose distribution maps into Gaussian noise by adding small noise and trains a noise predictor to predict the noise added in each timestep. In the reverse process, it removes the noise from the original Gaussian noise in multiple steps with the well-trained noise predictor and finally outputs the predicted dose distribution map. To ensure the accuracy of the prediction, we further design a structure encoder to extract anatomical information from patient anatomy images and enable the noise predictor to be aware of the dose constraints within several essential organs, i.e., the planning target volume and organs at risk. Extensive experiments on an in-house dataset with 130 rectum cancer patients demonstrate the superiority of our method.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Radiotherapy, one of the mainstream treatments for cancer patients, has gained notable advancements in past decades. For promising curative effect, a high-quality radiotherapy plan is demanded to distribute sufficient dose of radiation to the planning target volume (PTV) while minimizing the radiation hazard to organs at risk (OARs). To achieve this, radiotherapy plans need to be manually adjusted by the dosimetrists in a trial-and-error manner, which is extremely labor-intensive and time-consuming <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. Additionally, the quality of treatment plans might be variable among radiologists due to their different expertise and experience <ref type="bibr" target="#b2">[3]</ref>. Consequently, it is essential to develop a robust methodology to automatically predict the dose distribution for cancer patients, relieving the burden on dosimetrists and accelerating the radiotherapy procedure.</p><p>Recently, the blossom of deep learning (DL) has promoted the automatic medical image processing tasks <ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref>, especially for dose prediction <ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref>. For example, Nguyen et al. <ref type="bibr" target="#b6">[7]</ref> modified the traditional 2D UNet <ref type="bibr" target="#b14">[15]</ref> to predict the dose of prostate cancer patients. Wang et al. <ref type="bibr" target="#b9">[10]</ref> utilized a progressive refinement UNet (PRUNet) to refine the predictions from low resolution to high resolution. Besides the above UNetbased frameworks, Song et al. <ref type="bibr" target="#b10">[11]</ref> employed the deepLabV3+ <ref type="bibr" target="#b15">[16]</ref> to excavate contextual information from different scales, thus obtaining accuracy improvements in the dose prediction of rectum cancer. Mahmood et al. <ref type="bibr" target="#b11">[12]</ref> utilized a generative adversarial network (GAN)-based method to predict the dose maps of oropharyngeal cancer. Furthermore, Zhan et al. <ref type="bibr" target="#b12">[13]</ref> designed a multi-organ constraint loss to enforce the deep model to better consider the dose requirements of different organs. Following the idea of multi-task learning, Tan et al. <ref type="bibr" target="#b7">[8]</ref> utilized isodose line and gradient information to promote the performance of dose prediction of rectum cancer. To ease the burden on the delineation of PTV and OARs, Li et al. <ref type="bibr" target="#b16">[17]</ref> constructed an additional segmentation task to provide the dose prediction task with essential anatomical knowledge.</p><p>Although the above methods have achieved good performance in predicting dose distribution, they suffer from the over-smoothing problem. These DL-based dose prediction methods always apply the L 1 or L 2 loss to guide the model optimization which calculates a posterior mean of the joint distribution between the predictions and the ground truth <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref>, leading to the over-smoothed predicted images without important high-frequency details <ref type="bibr" target="#b18">[19]</ref>. We display predicted dose maps from multiple deep models in Fig. <ref type="figure" target="#fig_0">1</ref>. As shown, compared with the ground truth, i.e., <ref type="bibr" target="#b4">(5)</ref> in Fig. <ref type="figure" target="#fig_0">1</ref>, the predictions from (1) to (3) are blurred with fewer high-frequency details, such as ray shapes. These high-frequency features formed by ray penetration reveal the ray directions and dose attenuation with the aim of killing the cancer cells while protecting the OARs as much as possible, which are critical for radiotherapy. Consequently, exploring an automatic method to generate high-quality predictions with rich high-frequency information is important to improve the performance of dose prediction. Currently, diffusion model <ref type="bibr" target="#b19">[20]</ref> has verified its remarkable potential in modeling complex image distributions in some vision tasks <ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref>. Unlike other DL models, the diffusion model is trained without any extra assumption about target data distribution, thus evading the average effect and alleviating the over-smoothing problem <ref type="bibr" target="#b23">[24]</ref>. Figure <ref type="figure" target="#fig_0">1</ref> (4) provides an example in which the diffusion-based model predicts a dose map with shaper and clearer boundaries of ray-penetrated areas. Therefore, introducing a diffusion model to the dose prediction task is a worthwhile endeavor.</p><p>In this paper, we investigate the feasibility of applying a diffusion model to the dose prediction task and propose a diffusion-based model, called DiffDP, to automatically predict the clinically acceptable dose distribution for rectum cancer patients. Specifically, the DiffDP consists of a forward process and a reverse process. In the forward process, the model employs a Markov chain to gradually transform dose distribution maps with complex distribution into Gaussian distribution by progressively adding pre-defined noise. Then, in the reverse process, given a pure Gaussian noise, the model gradually removes the noise in multiple steps and finally outputs the predicted dose map. In this procedure, a noise predictor is trained to predict the noise added in the corresponding step of the forward process. To further ensure the accuracy of the predicted dose distribution for both the PTV and OARs, we design a DL-based structure encoder to extract the anatomical information from the CT image and the segmentation masks of the PTV and OARs. Such anatomical information can indicate the structure and relative position of organs. By incorporating the anatomical information, the noise predictor can be aware of the dose constraints among PTV and OARs, thus distributing more appropriate dose to them and generating more accurate dose distribution maps.</p><p>Overall, the contributions of this paper can be concluded as follows: <ref type="bibr" target="#b0">(1)</ref> We propose a novel diffusion-based model for dose prediction in cancer radiotherapy to address the over-smoothing issue commonly encountered in existing DL-based dose prediction methods. To the best of our knowledge, we are the first to introduce the diffusion model for this task. <ref type="bibr" target="#b1">(2)</ref> We introduce a structure encoder to extract the anatomical information available in the CT images and organ segmentation masks, and exploit the anatomical information to guide the noise predictor in the diffusion model towards generating more precise predictions. (3) The proposed DiffDP is extensively evaluated on a clinical dataset consisting of 130 rectum cancer patients, and the results demonstrate that our approach outperforms other state-of-the-art methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>An overview of the proposed diffDP model is illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>, containing two Markov chain processes: a forward process and a reverse process. An image set of cancer patient is defined as {x, y}, where x ∈ R H ×W ×(2+o) represents the structure images, "2" signifies the CT image and the segmentation mask of the PTV, and o denotes the total number of segmentation mask of OARs. Meanwhile, y ∈ R H ×W ×1 is the corresponding dose distribution map for x. Concretely, the forward process produces a sequence of noisy images {y 0 , y 1 , . . . , y T }, y 0 = y by gradually adding a small amount of noise to y in T steps with the noise increased at each step and a noise predictor f is constructed to predict the noise added to y t-1 by treating y t , anatomic information from x and embedding of step t as input. To obtain the anatomic information, a structure encoder g is designed to extract the crucial feature representations from the structure images. Then, in the reverse process, the model progressively deduces the dose distribution map by iteratively denoising from y T using the well-trained noise predictor. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Diffusion Model</head><p>The framework of DiffDP is designed following the Denoising Diffusion Probabilistic Models (DDPM) <ref type="bibr" target="#b24">[25]</ref> which contains a forward process and a reverse process. By utilizing both processes, the DiffDP model can progressively transform the Gaussian noise into complex data distribution.</p><p>Forward Process. In the forward process, the DiffDP model employs the Markov chain to progressively add noise to the initial dose distribution map y 0 ∼ q(y 0 ) until the final disturbed image y T becomes completely Gaussian noise which is represented as y T ∼ N (y T | 0, I ). This forward process can be formulated as:</p><formula xml:id="formula_0">q(y 1:T | y 0 ) := T t=1 q(y t | y t-1 ),<label>(1)</label></formula><formula xml:id="formula_1">q(y t | y t-1 ) := N y t ; √ α t y t-1 , (1 -α t )I , (<label>2</label></formula><formula xml:id="formula_2">)</formula><p>where α t is the unlearnable standard deviation of the noise added to y t-1 . Herein, the α t (t = 1, . . . , T ) could accumulate during the forward process, which can be treated as the noise intensity γ t = t i=1 α i . Based on this, we can directly obtain the distribution of y t at any step t from y 0 through the following formula:</p><formula xml:id="formula_3">q(y t | y 0 ) = N y t ; √ γ t y 0 , (1 -γ t )I ,<label>(3)</label></formula><p>where the disturbed image y t is sampled using:</p><formula xml:id="formula_4">y t = √ γ t y 0 + 1 -γ t ε t ,<label>(4)</label></formula><p>in which ε t ∼ N (0, I ) is random noise sampled from normal Gaussian distribution.</p><p>Reverse Process. The reverse process also harnesses the Markov chain to progressively convert the latent variable distribution p θ (y T ) into distribution p θ (y 0 ) parameterized by θ . Corresponding to the forward process, the reverse one is a denoising transformation under the guidance of structure images x that begins with a standard Gaussian distribution y T ∼ N (y T | 0, I ). This reverse inference process can be formulated as:</p><formula xml:id="formula_5">p θ (y 0:T | y t , x) = p(y T ) T t=1 p θ (y t-1 | y t , x), (<label>5</label></formula><formula xml:id="formula_6">)</formula><formula xml:id="formula_7">p θ (y t-1 | y t , x) = N y t-1 ; μ θ (x, y t , γ t ), σ 2 t I . (<label>6</label></formula><formula xml:id="formula_8">)</formula><p>where μ θ (x, y t , t) is a learned mean, and σ t is a unlearnable standard deviation. Following the idea of <ref type="bibr" target="#b15">[16]</ref>, we parameterize the mean of μ θ as:</p><formula xml:id="formula_9">μ θ (x, y t , γ t ) = 1 √ α t y t - 1 -α t √ 1 -γ t ε t,θ ,<label>(7)</label></formula><p>where ε t,θ is a function approximator intended to predict ε t from the input x, y t and γ t . Consequently, the reverse inference at two adjacent steps can be expressed as:</p><formula xml:id="formula_10">y t-1 ← 1 √ α t y t - 1 -α t √ 1 -γ t ε t,θ + 1 -α t z t ,<label>(8)</label></formula><p>where z t ∼ N (0, I ) is a random noise sampled from normal Gaussian distribution. More derivation processes can be found in the original paper of diffusion model <ref type="bibr" target="#b24">[25]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Structure Encoder</head><p>Vanilla diffusion model has difficulty preserving essential structural information and produce unstable results when predicting dose distribution maps directly from noise with a simple condition mechanism. To address this, we design a structure encoder g that effectively extracts the anatomical information from the structure images guiding the noise predictor to generate more accurate dose maps by incorporating extracted structural knowledge. Concretely, the structure encoder includes five operation steps, each with a residual block (ResBlock) and a Down block, except for the last one. The ResBlock consists of two convolutional blocks (ConvBlock), each containing a 3 × 3 convolutional (Conv) layer, a GroupNorm (GN) layer, and a Swish activation function.</p><p>The residual connections are reserved for preventing gradient vanishment in the training.</p><p>The Down block includes a 3 × 3 Conv layer with a stride of 2. It takes structure image x as input, which includes the CT image and segmentation masks of PTV and OARs, and evacuates the compact feature representation in different levels to improve the accuracy of dose prediction. The structure encoder is pre-trained by L 1 loss and the corresponding feature representation x e = g(x) is then fed into the noise predictor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Noise Predictor</head><p>The purpose of the noise predictor f (x e , y t , γ t ) is to predict the noise added on the distribution map y t with the guidance of the feature representation x e extracted from the structure images x and current noise intensity γ t in each step t. Inspired by the great achievements of UNet <ref type="bibr" target="#b14">[15]</ref>, we employ a six-level UNet to construct the noise predictor. Specifically, the encoder holds the similar architecture with the structure encoder while the decoder comprises five deconvolution blocks to fulfill the up-sampling operation, and each contains an Up block and two ResBlock, except for the last one which discards the UP block. In each Up block, the Nearest neighbor up-sampling and a Conv layer with a kernel size of 1 are used. A bottleneck with two Resblocks and a self-attention module is embedded between the encoder and decoder.</p><p>In the encoding procedure, to guide the noise predictor with essential anatomical structure, the feature representations respectively extracted from the structure images x and noisy image y t are simultaneously fed into the noise predictor. Firstly, y t is encoded into feature maps through a convolutional layer. Then, these two feature maps are fused by element-wise addition, allowing the structure information in x to be transferred to the noise predictor. The following two down-sampling operations retain the addition operation to complete information fusion, while the last three use a cross-attention mechanism to gain similarity-based structure guidance at deeper levels.</p><p>In the decoding procedure, the noise predictor restores the feature representations captured by the encoder to the final output, i.e., the noise ε t,θ = f (x e , y t , γ t ) in step t. The skip connections between the encoder and decoder are reserved for multi-level feature reuse and aggregation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Objective Function</head><p>The main purpose of the DiffDP model is to train the noise predictor f and structure encoder g, so that the predicted noise ε t,θ = f (g(x), y t , γ t ) in the reverse process can approximate the added noise ε t in the forward process. To achieve this, we define the objective function as:</p><formula xml:id="formula_11">min θ E (x,y) E ε,γ f ⎛ ⎜ ⎝g(x), √ γ y 0 + 1 -γ ε t y t , γ t ⎞ ⎟ ⎠ -ε t , ε t ∼ N (0, I)<label>(9)</label></formula><p>For a clearer understanding, the training procedure is summarized in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1:</head><p>Training procedure 1: Input: Input image pairs where is the structure image and is the corresponding dose distribution map, the total number of diffusion steps 2: Initialize: Randomly initialize the noise predictor and pre-trained structure encoder 3: Repeat 4: Sample 5: Sample 6: Perform the gradient step on Equation (9) 7: until converged</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Training Details</head><p>We accomplish the proposed network in the PyTorch framework. All of our experiments are conducted through one NVIDIA RTX 3090 GPU with 24 GB memory and a batch size of 16 with an Adaptive moment estimation (Adam) optimizer. We train the whole model for 1500 epochs (about 1.5M training steps) where the learning rate is initialized to 1e-4 and reset to 5e-5 after 1200 epochs. The parameter T is set to 1000. Additionally, the noise intensity is initialized to 1e-2 and decayed to 1e-4 linearly along with the increase of steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head><p>Dataset and Evaluations. We measure the performance of our model on an in-house rectum cancer dataset which contains 130 patients who underwent volumetric modulated arc therapy (VMAT) treatment at West China Hospital. Concretely, for every patient, the CT images, PTV segmentation, OARs segmentations, and the clinically planned dose distribution are included. Additionally, there are four OARs of rectum cancer containing the bladder, femoral head R, femoral head L, and small intestine. We randomly select 98 patients for model training, 10 patients for validation, and the remaining 22 patients for test. The thickness of the CTs is 3 mm and all the images are resized to the resolution of 256 × 256 before the training procedure.</p><p>We measure the performance of our proposed model with multiple metrics. Considering Dm represents the minimal absorbed dose covering m% percentage volume of PTV, we involve D 98 , D 2 , maximum dose (D max ), and mean dose (D mean ) as metrics. Besides, the heterogeneity index (HI) is used to quantify dose heterogeneity <ref type="bibr" target="#b25">[26]</ref>. To quantify performance more directly, we calculate the difference ( ) of these metrics between the ground truth and the predicted results. More intuitively, we involve the dose volume histogram (DVH) <ref type="bibr" target="#b26">[27]</ref> as another essential metric of dose prediction performance. When the DVH curves of the predictions are closer to the ground truth, we can infer higher prediction accuracy.</p><p>Comparison with State-of-the-Art Methods. To verify the superior accuracy of our proposed model, we select multiple state-of-the-art (SOTA) models in dose prediction, containing UNet (2017) <ref type="bibr" target="#b6">[7]</ref>, GAN (2018) <ref type="bibr" target="#b11">[12]</ref>, deepLabV3+ (2020) <ref type="bibr" target="#b10">[11]</ref>, C3D (2021) <ref type="bibr" target="#b8">[9]</ref>, and PRUNet (2022) <ref type="bibr" target="#b9">[10]</ref>, for comparison. The quantitative comparison results are listed in Table . 1 where our method outperforms the existing SOTAs in terms of all metrics. Specifically, compared with deepLabV3+ with the second-best accuracy in HI (0.0448) and D 98 (0.0416), the results generated by the proposed are 0.0035 and 0.0014 lower, respectively. As for D 2 and D max , our method gains overwhelming performance with 0.0008 and 0.0005, respectively. Moreover, the paired t-test is conducted to investigate the significance of the results. The p-values between the proposed and other SOTAs are almost all less than 0.05, indicating that the enhancement of performance is statistically meaningful.</p><p>Besides the quantitative results, we also present the DVH curves derived by compared methods in Fig. <ref type="figure" target="#fig_2">3</ref>. The results are compared on PTV as well as two OARs: bladder and small intestine. Compared with other methods, the disparity between the DVH curves of   our method and the ground truth is the smallest, demonstrating the superior performance of the proposed. Furthermore, we display the visualization comparison in Fig. <ref type="figure" target="#fig_3">4</ref>. As we can see, the proposed model achieves the best visual quality with clearer and sharper high-frequency details (as indicated by red arrows). Furthermore, the error map of the proposed is the darkest, suggesting the least disparity compared with the ground truth.</p><p>Ablation Study. To study the contributions of key components of the proposed method, we conduct the ablation experiments by 1) removing the structure encoder from the proposed method and concatenating the anatomical images x and noisy image y t together as the original input for diffusion model (denoted as Baseline); 2) the proposed DiffDP model. The quantitative results are given in Table <ref type="table" target="#tab_1">2</ref>. We can clearly see the performance for all metrics is enhanced with the structure encoder, demonstrating its effectiveness in the proposed model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we introduce a novel diffusion-based dose prediction (DiffDP) model for predicting the radiotherapy dose distribution of cancer patients. The proposed method involves a forward and a reverse process to generate accurate prediction by progressively transferring the Gaussian noise into a dose distribution map. Moreover, we propose a structure encoder to extract anatomical information from patient anatomy images and enable the model to concentrate on the dose constraints within several essential organs. Extensive experiments on an in-house dataset with 130 rectum cancer patients demonstrate the superiority of our method.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Instances from a rectum cancer patient. (1) -(4): Dose maps predicted by UNet, GAN, deepLabV3+, and diffusion model.</figDesc><graphic coords="2,54,30,411,71,315,04,58,54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Illustration of the proposed DiffDP network.</figDesc><graphic coords="4,55,56,72,44,318,79,193,21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Visual comparison of DVH curves by our method and SOTA methods, including DVH curves of PTV, bladder, and small intestine.</figDesc><graphic coords="8,45,30,240,59,333,58,81,58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Visual comparison with SOTA models. From top to bottom: ground truth, predicted dose map and corresponding error maps.</figDesc><graphic coords="8,43,29,368,57,337,66,177,70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Quantitative comparison results with state-of-the-art methods in terms of HI , D 98 , D 2 , and D max . * means our method is significantly better than compared method with p &lt; 0.05 via paired t-test.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Ablation study of our method in terms of HI , D 98 , D 2 , and D mean . * means our method is significantly better than other variants with p &lt; 0.05 via paired t-test.</figDesc><table><row><cell>Methods</cell><cell>HI</cell><cell>D 98</cell><cell>D 2</cell><cell>D mean</cell></row><row><cell>Baseline</cell><cell cols="4">0.0444(4.7E-3)* 0.0426(4.2E-3) 0.0021(1.1E-5)* 0.0246(7.5E-4)*</cell></row><row><cell cols="2">Proposed 0.0413(4.5E-3)</cell><cell cols="2">0.0392(4.1E-3) 0.0008(1.1E-5)</cell><cell>0.0154(6.5E-4)</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement. This work is supported by the <rs type="funder">National Natural Science Foundation of China</rs> (<rs type="grantNumber">NSFC 62371325</rs>, <rs type="grantNumber">62071314</rs>), <rs type="programName">Sichuan Science and Technology Program</rs> <rs type="grantNumber">2023YFG0263</rs>, <rs type="grantNumber">2023YFG0025</rs>, <rs type="grantNumber">2023NSFSC0497</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_CegcXUj">
					<idno type="grant-number">NSFC 62371325</idno>
				</org>
				<org type="funding" xml:id="_NMVXk2t">
					<idno type="grant-number">62071314</idno>
					<orgName type="program" subtype="full">Sichuan Science and Technology Program</orgName>
				</org>
				<org type="funding" xml:id="_BxjjveZ">
					<idno type="grant-number">2023YFG0263</idno>
				</org>
				<org type="funding" xml:id="_fP2vz3K">
					<idno type="grant-number">2023YFG0025</idno>
				</org>
				<org type="funding" xml:id="_p2SbRmS">
					<idno type="grant-number">2023NSFSC0497</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Possibility of chest wall dose reduction using volumetric-modulated arc therapy (VMAT) in radiation-induced rib fracture cases: comparison with stereotactic body radiation therapy (SBRT)</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Murakami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Radiat. Res</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="327" to="332" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Semi-supervised medical image segmentation via a tripled-uncertainty guided mean teacher model with contrastive learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page">102447</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Variation in external beam treatment plan quality: an inter-institutional study of planners and planning systems</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Nelms</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pract. Radiat. Oncol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="296" to="305" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">ASMFS: adaptive-similarity-based multi-modality feature selection for classification of Alzheimer&apos;s disease. Pattern Recogn</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="page">108566</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">auto-context-based locality adaptive multi-modality GANs for PET synthesis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3D</biblScope>
			<biblScope unit="page" from="1328" to="1339" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Beyond covariance: SICE and kernel based visual feature representation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vision</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="page" from="300" to="320" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Dose prediction with U-Net: a feasibility study for predicting dose distributions from contours using deep learning on prostate IMRT patients</title>
		<author>
			<persName><forename type="first">D</forename><surname>Nguyen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.09233</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Incorporating isodose lines and gradient information via multi-task learning for dose prediction in radiotherapy</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tan</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87234-2_71</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87234-2_71" />
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer Assisted Intervention-MICCAI 2021: 24th International Conference, Proceedings, Part VII</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="753" to="763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A cascade 3D U-Net for dose prediction in radiotherapy</title>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Phys</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="5574" to="5582" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">VMAT dose prediction in radiotherapy by using progressive refinement UNet</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">488</biblScope>
			<biblScope unit="page" from="528" to="539" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Dose prediction using a deep neural network for accelerated planning of rectal cancer radiotherapy</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiother. Oncol</title>
		<imprint>
			<biblScope unit="volume">149</biblScope>
			<biblScope unit="page" from="111" to="116" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Automated treatment planning in radiation therapy using generative adversarial networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Babier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mcniven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Diamant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning for Healthcare Conference</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="484" to="499" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multi-constraint generative adversarial network for dose prediction in radiotherapy</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page">102339</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A transformer-embedded multi-task model for dose distribution prediction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Neural Syst</title>
		<imprint>
			<biblScope unit="page">2350043</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">U-Net: convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-24574-4_28</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-24574-4_28" />
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer-Assisted Intervention-MICCAI 2015: 18th International Conference</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hornegger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Wells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Frangi</surname></persName>
		</editor>
		<meeting><address><addrLine>Munich, Germany; Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015-10-09">5-9 October 2015. 2015</date>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-01234-2_49</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-01234-2_49" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<editor>
			<persName><forename type="first">V</forename><surname>Ferrari</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hebert</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Sminchisescu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</editor>
		<meeting>the European Conference on Computer Vision (ECCV)<address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="801" to="818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Explainable attention guided adversarial deep network for 3D radiotherapy dose distribution prediction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowl.-Based Syst</title>
		<imprint>
			<biblScope unit="volume">241</biblScope>
			<biblScope unit="page">108324</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Multi-level progressive transfer learning for cervical cancer dose prediction. Pattern Recogn</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">141</biblScope>
			<biblScope unit="page">109606</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.02398</idno>
		<title level="m">Diffusion model for generative image denoising</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep unsupervised learning using nonequilibrium thermodynamics</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Maheswaranathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ganguli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2256" to="2265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Diffusion models for medical anomaly detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wolleb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bieder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sandkühler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Cattin</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16452-1_4</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16452-1_4" />
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer Assisted Intervention-MICCAI 2022: 25th International Conference, Proceedings, Part VIII</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="35" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Diffusion deformable model for 4D temporal medical image generation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Ye</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16431-6_51</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16431-6_51" />
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer Assisted Intervention-MICCAI 2022: 25th International Conference, Proceedings, Part I</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="539" to="548" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Diffusion kernel attention network for brain disorder classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2814" to="2827" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">SRDiff: single image super-resolution with diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">479</biblScope>
			<biblScope unit="page" from="47" to="59" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Denoising diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural. Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6840" to="6851" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Denoising diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Helal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Omar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6840" to="6851" />
		</imprint>
	</monogr>
	<note>Homogeneity index: effective tool</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Clinical dose-volume histogram analysis for pneumonitis after 3D treatment for non-small cell lung cancer (NSCLC)</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Graham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Radiat. Oncol. Biol. Phys</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="323" to="329" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
