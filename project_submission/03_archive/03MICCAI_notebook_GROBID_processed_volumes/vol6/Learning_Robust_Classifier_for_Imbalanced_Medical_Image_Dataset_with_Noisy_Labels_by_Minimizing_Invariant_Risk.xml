<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk</title>
				<funder ref="#_kUHemHX">
					<orgName type="full">Hong Kong Innovation and Technology Fund</orgName>
				</funder>
				<funder ref="#_XZ9QEtz">
					<orgName type="full">Research Grants Council of the Hong Kong Special Administrative Region, China</orgName>
				</funder>
				<funder ref="#_eUhHkKu">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_sQvCpkd">
					<orgName type="full">Natural Science Foundation of Guangdong Province</orgName>
				</funder>
				<funder ref="#_NHxvRkW">
					<orgName type="full">Shenzhen Portion of Shenzhen-Hong Kong Science and Technology Innovation Cooperation Zone</orgName>
				</funder>
				<funder ref="#_mVQrGd5">
					<orgName type="full">National Key R&amp;D Program of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jinpeng</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Shatin, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hanqun</forename><surname>Cao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Shatin, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiaze</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Shatin, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Furui</forename><surname>Liu</surname></persName>
							<affiliation key="aff2">
								<orgName type="laboratory">Zhejiang Lab</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qi</forename><surname>Dou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Shatin, Hong Kong</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute of Medical Intelligence and XR</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Shatin, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Guangyong</forename><surname>Chen</surname></persName>
							<email>gychen@zhejianglab.com</email>
							<affiliation key="aff2">
								<orgName type="laboratory">Zhejiang Lab</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pheng-Ann</forename><surname>Heng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Shatin, Hong Kong</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute of Medical Intelligence and XR</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Shatin, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="306" to="316"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">E8C7B5EC72E4A79E671E8D87E717F2CE</idno>
					<idno type="DOI">10.1007/978-3-031-43987-2_30</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-13T19:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Imbalanced Data</term>
					<term>Noisy Labels</term>
					<term>Medical Image Analysis</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In medical image analysis, imbalanced noisy dataset classification poses a long-standing and critical problem since clinical largescale datasets often attain noisy labels and imbalanced distributions through annotation and collection. Current approaches addressing noisy labels and long-tailed distributions separately may negatively impact real-world practices. Additionally, the factor of class hardness hindering label noise removal remains undiscovered, causing a critical necessity for an approach to enhance the classification performance of noisy imbalanced medical datasets with various class hardness. To address this paradox, we propose a robust classifier that trains on a multi-stage noise removal framework, which jointly rectifies the adverse effects of label noise, imbalanced distribution, and class hardness. The proposed noise removal framework consists of multiple phases. Multi-Environment Risk Minimization (MER) strategy captures data-to-label causal features for noise identification, and the Rescaling Class-aware Gaussian Mixture Modeling (RCGM) learns class-invariant detection mappings for noise removal. Extensive experiments on two imbalanced noisy clinical datasets demonstrate the capability and potential of our method for boosting the performance of medical image classification.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Image classification is a significant challenge in medical image analysis. Although some classification methods achieve promising performance on balanced and clean medical datasets, balanced datasets with high-accuracy annotations are time-consuming and expensive. Besides, pruning clean and balanced datasets require a large amount of crucial clinical data, which is insufficient for large-scale deep learning. Therefore, we focus on a more practical yet unexplored setting for handling imbalanced medical data with noisy labels, utilizing all available lowcost data with possible noisy annotations. Noisy imbalanced datasets arise due to the lack of high-quality annotations <ref type="bibr" target="#b10">[11]</ref> and skewed data distributions <ref type="bibr" target="#b17">[18]</ref> where the number of instances largely varies across different classes. Besides, the class hardness problem where classification difficulties vary for different categories presents another challenge in removing label noise. Due to differences in disease epidemicity and collection difficulty, rare anomalies or anatomical features render diseases with low epidemicity easier to detect. However, existing techniques <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24]</ref> fail to jointly address these scenarios, leading to inadequate classification outcomes. Therefore, noisy-labeled, imbalanced datasets with various class hardness remain a persistent challenge in medical classification.</p><p>Existing approaches for non-ideal medical image classification can be summarized into noisy classification, imbalanced recognition, and noisy imbalanced identification. Noisy classification approaches <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b22">23]</ref> conduct noise-invariant learning depending on the big-loss hypothesis, where classifiers trained with clean data with lower empirical loss aid with de-noising identification. However, imbalanced data creates different confidence distributions of clean and noisy data in the majority class and minority class as shown in Fig. <ref type="figure" target="#fig_0">1</ref>, which invalidates the big-loss assumption <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>. Imbalanced recognition approaches <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b20">21]</ref> utilize augmented embeddings and imbalance-invariant training loss to re-balance the long-tailed medical data artificially, but the disturbance from noisy labels leads to uncasual feature learning, impeding the recognition of tail classes. Noisy longtailed identification technique <ref type="bibr" target="#b24">[25]</ref> has achieved promising results by addressing noise and imbalance concerns sequentially. However, the class hardness problem leads to vague decision boundaries that hinders accurate' noise identification.</p><p>In this work, we propose a multi-stage noise removal framework to address these concerns jointly. The main contributions of our work include: 1) We decompose the negative effects in practical medical image classification, 2) We minimize the invariant risk to tackle noise identification influenced by multiple factors, enabling the classifier to learn causal features and be distribution-invariant, 3) A re-scaling class-aware Gaussian Mixture Modeling (CGMM) approach is proposed to distinguish noise labels under various class hardness, 4) We evaluate our method on two medical image datasets, and conduct thorough ablation studies to demonstrate our approach's effectiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem Formulation</head><p>In the noisy imbalanced classification setting, we denote a medical dataset as {(x i , y i )} N i=1 where y i is the corresponding label of data x i and N is the total amount of instances. Here y i may be noisy. Further, we split the dataset according to class categories. Then, we have {D j } M j=1 , where M is the number of classes; D j denotes the subset for class j. In each subset containing N j samples, the data pairs are expressed as {(x j i , y j i )} Nj i=1 . Without loss of generality, we order the classes as N 1 &gt; N 2 &gt; ... &gt; N M -1 &gt; N M . Further, we denote the backbone as H(•; θ), X → Z mapping data manifold to the latent manifold, the classifier head as G(•; γ), Z → C linking latent space to the category logit space, and the identifier as F(•; φ), Z → C. We aim to train a robust medical image classification model composed of a representation backbone and a classifier head on label noise and imbalance distribution, resulting in a minimized loss on the testing dataset:</p><formula xml:id="formula_0">min i∈D L(G H(x test i ; θ); γ , y test i ) (1)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Mapping Correction Decomposition</head><p>We decompose the non-linear mapping p(y = c|x) as a product of two space mappings p G (y = c|z) • p H (z|x). Given that backbone mapping is independent of noisy imbalanced effects, we conduct further disentanglement by defining e as the negative effects and P as constant for fixed probability mappings:</p><formula xml:id="formula_1">p(y = c|x, e) = p H (z|x) • p G (y = c|z, e) = p H (z|x) • {p G (y = c|z) • p G (y = c|e)} = p H (z|x) • p G (y = c|z) • {p G (y = c|[e i , e n , e m ])} = P • Imbalance p G (e i |y = c) Hardness p G (e m |y = c, e i ) Noise p G (e n |y = c, e i , e m )<label>(2)</label></formula><p>The induction derives from the assumption that the incorrect mapping p G (y = c|z, e) conditions on both pure latent to logits mapping p G (y = c|z) and adverse effects p G (y = c|e). By Bayes theorem, we decompose the effect into imbalance, noise, and mode (hardness), where the noise effect depends on skew distribution and hardness effect; and the hardness effect is noise-invariant. Currently, noise removal methods only address pure noise effects (p G (e n |y = c)), while imbalance recognition methods can only resolve imbalanced distribution, which hinders the co-removal of adverse influences. Furthermore, the impact of hardness effects has not been considered in previous studies, which adds an extra dimension to noise removal. In essence, the fundamental idea of noisy classification involves utilizing clean data for classifier training, which determines the importance of noise identification and removal. To address these issues, we propose a mapping correction approach that combines independent noise detection and removal techniques to identify and remove noise effectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Minimizing Invariant Risk Across Multi-distributions</head><p>Traditional learning with noisy label methods mainly minimize empirical risk on training data. However, they fail to consider the influence of imbalanced distributions, which might cause a biased gradient direction on the optimization subspace. Following <ref type="bibr" target="#b24">[25]</ref>, we minimize the invariant risk <ref type="bibr" target="#b1">[2]</ref> across multi-environment for independent detector learning. By assuming that the robust classifier performs well on every data distribution, we solve the optimizing object by finding the optima to reduce the averaged distance for gradient shift: min</p><formula xml:id="formula_2">H θ :X →Z F φ :Z→Y ε∈Etr L(F φ • H θ ) s.t. F φ ∈ arg min Fφ :Z→Y L( Fφ • H θ ), ∀ε ∈ E tr , (3)</formula><p>where ε represents an environment (distribution) for classifier F φ and backbone H θ ; and L denotes the empirical loss for classification. Since the incorrect mapping is not caused by feature representation, the backbone H θ is fixed during the optimization. By transferring the constraints into a penalty in the optimizing object, we solve this problem by learning the constraint scale ω <ref type="bibr" target="#b1">[2]</ref>:</p><formula xml:id="formula_3">min F L(F • H) + ∇ w|w=1 L(w • F • H) 2 2 . (<label>4</label></formula><formula xml:id="formula_4">)</formula><p>Ideally, the noise removal process is distribution-invariant if data is uniformly distributed w.r.t. classes. By the law of large numbers, all constructed distributions should be symmetric according to the balanced distribution to obtain a uniform expectation. To simplify this assumption, we construct three different data distributions <ref type="bibr" target="#b24">[25]</ref> composed of one uniform distribution and two symmetric skewed distributions instead of theoretical settings. In practice, all environments are established from the training set with the same class categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Rescaling Class-Aware Gaussian Mixture</head><p>Existing noise labels learning methods <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b12">13]</ref> cluster all sample loss or confidence scores with Beta Mixture Model or Gaussian Mixture Model into noisy and clean distributions. From the perspective of clustering, definite and immense gaps between two congregate groups contribute to more accurate decisions. However, in medical image analysis, an overlooked mismatch exists between class hardness and difficulty in noise identification. This results in ineffectiveness of global cluster methods in detecting label noises across all categories. To resolve the challenge, we propose a novel method called rescaling class-aware Gaussian Mixture Modeling (RCGM) which clusters each category data independently by fitting confidence scores q ij from ith class into two Gaussian distributions as p n i (x n |μ n , Σ n ) and p c i (x c |μ c , Σ c ). The mixed Gaussian p M i (•) is obtained by linear combinations α ik for each distribution:</p><formula xml:id="formula_5">p M i (q ij ) := k∈{c,n} α ik p k i q ij | μ k i , Σ k i ,<label>(5)</label></formula><p>which produces more accurate and independent measurements of label quality. Rather than relying on the assumption that confidence distributions of training samples depend solely on their label quality, RCGM solves the effect of class hardness in noisy detection by individually clustering the scores in each category. This overcomes the limitations of global clustering methods and significantly enhances the accuracy of noise identification even when class hardness varies.</p><p>Instead of assigning a hard label to the potential noisy data as <ref type="bibr" target="#b7">[8]</ref> which also employs a class-specific GMM to cluster the uncertainty, we further re-scale the confidence score of class-wise noisy data. Let x ij be the jth in class i, then its probability of having a clean label is:</p><formula xml:id="formula_6">γ ij = α ik p c i (q ij | μ c i , Σ c i ) p M i (q ij ) , (<label>6</label></formula><formula xml:id="formula_7">)</formula><p>which is then multiplied by a hyperparameter s if the instance is predicted as noise to reduce its weight in the finetuning. With a pre-defined noise selection threshold as τ , we have the final clean score as:</p><formula xml:id="formula_8">v(x ij ) := γ ij if γ ij ≥ τ s • γ ij if γ ij &lt; τ (7)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Overall Learning Framework for Imbalanced and Noisy Data</head><p>In contrast to two-stage noise removal and imbalance classification techniques, our approach applies a multi-stage protocol: warm-up phases, noise removal phases, and fine-tuning phases as shown in Fig. <ref type="figure" target="#fig_1">2</ref>. In the warm-up stage, we train backbone H and classifier G a few epochs by assuming that G only remembers clean images with less empirical loss. In the noise removal phases, we learn classinvariant probability distributions of noisy-label effect with MER and remove class hardness impact with RCGM. Finally, in the fine-tuning phases, we apply MixUp technique <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26]</ref> to rebuild a hybrid distribution from noisy pairs and clean pairs by:</p><formula xml:id="formula_9">xkl := α kl x k + (1 -α kl )x l , ∀x k , x l ∈ D ŷkl := α kl y k + (1 -α kl )y l , ∀y k , y l ∈ D (<label>8</label></formula><formula xml:id="formula_10">)</formula><p>where α kl := v(x k ) v(x l ) denotes the balanced scale; and {(x kl , ŷkl )} are the mixed clean data for classifier fine-tuning. Sqrt sampler is applied to re-balance the data, and cross-stage KL <ref type="bibr" target="#b11">[12]</ref> and CE loss are the fine-tuning loss functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset and Evaluation Metric</head><p>We evaluated our approach on two medical image datasets with imbalanced class distributions and noisy labels. The first dataset, HAM10000 <ref type="bibr" target="#b21">[22]</ref>, is a dermatoscopic image dataset for skin-lesion classification with 10,015 images divided into seven categories. It contains a training set with 7,007 images, a validation set with 1,003 images, and a testing set with 2,005 images. Following the previous noisy label settings <ref type="bibr" target="#b24">[25]</ref>, we add 20% noise to its training set by randomly flipping labels. The second dataset, CHAOYANG <ref type="bibr" target="#b28">[29]</ref>, is a histopathology image dataset manually annotated into four cancer categories by three pathological experts, with 40% of training samples having inconsistent annotations from the experts. To emulate imbalanced scenarios, we prune the class sizes of the training set into an imbalanced distribution as <ref type="bibr" target="#b4">[5]</ref>. Consequently, CHAOYANG dataset consists of a training set with 2,181 images, a validation set with 713 images, and a testing set with 1,426 images, where the validation and testing sets have clean labels. The imbalanced ratios <ref type="bibr" target="#b11">[12]</ref> of HAM10000 and CHAOYANG are 59 and 20, respectively. The evaluation metrics are Macro-F1, B-ACC, and MCC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Implementation Details</head><p>We mainly follow the training settings of FCD <ref type="bibr" target="#b11">[12]</ref>. ResNet-18 pretrained on the ImageNet is the backbone. The batch size is 48. Learning rates are 0.06, 0.001, 0.06 and 0.006 with the cosine schedule for four stages, respectively. We train our models by SGD optimizer with sharpness-aware term <ref type="bibr" target="#b5">[6]</ref> for 90, 90, 90, and 20 epochs. The size of input image is 224 × 224. The scale and threshold in RCGM are 0.6 and 0.1, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Comparison with State-of-the-Art Methods</head><p>We compare our model with state-of-the-art methods which contain noisy methods (including DivideMix <ref type="bibr" target="#b12">[13]</ref>, NL <ref type="bibr" target="#b15">[16]</ref>, GCE <ref type="bibr" target="#b26">[27]</ref>, Co-Learning <ref type="bibr" target="#b18">[19]</ref>), imbalance methods (including Focal Loss <ref type="bibr" target="#b13">[14]</ref>, Sqrt-RS <ref type="bibr" target="#b16">[17]</ref>, PG-RS <ref type="bibr" target="#b9">[10]</ref>, CB-Focal <ref type="bibr" target="#b4">[5]</ref>, EQL <ref type="bibr" target="#b20">[21]</ref>, EQL V2 <ref type="bibr" target="#b19">[20]</ref>, CECE <ref type="bibr" target="#b4">[5]</ref>, CLAS <ref type="bibr" target="#b27">[28]</ref>, FCD <ref type="bibr" target="#b11">[12]</ref>), and noisy imbalanced classification methods (including H2E <ref type="bibr" target="#b24">[25]</ref>, NL+Sqrt-RS, GCE+Sqrt-RS, GCE+Focal). We train all approaches under the same data augmentations and network architecture.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Ablation Studies</head><p>As shown in Fig. <ref type="figure" target="#fig_2">3</ref>, we evaluate the effectiveness of the components in our method by decomposing them on extensive experiments. We choose the first stage of FCD <ref type="bibr" target="#b11">[12]</ref> as our baseline. Figure <ref type="figure" target="#fig_2">3a</ref> and 3b show that only using MER or RCGM achieves better performance than our strong baseline on both datasets. For example, MER achieves 5.37% and 1.15% improvements on HAM10000 and CHAOYANG, respectively, demonstrating the effectiveness of our noise removal techniques. Further, our multi-stage noise removal technique outperforms single MER and RCGM, revealing that the decomposition for noise effect and hardness effect works on noisy imbalanced datasets. We find that the combination of MER and RCGM improves more on CHAOYANG dataset. This is because CHAOYANG has more possible label noise than HAM10000 caused by the high annotating procedure. From Fig. <ref type="figure" target="#fig_2">3c</ref>, we observe the accuracy trends are as the scale increases and achieve the peak around 0.6. It indicates the re-scaling process for noise weight deduction contributes to balancing the feature learning and classification boundary disturbance from the mixture of noisy and clean data. Furthermore, similar performance trends reveal the robustness of scale s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion and Discussion</head><p>We propose a multi-step framework for noisy long-imbalanced medical image classification. We address three practical adverse effects including data noise, imbalanced distribution, and class hardness. To solve these difficulties, we conduct Multi-Environment Risk Minimization (MER) and rescaling class-aware Gaussian Mixture Modeling (RCGM) together for robust feature learning.</p><p>Extensive results on two public medical image datasets have verified that our framework works on the noisy imbalanced classification problem. The main limitation of our work is the manually designed multi-stage training protocol which lacks simplicity compared to end-to-end training and warrants future simplification.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Analysis of confidence distributions and class hardness on imbalanced noisy HAM10000 dataset [22]. (a) and (b) are confidence distributions of clean and noisy data on the majority class and the minority class, respectively (c) is the relationship between class rate and F1 score among different classes.</figDesc><graphic coords="2,57,48,53,72,337,27,89,98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Protocol for Noisy Long-tailed Recognition: (a) shows warm-up and MER schemes. Backbone H and classifier G are first trained in the warm-up phase. Noise identifier F is optimized across three constructed environments with H fixed during MER. (b) represents RCGM scheme for class-aware noise detection and score re-scaling. (c) displays final fine-tuning procedures including noise removal finetune and re-balanced finetune.</figDesc><graphic coords="4,61,92,78,53,316,72,138,97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Ablation analysis. (a) and (b) Quantitative performance comparison of different components of our method on HAM10000 and CHAOYANG datasets, respectively. (c) Comparative results of our approach with different s values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Quantitative comparisons with state-of-the-art methods on HAM10000 and CHAOYANG datasets. The second-best performances are underlined.</figDesc><table><row><cell>Method</cell><cell>HAM10000</cell><cell></cell><cell cols="2">CHAOYANG</cell><cell></cell></row><row><cell></cell><cell cols="5">Macro-F1 B-ACC MCC Macro-F1 B-ACC MCC</cell></row><row><cell>Focal Loss [14]</cell><cell>66.16</cell><cell>65.21</cell><cell>59.86 70.84</cell><cell>69.10</cell><cell>70.27</cell></row><row><cell>Sqrt-RS [17]</cell><cell>67.02</cell><cell>66.28</cell><cell>55.09 70.39</cell><cell>68.56</cell><cell>69.71</cell></row><row><cell>PG-RS [10]</cell><cell>62.91</cell><cell>63.29</cell><cell>51.14 71.03</cell><cell>69.35</cell><cell>70.18</cell></row><row><cell>CB-Focal [5]</cell><cell>63.41</cell><cell>72.63</cell><cell>52.21 73.20</cell><cell>72.46</cell><cell>71.37</cell></row><row><cell>EQL [21]</cell><cell>60.94</cell><cell>66.18</cell><cell>55.53 71.09</cell><cell>70.53</cell><cell>70.77</cell></row><row><cell>EQL V2 [20]</cell><cell>58.33</cell><cell>54.70</cell><cell>52.01 69.24</cell><cell>68.35</cell><cell>67.78</cell></row><row><cell>CECE [5]</cell><cell>40.92</cell><cell>56.75</cell><cell>37.46 47.12</cell><cell>47.56</cell><cell>43.50</cell></row><row><cell>CLAS [28]</cell><cell>69.61</cell><cell>70.85</cell><cell>63.67 71.91</cell><cell>71.46</cell><cell>70.71</cell></row><row><cell>FCD [12]</cell><cell>71.08</cell><cell>72.85</cell><cell>66.58 71.82</cell><cell>70.07</cell><cell>71.76</cell></row><row><cell>DivideMix [13]</cell><cell>69.72</cell><cell>70.84</cell><cell>65.33 50.44</cell><cell>49.34</cell><cell>50.29</cell></row><row><cell>NL [16]</cell><cell>44.42</cell><cell>42.52</cell><cell>55.81 71.75</cell><cell>69.99</cell><cell>71.63</cell></row><row><cell>NL+Sqrt-RS</cell><cell>62.46</cell><cell>61.42</cell><cell>52.44 71.77</cell><cell>70.88</cell><cell>71.46</cell></row><row><cell>GCE [27]</cell><cell>50.47</cell><cell>48.91</cell><cell>63.63 21.04</cell><cell>28.12</cell><cell>4.13</cell></row><row><cell>GCE+Sqrt-RS</cell><cell>70.81</cell><cell>70.76</cell><cell>65.86 70.83</cell><cell>69.77</cell><cell>70.21</cell></row><row><cell>GCE+Focal</cell><cell>66.19</cell><cell>68.71</cell><cell>61.82 72.91</cell><cell>71.25</cell><cell>72.68</cell></row><row><cell cols="2">Co-Learning [19] 58.05</cell><cell>51.02</cell><cell>57.73 60.73</cell><cell>59.78</cell><cell>64.13</cell></row><row><cell>H2E [25]</cell><cell>69.69</cell><cell>69.11</cell><cell>63.48 69.36</cell><cell>67.89</cell><cell>68.59</cell></row><row><cell>Ours</cell><cell>76.43</cell><cell cols="2">75.60 70.19 74.50</cell><cell cols="2">72.75 73.08</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Table1exhibits the overall comparison of all approaches. We first conclude that noisy imbalanced setting does negatively affect learning with noise methods and imbalanced methods. In imbalanced methods, CECE only obtains 40.92 in Macro-F1 on HAM10000 and 47.12% Macro-F1 on CHAOYANG. In noisy methods, NL and GCE also suffer great performance declines. We mix these weakly-performed approaches with methods from the other category, observing the accuracy improvement. Compared to GCE, GCE+Sqrt-RS achieves +20.34% Macro-F1 on HAM10000 and +49.79% Macro-F1 on CHAOYANG. Similar increases happen in GCE &amp; GCE+Focal and NL &amp; NL+Sqrt-RS. Then, we compare our approach to state-of-the-art methods of the noisy (DivideMix), imbalanced (FCD), and noisy long-tailed (H2E) methods. Our framework achieves improvements in all metrics on both datasets, demonstrating the rationality of the assumption and the effectiveness of our framework.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowlegdement. This work described in this paper was supported in part by the <rs type="funder">Shenzhen Portion of Shenzhen-Hong Kong Science and Technology Innovation Cooperation Zone</rs> under <rs type="grantNumber">HZQB-KCZYB-20200089</rs>. The work was also partially supported by a grant from the <rs type="funder">Research Grants Council of the Hong Kong Special Administrative Region, China</rs> (Project Number: <rs type="grantNumber">T45-401/22-N</rs>) and by a grant from the <rs type="funder">Hong Kong Innovation and Technology Fund</rs> (Project Number: <rs type="grantNumber">GHP/080/20SZ</rs>). The work was also partially supported by a grant from the <rs type="funder">National Key R&amp;D Program of China</rs> (<rs type="grantNumber">2022YFE0200700</rs>), a grant from the <rs type="funder">National Natural Science Foundation of China</rs> (Project No. <rs type="grantNumber">62006219</rs>), and a grant from the <rs type="funder">Natural Science Foundation of Guangdong Province</rs> (<rs type="grantNumber">2022A1515011579</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_NHxvRkW">
					<idno type="grant-number">HZQB-KCZYB-20200089</idno>
				</org>
				<org type="funding" xml:id="_XZ9QEtz">
					<idno type="grant-number">T45-401/22-N</idno>
				</org>
				<org type="funding" xml:id="_kUHemHX">
					<idno type="grant-number">GHP/080/20SZ</idno>
				</org>
				<org type="funding" xml:id="_mVQrGd5">
					<idno type="grant-number">2022YFE0200700</idno>
				</org>
				<org type="funding" xml:id="_eUhHkKu">
					<idno type="grant-number">62006219</idno>
				</org>
				<org type="funding" xml:id="_sQvCpkd">
					<idno type="grant-number">2022A1515011579</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43987-2 30.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Unsupervised label noise modeling and loss correction</title>
		<author>
			<persName><forename type="first">E</forename><surname>Arazo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ortego</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">E</forename><surname>O'connor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mcguinness</surname></persName>
		</author>
		<editor>Chaudhuri, K., Salakhutdinov, R.</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">2019</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.02893</idno>
		<title level="m">Invariant risk minimization</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Understanding and utilizing deep neural networks trained with noisy labels</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">B</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Webly supervised learning of convolutional networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Class-balanced loss based on effective number of samples</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Sharpness-aware minimization for efficiently improving generalization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Foret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kleiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mobahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Neyshabur</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=6Tm1mposlrM" />
	</analytic>
	<monogr>
		<title level="m">9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria</title>
		<imprint>
			<date type="published" when="2021-05-07">3-7 May 2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Classification in the presence of label noise: a survey</title>
		<author>
			<persName><forename type="first">B</forename><surname>Frénay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Verleysen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TNNLS</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="845" to="869" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Uncertainty-aware learning against label noise on imbalanced datasets</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<ptr target="https://ojs.aaai.org/index.php/AAAI/article/view/20654" />
	</analytic>
	<monogr>
		<title level="m">Thirty-Sixth AAAI Conference on Artificial Intelligence, AAAI 2022, Thirty-Fourth Conference on Innovative Applications of Artificial Intelligence, IAAI 2022, The Twelveth Symposium on Educational Advances in Artificial Intelligence, EAAI 2022 Virtual Event</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2022-03-01">22 February-1 March 2022. 2022</date>
			<biblScope unit="page" from="6960" to="6969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Decoupling representation and classifier for long-tailed recognition</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.09217</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Decoupling representation and classifier for long-tailed recognition</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep learning with noisy labels: exploring techniques and remedies in medical image analysis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Warfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gholipour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page">101759</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Flat-aware cross-stage distilled framework for imbalanced medical image classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16437-8_21</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16437-821" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13433</biblScope>
			<biblScope unit="page" from="217" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Dividemix: learning with noisy labels as semisupervised learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
		<idno>ICLR 2020</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Focal loss for dense object detection</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Deep representation learning on longtailed data: a learnable embedding augmentation perspective</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Normalized loss functions for deep learning with noisy labels</title>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Erfani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML 2020</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Exploring the limits of weakly supervised pretraining</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mahajan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning from noisy labels with deep neural networks: a survey</title>
		<author>
			<persName><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TNNLS</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Co-learning: learning from noisy labels with self-supervision</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM 2021</title>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Shen</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Equalization loss V2: a new gradient balance approach for long-tailed object detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Equalization loss for long-tailed object recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2020</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions</title>
		<author>
			<persName><forename type="first">P</forename><surname>Tschandl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rosendahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kittler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Data</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Robust learning at noisy labeled medical images: applied to skin lesion classification</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
		<idno>ISBI 2019</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Robust medical image classification from noisy labeled data with global and local representation guided co-training</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TMI</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1371" to="1382" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Identifying hard noise in longtailed sample distribution</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">S</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-19809-0_42</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-19809-042" />
	</analytic>
	<monogr>
		<title level="m">ECCV 2022</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Avidan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Brostow</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Cissé</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Farinella</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Hassner</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13686</biblScope>
			<biblScope unit="page" from="739" to="756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.09412</idno>
		<title level="m">mixup: beyond empirical risk minimization</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Generalized cross entropy loss for training deep neural networks with noisy labels</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Sabuncu</surname></persName>
		</author>
		<editor>Bengio, S., Wallach, H.M., Larochelle, H., Grauman, K., Cesa-Bianchi, N., Garnett, R.</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page">2018</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Improving calibration for long-tailed recognition</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2021</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Hard sample aware noise robust learning for histopathology image classification</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TMI</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="881" to="894" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
