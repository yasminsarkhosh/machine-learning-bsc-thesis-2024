<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis</title>
				<funder ref="#_Hup5BvF">
					<orgName type="full">County of Salzburg</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Michael</forename><surname>Gadermayr</surname></persName>
							<email>michael.gadermayr@fh-salzburg.ac.at</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Technology and Digitalization</orgName>
								<orgName type="institution">Salzburg University of Applied Sciences</orgName>
								<address>
									<settlement>Salzburg</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lukas</forename><surname>Koller</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Technology and Digitalization</orgName>
								<orgName type="institution">Salzburg University of Applied Sciences</orgName>
								<address>
									<settlement>Salzburg</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Maximilian</forename><surname>Tschuchnig</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Technology and Digitalization</orgName>
								<orgName type="institution">Salzburg University of Applied Sciences</orgName>
								<address>
									<settlement>Salzburg</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lea</forename><forename type="middle">Maria</forename><surname>Stangassinger</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Biomedical Sciences</orgName>
								<orgName type="institution">Salzburg University of Applied Sciences</orgName>
								<address>
									<settlement>Salzburg</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Christina</forename><surname>Kreutzer</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Spinal Cord Injury and Tissue Regeneration Center Salzburg</orgName>
								<orgName type="institution">Research Institute of Experimental Neuroregeneration</orgName>
								<address>
									<settlement>Salzburg</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sebastien</forename><surname>Couillard-Despres</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Spinal Cord Injury and Tissue Regeneration Center Salzburg</orgName>
								<orgName type="institution">Research Institute of Experimental Neuroregeneration</orgName>
								<address>
									<settlement>Salzburg</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gertie</forename><forename type="middle">Janneke</forename><surname>Oostingh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Anton</forename><surname>Hittmair</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Pathology and Microbiology</orgName>
								<orgName type="institution">Kardinal Schwarzenberg Klinikum</orgName>
								<address>
									<settlement>Schwarzach</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="477" to="486"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">2E0E60CFF5FEBC21F865EAADF4232359</idno>
					<idno type="DOI">10.1007/978-3-031-43987-2_46</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-13T19:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Histopathology</term>
					<term>Data augmentation</term>
					<term>MixUp</term>
					<term>Multiple Instance Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Multiple instance learning is a powerful approach for whole slide image-based diagnosis in the absence of pixel-or patch-level annotations. In spite of the huge size of whole slide images, the number of individual slides is often rather small, leading to a small number of labeled samples. To improve training, we propose and investigate novel data augmentation strategies for multiple instance learning based on the idea of linear and multilinear interpolation of feature vectors within and between individual whole slide images. Based on stateof-the-art multiple instance learning architectures and two thyroid cancer data sets, an exhaustive study was conducted considering a range of common data augmentation strategies. Whereas a strategy based on to the original MixUp approach showed decreases in accuracy, a novel multilinear intra-slide interpolation method led to consistent increases in accuracy.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Motivation</head><p>Whole slide imaging is capable of effectively digitizing specimen slides, showing both the microscopic detail and the larger context, without any significant manual effort. Due to the enormous resolution of the whole slide images (WSIs), a classification based on straight-forward convolutional neural network architectures is not feasible. Multiple instance learning <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b10">10,</ref><ref type="bibr" target="#b13">13,</ref><ref type="bibr" target="#b18">18,</ref><ref type="bibr" target="#b20">20]</ref> (MIL) represents a methodology (with a high momentum indicated by a large number of recent publications) to deal with these huge images corresponding to single (global) labels. In the MIL setting, WSIs correspond to labeled bags, whereas extracted patches correspond to unlabeled bag instances. MIL approaches typically consist of a feature extraction stage, a MIL pooling stage and a following downstream classification. State-of-the-art approaches mainly rely on convolutional neural network architectures for feature extraction, often in combination with attention <ref type="bibr" target="#b10">[10,</ref><ref type="bibr" target="#b11">11]</ref> or self-attention <ref type="bibr" target="#b12">[12]</ref>. For training the feature extraction stage, classical supervised and self-supervised learning is employed <ref type="bibr" target="#b10">[10,</ref><ref type="bibr" target="#b11">11]</ref>. While the majority of methods rely on separate learning stages, also end-to-end approaches have been proposed <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b14">14]</ref>. In spite of the large amount of data, the number of labeled samples in MIL (represented by the number of individual, globally labelled WSIs) is often small and/or imbalanced <ref type="bibr" target="#b5">[6]</ref>. General data augmentation strategies, such as rotations, flipping, stain augmentation and normalization and affine transformations, are applicable to increase the amount of data <ref type="bibr" target="#b15">[15]</ref>. All of these methods are performed in the image domain.</p><p>Here, we consider feature-level data augmentation directly applied to the representation extracted using a convolutional neural network. These methods can be easily combined with image-based augmentation and show the advantage of a high computational efficiency (since operations are efficient and pre-computed features can be used) <ref type="bibr" target="#b10">[10,</ref><ref type="bibr" target="#b11">11]</ref>. For example, Li et al. <ref type="bibr" target="#b11">[11]</ref> proposed an augmentation strategy based on sampling the patch-descriptors to generate several bags for an individual WSI. In this paper, we focus on the interpolations of patch descriptors based on the idea of Zhang et al <ref type="bibr" target="#b21">[21]</ref>, which is referred to as MixUp. This method was originally proposed as data agnostic approach which also shows good results if applied to image data <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b16">16]</ref>. Variations were proposed, to be applied to latent representations <ref type="bibr" target="#b17">[17]</ref> as well as to balance data sets <ref type="bibr" target="#b5">[6]</ref>. Due to the structure of MIL training data, we identified several options to perform interpolation-based data augmentation.</p><p>The main contribution of this work is a set of novel data augmentation strategies for MIL, based on the interpolation of patch descriptors. Inspired by the (linear) MixUp approach <ref type="bibr" target="#b21">[21]</ref>, we investigated several ways to translate this idea to the MIL setting. Beyond linear interpolation, we also defined a more flexible and novel multilinear approach. For evaluation, a large experimental study was conducted, including 2 histological data sets, 5 deep learning configurations for MIL, 3 common data augmentation strategies and 4 MixUp settings. We investigated the classification of WSIs containing thyroid cancer tissues <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">5]</ref>. To obtain an improved understanding of reasons behind the experimental results, we also investigate the feature distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>In this paper, we consider MIL approaches relying on separately trained feature extraction and classification stages <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b10">10,</ref><ref type="bibr" target="#b12">12]</ref>. The proposed augmentation methods are applied to the patch descriptors obtained after the feature extraction stage. This strategy is highly efficient during training since the features are only computed once (per patch) and for augmentation only simple arithmetic operations are applied to the (smaller) feature vectors. Image-based data augmentation strategies (such as stain-augmentation, rotations or deformations) can be combined easily with the feature-based approaches but require individual feature extraction during training. However, to avoid the curse of meta-parameters and thereby experiments these methods are not considered here.</p><p>In the original MixUp formulation of Zhang et al. <ref type="bibr" target="#b21">[21]</ref>, synthetic samples x are generated such that x = α • x i + (1 -α) • x j , where x i and x j are randomly sampled raw input feature vectors. Corresponding labels y are generated such that y = α • y i + (1 -α) • y j , where y i and y j are the corresponding one-hot label encodings. The weight α is drawn from a uniform distribution between 0 and 1.</p><p>A single input (corresponding to a WSI) of a MIL approach with a separate feature extraction stage <ref type="bibr" target="#b10">[10]</ref> can be expressed as a P-tupel X = (x 1 , ..., x P ) with x i being the feature vector of an individual patch and P being the number of patches per WSI. The method proposed by Zhang et al. cannot directly be applied to these tupels. However, there are several options to adapt the basic idea to the changed setting. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Inter-MixUp and Intra-MixUp</head><p>Inter-MixUp refers to the generation of synthetic feature vectors by linearly combining feature vectors of a pair of WSIs (see Fig. <ref type="figure" target="#fig_0">1 (a)</ref>). All features of a WSI with index w can be represented by X (w) , such that X (w) = (x (w ) 1 , ... , x (w ) P ) . To generate a new synthetic sample X (u) based on two samples X (w) and X (v) , we introduce the operation</p><formula xml:id="formula_0">X (u) = (α•x (w ) 1 +(1-α)•x (v ) 1 , α•x (w ) 2 +(1-α)•x (v ) 2 , ... , α•x (w ) P +(1-α)•x (v ) P )</formula><p>with α being a uniformly sampled random weight (α ∈ [0, 1]). The WSI indexes v and w are uniformly sampled from the set of indexes. The index u ranges from the 1 to the number of extracted WSI descriptors. Since the new synthetic descriptors are individually generated in each epoch, there is no benefit if the number of extracted WSI descriptors is increased. We fix this number to the number of WSIs in the training data set, in order to keep the number of training iterations per epoch consistent.</p><p>Two different configurations are considered. Firstly, we investigate the interpolation between WSIs of the same class (V1). Secondly, interpolation between all WSIs is performed, which also includes the interpolation between the labels (V2). In the case of V2, also the one-hot-encoded label vectors are linearly combined, such that y</p><formula xml:id="formula_1">(u ) = α • y (w ) + (1 -α) • y (v )</formula><p>The random values, α, v and w are selected individually for each individual WSI and each epoch. Before applying the MixUp operation, the vector tupel is randomly shuffled (as performed in all experiments).</p><p>Intra-WSI combinations (Intra-MixUp) refers to the generation of synthetic descriptors by combining feature vectors within an individual WSI (see Fig. <ref type="figure" target="#fig_0">1 (b)</ref>). A new synthetic patch descriptor x k is created based on the randomly selected descriptors x i and x j , such that x k = α • x i + (1 -α) • x j , with i and j being random indices (uniformly sampled from {1, 2, ..., P }) and α being a uniformly sampled random value a (α ∈ [0, 1]). The index k ranges from 1 to the number of extracted descriptors per patch. This number was kept stable (1024) during all experiments. The thereby obtained vector tupel (x 1 , ..., x P ) finally represents the synthetic WSI-based image descriptor. Besides performing combinations for each WSI during training, selective interpolation can be useful to keep real samples within the training data. This can be easily achieved by choosing (x 1 , ..., x P ) with a chance of β and (x 1 , ..., x P ) otherwise. While the Intra-MixUp method described before represents a linear interpolation method, we also investigated a multilinear approach by computing x k such that x k = α•x i +(1-α)•x j with α being a random vector and • being the element-wise product. This element-wise linear (multilinear) approach enables even higher variability in the generated samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Experimental Setting</head><p>As experimental architecture, use the dual-stream MIL approach proposed by Li et al <ref type="bibr" target="#b10">[10]</ref>. Since this model combines both, embedding-based and an instance-based encoding, the effect of both paths can be individually investigated without changing any other architectural details. Since the method represents a state-of-the-art approach, it further serves as well-performing baseline. In instance-based MIL, the information per patch is first condensed to a single scalar value, representing the classification per patch. Finally, all of these patch-based values are aggregated. In embedding-based MIL, the information per patch is translated into a feature vector. All feature vectors from a WSI are then aggregated followed by a classification. In the investigated model <ref type="bibr" target="#b10">[10]</ref> an instance-and an embedding-based pathway are employed in parallel and are merged in the end by weighted addition. The embedding-based pathway contains an attention mechanism, to higher weight patches that are similar to the so-called critical instance. The model makes use of an individual feature extraction stage. Due to the limited number of WSIs, we did not train the feature extraction stage <ref type="bibr" target="#b6">[7]</ref>, but utilize a pre-trained network instead. Specifically, we applied a ResNet18 pre-trained on the image-net challenge data, due to the high performance in previous work on similar data <ref type="bibr" target="#b4">[5]</ref>. ResNet18 was assessed as particularly appropriate due to the rather low dimensional output (512 dimensions). We actively decided not to use a self-supervised contrastive learning approach <ref type="bibr" target="#b10">[10]</ref> as feature extraction stage since invariant features could interfere with the effect of data augmentation. We investigated various settings consisting of instancebased only (INST), embedding-based only (EMB) and the dual-stream approach with weightings 3/1, 2/2 (balanced) and 1/3 for the instance and the embedding-based pathways.</p><p>As comparison, several other augmentation methods on feature level are investigated including random sampling, selective random sampling and random noise. Random sampling corresponds to the random selection of patches (feature vectors) from each WSI. Thereby the amount of investigated data per WSI is reduced with the benefit of increasing the variability of the data. In the experiments, we adjust the sample ratio q between the patch-based features for training and testing. A q of 50 % indicates that 512 descriptors are used for training while for testing always a fixed number of 1024 is used. Selective random sampling corresponds to the random sampling strategy, with the difference that the ratio of features is not fixed but drawn from a uniform random distribution (U (q, 100 %)). Here, a q of 50 % indicates that for each WSI, between 512 and 1024 feature vectors are selected. In the case of the random noise setting, to each feature vector x i , a random noise vector r is added (x i = x i + r). The elements of r are randomly sampled (individually for each x i ) from a normal distribution N (0, σ ).</p><p>To incorporate for the fact that the feature dimensions show different magnitudes, σ is computed as the product of the meta parameter σ and the standard deviation of the respective feature dimension.</p><p>In this work, we aimed at distinguishing different nodular lesions of the thyroid, focusing especially on benign follicular nodules (FN) and papillary carcinomas (PC). This differentiation is crucial, due to the different treatment options, in particular with respect to the extent of surgical resection of the thyroid gland <ref type="bibr" target="#b19">[19]</ref>. The data set utilized in the experiments consists of 80 WSIs overall. One half (40) of the data set consists of frozen and the other half (40) of paraffin sections <ref type="bibr" target="#b4">[5]</ref>), representing the different modalities. All images were acquired during clinical routine at the Kardinal Schwarzenberg Hospital. Procedures were approved by the ethics committee of the county of Salzburg (No. 1088/2021). The mean and median age of patients at the date of dissection was 47 and 50 years, respectively. The data set comprised 13 male and 27 female patients, corresponding to a slight gender imbalance. They were labeled by an expert pathologist with over 20 years experience. A total of 42 (21 per modality) slides were labeled as papillary carcinoma while 38 (19 per modality) were labeled as benign follicular nodule. For the frozen sections, fresh tissue was frozen at -15 • Celsius, slides were cut (thickness 5 µm) and stained immediately with hematoxylin and eosin. For the paraffin sections, tissue was fixed in 4 % phosphate-buffered formalin for 24 h. Subsequently formalin fixed paraffin embedded tissue was cut (thickness 2 µm) and stained with hematoxylin and eosin. The images were digitized with an Olympus VS120-LD100 slide loader system. Overviews at a 2x magnification were generated to manually define scan areas, focus points were automatically defined and adapted if needed. Scans were performed with a 20x objective (corresponding to a resolution of 344.57 nm/pixel). The image files were stored in the Oympus vsi format based on lossless compression.   q q q q q q q q 0 25 % 50 % 75 % 100 % 0.4 The data set was randomly separated into training (80 %) and test data (20 %). The whole pipeline, including the separation, was repeated 32 times to achieve representative scores. Due to the almost balanced setting, the overall classification accuracy (mean and standard deviation) is finally reported. Adam was used as optimizer. The models were trained for 200 epochs with an initial learning rate of 0.0002. Random shuffling of the vector tupels (shuffling within the WSIs) was applied for all experiments.</p><p>The patches were randomly extracted from the WSI, based on uniform sampling. For each patch, we checked that at least 75 % of the area was covered with tissue (green color channel) in order to exclude empty areas <ref type="bibr" target="#b4">[5]</ref>. To obtain a representation independent of the WSI size, we extracted 1024 patches with a size of 256 × 256 pixel per WSI, resulting in 1024 patch-descriptors per WSI <ref type="bibr" target="#b4">[5]</ref>. For feature extraction, a ResNet18 network, pretrained on the image-net challenge was deployed <ref type="bibr" target="#b10">[10]</ref>. Data and source code are publicly accessible via https://gitlab.com/mgadermayr/mixupmil. We use the reference implementation of the dual-stream MIL approach <ref type="bibr" target="#b10">[10]</ref>. To obtain further insight into the feature distribution, we randomly selected patch descriptor pairs and computed the Euclidean distances. In detail, we selected 10,000 pairs (a) from different classes, (b) from different WSIs (similar and dissimilar classes), (c,d) from the same class and different WSIs, and (e) from the same WSI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>Figure <ref type="figure" target="#fig_3">2</ref> shows the mean overall classification accuracy and standard deviations obtained with each individual combination. The columns represent the frozen (left) and paraffin data set (right). The top row (a) shows the baseline scores of embedding-based, instance-based and the 3 combinations. Subfigure (b) show the scores obtained with baseline data augmentation for embedding-based and dual-stream MIL. Subfigure (c) shows the scores obtained with interpolation between patches between (Inter-MixUp) and within WSIs (Intra-MixUp). Without data augmentation, scores between 0.49 and 0.72 were obtained for frozen and scores between 0.41 and 0.81 for the paraffin data set. To limit the number of figures and due to the fact that instance-based MIL showed weak scores only, in the following part the focus is on embedding-based and combined-MIL (2/2) only. With baseline data augmentation, scores between 0.69 and 0.73 were achieved for the frozen and between 0.78 and 0.83 for the paraffin data set. Inter-MixUp exhibited scores up to 0.71 for the frozen and up to 0.79 for the paraffin data set. Intra-MixUp showed average accuracy up to 0.78 for the frozen and up to 0.84 for the paraffin data set. The best scores were obtained with the multilinear setting. In Fig. <ref type="figure" target="#fig_4">3</ref>, the distributions of the descriptor (Euclidean) distances between (a-d) patches from different different WSIs (inter-WSI) and (e) patches within a single WSI (intra-WSI) are provided. The mean distances range from 171.3 to 177.8 for the inter-WSI settings. In the intra-WSI setting, a mean distance of 134.8 was obtained. Based on the used common box plot variation (whiskers length is less than 1.5× the interquartile range), a large number of data points was identified as outliers. However, these points are not considered as real outliers, but occur due to the asymmetrical data distribution (as indicated by the violin plot in the background). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>In this work, we proposed and examined novel data augmentation strategies based on the idea of interpolations of feature vectors in the MIL setting. Instance-based MIL did not show any competitive scores. Obviously the model reducing each patch to a single value is not adequate for the classification of frozen or paraffin sections from thyroid cancer tissues. The considered dual-stream approach, including an embedding and instance-based stream, exhibited slightly improved average scores, compared to embedding-based MIL only. In our analysis, we focused on the embedding-based configuration and on the balanced combined approach (referred to as 2/2). With the baseline data augmentation approaches, the maximum improvements were 0.03, and 0.02 for the frozen, and 0.01, and 0.05 for the paraffin data set. The Inter-MixUp approach did not show any systematic improvements. Independently of the chosen strategy (V1, V2), concerning the combination within or between classes, we did not notice any positive trend. The multilinear Intra-MixUp method, however, exhibited the best scores for 3 out of 4 combinations and the best overall mean accuracy for both, the frozen and the paraffin data set. Also a clear trend with increasing scores in the case of an increasing ratio of augmented data (β) is visible. The linear method showed a similar, but less pronounced trend. Obviously, the straightforward application of the MixUp scheme (as in case of the Inter-MixUp approach), is inappropriate for the considered setting. An inhibiting factor could be a high inter-WSI variability leading to incompatible feature vectors (which are too far away from realistic samples in the feature space). To particularly investigate this effect, we performed 2 different Inter-MixUp settings (V1 &amp; V2), with the goal of identifying the effect of mixed (and thereby more dissimilar) or similar classes during interpolation. The analysis of the distance distributions between patch representations confirmed that, the variability between WSIs is clearly larger than the variability within WSIs. In addition, the results showed that the variability between classes is, on patch-level, not clearly larger than the variability within a class. Obviously variability due to the acquisition outweigh any disease specific variability. This could provide an explanation for the effectiveness of Intra-MixUp approach compared to the (similarly) poorly performing Inter-MixUp settings. We expect that stain normalization methods (but not stain augmentation) could be utilized to align the different WSIs to provide a more appropriate basis for inter-WSI interpolation. With regard to the different data sets, we noticed a stronger, positive effect in case of the frozen section data set. This is supposed to be due to the clearly higher variability of the frozen sections corresponding with a need for a higher variability in the training data. We also noticed a stronger effect of the solely embedding-based architecture (also showing the best overall scores). We suppose that this is due to the fact that the additional loss of the dual-stream architecture exhibits a valuable regularization tool to reduce the amount of needed training data. With the proposed Intra-MixUp augmentation strategy, this effect diminishes, since the amount and quality of training data is increased.</p><p>To conclude, we proposed novel data augmentation strategies based on the idea of interpolations of image descriptors in the MIL setting. Based on the experimental results, the multilinear Intra-MixUp setting proved to be highly effective, while the Inter-MixUp method showed inferior scores compared to a state-of-the-art baseline. We learned that there is a clear difference between combinations within and between WSIs with a noticeable effect on the final classification accuracy. This is supposedly due to the high variability between the WSIs compared to a rather low variability within the WSIs. In the future, additional experiments will be conducted including stain normalization methods and larger benchmark data sets to provide further insights.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Overview of the proposed feature-based data augmentation approaches. In the case of Inter-MixUp (a), a linear combination was applied on the pairs of WSI descriptors with a randomly selected weight factor. In the case of Intra-MixUp (b), patch-based descriptors from the same WSI were merged with individual random weights.</figDesc><graphic coords="3,56,07,196,70,340,45,146,05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Mean overall classification accuracy and standard deviation obtained with each individual combination. The columns represent the frozen (left) and paraffin data set (right). The top row (a) shows the baseline scores of embedding-based, instance-based and 3 combinations. Subfigure (b) shows the scores obtained with baseline data augmentation for embedding-based and dualstream MIL. Subfigure (c) shows the scores obtained with interpolation between (Inter-MixUp) and within WSIs (Intra-MixUp).</figDesc><graphic coords="6,41,79,56,27,340,21,465,16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Analysis of the distributions of the patch descriptor distances between (a) patches from different classes, (b) randomly selected patches from different WSIs, (c,d) patches from the same class and different WSIs (for both classes, PC and FN) and (e) patches within the WSIs.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement. This work was partially funded by the <rs type="funder">County of Salzburg</rs> (no. <rs type="grantNumber">FHS2019-10-KIAMed</rs>)</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Hup5BvF">
					<idno type="grant-number">FHS2019-10-KIAMed</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An experimental study on classification of thyroid histopathology images using transfer learning</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">G</forename><surname>Buddhavarapu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Jothi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit. Lett</title>
		<imprint>
			<biblScope unit="volume">140</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Transmix: attend to mix for vision transformers</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="12135" to="12144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multiple instance learning with center embeddings for histopathology classification</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chikontwe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Go</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)</title>
		<meeting>the International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="519" to="528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Supermix: supervising the mixing data augmentation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dabouei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Soleymani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Taherkhani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Nasrabadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="13794" to="13803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Frozen-to-paraffin: categorization of histological frozen sections by the aid of paraffin sections and generative adversarial networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gadermayr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the MIC-CAI Workshop on Simulation and Synthesis in Medical Imaging (SASHIMI)</title>
		<meeting>the MIC-CAI Workshop on Simulation and Synthesis in Medical Imaging (SASHIMI)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="99" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Balanced-MixUp for highly imbalanced medical image classification</title>
		<author>
			<persName><forename type="first">A</forename><surname>Galdran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Carneiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A G</forename><surname>Ballester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)</title>
		<meeting>the Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="323" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Patch-based convolutional neural network for whole slide tissue image classification</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Samaras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Kurc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Saltz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2424" to="2433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Attention-based deep multiple instance learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ilse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tomczak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2127" to="2136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Weakly supervised multiple instance learning histopathological tumor segmentation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lerousseau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">12265</biblScope>
			<biblScope unit="page" from="470" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Cham</forename><surname>Springer</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59722-1_45</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-59722-145" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Dual-stream multiple instance learning network for whole slide image classification with self-supervised contrastive learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Eliceiri</surname></persName>
		</author>
		<ptr target="https://github.com/binli123/dsmil-wsi" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="14318" to="14328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A novel multiple instance learning framework for covid-19 severity assessment via data augmentation and self-supervised learning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page">101978</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Kernel self-attention for weaklysupervised image classification using deep multiple instance learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rymarczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Borowa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tabor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zielinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1721" to="1730" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Transmil: transformer based correlated multiple instance learning for whole slide image classification</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="2136" to="2147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Cluster-toconquer: a framework for end-to-end multi-instance learning for whole slide image classification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ehsan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Moskaluk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Syed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Medical Imaging with Deep Learning Conference (MIDL)</title>
		<meeting>the Medical Imaging with Deep Learning Conference (MIDL)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="682" to="698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Quantifying the effects of data augmentation and stain color normalization in convolutional neural networks for computational pathology</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tellez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page">101544</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On mixup training: improved calibration and predictive uncertainty for deep neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Thulasidasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chennupati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Bilmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Michalak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Manifold mixup: better representations by interpolating hidden states</title>
		<author>
			<persName><forename type="first">V</forename><surname>Verma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="6438" to="6447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">TransPath: transformer-based self-supervised learning for histopathological image classification</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)</title>
		<meeting>the Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="186" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Improving the diagnosis of thyroid cancer by machine learning and clinical data</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">11143</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">DTFD-MIL: double-tier feature distillation multiple instance learning for histopathology whole slide image classification</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="18802" to="18812" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">mixup: Beyond empirical risk minimization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR</title>
		<meeting>the International Conference on Learning Representations (ICLR</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
