<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Inverse Consistency by Construction for Multistep Deep Registration</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Hastings</forename><surname>Greer</surname></persName>
							<email>tgreer@cs.unc.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of North Carolina at Chapel Hill</orgName>
								<address>
									<settlement>Chapel Hill</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lin</forename><surname>Tian</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of North Carolina at Chapel Hill</orgName>
								<address>
									<settlement>Chapel Hill</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Francois-Xavier</forename><surname>Vialard</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University Paris-Est</orgName>
								<address>
									<settlement>Créteil</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Roland</forename><surname>Kwitt</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Salzburg</orgName>
								<address>
									<settlement>Salzburg</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sylvain</forename><surname>Bouix</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">ÉTS Montréal</orgName>
								<address>
									<settlement>Montreal</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Raul</forename><surname>San Jose Estepar</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Richard</forename><surname>Rushmore</surname></persName>
							<affiliation key="aff5">
								<orgName type="institution">Boston University</orgName>
								<address>
									<settlement>Boston</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marc</forename><surname>Niethammer</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of North Carolina at Chapel Hill</orgName>
								<address>
									<settlement>Chapel Hill</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Inverse Consistency by Construction for Multistep Deep Registration</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="688" to="698"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">1DAE5D794F841B253461A0015498BDEA</idno>
					<idno type="DOI">10.1007/978-3-031-43999-5_65</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-13T19:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Registration • Deep Learning</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Inverse consistency is a desirable property for image registration. We propose a simple technique to make a neural registration network inverse consistent by construction, as a consequence of its structure, as long as it parameterizes its output transform by a Lie group. We extend this technique to multi-step neural registration by composing many such networks in a way that preserves inverse consistency. This multi-step approach also allows for inverse-consistent coarse to fine registration. We evaluate our technique on synthetic 2-D data and four 3-D medical image registration tasks and obtain excellent registration accuracy while assuring inverse consistency.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Image registration, or finding the correspondence between a pair of images, is a fundamental task in medical image computing. One desirable property for registration algorithms is inverse consistency -the property that the transform found registering image A onto image B, composed with the transform found by registering image B onto image A, yields the identity map. Inverse consistency is useful for several reasons. Practically, it is convenient to have a single transform and its inverse associating two images instead of two transforms of unknown relationship. For within-subject registration, inverse consistency is often a natural assumption as long as images are consistent with each other, e.g., did not undergo surgical removal of tissue. For time series analysis, inverse consistency prevents bias <ref type="bibr" target="#b18">[19]</ref>. We propose a novel deep network structure that registers images in multiple steps in a way that is inverse-consistent by construction. Our approach is flexible and allows different transform types for different steps (Fig. <ref type="figure" target="#fig_0">1</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Inverse consistency in deep image registration approaches is commonly promoted via a penalty <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b26">27]</ref> on the inverse consistency error. Extensive work also exists on optimization-based exactly inverse consistent image registration. For example, by using a symmetric image similarity measure and an inverse consistency loss on the transformations <ref type="bibr" target="#b4">[5]</ref> or by performing robust inverse consistent rigid registrations with respect to a middle space <ref type="bibr" target="#b18">[19]</ref>. ANTs SyN <ref type="bibr" target="#b1">[2]</ref> is an approach to inverse consistent deformable registration, but by default is part of a multi-step affine then SyN pipeline which is not as a whole inverse consistent.</p><p>Mok et al. <ref type="bibr" target="#b13">[14]</ref> introduce a deep-learning framework that is exactly inverse consistent. They take advantage of the fact that a stationary velocity field (SVF) transform representation allows for fast inversion of a transform by integrating the negated velocity field. Thus, by calling their network twice, the second time with the inputs reversed, they can construct a transform</p><formula xml:id="formula_0">Φ AB = exp(N θ [I A , I B ]) • exp(-N θ [I B , I A ])</formula><p>. This registration network is inverseconsistent by construction, but only supports one step. Our approach will provide a general inverse consistent multi-step framework.</p><p>Iglesias et al. <ref type="bibr" target="#b9">[10]</ref> introduce a two-step deep registration framework for brain registration that is inverse consistent by construction. First, they independently segment each image with a U-Net into 97 anatomical regions. The centroids of these regions and the corresponding regions of an atlas are then used to obtain an affine transformation to the atlas. This is inverse consistent. Second, each brain image is resampled to the atlas space followed by an SVF-based transformation, where the velocity field is obtained by two calls to their velocity field network:</p><formula xml:id="formula_1">exp(N θ [I A , I B ] -N θ [I B , I A ]</formula><p>). This symmetrization retains inverse consistency and is conceptually similar to our approach. However, their approach, unlike ours, does not directly extend to N steps and is not trained end to end.</p><p>There is extensive literature on deep multi-step approaches. The core idea is to conduct the registration in multiple steps with the warped image produced by the previous step being the input to the latter step. Thus, the original input image pairs can be registered progressively. AVSM <ref type="bibr" target="#b21">[22]</ref> achieves this by reusing the same neural network at each step. Other works in the literature <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b22">23]</ref> setup different neural networks at each step. In addition, these steps are often conducted in a coarse-to-fine manner. Namely, the neural network at the current step registers the input images at a coarse resolution, interpolates the output deformation field to a finer resolution, composes the interpolated deformation field with the composed transformation from previous steps, warps the moving image at the finer resolution, and passes the warped image and target image to the neural network at next step. Greer et al. and Tian et al. <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b22">23]</ref> define an abstract TwoStep operator to represent the process described above. However, this TwoStep operation does not guarantee inverse consistency between the composed forward transformation and the composed backward transformation.</p><p>To address this issue, we propose a novel operator for multi-step registration to obtain inverse consistent registration by construction.</p><p>Definitions and Notation. We use subscripted capital letters, e.g., N θ , to represent neural networks that return arrays of numbers, and capital Greek letters Φ, Ψ, and Ξ to represent registration neural networks, i.e., neural networks that return transforms. A transform is a function R D → R D with D denoting the dimension of the images we are registering. N AB θ is shorthand for N θ called on the images I A and I B , likewise</p><formula xml:id="formula_2">Φ AB is shorthand for Φ[I A , I B ]. A deep registration network outputs a transform such that I A • Ξ AB ∼ I B .</formula><p>For a Lie group G and associated algebra g, exp is the (Lie-)exponential map from g → G <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b10">11]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Lie-Group Based Inverse Consistent Registration</head><p>To design a registration algorithm, one must pick a class of transforms that the algorithm will return. Many types of transforms that are useful for practical medical registration problems happen to also be Lie groups. We describe a procedure for designing a neural network that outputs a member of a specified Lie group in an inverse consistent manner and provide several examples.</p><p>Recall that a Lie group G is always associated with a Lie algebra g. Create a neural network N θ (of arbitrary design) with two input images and an output that can be considered an element of g.</p><p>A registration network Φ defined to act as follows on two images</p><formula xml:id="formula_3">Φ[I A , I B ] := exp(g(I A , I B )), g(I A , I B ) := N θ [I A , I B ] -N θ [I B , I A ]<label>(1)</label></formula><p>is inverse consistent, because g(I A , I B ) = -g(I B , I A ) by construction. We explore how this applies to several Lie groups.</p><p>Rigid Registration. The Lie algebra of rigid rotations is skew-symmetric matrices. N θ outputs a skew-symmetric matrix R and a vector t, so that</p><formula xml:id="formula_4">N AB θ = R t 0 1 , Φ (rigid) [I A , I B ](x) := exp(N θ [I A , I B ] -N θ [I B , I A ]) x 1 ,<label>(2)</label></formula><p>where Φ (rigid) will output a rigid transformation in an inverse consistent manner.</p><p>Here, the exponential map is just the matrix exponent.</p><p>Affine Registration. Relaxing R to be an arbitrary matrix instead of a skewsymmetric matrix in the above construction produces a network that performs inverse consistent affine registration.</p><p>Nonparametric Vector Field Registration. In the case of the group of diffeomorphisms, the corresponding Lie algebra<ref type="foot" target="#foot_0">1</ref> is the space of vector fields. If N θ outputs a vector field, implemented as a grid of vectors which are linearly interpolated, then, by using scaling and squaring <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3]</ref> to implement the Lie exponent, we have</p><formula xml:id="formula_5">Φ (svf) [I A , I B ](x) := exp(N θ [I A , I B ] -N θ [I B , I A ])(x),<label>(3)</label></formula><p>which is an inverse consistent nonparametric registration network. This is equivalent to the standard SVF technique for image registration, with a velocity field represented as a grid of vectors equal to</p><formula xml:id="formula_6">N θ [I A , I B ] -N θ [I B , I A ].</formula><p>MLP Registration. An ongoing research question is how to represent the output transform as a multi-layer perceptron (MLP) applied to coordinates. One approach is to reshape the vector of outputs of a ConvNet so that the vector represents the weight matrices defining an MLP (with D inputs and D outputs). This MLP is then a member of the Lie algebra of vector-valued functions, and the exponential map to the group of diffeomorphisms can be computed by solving the following differential equation to t = 1 using an integrator such as fourthorder Runge-Kutta. Again, by defining the velocity field to flip signs when the input image order is flipped, we obtain an inverse consistent transformation:</p><formula xml:id="formula_7">v(z) = N AB θ (z) -N BA θ (z), ∂ ∂t Φ AB (x, t) = v(Φ AB (x, t)), Φ AB (x, 0) = x, Φ AB (x) = Φ AB (x, 1). (4)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Multi-step Registration</head><p>The standard approach to composing two registration networks is to register the moving image to the fixed image, warp the moving image and then register the warped moving image to the fixed image again and compose the transforms. This is formalized in <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b22">23]</ref> as TwoStep, i.e.,</p><formula xml:id="formula_8">TwoStep{Φ, Ψ } := Φ[I A , I B ] • Ψ [I A • Φ[I A , I B ], I B ]. (<label>5</label></formula><formula xml:id="formula_9">)</formula><p>Unfortunately, TwoStep <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b22">23]</ref> is not always inverse consistent even with inverse consistent arguments. First, although Ψ [ ĨA , I B ] is the inverse of Ψ [I B , ĨA ], it does not necessarily have any relationship with Ψ [ ĨB , I A ] which is the term that appears when swapping the inputs to TwoStep.</p><formula xml:id="formula_10">Second, composing TwoStep {Φ, Ψ }[I A , I B ] • TwoStep{Φ, Ψ }[I B , I A ], results in Φ • Ψ • Φ -1 • ∼ Ψ -1 .</formula><p>The inverses are interleaved so that even if they were exact, they can not cancel.</p><p>Our contribution is an operator, TwoStepConsistent, that is inverse consistent if its components are inverse consistent. We assume that our component networks Φ and Ψ are inverse consistent, and that Φ returns a transform that we can explicitly find the square root of, such that √ Φ AB • √ Φ AB = Φ AB . Note that for transforms defined by Φ AB = exp(g) , √ Φ AB = exp(g/2). Since each network is inverse consistent, we have access to the inverses of the transforms they return. We begin with the relationship that Φ will be trained to fulfill <ref type="bibr" target="#b5">(6)</ref> and apply Ψ to register ÎA and ÎB</p><formula xml:id="formula_11">I A • Φ[I A , I B ] ∼ I B , ÎA := I A • Φ[I A , I B ] ∼ ÎB := I B • Φ[I B , I A ],</formula><formula xml:id="formula_12">I A • Φ[I A , I B ] • Ψ [ ÎA , ÎB ] I B • Φ[I B , I A ],<label>(7)</label></formula><formula xml:id="formula_13">I A • Φ[I A , I B ] • Ψ [ ÎA , ÎB ] • Φ[I A , I B ] I B . (<label>8</label></formula><formula xml:id="formula_14">)</formula><p>We isolate the transform in the left half of Eq. ( <ref type="formula" target="#formula_13">8</ref>) as our new operator, i.e.,</p><formula xml:id="formula_15">TwoStepConsistent{Φ, Ψ }[I A , I B ] := Φ[I A , I B ]•Ψ [ ÎA , ÎB ]• Φ[I A , I B ].<label>(9)</label></formula><p>In fact, we can verify that</p><formula xml:id="formula_16">TwoStepConsistent{Φ, Ψ }[I A , I B ] • TwoStepConsistent{Φ, Ψ }[I B , I A ] (10) = √ Φ • Ψ • √ Φ • √ Φ -1 • Ψ -1 • √ Φ -1 = id. (<label>11</label></formula><formula xml:id="formula_17">)</formula><p>Notably, This Procedure Extends to N -Step Registration. With the operator of Eq. ( <ref type="formula" target="#formula_15">9</ref>), a registration network composed from an arbitrary number of steps may be made inverse consistent. This is because TwoStepConsistent{•, •} is a valid second argument to TwoStepConsistent. For instance, a three-step network can be constructed as TwoStepConsistent{Φ, TwoStepConsistent{Ψ, Ξ}}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Synthetic Experiments</head><p>Inverse Consistent Rigid, Affine, Nonparametric, and MLP Registration. We train networks on MNIST 5 s using the methods in Sects. 3 and 4, demonstrating that the resulting networks are inverse-consistent. Our TwoStepConsistent (TSC) operator can be used on any combination of the networks defined in Sect. 3. For demonstrations, we join an MLP registration network to a vector field registration network, and join two affine networks to two vector field networks. Figure <ref type="figure">2</ref> shows successful inverse-consistent sample registrations.</p><p>Affine Registration Convergence. In addition to being inverse consistent, our method accelerates convergence and stability of affine registration, compared to directly predicting the matrix of an affine transform. Here, we disentangle whether this happens for any approach that parameterizes an affine transform by taking the exponent of a matrix, or whether this acceleration is Fig. <ref type="figure">2</ref>. We train single-step rigid, affine, vector field parameterized SVF, and neural deformation field (MLP) networks, as well as a two-step registration network (TSC) composed of a neural deformation field step followed by a vector field parameterized SVF step and a 4 step network (NSC) composed of two affine steps and two SVF steps. We observe excellent registration results indicated by the small differences (second row) after applying the estimated transformation Φ AB (third row). Composing with the inverse produces results very close to the identity map (last row) as desired.</p><p>unique to our inverse consistent method. We also claim that multi-step registration is important for registration accuracy and convergence time and that an inverse consistent multi-step operator, TwoStepConsistent, is thus beneficial.</p><p>To justify these claims, we investigate training for affine registration on the synthetic Hollow Triangles and Circles dataset from <ref type="bibr" target="#b22">[23]</ref> while varying the method used to obtain a matrix from the registration network and the type of multi-step registration used. To obtain an affine matrix, we either directly use the neural network output N AB θ , use exp(N AB θ ), or, as suggested in Sect. 3, use exp(N AB θ -N BA θ ). We either register in one step, use the TwoStep operator from <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b22">23]</ref>, or use our new TwoStepConsistent operator. This results in 9 training configurations, which we run 65 times each.</p><p>We observe that parameterizing an affine registration using the exp(N AB θ -N BA θ ) construction speeds up the first few epochs of training and gets even faster when combined with any multi-step method. In Fig. <ref type="figure" target="#fig_1">3</ref>, note that in the top-left corner of the first plot, the green loss curves (corresponding to models using N AB θ -N BA θ ) are roughly vertical, while the other loss curves are roughly horizontal, eventually bending down. After this initial lead, these green curves also converges to a better final loss. Further, all methods that use the N AB θ -N BA θ construction train reliably, while other methods sometimes fail to converge (Fig. <ref type="figure" target="#fig_1">3</ref>, right plot). This has a dramatic effect on the practicality of a method since training on 3-D data can take multiple days on expensive hardware.</p><p>Finally, as expected, the only two approaches that are inverse consistent are the single-step inverse consistent by construction network, and the network using two inverse-consistent by construction subnetworks, joined by the TwoStepConsistent operator. (Fig. <ref type="figure" target="#fig_1">3</ref>, middle, dotted and solid green). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Evaluation on 3-D Medical Datasets</head><p>We evaluate on several datasets, where we can compare to earlier registration approaches. We use the network Φ := TSC{Ψ 1 , TSC{Ψ 2 , TSC{Ξ 1 , Ξ 2 }}} with Ξ i inverse-consistent SVF networks backed by U-Nets and Ψ i inverseconsistent affine networks backed by ConvNets<ref type="foot" target="#foot_1">2</ref> . We rely on local normalized cross-correlation as our similarity measure, with σ = 5vx, and regularize the SVF networks by the sum of the bending energies of their velocity fields, with λ = 5. We train end to end, minimizing -LNCC(I A • Φ[I A , I B ], I B ) + λL reg for 100,000 iterations (∼2 days on 4 NVIDIA A6000s) with Adam optimization and a learning rate of 1e-4. In all cases, we normalize images to the range (0, 1). We evaluate registration accuracy with and without instance optimization <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b25">26]</ref>. Without instance optimization, registration takes ∼0.23 s on an NVIDIA RTX A6000 on the HCP <ref type="bibr" target="#b23">[24]</ref> dataset. With instance optimization, registration takes ∼43 s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Datasets</head><p>COPDGene/Dirlab Lung CT. We follow the data selection and preprocessing of <ref type="bibr" target="#b22">[23]</ref>. We train on 999 inhale/exhale pairs from COPDGene <ref type="bibr" target="#b17">[18]</ref>, resampled to 2mm spacing at [175 × 175 × 175], masked with lung segmentations, clipped to [-1000, 0] Hounsfield units, and scaled to (0, 1). We evaluate landmark error (MTRE) on the ten inhale/exhale pairs of the Dirlab challenge dataset <ref type="bibr" target="#b3">[4]</ref> 3 . OAI Knee MRI. We train and test on the split published with <ref type="bibr" target="#b21">[22]</ref>, with 2532 training examples and 301 test pairs from the Osteoarthritis Initiative (OAI) <ref type="bibr" target="#b15">[16]</ref> <ref type="foot" target="#foot_2">4</ref> . We evaluate using the mean Dice score of femoral and tibial cartilage. To compare directly to <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23]</ref> we train and evaluate at <ref type="bibr">[80 × 192 × 192]</ref>. HCP Brain MRI. We train on 1076 brain-extracted T1w images from the HCP dataset <ref type="bibr" target="#b23">[24]</ref> and test on a sample of 100 pairs between 36 images via mean Dice over 28 midbrain structures <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref>. We train and execute the network at [130 × 155 × 130], then compute the Dice score at full resolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>OASIS Brain MRI.</head><p>We use the OASIS-1 <ref type="bibr" target="#b11">[12]</ref> data preprocessed by <ref type="bibr" target="#b8">[9]</ref>. This dataset contains images of 414 subjects. Following the data split in <ref type="bibr" target="#b13">[14]</ref>, we train on 255 images and test on 153 images <ref type="foot" target="#foot_3">5</ref> . The images in the dataset are of size [160 × 192 × 224], and we crop the center of the image according to the preprocessing in <ref type="bibr" target="#b13">[14]</ref>, leading to a size of <ref type="bibr">[160 × 144 × 192]</ref>. During training, we sample image pairs randomly from the train set. For evaluation, we randomly pick 5 cases as the fixed images and register all the remaining 148 cases to the 5 cases, resulting in 740 image pairs overall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Comparisons</head><p>We use publicly-available pretrained weights and code for ANTs <ref type="bibr" target="#b1">[2]</ref>, PTVReg <ref type="bibr" target="#b24">[25]</ref>, GradICON <ref type="bibr" target="#b22">[23]</ref>, SynthMorph <ref type="bibr" target="#b7">[8]</ref>, SymNet <ref type="bibr" target="#b13">[14]</ref>, and EasyReg <ref type="bibr" target="#b9">[10]</ref>. SymNet, GradICON, and PTVReg are run on the datasets associated with their original publication. SynthMorph, which we evaluate on HCP, was originally trained and evaluated on HCP-A and OASIS. EasyReg was trained on HCP <ref type="bibr" target="#b23">[24]</ref> and ADNI <ref type="bibr" target="#b16">[17]</ref>. Our ConstrICON method outperforms the state of the art on HCP, OAI, and OASIS registration but underperforms on the DirLab data. Since we use shared hyperparameters between these datasets, which are not tuned to a specific task, we assert that this performance level will likely generalize to new datasets. We find that our method is more inverse consistent than existing inverse consistent by construction methods SymNet and SyNOnly with higher accuracy, and more inverse consistent than inverse-consistent-by-penalty GradI-CON (Table <ref type="table" target="#tab_0">1</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>The fundamental impact of this work is as a recipe for constructing a broad class of exactly inverse consistent, multi-step registration algorithms. We also are pleased to present registration results on four medically relevant datasets that are competitive with the current state of the art, and in particular are more accurate than existing inverse-consistent-by-construction neural approaches.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Cases registered by ConstrICON from DirLab and OAI</figDesc><graphic coords="2,55,98,54,08,340,30,54,64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. We vary the network used to perform affine registration and the method for composing steps on the Hollow Triangles and Circles dataset. Average loss curves and distribution of final losses are shown for 65 training runs per experimental configuration. Our TwoStepConsistent approach performs best overall. It shows fast convergence, high accuracy (indicated by a low similarity loss, left), is highly inverse consistent (middle), and trains reliably (indicated by the tight violin plot on the right). (Color figure online)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Results on 3-D medical registration. %|J| indicates the percentage of voxels with negative Jacobian. Φ AB • Φ BAid indicates the mean deviation in voxels from inverse consistency. Instance optimization is denoted by io. Our ConstrICON approach shows excellent registration performance while being highly inverse consistent.</figDesc><table><row><cell>HCP</cell><cell></cell><cell></cell><cell>DirLab</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Approach</cell><cell>DICE %|J|</cell><cell>Φ AB • Φ BA -id</cell><cell>Approach</cell><cell cols="2">MTRE %|J|</cell><cell>Φ AB • Φ BA -id</cell></row><row><cell>ANTs SyNOnly [2]</cell><cell>75.8 0</cell><cell>0.0350</cell><cell>ANTs SyN [2]</cell><cell>1.79</cell><cell>0</cell><cell>4.23</cell></row><row><cell>ANTs SyN</cell><cell>77.2 0</cell><cell>1.30</cell><cell>PTVReg [25]</cell><cell>0.96</cell><cell>0.60</cell><cell>6.13</cell></row><row><cell>ConstrICON</cell><cell cols="2">79.3 3.81e-6 0.000386</cell><cell>ConstrICON</cell><cell>1.61</cell><cell cols="2">6.6e-6 0.00518</cell></row><row><cell>ConstrICON + io</cell><cell>80.1 0</cell><cell>0.00345</cell><cell cols="2">ConstrICON + io 1.32</cell><cell cols="2">3.02e-6 0.00306</cell></row><row><cell>GradICON [23]</cell><cell cols="2">78.6 0.00120 0.309</cell><cell>GradICON [23]</cell><cell>1.26</cell><cell cols="2">0.0003 0.575</cell></row><row><cell>GradICON + io</cell><cell cols="2">80.2 0.000352 0.123</cell><cell cols="2">GradICON + io 0.96</cell><cell cols="2">0.0002 0.161</cell></row><row><cell cols="2">SynthMorph [8] brain 78.4 0.364</cell><cell>-</cell><cell>OAI</cell><cell></cell><cell></cell><cell></cell></row><row><cell>SynthMorph shape</cell><cell>79.7 0.298</cell><cell>-</cell><cell>Approach</cell><cell cols="2">DICE %|J|</cell><cell>Φ AB • Φ BA -id</cell></row><row><cell>OASIS</cell><cell></cell><cell></cell><cell>ANTs SyN</cell><cell>65.7</cell><cell>0</cell><cell>5.32</cell></row><row><cell>Approach</cell><cell>DICE %|J|</cell><cell>Φ AB • Φ BA -id</cell><cell>GradICON</cell><cell>70.4</cell><cell cols="2">0.0261 1.84</cell></row><row><cell>ConstrICON</cell><cell cols="2">79.7 9.73e-5 0.00776</cell><cell cols="2">GradICON + io 71.2</cell><cell cols="2">0.0042 0.504</cell></row><row><cell>SymNet [14]</cell><cell cols="2">79.1 0.00487 0.0595</cell><cell>ConstrICON</cell><cell>70.7</cell><cell cols="2">2.41e-7 0.0459</cell></row><row><cell>EasyReg [10]</cell><cell>77.2 -</cell><cell>0.181</cell><cell cols="2">ConstrICON + io 71.5</cell><cell cols="2">3.36e-7 0.0505</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Although in infinite dimensions, the name Lie algebra does not apply, in our case we only need the notions of the exponential map and tangent space at identity to preserve the inverse consistency property.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Specifically, networks.tallUNet2 and networks.ConvolutionalMatrixNet from the library icon registration version 1.1.1 on pypi.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>https://nda.nih.gov/oai.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>Due to changes in the OASIS-1 data, our test set slightly differs from<ref type="bibr" target="#b13">[14]</ref>. We evaluate all methods using our testing protocol so that results are consistent.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A Log-Euclidean framework for statistics on diffeomorphisms</title>
		<author>
			<persName><forename type="first">V</forename><surname>Arsigny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Commowick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Pennec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ayache</surname></persName>
		</author>
		<idno type="DOI">10.1007/11866565_113</idno>
		<ptr target="https://doi.org/10.1007/11866565113" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2006</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Larsen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Nielsen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Sporring</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">4190</biblScope>
			<biblScope unit="page" from="924" to="931" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Symmetric diffeomorphic image registration with cross-correlation: evaluating automated labeling of elderly and neurodegenerative brain</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">B</forename><surname>Avants</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Gee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Media</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="26" to="41" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">VoxelMorph: a learning framework for deformable medical image registration</title>
		<author>
			<persName><forename type="first">G</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Sabuncu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guttag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Dalca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TMI</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1788" to="1800" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A reference dataset for deformable image registration spatial accuracy evaluation using the COPDgene study archive</title>
		<author>
			<persName><forename type="first">R</forename><surname>Castillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Med. Biol</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">2861</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Consistent image registration</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Christensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TMI</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="568" to="582" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Eade</surname></persName>
		</author>
		<ptr target="http://ethaneade.com/lie.pdf" />
		<title level="m">Lie groups for 2D and 3D transformations</title>
		<imprint>
			<date type="published" when="2013-12">2013. Dec 117</date>
			<biblScope unit="page">118</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">ICON: learning regular maps through inverse consistency</title>
		<author>
			<persName><forename type="first">H</forename><surname>Greer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kwitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">X</forename><surname>Vialard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Niethammer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Syn-thMorph: learning contrast-invariant registration without acquired images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Billot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Greve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Iglesias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fischl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Dalca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TMI</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="543" to="558" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Hoopes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Greve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fischl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guttag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Dalca</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.16680</idno>
		<title level="m">Learning the effect of registration hyperparameters with HyperMorph</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">EasyReg: a ready-to-use deep learning tool for symmetric affine and nonlinear brain MRI registration</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Iglesias</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Theorie der transformationsgruppen i</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Ann</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="441" to="528" />
			<date type="published" when="1880">1880</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Open access series of imaging studies (OASIS): cross-sectional MRI data in young, middle aged, nondemented, and demented older adults</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Csernansky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Buckner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cogn. Neurosci</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1498" to="1507" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Large deformation diffeomorphic image registration with Laplacian pyramid networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C W</forename><surname>Mok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C S</forename><surname>Chung</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59716-0_21</idno>
		<idno>978-3-030-59716-0 21</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12263</biblScope>
			<biblScope unit="page" from="211" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fast symmetric diffeomorphic image registration with convolutional neural networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Mok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Chung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A multiple decoder CNN for inverse consistent 3D image registration</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nazib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fookes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Salvado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Perrin</surname></persName>
		</author>
		<idno type="DOI">10.1109/ISBI48211.2021.9433911</idno>
		<ptr target="https://doi.org/10.1109/ISBI48211.2021.9433911" />
	</analytic>
	<monogr>
		<title level="m">2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="904" to="907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The osteoarthritis initiative</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Nevitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Felson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Protocol Cohort Study</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Alzheimer&apos;s disease neuroimaging initiative (ADNI): clinical characterization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Petersen</surname></persName>
		</author>
		<idno type="DOI">10.1212/WNL.0b013e3181cb3e25</idno>
		<ptr target="https://doi.org/10.1212/WNL" />
	</analytic>
	<monogr>
		<title level="j">Neurology</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="201" to="209" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>b013e3181cb3e25</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Genetic epidemiology of COPD (COPDGene) study design</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Regan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">COPD: J. Chronic Obstr. Pulm. Dis</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="32" to="43" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Highly accurate inverse consistent registration: a robust approach</title>
		<author>
			<persName><forename type="first">M</forename><surname>Reuter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Rosas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fischl</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2010.07.020</idno>
		<ptr target="https://www.sciencedirect.com/science/article/pii/S1053811910009717" />
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1181" to="1196" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Anatomically curated segmentation of human subcortical structures in high resolution magnetic resonance imaging: an open science approach</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Rushmore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Neuroanat</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">HOA-2/SubcorticalParcellations: release-50-subjects</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Rushmore</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.7080547</idno>
		<ptr target="https://doi.org/10.5281/zenodo.7080547" />
		<imprint>
			<date type="published" when="2022">-1.1.0 (2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Networks for joint affine and nonparametric image registration</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Niethammer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">GradICON: approximate diffeomorphisms via gradient inverse consistency</title>
		<author>
			<persName><forename type="first">L</forename><surname>Tian</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2206.05897</idno>
		<ptr target="https://doi.org/10.48550/ARXIV.2206.05897" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The human connectome project: a data acquisition perspective</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Van Essen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2222" to="2231" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Isotropic total variation regularization of displacements in parametric image registration</title>
		<author>
			<persName><forename type="first">V</forename><surname>Vishnevskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Szekely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tanner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Goksel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TMI</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="385" to="395" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">PLOSL: population learning followed by one shot learning pulmonary image registration using tissue volume preserving and vesselness constraints</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Media</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page">102434</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Inverse-consistent deep networks for unsupervised deformable image registration</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<idno>CoRR abs/1809.03443</idno>
		<ptr target="http://arxiv.org/abs/1809.03443" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
