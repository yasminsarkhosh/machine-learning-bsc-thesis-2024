<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Building a Bridge: Close the Domain Gap in CT Metal Artifact Reduction</title>
				<funder ref="#_6J2rRKR">
					<orgName type="full">Sichuan Science and Technology Program</orgName>
				</funder>
				<funder ref="#_JmTBMxg">
					<orgName type="full">Sichuan University</orgName>
				</funder>
				<funder ref="#_Hg8RdNp">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Tao</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer Science</orgName>
								<orgName type="institution">Sichuan University</orgName>
								<address>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hui</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer Science</orgName>
								<orgName type="institution">Sichuan University</orgName>
								<address>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yan</forename><surname>Liu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">College of Electrical Engineering</orgName>
								<orgName type="institution">Sichuan University</orgName>
								<address>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Huaiqiang</forename><surname>Sun</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Radiology</orgName>
								<orgName type="institution">West China Hospital of Sichuan University</orgName>
								<address>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Yi</forename><surname>Zhang</surname></persName>
							<email>yzhang@scu.edu.cn</email>
							<affiliation key="aff3">
								<orgName type="department">School of Cyber Science and Engineering</orgName>
								<orgName type="institution">Sichuan University</orgName>
								<address>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Building a Bridge: Close the Domain Gap in CT Metal Artifact Reduction</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="206" to="216"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">C0756305DA50FD58991100997BBFC2E3</idno>
					<idno type="DOI">10.1007/978-3-031-43999-5_20</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-13T19:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Computed Tomography</term>
					<term>Metal Artifact Reduction</term>
					<term>Deep Learning</term>
					<term>Domain Gap</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Metal artifacts in computed tomography (CT) degrade the imaging quality, leading to a negative impact on the clinical diagnosis. Empowered by medical big data, many DL-based approaches have been proposed for metal artifact reduction (MAR). In supervised MAR methods, models are usually trained on simulated data and then applied to the clinical data. However, inferior MAR performance on clinical data is usually observed due to the domain gap between simulated and clinical data. Existing unsupervised MAR methods usually use clinical unpaired data for training, which often distort the anatomical structure due to the absence of supervision information. To address these problems, we propose a novel semi-supervised MAR framework. The clean image is employed as the bridge between the synthetic and clinical metalaffected image domains to close the domain gap. We also break the cycleconsistency loss, which is often utilized for domain transformation, since the bijective assumption is too harsh to accurately respond to the facts of real situations. To further improve the MAR performance, we propose a new Artifact Filtering Module (AFM) to eliminate features helpless in recovering clean images. Experiments demonstrate that the performance of the proposed method is competitive with several state-of-theart unsupervised and semi-supervised MAR methods in both qualitative and quantitative aspects.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Metal implants can heavily attenuate X-rays in computed tomography (CT) scans, leading to severe artifacts in reconstructed images. It is essential to remove metal artifacts in CT images for subsequent diagnosis.</p><p>Recently, with the emergence of deep learning (DL) <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>, many DLbased approaches have been proposed for metal artifact reduction (MAR) and achieved encouraging results. These methods can be roughly classified into three groups: supervised, unsupervised, and semi-supervised MAR methods. Supervised MAR methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24]</ref> directly learn the mapping from synthetic metal-affected data to metal-free one under the guidance of the desired data. Then the learned models are applied to the clinical data. Unfortunately, due to the domain gap between synthetic and clinical data, poor generalization performance usually occurs, leading to unexpected results. Unsupervised MAR methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b26">27]</ref> can avoid the problem since their training and application are both on the clinical data. Nonetheless, the absence of supervision information makes it easy to distort the anatomical structure in the corrected results. Recently, several semi-supervised MAR methods have been proposed. SFL-CNN <ref type="bibr" target="#b16">[17]</ref> and a variant of ADN <ref type="bibr" target="#b8">[9]</ref> denoted as SemiADN <ref type="bibr" target="#b13">[14]</ref> are two representative works, which utilize the same network to deal with synthetic and clinical data simultaneously. These methods inherit the advantages of both supervised and unsupervised MAR methods, but the mentioned-above domain gap problem remains. In these works, the network attempts to find a balance between the synthetic and clinical data but ultimately results in an unsatisfactory outcome in both domains, leaving room for further improvement.</p><p>In this work, our goal is to explicitly reduce the domain gap between synthetic and clinical metal-corrupted CT images for improved clinical MAR performance. Some domain adaptation-based networks <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b24">25]</ref> are designed to close the domain gap and they usually assume that there is a one-to-one correspondence between two domains, i.e. bijection, which is implemented via the constraint of cycle consistency loss. However, this assumption is too harsh to accurately respond to the facts of real situations. Furthermore, when the model learns an identical transformation, this assumption is still met. Hence, maintaining the diversity of image generation is another challenge.</p><p>To close the domain gap, we propose a novel semi-supervised MAR framework. In this work, the clean image domain acts as the bridge, where the bijection is substituted with two simple mappings and the strict assumption introduced by the cycle-consistency loss is relaxed. Our goal is to convert simulated and clinical metal-corrupted data back and forth. As an intermediate product, clean images are our target. To improve the transformations of two metal-corrupted images into metal-free ones, we propose a feature selection mechanism, denoted as Artifact Filtering Module (AFM), where AFM acts as a filter to eliminate features helpless in recovering clean images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem Formulation</head><p>The metal corruption process can be formulated as a linear superposition model as <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>:</p><formula xml:id="formula_0">X ma = X free + A,<label>(1)</label></formula><p>where X ma , X free , and A represent metal-affected CT images, metal-free CT images, and metal artifacts, respectively. X ma is the observation signal and X free is the target signal to be reconstructed. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Overview</head><p>Figure <ref type="figure" target="#fig_0">1</ref> presents the overall architecture of our proposed method. Let I s be the domain of all synthetic metal-corrupted CT images and I c be the domain of all clinical metal-corrupted CT images. The generators aim to convert them to clean CT image domain I f , where different generators take metal-corrupted CT images from different domains. I f takes the role of a bridge to close the domain gap. The following subsections present the details of these image translation branches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Image Translation</head><p>According to Eq. 1, if two metal artifact reduction translations are completed, the subsequent two transformations can be obtained by subtracting the output of the network from the original input. Therefore, only two translators are needed.</p><p>The first translator is used to convert I s into I f , denoted as G s2f and the second translator is used to convert I c into I f , denoted as G c2f . In this work, two translators, G s2f and G c2f , share the same network architecture, consisting of one encoder and one decoder, as shown in Fig. <ref type="figure" target="#fig_0">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(b) and (d).</head><p>Encoding Stage. In most DL-based MAR methods, the networks take a metalcorrupted CT image as input and map it to a metal-free CT image domain.</p><p>Noise-related features are involved in the entire process, which negatively affects the restoration of clean images. In the principal component analysis (PCA)-based image denoising method <ref type="bibr" target="#b0">[1]</ref>, by retaining only the most important features, noise and irrelevant information are eliminated. In this work, we propose an artifact filtering module (AFM) for feature selection. At the encoding step, feature maps that contribute little to the reconstruction are also considered to be related to noise, where the encoder acts as a filter and only allows useful information to pass through. Specifically, there are two criteria for feature selection: 1) the selected feature maps contain as much information as possible, which is assessed by Variance (V ar), and 2) the correlation between the selected feature maps should be as small as possible, which is measured by covariance (Cov). Finally, each feature map gets a score as:</p><formula xml:id="formula_1">score = V ar Cov + λ , (<label>2</label></formula><formula xml:id="formula_2">)</formula><p>where λ is a small constant to prevent division by zero and we set λ = 1e -7 in this paper. Feature maps with high scores will be selected. Therefore, we can dynamically select different feature maps according to the inputs.</p><p>Decoding Stage. At the encoding stage, features that are helpless to reconstruct the clean image are filtered out. Decoder then maps the remaining features, which contain useful information, back into the image domain. To push the generated image to fall into the clean image domain, we employ conditional normalization layers <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b14">15]</ref> and propose a metal-free spatially aware module (MFSAM). The mean and variance of the features are modulated to match those of the metal-free image style by the MFSAM. The details of MFSAM are illustrated in Fig. <ref type="figure" target="#fig_0">1 (c</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Metal Artifacts Reduction and Generation Stage.</head><p>The framework consists of four image translation branches: two metal artifacts reduction branches I s ←I f and I c ←I f , and two metal artifact generation branches I f ←I s and I f ←I c .</p><p>(1) I s ←I f : In this transformation, we employ G s2f to learn the mapping from the synthetic metal-affected image domain to the metal-free image domain, which is denoted as:</p><formula xml:id="formula_3">X s2f = G s2f (X s ),<label>(3)</label></formula><p>where X s is synthetic metal-affected CT image in I s and X s2f is the corrected result of X s . According to Eq. 1, the metal artifacts A s can be obtained as follows:</p><formula xml:id="formula_4">A s = X s -X s2f . (<label>4</label></formula><formula xml:id="formula_5">)</formula><p>(2) I c ←I f : In this transformation, we use G c2f to learn the mapping from the clinical metal-affected image domain to the metal-free image domain, resulting in metal-corrected CT image X c2f and the metal artifacts A c . This process is the same as the transformation of I s ←I f and can be formulated as follows:</p><formula xml:id="formula_6">X c2f = G c2f (X c ),<label>(5)</label></formula><formula xml:id="formula_7">A c = X c -X c2f , (<label>6</label></formula><formula xml:id="formula_8">)</formula><p>where X c is clinical metal-affected CT image in I c .</p><p>(3): I f ←I s : We use the artifacts of X s to obtain a synthetic domain metalcorrupted image X c2s by adding A s to the learned metal-free CT image X c2f :</p><formula xml:id="formula_9">X c2s = X c2f + A s . (<label>7</label></formula><formula xml:id="formula_10">)</formula><p>(4): I f ←I c : Synthesizing clinical domain metal-corrupted image X s2c can be achieved by adding A c to the learned metal-free CT image X s2f :</p><formula xml:id="formula_11">X s2c = X s2f + A c . (<label>8</label></formula><formula xml:id="formula_12">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Loss Function</head><p>In our framework, the loss function contains two parts: adversarial loss and reconstruction loss.</p><p>Adversarial Loss. Due to the lack of paired clinical metal-corrupted and metalfree CT images, as well as paired clinical and synthetic metal-corrupted CT images, we use PatchGAN-based discriminators, D f , D s , and D c , and introduce an adversarial loss for weak supervision. D f learns to distinguish whether an image is a metal-free image, D s learns to determine whether an image is a synthetic metal-affected CT image, and D c learns to determine whether an image is a clinical metal-affected CT image. The total adversarial loss L adv is written as:</p><formula xml:id="formula_13">L adv = E[logD f (X f )] + E[1 -logD f (X c2f )] + E[logD s (X s )] + E[1 -logD s (X c2s )] + E[logD c (X c )] + E[1 -logD c (X s2c )].<label>(9)</label></formula><p>Reconstruction Loss. The label X gt of X s is employed to guide the G s2f to reduce the metal artifacts. The reconstruction loss L s2f on X x2f can be formulated as:</p><formula xml:id="formula_14">L s2f = ||(X s2f -X gt )|| 1 . (<label>10</label></formula><formula xml:id="formula_15">)</formula><p>When X syn is transformed into the clinical domain, G c2f can also reduce the metal artifacts with the help of X gt . The reconstruction loss L sc2f on X sc2f can be formulated as:</p><formula xml:id="formula_16">L sc2f = ||(X sc2f -X gt )|| 1 , (<label>11</label></formula><formula xml:id="formula_17">)</formula><p>where X sc2f is the MAR results of X s2c .</p><p>To obtain optimal MAR results, it is necessary to remove any noise-related features while preserving as much of the content information as possible. When the input image is already metal-free, the input image has no noise-related features, and the reconstructed image should not suffer from any information loss. Here, we employed the model error loss to realize this constrain:</p><formula xml:id="formula_18">L model error = ||(X f 2f -X f )|| 1 + ||(X f 2f -X f )|| 1 , (<label>12</label></formula><formula xml:id="formula_19">)</formula><p>where X f 2f is a reconstructed image from X f using G s2f and X f 2f is a reconstructed image from X f using G c2f .  Overall Loss. The overall loss function is defined as follows:</p><formula xml:id="formula_20">L = L adv + λ recon (L s2f + L sc2f + L model error ), (<label>13</label></formula><formula xml:id="formula_21">)</formula><p>where λ recon is the weighting parameter and as suggested by <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b13">14]</ref>, it was set as 20.0 in our work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset and Implementation Details</head><p>In this work, we used one synthesized dataset and two clinical datasets, denoted as SY, CL1 and CL2, respectively. The proposed method was trained on SY and CL1. For data simulation, we followed the procedure of <ref type="bibr" target="#b25">[26]</ref> and used the metal-free CT images of the Spineweb dataset <ref type="bibr" target="#b2">[3]</ref>. We set the threshold to 2,000 HU <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b23">24]</ref> to obtain 116 metal masks from metal-affected CT images of the Spineweb dataset, where 100 masks are for training and the remaining 16 masks are for testing. We used 6,000 synthesized pairs for training and 2,000 pairs for evaluation. For CL1, we randomly chose 6,000 metal-corrupted CT images and 6,000 metal-free CT images from Spineweb for training and another 224 metal-corrupted CT images for testing. For CL2, clinical metal-corrupted CT images were collected from our local hospital to investigate the generalization performance. The model was implemented with the PyTorch framework and optimized by the Adam optimizer with the parameters (β 1 , β 2 ) = (0.5, 0.999).</p><p>The learning rate was initialized to 0.0001 and halved every 20 epochs. The network was trained with 60 epochs on one NVIDIA 1080Ti GPU with 11 GB memory, and the batch size was 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Comparison with State-of-the-Art Methods</head><p>The proposed method was compared with several classic and state-of-the-art (SOTA) MAR methods: LI <ref type="bibr" target="#b5">[6]</ref>, NMAR <ref type="bibr" target="#b12">[13]</ref>, ADN <ref type="bibr" target="#b8">[9]</ref>, β-cycleGAN <ref type="bibr" target="#b4">[5]</ref> and SemiADN <ref type="bibr" target="#b13">[14]</ref>. LI and NMAR are traditional MAR methods. ADN and β-cycleGAN are SOTA unsupervised MAR methods. SemiADN is a SOTA semisupervised MAR method. Structural similarity (SSIM) and peak signal-to-noise ratio (PSNR) were adopted as quantitative metrics. Our intuition for determining the number of feature maps selected in AFM is based on the observation that the majority of information in an image is typically related to its content, while noise-related features are few. Therefore, in our work, during the encoding stage, we discarded 2 out of 32 and 4 out of 64 feature maps at the first and second down-sampling stages, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MAR Performance on SY:</head><p>The quantitative scores are presented in Table <ref type="table" target="#tab_0">1</ref>.</p><p>The sizes of the 16 metal implants in the testing dataset are: <ref type="bibr">[254,</ref><ref type="bibr">274,</ref><ref type="bibr">270,</ref><ref type="bibr">262,</ref><ref type="bibr">267,</ref><ref type="bibr">363,</ref><ref type="bibr">414,</ref><ref type="bibr">441,</ref><ref type="bibr">438,</ref><ref type="bibr">445,</ref><ref type="bibr">527,</ref><ref type="bibr">732,</ref><ref type="bibr">845,</ref><ref type="bibr">889,</ref><ref type="bibr">837,</ref><ref type="bibr">735]</ref> in pixels. They are divided into five groups according to their sizes. It is observed that all methods significantly improve both SSIM and PSNR scores compared with uncorrected CT images. Aided by supervision, SemiADN obtains higher quantitative scores than ADN. Compared with these SOTA unsupervised and semi-supervised MAR methods, our method achieves the best quantitative performance. Figure <ref type="figure" target="#fig_1">2</ref> shows the visual comparisons on SY. The proposed method outperforms all other methods in artifact suppression and effectively preserves anatomical structures around metallic implants, thereby demonstrating its effectiveness.</p><p>MAR Performance on CL1: Figure <ref type="figure" target="#fig_2">3</ref> presents three representative clinical metal-affected CT images with different metallic implant sizes from small to large. When the metal is small, all methods can achieve good MAR performance but there are differences in tissue detail preservation. ADN and β-cycleGAN are more prone to lose details around the metal. In SemiADN, the missing details are recovered with the help of the supervision signal. However, in the second case, more artifacts are retained in SemiADN than ADN and β-cycleGAN. Compared with these MAR methods, our method is well-balanced between detail preservation and artifact reduction. When the metallic implant gets larger, as shown in  the third case, other methods are limited to reduce artifacts, and SemiADN even aggravates the impact of artifacts. Fortunately, our method is able to effectively suppress metal artifacts, thus demonstrating its potential for practical clinical use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MAR Performance on CL2:</head><p>To assess the generalization capability of our method, we further evaluated MAR performance on CL2 with the model trained on SYN and CL1. Two practical cases are presented in Fig. <ref type="figure" target="#fig_3">4</ref>. ADN and Semi-ADN fail to deal with severe artifacts and even introduce a deviation of HU value, while β-cycleGAN shows a certain ability to suppress these artifacts. Nonetheless, our proposed method outperforms β-cycleGAN in terms of artifact suppression and detail preservation. It can be seen that our method exhibits good generalization ability, which means it can effectively address metal artifacts even in scenarios where the simulated data and clinical metal-corrected data have different clean image domains. It shows the robustness of our proposed method across different imaging configurations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Ablation Study</head><p>In this section, we investigate the effectiveness of the proposed AFM. Table <ref type="table" target="#tab_1">2</ref> shows the results of our ablation models, where M1 refers to the model without AFM, and M2 replaces the AFM with channel attention. Table <ref type="table" target="#tab_1">2</ref> shows that AFM can improve the scores of M1. Although M2 integrates a channel attention mechanism to dynamically adjust the weight of different feature maps, our proposed AFM method achieves higher quantitative scores, which indicates its superior performance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we explicitly bridge the domain gap between synthetic and clinical metal-corrupted CT images. We employ the clean image domain as the bridge and break the cycle-consistency loss, thereby eliminating the necessity for strict bijection assumption. At the encoding step, feature maps with limited influence will be eliminated, where the encoder acts as a bottleneck only allowing useful information to pass through. Experiments demonstrate that the performance of the proposed method is competitive with several SOTA MAR methods in both qualitative and quantitative aspects. In particular, our method exhibits good generalization ability on clinical data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Overview of the proposed method. C: channel number, K: kernel size, S: stride, and P: padding size. More details on AFM are in Sect. 2.3.</figDesc><graphic coords="3,41,79,195,89,340,12,160,48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Visual comparisons with the SOTA MAR methods on simulated data. (a): Uncorrected, (b): LI,(c): NMAR,(d): ADN, (e): β-cycleGAN, (f): SemiADN, (e): Ours. Display window: [-375,560] HU.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Visual comparisons on CL1 dataset. Display window: [-1000,1000] HU.</figDesc><graphic coords="8,70,98,53,69,310,12,187,00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Visual comparisons on CL2 dataset. Display window: [-375,560] HU.</figDesc><graphic coords="8,55,98,276,77,340,12,138,04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Quantitative results of SOTA MAR methods on the simulated dataset.</figDesc><table><row><cell></cell><cell></cell><cell>→</cell><cell>Middle</cell><cell>→</cell><cell>Large</cell><cell>Average</cell><cell>Params(M)</cell></row><row><cell>Uncorrected</cell><cell>16.23/0.7092</cell><cell cols="3">16.16/0.6513 16.19 /0.6594 16.14/0.6443</cell><cell>16.12/0.6288</cell><cell>16.18/0.6684</cell><cell>-</cell></row><row><cell>LI</cell><cell>28.68/0.8095</cell><cell cols="3">26.84/0.7549 25.37/0.7347 26.07/0.7309</cell><cell>26.06/0.7296</cell><cell>27.19/0.7664</cell><cell>-</cell></row><row><cell>NMAR</cell><cell>29.41/0.8294</cell><cell cols="3">28.19/0.7913 27.24/0.7752 27.80/0.7743</cell><cell>27.62/0.7711</cell><cell>28.43/0.7987</cell><cell>-</cell></row><row><cell>ADN</cell><cell cols="4">31.32/ 0.8425 30.28/0.8043 30.50/0.8089 29.98/0.7908</cell><cell>29.69/0.7806</cell><cell>30.54/0.8127</cell><cell>32.43</cell></row><row><cell>β-cycleGAN</cell><cell>30.34/0.8365</cell><cell cols="3">28.17/0.7811 27.99/0.7961 27.18/0.7710</cell><cell>26.45/0.7502</cell><cell>28.53/0.7958</cell><cell>5.48</cell></row><row><cell>SemiADN</cell><cell>31.07/0.8636</cell><cell cols="3">30.99/0.8393 31.68/0.8500 30.23/0.8322</cell><cell>29.37/0.8144</cell><cell>30.66/0.8435</cell><cell>32.43</cell></row><row><cell>Ours</cell><cell cols="6">32.57/0.8789 31.28/0.8541 31.29/0.8562 30.83/0.8472 30.38/0.8402 31.54/0.8606 6.59</cell></row></table><note><p>PSNR(dB)/SSIM Small</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Quantitative comparison of different variants of our method.</figDesc><table><row><cell></cell><cell>M1</cell><cell>M2</cell><cell>Ours</cell></row><row><cell cols="2">PSNR(dB) 28.99</cell><cell>29.37</cell><cell>31.54</cell></row><row><cell>SSIM</cell><cell cols="3">0.8025 0.8353 0.8606</cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div><p>This work was supported in part by the <rs type="funder">National Natural Science Foundation of China</rs> under Grant <rs type="grantNumber">62271335</rs>; in part by the <rs type="funder">Sichuan Science and Technology Program</rs> under Grant <rs type="grantNumber">2021JDJQ0024</rs>; and in part by the <rs type="funder">Sichuan University</rs> "<rs type="programName">From 0 to 1" Innovative Research Program</rs> under Grant <rs type="grantNumber">2022SCUH0016</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Hg8RdNp">
					<idno type="grant-number">62271335</idno>
				</org>
				<org type="funding" xml:id="_6J2rRKR">
					<idno type="grant-number">2021JDJQ0024</idno>
				</org>
				<org type="funding" xml:id="_JmTBMxg">
					<idno type="grant-number">2022SCUH0016</idno>
					<orgName type="program" subtype="full">From 0 to 1&quot; Innovative Research Program</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">PCA based image denoising</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">M M</forename><surname>Babu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Subramanyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Prasad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Image Process</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">236</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fast enhanced CT metal artifact reduction using data domain deep learning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">U</forename><surname>Ghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">C</forename><surname>Karl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Tran. Comput. Imaging</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="181" to="193" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Vertebrae localization in pathological spine CT via dense classification from sparse annotations</title>
		<author>
			<persName><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zikic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Konukoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Haynor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Medical Image Computing and Computer-Assisted Intervention</title>
		<meeting>the Medical Image Computing and Computer-Assisted Intervention</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="262" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Arbitrary style transfer in real-time with adaptive instance normalization</title>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Unsupervised CT metal artifact learning using attentionguided β-CycleGAN</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3932" to="3944" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Image reconstruction from projections III: projection completion methods</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Lewitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optik</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="189" to="204" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Physically disentangled intra-and interdomain adaptation for varicolored haze removal</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="5841" to="5850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Generative mask pyramid network for CT/CBCT metal artifact reduction with joint projection-sinogram correction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liao</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-32226-7_9</idno>
		<idno>978-3-030-32226-7 9</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">MIC-CAI 2019</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11769</biblScope>
			<biblScope unit="page" from="77" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">ADN: artifact disentanglement network for unsupervised metal artifact reduction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="634" to="643" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">DuDoNet: dual domain network for CT metal artifact reduction</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="10512" to="10521" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">U-DuDoNet: unpaired dual-domain network for CT metal artifact reduction</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87231-1_29</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87231-1" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12906</biblScope>
			<biblScope unit="page">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Encoding metal mask projection for metal artifact reduction in computed tomography</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-A</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59713-9_15</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-59713-915" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12262</biblScope>
			<biblScope unit="page" from="147" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Normalized metal artifact reduction (NMAR) in computed tomography</title>
		<author>
			<persName><forename type="first">E</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raupach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kachelriess</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Phys</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="5482" to="5493" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Low-dimensional manifold constrained disentanglement network for metal artifact reduction</title>
		<author>
			<persName><forename type="first">C</forename><surname>Niu</surname></persName>
		</author>
		<idno type="DOI">10.1109/TRPMS.2021.3122071</idno>
		<ptr target="https://doi.org/10.1109/TRPMS.2021.3122071" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Radiat. Plasma Med. Sci. 1</title>
		<imprint>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Semantic image synthesis with spatially-adaptive normalization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2337" to="2346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Domain adaptation for image dehazing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A semi-supervised learning method of latent features based on convolutional neural networks for CT metal artifact reduction</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Cao</surname></persName>
		</author>
		<idno type="DOI">10.1002/mp.15633</idno>
		<ptr target="https://doi.org/10.1002/mp.15633" />
	</analytic>
	<monogr>
		<title level="j">Med. Phys</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3845" to="3859" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Attentive generative adversarial network to bridge multi-domain gap for image synthesis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICME46284.2020.9102761</idno>
		<ptr target="https://doi.org/10.1109/ICME46284.2020.9102761" />
	</analytic>
	<monogr>
		<title level="m">2020 IEEE International Conference on Multimedia and Expo (ICME)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">IDOL-net: an interactive dual-domain parallel network for CT metal artifact reduction</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1109/TRPMS.2022.3171440</idno>
		<ptr target="https://doi.org/10.1109/TRPMS.2022.3171440" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Radiat. Plasma Med. Sci. 1</title>
		<imprint>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">DAN-net: dual-domain adaptive-scaling non-local network for CT metal artifact reduction</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1088/1361-6560/ac1156</idno>
		<ptr target="https://doi.org/10.1088/1361-6560/ac1156" />
	</analytic>
	<monogr>
		<title level="j">Phys. Med. Biol</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page">155009</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Stay in the middle: a semisupervised model for CT metal artifact reduction</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICASSP49357.2023.10095681</idno>
		<ptr target="https://doi.org/10.1109/ICASSP49357.2023.10095681" />
	</analytic>
	<monogr>
		<title level="m">ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">DESEG: auto detector-based segmentation for brain metastases</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Med. Biol</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">25002</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Metal artifact reduction in 2D CT images with self-supervised cross-domain learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Med. Biol</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page">175003</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep sinogram completion with image prior for metal artifact reduction in CT images</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="228" to="238" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Single image dehazing via semi-supervised domain translation and architecture search</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1109/LSP.2021.3120322</idno>
		<ptr target="https://doi.org/10.1109/LSP.2021.3120322" />
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Lett</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="2127" to="2131" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Convolutional neural network based metal artifact reduction in x-ray computed tomography</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1370" to="1381" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Unsupervised reused convolutional network for metal artifact reduction</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhong</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-63820-7_67</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-63820-767" />
	</analytic>
	<monogr>
		<title level="m">ICONIP 2020</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Pasupa</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Leung</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">-S</forename><surname>Kwok</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Chan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>King</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">1332</biblScope>
			<biblScope unit="page" from="589" to="596" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
