<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">S3M: Scalable Statistical Shape Modeling Through Unsupervised Correspondences</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Lennart</forename><surname>Bastian</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Aided Medical Procedures</orgName>
								<orgName type="institution">Technical University Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexander</forename><surname>Baumann</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Aided Medical Procedures</orgName>
								<orgName type="institution">Technical University Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Computer Aided Medical Procedures</orgName>
								<orgName type="institution">Technical University Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Emily</forename><surname>Hoppe</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Aided Medical Procedures</orgName>
								<orgName type="institution">Technical University Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vincent</forename><surname>BÃ¼rgin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Aided Medical Procedures</orgName>
								<orgName type="institution">Technical University Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Mahdi</roleName><forename type="first">Ha</forename><forename type="middle">Young</forename><surname>Kim</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Aided Medical Procedures</orgName>
								<orgName type="institution">Technical University Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mahdi</forename><surname>Saleh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Benjamin</forename><surname>Busam</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Aided Medical Procedures</orgName>
								<orgName type="institution">Technical University Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nassir</forename><surname>Navab</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Aided Medical Procedures</orgName>
								<orgName type="institution">Technical University Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">S3M: Scalable Statistical Shape Modeling Through Unsupervised Correspondences</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="459" to="469"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">F7F24B5AE623DD33FBAF382D2C06EB53</idno>
					<idno type="DOI">10.1007/978-3-031-43999-5_44</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-13T19:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Statistical Shape Modeling</term>
					<term>Unsupervised Correspondence Estimation</term>
					<term>Geometric Deep Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Statistical shape models (SSMs) are an established way to represent the anatomy of a population with various clinically relevant applications. However, they typically require domain expertise, and labor-intensive landmark annotations to construct. We address these shortcomings by proposing an unsupervised method that leverages deep geometric features and functional correspondences to simultaneously learn local and global shape structures across population anatomies. Our pipeline significantly improves unsupervised correspondence estimation for SSMs compared to baseline methods, even on highly irregular surface topologies. We demonstrate this for two different anatomical structures: the thyroid and a multi-chamber heart dataset. Furthermore, our method is robust enough to learn from noisy neural network predictions, potentially enabling scaling SSMs to larger patient populations without manual segmentation annotation. The code is publically available at: https://github.com/alexanderbaumann99/S3M</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Statistical shape models (SSMs) are a powerful tool to characterize anatomical variations across a population. They have been widely used in medical image analysis and computational anatomy to represent organ structures, with numerous clinically relevant applications such as clustering, classification, and shape regression <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b20">21]</ref>. SSMs are generally represented by point-wise correspondences between shapes <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b12">13]</ref>, or deformation fields to a pre-defined template <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b27">28]</ref>. Despite the existence of implicit models <ref type="bibr" target="#b1">[2]</ref>, abstracting shape correspondences in the form of linear point distribution models (PDM) constitutes an appealing and interpretable way to represent shape distributions <ref type="bibr" target="#b2">[3]</ref>. Furthermore, many implicit models still rely on correspondence annotations during training <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b6">7]</ref>.</p><p>Creating SSMs is cumbersome and intricate, as significant manual human annotation is necessary. Domain experts typically first segment images in 3D. The labeled 3D organ surfaces must then be aligned and brought into correspondence, typically achieved through deformable image registration methods using manual landmark annotations <ref type="bibr" target="#b5">[6]</ref>. This is labor-intensive and error-prone, potentially inducing bias into downstream SSMs and applications <ref type="bibr" target="#b38">[39]</ref>.</p><p>Unsupervised methods have been proposed to estimate correspondences for SSMs <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b23">24]</ref>. However, they typically require precisely segmented and smooth surfaces to generate accurate inter-organ correspondences. ShapeWorks has been established to produce high-quality correspondences on several organs such as femurs or left atria <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b6">7]</ref>. However, as domain experts carefully curate most medical datasets, the robustness of such methods has not yet been thoroughly evaluated concerning label noise and segmentation inaccuracies. The main obstacles that prevent scaling SSMs to larger patient populations are unsupervised correspondence methods that can handle topological variations in noisy annotations, such as those produced by inexperienced annotators or predictions from deep neural networks. Robust methods to deal with these obstacles are required.</p><p>To address these challenges, we propose S3M, which leverages unsupervised deep geometric features while incorporating a global shape structure. Geometric Deep Learning (GDL) provides techniques to process 3D shapes and geometries, which are robust to noise, 3D rotations, and global deformations. We utilize graph neural networks (GNN) and functional mappings to establish dense surface correspondences of samples without supervision. This approach has significant clinical implications as it enables automatically representing anatomical shapes across large patient populations without requiring manual expert landmark annotations. We demonstrate that our proposed method creates objectively superior SSMs from shapes with noisy surface topologies. Moreover, it accurately corresponds regions of complex anatomies with mesh bifurcations such as the heart, which could ease the modeling of inter-organ relations <ref type="bibr" target="#b11">[12]</ref>.</p><p>Our contributions can be summarized as follows:</p><p>-We propose a novel unsupervised correspondence method for SSM curation based on geometric deep learning and functional correspondence. -S3M exhibits superior performance on two challenging anatomies: thyroid and heart. It generates objectively more suitable SSMs from noisy thyroid labels and challenging multi-chamber heart reconstructions. -To pave the way for unsupervised SSM generation in other medical domains, we open-source the code of our pipeline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Point Distribution Models. A population of shapes must be brought into correspondence to construct a PDM. This has been traditionally achieved through pair-wise registration methods <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b20">21]</ref>. However, pairwise approaches can admit bias as they neglect the population during correspondence generation <ref type="bibr" target="#b18">[19]</ref>. More recently, group-wise optimization methods such as ShapeWorks <ref type="bibr" target="#b10">[11]</ref> have been adopted as they jointly optimize over a cohort, overcoming such biases. They demonstrate superior prediction of clinically relevant anatomical variations <ref type="bibr" target="#b18">[19]</ref>. Furthermore, generic models that can perform well across various organs are sought after.</p><p>Graph Neural Networks (GNNs) have been used to enable structural feature extraction through message passing. They constitute a powerful tool to process 3D data and extract geometric features <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b37">38]</ref> which can be useful for disease prediction <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b29">30]</ref>. Other medical applications involve brain cortex mesh reconstruction <ref type="bibr" target="#b7">[8]</ref> and 3D organ-at-risk (ORA) segmentation <ref type="bibr" target="#b21">[22]</ref>. We use GNNs for deformable 3D organ shapes and learn to estimate dense correspondences in the presence of noise and anatomical variations.</p><p>Functional Correspondence. Functional maps abstract the notion of pointto-point correspondences by corresponding arbitrary functions, such as texture or curvature, across shapes. They are extensively used to estimate dense correspondences across deformable shapes <ref type="bibr" target="#b28">[29]</ref> and can be incorporated into learning frameworks <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b25">26]</ref>. These methods are typically evaluated on synthetic meshes with dense annotations and limited variable surface topology. In contrast, medical shapes exhibit higher variability, requiring robust surface representation for reliable correspondence matching. More recently, unsupervised functional correspondence models have been proposed <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b30">31]</ref>. These methods demonstrate strong performance on synthetic data without manual correspondence anno-tations. They extract features from the surface geometry using hand-crafted descriptors such as SHOT <ref type="bibr" target="#b35">[36]</ref>, wave-kernel signatures (WKS) <ref type="bibr" target="#b4">[5]</ref> or heat-kernel signatures (HKS) <ref type="bibr" target="#b8">[9]</ref>. The extracted features are then typically refined and projected onto the Laplace-Beltrami Operator (LBO) eigenfunctions <ref type="bibr" target="#b28">[29]</ref>. Î¼Match <ref type="bibr" target="#b23">[24]</ref> recently leveraged such an unsupervised approach in the medical domain.</p><p>They employ handcrafted features to extract representations from shapes with a relatively smooth surface topology; however, they fail for shapes with high degrees of surface noise or label inconsistencies. To scale SSM curation to larger datasets encompassing population variance, our method must be robust to a more variable and complex surface topology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>In the following, we propose a method to establish an SSM as a Point Distribution Model (PDM), illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>. Robust local features from the surface mesh are extracted using GNNs. These features are then projected onto the truncated eigenspace of the Laplace-Beltrami Operator using m = 20 eigenfunctions <ref type="bibr" target="#b28">[29]</ref>. We perform post-processing with a Product Manifold Filter (PMF) <ref type="bibr" target="#b36">[37]</ref> to obtain bijective correspondences for SSM generation. The shape model is subsequently created by aggregating correspondences across a dataset of predicted correspondences using the eigendecomposition of the covariance matrix.</p><p>Geometric Feature Description. Handcrafted descriptors <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b35">36]</ref> are unable to represent the complex surface topology of medical data adequately. To cope with surface artifacts and irregular morphologies, we use a graph-based descriptor <ref type="bibr" target="#b31">[32]</ref>. We first extract a surface mesh from a 3D volumetric grid using marching cubes <ref type="bibr" target="#b26">[27]</ref>. Graph nodes are defined as the mesh's vertices; edges are obtained using a k-nearest neighbor search with k = 10. Node features are given by spatial xyz-coordinates. The graph is fed into three topology adaptive layers <ref type="bibr" target="#b17">[18]</ref> using graph convolutions with a specific number of hops to define the number of nodes a message is passed to. Increasing the number of hops (we use 1, 2, 3 hops per layer, respectively) increases the receptive field, incorporating features from more distant nodes. Finally, features pass a linear layer before being projected onto the Laplace-Beltrami eigenfunctions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Deformable Correspondence Estimation.</head><p>PDMs require correspondences between samples to model the statistical distribution of the organ. Inspired by methods for geometric shape correspondence, we propose to estimate a functional mapping T to correspond high-level semantics from two input shapes, X i and X j . The LBO extends the Laplace operator to Riemannian manifolds, capturing intrinsic characteristics of the shape independent of its position and orientation in Euclidean space. It can be efficiently computed on a surface mesh using, for example, the cotangent weight discretization scheme <ref type="bibr" target="#b14">[15]</ref>. This results in a matrix representation of the LBO from which one can then calculate the associated eigenfunctions Ï i â R nÃm for a shape X i â R nÃ3 . Given a feature vector D i extracted from a surface mesh of shape X i and a neural network T Ï , we can approximate a functional mapping between shapes by solving the following optimization problem:</p><formula xml:id="formula_0">min Ï (Xi,Xj ) L(C ij , C ji ) where C ij = arg min C CA T Ï (Di) -A T Ï (Dj )<label>(1)</label></formula><p>Here, A T Ï (Di) â R mÃm denotes the transformed descriptor, written in the basis of the LBO eigenfunctions of shape X i and C ij â R mÃm represents the optimal functional mapping from the descriptor space of X i to the one of X j . Inspired by existing works on shape correspondence <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b33">34]</ref>, our loss function enforces four separate characteristics on the learned functional mapping, including bijectivity, orthogonality, and isometric properties. We refer to the supplementary materials for the complete definition. Notably, none of these losses uses ground truth correspondences, making the entire process unsupervised.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training and Inference.</head><p>During training, two shapes are sampled from the dataset, and the pipeline is optimized with Eq. 1. We increase model robustness by augmenting with rotations and small surface deformations. The point cloud is sub-sampled in each training iteration using farthest point sampling with random initialization. During inference, our model predicts pairwise correspondences. To accumulate these over an entire dataset of N shapes, we choose a template shape X T = arg min Xi N j=0 1 i =j L (C ij , C ji ) as the instance with the lowest average loss to all other shapes in the dataset. As in <ref type="bibr" target="#b28">[29]</ref>, we extract  point-to-point correspondences between the template X T and another shape X i by matching the transformed LBO eigenfunctions of X i , namely C iT Ï i , with the LBO eigenfunctions of the template Ï T using nearest neighbors. As PDMs require bijective correspondences, we subsequently post-process the results with PMF <ref type="bibr" target="#b36">[37]</ref>.</p><p>Statistical Shape Modeling. We use the PDM <ref type="bibr" target="#b12">[13]</ref> as the underlying method of the shape model. It takes input points of the form X â R N Ãd , where N , d are the number of shape samples and coordinates per shape, respectively. It returns a multi-variate normal distribution. In our case, d = 3n given each shape has n points. We calculate the mean shape X and the empirical covariance matrix S = cov(X) over the N samples <ref type="bibr" target="#b12">[13]</ref>. Since S has rank N -1, it has N -1 real eigenvectors v j with eigenvalues Î» j . If we consider the sum</p><formula xml:id="formula_1">s = X + N -1 j=1 Î± j Î» j v j , Î± j â¼ N (0, 1)<label>(2)</label></formula><p>then s â¼ N X, S , which is the desired distribution of the model. For the above, the points must be in correspondence across the samples. We thus use the correspondences generated in Sect. 3 to construct the PDM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>All experiments are carried out using two publicly available datasets: thyroid ultrasound scans and heart MRI acquisitions. Our model is implemented in PyTorch 1.12 using CUDA 11.6. Training takes between 2.5-3 h on an Nvidia A40 GPU and inference about 0.71 s for a pair of shapes. We use publically available implementations for all baseline methods.</p><p>Thyroid Dataset (SegThy) <ref type="bibr" target="#b24">[25]</ref>. The dataset comprises 3D freehand US scans of healthy thyroids from 32 volunteers aged 24-39. For each volunteer, three physicians acquired three scans each. Ultrasound scans generally exhibit noise induced by physical properties such as phase aberrations and attenuation. This leads to label inconsistencies or topological irregularities that pose a challenge for shape modeling (see Fig. <ref type="figure" target="#fig_1">2</ref>). US sweeps were compounded to a 3D grid of resolution 0.12 Ã 0.12 Ã 0.12 mm 3 . A single scan from each of the 16 volunteers was manually annotated by experts (ground truth) and used to train QuickNAT <ref type="bibr" target="#b24">[25]</ref>. The remaining scans were pseudo-labeled through QuickNAT segmentation predictions exhibiting moderate degrees of noise and inaccuracies (dice score of 0.94 <ref type="bibr" target="#b24">[25]</ref>). We divide the dataset into manual and pseudo-label predictions and evaluate them separately. The pseudo-label experiment evaluates the model's performance under topological noise and inaccuracies and is limited to 100 scans due to ShapeWorks memory constraints <ref type="bibr" target="#b19">[20]</ref>. We extract a surface mesh for each scan using marching cubes and subsample the meshes to 5000 vertices.</p><p>Heart Dataset <ref type="bibr" target="#b34">[35]</ref>. The data constitutes 30 MRI scans from a single cardiac phase of the heart. Each image has a voxel resolution of 1.25Ã1.25Ã2.7 mm 3 . Segmentation is carried out using an automated method, with subsequent manual corrections by domain experts. Labels are provided for: the right/left ventricle, right/left atrium, aorta, and pulmonary artery. We evaluate the capability of the models to reconstruct complex organs using three hierarchical compositions of the heart chambers. Composition 1 consists of the right ventricle, Composition 2 of the left and right atrium and ventricle, and Composition 3 of the whole heart, including the aorta and pulmonary artery. SSM Evaluation. We compare Shapeworks <ref type="bibr" target="#b10">[11]</ref>, Î¼Match <ref type="bibr" target="#b23">[24]</ref> and SURFMNet <ref type="bibr" target="#b30">[31]</ref>, with S3M. A four-fold cross-validation is employed. SURFMNet, Î¼Match, and S3M are trained on the training folds and correspondences are predicted on the training and validation set. Since the particle-based optimization of Shapeworks does not generalize to unseen data, it uses all folds for correspondence estimation. The SSM is built using correspondences from the training set, and evaluated with respect to two standardized metrics: generality and specificity <ref type="bibr" target="#b15">[16]</ref>. For generality, we measure how well the SSM can represent unseen instances from the fourth fold through the Chamfer distance between the original shape and its SSM reconstruction. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Discussion</head><p>Experiment 1: Thyroid SSM. Table <ref type="table" target="#tab_0">1</ref> depicts the performance for all methods on the thyroid shapes. SURFMNet results for the thyroid pseudo-labels are omitted, as the method did not converge. Consistent trends can be observed across all methods for both sets of thyroid labels. The two existing functional map-based methods were outperformed by Shapeworks, while the proposed S3M exceeded the latter's scores. The descriptor is the most significant difference between the three learned functional map methods. Hand-crafted shape descriptors like SHOT and a simple fully-connected residual network architecture do not adequately represent thyroids' noisy and heterogeneous shapes.</p><p>Our proposed method significantly outperformed Shapeworks in all metrics except the specificity of pseudo-labeled thyroids, where the results are not statistically significant. This was despite the advantage of optimizing correspondences across all shapes in training and validation. S3M can better cope with topological noise and generalizes to unseen samples, demonstrating potential in scaling SSM generation to larger datasets. Furthermore, it does not suffer from increasing memory requirements with the number of samples.  <ref type="table" target="#tab_2">2</ref> depicts the results of the different models on the three heart chamber compositions as previously defined. For the single-organ right atrium (composition 1), our proposed method fares comparably to ShapeWorks. For the more complex compositions 2 and 3, we observe larger increases in generalization and specificity for Shapeworks. Î¼Match fails to create a convincing SSM for any heart composition. Interestingly, SURFMNet can represent the more complex compositions 2 and 3 better than ShapeWorks, showing the strength of functional maps at representing complex high-level structures. S3M still exceeded the performance of SURFMNet, possibly due to the graph descriptor being better able to represent the surface topology.</p><p>From the qualitative results in Fig. <ref type="figure" target="#fig_3">3</ref>, it becomes more apparent that Shape-Works does not generate an adequate SSM for the more complex compositions. This further supports our proposed method's ability to learn correspondences for intricate and complex surface topologies, even consisting of meshes with bifurcations. The flexibility of our surface representation enables unsupervised correspondence estimation from multiple hierarchical sub-shapes, which is invaluable in multi-organ modeling such as for the heart <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b11">12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 3: Thyroid Pseudo-label Generalization</head><p>To further highlight the proposed methods' robustness to network-generated segmentation labels, we additionally measure the reconstruction ability of SSMs created from pseudo-labels on manually annotated thyroid labels under the Chamfer distance (Ours: 1.05 Â± 0.10 mm, Shapeworks: 1.84 Â± 0.40 mm). Notably, the proposed PDM on pseudo-labels generalizes better than the SSM built on few manual labels (1.25 Â± 0.11 mm; see Table <ref type="table" target="#tab_0">1</ref>), suggesting that more data can improve the SSM even if the labels are inaccurate. This is further supported by differences in shape (suppl. Figure <ref type="figure" target="#fig_0">1</ref>); the SSM's mean shape generated from pseudo-labels approximates the mean shapes on GT labels (and thus, the true organ shape) more closely.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We present an unsupervised approach for learning correspondences between shapes that exhibit noisy and irregular surface topologies. Our method leverages the strengths of geometric feature extractors to learn the intricacies of organ surfaces, as well as high-level functional bases of the Laplace-Beltrami operator to capture more extensive organ semantics. S3M outperforms existing methods on both manual labels, and label predictions from a network, demonstrating the potential to scale existing SSM pipelines to datasets that encompass more substantial population variance without additional annotation burden. Finally, we show that our model has the potential to learn correspondences between complex multi-organ shape hierarchies such as chambers of the heart, which would ease the manual burden of SSM curation for structures that currently still require meticulous manual landmark annotations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Our proposed method for unsupervised SSM curation. (a) We use a Siamese GNN as shape descriptor and project the extracted features onto the LBO eigenfunctions Ï to obtain spectral representations. (b) From these, we optimize a functional mapping between pairs of shapes with an unsupervised loss. Gradients are backpropagated to the geometric descriptors. (c) During inference, the dense correspondences are estimated between pairs of shapes based on the learned population parameters, which are then used to construct an SSM.</figDesc><graphic coords="3,55,98,54,29,340,30,136,42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. PDM results from the proposed method S3M on the thyroid dataset [25]. The top row depicts the PDM generated from manual annotations and the bottom row from network pseudo-labels. From left to right, we depict -3 â Î»1, -3 â Î»2, the mean shape, +3 â Î»2, +3 â Î»1, with Î»i the eigenmode corresponding to the i-th largest eigenvalue. Similar colors indicate corresponding regions predicted by the model.</figDesc><graphic coords="5,108,00,56,66,285,01,156,13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Qualitative Analysis of Whole-Heart SSMs. A sample from the heart dataset (a). Composition 1 (right ventricle) is denoted in red. Composition 2 (both ventricles and atria) combines red and green regions. Composition 3 additionally incorporates the vessels, denoted in blue The predicted SSM mean shapes for composition 3 are portrayed for ShapeWorks (b), Î¼Match (c), SURFMNet (d), and S3M (e).</figDesc><graphic coords="6,43,80,53,84,336,43,68,77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>SSM quality metrics for the Thyroid dataset<ref type="bibr" target="#b24">[25]</ref> </figDesc><table><row><cell>Metrics</cell><cell cols="2">Ground-Truth Segmentation</cell><cell cols="2">Network Pseudo-Labels</cell></row><row><cell></cell><cell cols="4">Generality [mm] â Specificity [mm] â Generality [mm] â Specificity [mm] â</cell></row><row><cell cols="2">SURFMNet 2.20 Â± 0.20</cell><cell>3.20 Â± 0.29</cell><cell>-</cell><cell>-</cell></row><row><cell>Î¼Match</cell><cell>1.92 Â± 0.07</cell><cell>2.81 Â± 0.18</cell><cell>1.90 Â± 0.08</cell><cell>2.84 Â± 0.10</cell></row><row><cell cols="2">Shapeworks 1.94 Â± 0.27</cell><cell>1.81 Â± 0.06</cell><cell>1.60 Â± 0.04</cell><cell>1.75 Â± 0.07</cell></row><row><cell cols="2">S3M (Ours) 1.25 Â± 0.11</cell><cell>1.59 Â± 0.06</cell><cell>0.95 Â± 0.07</cell><cell>1.84 Â± 0.08</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Specificity indicates how well random samples from the SSM represent the training data. We sample from the PDM 1000 times and calculate each sample's minimum Chamfer distance to the training shapes. Generalization and specificity are reported in mm. Numbers in bold indicate statistically significant results by a one-sided t-test (p &lt; 0.05).</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Whole Heart Statistical Shape Modeling Specificity [mm] â Generality [mm] â Specificity [mm] â Generality [mm] â Specificity [mm] â</figDesc><table><row><cell>Metrics</cell><cell>Composition 1</cell><cell></cell><cell>Composition 2</cell><cell></cell><cell>Composition 3</cell><cell></cell></row><row><cell cols="2">Generality [mm] â SURFMNet 1.10 Â± 0.39</cell><cell>1.79 Â± 0.87</cell><cell>1.37 Â± 0.16</cell><cell>2.00 Â± 0.30</cell><cell>1.71 Â± 0.17</cell><cell>2.54 Â± 0.36</cell></row><row><cell>Î¼Match</cell><cell>3.39 Â± 0.26</cell><cell>4.65 Â± 0.16</cell><cell>2.82 Â± 0.14</cell><cell>4.81 Â± 0.41</cell><cell>3.30 Â± 0.07</cell><cell>5.80 Â± 0.08</cell></row><row><cell cols="2">ShapeWorks 0.89 Â± 0.08</cell><cell>1.40 Â± 0.04</cell><cell>2.57 Â± 0.17</cell><cell>3.60 Â± 0.06</cell><cell>3.07 Â± 0.19</cell><cell>4.99 Â± 0.22</cell></row><row><cell cols="2">S3M (Ours) 0.85 Â± 0.07</cell><cell>1.30 Â± 0.01</cell><cell>1.30 Â± 0.13</cell><cell>1.72 Â± 0.05</cell><cell>1.63 Â± 0.17</cell><cell>2.14 Â± 0.07</cell></row></table><note><p>Experiment 2: Whole Heart SSM. Table</p></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43999-5 44.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Uncertain-DeepSSM: from images to probabilistic shape models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bhalodia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Elhabian</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-61056-2_5</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-61056-25" />
	</analytic>
	<monogr>
		<title level="m">ShapeMI 2020</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Reuter</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Wachinger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Lombaert</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Paniagua</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">O</forename><surname>Goksel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Rekik</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12474</biblScope>
			<biblScope unit="page" from="57" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">From images to probabilistic anatomical shapes: a deep variational bottleneck approach</title>
		<author>
			<persName><forename type="first">J</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Elhabian</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16434-7_46</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16434-746" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13432</biblScope>
			<biblScope unit="page" from="474" to="484" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Spatiotemporal cardiac statistical shape modeling: a data-driven approach</title>
		<author>
			<persName><forename type="first">J</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Elhabian</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-23443-9_14</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-23443-914" />
	</analytic>
	<monogr>
		<title level="m">STACOM MICCAI 2022</title>
		<editor>
			<persName><forename type="first">O</forename><surname>Camara</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">13593</biblScope>
			<biblScope unit="page" from="143" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Learning deep features for shape correspondence with domain invariance</title>
		<author>
			<persName><forename type="first">P</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Whitaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Elhabian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.10493</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">The wave kernel signature: a quantum mechanical approach to shape analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Aubry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Schlickewei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>ICCV Workshops</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Automated 3d whole-heart mesh reconstruction from 2d cine mr slices using statistical shape model</title>
		<author>
			<persName><forename type="first">A</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zacur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Grau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 IEEE EMBS</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1702" to="1706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Deepssm: a blueprint for image-to-shape deep learning models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bhalodia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Elhabian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Whitaker</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.07152</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Vox2cortex: fast explicit reconstruction of cortical surfaces from 3d MRI scans with geometric deep neural networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bongratz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rickmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>PÃ¶lsterl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wachinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2022</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="20773" to="20783" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Scale-invariant heat kernel signatures for non-rigid shape recognition</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2010</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1704" to="1711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Unsupervised deep multi-shape matching</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bernard</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-20062-5_4</idno>
		<idno>978- 3-031-20062-5 4</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">ECCV 2022</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Avidan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Brostow</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Cisse</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Farinella</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Hassner</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13663</biblScope>
			<biblScope unit="page" from="55" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Cates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Elhabian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Whitaker</surname></persName>
		</author>
		<title level="m">ShapeWorks. In: Statistical Shape and Deformation Analysis</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="257" to="298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Computational anatomy for multi-organ analysis in medical imaging: a review</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Cerrolaza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="44" to="67" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Training models of shape from sets of examples</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Graham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMVC</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Diffeomorphic statistical shape models</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Twining</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">O</forename><surname>Babalola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Vision Comput</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="326" to="332" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Discrete differential geometry: an applied introduction</title>
		<author>
			<persName><forename type="first">K</forename><surname>Crane</surname></persName>
			<affiliation>
				<orgName type="collaboration">AMS Commun</orgName>
			</affiliation>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1153" to="1159" />
			<pubPlace>Not</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Davies</surname></persName>
		</author>
		<title level="m">Learning Shape: Optimal Models for Analysing Natural Variability. The University of Manchester</title>
		<meeting><address><addrLine>United Kingdom</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep geometric functional maps: robust feature learning for shape correspondence</title>
		<author>
			<persName><forename type="first">N</forename><surname>Donati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ovsjanikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2020</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8592" to="8601" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Moura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10370</idno>
		<title level="m">Topology adaptive graph convolutional networks</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Benchmarking off-the-shelf statistical shape modeling tools in clinical applications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Goparaju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Henninger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page">102271</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning a conditional generative model for anatomical shape analysis</title>
		<author>
			<persName><forename type="first">B</forename><surname>GutiÃ©rrez-Becker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wachinger</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-20351-1_39</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-20351-139" />
	</analytic>
	<monogr>
		<title level="m">IPMI 2019</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">C S</forename><surname>Chung</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Gee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Yushkevich</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Bao</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11492</biblScope>
			<biblScope unit="page" from="505" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Statistical shape models for 3D medical image segmentation: a review</title>
		<author>
			<persName><forename type="first">T</forename><surname>Heimann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Meinzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="543" to="563" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Automatic identification of segmentation errors for radiotherapy using geometric learning</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Herk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Vasquez Osorio</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16443-9_31</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16443-9" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13435</biblScope>
			<biblScope unit="page">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">InceptionGCN: receptive field aware graph convolutional network for disease prediction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kazi</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-20351-1_6</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-20351-16" />
	</analytic>
	<monogr>
		<title level="m">IPMI 2019</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">C S</forename><surname>Chung</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Gee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Yushkevich</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Bao</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11492</biblScope>
			<biblScope unit="page" from="73" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Klatzow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dalmasso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>MartÃ­nez-AbadÃ­as</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sharpe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Uhlmann</surname></persName>
		</author>
		<title level="m">D shape correspondence for biological image data</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Tracked 3d ultrasound and deep neural network-based thyroid segmentation reduce interobserver variability in thyroid volumetry</title>
		<author>
			<persName><forename type="first">M</forename><surname>KrÃ¶nke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Eilers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dimova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>KÃ¶hler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Buschner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Plos One</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Deep functional maps: structured prediction for dense shape correspondence</title>
		<author>
			<persName><forename type="first">O</forename><surname>Litany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Remez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rodola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bronstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5659" to="5667" />
		</imprint>
		<respStmt>
			<orgName>ICCV</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Marching cubes: a high resolution 3d surface construction algorithm</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Lorensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Cline</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Siggraph Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="163" to="169" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Landmark-free statistical shape modeling via neural flow deformations</title>
		<author>
			<persName><forename type="first">D</forename><surname>LÃ¼dke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Amiranashvili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ambellan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ezhov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Menze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zachow</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16434-7_44</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16434-7" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13432</biblScope>
			<biblScope unit="page">44</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Functional maps: a flexible representation of maps between shapes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ovsjanikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ben-Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Solomon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Butscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM ToG</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Spectral graph convolutions for population-based disease prediction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Parisot</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-66179-7_21</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-66179-721" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2017</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Duchesne</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">10435</biblScope>
			<biblScope unit="page" from="177" to="185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Unsupervised deep learning for structured shape matching</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Roufosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ovsjanikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Graphite: graphinduced feature extraction for point cloud registration</title>
		<author>
			<persName><forename type="first">M</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Busam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tombari</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="241" to="251" />
		</imprint>
	</monogr>
	<note>In: 2020 3DV</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Bending graphs: hierarchical shape matching using gated optimal transport</title>
		<author>
			<persName><forename type="first">M</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cosmo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Busam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tombari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2022</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="11757" to="11767" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Weakly supervised deep functional maps for shape matching</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ovsjanikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="19264" to="19275" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Benchmark for algorithms segmenting the left atrium from 3d ct and mri datasets</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tobon-Gomez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1460" to="1473" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Unique signatures of histograms for local surface description</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tombari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Salti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Di Stefano</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-15558-1_26</idno>
		<ptr target="https://doi.org/10.1007/978-3-642-15558-126" />
	</analytic>
	<monogr>
		<title level="m">ECCV 2010</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Daniilidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Maragos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Paragios</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6313</biblScope>
			<biblScope unit="page" from="356" to="369" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Product manifold filter: non-rigid shape correspondence via kernel density estimation in the product space</title>
		<author>
			<persName><forename type="first">M</forename><surname>Vestner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Litman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rodola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Dynamic graph cnn for learning on point clouds</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Solomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acm ToG</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Disentangling human error from ground truth in segmentation of medical images</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="15750" to="15762" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
