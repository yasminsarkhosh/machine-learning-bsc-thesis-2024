<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Federated Uncertainty-Aware Aggregation for Fundus Diabetic Retinopathy Staging</title>
				<funder ref="#_VvYJTSr">
					<orgName type="full">A*STAR Central Research Fund &quot;A Secure and Privacy Preserving AI Platform for Digital Health&quot;, and A*STAR Career Development Fund</orgName>
				</funder>
				<funder ref="#_QxWHPYU">
					<orgName type="full">Agency for Science, Technology and Research (A*STAR)</orgName>
				</funder>
				<funder ref="#_DMhY9YC">
					<orgName type="full">National Research Foundation, Singapore</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Meng</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Agency for Science, Technology and Research (A*STAR)</orgName>
								<orgName type="institution">Institute of High Performance Computing (IHPC)</orgName>
								<address>
									<addrLine>1 Fusionopolis Way, #16-16</addrLine>
									<postCode>138632</postCode>
									<settlement>Connexis</settlement>
									<country>Singapore, Republic of Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lianyu</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">College of Computer Science and Technology</orgName>
								<orgName type="institution">Nanjing University of Aeronautics and Astronautics</orgName>
								<address>
									<postCode>211100</postCode>
									<settlement>Nanjing, Jiangsu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xinxing</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Agency for Science, Technology and Research (A*STAR)</orgName>
								<orgName type="institution">Institute of High Performance Computing (IHPC)</orgName>
								<address>
									<addrLine>1 Fusionopolis Way, #16-16</addrLine>
									<postCode>138632</postCode>
									<settlement>Connexis</settlement>
									<country>Singapore, Republic of Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ke</forename><surname>Zou</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">National Key Laboratory of Fundamental Science on Synthetic Vision and the College of Computer Science</orgName>
								<orgName type="institution">Sichuan University</orgName>
								<address>
									<postCode>610065</postCode>
									<settlement>Chengdu, Sichuan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yiming</forename><surname>Qian</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Agency for Science, Technology and Research (A*STAR)</orgName>
								<orgName type="institution">Institute of High Performance Computing (IHPC)</orgName>
								<address>
									<addrLine>1 Fusionopolis Way, #16-16</addrLine>
									<postCode>138632</postCode>
									<settlement>Connexis</settlement>
									<country>Singapore, Republic of Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rick</forename><forename type="middle">Siow Mong</forename><surname>Goh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yong</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Agency for Science, Technology and Research (A*STAR)</orgName>
								<orgName type="institution">Institute of High Performance Computing (IHPC)</orgName>
								<address>
									<addrLine>1 Fusionopolis Way, #16-16</addrLine>
									<postCode>138632</postCode>
									<settlement>Connexis</settlement>
									<country>Singapore, Republic of Singapore</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Huazhu</forename><surname>Fu</surname></persName>
							<email>hzfu@ieee.org</email>
							<affiliation key="aff0">
								<orgName type="department">Agency for Science, Technology and Research (A*STAR)</orgName>
								<orgName type="institution">Institute of High Performance Computing (IHPC)</orgName>
								<address>
									<addrLine>1 Fusionopolis Way, #16-16</addrLine>
									<postCode>138632</postCode>
									<settlement>Connexis</settlement>
									<country>Singapore, Republic of Singapore</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Federated Uncertainty-Aware Aggregation for Fundus Diabetic Retinopathy Staging</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="222" to="232"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">BC9146092E19C68E9FC227A6BB9BF01B</idno>
					<idno type="DOI">10.1007/978-3-031-43895-0_21</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-13T19:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Federated learning</term>
					<term>Uncertainty estimation</term>
					<term>DR staging M. Wang and L. Wang contributed equally</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep learning models have shown promising performance in the field of diabetic retinopathy (DR) staging. However, collaboratively training a DR staging model across multiple institutions remains a challenge due to non-iid data, client reliability, and confidence evaluation of the prediction. To address these issues, we propose a novel federated uncertainty-aware aggregation paradigm (FedUAA), which considers the reliability of each client and produces a confidence estimation for the DR staging. In our FedUAA, an aggregated encoder is shared by all clients for learning a global representation of fundus images, while a novel temperature-warmed uncertainty head (TWEU) is utilized for each client for local personalized staging criteria. Our TWEU employs an evidential deep layer to produce the uncertainty score with the DR staging results for client reliability evaluation. Furthermore, we developed a novel uncertainty-aware weighting module (UAW) to dynamically adjust the weights of model aggregation based on the uncertainty score distribution of each client. In our experiments, we collect five publicly available datasets from different institutions to conduct a dataset for federated DR staging to satisfy the real non-iid condition. The experimental results demonstrate that our FedUAA achieves better DR staging performance with higher reliability compared to other federated learning methods. Our proposed FedUAA paradigm effectively addresses the challenges of collaboratively training DR staging models across multiple institutions, and provides a robust and reliable solution for the deployment of DR diagnosis models in real-world clinical scenarios.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In the past decade, numerous deep learning-based methods for DR staging have been explored and achieved promising results <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b26">27]</ref>. However, most current studies focus on centralized learning, which necessitates data collection from multiple institutions to a central server for model training. This approach poses significant data privacy security risks. Additionally, in clinical practice, different institutions may have their own DR staging criteria <ref type="bibr" target="#b2">[3]</ref>. Consequently, it is difficult for the previous centralized DR staging method to utilize data of varying DR staging criteria to train a unified model.</p><p>Federated learning (FL) is a collaborative learning framework that enables training a model without sharing data between institutions, thereby ensuring data privacy <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b20">21]</ref>. In the FL paradigm, FedAvg <ref type="bibr" target="#b23">[24]</ref> and its variants <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23]</ref> are widely used and have achieved excellent performance in various medical tasks. However, these FL methods assign each client a static weight for model aggregation, which may lead to the global model not learning sufficient knowledge from clients with large heterogeneous features and ignoring the reliability of each client. In clinical practice, the data distributions of DR datasets between institutions often vary significantly due to medical resource constraints, population distributions, collection devices, and morbidity <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b28">29]</ref>. This variation poses great challenges for the exploration of federated DR staging methods. Moreover, most existing DR staging methods and FL paradigms mainly focus on performance improvement and ignore the exploration of the confidence of the prediction. Therefore, it is essential to develop a new FL paradigm that can provide reliable DR staging results while maintaining higher performance. Such a paradigm would reduce data privacy risks and increase user confidence in AI-based DR staging systems deployed in real-world clinical settings.</p><p>To address the issues, we propose a novel FL paradigm, named FedUAA, that employs a personalized structure to handle collaborative DR staging among multiple institutions with varying DR staging criteria. We utilize uncertainty to evaluate the reliability of each client's contribution. While uncertainty is a proposed measure to evaluate the reliability of model predictions <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b29">30]</ref>, it remains an open topic in FL research. In our work, we introduce a temperaturewarmed evidential uncertainty (TWEU) head to enable the model to generate a final result with uncertainty evaluation without sacrificing performance. Additionally, based on client uncertainty, we developed an uncertainty-aware weighting module (UAW) to dynamically aggregate models according to each client's uncertainty score distribution. This can improve collaborative DR staging across multiple institutions, particularly for clients with large data heterogeneity. Finally, we construct a dataset for federated DR staging based on five public datasets with different staging criteria from various institutions to satisfy the real non-iid condition. The comprehensive experiments demonstrate that FedUAA provides outstanding DR staging performance with a high degree of reliability, outperforming other state-of-the-art FL approaches. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>Figure <ref type="figure" target="#fig_0">1</ref> (a) shows the overview of our proposed FedUAA. During training, local clients share the encoder (ϕ) to the cloud server for model aggregation, while the TWEU (ψ) head is retained locally to generate DR staging results with uncertainty evaluation based on features from the encoder to satisfy local-specific DR staging criteria. The algorithm of our proposed FedUAA is detailed in Supplementary A. Therefore, the target of our FedUAA is:</p><formula xml:id="formula_0">min ϕ∈Φ,ψ∈Ψ N i=1 £ (f i (ϕ i , ψ i |X i ) , Y i ) , (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where £ is the total loss for optimizing the model, f i is the model of i -th client, while X i and Y i are the input and label of i -th client. Different from previous personalized FL paradigms <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4]</ref>, our FedUAA dynamically adjusts the weights for model aggregation according to the reliability of each client, i.e., the client with larger distributional heterogeneity tends to have larger uncertainty distribution and should be assigned a larger weight for model aggregation to strengthen attention on the client with data heterogeneity. Besides, by introducing TWEU, our FedUAA can generate a reliable prediction with an estimated uncertainty, which makes the model more reliable without losing DR staging performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Temperature-Warmed Evidential Uncertainty Head</head><p>To make the model more reliable without sacrificing DR staging performance, we propose a novel temperature-warmed evidence uncertainty head (TWEU), which can directly generate DR staging results with uncertainty score based on the features from the encoder. The framework of TWEU is illustrated in Fig. <ref type="figure" target="#fig_0">1 (b</ref>). Specifically, we take one of the client models as an example and we assume that the staging criteria of this client is K categories. Correspondingly, given a color fundus image input, we can obtain its K +1 non-negative mass values, whose sum is 1. This can be defined as</p><formula xml:id="formula_2">K i=1 b i + u = 1</formula><p>, where b i ≥ 0 is the probability of i -th category, while u represent the overall uncertainty score. Specifically, as shown in Fig. <ref type="figure" target="#fig_0">1</ref> (b), a local fully connected layer (FC) is used to learn the local DR category-related features F V , and the Softplus activation function is adopted to obtain the evidence E = [e 1 , ..., e K ] of K staging categories based on F V , so as to ensure that its feature value is greater than 0. Then, E is re-parameterized by Dirichlet concentration <ref type="bibr" target="#b4">[5]</ref>, as: </p><formula xml:id="formula_3">α = E + 1, i.e, α k = e k + 1</formula><formula xml:id="formula_4">k = e k S = α k -1 S , u = K S , where S = K k=1 α k i,j</formula><p>is the Dirichlet intensities. Therefore, the probability assigned to category k is proportional to the observed evidence for category k. Conversely, if less total evidence is obtained, the greater the uncertainty score will be. As shown in Fig. <ref type="figure" target="#fig_0">1</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Uncertainty-Aware Weighting Module</head><p>Most existing FL paradigms aggregate model parameters by assigning a fixed weight to each client, resulting in limited performance on those clients with large heterogeneity in their data distributions. To address this issue, as shown in Fig. <ref type="figure" target="#fig_0">1</ref> (a), we propose a novel uncertainty-aware weighting (UAW) module that can dynamically adjust the weights for model aggregation based on the reliability of each client, which enables the model to better leverage the knowledge from different clients and further improve the DR staging performance. Specifically, at the end of a training epoch, each client-side model produces an uncertainty value distribution (U ), and the ground truth for incorrect prediction of U GT also can be calculated based on the final prediction P by,</p><formula xml:id="formula_5">u GT i = 1 -1 {P i , Y i } , where 1 {P i , Y i } = 1 if P i = Y i 0 otherwise , (<label>2</label></formula><formula xml:id="formula_6">)</formula><p>where P i and Y i are the final prediction result and ground truth of i -th sample in local dataset. Based on U and U GT , we can find the optimal uncertainty score θ, which can well reflect the reliability of the local client. To this end, we calculate the ROC curve between U and U GT , and obtain all possible sensitivity (Sens)</p><p>and specificity (Spes) values corresponding to each uncertainty score (u) used as a threshold. Then, Youden index (J) <ref type="bibr" target="#b6">[7]</ref> is adopted to obtain the optimal uncertainty score θ by:</p><formula xml:id="formula_7">θ = arg max u J (u) , with J (u) = Sens (u) + Spes (u) -1.<label>(3)</label></formula><p>More details about Youden index are given in Supplementary B. Finally, the optimal uncertainty scores Θ = [θ 1 , ..., θ N ] of all clients are sent to the server, and a Softmax function is introduced to normalize Θ to obtain the weights for model aggregation as w i = e θi / N i=1 e θi . Therefore, the weights for model aggregation are proportional to the optimal threshold of the client. Generally, local dataset with larger uncertainty distributions will have a higher optimal uncertainty score θ, indicating that it is necessary to improve the feature learning capacity of the client model to further enhance its confidence in the feature representation, and thus higher weights should be assigned during model aggregation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Loss Function</head><p>As shown in Fig. <ref type="figure" target="#fig_0">1</ref> (b), the loss function of client model is:</p><formula xml:id="formula_8">L = L Uce + L T ce ,<label>(4)</label></formula><p>where  <ref type="bibr" target="#b4">(5)</ref> where Φ(•) is the digamma function, while β (α) is the multinomial beta function for the Dirichlet concentration parameter α. Meanwhile, the KL divergence function is introduced to ensure that incorrect predictions will yield less evidence:</p><formula xml:id="formula_9">L</formula><formula xml:id="formula_10">L Ice = K k=1 -y k log (b k ) 1 β (α) K k=1 b α k -1 k db = K k=1 y k (Φ (S) -Φ (α k )) ,</formula><formula xml:id="formula_11">L KL = log ⎛ ⎝ Γ K k=1 (α k ) Γ (K) K k=1 Γ (α i ) ⎞ ⎠ + K k=1 (α k -1) Φ (α k ) -Φ K i=1 αk ,<label>(6)</label></formula><p>where Γ (•) is the gamma function, while α = y + (1y) α represents the adjusted parameters of the Dirichlet distribution which aims to avoid penalizing the evidence of the ground-truth class to 0. In summary, the loss function L Uce for the model optimization based on the features that were parameterized by Dirichlet concentration is as follows: where λ is the balance factor for L KL . To prevent the model from focusing too much on KL divergence in the initial stage of training, causing a lack of exploration for the parameter space, we initialize λ as 0 and increase it gradually to 1 with the number of training iterations. And, seen from Sect. 2.1, Dirichlet concentration alters the original feature distribution of F v , which may reduce the model's confidence in the category-related evidence features, thus potentially leading to a decrease in performance. Aiming at this problem, as shown in Fig. <ref type="figure" target="#fig_0">1</ref> (b), we introduce temperature coefficients to enhance confidence in the belief masses, and the loss function L T ce to guide the model optimization based on the temperature-warmed belief features b T is formalized as:</p><formula xml:id="formula_12">L Uce = L Ice + λ * L KL ,<label>(7)</label></formula><formula xml:id="formula_13">L T ce = - K i=1 y i log (b T i ) . (<label>8</label></formula><formula xml:id="formula_14">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results</head><p>Dataset and Implementation: We construct a database for federated DR staging based on 5 public datasets, including APTOS (3,662 samples)<ref type="foot" target="#foot_0">1</ref> , Messidor (1,200 samples) <ref type="bibr" target="#b5">[6]</ref>, DDR (13,673 samples) <ref type="bibr" target="#b19">[20]</ref>, KaggleDR (35,126 samples) (DRR)<ref type="foot" target="#foot_1">2</ref> , and IDRiD (516 samples) <ref type="bibr" target="#b25">[26]</ref>, where each dataset is regarded as a client, More details of datasets are given in Supplementary C.</p><p>We conduct experiments on the Pytorch with 3090 GPU. The SGD with a learning rate of 0.01 is utilized. The batch size is set to 32, the number of epochs is 100, and the temperature coefficient τ is empirically set to 0.05. To facilitate training, the images are resized to 256 × 256 before feeding to the model. Performance for DR Staging: Table <ref type="table" target="#tab_0">1</ref> shows the DR staging AUC for different FL paradigms on different clients. Our FedUAA achieves the highest AUC scores on all clients, with a 1.48% improvement in average AUC compared to FedBN <ref type="bibr" target="#b22">[23]</ref>, which achieved the highest average AUC score among the compared methods. Meanwhile, most FL based approaches achieve higher DR staging performance than SingleSet, suggesting that collaborative training across multiple institutions can improve the performance of DR staging with high data privacy security. Moreover, as shown in Table <ref type="table" target="#tab_0">1</ref>, FL paradigms such as FedDyn <ref type="bibr" target="#b0">[1]</ref> and SCAFFOLD <ref type="bibr" target="#b15">[16]</ref> exhibit limited performance in our collaborative DR staging task due to the varying staging criteria across different clients, as well as significant differences in label distribution and domain features. These results indicate that our FedUAA is more effective than other FL methods for collaborative DR staging tasks. Furthermore, although all FL methods achieve comparable performance on APTOS and DDR clients with distinct features, our FedUAA approach significantly improves performance on clients with small data volumes or large heterogeneity distribution, such as DRR, Messidor, and IDRiD, by 1.27%, 1.33%, and 1.29% over suboptimal results, respectively, which further demonstrates the effectiveness of our core idea of adaptively adjusting aggregation weights based on the reliability of each client. In addition, we also conduct experiments demonstrate the statistical significance of performance improvement. As shown in Supplementary D, most average p-values are smaller than 0.05. These experimental results further prove the effectiveness of our proposed FedUAA.</p><p>Reliability Analysis: Providing reliable evaluation for final predictions is crucial for AI models to be deployed in clinical practice. As illustrated in Fig. <ref type="figure" target="#fig_4">2 (b)</ref>, the model without introducing uncertainty (Backbone) assigns high probability values for incorrect staging results without any alert messages, which is also a significant cause of low user confidence in the deployment of AI models to medical practices. Interestingly, our FedUAA can evaluate the reliability of the final decision through the uncertainty score. For example, for the data with obvious features (Fig. <ref type="figure" target="#fig_4">2</ref> (a)), our FedUAA produces a correct prediction result with a low uncertainty score, indicating that the decision is reliable. Conversely, even if our FedUAA gives an incorrect decision for the data with ambiguous features (Fig. <ref type="figure" target="#fig_4">2 (b</ref>)), it can indicate that the diagnosis result may be unreliable by assigning a higher uncertainty score, thus suggesting that the subject should seek a double-check from an ophthalmologist to avoid mis-diagnosis. Furthermore, as shown in Fig. <ref type="figure" target="#fig_4">2</ref> (c), we degraded the quality of the input image by adding different levels of Gaussian noise σ 2 to further verify the robustness of FedUAA. Seen from Fig. <ref type="figure" target="#fig_4">2 (c</ref>), the performance of all methods decreases as the level of added noise increases, however, our FedUAA still maintains a higher performance than other comparison methods, demonstrating the robustness of our FedUAA.</p><p>Ablation Study: We also conduct ablation experiments to verify the effectiveness of the components in our FedUAA. In this paper, the pre-trained ResNet50 <ref type="bibr" target="#b12">[13]</ref> is adopted as our backbone (BC) for SingleSet DR staging, while employing FedBN <ref type="bibr" target="#b22">[23]</ref> as the FL BC. Furthermore, most ensemble-based <ref type="bibr" target="#b16">[17]</ref> and MC-dropout-based <ref type="bibr" target="#b7">[8]</ref> uncertainty methods are challenging to extend to our federated DR staging task across multiple institutions with different staging criteria. Therefore, we compare our proposed method with the commonly used evidential based uncertainty approach (EU (L Uce )) <ref type="bibr" target="#b11">[12]</ref>.</p><p>For training model with SingleSet, as shown in Table <ref type="table" target="#tab_1">2</ref>, since Dirichlet concentration alters the original feature distribution of the backbone <ref type="bibr" target="#b11">[12]</ref>, resulting in a decrease in the model's confidence in category-related evidence, consequently, a decrease in performance when directly introducing EU (BC+EU (L Uce )) for DR staging. In contrast, our proposed BC+TWEU (L Uce +L T ce ) achieves superior performance compared to BC and BC+EU (L Uce ), demonstrating that TWEU (L Uce +L T ce ) enables the model to generate a reliable final decision without sacrificing performance. For training model with FL, as shown in Table <ref type="table" target="#tab_1">2</ref>, BC+FL outperforms SingleSet, indicating that introducing FL can effectively improve the performance for DR staging while maintaining high data privacy security. Besides, FL+EU (L Uce ) and FL+TWEU (L Uce +L T ce ) also obtain a similar conclusion as in SingleSet, further proving the effectiveness of TWEU. Meanwhile, the performance of our FedUAA (FL+TWEU (L Uce +L T ce )+UAW) achieves higher performance than FL+TWEU (L Uce +L T ce ) and FL backbone, especially for clients with large data distribution heterogeneity such as DRR, Messidor, and IDRiD. These results show that our proposed UAW can further improve the performance of FL in collaborative DR staging tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, focusing on the challenges in the collaborative DR staging between institutions with different DR staging criteria, we propose a novel FedUAA by combining the FL with evidential uncertainty theory. Compared to other FL methods, our FedUAA can produce reliable and robust DR staging results with uncertainty evaluation, and further enhance the collaborative DR staging performance by dynamically aggregating knowledge from different clients based on their reliability. Comprehensive experimental results show that our FedUAA addresses the challenges in collaborative DR staging across multiple institutions, and achieves a robust and reliable DR staging performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The overview of FedUAA (a) with TWEU module (b). An aggregated encoder is shared by all clients for learning a global representation of fundus images, while a novel TWEU head is kept on the local client for local personalized staging criteria. Furthermore, a novel UAW module is developed to dynamically adjust the weights for model aggregation based on the reliability of each client.</figDesc><graphic coords="3,56,31,54,14,311,38,154,57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>where α k and e k are the k -th category Dirichlet distribution parameters and evidence, respectively. Further calculating the belief masses (b) and corresponding uncertainty score (u) by b</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(b), L Uce is used to guide the model optimization based on the belief masses (b) and their corresponding uncertainty score (u). Finally, temperature coefficients τ is introduced to further enhance the classifier's confidence in belief masses, i.e., b T i = e (b i /τ ) K i=1 e (b i /τ ) , where b T = [b T 1 , ..., b T k ] is the belief masses that were temperature-warmed. As shown in Fig. 1 (b), L T ce is adopted to guide the model optimization based on the temperature-warmed belief features of b T .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Uce is adopted to guide the model optimization based on the features (b and u) which were parameterized by Dirichlet concentration. Given the evidence of E = [e 1 , ..., e k ], we can obtain Dirichlet distribution parameter α = E + 1, category related belief mass b = [b 1 , ..., b k ] and uncertainty score of u. Therefore, the original cross-entropy loss is improved as,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. (a) Instance of being correctly predicted (b) Sample with incorrect prediction result (c) Average AUC of different methods with increasing noise levels (σ 2 ).</figDesc><graphic coords="7,41,79,54,05,340,33,113,65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>AUC results for different FL methods applied to DR staging.</figDesc><table><row><cell>Methods</cell><cell>APTOS DDR</cell><cell>DRR</cell><cell cols="2">Messidor IDRiD Average</cell></row><row><cell>SingleSet</cell><cell cols="3">0.9059 0.8776 0.8072 0.7242</cell><cell>0.7168 0.8063</cell></row><row><cell>FedRep [4]</cell><cell cols="3">0.9372 0.8964 0.8095 0.7843</cell><cell>0.8047 0.8464</cell></row><row><cell>FedBN [23]</cell><cell cols="3">0.9335 0.9003 0.8274 0.7792</cell><cell>0.8193 0.8519</cell></row><row><cell>FedProx [22]</cell><cell cols="3">0.9418 0.8950 0.8127 0.7877</cell><cell>0.8049 0.8484</cell></row><row><cell>FedDyn [1]</cell><cell cols="3">0.9352 0.8778 0.8022 0.7264</cell><cell>0.5996 0.7882</cell></row><row><cell cols="4">SCAFFOLD [16] 0.9326 0.8590 0.7251 0.7288</cell><cell>0.6619 0.7815</cell></row><row><cell>FedDC [9]</cell><cell cols="3">0.9358 0.8858 0.7969 0.7390</cell><cell>0.7581 0.8236</cell></row><row><cell>Moon [18]</cell><cell cols="3">0.9436 0.8995 0.8117 0.7907</cell><cell>0.8115 0.8514</cell></row><row><cell>MDT [28]</cell><cell cols="3">0.9326 0.8908 0.7987 0.7919</cell><cell>0.7965 0.8421</cell></row><row><cell>Proposed</cell><cell cols="4">0.9445 0.9044 0.8379 0.8012 0.8299 0.8636</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>AUC results for different FL paradigms applied to DR staging.</figDesc><table><row><cell cols="5">Strategy BC EU TWEU UAW APTOS DDR</cell><cell>DRR</cell><cell>Messidor IDRiD Average</cell></row><row><cell cols="2">SingleSet ✓ ✗</cell><cell>✗</cell><cell>✗</cell><cell cols="3">0.9059 0.8776 0.8072 0.7242</cell><cell>0.7168 0.8063</cell></row><row><cell></cell><cell cols="2">✓ ✓ ✗</cell><cell>✗</cell><cell cols="3">0.9286 0.8589 0.8001 0.7404</cell><cell>0.6928 0.8042</cell></row><row><cell></cell><cell>✓ ✗</cell><cell>✓</cell><cell>✗</cell><cell cols="3">0.9414 0.8912 0.8279 0.7309</cell><cell>0.7616 0.8306</cell></row><row><cell>FL</cell><cell>✓ ✗</cell><cell>✗</cell><cell>✗</cell><cell cols="3">0.9335 0.9003 0.8274 0.7792</cell><cell>0.8193 0.8519</cell></row><row><cell></cell><cell cols="2">✓ ✓ ✗</cell><cell>✗</cell><cell cols="3">0.9330 0.8572 0.7938 0.7860</cell><cell>0.7783 0.8297</cell></row><row><cell></cell><cell>✓ ✗</cell><cell>✓</cell><cell>✗</cell><cell cols="3">0.9445 0.8998 0.8229 0.8002</cell><cell>0.8231 0.8581</cell></row><row><cell></cell><cell>✓ ✗</cell><cell>✓</cell><cell>✓</cell><cell cols="3">0.9445 0.9044 0.8379 0.8012 0.8299 0.8636</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://www.kaggle.com/datasets/mariaherrerot/aptos2019.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://www.kaggle.com/competitions/diabetic-retinopathy-detection.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This work was supported by the <rs type="funder">National Research Foundation, Singapore</rs> under its <rs type="programName">AI Singapore Programme (AISG Award</rs> No: <rs type="grantNumber">AISG2-TC-2021-003</rs>), the <rs type="funder">Agency for Science, Technology and Research (A*STAR)</rs> through its <rs type="programName">AME Programmatic Funding Scheme Under Project A20H4b0141</rs>, <rs type="funder">A*STAR Central Research Fund "A Secure and Privacy Preserving AI Platform for Digital Health", and A*STAR Career Development Fund</rs> (<rs type="grantNumber">C222812010</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_DMhY9YC">
					<idno type="grant-number">AISG2-TC-2021-003</idno>
					<orgName type="program" subtype="full">AI Singapore Programme (AISG Award</orgName>
				</org>
				<org type="funding" xml:id="_QxWHPYU">
					<orgName type="program" subtype="full">AME Programmatic Funding Scheme Under Project A20H4b0141</orgName>
				</org>
				<org type="funding" xml:id="_VvYJTSr">
					<idno type="grant-number">C222812010</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43895-0_21.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A E</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mattina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Whatmough</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Saligrama</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.04263</idno>
		<title level="m">Federated learning based on dynamic regularization</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Arivazhagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Choudhary</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.00818</idno>
		<title level="m">Federated learning with personalization layers</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deep learning based computeraided diagnosis systems for diabetic retinopathy: a survey</title>
		<author>
			<persName><forename type="first">N</forename><surname>Asiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Al Adel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Alzaidi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell. Med</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page">101701</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Exploiting shared representations for personalized federated learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hassani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mokhtari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shakkottai</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2089" to="2099" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Concepts of independence for proportions with a generalization of the dirichlet distribution</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Mosimann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">325</biblScope>
			<biblScope unit="page" from="194" to="206" />
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Feedback on a publicly distributed image database: the Messidor database</title>
		<author>
			<persName><forename type="first">E</forename><surname>Decencière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cazuguel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Anal. Stereol</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="231" to="234" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Estimation of the Youden Index and its associated cutoff point</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fluss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Faraggi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Reiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrical J.: J. Math. Methods Biosci</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="458" to="472" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Dropout as a Bayesian approximation: representing model uncertainty in deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1050" to="1059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">FEDDC: federated learning with non-IID data via local drift decoupling and correction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Z</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="10112" to="10121" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs</title>
		<author>
			<persName><forename type="first">V</forename><surname>Gulshan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Coram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMA</title>
		<imprint>
			<biblScope unit="volume">316</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page">2402</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Artificial intelligence for diabetic retinopathy screening, prediction and management</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">V</forename><surname>Gunasekeran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Ting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Y</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Opin. Ophthalmol</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="357" to="365" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.02051</idno>
		<title level="m">Trusted multi-view classification</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Evidence fusion with contextual discounting for multi-modality medical image segmentation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Denoeux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ruan</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16443-9_39</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16443-9_39" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13435</biblScope>
			<biblScope unit="page" from="401" to="411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Advances and open problems in federated learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kairouz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Avent</surname></persName>
		</author>
		<idno type="DOI">10.1561/2200000083</idno>
		<ptr target="https://doi.org/10.1561/2200000083" />
	</analytic>
	<monogr>
		<title level="j">Found. Trends R Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="1" to="210" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Scaffold: stochastic controlled averaging for federated learning</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Karimireddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Reddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Stich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Suresh</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5132" to="5143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Simple and scalable predictive uncertainty estimation using deep ensembles</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Model-contrastive federated learning</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="10713" to="10722" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Applications of deep learning in fundus images: a review</title>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page">101971</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Diagnostic assessment of deep learning algorithms for diabetic retinopathy screening</title>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">501</biblScope>
			<biblScope unit="page" from="511" to="522" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Federated learning: challenges, methods, and future directions</title>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Sahu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Talwalkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Mag</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="50" to="60" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Federated optimization in heterogeneous networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Sahu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sanjabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Talwalkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Mach. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="429" to="450" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">FEDBN: federated learning on non-IID features via local batch normalization</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.07623</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Communication-efficient learning of deep networks from decentralized data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hampson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Arcas</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Statistics</title>
		<imprint>
			<biblScope unit="page" from="1273" to="1282" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Federated learning in ocular imaging: current progress and future direction</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">X</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Diagnostics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">2835</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Indian diabetic retinopathy image dataset (IDRID): a database for diabetic retinopathy screening research</title>
		<author>
			<persName><forename type="first">P</forename><surname>Porwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">25</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Development and validation of a deep learning system for diabetic retinopathy and related eye diseases using retinal images from multiethnic populations with diabetes</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S W</forename><surname>Ting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y L</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMA</title>
		<imprint>
			<biblScope unit="volume">318</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page">2211</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Robust calibration with multi-domain temperature scaling</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural. Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="27510" to="27523" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Delving into local features for open-set domain adaptation in fundus image analysis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16449-1_65</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16449-1_65" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13437</biblScope>
			<biblScope unit="page" from="682" to="692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">TBraTS: trusted brain tumor segmentation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16452-1_48</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16452-1_48" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13438</biblScope>
			<biblScope unit="page" from="503" to="513" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
