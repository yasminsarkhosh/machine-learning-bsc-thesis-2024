<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Client-Level Differential Privacy via Adaptive Intermediary in Federated Medical Imaging</title>
				<funder ref="#_mWBbTAf">
					<orgName type="full">Hong Kong Innovation and Technology Commission</orgName>
				</funder>
				<funder ref="#_kJ9rGdY">
					<orgName type="full">NSERC</orgName>
				</funder>
				<funder ref="#_p9zxszZ">
					<orgName type="full">Hong Kong Research Grants Council</orgName>
				</funder>
				<funder ref="#_BQrdksW">
					<orgName type="full">Science, Technology and Innovation Commission of Shenzhen Municipality</orgName>
				</funder>
				<funder>
					<orgName type="full">Shenzhen Portion of Shenzhen-Hong Kong Science and Technology Innovation Cooperation Zone</orgName>
				</funder>
				<funder ref="#_FXX2Jvt">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Meirui</forename><surname>Jiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuan</forename><surname>Zhong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anjie</forename><surname>Le</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaoxiao</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">The University of British Columbia</orgName>
								<address>
									<settlement>Vancouver</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Qi</forename><surname>Dou</surname></persName>
							<email>qidou@cuhk.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Client-Level Differential Privacy via Adaptive Intermediary in Federated Medical Imaging</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="500" to="510"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">540F6DC06C86FA8F3AE23A8A18C366BD</idno>
					<idno type="DOI">10.1007/978-3-031-43895-0_47</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-13T19:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Federated Learning</term>
					<term>Client-level Differential Privacy</term>
					<term>Medical Image Analysis</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Despite recent progress in enhancing the privacy of federated learning (FL) via differential privacy (DP), the trade-off of DP between privacy protection and performance is still underexplored for real-world medical scenario. In this paper, we propose to optimize the trade-off under the context of client-level DP, which focuses on privacy during communications. However, FL for medical imaging involves typically much fewer participants (hospitals) than other domains (e.g., mobile devices), thus ensuring clients be differentially private is much more challenging. To tackle this problem, we propose an adaptive intermediary strategy to improve performance without harming privacy. Specifically, we theoretically find splitting clients into sub-clients, which serve as intermediaries between hospitals and the server, can mitigate the noises introduced by DP without harming privacy. Our proposed approach is empirically evaluated on both classification and segmentation tasks using two public datasets, and its effectiveness is demonstrated with significant performance improvements and comprehensive analytical studies. Code is available at: https://github.com/med-air/Client-DP-FL.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Differential privacy (DP) has emerged as a promising technique to safeguard the privacy of sensitive data in federated learning (FL) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b33">34]</ref>, offering privacy guarantees in a mathematical format <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b32">33]</ref>. However, introducing noise to ensure DP often comes at the cost of performance. Some recent studies have noticed that the noise added to the gradient impedes optimization <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b26">27]</ref>.</p><p>For critical medical applications requiring low error tolerance, such performance degradation makes the rigorous privacy guarantee diminish <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b21">22]</ref>. Therefore, it is imperative to maintain high performance while enhancing privacy, i.e., optimizing the privacy-performance trade-off. Unfortunately, despite its significance, such trade-off optimization in FL has not been sufficiently investigated to date.</p><p>Several studies have examined the trade-off in the centralized scenario. For instance, Li et al. <ref type="bibr" target="#b17">[18]</ref> proposed enhancing utility by leveraging public data or data statistics to estimate gradient geometry. Amid et al. <ref type="bibr" target="#b2">[3]</ref> utilized the loss on public data as a mirror map to improve performance. Li et al. <ref type="bibr" target="#b16">[17]</ref> suggested constructing less noisy preconditioners using historical gradients. In contrast to these studies, we concentrate on promoting the trade-off in FL, where public dataset is limited and sharing side information may not be feasible <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b28">29]</ref>. Specifically, we aim to ensure that clients are differentially private. Our objective is not to protect a single data point, but rather to achieve that a learned model does not reveal whether a client participated in decentralized training. This ensures that a client's entire dataset is safeguarded against differential attacks from third parties. This is particularly crucial in medical imaging, where sensitive patient information is typically kept within each hospital. Nevertheless, in medical imaging, the number of participants (silos) is usually much smaller than in other domains, such as mobile devices <ref type="bibr" target="#b11">[12]</ref>. This cross-silo situation necessitates adding a considerable amount of noise to protect client privacy, making the optimization of the trade-off uniquely challenging <ref type="bibr" target="#b19">[20]</ref>.</p><p>To improve the trade-off of privacy protection and performance, the key point is to mitigate the noise added to the client during gradient updates. Our idea is inspired by the observation in DP-FedAvg <ref type="bibr" target="#b23">[24]</ref>, which suggests that the utility of DP can be improved by utilizing a sufficiently large dataset with numerous users. Through an analysis of the DP accountant, we identified that the noise is closely related to the gradient clip bound and the number of participants. In this regard, we propose to split the original client into disjoint sub-clients, which act as intermediaries for exchanging information between the hospital and the server. This strategy increases the number of client updates against queries, thereby consequently reducing the magnitude of noise. However, finding an optimal splitting is not straightforward due to the non-identical nature of data samples. Splitting a client into more sub-clients may increase the diversity of FL training, which can adversely harm the final performance. Thus, there is a trade-off between noise level and training diversity. Our objective is to explore the relationships among clients, noise effects, and training diversities to identify a balance point that maximizes the trade-off between privacy and performance.</p><p>In this paper, we present a novel adaptive intermediary method to optimize the privacy-performance trade-off. Our approach is based on the interplay relationships among noise levels, training diversities, and the number of clients. Specifically, we observe a reciprocal correlation between the noise level and the number of intermediaries, as well as a linear correlation between the training diversity and the intermediary number. To determine the optimal number of intermediaries, we introduce a new term called intermediary ratio, which quantifies the ratio of noise level and training diversity. Our theoretical analysis demonstrates that splitting the original clients into more intermediaries achieves DP with the same privacy budget and DP failure probability. Furthermore, we show that when sample-level DP and client-level DP have equivalent noise levels, the variance of the difference between noisy and original model diverges exponentially with more training steps, leading to poor performance. We evaluate our method on both classification and segmentation tasks, including the intracranial hemorrhage diagnosis with 25,000 CT slices, and the prostate MRI segmentation with heterogeneous data from different hospitals. Our method consistently outperforms various DP optimization methods on both tasks and can serve as a lightweight add-on with good compatibility. In addition, we conduct comprehensive analytical studies to demonstrate the effectiveness of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Preliminaries</head><p>In this work, we consider client-level differential privacy. We first introduce the definition of DP as follows: Definition 1. (( , δ)-Differential Privacy <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>) For a randomized learning mechanism M : X → R, where X is the collection of datasets it can be trained on, and Y is the collection of model it can generate, it is ( , δ)-DP if:</p><formula xml:id="formula_0">(∀S ⊆ R)(∀D, D ∈ X , D ∼ D ) Pr[M (D) ∈ S] ≤ exp(ε) • Pr [M (D ) ∈ S] + δ,</formula><p>where denotes the privacy budget, and δ represents the probability that -DP fails in this mechanism. Note that the smaller the value is, the more private the mechanism is. Our aim of applying DP is to protect the collection of "datasets" X , which are client model updates in every communication round in the context of FL. The protection can be done by incorporating a DP-preserving randomization mechanism into the learning process. One commonly used method is the Gaussian mechanism, which involves bounding the contribution (l 2 -norm) of each client update followed by adding Gaussian noise proportional to that bound onto the aggregate <ref type="bibr" target="#b23">[24]</ref>. Specifically, suppose there are N clients, denote the gradients of each client as Δ i , the server model θ t+1 at round t+1 is updated by adding the Gaussian mechanism approximating the sum of updates as follows:</p><formula xml:id="formula_1">θ t+1 ← θ t + 1 N i∈[N ] Δ i / max( Δ i 2 C , 1) + N (0, z 2 C 2 I) , (<label>1</label></formula><formula xml:id="formula_2">)</formula><p>where C is the gradient clipping threshold, and z is the noise multiplier determined by the privacy accountant with given , δ, and training steps. The noise multiplier z indicates the amount of noise required to reach a particular privacy budget. To privatize the participation of clients in FL, the noise added for client-level DP typically correlates with the number of clients. This incurs a large magnitude of noise in cross-silo FL in the medical field, which can significantly deteriorate the final server model performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Adaptive Intermediary for Improving Client-Level DP</head><p>The key to optimizing the privacy-performance trade-off lies in mitigating the effects of noise without compromising privacy protection. Based on the noise calculation in Eq. ( <ref type="formula" target="#formula_1">1</ref>), we propose to study the final effects of noise on the server model, which can be denoted as ζ ∼ N (0, σ 2 I), where σ = zC /N. Note that the final noise (ζ) is determined by σ, which relates to the noise multiplier z, clip threshold C, and the number of clients N . In DP, the clip threshold and the noise multiplier are usually pre-assigned. Therefore, the noise level can be reduced by increasing the number of clients N . To this end, we propose to reduce the noise by splitting the original clients into non-overlapping sub-clients, which serve as intermediaries to communicate with the server (see Fig. <ref type="figure" target="#fig_0">1 (a)</ref>). We validate our hypothesis by studying the feasibility and analyzing the relationships between the intermediary number, noise, and performance.</p><p>Feasibility. We demonstrate the feasibility by showing the use of intermediary preserves privacy. For X the collection of possible datasets from extant clients, denote D i ∈ X the dataset of client i, we randomly split D i into v disjoint subsets D i,1 , ..., D i,v , so that j D i,j = D i . We define the dataset D i,j of client i as the intermediary j. Then we show that partitioning extant clients into multiple intermediaries is capable of maintaining DP. Denote the collection of all possible datasets formed by the intermediaries as Y, and note that X ⊆ Y. We have:</p><formula xml:id="formula_3">Theorem 1. If a randomized learning mechanism M : X → R is ( , δ) -DP , then its induced mechanism M : Y → R is also ( , δ)-DP.</formula><p>This indicates that partitioning the original client into intermediaries keeps the same DP regime. The proof can be found in Appendix C. We also analyze the reverse relation in the appendix section to complete the overall relationship.</p><p>Privacy-Performance Trade-Off Analysis. With the above basis, we further investigate the privacy-performance trade-off by varying the number of intermediaries. According to the noise calculation of σ = zC /N, we can reduce noise by splitting clients into intermediaries to increase N . However, increasing the number of intermediaries causes each intermediary to hold fewer samples. This may affect the aggregation direction and harms final performance consequently.</p><p>There is a trade-off behind intermediary splitting. To investigate the trade-off, we design and study two highly related metrics, i.e., noise level ξ and client update diversity level ϕ. Denoting clipped gradients as Δi , we define the noise level and diversity level as:</p><formula xml:id="formula_4">ξ = ζ i∈N Δi 2 , ϕ = i∈N Δ i 2 i∈N Δi 2 . (<label>2</label></formula><formula xml:id="formula_5">)</formula><p>By varying the number of intermediaries, we obtain different values for noise levels and diversities (see Fig. <ref type="figure" target="#fig_0">1 (b)</ref>). By fitting the relations between noise level (client update diversity) and the number of intermediaries for each client (denoted as v), we surprisingly find the relations that:</p><formula xml:id="formula_6">ξ v = v -1 • ξ, ϕ v = v • ϕ,<label>(3)</label></formula><p>where ξ v and ϕ v denote the value when each client is split into v intermediaries. By defining the intermediary ratio as λ = ξ /ϕ, we can use this ratio to quantify the relations between noise level and diversity, which helps identify the optimal number of intermediaries to generate.</p><p>Adaptive Intermediary Generation. We can generate the intermediary based on the defined intermediary ratio λ. We experimentally investigated the relationships between the final performance and the number of intermediaries and found the optimal ratio lies in the range of 1 /N. Therefore, for each client, the number of intermediaries is v = 2 N • ξ /ϕ. Considering the extreme case of lim N →∞ ξ = 0, we can also infer the ratio λ = 0, which further validates the rationality and consistency with our empirical findings. For the practical application, we can initialize the number of intermediaries via the first round results. Then, for each round, we will re-calculate the ratio using ξ and ϕ from the last round, and then adaptively split clients to make sure the new ratio lies around 1 /N.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Cumulation of Sample-Level DP to Client-Level</head><p>We further investigate the relationships between client-level DP and sample-level DP, by cumulating sample-level DP mechanism to a client level. In DP-SGD <ref type="bibr" target="#b0">[1]</ref>, denote the standard deviation of Gaussian noise as σ = z( , δ)c/K with K being the batch size, c being the sample-level gradient clip bound and z being the noise multiplier determined by privacy accountant with ( , δ). Noise is added to each batch gradient before taking a descent, so that each step is ( , δ)-DP.</p><p>Note that z can take different forms, the form provided by moment accountant <ref type="bibr" target="#b0">[1]</ref> is z( , δ) = O( ln(1/δ)/ 2 ). Through the use of the moment accountant and sensitivity cumulation, we can calculate the standard deviation of cumulated noise in T steps as  <ref type="figure">T</ref> ). With regards to performance, we prove in Appendix C that the variance of the difference between the noisy model and the original model diverges with a rate of O((1 -2ηβ + η 2 μ 2 ) T ) for μ-convex, β-smooth loss functions. This shows that increasing T also increases the probability of obtaining a model which diverges further from the original model, resulting in poorer performance.</p><p>On the Client-Level. For client-level noise, we can compute the standard deviation as σ c = z( c , δ c )C, where C is the clip bound of client update. The clip bound is typically set to the median among l2-norms of all client updates. Assuming an identical distribution across clients and samples, we have C = O(T c). As a result, we have z c = O(z T ), indicating that the cumulation of sample-level noise in DP-SGD gives the same DP level up to a constant, which is equivalent to adding noise directly to the client level through the moment accountant. Regarding the performance, we note that by leveraging the noisy models from several clients that hold identically distributed datasets, we can reduce the probability of getting a significantly drifted model without additional privacy leakage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Setup</head><p>Datasets. We evaluate our method on two tasks: 1) intracranial hemorrhage (ICH) classification, and 2) prostate MRI segmentation. For ICH classification, we use the RSNA-ICH dataset <ref type="bibr" target="#b8">[9]</ref> and follow <ref type="bibr" target="#b14">[15]</ref> to relieve the class imbalance across ICH subtypes and perform the binary diseased-or-healthy classification. We randomly sample 25,000 slices and split them into 20 clients, where each client data is split into 60%, 20%, and 20% for training, validation, and testing. We resize images to 224 × 224 and perform data augmentation with random affine and horizontal flip. For prostate segmentation, we adopt a multi-site T2weighted MRI dataset <ref type="bibr" target="#b20">[21]</ref> which contains 6 different data sources from 3 public datasets <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b25">26]</ref>. We regard each data source as one client, resize images to 256 × 256, and use 50%, 25%, and 25% for for training, validation and testing.</p><p>Table <ref type="table">1</ref>. Performance comparison of different DP optimization methods and ours. We report mean and standard deviation across three independent runs with different seeds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Intracranial Hemorrhage Diagnosis (N = 20)</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>No Privacy z = 0.5 z = 1.0 z = 1.5 Privacy Setup. We use the Opacus' <ref type="bibr" target="#b31">[32]</ref> implementation of privacy loss random variables (PRVs) accountant <ref type="bibr" target="#b9">[10]</ref> for the Gaussian mechanism for our privacy accounting. We restrict the total number of training rounds and then account for any privacy overheads with various privacy levels controlled by the noise multiplier z, where a higher z indicates a higher privacy regime . Adaptive clipping <ref type="bibr" target="#b3">[4]</ref> is employed to bound each client's contribution in the federation. Following <ref type="bibr" target="#b32">[33]</ref>, we report the results by exploring effects of different noise multiplier z values. We set z in the range of {0.  -k where k is the smallest integer that satisfies 10 -k ≤ 1/n for the client number n as suggested by <ref type="bibr" target="#b16">[17]</ref>.</p><formula xml:id="formula_7">AUC ↑ Acc ↑ AUC ↑ Acc ↑ AUC ↑ Acc ↑ AUC ↑ Acc ↑ DP-</formula><p>Implementation Details. We use Adam optimize, set the local update epoch to 1, and set total communication rounds to 100. We use DenseNet121 <ref type="bibr" target="#b10">[11]</ref> for classification, the batch size is 16 and the learning rate is 3 × 10 -4 . We use UNet <ref type="bibr" target="#b29">[30]</ref> for segmentation, the batch size of 8, and the learning rate is 10 -3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Empirical Evaluation</head><p>First, we present experimental results using different global optimizers on the server with client-level DP. Then, we demonstrate how our adaptive intermedi-ary strategy benefits privacy-performance trade-offs. We consider four popular private server optimizers: DP-FedAvg <ref type="bibr" target="#b23">[24]</ref> which adds client-level privacy protection to FedAvg <ref type="bibr" target="#b22">[23]</ref>, DP-FedAdam which is a differentially private version of the optimizer FedAdam <ref type="bibr" target="#b27">[28]</ref>, DP-FedNova which we equip the global solver FedNova <ref type="bibr" target="#b30">[31]</ref> for client-level DP, and DP 2 -RMSProp <ref type="bibr" target="#b16">[17]</ref> which is a very recent private optimization framework and we deploy it as the global optimizer in FL.</p><p>We perform validation with different noise multiplier values. Non-private FL is also provided as a performance upper bound. Note that our method has the same performance ascompared methods in non-private settings, because there are no noises to harmonize. As can be observed from Table <ref type="table">1</ref>, severe performance degradation occurs in the private cross-silo FL setting, especially for high-privacy regimes (e.g., z = 0.7 for prostate segmentation). There are no significant differences among different global optimizers, which shows that the optimizers carefully designed for non-private FL are unable to address the noisy gradient issue in DP settings. However, our method relieves the gradient corruption and consistently and substantially boosts performance even with large noises (e.g., 44.55% Dice boost on prostate segmentation with z = 0.7). We also identify that the influences on performance introduced by DP may vary across different tasks and client numbers. For example, the segmentation task with fewer clients is more seriously damaged compared with the classification task with more clients. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Analytical Studies</head><p>Effects of Optimizing Privacy-Performance Trade-Offs. We present the dynamic behavior of our method regarding variations of the intermediary ratio λ across different rounds in Fig. <ref type="figure" target="#fig_2">2 (a)</ref>. Compared with DP-FedAvg <ref type="bibr" target="#b23">[24]</ref>, where λ shows a significant increase with the rise of noise multiplier z, our method harmonizes this trend with more centralized distributions by the adaptive intermediary for better privacy-performance trade-offs. In Fig. <ref type="figure" target="#fig_2">2 (b)</ref>, we also study the standard deviation of similarities, which is another metric for quantifying gradient diversity between local and global gradients. Our method shows more stable optimization directions with less variance among clients. Moreover, we observe a decline in gradient diversities as the privacy regime rises for DP-FedAvg <ref type="bibr" target="#b23">[24]</ref>. To interpret, we speculate that local optimization may be dominated by greater noises for more common gradient de-corruption.</p><p>Client Scalability Analysis. As the noise level is highly dependent on client numbers (see Eq. ( <ref type="formula" target="#formula_1">1</ref>) and Table <ref type="table">1</ref>), we investigate the scalability of DP-FedAvg <ref type="bibr" target="#b23">[24]</ref> and our method by varying number of clients. Figure <ref type="figure" target="#fig_2">2 (c</ref>) presents the results on prostate segmentation with different training clients (z = 0.3). Notably, we keep test data unchanged for fair comparisons. We observe a dramatic drop in performance of DP-FedAvg <ref type="bibr" target="#b23">[24]</ref> due to excessive noise when the number of clients shrinks. However, our method performs stably even under extreme conditions, e.g., the federation only has two participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stability of Adaptive Intermediary</head><p>Estimation. Finally, we analyze the historical variation of our adaptive intermediary strategy in Fig. <ref type="figure" target="#fig_2">2 (d)</ref>, where we present the intermediary numbers during the training progress. We expect that more intermediaries are required to balance the privacy-performance trade-off with a greater noise multiplier z. Besides, we verify the reliability and stability of our adaptive intermediary estimation by showing that the variation during the training does not exceed one, except for a single instance when z = 0.7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we propose a novel adaptive intermediary method to promote privacy-performance trade-offs in the context of client-level DP in FL. We have comprehensively studied the relations among number of intermediaries, noise levels and training diversities in our work. We also investigate relations between sample-level and client-level DP. Our proposed method outperforms compared methods on both medical image diagnosis and segmentation tasks and shows good compatibility with existing DP optimizers. For future work, it is promising to investigate our method for clients with imbalanced class distributions, where the intermediary may not have all labels.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. (a) Overview of our intermediary strategy, which protects participating hospitals with superior privacy-performance trade-offs. The server aggregates local models from non-overlapping intermediaries with DP guarantees. (b) Continuously splitting intermediaries may not continuously improve performance, as it reduces gradient noises in a reciprocal manner, but also increases gradient diversity or heterogeneity linearly.</figDesc><graphic coords="3,48,30,53,87,327,52,91,63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>σ T = z ( T , δ T )S T , where T = O( √ T ), δ T = O(δ), and S T = O(T c). It follows that z = O(1/ T ) = O(z/ √ T ), and σ s = O( √ T σ s ). This indicates that the noise scale cumulates at a rate of O( √</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Analytical studies on prostate segmentation. (a) The distribution of normalized ratio λ across communication rounds under different privacy levels. (b) The std of cosine similarities between Δi and the aggregated gradients in each round under different privacy levels. (c) Performance with different client numbers. (d) Intermediary variations across training rounds under different privacy regimes.</figDesc><graphic coords="8,56,97,315,44,338,68,94,99" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement. This work was supported in part by <rs type="funder">Shenzhen Portion of Shenzhen-Hong Kong Science and Technology Innovation Cooperation Zone</rs> under HZQB-KCZYB-20200089, in part by <rs type="funder">National Natural Science Foundation of China</rs> (Project No. <rs type="grantNumber">62201485</rs>), in part by <rs type="funder">Hong Kong Innovation and Technology Commission</rs> Project No. <rs type="grantNumber">ITS/238/21</rs>, in part by <rs type="funder">Science, Technology and Innovation Commission of Shenzhen Municipality</rs> Project No. <rs type="grantNumber">SGDX20220530111201008</rs>, in part by <rs type="funder">Hong Kong Research Grants Council</rs> Project No. <rs type="grantNumber">T45-401/22</rs>-N, and in part by <rs type="funder">NSERC</rs> <rs type="grantName">Discovery Grant</rs> (<rs type="grantNumber">DGECR-2022-00430</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_FXX2Jvt">
					<idno type="grant-number">62201485</idno>
				</org>
				<org type="funding" xml:id="_mWBbTAf">
					<idno type="grant-number">ITS/238/21</idno>
				</org>
				<org type="funding" xml:id="_BQrdksW">
					<idno type="grant-number">SGDX20220530111201008</idno>
				</org>
				<org type="funding" xml:id="_p9zxszZ">
					<idno type="grant-number">T45-401/22</idno>
				</org>
				<org type="funding" xml:id="_kJ9rGdY">
					<idno type="grant-number">DGECR-2022-00430</idno>
					<orgName type="grant-name">Discovery Grant</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep learning with differential privacy</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Computer and Communications Security</title>
		<meeting>the 2016 Conference on Computer and Communications Security</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Federated learning and differential privacy for medical image analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Adnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kalra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Cresswell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1953</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Public data-assisted mirror descent for private model training</title>
		<author>
			<persName><forename type="first">E</forename><surname>Amid</surname></persName>
		</author>
		<idno>PMLR</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="517" to="535" />
		</imprint>
		<respStmt>
			<orgName>ICML</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Differentially private learning with adaptive clipping</title>
		<author>
			<persName><forename type="first">G</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Thakkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ramaswamy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="17455" to="17466" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Federated learning for predicting clinical outcomes in patients with COVID-19</title>
		<author>
			<persName><forename type="first">I</forename><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1735" to="1743" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Unlocking high-accuracy differentially private image classification through scale</title>
		<author>
			<persName><forename type="first">S</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Berrada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hayes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.13650</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Calibrating noise to sensitivity in private data analysis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nissim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1007/11681878_14</idno>
		<ptr target="https://doi.org/10.1007/11681878_14" />
	</analytic>
	<monogr>
		<title level="m">TCC 2006</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Halevi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Rabin</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">3876</biblScope>
			<biblScope unit="page" from="265" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The algorithmic foundations of differential privacy</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Found. Trends Theoret. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="211" to="407" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Construction of a machine learning dataset through collaboration: the RSNA 2019 brain CT hemorrhage challenge</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Flanders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiol. Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">190211</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Numerical composition of differential privacy</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gopi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wutschitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="11631" to="11642" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Densely connected convolutional networks</title>
		<author>
			<persName><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="4700" to="4708" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Advances and open problems in federated learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kairouz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Found. Trends Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="1" to="210" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">End-to-end privacy preserving deep learning on multiinstitutional medical imaging</title>
		<author>
			<persName><forename type="first">G</forename><surname>Kaissis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="473" to="484" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Federated learning with local differential privacy: tradeoffs between privacy, utility, and communication</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Günlü</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2650" to="2654" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Improved performance and robustness of multi-task representation learning with consistency loss between pretexts for intracranial hemorrhage identification in head CT</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kyung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page">102489</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Computer-aided detection and diagnosis for prostate cancer based on mono and multi-parametric MRI: a review</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lemaître</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Martí</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Biol. Med</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="8" to="31" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Differentially private adaptive optimization with delayed preconditioners</title>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Private adaptive optimization with side information</title>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Reddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Smith</surname></persName>
		</author>
		<idno>PMLR</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="13086" to="13105" />
		</imprint>
		<respStmt>
			<orgName>ICML</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Evaluation of prostate segmentation algorithms for MRI: the promise12 challenge</title>
		<author>
			<persName><forename type="first">G</forename><surname>Litjens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="359" to="373" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">On privacy and personalization in cross-silo federated learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">MS-Net: multi-site network for improving prostate segmentation with heterogeneous MRI data</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TMI</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2713" to="2724" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">the medical algorithmic audit</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Mccradden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Denniston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Oakden-Rayner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lancet Digital Health</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="384" to="e397" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Communication-efficient learning of deep networks from decentralized data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mcmahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AISTATS</title>
		<imprint>
			<biblScope unit="page" from="1273" to="1282" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning differentially private recurrent language models</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Rényi differential privacy</title>
		<author>
			<persName><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 30th Computer Security Foundations Symposium (CSF)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="263" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">NCI-Proceedings of the IEEE-ISBI conference 2013 challenge: automated segmentation of prostate structures</title>
		<author>
			<persName><forename type="first">B</forename><surname>Nicholas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Anant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Cancer Imaging Archive</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Tempered sigmoid activations for deep learning with differential privacy</title>
		<author>
			<persName><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AAAI</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="9312" to="9321" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Adaptive federated optimization</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Reddi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The future of digital health with federated learning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Rieke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">U-Net: convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-24574-4_28</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-24574-4_28" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2015</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hornegger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">9351</biblScope>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Tackling the objective inconsistency problem in heterogeneous federated optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Yousefpour</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.12298</idno>
		<title level="m">Opacus: user-friendly differential privacy library in PyTorch</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Federated f-differential privacy</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Su</surname></persName>
		</author>
		<idno>PMLR</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>AIS-TATS</publisher>
			<biblScope unit="page" from="2251" to="2259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Ziller</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.02586</idno>
		<title level="m">Differentially private federated deep learning for multi-site medical image segmentation</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
