<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Flexible Framework for Simulating and Evaluating Biases in Deep Learning-Based Medical Image Analysis</title>
				<funder>
					<orgName type="full">River Fund at Calgary Foundation</orgName>
				</funder>
				<funder>
					<orgName type="full">Natural Sciences and Engineering Research Council of Canada</orgName>
				</funder>
				<funder>
					<orgName type="full">Canadian Institutes of Health Research</orgName>
				</funder>
				<funder>
					<orgName type="full">Alberta Innovates</orgName>
				</funder>
				<funder>
					<orgName type="full">Canada Research Chairs Program</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Emma</forename><forename type="middle">A M</forename><surname>Stanley</surname></persName>
							<email>emma.stanley@ucalgary.ca</email>
							<idno type="ORCID">0000-0002-7802-6820</idno>
							<affiliation key="aff0">
								<orgName type="department">Department of Biomedical Engineering</orgName>
								<orgName type="institution">University of Calgary</orgName>
								<address>
									<settlement>Calgary</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Radiology</orgName>
								<orgName type="institution">University of Calgary</orgName>
								<address>
									<settlement>Calgary</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Hotchkiss Brain Institute</orgName>
								<orgName type="institution">University of Calgary</orgName>
								<address>
									<settlement>Calgary</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Alberta Children&apos;s Hospital Research Institute</orgName>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">University of Calgary</orgName>
								<address>
									<settlement>Calgary</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Matthias</forename><surname>Wilms</surname></persName>
							<idno type="ORCID">0000-0001-8845-360X</idno>
							<affiliation key="aff2">
								<orgName type="department">Hotchkiss Brain Institute</orgName>
								<orgName type="institution">University of Calgary</orgName>
								<address>
									<settlement>Calgary</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Alberta Children&apos;s Hospital Research Institute</orgName>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">University of Calgary</orgName>
								<address>
									<settlement>Calgary</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="department">Department of Pediatrics</orgName>
								<orgName type="institution">University of Calgary</orgName>
								<address>
									<settlement>Calgary</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff6">
								<orgName type="department">Department of Community Health Sciences</orgName>
								<orgName type="institution">University of Calgary</orgName>
								<address>
									<settlement>Calgary</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nils</forename><forename type="middle">D</forename><surname>Forkert</surname></persName>
							<idno type="ORCID">0000-0003-2556-3224</idno>
							<affiliation key="aff0">
								<orgName type="department">Department of Biomedical Engineering</orgName>
								<orgName type="institution">University of Calgary</orgName>
								<address>
									<settlement>Calgary</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Radiology</orgName>
								<orgName type="institution">University of Calgary</orgName>
								<address>
									<settlement>Calgary</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Hotchkiss Brain Institute</orgName>
								<orgName type="institution">University of Calgary</orgName>
								<address>
									<settlement>Calgary</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Alberta Children&apos;s Hospital Research Institute</orgName>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">University of Calgary</orgName>
								<address>
									<settlement>Calgary</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff7">
								<orgName type="department">Department of Clinical Neurosciences</orgName>
								<orgName type="institution">University of Calgary</orgName>
								<address>
									<settlement>Calgary</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Flexible Framework for Simulating and Evaluating Biases in Deep Learning-Based Medical Image Analysis</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="489" to="499"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">D6DCF0624CD5852048B4234406C5EBC5</idno>
					<idno type="DOI">10.1007/978-3-031-43895-0_46</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-13T19:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Despite the remarkable advances in deep learning for medical image analysis, it has become evident that biases in datasets used for training such models pose considerable challenges for a clinical deployment, including fairness and domain generalization issues. Although the development of bias mitigation techniques has become ubiquitous, the nature of inherent and unknown biases in real-world medical image data prevents a comprehensive understanding of algorithmic bias when developing deep learning models and bias mitigation methods. To address this challenge, we propose a modular and customizable framework for bias simulation in synthetic but realistic medical imaging data. Our framework provides complete control and flexibility for simulating a range of bias scenarios that can lead to undesired model performance and shortcut learning. In this work, we demonstrate how this framework can be used to simulate morphological biases in neuroimaging data for disease classification with a convolutional neural network as a first feasibility analysis. Using this case example, we show how the proportion of bias in the disease class and proximity between disease and bias regions can affect model performance and explainability results. The proposed framework provides the opportunity to objectively and comprehensively study how biases in medical image data affect deep learning pipelines, which will facilitate a better understanding of how to responsibly develop models and bias mitigation methods for clinical use. Code is available at github.com/estanley16/SimBA. M. Wilms and N.D. Forkert-Shared last authorship.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Deep learning for medical image analysis is a key tool to facilitate precision medicine and support clinical decision making. However, it has become increasingly evident that biases in the training data can lead to obstacles for clinical implementation. In this work, we define bias as a property of the data (e.g., class/attribute imbalance, spurious correlations) used for training a model that can lead to shortcut learning and/or failure to adequately represent data subgroups, which may lead to reduced generalizability and/or fairness when applied in real-world scenarios. For instance, such biases have been shown to lead to poor generalization capabilities of models evaluated on cohorts with sociodemographic population statistics different to those that it was trained on <ref type="bibr" target="#b8">[9]</ref>, which can lead to systematic misdiagnosis of subpopulations <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b17">18]</ref>. Moreover, image acquisition biases can act as spurious correlations to the target (shortcut learning) <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b22">23]</ref>.</p><p>Due to these problems, a plethora of research has recently gone towards bias mitigation <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26]</ref> and data harmonization <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b22">23]</ref>. However, the utility of real-world medical images to assess and address bias-related challenges is often limited and may not be a comprehensive or sustainable solution. This is because all real-world datasets inherently suffer from biases that can be related to cohort selection, varying scanners and protocols, biases in "ground truth" labels, or any other (un-)known confounding factors associated with the data or the labels. Additionally, many medical imaging datasets do not contain suitable sociodemographic information or representation to adequately investigate the full range of bias scenarios that could be encountered in practice, especially when considering intersectional analyses <ref type="bibr" target="#b21">[22]</ref>. Moreover, limitations in the seminal work on underdiagnosis disparities in deep learning models for chest X-ray analysis <ref type="bibr" target="#b17">[18]</ref> have been identified since the various sources of bias present in the dataset could not be effectively distinguished from algorithmic bias <ref type="bibr" target="#b2">[3]</ref> and known confounding factors were not rigorously accounted for <ref type="bibr" target="#b14">[15]</ref>. However, even when known confounders such as disease prevalence between groups are considered, it may not be possible to adequately correct for them and unknown confounders and associated spurious correlations may still exist that go unaccounted for, such as annotation bias in labels used for training. Thus, it is very challenging to understand how biases in medical image data affect deep learning pipelines, especially if it is unknown what biases are present in the dataset, their magnitude and frequency, and how to correct them. As noted by various researchers, "understanding the root cause of bias [. . . ] is a key step towards eliminating that bias" <ref type="bibr" target="#b18">[19]</ref>. Therefore, there is a need for a resource that enables researchers to objectively study how biases in medical images affect deep learning models, without the limitations associated with real-world datasets. As a first step towards addressing this need, we propose a flexible framework for generating synthetic neuroimaging data with controlled simulation of realistic biases.</p><p>Current methods that have been proposed for fully controlled simulation of features in deep learning datasets, where generating factors can be fully disentangled and are well known in advance, are largely limited to toy problems or MNIST-like scenarios <ref type="bibr" target="#b3">[4]</ref>. On the other hand, a considerable amount of recent research has gone into the supervised and unsupervised disentanglement of generating factors of medical images with generative models that can subsequently be used to synthesize data with specific factor variations <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b10">11]</ref>. However, in such setups, unknown biases could still exist, the true generating factors of real-world data are usually unknown, and it is often impossible to spatially localize an effect. Therefore, we believe that such standard generative models do not offer the flexibility and control of the data generation mechanism that is required to fully analyze the effect of data biases on deep learning models. With our proposed framework, we aim to provide a method for synthesizing realistic image data with a fidelity similar to standard generative models, while still providing a high level of flexibility and control over the type, scale, and proportions of simulated bias features that is usually only available in MNIST-like setups.</p><p>In this work, we simulate brain magnetic resonance (MR) images with regionspecific morphology variations representing disease and bias effects. We also introduce global morphological variation representing distinct synthetic subjects. This option facilitates bridging the relationship between understanding the impacts of biases alone, and how biases combine with real-world variation when training deep learning models. We utilize neuroimaging data as an initial use case and focus on morphological biases in this work. However, the proposed modular framework is not limited to neuroimaging problems and could be modified to introduce other bias effects, such as gray value effects caused by acquisition parameters or pathologies. Ultimately, this framework can serve as a tool for generating datasets to facilitate analysis of how deep learning models handle various sources of bias. With complete control over the number of samples, types of bias, number of subgroups with different biases, intersections of biased subgroups, and strength and proportion of bias in target classes, datasets generated with this framework can be used as a tool for evaluating how proposed or state-of-the-art models are affected by biases in terms of performance, explainable AI, uncertainty, etc., as well as for benchmarking bias mitigation and data harmonization strategies on a wide range of realistic, controlled scenarios.</p><p>The contributions of this paper are summarized as follows: <ref type="bibr" target="#b0">(1)</ref> We propose a flexible framework for simulating brain MR datasets, which contain variable morphological disease and bias effects, as a first step towards the controlled and systematic study of how biases in medical imaging data affect deep learning pipelines. <ref type="bibr" target="#b1">(2)</ref> We show how this modular framework can be customized to facilitate the investigation of a vast range of data cases that can lead to biased deep learning models. (3) We provide empirical evidence that data generated using this framework can be used to mimic realistic morphological biases in neuroimaging that lead to undesirable performance in a convolutional neural network, and show how these biases can be investigated with explainable AI methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>The purpose of the proposed framework is to generate a dataset for a multi-class classification problem consisting of synthetic T1-weighted MR images, with N images I i and associated labels corresponding to m disease classes. For simplicity, in this description of the methods, we focus on the binary classification task (m=2) with disease labels corresponding to disease (D) and no disease (ND). All images are derived by applying non-linear diffeomorphic transformations to a template image I T , which represents an average brain morphology. More specifically, we consider three types of transformations: (1) ϕ S , a subject morphology, (2) ϕ D , a disease (target) effect, and (3) ϕ B , a bias effect. ϕ S is a global nonlinear transformation that deforms I T into a (simulated) subject morphology. In contrast, ϕ D and ϕ B are spatially localized deformations that only modify I T locally to introduce an effect (ϕ D ) that can be used to differentiate disease classes, and a bias effect (ϕ B ). In our setup, each synthetic image is generated by sampling the transformations ϕ S , ϕ D , and optionally ϕ B from dedicated generative models (Fig. <ref type="figure" target="#fig_0">1A</ref> and Suppl. Mat. Fig. <ref type="figure" target="#fig_0">1</ref>). Moreover, we assume that all diffeomorphic transformations are parameterized via stationary velocity fieldse.g., ϕ S = exp(v S ), where v S denotes the velocity field and exp(•) is the group exponential map from the Log-Euclidean framework, which can be efficiently computed via the scaling-and-squaring algorithm; see <ref type="bibr" target="#b0">[1]</ref>. The resulting dataset is defined by the user-specified sample size, number of target disease classes, number of subgroups within the dataset containing bias effects, whether intersubject variability effects are introduced to the datasets, types and degree of each respective effect, and proportions of each respective class and bias group.</p><p>Principal Component Analysis-Based Generative Models for Simulating Effects/Variability. To apply anatomically realistic morphological deformations to our template neuroimaging dataset in this work, we fit a principal component analysis (PCA) to the velocity fields of real T1-weighted MR images of different healthy subjects, which were non-linearly registered to the template image I T . We treat the resulting low-dimensional affine subspace model as a generative model and sample velocity fields representing a range of real anatomical variation from it. For region-specific effects (ϕ D and ϕ B ), the real T1-weighted MR image velocity fields within the regions defined by a label atlas are masked prior to PCA fitting, whereas the full brain is used in the PCA model for simulating subject morphology (ϕ S ). Thus, by sampling velocity fields v D , v B , and v S from the latent space of the respective subspace models, we can model disease, bias, and subject morphology as variations within an expected extent of human neuroanatomy.</p><p>Disease and Bias Effects. We model disease (ϕ D ) and bias (ϕ B ) effects as morphological deformations localized to specific brain regions. We also assume that datasets belonging to each disease class have these localized effects sampled from respective distributions in a bimodal Gaussian mixture model within the PCA subspace of the disease effect model. We assume that bias effects are introduced as an additional morphological deformation in a separate brain region, and that these effects are sampled from a Gaussian distribution within the PCA subspace of the bias effect model. In general, an arbitrary number of target classes and bias groups can be introduced to the datasets in a similar sampling procedure.</p><p>Subject Morphology. To better emulate anatomical variation in clinical data and warrant the use of deep learning models, global morphological variation representing distinct subjects (ϕ S ) are applied to the entire anatomy within I T . These are also sampled from a Gaussian distribution within the PCA subspace of the dedicated subject morphology model.</p><p>Introducing Effects to the Template Image. The sparsely defined velocity fields for the disease and bias effects, v D and v B , are densified using the scattered grid B-spline method <ref type="bibr" target="#b9">[10]</ref> to produce a dense velocity field that includes both effects (if present). If inter-subject variability is desired, the conjugate action mechanism <ref type="bibr" target="#b11">[12]</ref> is used to transport the deformation field to the "subject" space, where the "subject" is generated using the sampled v S /ϕ S from the subject morphology PCA model. Framework Customization. For this initial work, we utilize velocity fields from real-world datasets to simulate anatomically realistic effects representing disease features, bias features, and subject morphology via different PCA-based generative models. Although real-world datasets do contain biases, the way in which we propose introducing these effects into the synthetic dataset is highly controlled in such a way where it is known exactly which and how many regions represent either disease or bias effects. Thus, this approach enables a controlled study of bias while benefiting from the utilization of 3D medical images that are representative of real-world clinical data. Moreover, due to the modularity of the proposed framework, such effects can also be introduced through a variety of other methods for generating deformation fields, ranging from highly precise but simple (e.g., single displacement vectors) to more realistic but increasingly complex approaches (e.g., generative models). Furthermore, in this work, we simulate morphological changes in brain images via diffeomorphic transformations as a use case, but the framework can be adapted to other disease or bias effects that would alter the topology (e.g., gray value changes or lesions). Moreover, other imaging modalities or body regions (e.g., cardiac MRI) as well as other generative models (e.g., generative adversarial networks) could be integrated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head><p>To evaluate our synthetic datasets in a deep learning pipeline, we trained a CNN to predict whether images from biased datasets belong to the disease (D) or no disease (ND) class. More precisely, we evaluated (1) how the proportion of datasets containing bias features within the D class, and (2) how the spatial proximity between the disease region and bias region affect the performance and explainability (XAI) results of a CNN trained to classify D from ND cases (Fig. <ref type="figure" target="#fig_0">1B</ref>). All experiments were performed with Keras/Tensorflow v. 2.10. Simulated Datasets. The SRI24 Normal Adult Brain Anatomy atlas <ref type="bibr" target="#b16">[17]</ref> was used as the template image and each PCA model for sampling morphological effects was trained on T1-weighted MRI data from 50 subjects who were part of the IXI database of healthy individuals 1 . Velocity fields for this dataset were estimated by utilizing ITK's VariationalRegistration framework <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b23">24]</ref>. The left insular cortex was selected as the brain region for the disease effect, and the brain regions used to model bias effects were either the left putamen, right putamen, or right postcentral gyrus as defined by the LPB40 atlas <ref type="bibr" target="#b19">[20]</ref>, depending on the desired spatial proximity. The datasets belonging to the D and ND classes had effects sampled from N (0, 1) and N (2, 1), respectively, along the first principal component of the generative model for the disease region, and the datasets with bias features had effects sampled from N (2, 1) along the first principal components of the models for the respective bias regions. Inter-subject variability effects were sampled from a Gaussian distribution of N (0, 1) along the first 10 principal components of the subject morphology generative model. Experiments. To evaluate the effect on model performance and XAI in relation to the proportion of datasets containing bias features within the disease class, the generated datasets had either 60% or 80% of the simulated images from the D class containing the bias feature, with 30% of the simulated images from the ND class containing the bias feature for all experiments. To evaluate the effect of proximity between disease and bias regions, the distances between regions were defined as either near, middle, or far, for the left putamen, right putamen, and right postcentral gyrus, respectively (see Fig. <ref type="figure" target="#fig_2">2B</ref>). Each simulated dataset contained a balanced representation of D and ND labels. The proximity experiments were performed under both 60% and 80% conditions defined by the proportion experiments. Model performance with the biased datasets was compared against a baseline experiment in which the datasets do not contain any simulated bias features but only the disease effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model and Training.</head><p>A CNN was used as a model for predicting whether datasets belonged to the D or ND class. The model consisted of 5 blocks each containing a convolutional layer with (3×3×3) kernel, batch normalization, sigmoid activation, and (2×2×2) max pooling. The convolutional filter sizes were 32, 64, 128, 256, and 512 for each respective block. The sixth block contained average pooling, dropout (rate=0.2), and a dense classification layer with softmax activation. Binary cross entropy loss, Adam optimizer (learning rate = 1e -4 ), and batch size 4 with early stopping based on validation loss (patience=30) were used for training. Each experiment simulated and used 500 datasets of voxel dimensions (173×211×155) with a 55%/15%/30% train/validation/test split, stratified by disease and bias labels.</p><p>Evaluation. Model performance was evaluated using accuracy, sensitivity, and specificity computed for the aggregate test set, as well as separately for the bias (B) and no bias (NB) groups. Results are reported as the mean ± standard deviation of the models with 5 different weight initialization seeds on the same train/validation/test splits, following <ref type="bibr" target="#b17">[18]</ref>. The SmoothGrad (SG) <ref type="bibr" target="#b20">[21]</ref> method was used for XAI evaluation. Average SG maps were computed with 25 individual SG maps (5 from each seed) for the datasets in the test set with the bias feature, which were correctly identified as being in the disease class.</p><p>Results and Discussion. The results of our evaluation are summarized in Fig. <ref type="figure" target="#fig_2">2</ref>, with full quantitative results shown in Tables <ref type="table">1</ref> and<ref type="table">2</ref> in the Supplementary Material. As seen in Fig. <ref type="figure" target="#fig_2">2A</ref>, for all conditions with simulated dataset bias, the sensitivity is higher and specificity is lower within the B group, while the opposite was found for the NB group. Due to the higher representation of biased datasets in the D class, it seems reasonable to assume that the model uses the presence of bias features as a shortcut for predicting the disease state, and thus predicts the D class more often for the B group, resulting in fewer true negatives. Within the NB group, the absence of bias features seems to be also used as a shortcut for predicting the ND class, resulting in a higher number of ND class predictions and consequently fewer true positives. While these shortcuts are apparent in all experiments utilizing biased datasets, there is a stronger relationship between disease-bias region proximity and the degree of the shortcuts (measured by lower specificity in the bias group and lower sensitivity in the NB group) when the dataset has 80% of the D class containing the bias effect compared to 60%. In these 80% conditions, it was observed that the sensitivity in the NB group decreases as a function of region proximity, indicating that the model uses the absence of the bias effect as a shortcut for predicting the ND class more often when regions are further away. Likewise, specificity in the B group increases as a function of region proximity, indicating that the model uses the presence of the bias as a shortcut for predicting the D class label less often when regions are further away. A potential explanation for this may be that the CNN used has a spatially localized receptive field. Thus, when the bias and disease regions are near to each other, the network learns to associate them more closely and predicts the D class label more often for images with the bias effect. When the regions are farther apart from each other, the CNN becomes more tuned to recognize bias effects separately from disease effects. Thus, when the bias effect is not present, the model assumes the image belongs to the ND class. Furthermore, as seen in Fig. <ref type="figure" target="#fig_2">2B</ref>, with 60% of the D class containing the bias feature, the SG maps show minor activation in the region with the bias effect, particularly in the far proximity condition. However, when 80% of the D class contains the bias feature, the SG maps highlight the bias regions considerably more intensely for all proximities analyzed. Even though the model still uses prediction shortcuts, which affect performance of the B and NB groups when 60% of the images from the D class exhibit the bias feature, the regions associated with the bias are less clearly identifiable in the group-averaged SG saliency maps, suggesting that XAI may not always be a reliable tool to uncover sources of bias in medical image data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this work, we presented a flexible and modular framework for simulating bias in medical imaging datasets using realistic morphological effects in neuroimaging as a use case. By sampling brain region-specific morphological variation representing the disease state and bias features from generative models in a controlled manner, we can generate synthetic datasets of arbitrary size and composition, which enables the investigation of a vast range of dataset bias scenarios and corresponding impacts on deep learning pipelines. Directions for future work with this framework are extensive and could include the analysis of more variations of bias proportions and proximities on alternate model architectures (e.g., vision transformers), evaluation of state-of-the-art bias mitigation strategies on various dataset compositions, as well as assessing other potential limitations of explainability methods as a tool for investigating bias. We believe that our work provides a strong foundation for advancing understanding of bias in deep learning for medical image analysis and consequently developing responsible models and methods for clinical use.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. A) Schematic representing how displacement fields for disease effects (ϕD), bias effects (ϕB), and subject morphology (ϕS) are introduced to a template image IT to generate custom datasets. B) Synthetic dataset evaluation pipeline used in this paper. A convolutional neural network (CNN) is trained to classify the disease class from a dataset with subgroups containing bias features and evaluated with subgroup performance and explainability.</figDesc><graphic coords="5,55,98,279,74,340,18,236,83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>1</head><label></label><figDesc>https://brain-development.org/ixi-dataset/.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Results of experiments investigating effect of the proportion of bias effect in the disease class and proximity between disease and bias regions. A) Mean sensitivity (left column) and specificity (right column) for test datasets with bias (green circle) and without bias (blue square). Error bars represent standard deviation over 5 different model initialization seeds with the same train/validation/test split. Black lines represent mean sensitivity and specificity with 95% confidence interval over 5 different model seeds with the same train/validation/test split of dataset containing no bias effects. B) Average SmoothGrad saliency maps with disease region circled in solid/magenta and bias region circled in dashed/cyan. (Color figure online)</figDesc><graphic coords="8,41,79,302,51,340,21,120,43" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This work was supported by <rs type="funder">Alberta Innovates</rs>, the <rs type="funder">Natural Sciences and Engineering Research Council of Canada</rs>, the <rs type="funder">River Fund at Calgary Foundation</rs>, <rs type="funder">Canada Research Chairs Program</rs>, and the <rs type="funder">Canadian Institutes of Health Research</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43895-0 46.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A log-Euclidean framework for statistics on diffeomorphisms</title>
		<author>
			<persName><forename type="first">V</forename><surname>Arsigny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Commowick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Pennec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ayache</surname></persName>
		</author>
		<idno type="DOI">10.1007/11866565_113</idno>
		<ptr target="https://doi.org/10.1007/11866565113" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2006</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Larsen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Nielsen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Sporring</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">4190</biblScope>
			<biblScope unit="page" from="924" to="931" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The iSTAGING and PHENOM consortia: deep generative medical image harmonization for improving cross-site generalization in deep learning predictors</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Bashyam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Magn. Reson. Imaging</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="908" to="916" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Potential sources of dataset bias complicate investigation of underdiagnosis by machine learning algorithms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bernhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1157" to="1158" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Morpho-MNIST: quantitative assessment and diagnostics for representation learning</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kainz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Konukoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep learning-based unlearning of dataset bias for MRI harmonisation and confound removal</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Dinsdale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jenkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I L</forename><surname>Namburete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">228</biblScope>
			<biblScope unit="page">117689</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Bildverarbeitung für die Medizin 2015. I</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ehrhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schmidt-Richberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Werner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Handels</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-662-46224-9_37</idno>
		<ptr target="https://doi.org/10.1007/978-3-662-46224-937" />
		<editor>Handels, H., Deserno, T.M., Meinzer, H.-P., Tolxdorff, T.</editor>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="209" to="214" />
			<pubPlace>Heidelberg</pubPlace>
		</imprint>
	</monogr>
	<note>Variational registration</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Review of disentanglement approaches for medical applications -towards solving the gordian knot of generative models in healthcare</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fragemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ardizzone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Egger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kleesiek</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.11132</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Machine learning with multi-site imaging data: an empirical study on the impact of scanner effects</title>
		<author>
			<persName><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Konukoglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.04597</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>cs, eess, q-bio</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Gender imbalance in medical imaging datasets produces biased classifiers for computer-aided diagnosis</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Larrazabal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nieto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Milone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ferrante</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl. Acad. Sci</title>
		<meeting>Natl. Acad. Sci</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="12592" to="12594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Scattered data interpolation with multilevel Bsplines</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wolberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Visual Comput. Graphics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="228" to="244" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning disentangled representations in the imaging domain</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thermos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Q</forename><surname>O'neil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Tsaftaris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page">102516</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Geodesics, parallel transport &amp; one-parameter subgroups for diffeomorphic image registration</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lorenzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Pennec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vision</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="111" to="127" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Pseudo bias-balanced learning for debiased chest X-ray classification</title>
		<author>
			<persName><forename type="first">L</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16452-1_59</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16452-159" />
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer Assisted Intervention -MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13438</biblScope>
			<biblScope unit="page" from="621" to="631" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Debiasing deep chest X-ray classifiers using intra-and post-processing methods</title>
		<author>
			<persName><forename type="first">R</forename><surname>Marcinkevics</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ozkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Vogt</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Machine Learning for Healthcare Conference</title>
		<meeting>the 7th Machine Learning for Healthcare Conference</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="504" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Confounding factors need to be accounted for in assessing bias by machine learning algorithms</title>
		<author>
			<persName><forename type="first">P</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mathai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Shafaat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Summers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1159" to="1160" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Fairness in cardiac MR image analysis: an investigation of bias due to data imbalance in deep learning based segmentation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Puyol-Antón</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87199-4_39</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87199-439" />
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer Assisted Intervention -MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12903</biblScope>
			<biblScope unit="page" from="413" to="423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The SRI24 multichannel atlas of normal adult human brain structure</title>
		<author>
			<persName><forename type="first">T</forename><surname>Rohlfing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Zahr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">V</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pfefferbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hum. Brain Mapp</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="798" to="819" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Underdiagnosis bias of artificial intelligence algorithms applied to chest radiographs in under-served patient populations</title>
		<author>
			<persName><forename type="first">L</forename><surname>Seyyed-Kalantari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B A</forename><surname>Mcdermott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2176" to="2182" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Reply to: &apos;Potential sources of dataset bias complicate investigation of underdiagnosis by machine learning algorithms&apos; and &apos;Confounding factors need to be accounted for in assessing bias by machine learning algorithms&apos;</title>
		<author>
			<persName><forename type="first">L</forename><surname>Seyyed-Kalantari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B A</forename><surname>Mcdermott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1161" to="1162" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Construction of a 3D probabilistic atlas of human cortical structures</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Shattuck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1064" to="1080" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Smilkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Thorat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Viégas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.03825</idno>
		<title level="m">SmoothGrad: removing noise by adding noise</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Ethical and Philosophical Issues in Medical Imaging, Multimodal Learning and Fusion Across Scales for Clinical Decision Support, and Topological Data Analysis for Biomedical Imaging</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A M</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wilms</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Forkert</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-23223-7_2</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-23223-72" />
	</analytic>
	<monogr>
		<title level="j">LNCS</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">S H</forename><surname>Baxter</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">13755</biblScope>
			<biblScope unit="page" from="14" to="25" />
			<date type="published" when="2022">2022</date>
			<publisher>Springer</publisher>
			<pubPlace>Cham</pubPlace>
		</imprint>
	</monogr>
	<note>Disproportionate subgroup impacts and other challenges of fairness in artificial intelligence for medical image analysis</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Detect and correct bias in multi-site neuroimaging datasets</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wachinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rieckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pölsterl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page">101879</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Estimation of lung motion fields in 4D CT data by variational non-linear intensity-based registration: a comparison and evaluation study</title>
		<author>
			<persName><forename type="first">R</forename><surname>Werner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schmidt-Richberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Handels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ehrhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Med. Biol</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page">4247</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Removal of confounders via invariant risk minimization for medical diagnosis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Nguyen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16452-1_55</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16452-155" />
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer Assisted Intervention -MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13438</biblScope>
			<biblScope unit="page" from="578" to="587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Training confounder-free deep learning models for medical applications</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Adeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Pohl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">6010</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
