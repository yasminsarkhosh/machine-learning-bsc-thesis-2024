<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">FedIIC: Towards Robust Federated Learning for Class-Imbalanced Medical Image Classification</title>
				<funder ref="#_vppBJ7q">
					<orgName type="full">Natural Science Foundation of Hubei Province of China</orgName>
				</funder>
				<funder>
					<orgName type="full">HPC Platform of HUST</orgName>
				</funder>
				<funder ref="#_YpEy523 #_DmsTYx5">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_pWEhB3h">
					<orgName type="full">Research Grants Council GRF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Nannan</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic Information and Communications</orgName>
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
								<address>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Li</forename><surname>Yu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xin</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic Information and Communications</orgName>
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
								<address>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kwang-Ting</forename><surname>Cheng</surname></persName>
							<email>timcheng@ust.hk</email>
							<affiliation key="aff1">
								<orgName type="department">School of Engineering</orgName>
								<orgName type="institution">Hong Kong University of Science and Technology</orgName>
								<address>
									<settlement>Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zengqiang</forename><surname>Yan</surname></persName>
							<email>z_yan@hust.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic Information and Communications</orgName>
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
								<address>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">FedIIC: Towards Robust Federated Learning for Class-Imbalanced Medical Image Classification</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="692" to="702"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">BDAA102A9F490ED0F09611FFDE1E1E3E</idno>
					<idno type="DOI">10.1007/978-3-031-43895-0_65</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-13T19:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Federated learning</term>
					<term>Class imbalance</term>
					<term>Contrastive learning</term>
					<term>Classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Federated learning (FL), training deep models from decentralized data without privacy leakage, has shown great potential in medical image computing recently. However, considering the ubiquitous class imbalance in medical data, FL can exhibit performance degradation, especially for minority classes (e.g. rare diseases). Existing methods towards this problem mainly focus on training a balanced classifier to eliminate class prior bias among classes, but neglect to explore better representation to facilitate classification performance. In this paper, we present a privacy-preserving FL method named FedIIC to combat class imbalance from two perspectives: feature learning and classifier learning. In feature learning, two levels of contrastive learning are designed to extract better class-specific features with imbalanced data in FL. In classifier learning, per-class margins are dynamically set according to real-time difficulty and class priors, which helps the model learn classes equally. Experimental results on publicly-available datasets demonstrate the superior performance of FedIIC in dealing with both real-world and simulated multi-source medical imaging data under class imbalance. Code is available at https://github.com/wnn2000/FedIIC.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Federated learning (FL), allowing decentralized data sources to train a unified deep learning model collaboratively without data sharing, has drawn great attention in medical imaging due to its privacy-preserving properties <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b41">40]</ref>. Existing studies of FL mainly focus on data heterogeneity across clients <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b31">31]</ref>, while ignoring the widely-existed class imbalance problem in medical scenarios. In clinical practice, the number of samples for different diseases may vary greatly due to varying incidence rates in the population. When conducting FL on cooperative medical institutions with global class-imbalanced data, the global model may suffer from significant performance degradation, which typically manifests as the recognition accuracy of minority classes (e.g. rare diseases) being lower than that of majority classes (e.g. common diseases) <ref type="bibr" target="#b34">[34]</ref>. Deploying such a biased global/federated model is fatal, especially for misdiagnosing a rare disease <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b43">42]</ref>. Therefore, addressing class imbalance in federated learning is of great value.</p><p>Several FL frameworks have been proposed to tackle imbalanced data <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b42">41]</ref>. Following re-weighting <ref type="bibr" target="#b6">[7]</ref>, Wang et al. <ref type="bibr" target="#b40">[39]</ref> presented a weighted form of cross entropy loss named ratio loss depending on a balanced auxiliary dataset for the server to calculate weights. Sarkar et al. <ref type="bibr" target="#b33">[33]</ref> introduced focal loss <ref type="bibr" target="#b23">[24]</ref> to up-weight hard samples. CLIMB <ref type="bibr" target="#b35">[35]</ref> assigned larger weights to clients more likely to own minority classes via a meta-algorithm. Inspired by decoupling <ref type="bibr" target="#b16">[17]</ref>, CReFF <ref type="bibr" target="#b34">[34]</ref> retrained a new classifier with balanced synthetic features in the server. All these methods aim to balance classes from the classifier perspective without exploring better representations with class-imbalanced data for performance improvement.</p><p>In this paper, we formulate the effect of class imbalance in FL into the attribute bias and the class bias <ref type="bibr" target="#b37">[37]</ref>. The attribute bias means minority classes have more imbalanced background attributes in their class-specific attributes compared to majority classes, making them less distinguishable. The class bias represents the difference in prior probabilities across classes, resulting in biased predictions toward majority classes. To handle the two biases, we present a new class-balancing FL method named FedIIC from two perspectives: feature learning and classifier learning. The key idea of FedIIC is to alleviate the two biases through the calibration of the feature extractor and the classifier. Specifically, two-level supervised contrastive learning <ref type="bibr" target="#b17">[18]</ref>, i.e. intra-and inter-client contrastive learning, is built to calibrate the feature extractor for better feature learning. For classifier learning, difficulty-aware logit adjustment is adopted to calibrate the classifier dynamically for better decision boundaries. Extensive comparison experiments on both real-world and simulated multi-source data validate FedIIC's effectiveness.</p><p>The main contributions are summarized as follows. (1) A new viewpoint of realistic medical FL scenarios where global training data is class-imbalanced. (2) A novel privacy-preserving framework FedIIC for balanced federated learning.</p><p>(3) Superior performance in dealing with class imbalance under both real-world and simulated multi-source decentralized settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Preliminaries and Overview</head><p>Considering a typical FL scenario for multi-class image classification with K participants, each participant is assumed to own a private dataset</p><formula xml:id="formula_0">D k = {(x i , y i )} N k i=1 , k ∈ [K],</formula><p>where N k is the data amount of D k , and denote each image-label pair as</p><formula xml:id="formula_1">(x i ∈ X ⊆ R d , y i ∈ Y = [L]</formula><p>). The goal of FL is to Assuming each image has two kinds of latent attributes, i.e. Z c and Z a , representing the class-specific attributes (determining the category of the image, e.g. texture, color, etc.) and the variant background attributes (e.g. brightness, contrast, etc.) respectively <ref type="bibr" target="#b37">[37]</ref>, based on the Bayes theorem, the posterior probability of classification can be formulated as</p><formula xml:id="formula_2">P (y | x) = P (y | Z c , Z a ) = p(Z c | y) p(Z c ) • p(Z a | y, Z c ) p(Z a | Z c ) • p(y),<label>(1)</label></formula><p>where the last two items represent the attribute bias and the class bias respectively, which widely exist in class-imbalanced data and affect the posterior probability. For robust FL with class-imbalanced data, the key idea is to alleviate the two biases simultaneously, instead of focusing on the latter as <ref type="bibr" target="#b34">[34]</ref>. Hence, we propose FedIIC to address class imbalance from the two perspectives as illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>. Details are presented in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Intra-Client Contrastive Learning</head><p>Limited local data affects data diversity (i.e., limited (Z c , Z a ) combinations), especially for minority classes, making Z c less distinguishable. To emphasize more on the learning of Z c , supervised contrastive learning (SCL), proven to be effective for representation learning <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b46">45]</ref>, is introduced in local training.</p><p>The basic loss function of SCL can be formulated as</p><formula xml:id="formula_3">L SCL = i∈I -1 |P (i)| j∈P (i) log exp(z i • z j /τ ) a∈A(i) exp(z i • z a /τ ) , (<label>2</label></formula><formula xml:id="formula_4">)</formula><p>where I denotes the index set of the multi-view batch generated by different augmentations (e.g. the two views in Fig. <ref type="figure" target="#fig_0">1</ref> ), |•| measures the number of elements in a set, A(i) = I\{i}, P (i) = {s ∈ A(i)|y s = y i }, τ represents the temperature, and z denotes the l 2 -normalized embedding of a sample x. Note that in this paper, we use a 2-layer MLP h(•) to obtain z before it is normalized as <ref type="bibr" target="#b2">[3]</ref>, i.e.</p><formula xml:id="formula_5">z = h(g(x)) h(g(x)) 2</formula><p>. In the multi-view batch, L SCL keeps the embeddings of the same class closer while pushing the embeddings of different classes further away, which helps the model learn better Z c of each class due to richer Z a . However, SCL can not perfectly address class imbalance as the majority classes would benefit more from Eq. 2 following traditional training losses (e.g. the cross entropy loss).</p><p>To overcome this problem, we propose to employ a dynamic temperature τ := P τ = (p i p j ) t τ in Eq. 2 inspired by <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b46">45]</ref>, where p i is the prior probability of class i in the local dataset and t is a parameter set as 0.5 by default. Hence, the loss function is rewritten as</p><formula xml:id="formula_6">L Intra = i∈I -1 |P (i)| j∈P (i) log exp(z i • z j /τ ) a∈A(i) exp(z i • z a /τ ) , (<label>3</label></formula><formula xml:id="formula_7">)</formula><p>named intra-client contrastive learning. Through P , sample pairs of the minority classes are up-weighted compared to those of the majority classes, leading to better balance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Inter-client Contrastive Learning</head><p>Given limited local data under FL, the effectiveness of intra-client contrastive learning may be bounded. How to better utilize cross-client data from the global perspective is crucial for further performance improvement. Inspired by learning from prototypes <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b31">31]</ref>, we propose inter-client contrastive learning. Assuming a set of shared class-wise prototypes V = {v 1 , v 2 , ..., v L } across clients, the local model can be trained by</p><formula xml:id="formula_8">L Inter = i∈I -1 |P (i)| log exp(z i • v yi /τ ) L j=1 exp(z i • v j /τ ) , (<label>4</label></formula><formula xml:id="formula_9">)</formula><p>where y i is the label of sample i. When minimizing L Inter , the embedding of each sample will get closer to the prototype of the same class while farther from the prototypes of different classes, encouraging local models to learn common attributes (i.e. class-specific attributes) for samples with the same classes.</p><p>To this end, how to produce high-quality prototypes is the key to interclient contrastive learning. In previous studies, one common method to generate prototypes is uploading and aggregating local information. For example, Mu et al. <ref type="bibr" target="#b31">[31]</ref> and Chen et al. <ref type="bibr" target="#b3">[4]</ref> uploaded features to the server directly to generate prototypes. However, it may cause privacy leakage under well-designed attacks and will introduce extra communication costs. Different from these methods, in FedIIC, we propose a new method to generate global prototypes without uploading extra information. Considering that the essence of linear classification is similarity calculation based on vector inner product, the weights of a welltrained linear classifier are nearly co-linear with the feature vectors of different classes <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b32">32,</ref><ref type="bibr" target="#b46">45]</ref>. Therefore, the weights of a linear classifier denoted as W = {w 1 , w 2 , ..., w L }, can represent the corresponding features of L classes learned by the feature extractor g(•) to some extent. Specifically, given a global model [f g (•), g g (•), h g (•)] after model aggregation in the server, the weights of g g (•) are fed to h g (•) to calculate the initial prototypes V = { v 1 , v 2 , ..., v L } as shown in Fig. <ref type="figure" target="#fig_0">1</ref>. Considering that features of different classes should have low inter-class similarity, we further fine-tune V via gradient descent by</p><formula xml:id="formula_10">V ← V -∇ i∈Y max j∈Y,j =i ( v i v i 2 • v j v j 2 ).<label>(5)</label></formula><p>In this way, the cosine similarity of any ( v i , v j ) pair in V is minimized to be equal, resulting in V with lower inter-class similarity. This operation is called orthogonalization. Finally, the class-wise prototypes V are defined as the element-wise l 2 -normalization of V and are sent to clients for inter-client contrastive learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Difficulty-Aware Logit Adjustment</head><p>After calibrating the feature extractor g(•), one common method to calibrate the linear classifier f (•) is logit adjustment (LA) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b30">30]</ref> to alleviate the impact of class imbalance in local training. Specifically, Zhang et al. <ref type="bibr" target="#b44">[43]</ref> proposed to add per-class margins to logits and re-compute the cross entropy (CE) loss by</p><formula xml:id="formula_11">L LA = i∈I -log exp(f (g(x i )) yi -δ yi ) y ∈Y exp(f (g(x i )) y -δ y ) , (<label>6</label></formula><formula xml:id="formula_12">)</formula><p>where δ y denotes the positive per-class margin and is inversely proportional to the local class frequency p(y). In this way, during local training, the logits of minority classes will increase to compensate for the item, which in turn trains the model to emphasize more on minority classes. However, the frequency-dependent margin may not be appropriate for medical data. For instance, some disease types/classes may have large intra-class variations and are difficult to diagnose even with a large amount of data, which may result in even smaller per-class margins. To address this, in FedIIC, the per-class margin is calculated based on not only the class frequency but also difficulties inspired by <ref type="bibr" target="#b45">[44]</ref>. Specifically, we define δ y := log([l ce (y)] q /p(y)), where l ce (y) is the average CE loss of all samples belonging to class y in any round and q is a hyper-parameter set as 0.25 by default. l ce (y) is calculated as follows. At any round r, the total sample number of class y, denoted as N y r , belonging to clients of communication is first calculated. After receiving the global model from the server and before local training, each client i uploads l i ce (y), i.e. the total loss of class y, to the server. Finally, l ce (y) is calculated as 1 N y r i l i ce (y). This process to calculate average loss value can be privacy-preserving under the existing secure multiparty computation framework based on homomorphic encryption <ref type="bibr" target="#b35">[35]</ref>. Based on the newly defined δ y , Eq. 6 is renamed as L DALA . Note that the calculation of L DALA does not rely on the multi-view batch like L Intra and L Inter . For a fair </p><formula xml:id="formula_13">L = L DALA + k 1 L Intra + k 2 L Inter ,<label>(7)</label></formula><p>where k 1 and k 2 are trade-off hyper-parameters. After minimizing L during the local training phase of each client, the global model is updated by FedAvg <ref type="bibr" target="#b28">[28]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>Datasets. Three FL scenarios with class-imbalanced global data are used for evaluation, which are described as follows:</p><p>1. Real Multi-Source Dermoscopic Image Datasets (denoted as Real ) consisting of five data sources from three datasets, including PH 2 <ref type="bibr" target="#b29">[29]</ref>, Atlas <ref type="bibr" target="#b0">[1]</ref>, and HAM10000 <ref type="bibr" target="#b39">[38]</ref> where each source is treated as an individual client. For evaluation, we construct a separate test set by randomly sampling from the training set of ISIC 2019 <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b39">38]</ref> and ensure that the test set has no overlap with the above five data sources. 2. Intracranial Hemorrhage Classification (denoted as ICH ). The RNSA ICH dataset <ref type="bibr" target="#b9">[10]</ref>, containing five ICH subtypes, is adopted for experiments. The same pre-processing strategies in <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b25">26]</ref> are adopted, and images with only one single hemorrhage type are selected. Following <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b25">26]</ref>, data is split according to 7:1:2 for training, validation, and testing respectively. To simulate heterogeneous multi-source data, following <ref type="bibr" target="#b34">[34]</ref>, Dirichlet distribution, i.e. Dir(α = 1.0), is used to divide the training set to 20 clients. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Skin Lesion Classification (denoted as ISIC ).</head><p>The training data of ISIC 2019 <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b39">38]</ref>, containing eight classes, is used for evaluation. Following <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b25">26]</ref>, we split the dataset by 7:1:2 for training, validation, and testing respectively. Similarly, Dirichlet distribution, i.e. Dir(α = 1.0), is used to generate highly heterogeneous data partitions of 10 clients.</p><p>Data distributions of the three training settings are illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>, and imbalance ratios are <ref type="bibr">35.43, 19</ref>.59 and 57.60, respectively.</p><p>Implementation Details. EfficientNet-B0 <ref type="bibr" target="#b36">[36]</ref>, pre-trained by ImageNet <ref type="bibr" target="#b7">[8]</ref>, is adopted as the backbone trained by an Adam optimizer with betas as 0.9 and 0.999, a weight decay as 5e-4, constant learning rates of 1e-4 for Real and 3e-4 for both ICH and ISIC, and a batch size of 32. For ICH, the multi-view batch for contrastive learning is generated by following <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b25">26]</ref>. For both Real and ISIC, the multi-view batch is generated by 1) RandAug <ref type="bibr" target="#b5">[6]</ref> and 2) SimAugment <ref type="bibr" target="#b2">[3]</ref>. The hyper-parameters k 1 and k 2 in Eq. 7 are set as 2.0. For federated training, the local training epoch is set as 1 and the global training round is set as 200 for ICH and ISIC and 30 for Real. At each round, all clients (i.e., 100%) are included for model aggregation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Comparison with State-of-the-Art Methods</head><p>Ten related approaches are included for comprehensive comparison, including FedAvg <ref type="bibr" target="#b28">[28]</ref>, FedProx <ref type="bibr" target="#b19">[20]</ref> addressing data heterogeneity, MOON <ref type="bibr" target="#b18">[19]</ref> and Fed-Proc <ref type="bibr" target="#b31">[31]</ref> utilizing contrastive learning in FL, FedFocal <ref type="bibr" target="#b33">[33]</ref> utilizing focal loss  <ref type="bibr" target="#b23">[24]</ref> for balancing, FedRS <ref type="bibr" target="#b22">[23]</ref> addressing the class-missing problem, FedLC <ref type="bibr" target="#b44">[43]</ref> applying frequency-dependent logits adjustment in FL, PRR-Imb <ref type="bibr" target="#b3">[4]</ref> training personalized models with heterogeneous and imbalanced data, and CLIMB <ref type="bibr" target="#b35">[35]</ref> and CReFF <ref type="bibr" target="#b34">[34]</ref> addressing class-imbalance global data in FL. All the methods share the same experimental details described above for a fair comparison. More implementation details and visualization results can be found in supplemental materials. Following the ISIC 2019 competition, balanced accuracy (BACC) is used as the primary metric for class-imbalanced testing sets. Two key metrics in classification, i.e. F1 score (F1) and accuracy (ACC) are also employed for evaluation. Comparison results are summarized in Table <ref type="table" target="#tab_0">1</ref>. As can see, FedIIC achieves the best performance against all previous methods across the three metrics, outperforming the second-best approach (CReFF) by 3.99%, 7.32%, and 2.01% in BACC on Real, ISIC, and ICH respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Ablation Study</head><p>To validate the effectiveness of each component in FedIIC, a series of ablation studies are conducted on ISIC and ICH following the same experimental details described in Sect. 3. Quantitative results are summarized in Table <ref type="table" target="#tab_1">2</ref>. Under severe global imbalance, FedAvg is struggling. With the introduction of DALA, the performance is improved in BACC but degraded in F1. It is consistent with the quantitative results between CReFF and FedAvg on ICH in Table <ref type="table" target="#tab_0">1</ref>, indicating the limitation of only eliminating class bias through classifier calibration while ignoring attribute bias. The above results validate the necessity of addressing the imbalance in feature learning for performance improvement. Therefore, introducing either intra-or inter-client contrastive learning for better representation learning under class imbalance is beneficial in both BACC and F1. By combining all the components, FedIIC achieves the best overall performance, outperforming FedAvg with large margins.</p><p>Ablation studies of hyper-parameters in FedIIC are conducted on ISIC as stated in Table <ref type="table" target="#tab_2">3</ref>. Setting t = 0 encounters noticeable performance degradation, indicating the necessity of dynamic temperatures based on class priors in intraclient contrastive learning. Meanwhile, the performance gap between the initial prototypes V with and without orthogonalization validates the effectiveness of reducing inter-class similarity in prototypes. When introducing difficulty to logit adjustment (i.e., d = 0.25), we observe an increase in BACC and a decrease in F1, which is consistent with the above analysis in Table <ref type="table" target="#tab_0">1</ref> (i.e., CReFF vs. FedAvg).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>This paper discusses a more realistic federated learning (FL) setting in medical scenarios where global data is class-imbalanced and presents a novel framework FedIIC. The key idea behind FedIIC is to calibrate both the feature extractor and the classification head to simultaneously eliminate attribute biases and class biases. Specifically, both intra-and inter-client contrastive learning are introduced for balanced feature learning, and difficulty-aware logit adjustment is deployed to balance decision boundaries across classes. Experimental results on both real-world and simulated medical FL scenarios demonstrate FedIIC's superiority against the state-of-the-art FL approaches. We believe that this study is helpful to build real-world FL systems for clinical applications.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Overview of the proposed FedIIC.</figDesc><graphic coords="3,41,79,54,02,340,42,113,68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Illustration of imbalanced data distributions. The radius of each solid circle represents each client's data amount of a specific class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Quantitative comparison results under the Real, ISIC, and ICH settings. For Real, the average results (%) from the last five rounds are reported. For ISIC and ICH, the results (%) based on the best model (evaluated by the validation set) on the testing set are reported. The best results are marked in bold.</figDesc><table><row><cell>Methods</cell><cell>Year</cell><cell>Datasets</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Real</cell><cell>ISIC</cell><cell>ICH</cell></row><row><cell></cell><cell></cell><cell>BACC F1</cell><cell>ACC BACC F1</cell><cell>ACC BACC F1</cell><cell>ACC</cell></row><row><cell>FedAvg [28]</cell><cell cols="4">AISTATS'17 45.21 44.47 44.57 49.41 54.31 72.50 73.75 77.35 84.83</cell></row><row><cell cols="2">FedProx [20] MLSys'20</cell><cell cols="3">45.61 44.90 44.89 69.00 69.46 80.50 79.62 82.45 86.78</cell></row><row><cell>MOON [19]</cell><cell>CVPR'21</cell><cell cols="3">44.40 43.28 43.68 66.31 71.27 81.38 77.05 78.81 84.87</cell></row><row><cell cols="2">FedProc [31] FGCS'23</cell><cell cols="3">38.83 37.98 39.36 31.16 35.45 66.88 73.29 76.23 84.89</cell></row><row><cell>FedRS [23]</cell><cell>KDD'21</cell><cell cols="3">45.23 44.50 44.46 24.93 26.01 61.39 72.44 76.51 84.13</cell></row><row><cell>FedLC [43]</cell><cell>ICML'22</cell><cell cols="3">46.73 45.88 45.60 45.84 41.89 70.33 76.53 78.96 84.92</cell></row><row><cell cols="2">FedFocal [33] IJCAI'20</cell><cell cols="3">44.00 43.31 42.96 47.68 38.29 56.99 63.04 54.80 52.30</cell></row><row><cell cols="2">PRR-Imb [4] TMI'22</cell><cell cols="3">50.49 47.60 47.48 49.97 46.52 68.18 71.72 69.98 78.85</cell></row><row><cell>CLIMB [35]</cell><cell>ICLR'22</cell><cell cols="3">46.07 45.91 45.86 49.70 52.32 71.65 72.64 76.08 84.73</cell></row><row><cell>CReFF [34]</cell><cell>IJCAI'22</cell><cell cols="3">51.13 48.56 49.46 71.52 57.83 72.92 82.21 74.64 81.63</cell></row><row><cell cols="2">FedIIC (ours) -</cell><cell cols="3">55.12 51.57 51.67 78.84 78.05 85.71 84.22 84.73 87.77</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Component-wise study.</figDesc><table><row><cell>FedAvg DALA Intra Inter ISIC</cell><cell>ICH</cell></row><row><cell>BACC F1</cell><cell>BACC F1</cell></row><row><cell cols="2">49.41 54.31 73.75 77.35</cell></row><row><cell cols="2">50.65 42.12 81.26 76.47</cell></row><row><cell cols="2">51.30 43.84 81.96 82.68</cell></row><row><cell cols="2">75.78 76.55 83.81 82.39</cell></row><row><cell cols="2">78.84 78.05 84.22 84.73</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Parameter-wise study.</figDesc><table><row><cell>Param</cell><cell></cell><cell>BACC F1</cell></row><row><cell>t</cell><cell cols="2">0.0 76.33 75.43</cell></row><row><cell></cell><cell cols="2">0.5 78.84 78.05</cell></row><row><cell cols="3">orth. w/o 72.64 75.34</cell></row><row><cell></cell><cell>w</cell><cell>78.84 78.05</cell></row><row><cell>d</cell><cell cols="2">0.0 77.32 78.41</cell></row><row><cell></cell><cell cols="2">0.25 78.84 78.05</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement. This work was supported in part by the <rs type="funder">National Natural Science Foundation of China</rs> under Grants <rs type="grantNumber">62202179</rs> and <rs type="grantNumber">62271220</rs>, in part by the <rs type="funder">Natural Science Foundation of Hubei Province of China</rs> under Grant <rs type="grantNumber">2022CFB585</rs>, and in part by the <rs type="funder">Research Grants Council GRF</rs> Grant <rs type="grantNumber">16203319</rs>. The computation is supported by the <rs type="funder">HPC Platform of HUST</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_YpEy523">
					<idno type="grant-number">62202179</idno>
				</org>
				<org type="funding" xml:id="_DmsTYx5">
					<idno type="grant-number">62271220</idno>
				</org>
				<org type="funding" xml:id="_vppBJ7q">
					<idno type="grant-number">2022CFB585</idno>
				</org>
				<org type="funding" xml:id="_pWEhB3h">
					<idno type="grant-number">16203319</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43895-0_65.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Argenziano</surname></persName>
		</author>
		<title level="m">Interactive atlas of dermoscopy</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning imbalanced datasets with label-distribution-aware margin loss</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gaidon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Arechiga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
		<respStmt>
			<orgName>ICML</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Personalized retrogress-resilient federated learning toward imbalanced medical data</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3663" to="3674" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Combalia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.02288</idno>
		<title level="m">BCN20000: dermoscopic lesions in the wild</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">RandAugment: practical automated data augmentation with a reduced search space</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Class-balanced loss based on effective number of samples</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="9268" to="9277" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">ImageNet: a large-scale hierarchical image database</title>
		<author>
			<persName><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="248" to="255" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Self-balancing federated learning with global imbalanced data in mobile systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Duan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Parallel Distrib. Syst</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="71" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Construction of a machine learning dataset through collaboration: the RSNA 2019 brain CT hemorrhage challenge</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Flanders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiol. Artif. Intel</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">190211</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Dissecting supervised constrastive learning</title>
		<author>
			<persName><forename type="first">F</forename><surname>Graf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Niethammer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kwitt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3821" to="3830" />
		</imprint>
		<respStmt>
			<orgName>ICML</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Dual class-aware contrastive federated semisupervised learning</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.08914</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">HarmoFL: harmonizing local and global drifts in federated learning on heterogeneous medical images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1087" to="1095" />
		</imprint>
		<respStmt>
			<orgName>AAAI</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Dynamic bank learning for semi-supervised federated image diagnosis with class imbalance</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16437-8_19</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16437-8_19" />
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer Assisted Intervention -MICCAI 2022: 25th International Conference</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Singapore; Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">September 18-22, 2022. 2022</date>
			<biblScope unit="page" from="196" to="206" />
		</imprint>
	</monogr>
	<note>Proceedings, Part III</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Flexible sampling for long-tailed skin lesion classification</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ju</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16437-8_44</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16437-8_44" />
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer Assisted Intervention -MICCAI 2022: 25th International Conference</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Singapore; Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">September 18-22, 2022. 2022</date>
			<biblScope unit="page" from="462" to="471" />
		</imprint>
	</monogr>
	<note>Proceedings, Part III</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Exploring balanced feature spaces for representation learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Decoupling representation and classifier for long-tailed recognition</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Supervised contrastive learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Khosla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="18661" to="18673" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Model-contrastive federated learning</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="10713" to="10722" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Federated optimization in heterogeneous networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Mach. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="429" to="450" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Targeted supervised contrastive learning for long-tailed recognition</title>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="6918" to="6928" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">FedBN: federated learning on non-IID features via local batch normalization</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">FedRS: federated learning with restricted softmax for label distribution non-IID data</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Zhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<biblScope unit="page" from="995" to="1005" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Focal loss for dense object detection</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">FedDG: federated domain generalization on medical image segmentation via episodic learning in continuous frequency space</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1013" to="1023" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Federated semi-supervised medical image classification via inter-client relation matching</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Heng</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87199-4_31</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87199-4_31" />
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer Assisted Intervention -MICCAI 2021: 24th International Conference</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Strasbourg, France; Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021-10-01">September 27-October 1, 2021. 2021</date>
			<biblScope unit="page" from="325" to="335" />
		</imprint>
	</monogr>
	<note>Proceedings, Part III</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Fighting class imbalance with contrastive learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Marrakchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Makansi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer Assisted Intervention -MICCAI 2021: 24th International Conference</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Strasbourg, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021-10-01">September 27-October 1, 2021</date>
			<biblScope unit="page" from="466" to="476" />
		</imprint>
	</monogr>
	<note>Proceedings, Part III</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Cham</forename><surname>Springer</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87199-4_44</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87199-4_44" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Communicationefficient learning of deep networks from decentralized data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hampson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Arcas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1273" to="1282" />
		</imprint>
		<respStmt>
			<orgName>AISTATS</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">PH2-A dermoscopic image database for research and benchmarking</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mendonça</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Ferreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Marques</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Marcal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rozeira</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>EMBC</publisher>
			<biblScope unit="page" from="5437" to="5440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Long-tail learning via logit adjustment</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Menon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">FedProc: prototypical contrastive federated learning on non-IID data</title>
		<author>
			<persName><forename type="first">X</forename><surname>Mu</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.future.2023.01.019</idno>
		<ptr target="https://doi.org/10.1016/j.future.2023.01.019" />
	</analytic>
	<monogr>
		<title level="j">Future Gener. Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page" from="93" to="104" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Prevalence of neural collapse during the terminal phase of deep learning training</title>
		<author>
			<persName><forename type="first">V</forename><surname>Papyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl. Acad. Sci. U.S.A</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">40</biblScope>
			<biblScope unit="page" from="24652" to="24663" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Fed-Focal loss for imbalanced data classification in federated learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Federated learning on heterogeneous and long-tailed data via classifier re-training with federated features</title>
		<author>
			<persName><forename type="first">X</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">An agnostic approach to federated learning with class imbalance</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cervino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hassani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ribeiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">EfficientNet: rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6105" to="6114" />
		</imprint>
		<respStmt>
			<orgName>ICML</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Invariant feature learning for generalized long-tailed classification</title>
		<author>
			<persName><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2022: 17th European Conference</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Avidan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Brostow</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Cissé</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Farinella</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Hassner</surname></persName>
		</editor>
		<meeting><address><addrLine>Tel Aviv, Israel</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">October 23-27, 2022</date>
			<biblScope unit="page" from="709" to="726" />
		</imprint>
	</monogr>
	<note>Proceedings, Part XXIV</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Cham</forename><surname>Springer</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-20053-3_41</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-20053-3_41" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions</title>
		<author>
			<persName><forename type="first">P</forename><surname>Tschandl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rosendahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kittler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Data</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Addressing class imbalance in federated learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v35i11.17219</idno>
		<ptr target="https://doi.org/10.1609/aaai.v35i11.17219" />
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI Conf</title>
		<meeting>AAAI Conf</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="10165" to="10173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Variation-aware federated learning with multi-source decentralized medical image data</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wicaksana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">T</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Biomed. Health Inform</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2615" to="2628" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Federated learning with class imbalance reduction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>EUSIPCO</publisher>
			<biblScope unit="page" from="2174" to="2178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">ProCo: prototype-aware contrastive learning for long-tailed medical image classification</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16452-1_17</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16452-1_17" />
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer Assisted Intervention -MICCAI 2022: 25th International Conference</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Singapore; Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">September 18-22, 2022. 2022</date>
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
	<note>Proceedings, Part VIII</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Federated learning with label distribution skew via logits calibration</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="26311" to="26329" />
		</imprint>
		<respStmt>
			<orgName>ICML</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Adaptive logit adjustment loss for long-tailed visual recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v36i3.20258</idno>
		<ptr target="https://doi.org/10.1609/aaai.v36i3.20258" />
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI Conf</title>
		<meeting>AAAI Conf</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="3472" to="3480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Balanced contrastive learning for long-tailed visual recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">P P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">G</forename><surname>Jiang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="6908" to="6917" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
