<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Intelligent Virtual B-Scan Mirror (IVBM)</title>
				<funder>
					<orgName type="full">Carl Zeiss Meditec</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Michael</forename><surname>Sommersperger</surname></persName>
							<email>michael.sommersperger@tum.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Technical University of Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shervin</forename><surname>Dehghani</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Technical University of Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Philipp</forename><surname>Matten</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Medical University of Vienna</orgName>
								<address>
									<settlement>Vienna</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kristina</forename><surname>Mach</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Technical University of Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hessam</forename><surname>Roodaki</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Carl Zeiss Meditec AG</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ulrich</forename><surname>Eck</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Technical University of Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nassir</forename><surname>Navab</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Technical University of Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Intelligent Virtual B-Scan Mirror (IVBM)</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="418" to="428"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">F551EDE5E0332F515E3B27A8BE2B6A37</idno>
					<idno type="DOI">10.1007/978-3-031-43996-4_40</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-13T19:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Optical Coherence Tomography</term>
					<term>Surgical Visualization</term>
					<term>Volume Raymarching</term>
					<term>Virtual Mirrors</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Swept-Source Optical Coherence Tomography (SS-OCT) allows surgeons to perform certain ophthalmic procedures under the exclusive guidance of real-time volumetric optical coherence tomography (4D OCT). In such scenarios, surgeons are no longer limited to rigid views through an operating microscope. Instead, direct volume rendering (DVR) of 4D OCT enables surgical maneuvers to be performed from arbitrary viewpoints. While 4D OCT maximizes the use of the depth-resolved OCT data by displaying it from an oblique perspective, performing complex instrument maneuvers from such views places a higher mental demand on the surgeon. In this work, we propose an Intelligent Virtual B-scan Mirror (IVBM), a novel concept for surgical 4D OCT visualization to provide additional guidance for targeted instrument interactions. The IVBM integrates a virtual mirror into a selected cross-section of the OCT volume. This mirror acts intelligently by only being sensitive to voxels associated with surgical instruments. Furthermore, volume structures aligned with the IVBM are highlighted, while structures behind the IVBM are preserved through an adaptive opacity transfer function. Unlike previous perceptual OCT visualization concepts, which primarily address depth perception in axial OCT direction, this novel approach aids surgical interactions from arbitrary views. This paper presents the definition and implementation of an IVBM in a 4D OCT integrated microscope. Our user study in a virtual simulation environment confirms the benefits and provides insights into the interaction with the concept.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Vitreoretinal surgeries are complex procedures that require extreme manual dexterity. Typically, surgeons operate through a stereoscopic microscope viewing the surgical area exclusively from an overhead perspective while manipulating delicate anatomical structures with sub-millimeter precision. In an effort to achieve improved surgical visualization, Optical Coherence Tomography (OCT) has been integrated into surgical microscopes, providing high-resolution depth-resolved imaging. Advances in spiral scanning and swept-source OCT <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b11">12]</ref> even paved the way for real-time volumetric imaging, enabling 4D visualizations of anatomical structures and surgical instruments. With the validation of intraoperative OCT through clinical studies <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>, the emergence of 4D OCT systems prompts the anticipation of more precise and efficient microsurgical treatments. A common task in vitreoretinal surgery is to grasp and peel an Epiretinal Membrane (ERM), a 60 μm <ref type="bibr" target="#b24">[24]</ref> thin layer that forms on top of the retina, while avoiding to damage the on average 250 μm thick retina <ref type="bibr" target="#b10">[11]</ref>.</p><p>GPU-accelerated direct volume rendering (DVR) was shown to be an effective way of visualizing surgical maneuvers, enabling real-time rendering of 4D OCT data on stereo displays <ref type="bibr" target="#b20">[20]</ref>. Instead of viewing the surgical site from the top, as with stereoscopic microscopes, the depth-resolved properties of 4D OCT can be directly and fully utilized when oblique or even more extreme lateral views are provided <ref type="bibr" target="#b5">[6]</ref>. This could even lead to more precise tool-tissue interactions since visualization of the surgical area from alternative viewpoints enables improved distance perception. This can be leveraged for instance when approaching small structures located at or above the retina during ERM or Internal Limiting Membrane (ILM) peeling <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9]</ref>. On the other hand, such setups also introduce new complexities since surgical interaction from a lateral perspective is not common in current ophthalmic procedures. In particular, hand-eye coordination is naturally challenged when navigating instruments to a target from an uncommon view, imposing a higher mental demand on surgeons. To exploit the full potential of the 4D depth-resolved imaging modality, advanced visualization techniques could provide additional guidance and support complex maneuvers.</p><p>For this reason, we propose an Intelligent Virtual B-scan Mirror (IVBM), a novel visualization concept to improve targeted instrument interactions in 4D OCT-guided surgery. As illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>, the concept of an IVBM is inspired by the reflective but at the same time transparent nature of glass. Conceptually, grasping an arbitrarily positioned object in space is challenging in the absence of depth cues. However, the reflections can provide an additional view that aids navigation to the target. Semi-transparency, on the other hand, preserves the background. We transfer this concept to volume raymarching in 4D OCT and integrate a mirror into a selected volume cross-section, which represents a virtual B-scan. While the IVBM highlights volume intensities within this virtual Bscan, it integrates an intelligent mirror, which is only sensitive to voxels that are close to the IVBM and associated with a surgical instrument. Volume structures behind the IVBM are preserved through an adaptive opacity transfer function. In addition, we leverage a perceptually linear color map to encode distance information and enhance the mirrored instrument in the IVBM. Compared to previous works, the proposed method particularly focuses on targeted instrument interactions from alternative viewpoints. The results of our user study provide detailed insights into user perception and interaction with the IVBM and emphasize the benefits for targeted maneuvers in 4D OCT-guided vitreoretinal surgery.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Virtual mirrors have been initially proposed to support spatial perception and provide secondary views of virtual objects in augmented reality <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b19">19]</ref>. Applications have been introduced in angiography or laparoscopic surgery <ref type="bibr" target="#b15">[15,</ref><ref type="bibr" target="#b21">21]</ref> and effectiveness of a mirror view in medical scenarios has been shown in user studies with clinical experts <ref type="bibr" target="#b1">[2]</ref>. Previous works on OCT volume visualization have so far solely focused on depth perception in axial OCT direction. These include applying a color transfer function based on the distance to a central reference depth <ref type="bibr" target="#b2">[3]</ref> or to an identified retinal reference layer <ref type="bibr" target="#b22">[22]</ref>. Other ways of providing spatial cues include the augmentation of 2D OCT B-scans <ref type="bibr" target="#b17">[17]</ref> or sound feedback to convey distance information <ref type="bibr" target="#b13">[14]</ref>.</p><p>As opposed to previous works on perceptual OCT visualization, the IVBM provides depth cues that aid targeted instrument navigation when viewing the surgical scene from a lateral perspective and targeting a specific cross-section, where axial depth perception is not a primary issue. Augmentation methods proposed in previous works are not designed for such scenarios. Previous works on virtual mirrors have mainly been implemented by rendering the scene from an alternative viewpoint and showing the mirror view next to the virtual objects. In contrast, we augment a selective mirror in-situ into a OCT cross-section. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Definition of an Intelligent Virtual B-Scan Mirror</head><p>We define an Intelligent Virtual B-scan Mirror (IVBM) as an augmentation of a selected virtual B-scan, which fulfills the following two requirements: (i) voxels integrated into the IVBM are highlighted in the volume rendering, while still visualized semi-transparent to preserve volume structures behind the IVBM. (ii) The selected B-scan cross-section acts as an intelligent mirror by only being sensitive to voxels associated with the surgical instruments in proximity to the IVBM. As illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>, the IVBM has the advantage of providing depth cues by visualizing the intersection of the instrument with the cross-section, when the instrument tip meets the tip of the mirrored instrument. It is also capable of visualizing instrument structures that are occluded in the direct view or located behind the IVBM cross-section and amplifies target structures that are aligned with the IVBM. The following sections describe the required components, as well as the composition and direct integration of the IVBM in the volume raymarching algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Method Components</head><p>Since the IVBM integrates a mirror that is sensitive only to surgical instruments, mirror candidate voxels need to be identified in the volume. To achieve the realtime processing rates necessary for 4D OCT visualizations, we first identify the instrument in a 2D projection image of the volume. Inspired by <ref type="bibr" target="#b23">[23]</ref>, we create a 2D projection image that encodes the average intensity along each OCT A-scan. This image is forwarded to a Unet-like <ref type="bibr" target="#b16">[16]</ref> convolutional neural network with ResNet34 <ref type="bibr" target="#b9">[10]</ref> backbone to generate a binary instrument map M tool . Since the OCT signal is fully blocked at the instrument surface, the anatomical structures below the instrument are obscured, and the corresponding A-scans contain only instrument-related voxels. Thus, the 3D position of the voxels associated with the instrument can be obtained by the detected A-scans in M tool , as further described in Sect. 3.3. Before forwarding the OCT volume and the instrument map M tool to the DVR algorithm, we additionally process the volume by applying a 3D median filter to reduce the OCT-typical speckle noise. An overview of the method is illustrated in Fig. <ref type="figure" target="#fig_2">3</ref>. With this set of components in place, the composition of the IVBM is fully realized within the DVR algorithm, as described in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Composition of an Intelligent Virtual B-Scan Mirror</head><p>During volume raymarching, if a camera ray #» r c intersects with the IVBM, as shown in Fig. <ref type="figure" target="#fig_2">3</ref>, three components contribute to the resulting ray color: (i) any voxel p m along #» r c that is integrated into the IVBM, (ii) any voxel p v along #» r c behind the IVBM and (iii) the specific voxel p t , at which the mirror ray # » r m intersects with the surgical instrument. We define the IVBM plane M IV BM as any arbitrary, either manually or automatically selected plane and can thus be defined by the general equation:</p><formula xml:id="formula_0">xn x + yn y + zn z + d = 0<label>(1)</label></formula><p>where #» n = (n x , n y , n z ) specifies the normal of the plane. We define a distance threshold d IV BM specifying the thickness of the IVBM. During volume raymarching, a voxel p m with position (p x , p y , p z ) is integrated in the IVBM, if the following condition is fulfilled:</p><formula xml:id="formula_1">|n x p x + n y p y + n z p z + d| n 2 x + n 2 y + n 2 z &lt; d IV BM (2)</formula><p>To visualize the mirror reflections of surgical instruments, a mirror ray # » r m is cast from each point p m obtained by <ref type="bibr" target="#b1">(2)</ref>. The mirror ray direction is determined by:</p><formula xml:id="formula_2"># » r m = #» r c -2 • dot( #» r c , #» n ) • #» n (3)</formula><p>During sampling along # » r m , we leverage the binary map M tool and an intensity threshold t tool = 0.25 (empirically obtained to discard OCT speckle noise), and select the mirrored instrument voxel p t if the following condition is fulfilled:</p><formula xml:id="formula_3">M tool (p t ) == 1 ∧ I(p t ) &gt; t tool (4)</formula><p>To mirror the instrument only when close to the IVBM, we limit the number of sampled steps n steps along # » r m . In case of intersection with an instrument as determined by ( <ref type="formula">4</ref>), the raymarching is terminated and the instrument reflection is augmented in the IVBM plane at p m with color component C pt . In particular, we encode the distance along # » r m between p m at the IVBM and p t at the instrument by employing a perceptually linear color map. We employ the L * a * b * color space similar to <ref type="bibr" target="#b22">[22]</ref> with the following modifications:</p><formula xml:id="formula_4">C L * a * b * (I, δ * ) = γ(I) • (δ * • C 0 + (1 -δ * ) • C 1 )<label>(5)</label></formula><p>where δ * = (i m • 0.7)/n steps is a distance predicate that considers the step index i m ∈ [0, n steps ] along # » r m when reaching the instrument at p t . Further, γ(I) is a scaling factor as introduced in <ref type="bibr" target="#b22">[22]</ref>. Choosing C 0 = (I(p t ), -1.5, 1) and C 1 = (I(p t ), -1.0, -1.0) achieves a color interpolation between blue hue when the instrument is further from the mirror and green hue when close to the mirror. The RGB component of the instrument reflection is then obtained with:</p><formula xml:id="formula_5">Cp t = [RGB(C L * a * b * (I(p t ), δ * (p)))]<label>(6)</label></formula><p>where RGB(C) is an L * a * b * to RGB color space conversion. We additionally decrease the opacity of the reflections with increasing distance of the instrument to the mirror using σ(p t ) = 1.0 -(step m /n steps ) 2 .</p><p>The overall appearance of a voxel at p m , integrating instrument reflections while enhancing the natural intensities in the IVBM plane is finally defined by:</p><formula xml:id="formula_6">C(p m ) = [μ • I(p m ) • (1 -σ(p t )) + Cp t • σ(p t ), α(μI(p m ))]<label>(7)</label></formula><p>In practice, μ is a dynamically modifiable parameter to amplify the volume intensities of the virtual B-scan and α(I) is a conventional piece-wise linear opacity function. During volume raymarching, we use alpha blending to integrate the IVBM with the remaining volume structures as determined by <ref type="bibr" target="#b1">(2)</ref>. In general, voxels p v that are not in the IVBM can be rendered using any convention for direct volume rendering. During our experiments and for the visualizations in Fig. <ref type="figure" target="#fig_1">2</ref> and Fig. <ref type="figure" target="#fig_2">3</ref> we use classic Phong shading as previously employed for OCT volume rendering <ref type="bibr" target="#b20">[20]</ref>. In our visualizations, it provides structural surface details while visually highlighting the IVBM in the final rendering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup and User Study</head><p>System Integration and Time Profiling. To evaluate if IVBMs can be deployed for the live display of 4D OCT data, we implemented the proposed concept in a C++ visualization framework. The 2D projection image generation and IVBMintegrated volume raymarching were implemented using OpenGL 4.6 and tested on a Windows 10 system with Intel Core i7-8700K @3.7 GHz and NVidia RTX 3090Ti GPU. We train our instrument segmentation network on a custom data set consisting of 3356 2D projection images generated from OCT volumes with a resolution of 391×391×644 voxels that contain a synthetic eye model and a surgical forceps and include random rotations and flipping for data augmentation. We use PyTorch 1.13 and TensorRT 8.4 for model training and optimization. The data was labeled by two biomedical engineers. The average overall processing and rendering time, based on 20 test volumes with the same resolution, was 44.3 (±3.1) ms (filter: 8.1 (± 1.2) ms, projection image generation and instrument segmentation: 5.7 (±2.6) ms, rendering: 30.5 (±0.6) ms). These benchmarks were achieved with n steps = 120 mirror sample steps. To demonstrate the live 4D interactions, our method was integrated into the 4D SS-OCT system presented in <ref type="bibr" target="#b3">[4]</ref>, acquiring OCT volumes with resolution 391 × 391 × 644 at 10 Hz volume update rates. In the supplementary materials, we include video recordings of instrument maneuvers in 4D OCT with our IVBM visualizations.</p><p>User Study. To determine if an IVBM could aid users in performing targeted instrument maneuvers under 4D OCT guidance, we conducted a user study in which we asked participants to move the tip of a surgical instrument to defined target locations. To achieve continuous, accurate, and efficient data collection during the study, we employ a virtual environment (Unity 2021.3) with simulated 4D OCT based on the method proposed in <ref type="bibr" target="#b18">[18]</ref>. Additionally, a haptic 3D input device (3D Systems Geomagic Touch) was integrated to navigate the virtual surgical instruments, where motion scaling of 4 : 1 was applied to reduce the influence of the individual manual tremor of the users. Small targets were generated on top of the retina, and the IVBM was automatically positioned at the target locations. To measure the effectiveness of the IVBM when interacting from uncommon perspectives, the virtual scene was rendered from a fixed view approximately orthogonal to the A-scan direction. As stereo vision through a microscope is an inherent part of common ophthalmic procedures, the simulation environment was displayed on an HTC Vive Pro headset leveraging stereo rendering. Users were asked to navigate the instrument tip to the target location and to press a button once satisfied with the positioning. The participants included in total 15 biomedical experts (12 male, 3 female) familiar with ophthalmology and OCT. The study was conducted in accordance with the declaration of Helsinki, the study data were anonymized, and vision tests were performed before the study to ensure healthy vision of all participants. After familiarizing themselves with the interaction in the virtual environment, participants performed 8 trials, with IVBM enabled. For ablation, the same number of trials were performed without IVBM, employing the method proposed in <ref type="bibr" target="#b20">[20]</ref> for 4D OCT DVR with Phong shading as a baseline. The accuracy of the positioning and distance to the target was measured over the progression of the trials. Our results show that users reached the target with an average error of 70 µm (±40 µm) when the IVBM was activated, while in baseline rendering an average error of 135 µm (±128 µm) was measured, suggesting statistically significant differences between the distributions (p &lt; 0.002 based on a Kruskal-Wallis test after detecting unequal variances). Furthermore, we analyzed the distance between the instrument tip and the target with respect to the progress of the trial. Figure <ref type="figure" target="#fig_3">4a</ref> shows that when the IVBM was enabled, the deviation of the distance error continuously decreased, especially in the last quarter of the trial progressions, resulting in both more accurate and precise targeting. The outcomes of the NASA-TLX survey (Fig. <ref type="figure" target="#fig_3">4b</ref>) conducted after the study showed improvements in all categories when the IVBM was activated. However, statistical significance could only be found in the categories performance (p &lt; 0.001) and physical demand (p &lt; 0.02) based on an ANOVA test for equal variances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion and Conclusion</head><p>Discussion. When users were provided an IVBM, statistically significant improvements regarding the targeting error were found. In a clinical setting, such as during retinal membrane peeling, similar improvements could make a substantial difference and may lead to a safer and more efficient treatment. The results of the subjective task load assessment were also overall improved when the IVBM was enabled, however, statistical significance could not be obtained in categories such as mental demand or frustration. Potential depth conflicts could be investigated in further studies and evaluated with clinical experts. Interestingly, a higher targeting accuracy was achieved with IVBM, even in cases when users reported a higher effort or judged their performance inferior compared to baseline. An advantage of the IVBM is direct in-situ visualization that also highlights target structures, as users do not need to move their gaze from the surgical area to perceive the mirrored view. We envision an automatic identification of anatomical targets to find optimal IVBM positioning in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion.</head><p>We presented a novel visualization concept that augments a selected volume cross-section with an intelligent virtual mirror for targeted instrument navigation in 4D OCT. We have provided a definition and implementation of an IVBM and demonstrated its potential to effectively support surgical tasks and to be integrated into a 4D OCT system. We demonstrated the IVBM in simulated vitreoretinal surgery, however, we intend to further apply this concept also to other 4D medical imaging modalities.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. (a) In daily life, navigating an instrument to a target is challenging without visual cues for distance perception. (b) Mirrors can provide additional views for improved targeting, see the reflection of the tweezers in the glass. (c) In 4D OCTguided retinal surgery, navigating to a target is challenging from oblique views. (d) Our IVBM (outlined in green) leverages visual cues inspired by the reflective but transparent behavior illustrated in (b) for 4D OCT visualizations. (Color figure online)</figDesc><graphic coords="2,55,98,54,23,340,24,91,48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The advantages of an IVBM include: (i) only voxels associated with surgical instruments are mirrored, while a perceptually linear color scheme is applied, which encodes the mirror distance (left), (ii) occluded instrument parts are visualized in the mirror view (middle) and (iii) the mirror is semi-transparent and integrated into a volume cross-section, visualizing tool and tissue structures behind it (right). The examples presented in this Figure show the IVBM outlined in green for better illustration.</figDesc><graphic coords="3,41,79,54,32,340,24,111,37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Method overview: an OCT volume and a 2D instrument segmentation map are provided to the DVR algorithm. During volume raymarching, voxel intensities at the IVBM plane are highlighted and rendered transparent while intersections of the mirror ray with the instrument are integrated using a perceptually linear color map.</figDesc><graphic coords="4,74,97,206,72,305,80,124,60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Distance to the target over the course of the trial progression (a). Results of the subjective task load index based on NASA-TLX (b).</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This work is partially supported and the data is provided by <rs type="funder">Carl Zeiss Meditec</rs>. The authors wish to thank SynthesEyes (https://syntheseyes.de) for providing the excellent simulation setup for the user study.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43996-4_40.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The virtual mirror: a new interaction paradigm for augmented reality environments</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bichlmeier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Heining</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Feuerstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1498" to="1510" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Laparoscopic virtual mirror for understanding vessel structure evaluation study by twelve surgeons</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bichlmeier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Heining</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rustaee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="125" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Depth-based, motion-stabilized colorization of microscope-integrated optical coherence tomography volumes for microscope-independent microsurgery</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">D</forename><surname>Bleicher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jackson-Atogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Viehland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gabr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Izatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Toth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transl. Vis. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Surgical microscope integrated MHz SS-OCT with live volumetric visualization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Britten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomed. Optics Express</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="846" to="865" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Constant linear velocity spiral scanning for near video rate 4d oct ophthalmic and surgical imaging with isotropic transverse sampling</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">M</forename><surname>Carrasco-Zevallos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Viehland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Mcnabb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Izatt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomed. Optics Express</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">5052</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Teleoperating robots from arbitrary viewpoints in surgical contexts</title>
		<author>
			<persName><forename type="first">M</forename><surname>Draelos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Toth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Izatt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2549" to="2555" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Outcomes of intraoperative oct-assisted epiretinal membrane surgery from the pioneer study</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Ehlers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ophthalmol. Retina</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="263" to="267" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The DISCOVER study 3-year results: feasibility and usefulness of microscope-integrated intraoperative oct during ophthalmic surgery</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Ehlers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ophthalmology</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1014" to="1027" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Intrasurgical microscope-integrated spectral domain optical coherence tomography-assisted membrane peeling</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">I</forename><surname>Falkner-Radler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Glittenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Binder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Retina</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2100" to="2106" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Diurnal variation of retina thickness measured with time domain and spectral domain optical coherence tomography in healthy subjects</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">J</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Heo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">I</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Invest. Ophthalmol. Vis. Sci</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="6497" to="6500" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Live video rate volumetric OCT imaging of the retina with multi-MHz a-scan rates</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Kolb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">213144</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">vMirror: enhancing the interaction with occluded or distant objects in VR with virtual mirrors</title>
		<author>
			<persName><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2021 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Surgical Soundtracks: towards automatic musical augmentation of surgical procedures</title>
		<author>
			<persName><forename type="first">S</forename><surname>Matinfar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI 2017</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Descoteaux</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Maier-Hein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Franz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Jannin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Collins</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Duchesne</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">10434</biblScope>
			<biblScope unit="page" from="673" to="681" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Cham</forename><surname>Springer</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-66185-8_76</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-66185-8_76" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Laparoscopic virtual mirror new interaction paradigm for monitor based augmented reality</title>
		<author>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Feuerstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bichlmeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Virtual Reality Conference</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007">2007. 2007</date>
			<biblScope unit="page" from="43" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">U-Net: convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-24574-4_28</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-24574-4_28" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2015</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hornegger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">9351</biblScope>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Introducing augmented reality to optical coherence tomography in ophthalmic microsurgery</title>
		<author>
			<persName><forename type="first">H</forename><surname>Roodaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Filippatos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Symposium on Mixed and Augmented Reality</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Surgical scene generation and adversarial networks for physics-based iOCT synthesis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sommersperger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomed. Optics Express</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2414" to="2430" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Embedded virtual views for augmented reality navigation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tatzgern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kalkofen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grasset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schmalstieg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium Mixed Augmented Reality-Workshop Visualization in Mixed Reality Environments</title>
		<meeting>the International Symposium Mixed Augmented Reality-Workshop Visualization in Mixed Reality Environments</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page">123</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Enhanced volumetric visualization for real time 4D intraoperative ophthalmic swept-source OCT</title>
		<author>
			<persName><forename type="first">C</forename><surname>Viehland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomed. Optics Express</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1815" to="1829" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Augmented reality during angiography: integration of a virtual mirror for improved 2D/3D visualization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fallavollita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kreiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="257" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Layer-aware iOCT volume rendering for retinal surgery</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Eck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Nasseri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics Workshop on Visual Computing for Biology and Medicine. The Eurographics Association</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Kozlíková</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Linsen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Vázquez</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Lawonn</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Raidou</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Processing-aware real-time rendering for optimized tissue visualization in intraoperative 4D OCT</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sommersperger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nasseri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Eck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59722-1_26</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-59722-1_26" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12265</biblScope>
			<biblScope unit="page" from="267" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Characterization of epiretinal membranes using optical coherence tomography</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Wilkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ophthalmology</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2142" to="2151" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
