<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">How Does Pruning Impact Long-Tailed Multi-label Medical Image Classifiers?</title>
				<funder ref="#_upXwF7h">
					<orgName type="full">NSF CAREER</orgName>
				</funder>
				<funder>
					<orgName type="full">Amazon Research Award</orgName>
				</funder>
				<funder ref="#_D9dU3f9">
					<orgName type="full">National Library of Medicine</orgName>
				</funder>
				<funder>
					<orgName type="full">Intramural Research Programs of the National Institutes of Health, Clinical Center</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Gregory</forename><surname>Holste</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Texas at Austin</orgName>
								<address>
									<settlement>Austin</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ziyu</forename><surname>Jiang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Texas A&amp;M University</orgName>
								<address>
									<settlement>College Station</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ajay</forename><surname>Jaiswal</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Texas at Austin</orgName>
								<address>
									<settlement>Austin</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Maria</forename><surname>Hanna</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Weill Cornell Medicine</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shlomo</forename><surname>Minkowitz</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Weill Cornell Medicine</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alan</forename><forename type="middle">C</forename><surname>Legasto</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Weill Cornell Medicine</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Joanna</forename><forename type="middle">G</forename><surname>Escalon</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Weill Cornell Medicine</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sharon</forename><surname>Steinberger</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Weill Cornell Medicine</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mark</forename><surname>Bittman</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Weill Cornell Medicine</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><forename type="middle">C</forename><surname>Shen</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Clinical Center</orgName>
								<orgName type="institution">National Institutes of Health</orgName>
								<address>
									<settlement>Bethesda</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ying</forename><surname>Ding</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Texas at Austin</orgName>
								<address>
									<settlement>Austin</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ronald</forename><forename type="middle">M</forename><surname>Summers</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Clinical Center</orgName>
								<orgName type="institution">National Institutes of Health</orgName>
								<address>
									<settlement>Bethesda</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">George</forename><surname>Shih</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Weill Cornell Medicine</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yifan</forename><surname>Peng</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Weill Cornell Medicine</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Texas at Austin</orgName>
								<address>
									<settlement>Austin</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">How Does Pruning Impact Long-Tailed Multi-label Medical Image Classifiers?</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="663" to="673"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">DA2EDFB61235480241BD218266E27164</idno>
					<idno type="DOI">10.1007/978-3-031-43904-9_64</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-13T19:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Pruning</term>
					<term>Chest X-Ray</term>
					<term>Imbalance</term>
					<term>Long-Tailed Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Pruning has emerged as a powerful technique for compressing deep neural networks, reducing memory usage and inference time without significantly affecting overall performance. However, the nuanced ways in which pruning impacts model behavior are not well understood, particularly for long-tailed, multi-label datasets commonly found in clinical settings. This knowledge gap could have dangerous implications when deploying a pruned model for diagnosis, where unexpected model behavior could impact patient well-being. To fill this gap, we perform the first analysis of pruning's effect on neural networks trained to diagnose thorax diseases from chest X-rays (CXRs). On two large CXR datasets, we examine which diseases are most affected by pruning and characterize class "forgettability" based on disease frequency and co-occurrence behavior. Further, we identify individual CXRs where uncompressed and heavily pruned models disagree, known as pruning-identified exemplars (PIEs), and conduct a human reader study to evaluate their unifying qualities. We find that radiologists perceive PIEs as having more label noise, lower image quality, and higher diagnosis difficulty. This work represents a first step toward understanding the impact of pruning on model behavior in deep long-tailed, multi-label medical image classification. All code, model weights, and data access instructions can be found at https://github.com/VITA-Group/PruneCXR.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Deep learning has enabled significant progress in image-based computer-aided diagnosis <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b32">33]</ref>. However, the increasing memory requirements of deep neural networks limit their practical deployment in hardware-constrained environments. One promising approach to reducing memory usage and inference latency is model pruning , which aims to remove redundant or unimportant model weights <ref type="bibr" target="#b20">[21]</ref>. Since modern deep neural networks are often overparameterized, they can be heavily pruned with minimal impact on overall performance <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b33">34]</ref>. This being said, the impact of pruning on model behavior beyond high-level performance metrics like top-1 accuracy remain unclear. This gap in understanding has major implications for real-world deployment of neural networks for high-risk tasks like disease diagnosis, where pruning may cause unexpected consequences that could potentially threaten patient well-being.</p><p>To bridge this gap, this study aims to answer the following guiding questions by conducting experiments to dissect the differential impact of pruning: Q1. What is the impact of pruning on overall performance in longtailed multi-label medical image classification? Q2. Which disease classes are most affected by pruning and why? Q3. How does disease co-occurrence influence the impact of pruning? Q4. Which individual images are most vulnerable to pruning?</p><p>We focus our experiments on thorax disease classification on chest X-rays (CXRs), a challenging long-tailed and multi-label computer-aided diagnosis problem, where patients may present with multiple abnormal findings in one exam and most findings are rare relative to the few most common diseases <ref type="bibr" target="#b11">[12]</ref>.</p><p>This study draws inspiration from Hooker et al. <ref type="bibr" target="#b12">[13]</ref>, who found that pruning disparately impacts a small subset of classes in order to maintain overall performance. The authors also introduced pruning-identified exemplars (PIEs), images where an uncompressed and heavily pruned model disagree. They discovered that PIEs share common characteristics such as multiple salient objects and noisy, fine-grained labels. While these findings uncover what neural networks "forget" upon pruning, the insights are limited to highly curated natural image datasets where each image belongs to one class. Previous studies have shown that pruning can enhance fairness <ref type="bibr" target="#b30">[31]</ref>, robustness <ref type="bibr" target="#b0">[1]</ref>, and efficiency for medical image classification <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b31">32]</ref> and segmentation <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b28">29]</ref> tasks. However, these efforts also either focused solely on high-level performance or did not consider settings with severe class imbalance or co-occurrence.</p><p>Unlike existing work, we explicitly connect class "forgettability" to the unique aspects of our problem setting: disease frequency (long-tailedness) and disease cooccurrence (multi-label behavior). Since many diagnostic exams, like CXR, are long-tailed and multi-label, this work fills a critical knowledge gap enabling more informed deployment of pruned disease classifiers. We hope that our findings can provide a foundation for future research on pruning in clinically realistic settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Preliminaries</head><p>Datasets. For this study, we use expanded versions of NIH ChestXRay14 <ref type="bibr" target="#b29">[30]</ref> and MIMIC-CXR <ref type="bibr" target="#b17">[18]</ref>, two large-scale CXR datasets for multi-label disease classification. <ref type="foot" target="#foot_0">1</ref> As described in Holste et al. <ref type="bibr" target="#b11">[12]</ref>, we augmented the set of possible labels for each image by adding five new rare disease findings parsed from radiology reports. This creates a challenging long-tailed classification problem, with training class prevalence ranging from under 100 to over 70,000 (Supplement). NIH-CXR-LT contains 112,120 CXRs, each labeled with at least one of 20 classes, while MIMIC-CXR-LT contains 257,018 frontal CXRs labeled with at least one of 19 classes. Each dataset was split into training (70%), validation (10%), and test (20%) sets at the patient level.</p><p>Model Pruning &amp; Evaluation. Following Hooker et al. <ref type="bibr" target="#b12">[13]</ref>, we focus on global unstructured L1 pruning <ref type="bibr" target="#b33">[34]</ref>. After training a disease classifier, a fraction k of weights with the smallest magnitude are "pruned" (set to zero); for instance, k = 0.9 means 90% of weights have been pruned. While area under the receiver operating characteristic curve is a standard metric on related datasets <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b29">30]</ref>, it can become heavily inflated in the presence of class imbalance <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5]</ref>. Since we seek a metric that is both resistant to imbalance and captures performance across thresholds (as choosing a threshold is non-trivial in the multi-label setting <ref type="bibr" target="#b26">[27]</ref>), we use average precision (AP) as our primary metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Assessing the Impact of Pruning</head><p>Experimental Setup. We first train a baseline model to classify thorax diseases on both NIH-CXR-LT and MIMIC-CXR-LT. The architecture used was a ResNet50 <ref type="bibr" target="#b8">[9]</ref> with ImageNet-pretrained weights and a sigmoid cross-entropy loss. For full training details, please see the Supplemental Materials and code repository. Following Hooker et al. <ref type="bibr" target="#b12">[13]</ref>, we then repeat this process with 30 unique random initializations, performing L1 pruning at a range of sparsity ratios k ∈ {0, 0.05, . . . , 0.9, 0.95} on each model and dataset. Using a "population" of 30 models allows for reliable estimation of model performance at each sparsity ratio. We then analyze how pruning impacts overall, disease-level, and image-level model behavior with increasing sparsity as described below.</p><p>Overall and Class-Level Analysis. To evaluate the overall impact of pruning, we compute the mean AP across classes for each sparsity ratio and dataset. We use Welch's t-test to assess performance differences between the 30 uncompressed models and 30 k-sparse models. We then characterize the class-level impact of pruning by considering the relative change in AP from an uncompressed model to its k-sparse counterpart for all k. Using relative change in AP allows for comparison of the impact of pruning regardless of class difficulty. We then define the forgettability curve of a class c as follows: med AP i,k,c -AP i,0,c AP i,0,c i∈{1,...,30} k∈{0,0.05,...,0.9,0.95} <ref type="bibr" target="#b0">(1)</ref> where AP i,k,c := AP of the i th model with sparsity k on class c, and med(•) := median across all 30 runs. We analyze how these curves relate to class frequency and co-occurrence using Pearson (r) and Spearman (ρ) correlation tests. Incorporating Disease Co-occurrence Behavior. For each unique pair of NIH-CXR-LT classes, we compute the Forgettability Curve Dissimilarity (FCD), the mean squared error (MSE) between the forgettability curves of each disease. FCD quantifies how similar two classes are with respect to their forgetting behavior over all sparsity ratios. Ordinary least squares (OLS) linear regression is employed to understand the interaction between difference in class frequency and class co-occurrence with respect to FCD for a given disease pair.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Pruning-Identified Exemplars (PIEs)</head><p>Definition. After evaluating the overall and class-level impact of pruning on CXR classification, we investigate which individual images are most vulnerable to pruning. Like Hooker et al. <ref type="bibr" target="#b12">[13]</ref>, we consider PIEs to be images where an uncompressed and pruned model disagree. Letting C be the number of classes, we compute the average prediction 1 30 i ŷ0 ∈ R C of the uncompressed models and average prediction 1 30 i ŷ0.9 ∈ R C of the L1-pruned models at 90% sparsity for all NIH-CXR-LT test set images. Then the Spearman rank correlation σ( 1 30 i ŷ0 , 1 30 i ŷ0.9 ) represents the agreement between the uncompressed and heavily pruned models for each image; we define PIEs as images whose correlation falls in the bottom 5 th percentile of test images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis and Human Study.</head><p>To understand the common characteristics of PIEs, we compare how frequently (i) each class appears and (ii) images with d = 0, . . . , 3, 4+ simultaneous diseases appear in PIEs relative to non-PIEs. To further analyze qualities of CXRs that require domain expertise, we conducted a human study to assess radiologist perceptions of PIEs. Six board-certified attending radiologists were each presented with a unique set of 40 CXRs (half PIE, half non-PIE). Each image was presented along with its ground-truth labels and the following three questions:  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">What is the Overall Effect of Pruning?</head><p>We find that under L1 pruning, the first sparsity ratio causing a significant drop in mean AP is 65% for NIH-CXR-LT (P &lt; 0.001) and 60% for MIMIC-CXR-LT (P &lt; 0.001) (Fig. <ref type="figure" target="#fig_1">1,</ref><ref type="figure">left</ref>). This observation may be explained by the fact that ResNet50 is highly overparameterized for this task. Since only a subset of weights are required to adequately model the data, the trained classifiers have naturally sparse activations (Fig. <ref type="figure" target="#fig_0">1</ref>, right). For example, over half of all learned weights have magnitude under 0.01. However, beyond a sparsity ratio of 60%, we observe a steep decline in performance with increasing sparsity for both datasets.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Which Diseases are Most Vulnerable to Pruning and Why?</head><p>Class forgettability curves in Fig. <ref type="figure" target="#fig_2">2</ref> depict the relative change in AP by sparsity ratio for a representative subset of classes. Although these curves follow a similar general trend to Fig. <ref type="figure" target="#fig_0">1</ref>, some curves (i) drop earlier and (ii) drop more considerably at high sparsity. Notably, we find a strong positive relationship between training class frequency and (i) the first sparsity ratio at which a class experienced a median 20% relative drop in AP (ρ = 0.61, P = 0.005 for NIH-CXR-LT; ρ = 0.93, P 0.001 for MIMIC-CXR-LT) and (ii) the median relative change in AP at 95% sparsity (ρ = 0.75, P &lt; 0.001 for NIH-CXR-LT; ρ = 0.75, P &lt; 0.001 for MIMI-CXR-LT). These findings indicate that, in general, rare diseases are forgotten earlier (Fig. <ref type="figure" target="#fig_3">3</ref>, left) and are more severely impacted at high sparsity (Fig. <ref type="figure" target="#fig_3">3</ref>, right).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">How Does Disease Co-occurrence Influence Class Forgettability?</head><p>Our analysis reveals that for NIH-CXR-LT, the absolute difference in log test frequency between two diseases is a strong predictor of the pair's FCD (ρ = 0.64, P 0.001). This finding suggests that diseases with larger differences in prevalence exhibit more distinct forgettability behavior upon L1 pruning (Fig. <ref type="figure" target="#fig_4">4</ref>, left). To account for the multi-label nature of thorax disease classification, we also explore the relationship between intersection over union (IoU) -a measure of co-occurrence between two diseases -and FCD. Our analysis indicates that the IoU between two diseases is negatively associated with FCD (ρ = -0.47, P 0.001). This suggests that the more two diseases co-occur, the more similar their forgetting trajectories are across all sparsity ratios (Fig. <ref type="figure" target="#fig_4">4</ref>, right). For example, the disease pair (Infiltration, Hernia) has a dramatic difference in prevalence (|LogFreqDiff| = 4.58) and rare co-occurrence (IoU 1/4 = 0.15), resulting in an extremely high FCD for the pair of diseases.</p><p>We also find, however, that there is a push and pull between differences in individual class frequency and class co-occurrence with respect to FCD. To illustrate, consider the disease pair (Emphysema, Pneumomediastinum) marked in black in Fig. <ref type="figure" target="#fig_4">4</ref>. These classes have an absolute difference in log frequency of 2.04, which would suggest an FCD of around 0.58. However, because Emphysema and Pneumomediastinum co-occur relatively often (IoU 1/4 = 0.37), their forgettability curves are more similar than prevalence alone would dictate, resulting in a lower FCD of 0.18. To quantify this effect, we obtain an OLS model that fitted FCD as a function of |LogFreqDiff|, IoU 1/4 , and their interaction: FCD = 0.27+0.21|LogFreqDiff|-0.05(IoU) 1/4 -0.31|LogFreqDiff| * (IoU) 1/4 (2)</p><p>We observe a statistically significant interaction effect between the difference in individual class frequency and class co-occurrence on FCD (β 3 = -0.31, P = 0.005). Thus, for disease pairs with a very large difference in prevalence, the effect of co-occurrence on FCD is even more pronounced (Supplement).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">What Do Pruning-Identified CXRs have in Common?</head><p>For NIH-CXR-LT, we find that PIEs are more likely to contain rare diseases and more likely to contain 3+ simultaneous diseases when compared to non-PIEs (Fig. <ref type="figure" target="#fig_5">5</ref>). The five rarest classes appear 3-15x more often in PIEs than non-PIEs, and images with 4+ diseases appear 3.2x more often in PIEs.</p><p>In a human reader study involving 240 CXRs from the NIH-CXR-LT test set (120 PIEs and 120 non-PIEs), radiologists perceived that PIEs had more label noise, lower image quality, and higher diagnosis difficulty (Fig. <ref type="figure" target="#fig_6">6</ref>). However, due to small sample size and large variability, these differences are not statistically significant. Respondents fully agreed with the label 55% of the time  for PIEs and 57.5% of the time for non-PIEs (P = 0.35), gave an average image quality of 3.6 for PIEs and 3.8 for non-PIEs (P = 0.09), and gave an average diagnosis difficulty of 2.5 for PIEs and 2.05 for non-PIEs (P = 0.25).</p><p>Overall, these findings suggest that pruning identifies CXRs with many potential sources of difficulty, such as containing underrepresented diseases, (partially) incorrect labels, low image quality, and complex disease presentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion and Conclusion</head><p>In conclusion, we conducted the first study of the effect of pruning on multi-label, long-tailed medical image classification, focusing on thorax disease diagnosis in CXRs. Our findings are summarized as follows:</p><p>1. As observed in standard image classification, CXR classifiers can be heavily pruned (up to 60% sparsity) before dropping in overall performance. 2. Class frequency is a strong predictor of both when and how severely a class is impacted by pruning. Rare classes suffer the most. 3. Large differences in class frequency lead to dissimilar "forgettability" behavior and stronger co-occurrence leads to more similar forgettability behavior.</p><p>-Further, we discover a significant interaction effect between these two factors with respect to how similarly pruning impacts two classes.</p><p>4. We adapt PIEs to the multi-label setting, observing that PIEs are far more likely to contain rare diseases and multiple concurrent diseases.</p><p>-A radiologist study further suggests that PIEs have more label noise, lower image quality, and higher diagnosis difficulty.</p><p>It should be noted that this study is limited to the analysis of global unstructured L1 (magnitude-based) pruning, a simple heuristic for post-training network pruning. Meanwhile, other state-of-the-art pruning approaches <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b21">22]</ref> and model compression techniques beyond pruning (e.g., weight quantization <ref type="bibr" target="#b13">[14]</ref> and knowledge distillation <ref type="bibr" target="#b10">[11]</ref>) could be employed to strengthen this work. Additionally, since our experiments only consider the ResNet50 architecture, it remains unclear whether other training approaches, architectures, or compression methods could mitigate the adverse effects of pruning on rare classes. In line with recent work <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b18">19]</ref>, future research may leverage the insights gained from this study to develop an algorithm for improved long-tailed learning on medical image analysis tasks. For example, PIEs could be interpreted as salient, difficult examples that warrant greater weight during training. Conversely, PIEs may just as well be regarded as noisy examples to be ignored, using pruning as a tool for data cleaning.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Overall effect of pruning on disease classification performance. Presented is the mean AP (median across 30 runs) for sparsity ratios k ∈ {0, . . . , 0.95} (left) and log-scale histogram of model weight magnitudes (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>1 .</head><label>1</label><figDesc>Do you fully agree with the given label? [Yes/No] 2. How would you rate the image quality? [1-5 Likert] 3. How difficult is it to properly diagnose this image? [1-5 Likert]We use the Kruskal-Wallis test to evaluate differential perception of PIEs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. "Forgettability curves" depicting relative change in AP (median across 30 runs at each sparsity ratio) upon L1 pruning for a subset of classes.</figDesc><graphic coords="5,105,54,244,88,265,96,94,51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Relationship between class "forgettability" and frequency. We characterize which classes are forgotten first (left) and which are most forgotten (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Mutual relationship between pairs of diseases and their forgettability curves.For each pair of NIH-CXR-LT classes, FCD is plotted against the absolute difference in log frequency (left) and the IoU between the two classes (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Unique characteristics of PIEs. Presented is the ratio of class prevalence (left) and number of diseases per image (right) in PIEs relative to non-PIEs. The dotted line represents the 1:1 ratio (equally frequent in PIEs vs. non-PIEs).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Human study results describing radiologist perception of PIEs vs. non-PIEs. Mean ± standard deviation (error bar) radiologist scores are presented.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>NIH ChestXRay14 can be found here, and MIMIC-CXR can be found here.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. This project was supported by the <rs type="funder">Intramural Research Programs of the National Institutes of Health, Clinical Center</rs>. It also was supported by the <rs type="funder">National Library of Medicine</rs> under Award No. <rs type="grantNumber">4R00LM013001</rs>, <rs type="funder">NSF CAREER</rs> Award No. <rs type="grantNumber">2145640</rs>, <rs type="grantName">Cornell Multi-Investigator Seed Grant</rs> (<rs type="projectName">Peng and Shih</rs>), and <rs type="funder">Amazon Research Award</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_D9dU3f9">
					<idno type="grant-number">4R00LM013001</idno>
				</org>
				<org type="funded-project" xml:id="_upXwF7h">
					<idno type="grant-number">2145640</idno>
					<orgName type="grant-name">Cornell Multi-Investigator Seed Grant</orgName>
					<orgName type="project" subtype="full">Peng and Shih</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43904-9 64.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Enhancing adversarial defense for medical image analysis systems with pruning and attention mechanism</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Phys</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="6198" to="6212" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The relationship between precision-recall and roc curves</title>
		<author>
			<persName><forename type="first">J</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goadrich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="233" to="240" />
		</imprint>
		<respStmt>
			<orgName>ICML</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Stamp: simultaneous training and model pruning for low data regimes in medical image segmentation</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Dinsdale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jenkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Namburete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page">102583</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Automatic searching and pruning of deep neural networks for medical imaging diagnostic</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Fernandes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Yen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="5664" to="5674" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Learning from Imbalanced Data Sets</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>García</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Galar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Prati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Krawczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-98074-4</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-98074-4" />
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>Springer</publisher>
			<pubPlace>Cham</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Frankle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Carbin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.03635</idno>
		<title level="m">The lottery ticket hypothesis: finding sparse, trainable neural networks</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Hierarchical pruning for simplification of convolutional neural networks in diabetic retinopathy classification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hajabdollahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Esfandiarpoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Najarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Samavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Soroushmehr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Engineering in Medicine and Biology Society</title>
		<imprint>
			<biblScope unit="page" from="970" to="973" />
			<date type="published" when="2019">2019</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Radiomics-Guided Global-Local Transformer For Weakly Supervised Pathology Localization in Chest X-rays</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Holste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tewfik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med, Imaging PP</title>
		<imprint>
			<date type="published" when="2022-10">Oct (2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, CVPR</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition, CVPR</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep learning techniques for medical image segmentation: achievements and challenges</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Hesamian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Digit. Imaging</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="582" to="596" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<title level="m">Distilling the knowledge in a neural network</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Long-tailed classification of thorax diseases on chest x-ray: A new benchmark study</title>
		<author>
			<persName><forename type="first">G</forename><surname>Holste</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-17027-0_3</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-17027-03" />
	</analytic>
	<monogr>
		<title level="m">Data Augmentation, Labelling, and Imperfections: Second MICCAI Workshop</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="22" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Hooker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Frome</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.05248</idno>
		<title level="m">What do compressed deep neural networks forget? arXiv preprint</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Quantization and training of neural networks for efficient integerarithmetic-only inference</title>
		<author>
			<persName><forename type="first">B</forename><surname>Jacob</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2704" to="2713" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Attend who is weak: Pruning-assisted medical image localization under sophisticated and implicit imbalances</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jaiswal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Rousseau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<publisher>WACV</publisher>
			<biblScope unit="page" from="4987" to="4996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Neural network pruning for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bollavaram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Delaye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sirasao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robotic Interventions, and Modeling</title>
		<imprint>
			<publisher>SPIE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">2021</biblScope>
			<biblScope unit="page" from="415" to="425" />
		</imprint>
	</monogr>
	<note type="report_type">Image-Guided Procedures</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Self-damaging contrastive learning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Mortazavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4927" to="4939" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">MIMIC-CXR, a de-identified publicly available database of chest radiographs with free-text reports</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Johnson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Pruning-guided curriculum learning for semi-supervised semantic segmentation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="5914" to="5923" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Gmp*: Well-tuned global magnitude pruning can outperform most bert-pruning methods</title>
		<author>
			<persName><forename type="first">E</forename><surname>Kurtic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Alistarh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.06384</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Optimal brain damage</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Solla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inform. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ajanthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.02340</idno>
		<title level="m">Snip: single-shot network pruning based on connection sensitivity</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Automated diagnosing primary open-angle glaucoma from fundus image by simulating human&apos;s grading with deep learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">14080</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">The lighter the better: rethinking transformers in medical image segmentation through adaptive pruning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">T</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.14413</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deep neural network pruning for nuclei instance segmentation in hematoxylin and eosin-stained histological images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mahbod</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Entezari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ellinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Saukh</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-17721-7_12</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-17721-712" />
	</analytic>
	<monogr>
		<title level="m">Applications of Medical Artificial Intelligence: First International Workshop, AMAI 2022, Held in Conjunction with MICCAI 2022</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Shabestari</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Xing</surname></persName>
		</editor>
		<meeting><address><addrLine>Singapore; Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022-09-18">September 18, 2022. 2022</date>
			<biblScope unit="page" from="108" to="117" />
		</imprint>
	</monogr>
	<note>Proceedings</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Chexnet: radiologist-level pneumonia detection on chest -Xrays with deep learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05225</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Long-tail zero and few-shot learning via contrastive pretraining on and for small data</title>
		<author>
			<persName><forename type="first">N</forename><surname>Rethmeier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Augenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Sciences &amp; Mathematics Forum</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2022">2022</date>
			<publisher>MDPI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Chexclusion: fairness gaps in deep chest x-ray classifiers</title>
		<author>
			<persName><forename type="first">L</forename><surname>Seyyed-Kalantari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mcdermott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BIOCOMPUTING 2021: proceedings of the Pacific symposium</title>
		<imprint>
			<publisher>World Scientific</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="232" to="243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Valverde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shatillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tohka</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.13590</idno>
		<title level="m">Sauron u-net: Simple automated redundancy elimination in medical image segmentation via filter pruning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">ChestX-Ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bagheri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Summers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition, CVPR</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3462" to="3471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">FairPrune: achieving fairness through pruning for dermatological disease diagnosis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16431-6_70</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16431-670" />
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer Assisted Intervention -MICCAI 2022: 25th International Conference</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Singapore; Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">September 18-22, 2022. 2022</date>
			<biblScope unit="page" from="743" to="753" />
		</imprint>
	</monogr>
	<note>Proceedings, Part I</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Network pruning for OCT image classification</title>
		<author>
			<persName><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-32956-3_15</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-32956-315" />
	</analytic>
	<monogr>
		<title level="m">Ophthalmic Medical Image Analysis: 6th International Workshop</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</editor>
		<meeting><address><addrLine>Shenzhen, China; Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-10-17">2019. October 17. 2019</date>
			<biblScope unit="page" from="121" to="129" />
		</imprint>
	</monogr>
	<note>OMIA</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A review of deep learning in medical imaging: imaging traits, technology trends, case studies with progress highlights, and future promises</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="820" to="838" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">To prune, or not to prune: exploring the efficacy of pruning for model compression</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.01878</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
