<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Improved Flexibility and Interpretability of Large Vessel Stroke Prognostication Using Image Synthesis and Multi-task Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Minyan</forename><surname>Zeng</surname></persName>
							<email>minyan.zeng@adelaide.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">Australian Institute for Machine Learning</orgName>
								<orgName type="institution">University of Adelaide</orgName>
								<address>
									<settlement>Adelaide</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Public Health</orgName>
								<orgName type="institution">University of Adelaide</orgName>
								<address>
									<settlement>Adelaide</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yutong</forename><surname>Xie</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Australian Institute for Machine Learning</orgName>
								<orgName type="institution">University of Adelaide</orgName>
								<address>
									<settlement>Adelaide</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Minh-Son</forename><surname>To</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Australian Institute for Machine Learning</orgName>
								<orgName type="institution">University of Adelaide</orgName>
								<address>
									<settlement>Adelaide</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Flinders Health and Medical Research Institute</orgName>
								<orgName type="institution" key="instit2">Flinders University</orgName>
								<address>
									<settlement>Bedford Park</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lauren</forename><surname>Oakden-Rayner</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Australian Institute for Machine Learning</orgName>
								<orgName type="institution">University of Adelaide</orgName>
								<address>
									<settlement>Adelaide</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Royal Adelaide Hospital</orgName>
								<address>
									<settlement>Adelaide</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Luke</forename><surname>Whitbread</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Australian Institute for Machine Learning</orgName>
								<orgName type="institution">University of Adelaide</orgName>
								<address>
									<settlement>Adelaide</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">School of Computer and Mathematical Sciences</orgName>
								<orgName type="institution">University of Adelaide</orgName>
								<address>
									<settlement>Adelaide</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Stephen</forename><surname>Bacchi</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Flinders Health and Medical Research Institute</orgName>
								<orgName type="institution" key="instit2">Flinders University</orgName>
								<address>
									<settlement>Bedford Park</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Royal Adelaide Hospital</orgName>
								<address>
									<settlement>Adelaide</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alix</forename><surname>Bird</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Australian Institute for Machine Learning</orgName>
								<orgName type="institution">University of Adelaide</orgName>
								<address>
									<settlement>Adelaide</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Public Health</orgName>
								<orgName type="institution">University of Adelaide</orgName>
								<address>
									<settlement>Adelaide</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Luke</forename><surname>Smith</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Australian Institute for Machine Learning</orgName>
								<orgName type="institution">University of Adelaide</orgName>
								<address>
									<settlement>Adelaide</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Public Health</orgName>
								<orgName type="institution">University of Adelaide</orgName>
								<address>
									<settlement>Adelaide</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rebecca</forename><surname>Scroop</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Royal Adelaide Hospital</orgName>
								<address>
									<settlement>Adelaide</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Timothy</forename><surname>Kleinig</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Royal Adelaide Hospital</orgName>
								<address>
									<settlement>Adelaide</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jim</forename><surname>Jannes</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Royal Adelaide Hospital</orgName>
								<address>
									<settlement>Adelaide</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lyle</forename><forename type="middle">J</forename><surname>Palmer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Australian Institute for Machine Learning</orgName>
								<orgName type="institution">University of Adelaide</orgName>
								<address>
									<settlement>Adelaide</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Public Health</orgName>
								<orgName type="institution">University of Adelaide</orgName>
								<address>
									<settlement>Adelaide</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mark</forename><surname>Jenkinson</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Australian Institute for Machine Learning</orgName>
								<orgName type="institution">University of Adelaide</orgName>
								<address>
									<settlement>Adelaide</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">School of Computer and Mathematical Sciences</orgName>
								<orgName type="institution">University of Adelaide</orgName>
								<address>
									<settlement>Adelaide</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">South Australian Health and Medical Research Institute</orgName>
								<address>
									<settlement>Adelaide</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Improved Flexibility and Interpretability of Large Vessel Stroke Prognostication Using Image Synthesis and Multi-task Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D3D6E82594F5B13972DD21F00752ABBE</idno>
					<idno type="DOI">10.1007/978-3-031-43904-967.</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-13T19:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>While acute ischemic stroke due to large vessel occlusion (LVO) may be life-threatening or permanently disabling, timely intervention with endovascular thrombectomy (EVT) can prove life-saving for affected patients. Appropriate patient selection based on prognostic prediction is vital for this costly and invasive procedure, as not all patients will benefit from EVT. Accurate prognostic prediction for LVO presents a significant challenge. Computed Tomography Perfusion (CTP) maps can provide additional information for clinicians to make decisions. However, CTP maps are not always available due to variations in available equipment, funding, expertise and image quality. To address these gaps, we test (i) the utility of acquired CTP maps in a deep learning prediction model, (ii) the ability to improve flexibility of this model through image synthesis, and (iii) the added benefits of including multi-task learning with a simple clinical task to focus the synthesis on key clinical features. Our results demonstrate that network architectures utilising a full set of images can still be flexibly deployed if CTP maps are unavailable as their benefits can be effectively synthesized from more widely available images (NCCT and CTA). Additionally, such synthesized images may help with interpretability and building a clinically trusted model.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Ischemic stroke caused by large vessel occlusion (LVO) is one of the leading causes of death and disability worldwide <ref type="bibr" target="#b0">[1]</ref>. These occlusions restrict cerebral blood supply, resulting in rapid and irreversible damage to brain tissues. As such, prompt reperfusion treatment is critical to restore blood flow and salvage brain tissues from permanent damage. Endovascular thrombectomy (EVT) is the standard treatment recommended for LVO patients <ref type="bibr" target="#b1">[2]</ref>. However, this treatment is costly and invasive and does not improve prognoses for all LVO patients <ref type="bibr" target="#b2">[3]</ref>. Therefore, it is vital to identify those most likely to benefit from EVT.</p><p>There have been a number of models proposed for the prognostication of LVO in recent years <ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref>. The majority are traditional statistical models using nonimaging data, with the identification of clinical predictors for prognostication having shown limited capability <ref type="bibr" target="#b6">[7]</ref>. A few models incorporate raw image data using deep-learning techniques, while most of these <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref> utilize a single image modality, such as Non-Contrast Computed Tomography (NCCT).</p><p>CT Perfusion (CTP) maps are increasingly utilized for the prediction of LVO outcomes because they offer quantitative information on blood flow and volume in the brain, as well as the arrival time of blood bolus to brain tissues <ref type="bibr" target="#b7">[8]</ref>. This information can show the brain perfusion status and identify the brain tissues that are irreversibly damaged (ischemic core), and those that are potentially salvageable (penumbra) <ref type="bibr" target="#b7">[8]</ref>. In contrast, NCCT images can highlight the ischemic core as these tissues normally appear hypodense and CT angiography (CTA) can illustrate the collateral supply via highlighting vessel structure using a low dose contrast injection <ref type="bibr" target="#b8">[9]</ref>. These two modalities are routinely collected at patients' admission because of their rapid acquisition and high tolerance <ref type="bibr" target="#b1">[2]</ref>. Although the information estimated by NCCT and CTA can reflect the status of blood perfusion to some extent <ref type="bibr" target="#b8">[9]</ref>, these images are not as clinically useful as CTP maps since they do not directly show the most prominent neuropathological changes of ischemic stroke-ischemic core and salvageable penumbra. An example of ischemic changes shown by NCCT, CTA and CTP maps is presented in Fig. <ref type="figure" target="#fig_0">1</ref>, where it can be seen that CTP maps provide clearer visual information, and hence are likely to lead to more accurate and clinically trusted prediction models. As such, it is important to investigate the benefits of incorporating CTP maps into deep learning prediction models. Despite the advantages of CTP maps, several factors have limited their utilization: (i) it is time-consuming to acquire, process and interpret the images <ref type="bibr" target="#b1">[2]</ref>; (ii) poor quality maps are more likely due to motion artefacts and inadequate contrast agent, potentially making them uninterpretable <ref type="bibr" target="#b9">[10]</ref>; and (iii) they require substantial investment to purchase advanced scanners, hire professional staff to run and maintain the scanner, which limits usage in hospitals with limited funding, such as in many rural and remote areas <ref type="bibr" target="#b10">[11]</ref>. Therefore, it will be helpful if the flexibility of models incorporating CTP maps can be improved through image synthesis from commonly available image modalities (e.g., NCCT and CTA). In this way, patients without access to a CTP scanner, or with uninterpretable CTP maps, can still benefit from the prognostic prediction that uses clinically-relevant features of CTP maps to inform treatment selection.</p><p>In recent years, techniques of image synthesis have shown promising potential in medicine <ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref>. However, most of these models have focused on imageto-image conversion tasks. In this paper, we propose a two-stage model that incorporates clinical knowledge for image synthesis and multimodal prognostic prediction. Specifically, in the image synthesis stage, the model was assigned to optimize a joint task, including a generative task, a discriminative task and a clinically-focused task. In the multimodal prognostic prediction stage, the model utilized imaging and non-imaging clinical information for predicting the dichotomised modified Rankin Scale (mRS) score 3 months post-stroke -the main outcome in stroke prognosis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Dataset and Pre-processing</head><p>Data utilized in this research was collected from the Royal Adelaide Hospital, which provides the sole EVT service to all stroke patients in South Australia and Northern Territory. There were 460 LVO patients included in the study, admitted between 01 Dec 2016 and 01 Dec 2021, and treated with EVT with full image modalities (NCCT, CTA and CTP maps). Of these, 256 achieved functional independency (mRS ≤ 2) 3 months post-stroke. The non-imaging data (i.e., age, stroke severity, blood glucose, pre-admission functional status, use of intravenous thrombolysis, onset-to-groin puncture time, stroke hemisphere, and 3-month mRS score) was collected by experienced neurologists and nurses adhering to the standard admission procedure. The study was approved by The Central Adelaide Local Health Network Human Research Ethics Committee.</p><p>The NCCT and CTA images were skull-stripped with the attenuation clipped between 0 and 100 Hounsfield Units (HU) for the NCCT images and 0 and 750 HU for the CTA images. Multimodal CT imaging data, including NCCT, CTA and CTP maps, were acquired using Canon Aquilion ONE scanners. The NCCT and CTA acquisitions have isotropic voxel sizes ranging from 0.4-0.6 mm and 0.4-0.7 mm, respectively. The acquisition voxel size of the CTP maps is 0.4×0.4×4.9 mm 3 . Four CTP maps, including cerebral blood volume (CBV), cerebral blood flow (CBF), mean transit time (MTT), and relative arrival time of contrast (Delay), were selected for their clinical utility, based on consultations with two senior neurologists. To rule out the impact of different brain sizes, affine registration to a CT template was performed for each modality <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref>. The CTP maps were linearly scaled versions of the "true" (quantitative) maps using the within-scan relative values for prognostic prediction, rather than absolute values that may be influenced by a range of nuisance factors (e.g. head size, blood pressure) <ref type="bibr" target="#b16">[17]</ref>. The image intensities for each modality were normalised to the interval of [0,1] by rescaling the min-max range for prognostication. Images were resampled to a 1mm isotropic resolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Models</head><p>Problem Statement. We take</p><formula xml:id="formula_0">X i NCCT , X i CTA , X i CTP , X i Cli var , y mRS i N</formula><p>i=1 to be a set of data for N patients, where X i NCCT , X i CTA , and X i Cli var are the NCCT, CTA and clinical non-imaging data (i.e., age, stroke severity, blood glucose, pre-admission functional status, use of intravenous thrombolysis, and onset-togroin puncture time) for the i th patient. Four CTP maps for the i th patient are denoted by the set X i CTP which is defined as</p><formula xml:id="formula_1">X i CBF , X i CBV , X i MTT , X i</formula><p>Delay . The dichotomized prognostic outcome for the i th patient is denoted by</p><formula xml:id="formula_2">y mRS i defined as {0 if mRS ≤ 2, or 1 if mRS &gt; 2}.</formula><p>We aim to: (i) evaluate the performance of CTP maps in predicting the dichotomized mRS score; and (ii) synthesize the CTP maps using two commonly used image modalities (NCCT and CTA) at admission for prognostic prediction. For the first aim, the model can be written as:</p><formula xml:id="formula_3">ŷ i acq = F acq X i CBF , X i CBV , X i MTT , X i Delay , X i Cli var<label>(1)</label></formula><p>where ŷ i acq is the predicted outcome and F acq is the mapping function from the acquired CTP maps and clinical information to the dichotomized mRS score.</p><p>For the second aim, there are two tasks, including (i) learning a mapping function G for CTP map generation, and (ii) learning a function F syn to map synthetic CTP maps and clinical information to the dichotomized mRS score. That is:</p><formula xml:id="formula_4">Xi CBF , Xi CBV , Xi MTT , Xi Delay = G X i NCCT , X i CTA ,<label>(2)</label></formula><formula xml:id="formula_5">ŷ i syn = F syn Xi CBF , Xi CBV , Xi MTT , Xi Delay , X i Cli var<label>(3)</label></formula><p>where Xi CBF , Xi CBV , Xi MTT , Xi Delay are the predicted CBF, CBV, MTT, and Delay maps and ŷ i syn is the predicted outcome from synthetic CTP maps for the i th patient. To fulfil the second aim, we propose a two-stage deep learning framework, including a clinical-guided synthesis and a multimodal prognostic prediction. The network architecture and loss function are detailed below. Stage 1: Clinical-Guided Synthesis. The method for synthesizing CTP maps utilizes a 3D generative adversarial network (GAN) model, which is illustrated in Fig. <ref type="figure" target="#fig_1">2</ref> -stage 1. The encoder-decoder is a U-net architecture <ref type="bibr" target="#b17">[18]</ref>. The encoder contains one convolutional layer (32 filters) and five 3D-residual blocks (32, 64, 128, 256, 256 filters) with 3 × 3 × 3 kernels. Each convolutional layer in the residual block is followed by instance normalization and LeakyReLU activation. The decoder contains five 3D-residual blocks (128, 64, 32, 32, 4 filters) with 3 × 3 × 3 kernels. After each residual block, features were upsampled and combined with encoder outputs, as usual. NCCT and CTA inputs were concatenated at the channel level. The discriminator contains one convolutional layer (16 filters) and four 3D-residual blocks (32, 64, 128, 256 filters). Real CTP maps and synthetic CTP maps (e.g., X i CBF and Xi CBF ) were input to the discriminator, where two classification heads were designed for: a discriminative task with four fully connected (FC) layers (filters from 128 to 2) to distinguish real from synthetic maps; and a clinical task with a FC layer (filters from 128 to 2) to identify the cerebral hemisphere of the occlusion. The loss function is:</p><formula xml:id="formula_6">Loss Stage1 = Loss mse G X i NCCT , X i CTA , X i CTP -Loss bce D G X i NCCT , X i CTA , 0 + Loss bce D X i CTP , 1 -Loss bce D G X i NCCT , X i CTA , y i hemi + Loss bce D X i CTP , y i hemi (4)</formula><p>where Loss mse and Loss bce calculate the mean square error and the binary cross entropy, respectively. D is a mapping function for discriminative and clinical tasks. y i hemi is the label of the clinical task {0 : occlusion in the left hemishpere; 1 : occlusion in the right hemishpere}. We used the total loss for the set of synthetic CTP maps for backpropagation. Step 1 :</p><formula xml:id="formula_7">Loss img = Loss bce F img Xi CTP , y mRS i (5)</formula><p>Step 2 :</p><formula xml:id="formula_8">Loss logistic = Loss bce F logistic F img Xi CTP , X i Cli var , y mRS i (6)</formula><p>where F img is a mapping function of Xi CTP to a binary mRS score and F logistic is a mapping function of step 1 outputs and X i Cli var to a binary mRS score. Xi</p><formula xml:id="formula_9">CTP is composed of Xi CBF , Xi CBF , Xi MTT , Xi</formula><p>Delay , concatenated as channels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head><p>We performed two sets of experiments in the current study. In the first set of experiments, we compared prognostic prediction performance between models using different modalities, including (i) NCCT and CTA, (ii) CTP maps, (iii) NCCT, CTA and CTP maps, (iv) non-imaging data, (v) NCCT, CTA and nonimaging data, (vi) CTP maps and non-imaging data, and (vii) NCCT, CTA, CTP maps and non-imaging data. Images were input into the models with the architecture described in Sect. 2.2 stage 2, where inputs were replaced with corresponding imaging modalities concatenated at the channel level. In the second set of experiments, we evaluated the quality of the synthetic images and the performance when using them for prognostic prediction. We initially compared our model to four synthesis models: UNET, WGAN, CycleGAN and L2GAN. The L2GAN has the same architecture as our model but is not assigned the additional clinical task in the discriminator. To evaluate the quality of the synthetic images, we compared the structural similarity index measure (SSIM) and peak signalto-noise ratio (PSNR) between synthesis models. Area under the ROC curve (AUC), accuracy (ACC), and F1-Score were used to assess the performance of prognostic prediction. We also compared our model to three state-of-the-art models that used raw images and clinical non-imaging data <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>. We randomly split the data into a training and a testing dataset. We used 4-fold cross-validation for training. For image synthesis, the models were trained for 200 epochs with a batch size of 4 using the Adam optimizer with learning rates of 2 × 10 -4 and 2 × 10 -5 for the generator and discriminator, respectively. For prognostic prediction, models with image inputs were trained for 100 epochs with a batch size of 4 using the Adam optimizer with a learning rate of 1 × 10 -5 . All of the models were trained independently. The experiments above were implemented using PyTorch on the NVIDIA 3090 24GB GPU. Logistic regression models were trained with hyperparameters using grid search (Supplementary Table <ref type="table" target="#tab_0">S1</ref>) based on Scikit-learn.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Results of Image Synthesis and Prognostic Prediction</head><p>Data Modalities for Prognostic Prediction. The performance of models using different combinations of data modalities is shown in Figs. <ref type="figure">3</ref> and<ref type="figure">4</ref> and supplementary Table <ref type="table" target="#tab_1">S2</ref>. Models that included CTP maps clearly had better performance (Fig. <ref type="figure">3</ref>). When non-imaging data were incorporated into the models (Fig. <ref type="figure">4</ref>), those with CTP maps outperformed those without. This demonstrates that the inclusion of CTP maps can increase the performance of prognostic prediction. The validation results are similar to these test data results (Table <ref type="table" target="#tab_1">S2</ref>). Synthetic CTP Maps for Prognostic Prediction. The model incorporating the CTP maps generated by our proposed method shows the best performance of prognostic prediction compared to other synthesis methods (Table <ref type="table" target="#tab_1">2</ref>). This indicates that the inclusion of another clinical task can improve the outcome prediction. Also, the predictive performance of our synthetic maps is considerably closer to that of the acquired maps (bottom row) (ROC curves shown in Supplementary Fig. <ref type="figure" target="#fig_1">S2</ref>), indicating that the proposed method can recover most of its predictive ability when CTP maps are unavailable. Moreover, our model with the synthetic CTP maps also outperformed three state-of-the-art models trained on our dataset (Table <ref type="table">3</ref>) (ROC curves shown in Supplementary Fig. <ref type="figure" target="#fig_1">S2</ref>). This demonstrates that training strategies incorporating CTP map synthesis may be able to encourage the models to concentrate more on the most clinically relevant features in NCCT and CTA images for outcome prediction. Such training strategies may help build models that not only have better performance but are also clinically trusted, given their ability to demonstrate the replication of key clinical imaging features. Validation set results are similar to these (Supplementary Tables <ref type="table">S3-S5</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>This study demonstrates that CTP maps, which are known to provide critical information for clinicians, also benefit prognostic prediction using deep learning techniques. When CTP maps are not available at hospital admission, their benefits can still be largely retained through image synthesis. Using multi-task learning with a simple clinical task, our model outperformed other synthesis methods in both image quality and the performance of prognostic prediction.</p><p>Our synthetic CTP maps show key clinical features that are able to be readily discerned upon visual inspection. These findings verify the advantages of including additional CTP maps in LVO prognostication and establish the ability to effectively synthesize such maps to retain their benefits. While we acknowledge that our network architectures are not novel, we highlight the novelty of our architectures for stroke prognostication. The proposed framework can provide significant utility in the future to aid in the selection of patients for high-stakes time-critical EVT, particularly for those who have limited access to advanced imaging. Furthermore, by demonstrating the key clinical imaging features, our framework may improve confidence in building a clinically trusted model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Examples of NCCT, CTA, and two CTP maps</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Overview of the proposed method for image synthesis and prognostic prediction</figDesc><graphic coords="5,47,16,357,74,333,64,117,04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .Fig. 4 .</head><label>34</label><figDesc>Fig. 3. AUCs of models using imaging data only</figDesc><graphic coords="7,71,22,63,11,111,34,64,96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>AUC</head><label></label><figDesc>0 ± 2.5 69.6 ± 3.9 68.0 ± 4.3 UNET 78.3 ± 1.0 69.3 ± 2.4 67.5 ± 3.0 WGAN 78.9 ± 3.3 70.9 ± 5.1 69.5 ± 6.0 CycleGAN 77.8 ± 1.9 70.1 ± 3.4 68.1 ± 3.4 L2GAN 79.5 ± 1.1 71.8 ± 2.0 69.5 ± 1.1 Our method 80.7 ± 1.0 72.0 ± 2.4 70.3 ± 2.0 Acquired CTP 81.8 ± 1.7 73.4 ± 4.2 71.4 ± 3.1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .Table 3 . 6 Samak 1 Image</head><label>5361</label><figDesc>Fig. 5. Illustration of synthetic CTP maps generated by models (rightmost 5 columns). The dashed squares indicate the location of the lesion in the acquired images (Acq CTP, which is the ground truth for image generation). The solid square indicates the nonischemic regions for comparison. The colour bars show the corresponding CTP values of the colours. Table 3. Performance of models for prediction of 3-month mRS. Bacchi S [4] and Samak Z [5] are state-of-the-art models. The bottom row shows the ideal case for comparison.AUC(%) ACC(%) F1(%)Bacchi S NCCT only<ref type="bibr" target="#b3">[4]</ref> 74.6 ± 3.0 69.6 ± 3.7 63.2 ± 5.9Bacchi SNCCT+CT A<ref type="bibr" target="#b3">[4]</ref> 76.8 ± 0.8 67.9 ± 0.6 63.4 ± 2.6 Samak Z [5] 76.6 ± 0.7 70.4 ± 1.4 63.7 ± 3.1 Our method 80.7 ± 1.0 72.0 ± 2.4 70.3 ± 2.0 Acquired CTP 81.8 ± 1.7 73.4 ± 4.2 71.4 ± 3.1</figDesc><graphic coords="8,98,76,53,90,273,88,151,96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Image quality of five generative models</figDesc><table><row><cell>Models</cell><cell>SSIM (%)</cell><cell></cell><cell></cell><cell></cell><cell>PSNR</cell><cell></cell><cell></cell></row><row><cell></cell><cell>CBF</cell><cell>CBV</cell><cell>MTT</cell><cell>Delay</cell><cell>CBF</cell><cell>CBV</cell><cell>MTT</cell><cell>Delay</cell></row><row><cell>UNET</cell><cell cols="8">75.2 ± 0.5 79.3 ± 0.6 54.4 ± 1.3 61.7 ± 0.5 31.0 ± 0.2 34.7 ± 0.4 20.0 ± 0.1 20.3 ± 0.1</cell></row><row><cell>WGAN</cell><cell cols="8">79.0 ± 1.2 83.2 ± 0.8 46.4 ± 4.0 55.2 ± 2.1 31.0 ± 1.0 34.2 ± 0.5 19.5 ± 0.4 19.1 ± 0.3</cell></row><row><cell cols="9">CycleGAN 80.9 ± 1.2 84.5 ± 1.0 57.7 ± 0.5 66.6 ± 0.5 31.0 ± 0.3 34.1 ± 0.6 19.3 ± 0.1 19.3 ± 0.1</cell></row><row><cell>L2GAN</cell><cell cols="8">82.2 ± 0.3 85.8 ± 0.4 59.8 ± 0.5 67.7 ± 0.7 31.7 ± 0.1 35.1 ± 0.2 19.9 ± 0.3 20.2 ± 0.3</cell></row></table><note><p>Ours 82.5 ± 0.4 86.6 ± 0.2 60.7 ± 0.4 69.2 ± 0.5 31.6 ± 0.3 35.2 ± 0.1 20.0 ± 0.1 20.2 ± 0.1</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Performance of models using acquired NCCT and CTA, and synthetic CTP maps, compared to the ideal case with acquired CTP maps (bottom row), for prediction of 3-month mRS.</figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Ischemic strokes due to large-vessel occlusions contribute disproportionately to stroke-related dependence and death: a review</title>
		<author>
			<persName><forename type="first">K</forename><surname>Malhotra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gornbein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Saver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Neurol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">651</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">2018 guidelines for the early management of patients with acute ischemic stroke: a guideline for healthcare professionals from the</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Powers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Heart Association/American Stroke Association. Stroke</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="46" to="e99" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Endovascular versus medical therapy for large-vessel anterior occlusive stroke presenting with mild symptoms</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Wolman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Stroke</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="324" to="331" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep learning in the prediction of ischaemic stroke thrombolysis functional outcomes: a pilot study</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bacchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zerner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Oakden-Rayner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kleinig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jannes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acad. Radiol</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="19" to="e23" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Transop: transformer-based multimodal classification for stroke treatment outcome prediction</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">A</forename><surname>Samak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Clatworthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mirmehdi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.10829</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Pre-thrombectomy prognostic prediction of large-vessel ischemic stroke using machine learning: a systematic review and meta-analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Neurol</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">945813</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Acute neurological deterioration in large vessel occlusions and mild symptoms managed medically</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Saleem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stroke</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1428" to="1434" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Thrombectomy 6 to 24 hours after stroke with a mismatch between deficit and infarct. New Engl</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Nogueira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Med</title>
		<imprint>
			<biblScope unit="volume">378</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="21" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Time dependence of reliability of noncontrast computed tomography in comparison to computed tomography angiography source image in acute ischemic stroke</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Stroke</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="60" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Comparison of time consumption and success rate between CT angiography-and CT perfusion-based imaging assessment strategy for the patients with acute ischemic stroke</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Automated processing of head CT perfusion imaging for ischemic stroke triage: a practical guide to quality assurance and interpretation</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Allen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Roentgenol</title>
		<imprint>
			<biblScope unit="volume">217</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1401" to="1416" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Generative adversarial networks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="139" to="144" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Wasserstein generative adversarial networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="214" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Unpaired image-to-image translation using cycle-consistent adversarial networks</title>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2223" to="2232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A global optimisation method for robust affine registration of brain images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jenkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="143" to="156" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A publicly available, high resolution, unbiased CT brain template</title>
		<author>
			<persName><forename type="first">J</forename><surname>Muschelli</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-50153-2_27</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-50153-227" />
	</analytic>
	<monogr>
		<title level="m">IPMU 2020</title>
		<editor>
			<persName><forename type="first">M.-J</forename><surname>Lesot</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">1239</biblScope>
			<biblScope unit="page" from="358" to="366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Reproducibility of quantitative CT brain perfusion measurements in patients with symptomatic unilateral carotid artery stenosis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Waaijer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Neuroradiol</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="927" to="932" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">U-net: convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-24574-4_28</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-24574-428" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2015</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hornegger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">9351</biblScope>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
