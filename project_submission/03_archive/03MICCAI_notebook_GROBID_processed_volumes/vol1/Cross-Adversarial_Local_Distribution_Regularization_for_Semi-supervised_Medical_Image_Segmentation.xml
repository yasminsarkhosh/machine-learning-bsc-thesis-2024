<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Cross-Adversarial Local Distribution Regularization for Semi-supervised Medical Image Segmentation</title>
				<funder>
					<orgName type="full">Australian Defence Science and Technology</orgName>
					<orgName type="abbreviated">DST</orgName>
				</funder>
				<funder>
					<orgName type="full">Next Generation Technology Fund</orgName>
					<orgName type="abbreviated">NGTF</orgName>
				</funder>
				<funder ref="#_xx65nMM">
					<orgName type="full">Australian Research Council</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Thanh</forename><surname>Nguyen-Duc</surname></persName>
							<email>thanh.nguyen4@monash.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Monash University</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Trung</forename><surname>Le</surname></persName>
							<email>trunglm@monash.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Monash University</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Roland</forename><surname>Bammer</surname></persName>
							<email>roland.bammer@monash.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Monash University</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">He</forename><surname>Zhao</surname></persName>
							<email>he.zhao@ieee.org</email>
							<affiliation key="aff1">
								<orgName type="laboratory">CSIRO&apos;s Data61</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jianfei</forename><surname>Cai</surname></persName>
							<email>jianfei.cai@monash.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Monash University</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dinh</forename><surname>Phung</surname></persName>
							<email>dinh.phung@monash.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Monash University</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Cross-Adversarial Local Distribution Regularization for Semi-supervised Medical Image Segmentation</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="183" to="194"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">3BA742B49257A02093755D2517A30F23</idno>
					<idno type="DOI">10.1007/978-3-031-43907-0_18</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-13T19:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Semi-supervised segmentation</term>
					<term>Adversarial local distribution</term>
					<term>Adversarial examples</term>
					<term>Cross-adversarial local distribution</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Medical semi-supervised segmentation is a technique where a model is trained to segment objects of interest in medical images with limited annotated data. Existing semi-supervised segmentation methods are usually based on the smoothness assumption. This assumption implies that the model output distributions of two similar data samples are encouraged to be invariant. In other words, the smoothness assumption states that similar samples (e.g., adding small perturbations to an image) should have similar outputs. In this paper, we introduce a novel cross-adversarial local distribution (Cross-ALD) regularization to further enhance the smoothness assumption for semi-supervised medical image segmentation task. We conducted comprehensive experiments that the Cross-ALD archives state-of-the-art performance against many recent methods on the public LA and ACDC datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Medical image segmentation is a critical task in computer-aided diagnosis and treatment planning. It involves the delineation of anatomical structures or pathological regions in medical images, such as magnetic resonance imaging (MRI) or computed tomography (CT) scans. Accurate and efficient segmentation is essential for various medical applications, including tumor detection, surgical planning, and monitoring disease progression. However, manual medical imaging annotation is time-consuming and expensive because it requires the domain knowledge from medical experts. Therefore, there is a growing interest in developing semi-supervised learning that leverages both labeled and unlabeled data to improve the performance of image segmentation models <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b27">27]</ref>.</p><p>Existing semi-supervised segmentation methods exploit smoothness assumption, e.g., the data samples that are closer to each other are more likely to to have the same label. In other words, the smoothness assumption encourages the model to generate invariant outputs under small perturbations. We have seen such perturbations being be added to natural input images at data-level <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21]</ref>, feature-level <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b23">23,</ref><ref type="bibr" target="#b25">25]</ref>, and model-level <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b28">28]</ref>. Among them, virtual adversarial training (VAT) <ref type="bibr" target="#b13">[14]</ref> is a well-known one which promotes the smoothness of the local output distribution using adversarial examples. The adversarial examples are near decision boundaries generated by adding adversarial perturbations to natural inputs. However, VAT can only create one adversarial sample in a run, which is often insufficient to completely explore the space of possible perturbations (see Sect. 2.1). In addition, the adversarial examples of VAT can also lie together and lose diversity that significantly reduces the quality of adversarial examples <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b19">20]</ref>. Mixup regularization <ref type="bibr" target="#b29">[29]</ref> is a data augmentation method used in deep learning to improve model generalization. The idea behind mixup is to create new training examples by linearly interpolating between pairs of existing examples and their corresponding labels, which has been adopted in <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b18">19]</ref> to semi-supervised learning. The work <ref type="bibr" target="#b4">[5]</ref> suggests that Mixup improves the smoothness of the neural function by bounding the Lipschitz constant of the gradient function of the neural networks. However, we show that mixing between more informative samples (e.g., adversarial examples near decision boundaries) can lead to a better performance enhancement compared to mixing natural samples (see Sect. <ref type="bibr">3.3)</ref>.</p><p>In this paper, we propose a novel cross-adversarial local distribution regularization for semi-supervised medical image segmentation for smoothness assumption enhancement<ref type="foot" target="#foot_0">1</ref> . Our contributions are summarized as follows: 1) To overcome the VAT's drawback, we formulate an adversarial local distribution (ALD) with Dice loss function that covers all possible adversarial examples within a ball constraint. 2) To enhance smoothness assumption, we propose a novel cross-adversarial local distribution regularization (Cross-ALD) to encourage the smoothness assumption, which is a random mixing between two ALDs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3)</head><p>We also propose a sufficiently approximation for the Cross-ALD by a multiple particle-based search using semantic feature Stein Variational Gradient Decent (SVGDF), an enhancement of the vanilla SVGD <ref type="bibr" target="#b9">[10]</ref>. 4) We conduct comprehensive experiments on ADCD <ref type="bibr" target="#b0">[1]</ref> and LA <ref type="bibr" target="#b26">[26]</ref> datasets, showing that our Cross-ALD regularization achieves state-of-the-art performance against existing solutions <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b22">22,</ref><ref type="bibr" target="#b28">28]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>In this section, we begin by reviewing the minimax optimization problem of virtual adversarial training (VAT) <ref type="bibr" target="#b13">[14]</ref>. Given an input, we then formulate a novel adversarial local distribution (ALD) with Dice loss, which benefits the medical semi-supervised image segmentation problem specifically. Next, a crossadversarial local distribution (Cross-ALD) is constructed by randomly combining two ALDs. We approximate the ALD by a particle-based method named semantic feature Stein Variational Gradient Descent (SVGDF). Considering the resolution of medical images are usually high, we enhance the vanilla SVGD <ref type="bibr" target="#b9">[10]</ref> from data-level to feature-level, which is named SVGDF. We finally provide our regularization loss for semi-supervised medical image segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The Minimax Optimization of VAT</head><p>Let D l and D ul be the labeled and unlabeled dataset, respectively, with P D l and P D ul being the corresponding data distribution. Denote x ∈ R d as our ddimensional input in a space X. The labeled image x l and segmentation groundtruth y are sampled from the labeled dataset D l (x l , y ∼ P D l ), and the unlabeled image sampled from D ul is x ∼ P D ul .</p><p>Given an input x ∼ P D ul (i.e., the unlabeled data distribution), let us denote the ball constraint around the image x as</p><formula xml:id="formula_0">C (x) = {x ∈ X : ||x -x|| p ≤ },</formula><p>where is a ball constraint radius with respect to a norm || • || p , and x is an adversarial example<ref type="foot" target="#foot_1">2</ref> . Given that f θ is our model parameterized by θ, VAT <ref type="bibr" target="#b13">[14]</ref> trains the model with the loss of vat that a minimax optimization problem:</p><formula xml:id="formula_1">vat := min θ E x∼P D ul max x ∈C (x) D KL (f θ (x ), f θ (x)) , (<label>1</label></formula><formula xml:id="formula_2">)</formula><p>where D KL is the Kullback-Leibler divergence. The inner maximization problem is to find an adversarial example near decision boundaries, while the minimization problem enforces the local smoothness of the model. However, VAT is insufficient to explore the set of of all adversarial examples within the constraint C because it only find one adversarial example x given a natural input x. Moreover, the works <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b19">20]</ref> show that even solving the maximization problem with random initialization, its solutions can also lie together and lose diversity, which significantly reduces the quality of adversarial examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Adversarial Local Distribution</head><p>In order to overcome the drawback of VAT, we introduce our proposed adversarial local distribution (ALD) with Dice loss function instead of D KL in <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15]</ref>. ALD forms a set of all adversarial examples x within the ball constraint given an input x. Therefore, the distribution can helps to sufficiently explore all possible adversarial examples. The adversarial local distribution P θ (x |x) is defined with a ball constraint C as follow:</p><formula xml:id="formula_3">P θ (x |x) := e Dice(x ,x;θ) C (x) e Dice(x ,x;θ) dx = e Dice(x ,x;θ) Z(x; θ) ,<label>(2)</label></formula><p>where P θ (•|x) is the conditional local distribution, and Z(x; θ) is a normalization function. The Dice is the Dice loss function as shown in Eq. 3</p><formula xml:id="formula_4">Dice (x , x; θ) = 1 C C c=1 [1 - 2||p θ ( ŷc |x) ∩ p θ ( ỹc |x )|| ||p θ ( ŷc |x) + p θ ( ỹc |x )|| ],<label>(3)</label></formula><p>where C is the number of classes. p θ ( ŷc |x) and p θ ( ỹc |x ) are the predictions of input image x and adversarial image x , respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Cross-Adversarial Distribution Regularization</head><p>Given two random samples x i , x j ∼ P D (i = j), we define the cross-adversarial distribution (Cross-ALD) denoted Pθ as shown in Eq. 4</p><formula xml:id="formula_5">Pθ (•|x i , x j ) = γP θ (•|x i ) + (1 -γ)P θ (•|x j )<label>(4)</label></formula><p>where γ ∼ Beta(α, α) for α ∈ (0, ∞), inspired by <ref type="bibr" target="#b29">[29]</ref>. The Pθ is the Cross-ALD distribution, a mixture between the two adversarial local distributions. Given Eq. 4, we propose the Cross-ALD regularization at two random input images x i , x j ∼ P D (i = j) as</p><formula xml:id="formula_6">R(θ, x i , x j ) := E x ∼ Pθ (•|xi,xj ) [log Pθ ( x |x i , x j )] = -H( Pθ (•|x i , x j )),<label>(5)</label></formula><p>where H indicates the entropy of a given distribution. When minimizing R(θ, x i , x j ) or equivalently -H(P θ (•|x i , x j )) w.r.t. θ, we encourage P θ (•|x i , x j ) to be closer to a uniform distribution. This implies that the outputs of f ( x ) = f ( x ) = a constant c, where x , x ∼ Pθ (•|x i , x j ). In other words, we encourages the invariant model outputs under small perturbations. Therefore, minimizing the Cross-ALD regularization loss leads to an enhancement in the model smoothness. While VAT only enforces local smoothness using one adversarial example, Cross-ALD further encourages smoothness of both local and mixed adversarial distributions to improve the model generalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Multiple Particle-Based Search to Approximate the Cross-ALD Regularization</head><p>In Eq. 2, the normalization Z(x; θ) in denominator term is intractable to find. Therefore, we propose a multiple particle-based search method named SVGDF to sample x (1) , x (2) , . . . , x (N ) ∼ P θ (•|x)). N is the number of samples (or adversarial particles). SVGDF is used to solve the optimization problem of finding a target distribution P θ (•|x)). SVGDF is a particle-based Bayesian inference algorithm that seeks a set of points (or particles) to approximate the target distribution without explicit parametric assumptions using iterative gradient-based updates. Specifically, a set of adversarial particles (x (n) ) is initialized by adding uniform noises, then projected onto the ball C . These adversarial particles are then iteratively updated using a closed-form solution (Eq. 6) until reaching termination conditions (, number of iterations).</p><formula xml:id="formula_7">x (n),(l+1) = C x (n),(l) + τ * φ(x (n),(l) ) s.t. φ(x ) = 1 N N j=1</formula><p>[k(Φ(x (j),(l) ), Φ(x ))∇ x (j),(l) log P (x (j),(l) |x)</p><formula xml:id="formula_8">+ ∇ x (j),(l) k(Φ(x (j),(l) ), Φ(x ))],<label>(6)</label></formula><p>where x (n),(l) is a n th adversarial particle at l th iteration (n ∈ {1, 2, ..., N }, and l ∈ {1, 2, ..., L} with the maximum number of iteration L). C is projection operator to the C constraint. τ is the step size updating. k is the radial basis function</p><formula xml:id="formula_9">(RBF) kernel k(x , x) = exp -||x -x|| 2 2σ 2</formula><p>. Φ is a fixed feature extractor (e.g., encoder of U-Net/V-Net). While vanilla SVGD <ref type="bibr" target="#b9">[10]</ref> is difficult to capture semantic meaning of high-resolution data because of calculating RBF kernel (k) directly on the data-level, we use the feature extractor Φ as a semantic transformation to further enhance the SVGD algorithm performance for medical imaging. Moreover, the two terms of φ in Eq. 6 have different roles: (i) the first one encourages the adversarial particles to move towards the high density areas of P θ (•|x) and (ii) the second one prevents all the particles from collapsing into the local modes of P θ (•|x) to enhance diversity (e.g.,pushing the particles away from each other). Please refer to the Cross-ALD Github repository for more details.</p><p>SVGDF approximates P θ (•|x i ) and P θ (•|x j ) in Eq. 4, where x i , x j ∼ P D ul (i = j). We form sets of adversarial particles as</p><formula xml:id="formula_10">D adv |x i = { x (1) i , x (2) i , . . . , x (N ) i } and D adv |x j = {x (1) j , x (2) j , . . . , x (N ) j</formula><p>}. The problem (5) can then be relaxed to</p><formula xml:id="formula_11">R(θ, x i , x j ) := E x (n) i ∼P D adv |x i ,x (m) j ∼P D adv |x j Dice (x , x; θ) s.t. : x = γx (n) i + (1 -γ)x (m) j ; x = γx i + (1 -γ)x j , (<label>7</label></formula><formula xml:id="formula_12">)</formula><p>where γ ∼ Beta(α, α) for α ∈ (0, ∞).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Cross-ALD Regularization Loss in Medical Semi-supervised Image Segmentation</head><p>In this paper, the overall loss function total consists of three loss terms. The first term is the dice loss, where labeled image x l and segmentation ground-truth y are sampled from labeled dataset D l . The second term is a contrastive learning loss for inter-class separation cs proposed by <ref type="bibr" target="#b20">[21]</ref>. The third term is our Cross-ALD regularization, which is an enhancement of vat to significantly improve the model performance.</p><formula xml:id="formula_13">total := min θ E (x l ,y )∼P D l l Dice (x l , y; θ) + λ cs E x l ∼P D l ,x ∼P D ul cs (x l , x) + λ Cross-ALD E (xi,xj )∼P D ul R(θ, x i , x j ) ,<label>(8)</label></formula><p>where λ cs and λ Cross-ALD are the corresponding weights to balance the losses. Note that our implementation is replacing vat loss with the proposed Cross-AD regularization in SS-Net code repository<ref type="foot" target="#foot_2">3</ref>  <ref type="bibr" target="#b20">[21]</ref> to reach the state-of-the-art performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>In this section, we conduct several comprehensive experiments using the ACDC<ref type="foot" target="#foot_3">4</ref> dataset <ref type="bibr" target="#b0">[1]</ref> and the LA<ref type="foot" target="#foot_4">5</ref> dataset <ref type="bibr" target="#b26">[26]</ref> for 2D and 3D image segmentation tasks, respectively. For fair comparisons, all experiments are conducted using the identical setting, following <ref type="bibr" target="#b20">[21]</ref>. We evaluate our model in challenging semi-supervised scenarios, where only 5% and 10% of the data are labeled and the remaining data in the training set is treated as unlabeled. The Cross-ALD uses the U-Net <ref type="bibr" target="#b17">[18]</ref> and V-Net <ref type="bibr" target="#b12">[13]</ref> architectures for the ACDC and LA dataset, respectively. We compare the diversity between the adversarial particles generated by our method against vanilla SVGD and VAT with random initialization in Sect. 3.1 . We then illustrate the Cross-AD outperforms other recent methods on ACDC and LA datasets in Sect. 3.2. We show ablation studies in Sect. 3.3. The effect of the number particles to the model performance is studied in the Cross-ALD Github repository.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Diversity of Adversarial Particle Comparison</head><p>Settings. We fixed all the decoder models (U-Net for ACDC and V-Net for LA). We run VAT with random initialization and SVGD multiple times to produce adversarial examples, which we compared to the adversarial particles generated using SVGDF. SVGDF is the proposed algorithm, which leverages feature transformation to capture the semantic meaning of inputs. Φ is the decoder of U-Net in ACDC dataset, while Φ is the decoder of V-Net in LA dataset. We set the same radius ball constraint, updating step, and etc. We randomly pick three images from the datasets to generate adversarial particles. To evaluate their diversity, we report the sum squared error (SSE) between these particles. Higher SSE indicates more diversity, and for each number of particles, we calculate the average of the mean of SSEs.  Results. Note that the advantage of SVGD over VAT is that the former generates diversified adversarial examples because of the second term in Eq. 6 while VAT only creates one example. Moreover, vanilla SVGD is difficult to capture semantic meaning of high-resolution medical imaging because it calculates kernel k on image-level. In Fig. <ref type="figure" target="#fig_0">1</ref>, our SVGDF produces the most diverse particles compared to SVGD and VAT with random initialization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Performance Evaluation on the ACDC and la Datasets</head><p>Settings. We use the metrics of Dice, Jaccard, 95% Hausdorff Distance (95HD), and Average Surface Distance (ASD) to evaluate the results. We compare our Cross-ALD to six recent methods including UA-MT <ref type="bibr" target="#b28">[28]</ref> (MICCAI <ref type="bibr">'19)</ref>, SASSNet <ref type="bibr" target="#b7">[8]</ref> (MICCAI <ref type="bibr">'20)</ref>, DTC <ref type="bibr" target="#b10">[11]</ref> (AAAI'21) , URPC <ref type="bibr" target="#b11">[12]</ref> (MICCAI'21) , MC-Net <ref type="bibr" target="#b22">[22]</ref> (MICCAI <ref type="bibr">'21)</ref>, and SS-Net <ref type="bibr" target="#b20">[21]</ref> (MICCAI <ref type="bibr">'22)</ref>. The loss weights λ Cross-ALD and λ cs are set as an iteration dependent warming-up function <ref type="bibr" target="#b6">[7]</ref>, and number of particles N = 2. All experiments are conducted using the identical settings in the Github repository <ref type="foot" target="#foot_5">6</ref> [21] for fair comparisons.</p><p>Results. Recall that our Cross-ALD generates diversified adversarial particles using SVGDF compared to vanilla SVGD and VAT, and further enhances smoothness of cross-adversarial local distributions. In Table <ref type="table" target="#tab_0">1</ref> and 2, the Cross-ALD can significantly outperform other recent methods with only 5%/10% labeled data training based on the four metrics. Especially, our method impressively gains 14.7% and 2.3% Dice score higher than state-of-the-art SS-Net using 5% labeled data of ACDC and LA, respectively. Moreover, the visualized results of Fig. <ref type="figure" target="#fig_1">2</ref> shows Cross-ALD can segment the most organ details compared to other methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Ablation Study</head><p>Settings. We use the same network architectures and parameter settings in Sect. 3.2, and train the models with 5% labeled training data of ACDC and LA. We illustrate that crossing adversarial particles is more beneficial than random  mixup between natural inputs (RanMixup <ref type="bibr" target="#b29">[29]</ref>) because these particles are near decision boundaries. Recall that our SVGDF is better than VAT and SVGD by producing more diversified adversarial particles. Applying SVGDF's particles and cs (SVGDF + cs ) to gain the model performance in the semi-supervised segmentation task, while Cross-ALD efficiently enhances smoothness to significantly improve the generalization.</p><p>Result. Table <ref type="table" target="#tab_2">3</ref> shows that mixing adversarial examples from VAT outperform those from RanMixup. While SVGDF + cs is better than SVGD and VAT, the proposed Cross-ALD achieves the most outstanding performance among comparisons methods. In addition, our method produces more accurate segmentation masks compared to the ground-truth, as shown in Fig. <ref type="figure" target="#fig_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we have introduced a novel cross-adversarial local distribution (Cross-ALD) regularization that extends and overcomes drawbacks of VAT and Mixup techniques. In our method, SVGDF is proposed to approximate Cross-ALD, which produces more diverse adversarial particles than vanilla SVGD and VAT with random initialization. We adapt Cross-ALD to semi-supervised medical image segmentation to achieve start-of-the-art performance on the ACDC and LA datasets compared to many recent methods such as VAT <ref type="bibr" target="#b13">[14]</ref>, UA-MT <ref type="bibr" target="#b28">[28]</ref>, SASSNet <ref type="bibr" target="#b7">[8]</ref>, DTC <ref type="bibr" target="#b10">[11]</ref>, URPC <ref type="bibr" target="#b11">[12]</ref> , MC-Net <ref type="bibr" target="#b22">[22]</ref>, and SS-Net <ref type="bibr" target="#b20">[21]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Diversity comparison of our SVGDF, SVGD and VAT with random initialization using sum of square error (SSE) of ACDC and LA datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Visualization results of several semi-supervised segmentation methods with 5% labeled training data and its corresponding ground-truth on ACDC and LA datasets.</figDesc><graphic coords="9,73,98,285,77,304,60,102,40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Performance comparisons with six recent methods on ACDC dataset. All results of existing methods are used from<ref type="bibr" target="#b20">[21]</ref> for fair comparisons.</figDesc><table><row><cell>Method</cell><cell cols="2"># Scans used</cell><cell>Metrics</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Complexity</cell></row><row><cell></cell><cell cols="8">Labeled Unlabeled Dice(%)↑ Jaccard(%)↑ 95HD(voxel)↓ ASD(voxel)↓ Para.(M) MACs(G)</cell></row><row><cell>U-Net</cell><cell>3(5%)</cell><cell>0</cell><cell>47.83</cell><cell>37.01</cell><cell>31.16</cell><cell>12.62</cell><cell>1.81</cell><cell>2.99</cell></row><row><cell>U-Net</cell><cell cols="2">7(10%) 0</cell><cell>79.41</cell><cell>68.11</cell><cell>9.35</cell><cell>2.7</cell><cell>1.81</cell><cell>2.99</cell></row><row><cell>U-Net</cell><cell cols="2">70(All) 0</cell><cell>91.44</cell><cell>84.59</cell><cell>4.3</cell><cell>0.99</cell><cell>1.81</cell><cell>2.99</cell></row><row><cell>UA-MT [28]</cell><cell cols="2">3 (5%) 67(95%)</cell><cell>46.04</cell><cell>35.97</cell><cell>20.08</cell><cell>7.75</cell><cell>1.81</cell><cell>2.99</cell></row><row><cell>SASSNet [8]</cell><cell></cell><cell></cell><cell>57.77</cell><cell>46.14</cell><cell>20.05</cell><cell>6.06</cell><cell>1.81</cell><cell>3.02</cell></row><row><cell>DTC [11]</cell><cell></cell><cell></cell><cell>56.9</cell><cell>45.67</cell><cell>23.36</cell><cell>7.39</cell><cell>1.81</cell><cell>3.02</cell></row><row><cell>URPC [12]</cell><cell></cell><cell></cell><cell>55.87</cell><cell>44.64</cell><cell>13.6</cell><cell>3.74</cell><cell>1.83</cell><cell>3.02</cell></row><row><cell>MC-Net [22]</cell><cell></cell><cell></cell><cell>62.85</cell><cell>52.29</cell><cell>7.62</cell><cell>2.33</cell><cell>2.58</cell><cell>5.39</cell></row><row><cell>SS-Net [21]</cell><cell></cell><cell></cell><cell>65.82</cell><cell>55.38</cell><cell>6.67</cell><cell>2.28</cell><cell>1.83</cell><cell>2.99</cell></row><row><cell>Cross-ALD (Ours)</cell><cell></cell><cell></cell><cell>80.6</cell><cell>69.08</cell><cell>5.96</cell><cell>1.9</cell><cell>1.83</cell><cell>2.99</cell></row><row><cell>UA-MT [28]</cell><cell cols="2">7 (10%) 63(90%)</cell><cell>81.65</cell><cell>70.64</cell><cell>6.88</cell><cell>2.02</cell><cell>1.81</cell><cell>2.99</cell></row><row><cell>SASSNet [8]</cell><cell></cell><cell></cell><cell>84.5</cell><cell>74.34</cell><cell>5.42</cell><cell>1.86</cell><cell>1.81</cell><cell>3.02</cell></row><row><cell>DTC [11]</cell><cell></cell><cell></cell><cell>84.29</cell><cell>73.92</cell><cell>12.81</cell><cell>4.01</cell><cell>1.81</cell><cell>3.02</cell></row><row><cell>URPC [12]</cell><cell></cell><cell></cell><cell>83.1</cell><cell>72.41</cell><cell>4.84</cell><cell>1.53</cell><cell>1.83</cell><cell>3.02</cell></row><row><cell>MC-Net [22]</cell><cell></cell><cell></cell><cell>86.44</cell><cell>77.04</cell><cell>5.5</cell><cell>1.84</cell><cell>2.58</cell><cell>5.39</cell></row><row><cell>SS-Net [21]</cell><cell></cell><cell></cell><cell>86.78</cell><cell>77.67</cell><cell>6.07</cell><cell>1.4</cell><cell>1.83</cell><cell>2.99</cell></row><row><cell>Cross-ALD (Ours)</cell><cell></cell><cell></cell><cell>87.52</cell><cell>78.62</cell><cell>4.81</cell><cell>1.6</cell><cell>1.83</cell><cell>2.99</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Performance comparisons with six recent methods on LA dataset. All results of existing methods are used from<ref type="bibr" target="#b20">[21]</ref> for fair comparisons.</figDesc><table><row><cell>Method</cell><cell cols="2"># Scans used</cell><cell>Metrics</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Complexity</cell></row><row><cell></cell><cell cols="8">Labeled Unlabeled Dice(%)↑ Jaccard(%)↑ 95HD(voxel)↓ ASD(voxel)↓ Para.(M) MACs(G)</cell></row><row><cell>V-Net</cell><cell>4(5%)</cell><cell>0</cell><cell>52.55</cell><cell>39.6</cell><cell>47.05</cell><cell>9.87</cell><cell>9.44</cell><cell>47.02</cell></row><row><cell>V-Net</cell><cell cols="2">8(10%) 0</cell><cell>82.74</cell><cell>71.72</cell><cell>13.35</cell><cell>3.26</cell><cell>9.44</cell><cell>47.02</cell></row><row><cell>V-Net</cell><cell cols="2">80(All) 0</cell><cell>91.47</cell><cell>84.36</cell><cell>5.48</cell><cell>1.51</cell><cell>9.44</cell><cell>47.02</cell></row><row><cell>UA-MT [28]</cell><cell cols="2">4 (5%) 76(95%)</cell><cell>82.26</cell><cell>70.98</cell><cell>13.71</cell><cell>3.82</cell><cell>9.44</cell><cell>47.02</cell></row><row><cell>SASSNet [8]</cell><cell></cell><cell></cell><cell>81.6</cell><cell>69.63</cell><cell>16.16</cell><cell>3.58</cell><cell>9.44</cell><cell>47.05</cell></row><row><cell>DTC [11]</cell><cell></cell><cell></cell><cell>81.25</cell><cell>69.33</cell><cell>14.9</cell><cell>3.99</cell><cell>9.44</cell><cell>47.05</cell></row><row><cell>URPC [12]</cell><cell></cell><cell></cell><cell>82.48</cell><cell>71.35</cell><cell>14.65</cell><cell>3.65</cell><cell>5.88</cell><cell>69.43</cell></row><row><cell>MC-Net [22]</cell><cell></cell><cell></cell><cell>83.59</cell><cell>72.36</cell><cell>14.07</cell><cell>2.7</cell><cell>12.35</cell><cell>95.15</cell></row><row><cell>SS-Net [21]</cell><cell></cell><cell></cell><cell>86.33</cell><cell>76.15</cell><cell>9.97</cell><cell>2.31</cell><cell>9.46</cell><cell>47.17</cell></row><row><cell>Cross-ALD (Ours)</cell><cell></cell><cell></cell><cell>88.62</cell><cell>79.62</cell><cell>7.098</cell><cell>1.83</cell><cell>9.46</cell><cell>47.17</cell></row><row><cell>UA-MT [28]</cell><cell cols="2">8 (10%) 72(90%)</cell><cell>87.79</cell><cell>78.39</cell><cell>8.68</cell><cell>2.12</cell><cell>9.44</cell><cell>47.02</cell></row><row><cell>SASSNet [8]</cell><cell></cell><cell></cell><cell>87.54</cell><cell>78.05</cell><cell>9.84</cell><cell>2.59</cell><cell>9.44</cell><cell>47.05</cell></row><row><cell>DTC [11]</cell><cell></cell><cell></cell><cell>87.51</cell><cell>78.17</cell><cell>8.23</cell><cell>2.36</cell><cell>9.44</cell><cell>47.05</cell></row><row><cell>URPC [12]</cell><cell></cell><cell></cell><cell>86.92</cell><cell>77.03</cell><cell>11.13</cell><cell>2.28</cell><cell>5.88</cell><cell>69.43</cell></row><row><cell>MC-Net [22]</cell><cell></cell><cell></cell><cell>87.62</cell><cell>78.25</cell><cell>10.03</cell><cell>1.82</cell><cell>12.35</cell><cell>95.15</cell></row><row><cell>SS-Net [21]</cell><cell></cell><cell></cell><cell>88.55</cell><cell>79.62</cell><cell>7.49</cell><cell>1.9</cell><cell>9.46</cell><cell>47.17</cell></row><row><cell>Cross-ALD (Ours)</cell><cell></cell><cell></cell><cell>89.92</cell><cell>81.78</cell><cell>7.65</cell><cell>1.546</cell><cell>9.46</cell><cell>47.17</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Ablation study on ACDC and LA datasets.</figDesc><table><row><cell cols="2">Dataset Method</cell><cell cols="2"># Scans used</cell><cell>Metrics</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="6">Labeled Unlabeled Dice(%)↑ Jaccard(%)↑ 95HD(voxel)↓ ASD(voxel)↓</cell></row><row><cell cols="2">ACDC U-Net</cell><cell>4(5%)</cell><cell>0</cell><cell>47.83</cell><cell>37.01</cell><cell>31.16</cell><cell>12.62</cell></row><row><cell></cell><cell>RanMixup</cell><cell cols="2">4 (5%) 76(95%)</cell><cell>61.78</cell><cell>51.69</cell><cell>8.16</cell><cell>3.44</cell></row><row><cell></cell><cell>VAT</cell><cell></cell><cell></cell><cell>63.87</cell><cell>53.18</cell><cell>7.61</cell><cell>3.38</cell></row><row><cell></cell><cell>VAT + Mixup</cell><cell></cell><cell></cell><cell>66.23</cell><cell>56.37</cell><cell>7.18</cell><cell>2.53</cell></row><row><cell></cell><cell>SVGD</cell><cell></cell><cell></cell><cell>66.53</cell><cell>58.09</cell><cell>6.41</cell><cell>2.4</cell></row><row><cell></cell><cell>SVGDF</cell><cell></cell><cell></cell><cell>73.15</cell><cell>61.71</cell><cell>6.32</cell><cell>2.12</cell></row><row><cell></cell><cell>SVGDF + cs</cell><cell></cell><cell></cell><cell>74.89</cell><cell>62.61</cell><cell>6.52</cell><cell>2.01</cell></row><row><cell></cell><cell>Cross-ALD (Ours)</cell><cell></cell><cell></cell><cell>80.6</cell><cell>69.08</cell><cell>5.96</cell><cell>1.9</cell></row><row><cell>LA</cell><cell>V-Net</cell><cell>3(5%)</cell><cell>0</cell><cell>52.55</cell><cell>39.6</cell><cell>47.05</cell><cell>9.87</cell></row><row><cell></cell><cell>RanMixup</cell><cell cols="2">3 (5%) 67(95%)</cell><cell>79.82</cell><cell>67.44</cell><cell>16.52</cell><cell>5.19</cell></row><row><cell></cell><cell>VAT</cell><cell></cell><cell></cell><cell>82.27</cell><cell>70.46</cell><cell>13.82</cell><cell>3.48</cell></row><row><cell></cell><cell>VAT + Mixup</cell><cell></cell><cell></cell><cell>83.28</cell><cell>71.77</cell><cell>12.8</cell><cell>2.63</cell></row><row><cell></cell><cell>SVGD</cell><cell></cell><cell></cell><cell>84.62</cell><cell>73.6</cell><cell>11.68</cell><cell>2.94</cell></row><row><cell></cell><cell>SVGDF</cell><cell></cell><cell></cell><cell>86.3</cell><cell>76.17</cell><cell>10.01</cell><cell>2.11</cell></row><row><cell></cell><cell>SVGDF + cs</cell><cell></cell><cell></cell><cell>86.55</cell><cell>76.51</cell><cell>9.41</cell><cell>2.24</cell></row><row><cell></cell><cell>Cross-ALD (Ours)</cell><cell></cell><cell></cell><cell>87.52</cell><cell>78.62</cell><cell>4.81</cell><cell>1.6</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The Cross-ALD implementation in https://github.com/PotatoThanh/Crossadversarial-local-distribution-regularization.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>A sample generated by adding perturbations toward the adversarial direction.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>https://github.com/ycwu1997/SS-Net.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>https://www.creatis.insa-lyon.fr/Challenge/acdc/databases.html.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>http://atriaseg2018.cardiacatlas.org.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>https://github.com/ycwu1997/SS-Net.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This work was partially supported by the <rs type="funder">Australian Defence Science and Technology (DST) Group</rs> under the <rs type="funder">Next Generation Technology Fund (NGTF)</rs> scheme. Dinh Phung further gratefully acknowledges the partial support from the <rs type="funder">Australian Research Council</rs>, project <rs type="grantNumber">ARC DP230101176</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_xx65nMM">
					<idno type="grant-number">ARC DP230101176</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43907-0 18.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep learning techniques for automatic MRI cardiac multistructures segmentation and diagnosis: is the problem solved?</title>
		<author>
			<persName><forename type="first">O</forename><surname>Bernard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2514" to="2525" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Remixmatch: Semi-supervised learning with distribution alignment and augmentation anchoring</title>
		<author>
			<persName><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.09785</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Mixmatch: A holistic approach to semi-supervised learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inform. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Semi-supervised semantic segmentation needs strong, varied perturbations</title>
		<author>
			<persName><forename type="first">G</forename><surname>French</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mackiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Finlayson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.01916</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Enhancing mixup-based semi-supervised learningwith explicit lipschitz regularization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Gyawali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghimire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE International Conference on Data Mining (ICDM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1046" to="1051" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semi-supervised semantic segmentation with directional contextaware consistency</title>
		<author>
			<persName><forename type="first">X</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1205" to="1214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Temporal ensembling for semi-supervised learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.02242</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Shape-aware semi-supervised 3D semantic segmentation for medical images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59710-8_54</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-59710-8" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12261</biblScope>
			<biblScope unit="page">54</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Transformationconsistent self-ensembling model for semisupervised medical image segmentation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="523" to="534" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Stein variational gradient descent: A general purpose bayesian inference algorithm</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NeurIPS</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><surname>Luxburg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<meeting>NeurIPS</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Semi-supervised medical image segmentation through dual-task consistency</title>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="8801" to="8809" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Efficient semi-supervised gross target volume of nasopharyngeal carcinoma segmentation via uncertainty rectified pyramid consistency</title>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87196-3_30</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87196-330" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12902</biblScope>
			<biblScope unit="page" from="318" to="329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">V-net: Fully convolutional neural networks for volumetric medical image segmentation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Milletari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Ahmadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fourth International Conference on 3D Vision (3DV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="565" to="571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Virtual adversarial training: a regularization method for supervised and semi-supervised learning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">I</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ishii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1979" to="1993" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Particle-based adversarial local distribution regularization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Nguyen-Duc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Q</forename><surname>Phung</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="5212" to="5224" />
		</imprint>
		<respStmt>
			<orgName>AISTATS</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">An overview of deep semi-supervised learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ouali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hudelot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tami</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.05278</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Semi-supervised semantic segmentation with cross-consistency training</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ouali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hudelot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="12674" to="12684" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">18th International Conference</title>
		<meeting><address><addrLine>Munich, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015-10-05">2015. October 5-9, 2015. 2015</date>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
	<note>Proceedings, Part III 18</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Fixmatch: simplifying semi-supervised learning with consistency and confidence</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural. Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="596" to="608" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Diversity can be transferred: Output diversification for white-and black-box attacks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tashiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. NeurIPS</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="4536" to="4548" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Exploring smoothness and class-separation for semi-supervised medical image segmentation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<biblScope unit="volume">13435</biblScope>
			<biblScope unit="page" from="34" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Cham</forename><surname>Springer</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16443-9_4</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16443-94" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Semi-supervised left atrium segmentation with mutual consistency training</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87196-3_28</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87196-328" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12902</biblScope>
			<biblScope unit="page" from="297" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning meta-class memory for few-shot semantic segmentation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="517" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">3D semi-supervised learning with uncertainty-aware multi-view cotraining</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3646" to="3655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Intra-and inter-pair consistency for semi-supervised gland segmentation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Verjans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="894" to="905" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A global benchmark of algorithms for segmenting the left atrium from late gadolinium-enhanced cardiac magnetic resonance imaging</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page">101832</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A survey on deep semi-supervised learning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Uncertainty-aware self-ensembling model for semi-supervised 3D left atrium segmentation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-W</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Heng</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-32245-8_67</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-32245-867" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2019</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11765</biblScope>
			<biblScope unit="page" from="605" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.09412</idno>
		<title level="m">mixup: Beyond empirical risk minimization</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
