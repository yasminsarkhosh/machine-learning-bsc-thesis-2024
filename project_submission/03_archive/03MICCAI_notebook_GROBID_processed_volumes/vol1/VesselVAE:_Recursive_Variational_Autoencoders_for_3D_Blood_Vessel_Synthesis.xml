<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">VesselVAE: Recursive Variational Autoencoders for 3D Blood Vessel Synthesis</title>
				<funder ref="#_YThrRrw">
					<orgName type="full">Argentina</orgName>
				</funder>
				<funder ref="#_Wd3emCB">
					<orgName type="full">Salesforce, USA</orgName>
				</funder>
				<funder>
					<orgName type="full">National Scientific and Technical Research Council (CONICET)</orgName>
				</funder>
				<funder>
					<orgName type="full">Universidad Torcuato Di Tella, Argentina</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Paula</forename><surname>Feldman</surname></persName>
							<email>paulafeldman@conicet.gov.ar</email>
							<affiliation key="aff0">
								<orgName type="institution">Consejo Nacional de Investigaciones Científicas y Técnicas</orgName>
								<address>
									<settlement>Buenos Aires</settlement>
									<country key="AR">Argentina</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Universidad Torcuato Di Tella</orgName>
								<address>
									<settlement>Buenos Aires</settlement>
									<country key="AR">Argentina</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Miguel</forename><surname>Fainstein</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Universidad Torcuato Di Tella</orgName>
								<address>
									<settlement>Buenos Aires</settlement>
									<country key="AR">Argentina</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Viviana</forename><surname>Siless</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Universidad Torcuato Di Tella</orgName>
								<address>
									<settlement>Buenos Aires</settlement>
									<country key="AR">Argentina</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Claudio</forename><surname>Delrieux</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Consejo Nacional de Investigaciones Científicas y Técnicas</orgName>
								<address>
									<settlement>Buenos Aires</settlement>
									<country key="AR">Argentina</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Universidad Nacional del Sur</orgName>
								<address>
									<settlement>Bahía Blanca</settlement>
									<country key="AR">Argentina</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Emmanuel</forename><surname>Iarussi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Consejo Nacional de Investigaciones Científicas y Técnicas</orgName>
								<address>
									<settlement>Buenos Aires</settlement>
									<country key="AR">Argentina</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Universidad Torcuato Di Tella</orgName>
								<address>
									<settlement>Buenos Aires</settlement>
									<country key="AR">Argentina</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">VesselVAE: Recursive Variational Autoencoders for 3D Blood Vessel Synthesis</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="67" to="76"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">387C6A47D7A8658F0C2AA0CEB1BE65F7</idno>
					<idno type="DOI">10.1007/978-3-031-43907-0_7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-13T19:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Vascular 3D model</term>
					<term>Generative modeling</term>
					<term>Neural Networks</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a data-driven generative framework for synthesizing blood vessel 3D geometry. This is a challenging task due to the complexity of vascular systems, which are highly variating in shape, size, and structure. Existing model-based methods provide some degree of control and variation in the structures produced, but fail to capture the diversity of actual anatomical data. We developed VesselVAE, a recursive variational Neural Network that fully exploits the hierarchical organization of the vessel and learns a low-dimensional manifold encoding branch connectivity along with geometry features describing the target surface.</p><p>After training, the VesselVAE latent space can be sampled to generate new vessel geometries. To the best of our knowledge, this work is the first to utilize this technique for synthesizing blood vessels. We achieve similarities of synthetic and real data for radius (.97), length (.95), and tortuosity (.96). By leveraging the power of deep neural networks, we generate 3D models of blood vessels that are both accurate and diverse, which is crucial for medical and surgical training, hemodynamic simulations, and many other purposes.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Accurate 3D models of blood vessels are increasingly required for several purposes in Medicine and Science <ref type="bibr" target="#b24">[25]</ref>. These meshes are typically generated using either image segmentation or synthetic methods. Despite significant advances in vessel segmentation <ref type="bibr" target="#b25">[26]</ref>, reconstructing thin features accurately from medical images remains challenging <ref type="bibr" target="#b1">[2]</ref>. Manual editing of vessel geometry is a tedious and error prone task that requires expert medical knowledge, which explains the scarcity of curated datasets. As a result, several methods have been developed to adequately synthesize blood vessel geometry <ref type="bibr" target="#b28">[29]</ref>.</p><p>Within the existing literature on generating vascular 3D models, we identified two primary types of algorithms: fractal-based, and space-filling algorithms. Fractal-based algorithms use a set of fixed rules that include different branching parameters, such as the ratio of asymmetry in arterial bifurcations and the relationship between the diameter of the vessel and the flow <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b32">33]</ref>. On the other hand, space-filling algorithms allow the blood vessels to grow into a specific perfusion volume while aligning with hemodynamic laws and constraints on the formation of blood vessels <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b24">25]</ref>. Although these model-based methods provide some degree of control and variation in the structures produced, they often fail to capture the diversity of real anatomical data.</p><p>In recent years, deep neural networks led to the development of powerful generative models <ref type="bibr" target="#b29">[30]</ref>, such as Generative Adversarial Networks <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b11">12]</ref> and Diffusion Models <ref type="bibr" target="#b10">[11]</ref>, which produced groundbreaking performance in many applications, ranging from image and video synthesis to molecular design. These advances have inspired the creation of novel network architectures to model 3D shapes using voxel representations <ref type="bibr" target="#b27">[28]</ref>, point clouds <ref type="bibr" target="#b30">[31]</ref>, signed distance functions <ref type="bibr" target="#b18">[19]</ref>, and polygonal meshes <ref type="bibr" target="#b17">[18]</ref>. In particular, and close to our aim, Wolterink et al. <ref type="bibr" target="#b26">[27]</ref> propose a GAN model capable of generating coronary artery anatomies. However, this model is limited to generating single-channel blood vessels and thus does not support the generation of more complex, tree-like vessel topologies.</p><p>In this work we propose a novel data-driven framework named VesselVAE for synthesizing blood vessel geometry. Our generative framework is based on a Recursive variational Neural Network (RvNN), that has been applied in various contexts, including natural language <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref>, shape semantics modeling <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15]</ref>, and document layout generation <ref type="bibr" target="#b19">[20]</ref>. In contrast to previous data-driven methods, our recursive network fully exploits the hierarchical organization of the vessel and learns a low-dimensional manifold encoding branch connectivity along with geometry features describing the target surface. Once trained, the Vessel-VAE latent space is sampled to generate new vessel geometries. To the best of our knowledge, this work is the first to synthesize multi-branch blood vessel trees by learning from real data. Experiments show that synth and real blood vessel geometries are highly similar measured with the cosine similarity: radius (.97), length (.95), and tortuosity (.96).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>Input. The network input is a binary tree representation of the blood vessel 3D geometry. Formally, each tree is defined as a tuple (T, E), where T is the set of nodes, and E is the set of directed edges connecting a pair of nodes (n, m), with n, m ∈ T . In order to encode a 3D model into this representation, vessel segments V are parameterized by a central axis consisting of ordered points in Euclidean space: V = v 1 , v 2 , . . . , v N and a radius r, assuming a piece-wise tubular vessel for simplicity. We then construct the binary tree as a set of nodes T = n 1 , n 2 , . . . , n N , where each node n i represents a vessel segment v and contains an attribute vector 4 with the coordinates of the corresponding point and its radius r i . See Sect. 3 for details.</p><formula xml:id="formula_0">x i = [x i , y i , z i , r i ] ∈ R</formula><p>Network Architecture. The proposed generative model is a Recursive variational Neural Network (RvNN) consisting of two main components: the Encoder (Enc) and the Decoder (Dec) networks. The Encoder transforms a tree structure into a hierarchical encoding on the learned manifold. The Decoder network is capable of sampling from this encoded space to decode tree structures, as depicted in Fig. <ref type="figure" target="#fig_0">1</ref>. The encoding and decoding processes are achieved through a depth-first traversal of the tree, where each node is combined with its parent node recursively. The model outputs a hierarchy of vessel branches, where each internal node in the hierarchy is represented by a vector that encodes its own attributes and the information of all subsequent nodes in the tree.</p><p>Within the RvNN Decoder network there are two essential components: the Node Classifier (Cls) and the Features Decoder Multi-Layer Perceptron (Features Dec-MLP). The Node Classifier discerns the type of node to be decoded, whether it is a leaf node or an internal node with one or two bifurcations. This is implemented as a multi-layer perceptron trained to predict a three-category bifurcation probability based on the encoded vector as input. Complementing the Node Classifier, the Features Dec-MLP is responsible for reconstructing the attributes of each node, specifically its coordinates and radius. Furthermore, two additional components, the Right and Left Dec-MLP, are in charge of recursively decoding the next encoded node in the tree hierarchy. These decoder's branches execute based on the classifier prediction for that encoded node. If the Node Classifier predicts a single child for a node, a right child is assumed by default.</p><p>In addition to the core architecture, our model is further augmented with three auxiliary, shallow, fully-connected neural networks: f μ , f σ , and g z . Positioned before the RvNN bottleneck, the f μ and f σ networks shape the distribution of the latent space where encoded tree structures lie. Conversely, the g z network, situated after the bottleneck, facilitates the decoding of latent variables, aiding the Decoder network in the reconstruction of tree structures. Collectively, these supplementary networks streamline the data transformation process through the model. All activation functions used in our networks are leaky ReLUs. See the Appendix for implementation details.</p><p>Objective. Our generative model is trained to learn a probability distribution over the latent space that can be used to generate new blood vessel segments. After encoding, the decoder takes samples from a multivariate Gaussian distribution:</p><formula xml:id="formula_1">z s (x) ∼ N (μ, σ) with μ = f μ (Enc(x)) and σ = f σ (Enc(x))</formula><p>, where Enc is the recursive encoder and f μ , f σ are two fully-connected neural networks. In order to recover the feature vectors x for each node along with the tree topology, we simultaneously train the regression network (Features Dec-MLP in Fig. <ref type="figure" target="#fig_0">1</ref>) on a reconstruction objective L recon , and the Node Classifier using L topo . Additionally, in line with the general framework proposed by β-VAE <ref type="bibr" target="#b9">[10]</ref>, we incorporated a Kullback-Leibler (KL) divergence term encouraging the distribution p(z s (x)) over all training samples x to move closer to the prior of the standard normal distribution p(z). We therefore minimize the following equation:</p><formula xml:id="formula_2">L = L recon + αL topo + γL KL ,<label>(1)</label></formula><p>where the reconstruction loss is defined as</p><formula xml:id="formula_3">L recon = Dec (z s (x)) -x 2 , the Kullback-Leibler divergence loss is L KL = D KL (p (z s (x)) p(z)),</formula><p>and the topology objective is a three-class cross entropy loss L topo = Σ 3 c=1 x c log(Cls(Dec(x)) c ). Notice that x c is a binary indicator (0 or 1) for the true class of the sample x. Specifically, x c = 1 if the sample belongs to class c and 0 otherwise. Cls(Dec(x)) c is the predicted probability of the sample x belonging to class c (zero, one, or two bifurcations), as output by the classifier. Here, Dec(x) denotes the encoded-decoded node representation of the input sample x. 3D Mesh Synthesis. Several algorithms have been proposed in the literature to generate a surface 3D mesh from a tree-structured centerline <ref type="bibr" target="#b28">[29]</ref>. For simplicity and efficiency, we chose the approach described in <ref type="bibr" target="#b5">[6]</ref>, which produces good quality meshes from centerlines with a low sample rate. The implemented method iterates through the points in the curve generating a coarse quadrilateral Fig. <ref type="figure">2</ref>. Dataset and pre-processing overview: The raw meshes from the IntraA 3D collection undergo pre-processing using the VMTK toolkit. This step is crucial for extracting centerlines and cross-sections from the meshes, which are then used to construct their binary tree representations. mesh along the segments and joints. The centerline sampling step is crucial for a successful reconstruction outcome. Thus, our re-sampling is not equispaced but rather changes with curvature and radius along the centerline, increasing the frequency of sampling near high-curvature regions. This results in a better quality and more accurate mesh. Finally, Catmull-Clark subdivision algorithm <ref type="bibr" target="#b4">[5]</ref> is used to increase mesh resolution and smooth out the surface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Setup</head><p>Materials. We trained our networks using a subset of the open-access IntrA dataset<ref type="foot" target="#foot_0">1</ref> published by <ref type="bibr">Yang et al. in 2020 [32]</ref>. This subset consisted of 1694 healthy vessel segments reconstructed from 2D MRA images of patients. We converted 3D meshes into a binary tree representation and used the network extraction script from the VMTK toolkit<ref type="foot" target="#foot_1">2</ref> to extract the centerline coordinates of each vessel model. The centerline points were determined based on the ratio between the sphere step and the local maximum radius, which was computed using the advancement ratio specified by the user. The radius of the blood vessel conduit at each centerline sample was determined using the computed crosssections assuming a maximal circular shape (See Fig. <ref type="figure">2</ref>). To improve computational efficiency during recursive tree traversal, we implemented an algorithm that balances each tree by identifying a new root. We additionally trimmed trees to a depth of ten in our experiments. This decision reflects a balance between the computational demands of depth-first tree traversal in each training step and the complexity of the training meshes. We excluded from our study trees that exhibited greater depth, nodes with more than two children, or with loops. However, non-binary trees can be converted into binary trees and it is possible to train with deeper trees at the expense of higher computational costs. Ultimately, we were able to obtain 700 binary trees from the original meshes using this approach.</p><p>Implementation Details. For the centerline extraction, we set the advancement ratio in the VMTK script to 1.05. The script can sometimes produce multiple cross-sections at centerline bifurcations. In those cases, we selected the sample with the lowest radius, which ensures proper alignment with the centerline principal direction. All attributes were normalized to a range of [0, 1]. For the mesh reconstruction we used 4 iterations of Catmull-Clark subdivision algorithm. The data pre-processing pipeline and network code were implemented in Python and PyTorch Framework.</p><p>Training. In all stages, we set the batch size to 10 and used the ADAM optimizer with β 1 = 0.9, β 2 = 0.999, and a learning rate of 1 × 10 -4 . We set α = .3 and γ = .001 for Eq. 1 in our experiments. To enhance computation speed, we implemented dynamic batching <ref type="bibr" target="#b15">[16]</ref>, which groups together operations involving input trees of dissimilar shapes and different nodes within a single input graph. It takes approximately 12 h to train our models on a workstation equipped with an NVIDIA A100 GPU, 80 GB VRAM, and 256 GB RAM. However, the memory footprint during training is very small (≤1 GB) due to the use of a lightweight tree representation. This means that the amount of memory required to store and manipulate our training data structures is minimal. During training, we ensure that the reconstructed tree aligns with the original structure, rather than relying solely on the classifier's predictions. We train the classifier using a crossentropy loss that compares its predictions to the actual values from the original tree. Since the number of nodes in each class is unbalanced, we scale the weight given to each class in the cross-entropy loss using the inverse of each class count. During preliminary experiments, we observed that accurately classifying nodes closer to the tree root is critical. This is because a miss-classification of top nodes has a cascading effect on all subsequent nodes in the tree (i.e. skip reconstructing a branch). To account for this, we introduce a weighting scheme that for each node, assigns a weight to the cross-entropy loss based on the number of total child nodes. The weight is normalized by the total number of nodes in the tree.</p><p>Metrics. We defined a set of metrics to evaluate our trained network's performance. By using these metrics, we can determine how well the generated 3D models of blood vessels match the original dataset distribution, as well as the diversity of the generated output. The chosen metrics have been widely used in the field of blood vessel 3D modeling, and have shown to provide reliable and accurate quantification of blood vessels main characteristics <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b12">13]</ref>. We analyzed tortuosity per branch, the vessel centerline total length, and the average radius of the tree. Tortuosity distance metric <ref type="bibr" target="#b3">[4]</ref> is a widely used metric in the field of blood vessel analysis, mainly because of its clinical importance. It measures the amount of twistiness in each branch of the vessel. Vessel's total length and average radius were used in previous work to distinguish healthy vasculature from cancerous malformations. Finally, in order to measure the distance across distributions for each metric, we compute the cosine similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>We conducted both quantitative and qualitative analyses to evaluate the model's performance. For the quantitative analyses, we implemented a set of metrics commonly used for characterizing blood vessels. We computed histograms of the radius, total length, and tortuosity for the real blood vessel set and the generated set (700 samples) in Fig. <ref type="figure" target="#fig_1">3 (a)</ref>. The distributions are aligned and consistent. We measured the closeness of histograms with the cosine similarity by projecting the distribution into a vector of n-dimensional space (n is the number of bins in the histogram). Since our points are positive, the results range from 0 to 1. We obtain a radius cosine similarity of .97, a total length cosine similarity of .95, and a tortuosity cosine similarity of .96. Results show high similarities between histograms demonstrating that generated blood vessels are realistic. Given the differences with the baselines generated topologies, for a fair comparison, we limited our evaluation to a visual inspection of the meshes.</p><p>The qualitative analyses consisted of a visual evaluation of the reconstructed outputs provided by the decoder network. We visually compared them to stateof-the-art methods in Fig. <ref type="figure" target="#fig_1">3 (b</ref>). The method described by Wolterink and colleagues <ref type="bibr" target="#b26">[27]</ref> is able to generate realistic blood vessels but without branches, and the method described by Hamarneh et al. <ref type="bibr" target="#b8">[9]</ref> is capable of generating branches with straight shapes, missing on realistic modeling. In contrast, our method is capable of generating realistic blood vessels containing branches, with smooth varying radius, lengths, and tortuosity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>We have presented a novel approach for synthesizing blood vessel models using a variational recursive autoencoder. Our method enables efficient encoding and decoding of binary tree structures, and produces high-quality synthesized models. In the future, we aim to explore combinations of our approach with representing surfaces by the zero level set in a differentiable implicit neural representation (INR) <ref type="bibr" target="#b0">[1]</ref>. This could lead to more accurate and efficient modeling of blood vessels and potentially other non-tree-like structures such as capillary networks. Since the presented framework would require significant adaptations to accommodate such complex topologies, exploring this problem would certainly be an interesting direction for future research. Additionally, the generated geometries might show self-intersections. In the future, we would like to incorporate restrictions into the generative model to avoid such artifacts. Overall, we believe that our proposed approach holds great promise for advancing 3D blood vessel geometry synthesis and contributing to the development of new clinical tools for healthcare professionals.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Top: Overview of the Recursive variational Neural Network for synthesizing blood vessel structures. The architecture follows an Encoder-Decoder framework which can handle the hierarchical tree representation of the vessels. VesselVAE learns to generate the topology and attributes for each node in the tree, which is then used to synthesize 3D meshes. Bottom: Layers of the Encoder and Decoder networks comprising branches of fully-connected layers followed by leaky ReLU activations. Note that the right/left Enc-MLPs within the Encoder are triggered respectively when the incoming node in the tree is identified as a right or left child. Similarly, the Decoder only uses right/left Dec-MLPs when the Node Classifier predicts bifurcations.</figDesc><graphic coords="3,69,72,57,59,322,78,181,30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. (a) shows the histograms of total length, average radius and tortuosity per branch for both, real and synthetic samples. (b) shows a visual comparison among our method and two baselines [9, 27].</figDesc><graphic coords="7,77,70,58,64,314,92,282,37" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://github.com/intra3d2019/IntrA.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>http://www.vmtk.org/vmtkscripts/vmtknetworkextraction.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This project was supported by grants from <rs type="funder">Salesforce, USA</rs> (<rs type="projectName">Einstein AI 2020</rs>), <rs type="funder">National Scientific and Technical Research Council (CONICET)</rs>, <rs type="funder">Argentina</rs> (<rs type="grantNumber">PIP 2021-2023 GI -11220200102981CO</rs>), and <rs type="funder">Universidad Torcuato Di Tella, Argentina</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_Wd3emCB">
					<orgName type="project" subtype="full">Einstein AI 2020</orgName>
				</org>
				<org type="funding" xml:id="_YThrRrw">
					<idno type="grant-number">PIP 2021-2023 GI -11220200102981CO</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43907-0_7.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Going off-grid: continuous implicit neural representations for 3D vascular modeling</title>
		<author>
			<persName><forename type="first">D</forename><surname>Alblas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brune</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Wolterink</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-23443-9_8</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-23443-9_8" />
	</analytic>
	<monogr>
		<title level="m">STACOM 2022</title>
		<editor>
			<persName><forename type="first">O</forename><surname>Camara</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13593</biblScope>
			<biblScope unit="page" from="79" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Deep learning-based carotid artery vessel wall segmentation in black-blood MRI using anatomical priors</title>
		<author>
			<persName><forename type="first">D</forename><surname>Alblas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brune</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Wolterink</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.01137</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Vascular attributes and malignant brain tumors</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bullitt</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-540-39899-8_82</idno>
		<ptr target="https://doi.org/10.1007/978-3-540-39899-8_82" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2003</title>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Ellis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Peters</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">2878</biblScope>
			<biblScope unit="page" from="671" to="679" />
		</imprint>
	</monogr>
	<note type="report_type">Heidelberg</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Measuring tortuosity of the intracerebral vasculature from MRA images</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bullitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gerig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Pizer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Aylward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1163" to="1171" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Recursively generated b-spline surfaces on arbitrary topological meshes</title>
		<author>
			<persName><forename type="first">E</forename><surname>Catmull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Aided Des</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="350" to="355" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Surface models of tube trees</title>
		<author>
			<persName><forename type="first">P</forename><surname>Felkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wegenkittl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Buhler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Computer Graphics International</title>
		<meeting>Computer Graphics International</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="70" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Threedimensional synthetic blood vessel generation using stochastic l-systems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Galarreta-Valverde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Macedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mekkaoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Jackowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Processing</title>
		<imprint>
			<biblScope unit="volume">8669</biblScope>
			<biblScope unit="page" from="414" to="419" />
			<date type="published" when="2013">2013. 2013</date>
			<publisher>SPIE</publisher>
		</imprint>
	</monogr>
	<note>Medical Imaging</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Generative adversarial networks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="139" to="144" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Vascusynth: simulating vascular trees for generating volumetric image data with ground-truth segmentation and tree analysis</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hamarneh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jassi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Med. Imaging Graph</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="605" to="616" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">beta-VAE: learning basic visual concepts with a constrained variational framework</title>
		<author>
			<persName><forename type="first">I</forename><surname>Higgins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Denoising diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural. Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6840" to="6851" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">GANs for medical image analysis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kazeminia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell. Med</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="page">101938</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Three-dimensional quantification of capillary networks in healthy and cancerous tissues of two mice</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Microvasc. Res</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="314" to="322" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Grass: generative recursive autoencoders for shape structures</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Yumer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph. (TOG)</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Grains: generative recursive autoencoders for indoor scenes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph. (TOG)</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Looks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Herreshoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hutchins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Norvig</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.02181</idno>
		<title level="m">Deep learning with dynamic computation graphs</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Computational modelling of the cerebral cortical microvasculature: effect of x-ray microbeams versus broad beam irradiation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Merrem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bartzsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Laissue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Oelfke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Med. Biol</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">3902</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Polygen: an autoregressive generative model of 3D meshes</title>
		<author>
			<persName><forename type="first">C</forename><surname>Nash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Battaglia</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7220" to="7229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">DeepSDF: learning continuous signed distance functions for shape representation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Florence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Straub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Newcombe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lovegrove</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="165" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Read: recursive autoencoders for document layout generation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ben-Eliezer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Perel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Averbuch-Elor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="544" to="545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Interactive synthesis of 3D geometries of blood vessels</title>
		<author>
			<persName><forename type="first">N</forename><surname>Rauch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Harders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics 2021 -Short Papers</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Theisel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Wimmer</surname></persName>
		</editor>
		<imprint>
			<publisher>The Eurographics Association</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Tissue metabolism driven arterial tree generation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Reichold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Székely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hirsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1397" to="1414" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Recursive deep learning for natural language processing and computer vision</title>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Stanford University</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Parsing natural scenes and natural language with recursive neural networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine Learning (ICML-11)</title>
		<meeting>the 28th International Conference on Machine Learning (ICML-11)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="129" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Adaptive constrained constructive optimisation for complex vascularisation processes</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D M</forename><surname>Talou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Safaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Blanco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deepvesselnet: vessel segmentation, centerline prediction, and bifurcation detection in 3-D angiographic volumes</title>
		<author>
			<persName><forename type="first">G</forename><surname>Tetteh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Neurosci</title>
		<imprint>
			<biblScope unit="page">1285</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Blood vessel geometry synthesis using generative adversarial networks</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Wolterink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Leiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Isgum</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.04381</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning a probabilistic latent space of object shapes via 3D generative-adversarial modeling</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Comparative study of surface modeling methods for vascular structures</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Med. Imaging Graph</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="14" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Generative AI-empowered simulation for autonomous driving in vehicular mixed reality metaverses</title>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.08418</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Pointflow: 3D point cloud generation with continuous normalizing flows</title>
		<author>
			<persName><forename type="first">G</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4541" to="4550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Intra: 3D intracranial aneurysm dataset for deep learning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Igarashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2656" to="2666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Arterial branching within the confines of fractal l-system formalism</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zamir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Gen. Physiol</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="267" to="276" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
