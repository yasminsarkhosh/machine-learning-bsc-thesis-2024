<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Federated Condition Generalization on Low-dose CT Reconstruction via Cross-domain Learning</title>
				<funder ref="#_PwX4Q3r #_bX44S8C">
					<orgName type="full">NSFC</orgName>
				</funder>
				<funder>
					<orgName type="full">Young Talent Support Project of Guangzhou Association for Science and Technology</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Shixuan</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Biomedical Engineering</orgName>
								<orgName type="institution">Southern Medical University</orgName>
								<address>
									<settlement>Guangdong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">Pazhou Lab (Huangpu)</orgName>
								<address>
									<settlement>Guangdong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Boxuan</forename><surname>Cao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Biomedical Engineering</orgName>
								<orgName type="institution">Southern Medical University</orgName>
								<address>
									<settlement>Guangdong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">Pazhou Lab (Huangpu)</orgName>
								<address>
									<settlement>Guangdong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yinda</forename><surname>Du</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Biomedical Engineering</orgName>
								<orgName type="institution">Southern Medical University</orgName>
								<address>
									<settlement>Guangdong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">Pazhou Lab (Huangpu)</orgName>
								<address>
									<settlement>Guangdong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yaoduo</forename><surname>Zhang</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">School of Biomedical Engineering</orgName>
								<orgName type="institution">Guangzhou Medical University</orgName>
								<address>
									<settlement>Guangdong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ji</forename><surname>He</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">School of Biomedical Engineering</orgName>
								<orgName type="institution">Guangzhou Medical University</orgName>
								<address>
									<settlement>Guangdong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhaoying</forename><surname>Bian</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Biomedical Engineering</orgName>
								<orgName type="institution">Southern Medical University</orgName>
								<address>
									<settlement>Guangdong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">Pazhou Lab (Huangpu)</orgName>
								<address>
									<settlement>Guangdong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dong</forename><surname>Zeng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Biomedical Engineering</orgName>
								<orgName type="institution">Southern Medical University</orgName>
								<address>
									<settlement>Guangdong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Radiology</orgName>
								<orgName type="institution" key="instit1">Zhujiang Hospital</orgName>
								<orgName type="institution" key="instit2">Southern Medical University</orgName>
								<address>
									<settlement>Guangdong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">Pazhou Lab (Huangpu)</orgName>
								<address>
									<settlement>Guangdong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Jianhua</forename><surname>Ma</surname></persName>
							<email>jhma@smu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Biomedical Engineering</orgName>
								<orgName type="institution">Southern Medical University</orgName>
								<address>
									<settlement>Guangdong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">Pazhou Lab (Huangpu)</orgName>
								<address>
									<settlement>Guangdong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Federated Condition Generalization on Low-dose CT Reconstruction via Cross-domain Learning</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="47" to="56"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">F020C21218062DEFF9EFC8DAF5A296B8</idno>
					<idno type="DOI">10.1007/978-3-031-43898-1_5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-13T19:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>low-dose CT</term>
					<term>image reconstruction</term>
					<term>federal learning</term>
					<term>generalization</term>
					<term>generalization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The harmful radiation dose associated with CT imaging is a major concern because it can cause genetic diseases. Acquiring CT data at low radiation doses has become a pressing goal. Deep learning (DL)based methods have proven to suppress noise-induced artifacts and promote image quality in low-dose CT imaging. However, it should be noted that most of the DL-based methods are constructed based on the CT data from a specific condition, i.e., specific imaging geometry and specific dose level. Then these methods might generalize poorly to the other conditions, i.e., different imaging geometries and other radiation doses, due to the big data heterogeneity. In this study, to address this issue, we propose a condition generalization method under a federated learning framework (FedCG) to reconstruct CT images on two conditions: three different dose levels and different sampling shcemes at three different geometries. Specifically, the proposed FedCG method leverages a cross-domain learning approach: individual-client sinogram learning and cross-client image reconstruction for condition generalization. In each individual client, the sinogram at each condition is processed similarly to that in the iRadon-MAP. Then the CT images at each client are learned via a condition generalization network in the server which considers latent common characteristics in the CT images at all conditions and preserves the client-specific characteristics in each condition. Experiments show that the proposed FedCG outperforms the other competing methods on two imaging conditions in terms of qualitative and quantitative assessments.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Lowering radiation dose is desired in the computed tomography (CT) examination. Various strategies, i.e., lowering incident photons directly (low-mAs), reducing sampling views (sparse-view) and reducing sampling angles (limitedview) can be used for low-dose CT imaging. However, the reconstructed images under these conditions would suffer from severe quality degradation. A number of reconstruction algorithms have been proposed to improve low-dose CT image quality <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref>. Among them, deep learning (DL)-based methods have shown great promise for low-dose CT imaging, including methods that learn noise distribution features from the image domain to directly reduce noise and artifacts in the reconstructed image <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>, as well as methods to improve the reconstruction quality based on the sinogram domain <ref type="bibr" target="#b2">[3]</ref>. In addition, cross-domain learning methods are able to learn CT data features from dual domains to construct models that approximate traditional reconstruction process <ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref>.</p><p>However, most DL-based CT reconstruction methods are condition-specific, i.e., dose-specific, and geometry-specific. In the dose-specific case, these methods are constructed on the dataset at one specific dose level, which might fail to obtain promising result at other dose levels. Centralized learning via collecting data at different dose levels is an alternative way, but it is difficult to collect sufficient data efficiently. In the geometry-specific case, the DL-based methods, especially the cross-domain learning methods, usually reconstruct the final image from the measured sinogram data with a specific imaging geometry that takes the geometry parameters into account during reconstruction. However, the geometry parameters in the scanner are vendor-specific and different from each other. Then the DL-based methods trained on data from one geometry would fail to be transferred to those from the other geometry due to the different characteristics distributions and big data heterogeneity among different geometries. Xia et al. constructed a framework for modulating deep learning models based on CT imaging geometry parameters to improve the reconstruction performance of the DL models under multiple CT imaging geometries <ref type="bibr" target="#b6">[7]</ref>, but the method did not consider model degradation due to variations in scanning conditions. Multi-task learning methods can be used to address this issue, but they are limited by the tedious design of auxiliary tasks, which leads to lower efficiency <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref>, and the privacy issues caused by the sharing of data are also limitations of these methods.</p><p>Different from the centralized learning, federated learning has potential to the train model on decentralized data without the need to centralized or share data, which provides significant benefits over centralized learning methods <ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref>. Federated learning has made achievements in medical imaging <ref type="bibr" target="#b13">[14]</ref> and applications in CT reconstruction, for example, Li et al. presented a semi-centralized federated learning method to promote the generalization performance of the learned global model <ref type="bibr" target="#b14">[15]</ref>, Yang et al. propose a hypernetwork-based federated learning method to construct personalized CT imaging models for local clients <ref type="bibr" target="#b15">[16]</ref>. However these methods are constructed on image domain and do not consider the perturbations of multi-source CT data on the sinogram domain, thus the local specificity is insufficien and the generalization of the model still needs to be improved.</p><p>Inspired by the previous work <ref type="bibr" target="#b3">[4]</ref> and federated learning framework, we propose a condition generalization method under a federated learning framework to reconstruct CT images from different conditions, i.e., different dose levels, different geometries, and different sampling shcemes. The proposed method is termed as federated condition generalization (FedCG). Specifically, the proposed FedCG method can be treated as the extension of iRadonMAP <ref type="bibr" target="#b3">[4]</ref> to the federated learning framework. And it leverages a cross-domain learning approach: individual-client sinogram learning, and cross-client image reconstruction for condition generalization. In each client, the sinogram at each individual condition is processed similarly to that in iRadonMAP, then the latent characteristics of reconstructed CT images at all conditions are processed through the framework via a condition generalization network in the server. The condition generalization network considers latent common characteristics in the CT images at all conditions and preserves the client-specific characteristics in each condition. Different from the existing FL framework, the server in the proposed FedCG holds a large amount of labeled data that is closer to real world. We validate the proposed FedCG method on two simulation studies, including three different dose levels at the same geometry, and three different sampling shcemes at the different geometries. The effectiveness of FedCG has been validated with significant performance improvements on both tasks compared with a number of competing methods and FL methods, as well as comprehensive ablation studies. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">iRadonMAP</head><p>As a cross-domain learning framework for Radon inversion in CT reconstruction, iRadonMAP consists of a sinogram domain sub-network, an image domain subnetwork, and a learnable back-projection layer, which can be written as follows <ref type="bibr" target="#b3">[4]</ref>:</p><formula xml:id="formula_0">μ = F i {F R -1 [F s (p; θ s ); θ R -1 ]; θ i }, (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where μ is the final image, p is the sinogram data, F s (•; θ s ) and F i (•; θ i ) denote the sinogram domain sub-network (i.e., SinoNet) and the image domain subnetwork (i.e., ImageNet) of iRadonMAP,</p><formula xml:id="formula_2">F R -1 (•; θ R -1</formula><p>) is learnable back projection layer, the details of F R -1 (•; θ R -1 ) are available in <ref type="bibr" target="#b3">[4]</ref>. θ denotes the parameters of networks.</p><p>Although iRadonMAP can obtain promising reconstruction result, the generalization is still an area that is poorly exploited. When iRadonMAP is trained on CT data with a particular condition (i.e., specific dose level and imaging geometry) and is inferred on CT data with a different condition, it would become unstable as a result of data heterogeneity among different conditions. Federated learning framework is an alternative strategy to address this issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Proposed FedCG Method</head><p>In this study, inspired by the previous work <ref type="bibr" target="#b3">[4]</ref> and federated learning framework, we propose a condition generalization method under a federated learning framework (FedCG) to reconstruct CT images from different conditions as an extension of the cross-domain learning framework iRadonMAP in federal learning. Specifically, the proposed FedCG is characterized by the following aspects: Individual-client Sinogram Learning. Due to the big data heterogeneity among different conditions and data privacy preservation, as shown in Fig. <ref type="figure" target="#fig_0">1</ref>, in the proposed FedCG, the sinogram data at each condition is processed via SinoNet and learnable back-projection layer as in the iRadonMAP, and the corresponding parameters are not exchanged to communication and augment data privacy when the clients have unique distributions. Furthermore, the individualclient sinogram learning strategy allows for processing condition-specific sionogram data, which can vary flexibly across clients and among different conditions. Then ImageNet can be utilized to reconstruct final CT images wherein the corresponding parameters are updated with the help of federated learning strategy. The central server collects the information from all clients without directly sharing the private data of each client.</p><p>Central Data Guidance Training. Different from the existing federated learning framework, the central server has labeled data that is closer to real world, as shown in Fig. <ref type="figure" target="#fig_0">1</ref>. In each training round, the central server model can obtain well-trained model with the labeled data, and then the corresponding parameters in the ImageNet can be updated as follows:</p><formula xml:id="formula_3">t+1 θ i = ω 0 t+1 θ 0 + (1 -ω 0 ) K k=1 ω k t+1 θ i k , (<label>2</label></formula><formula xml:id="formula_4">)</formula><p>where ω 0 is the weight of central model, ω k = n k n , where n k denotes the number of local iterations.</p><p>Condition Generalization in FL. To fully consider the unique distribution in each client, inspired by Xia et al. <ref type="bibr" target="#b6">[7]</ref>, we introduce condition generalization (CG) network to learn the deep features across scanners and protocols. Specifically, the CG network in each client generates a specific normalized parameters vector according to the imaging geometry and scanning protocol:</p><formula xml:id="formula_5">ρ = [g 1 , • • • , g n , C],<label>(3)</label></formula><p>where ρ represents the condition parameter in each client, g 1 , • • • , g n are normalized imaging geometric parameters. C is a parameter that represents protocol parameter (i.e., dose level, sparse views, and limited angles). In the kth local client, ρ k is fed into the local model along with the input data. And in the central server, all condition parameters are fed into the central model. As shown in Fig. <ref type="figure" target="#fig_0">1</ref>, multilayer perceptron (MLP) which consists of fully connected layers map ρ into high-dimensional condition vectors, and the vectors are used to modulate the feature map of the ImageNet as follows:</p><formula xml:id="formula_6">f = h 1 (ρ) f + h 2 (ρ),<label>(4)</label></formula><p>h 1 , h 2 are MLPs with shared parameters. f is the feature map of network layer, f is the modulated feature map. Then, the total loss function of the proposed FedCG can be written as follows:</p><formula xml:id="formula_7">L total = ω 0 μ * 0 -μ 0 2 2 + (1 -ω 0 )( K k=1 ω k μ * k -μ k 2 2 + K k=1 λ k ω k p * k -p k 1 ),<label>(5)</label></formula><p>where μ * 0 is the noise-free image in the central server, μ * k is the noise-free image in the kth client, μ 0 is the output image of central ImageNet, μ k is the output image of iRadonMAP in the kth client, p * k is the noise-free sinogram in the kth client, p k is the intermediate output of SinoNet in the kth client, λ is the parameter that controls the singoram loss function in the local client.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset</head><p>The experiments are carried out on three publicly available datasets (120, 000 CT images) <ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref>, six private datasets from different scanners (Data #1: 1100 brain CT images, Data #2: 1500 chest CT images, Data #3: 847 body phantom CT images, Data #4: 1600 body phantom CT images, Data #5: 1561 abdomen CT images, Data #6: 1598 abdomen CT images). In the experiment, two different conditions are presented, i.e., different dose levels with different geometries (Condition #1), and different sampling shcemes with different geometries (Condition #2).</p><p>In the Condition #1, the three publicly available datasets are collected for the central server, Data #1, Data #2, and Data #3 are selected for three local clients (Client #1, Client #2 and Client #3), respectively. We obtained the corresponding low-dose sinogram data at different dose levels from the normal-dose CT images based on the previous study, respectively <ref type="bibr" target="#b19">[20]</ref>. The X-ray intensities of Clients #1, #2, #3 are 5e5, 2e5, 1e5. In Condition #2, the simulated limitedangle CT images, sparse-view CT images, and ultra-low-dose CT images from the publicly available datasets are collected for the central server. Data #4 contains simulated limited-angle cases (120 degrees of parallel beam, with full angles of 180 degrees), Data #5 contains simulated sparse-view cases (144 views, with full views of 1152) and Data #6 contains simulated ultra-low-dose cases (X-ray intensity of 5e4) are icollected for the three local clients, respectively. In the both experiments, ninety percent of data are used for training and the remaining for testing for all clients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Implementation Details</head><p>FedCG is constructed by Pytorch toolbox <ref type="bibr" target="#b20">[21]</ref>, training with an NVIDIA RTX A6000 graphics processing unit with 48 GB memory, and the CT simulation and reconstruction are carried out by the Astra toolbox <ref type="bibr" target="#b21">[22]</ref>. The iRadonMAPs in all the local clients and the ImageNet in the central server are optimized by the RMSProp optimizer, and the learning rate of all the models is 2e-5. The number of training rounds is set to 1000, and the central ImageNet has 100 iterations per round while each local client has 10. ω 0 in the Eq. 2 is empirically set to 0.6. More details on the imaging geometries and architecture of the iRdaonMAP can be found in the supplementary materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Result</head><p>In this work, five algorithms are selected for comparison. The classical FBP algorithm and the iRadonMAPs trained on condition-specific dataset, FedAvg <ref type="bibr" target="#b9">[10]</ref>, Fedprox <ref type="bibr" target="#b10">[11]</ref> and FedBN <ref type="bibr" target="#b11">[12]</ref>. Peak signal-to-noise ratio (PSNR), structural similarity index (SSIM) and root mean square error (RMSE) are used to quantify reconstruction performance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Reuslt on Condition #1</head><p>Figure <ref type="figure" target="#fig_1">2</ref> shows results reconstructed by all the competing methods on Condition #1 wherein the normal-dose FBP images are chosen as ground truth for comparison. The results show that the proposed FedCG produces the sharpest images with fine details at all clients, as apparent from the zoomed-in regions of interest (ROIs). Although iRadonMAP can suppress noise-induced artifacts to some extent, it might introduce undesired artifacts as indicated by the red arrows. FedAvg and FedProx can also produce sharp images, but the reconstruction of the fine structure details is less detailed than that in FedCG results. Moreover, the shifted values occur in both FedAvg and FedProx results, as indicated by the blue arrows. FedBN can reconstruct the textures with less noise, but with unsatisfactory performance in the fine texture recovery as indicated by purple arrows. Furthermore, the quantitative measurements also indicate that the proposed FedCG can obtain the best performance among all the competing methods. The possible reason might be that the labeled data in the central server provide sufficient prior information to promote FedCG reconstruction performance. More experimental results are listed in the supplementary materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Result on Condition #2</head><p>Figure <ref type="figure" target="#fig_2">3</ref> shows the results reconstructed by all the competing methods on Condition #2 wherein the normal-dose FBP images are chosen as ground truth for comparison. It can be observed that the iRadonMAP can produce promising reconstruction results that are closest to the ground truth as it is trained with the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Ablation Experiments</head><p>ω 0 plays a key role in the proposed FedCG reconstruction performance, then we conduct ablation experiments with different ω 0 on settings Condition #1. Figure <ref type="figure" target="#fig_3">4</ref> shows the mean value of PSNR, SSIM, and RMSE with different ω 0 settings. From the results, when ω 0 = 0, FedCG approaches to FedAvg with poor performance. When ω 0 ∈ [0, 0.2], both Client #1 and Client #2 obtain degraded reconstruction performance and Client #3 obtains improved reconstruction performance. And when ω 0 &gt; 0.3, we can see that the reconstruction accuracy increases with increasing ω 0 for Client #1 and Client #2, but reconstruction accuracy for Client #3 degrades with increasing ω 0 . Setting ω 0 = 0.6 yields the best results with the weighted central server parameters leading substantial improvement in all quantitative measurements for Client #1 and Client #2, while setting ω 0 = 0.3 for client #3. The possible reason might be that the similar information are shared among the central server and Client #1, Client #2, but there is large heterogeneity between central server and Client #3. When ω 0 &gt; 0.6, the performance for all clients degrades obviously due to an overly large weight which affects the unique information of each client. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this work, we propose a condition generalization method under a federated learning framework to reconstruct CT images on different conditions. Experiments on different dose levels with different geometries, and different sampling shcemes with different geometries show that the proposed FedCG achieves improved reconstruction performance compared with the other competing methods at all the cases qualitatively and quantitatively.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Pipeline of the proposed FedCG.</figDesc><graphic coords="3,55,47,387,98,341,71,158,17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Reconstruction results of Condition #1. The display windows for CT images at Client #1, Client #2, Client #3 are [-150,150], [-150,150], [-200,200] HU, respectively. The display windows for zoomed-in ROIs are [-10,150], [-30,50], [-150,150] HU, respectively.</figDesc><graphic coords="7,55,98,59,96,340,18,161,74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Reconstruction results of Condition #2. The display windows of Client #1, Client #2, Client #3 are [-1024,400], [-100,100], [-200,200] HU, respectively, with the same in zoomed-in ROIs</figDesc><graphic coords="8,45,72,58,49,335,41,164,20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Mean values of FedCG's quantitative metrics under different ω0.</figDesc><graphic coords="9,63,18,59,24,332,98,175,48" type="bitmap" /></figure>
		</body>
		<back>

			<div type="funding">
<div><p>This work was supported in part by the <rs type="funder">NSFC</rs> under Grant <rs type="grantNumber">U21A6005</rs>, and Grant <rs type="grantNumber">12226004</rs>, and <rs type="funder">Young Talent Support Project of Guangzhou Association for Science and Technology</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_PwX4Q3r">
					<idno type="grant-number">U21A6005</idno>
				</org>
				<org type="funding" xml:id="_bX44S8C">
					<idno type="grant-number">12226004</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43898-1_5.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Low-dose CT with a residual encoder-decoder convolutional neural network</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Kalra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2524" to="2535" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Noise-conscious explicit weighting network for robust low-dose CT imaging</title>
		<author>
			<persName><forename type="first">S</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physics of Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">12463</biblScope>
			<biblScope unit="page" from="711" to="718" />
			<date type="published" when="2023">2023. 2023</date>
			<publisher>SPIE</publisher>
		</imprint>
	</monogr>
	<note>Medical Imaging</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semi-supervised learned sinogram restoration network for lowdose CT image reconstruction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physics of Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">11312</biblScope>
			<biblScope unit="page" from="67" to="73" />
			<date type="published" when="2020">2020. 2020</date>
			<publisher>SPIE</publisher>
		</imprint>
	</monogr>
	<note>Medical Imaging</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Radon inversion via deep learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2076" to="2087" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Noise characteristics modeled unsupervised network for robust CT image reconstruction</title>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3849" to="3861" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Dual-domain modulation for high-performance multi-geometry low-dose CT image reconstruction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physics of Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">12463</biblScope>
			<biblScope unit="page" from="687" to="693" />
			<date type="published" when="2023">2023. 2023</date>
			<publisher>SPIE</publisher>
		</imprint>
	</monogr>
	<note>Medical Imaging</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">CT reconstruction with PDF: parameter-dependent framework for data from multiple geometries and dose levels</title>
		<author>
			<persName><forename type="first">W</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3065" to="3076" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Revisiting multi-task learning in the deep learning era</title>
		<author>
			<persName><forename type="first">S</forename><surname>Vandenhende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Georgoulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Proesmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.13379</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A brief review on multi-task learning</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Thung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Wee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multimedia Tools Appl</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="29705" to="29725" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Communication-efficient learning of deep networks from decentralized data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hampson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Arcas</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Statistics</title>
		<imprint>
			<biblScope unit="page" from="1273" to="1282" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Federated optimization in heterogeneous networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Sahu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sanjabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Talwalkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Mach. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="429" to="450" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.07623</idno>
		<title level="m">Fedbn: federated learning on non-iid features via local batch normalization</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Federated adversarial domain adaptation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.02054</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The future of digital health with federated learning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Rieke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">119</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Semi-centralized federated learning network for low-dose CT imaging</title>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physics of Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">12463</biblScope>
			<biblScope unit="page" from="1024" to="1028" />
			<date type="published" when="2023">2023. 2023</date>
			<publisher>SPIE</publisher>
		</imprint>
	</monogr>
	<note>Medical Imaging</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Hypernetwork-based personalized federated learning for multi-institutional CT imaging</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.03709</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">TU-FG-207A-04: overview of the low dose CT grand challenge</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mccollough</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Phys</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3759" to="3760" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>Part35</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">U</forename><surname>Gava</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>Unitobrain</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">The kits19 challenge data: 300 kidney tumor cases with clinical context, CT semantic segmentations, and surgical outcomes</title>
		<author>
			<persName><forename type="first">N</forename><surname>Heller</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.00445</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A simple low-dose x-ray CT simulation from high-dose scan</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Nucl. Sci</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2226" to="2233" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<title level="m">Automatic differentiation in pytorch</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Fast and flexible X-ray tomography using the ASTRA toolbox</title>
		<author>
			<persName><forename type="first">W</forename><surname>Van Aarle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Opt. Exp</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="25129" to="25147" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
