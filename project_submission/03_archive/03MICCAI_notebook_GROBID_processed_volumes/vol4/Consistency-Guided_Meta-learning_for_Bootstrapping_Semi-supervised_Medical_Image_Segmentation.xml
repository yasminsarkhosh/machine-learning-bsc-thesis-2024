<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Consistency-Guided Meta-learning for Bootstrapping Semi-supervised Medical Image Segmentation</title>
				<funder>
					<orgName type="full">Stanford 2022 HAI</orgName>
				</funder>
				<funder ref="#_fbhVVt2 #_3kM7J3E">
					<orgName type="full">National Institutes of Health</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Qingyue</forename><surname>Wei</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
								<address>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yu</forename><surname>Lequan</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">The University of Hong Kong</orgName>
								<address>
									<addrLine>Pok Fu Lam</addrLine>
									<settlement>Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xianhang</forename><surname>Li</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Santa Cruz</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wei</forename><surname>Shao</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">University of Florida</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Cihang</forename><surname>Xie</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Santa Cruz</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lei</forename><surname>Xing</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
								<address>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuyin</forename><surname>Zhou</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Santa Cruz</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Consistency-Guided Meta-learning for Bootstrapping Semi-supervised Medical Image Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1029C353E860C5FC73881A9AF7789774</idno>
					<idno type="DOI">10.1007/978-3-031-43901-818.</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-13T19:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>semi-supervised learning</term>
					<term>meta-learning</term>
					<term>medical image segmentation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Medical imaging has witnessed remarkable progress but usually requires a large amount of high-quality annotated data which is time-consuming and costly to obtain. To alleviate this burden, semisupervised learning has garnered attention as a potential solution. In this paper, we present Meta-Learning for Bootstrapping Medical Image Segmentation (MLB-Seg), a novel method for tackling the challenge of semi-supervised medical image segmentation. Specifically, our approach first involves training a segmentation model on a small set of clean labeled images to generate initial labels for unlabeled data. To further optimize this bootstrapping process, we introduce a per-pixel weight mapping system that dynamically assigns weights to both the initialized labels and the model's own predictions. These weights are determined using a meta-process that prioritizes pixels with loss gradient directions closer to those of clean data, which is based on a small set of precisely annotated images. To facilitate the meta-learning process, we additionally introduce a consistency-based Pseudo Label Enhancement (PLE) scheme that improves the quality of the model's own predictions by ensembling predictions from various augmented versions of the same input. In order to improve the quality of the weight maps obtained through multiple augmentations of a single input, we introduce a mean teacher into the PLE scheme. This method helps to reduce noise in the weight maps and stabilize its generation process. Our extensive experimental results on public atrial and prostate segmentation datasets demonstrate that our proposed method achieves state-of-the-art results under semi-supervision. Our code is available at https://github.com/aijinrjinr/MLB-Seg.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Reliable and robust segmentation of medical images plays a significant role in clinical diagnosis <ref type="bibr" target="#b13">[12]</ref>. In recent years, deep learning has led to significant progress in image segmentation tasks <ref type="bibr" target="#b7">[6,</ref><ref type="bibr" target="#b28">26]</ref>. However, training these models <ref type="bibr" target="#b25">[23]</ref> requires large-scale image data with precise pixel-wise annotations, which are usually time-consuming and costly to obtain. To address this challenge, recent studies have explored semi-supervised learning approaches for medical image segmentation, leveraging unlabeled data to enhance performance <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b23">21]</ref>. Semi-supervised learning (SSL) commonly uses two methods: pseudo labeling and consistency regularization. Pseudo labeling uses a model's predictions on unlabeled data to create "pseudo labels" and augment the original labeled data set, allowing for improved accuracy and reduced cost in training <ref type="bibr" target="#b2">[2,</ref><ref type="bibr" target="#b8">7,</ref><ref type="bibr" target="#b11">10]</ref>. Despite its potential benefits, the pseudo labeling approach may pose a risk to the accuracy of the final model by introducing inaccuracies into the training data. Consistency regularization, on the other hand, aims to encourage the model's predictions to be consistent across different versions of the same input. UA-MT <ref type="bibr" target="#b24">[22]</ref> and DTC <ref type="bibr" target="#b12">[11]</ref> are examples of consistency regularization-based methods that use teacher-student models for segmentation and emphasize dual consistency between different representations, respectively.</p><p>Combining both methods can potentially lead to improved performance, as pseudo labeling leverages unlabeled data and consistency regularization improves the model's robustness <ref type="bibr" target="#b3">[3,</ref><ref type="bibr" target="#b22">20]</ref>. However, pseudo labeling still inevitably introduces inaccuracies that can hinder the model's performance. To overcome this challenge, we propose a novel consistency-guided meta-learning framework called Meta-Learning for Bootstrapping Medical Image Segmentation (MLB-Seg). Our approach uses pixel-wise weights to adjust the importance of each pixel in the initialized labels and pseudo labels during training. We learn these weights through a meta-process that prioritizes pixels with loss gradient direction closer to those of clean data, using a small set of clean labeled images. To further improve the quality of the pseudo labels, we introduce a consistency-based Pseudo Label Enhancement (PLE) scheme that ensembles predictions from augmented versions of the same input. To address the instability issue arising from using data augmentation, we incorporate a mean-teacher model to stabilize the weight map generation from the student meta-learning model, which leads to improved performance and network robustness. Our proposed approach has been extensively evaluated on two benchmark datasets, LA <ref type="bibr" target="#b4">[4]</ref> and PROMISE12 <ref type="bibr" target="#b10">[9]</ref>, and has demonstrated superior performance compared to existing methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>We present MLB-Seg, a novel consistency-guided meta-learning framework for semi-supervised medical image segmentation. Assume that we are given a training dataset consisting of clean data D c = {(x c i , y c i )} N i=1 , and unlabeled data</p><formula xml:id="formula_0">D u = {(x u k )} K k=1 (N K)</formula><p>, where the input image x c i , x u k are of size H × W with the corresponding clean ground-truth mask y c i . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Meta-learning for Bootstrapping</head><p>We first estimate labels for all unlabeled data using the baseline model which is trained on the clean data, denoted as follows</p><formula xml:id="formula_1">y ñ k = f c (x u k ; θ c ),<label>(1)</label></formula><p>where f c (:; θ c ) denotes the trained model parameterized by θ c and k = 1, 2, ..., K.</p><p>We further denote them as D n = {(x ñ j , y ñ j )} K j=1 . We then develop a novel meta-learning model for medical image segmentation, which learns from the clean set D c to bootstrap itself up by leveraging the learner's own predictions (i.e., pseudo labels), called Meta-Learning for Bootstrapping (MLB). As shown in Fig. <ref type="figure" target="#fig_0">1</ref>, by adaptively adjusting the contribution between the initialized and pseudo labels commensurately in the loss function, our method effectively alleviates the negative effects from the erroneous pixels. Specifically, at training step t, given a training batch from</p><formula xml:id="formula_2">D n that S n = {(x ñ j , y ñ j ), 1 ≤ j ≤ b n } and a clean training batch S c = {(x c i , y c i ), 1 ≤ i ≤ b c } where b n , b c</formula><p>are the batch size respectively. Our objective is:</p><formula xml:id="formula_3">θ * (w n , w p ) = arg min θ K j=1 w n j • L(f (x ñ j ; θ), y ñ j ) + w p j • L(f (x ñ j ; θ), y p j ),<label>(2)</label></formula><formula xml:id="formula_4">y p j = arg max c=1,...,C f (x ñ j ; θ),<label>(3)</label></formula><p>where y p j is the pseudo label generated by f (x ñ j ; θ), L(•) is the cross-entropy loss function, C is the number of classes (we set C = 2 throughout this paper), w n j , w p j ∈ R H×W are the weight maps used for adjusting the contribution between the initialized and the pseudo labels in two different loss terms. • denotes the Hadamard product. We aim to solve for Eq. 2 following 3 steps:</p><p>-Step 1: Update θt+1 based on S n and current weight map set. Following <ref type="bibr" target="#b16">[15]</ref>, during training step t, we calculate θt+1 to approach the optimal θ * (w n , w p ) as follows:</p><formula xml:id="formula_5">θt+1 = θ t -α∇( bn j=1 w n j • L(f (x ñ j ; θ), y ñ j ) + w p j • L(f (x ñ j ; θ), y p j )) θ=θt , (<label>4</label></formula><formula xml:id="formula_6">)</formula><p>where α represents the step size. -Step 2: Generate the meta-learned weight maps w n * , w p * based on S c and θt+1 by minimizing the standard cross-entropy loss in the meta-objective function over the clean training data:</p><formula xml:id="formula_7">w n * , w p * = arg min w n ,w p ≥0 1 N N i=1 L(f (x c i ; θ * (w n , w p )), y c i ).<label>(5)</label></formula><p>Note that here we restrict every element in w n/p to be non-negative to prevent potentially unstable training <ref type="bibr" target="#b16">[15]</ref>. Such a meta-learned process yields weight maps which can better balance the contribution of the initialized and the pseudo labels, thus reducing the negative effects brought by the erroneous pixels. Following <ref type="bibr" target="#b16">[15,</ref><ref type="bibr" target="#b27">25]</ref>, we only apply one-step gradient descent of w n/p j based on a small clean-label data set S c , to reduce the computational expense. To be specific, at training step t, w n/p j is first initialized as 0, then we estimate w n * , w p * as: </p><formula xml:id="formula_8">(w n j,t , w p j,t ) = -β∇( 1 b c bc i=1 L(f (x c i ; θt+1 ), y c i )) w n j ,w p j =0 ,<label>(6)</label></formula><p>where β stands for the step size and w n/pr,s j,t</p><p>indicates the value at r th row, s th column of w n/p j at time t. Equation 7 is used to enforce all weights to be strictly non-negative. Then Eq. 8 is introduced to normalize the weights in a single training batch so that they sum up to one. Here, we add a small number to keep the denominator greater than 0.</p><p>-Step 3: The meta-learned weight maps are used to spatially modulate the pixel-wise loss to update θ t+1 :</p><formula xml:id="formula_10">θ t+1 = θ t -α∇( bn j=1 w n j,t • L(f (x ñ j ; θ), y ñ j ) + w p j,t • L(f (x ñ j ; θ), y p j )) θ=θt . (9)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Consistency-Based Pseudo Label Enhancement</head><p>To generate more reliable pseudo labels, we propose Pseudo Label Enhancement (PLE) scheme based on consistency, which enforces consistency across augmented versions of the same input. Specifically, we perform Q augmentations on the same input image and enhance the pseudo label by averaging the outputs of the Q augmented versions and the original input:</p><formula xml:id="formula_11">y p j = arg max c=1,...,C 1 Q + 1 ( Q q=1 τ -1 q (f (x ñq j ; θ)) + f (x ñ0 j ; θ)), (<label>10</label></formula><formula xml:id="formula_12">)</formula><p>where f (x ñq j ; θ) is the output of q-th augmented sample, f (x ñ0 N +j ; θ) is the output of the original input, and τ -1 q means the corresponding inverse transformation of the q-th augmented sample. Meanwhile, to further increase the output consistency among all the augmented samples and original input, we introduce an additional consistency loss L Aug c to the learning objective:</p><formula xml:id="formula_13">L Aug c (x ñ j ) = 2 (Q + 1)Q 1 HW q,v r,s ||f (x ñq j ; θ) r,s -τ q (τ -1 v (f (x ñv j ; θ))) r,s || 2 ,<label>(11)</label></formula><p>where (r, s) denotes the pixel index. τ q is the corresponding transformation to generate the q-th augmented sample. (q, v) denotes the pairwise combination among all augmented samples and the original input. The final loss is the mean square distance among all (Q+1)Q 2 pairs of combinations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Mean Teacher for Stabilizing Meta-learned Weights</head><p>Using PLE alone can result in performance degradation with increasing numbers of augmentations due to increased noise in weight maps. This instability can compound during subsequent training iterations. To address this issue during meta-learning, we propose using a mean teacher model <ref type="bibr" target="#b18">[17]</ref> with consistency loss (Eq. 13). The teacher network guides the student meta-learning model, stabilizing weight updates and resulting in more reliable weight maps. Combining PLE with the mean teacher model improves output robustness. The student model is used for meta-learning, while the teacher model is used for weight ensemble with Exponential Moving Average (EMA) <ref type="bibr" target="#b18">[17]</ref> applied to update it. The consistency loss maximizes the similarity between the teacher and student model outputs, adding reliability to the student model and stabilizing the teacher model. For each input x ñ j in the batch S n , we apply disturbance to the student model input to become the teacher model input. Then a consistency loss L ST c is used to maximize the similarity between the outputs from the teacher model and student model, further increasing the student model's reliability while stabilizing the teacher model. Specifically, for each input x ñ j in the batch S n , then corresponding input of teacher model is</p><formula xml:id="formula_14">x T j = x ñ j + γN (μ, σ), (<label>12</label></formula><formula xml:id="formula_15">)</formula><p>where N (μ, σ) ∈ R H×W denotes the Gaussian distribution with μ as mean and σ as standard deviation. And γ is used to control the noise level. The consistency loss is implemented based on pixel-wise mean squared error (MSE) loss:</p><formula xml:id="formula_16">L ST c (x ñ j ) = 1 HW r,s ||f (x ñ j ; θ S t ) r,s -f (x T j ; θ T t ) r,s || 2 . (<label>13</label></formula><formula xml:id="formula_17">)</formula><p>3 Experiments</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Setup</head><p>Datasets. We evaluate our proposed method on two different datasets including 1) the left atrial (LA) dataset from the 2018 Atrial Segmentation Challenge <ref type="bibr" target="#b4">[4]</ref> as well as 2) the Prostate MR Image Segmentation 2012 (PROMISE2012) dataset <ref type="bibr" target="#b10">[9]</ref>. Specifically, LA dataset is split into 80 scans for training and 20 scans for evaluation following <ref type="bibr" target="#b24">[22]</ref>. From the training set, 8 scans are randomly selected as the meta set. All 2D input images were resized to 144 × 144. For PROMISE2012, we randomly split 40/4/6 cases for training and 10 for evaluation (4 for validation, 6 for test) following <ref type="bibr" target="#b14">[13]</ref>. We randomly pick 3 cases from the training set as the meta set and resize all images to 144 × 144. We evaluate our segmentation performances using four metrics: the Dice coefficient, Jaccard Index (JI), Hausdorff Distance (HD), and Average Surface Distance (ASD).</p><p>Implementation Details. All of our experiments are based on 2D images. We adopt UNet++ as our baseline. Network parameters are optimized by SGD setting the learning rate at 0.005, momentum to be 0.9 and weight decay as 0.0005. The exponential moving average (EMA) decay rate is set as 0.99 following <ref type="bibr" target="#b18">[17]</ref>.</p><p>For the label generation process, we first train with all clean labeled data for 30 epochs with batch size set as 16. We then use the latest model to generate labels for unlabeled data. Next, we train our MLB-Seg for 100 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results Under Semi-supervision</head><p>To illustrate the effectiveness of MLB-Seg under semi-supervision. We compare our method with the baseline (UNet++ <ref type="bibr" target="#b28">[26]</ref>) and previous semi-supervised methods on LA dataset (Table <ref type="table" target="#tab_1">1</ref>) and PROMISE12 (Table <ref type="table" target="#tab_2">2</ref>), including an adversarial learning method <ref type="bibr" target="#b26">[24]</ref>, consistency based methods <ref type="bibr" target="#b6">[5,</ref><ref type="bibr" target="#b12">11,</ref><ref type="bibr" target="#b19">18,</ref><ref type="bibr" target="#b22">20,</ref><ref type="bibr" target="#b24">22]</ref>, an uncertaintybased strategy <ref type="bibr" target="#b0">[1]</ref>, and contrastive learning based methods <ref type="bibr" target="#b14">[13,</ref><ref type="bibr" target="#b21">19]</ref>. For a fair comparison in Table <ref type="table" target="#tab_2">2</ref>, we also use UNet <ref type="bibr" target="#b17">[16]</ref> as the backbone and resize images to 256 × 256, strictly following the settings in Self-Paced <ref type="bibr" target="#b14">[13]</ref>. We split the evaluation set (10 cases) into 4 cases as the validation set, and 6 as the test set.</p><p>We then select the best checkpoint based on the validation set and report the results on the test set. As shown in Table <ref type="table" target="#tab_1">1</ref> and 2, our MLB-Seg outperforms recent state-of-the-art methods on both PROMISE12 (under different combinations of backbones and image sizes) and the LA dataset across almost all evaluation measures. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Ablation Study</head><p>To explore how different components of our MLB-Seg contribute to the final result, we conduct the following experiments under semi-supervision on PROMISE12: 1) the bootstrapping method <ref type="bibr" target="#b15">[14]</ref> (using fixed weights without applying meta-learning); 2) MLB, which only reweights the initialized labels and pseudo labels without applying PLE and mean teacher; 3) MLB + mean teacher which combines MLB with mean teacher scheme; 4) MLB + PLE which applies PLE strategy with MLB. When applying multiple data augmentations (i.e., for Q = 2, 4), we find the best performing combinations are 2 × PLE (using one zoom in and one zoom out), 4 × PLE (using one zoom in and two zoom out and one flip for each input); 5) MLB + PLE + mean teacher which combines PLE, mean teacher with MLB simultaneously to help better understand how mean teacher will contribute to PLE. Our results are summarized in Table <ref type="table" target="#tab_3">3</ref>, which shows the effectiveness of our proposed components. The best results are achieved when all components are used.</p><p>To demonstrate how PLE combined with the mean teacher model help stabilize the meta-weight update, we compare the performance of MLB + PLE (w/mean teacher) with MLB + PLE + mean teacher under different augmentations (Q) on PROMISE12 dataset (See supplementary materials for details). We find out that for MLB + PLE (w/o mean teacher), performance improves from 74.34% to 74.99% when Q is increased from 1 to 2, but decreases significantly when Q ≥ 4. Specifically, when Q reaches 4 and 6, the performance significant drops from 74.99% to 72.07% (Q = 4) and from 74.99% to 70.91% (Q = 6) respectively. We hypothesize that this is due to increased noise from initialized labels in some training samples, which can lead to instability in weight updates. To address this issue, we introduce the mean-teacher model <ref type="bibr" target="#b18">[17]</ref> into PLE to stabilize weight map generation from the student meta-learning model. And MLB + PLE + mean teacher turns out to consistently improve the stability of metalearning compared with its counterpart without using mean teacher, further validating the effectiveness of our method (see Supplementary for more examples). Specifically, for MLB + PLE + mean teacher, the performance reaches 76.63% (from 72.07%) when Q = 4, 75.84% (from 70.91%) when Q = 6.</p><p>Qualitative Analysis. To illustrate the benefits of MLB-Seg for medical image segmentation, we provide a set of qualitative examples in Fig. <ref type="figure" target="#fig_1">2</ref>. In the visualization of weight maps of Fig. <ref type="figure" target="#fig_1">2</ref>, the blue/purple represents for the initialized label in y ñ/y p , while the red indicates pixels in w p * have higher values. We observe that MLB-Seg places greater emphasis on edge information. It is evident that higher weights are allotted to accurately predicted pseudo-labeled pixels that were initially mislabeled, which effectively alleviates the negative effects from erroneously initialized labels. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we propose a novel meta-learning based segmentation method for medical image segmentation under semi-supervision. With few expert-level labels as guidance, our model bootstraps itself up by dynamically reweighting the contributions from initialized labels and its own outputs, thereby alleviating the negative effects of the erroneous voxels. In addition, we address an instability issue arising from the use of data augmentation by introducing a mean teacher model to stabilize the weights. Extensive experiments demonstrate the effectiveness and robustness of our method under semi-supervision. Notably, our approach achieves state-of-the-art results on both the LA and PROMISE12 benchmarks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Schematic of the proposed MLB-Seg. Weight maps w n * , w p * associated with the initialized labels and pseudo labels are meta-learned and optimization is further improved by enhancing the pseudo label estimation. A mean teacher model is used to provide guidance for stabilizing the weight meta-update in the student model.</figDesc><graphic coords="3,64,47,53,87,323,38,149,83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Weight map visualization.</figDesc><graphic coords="9,87,96,63,83,276,79,123,61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Comparison with existing methods under semi-supervision on LA dataset.</figDesc><table><row><cell>Method</cell><cell cols="4">Dice (%)↑ JI (%)↑ HD (voxel)↓ ASD (voxel)↓</cell></row><row><cell>UNet++ [26]</cell><cell>81.33</cell><cell>70.87</cell><cell>14.79</cell><cell>4.62</cell></row><row><cell>DAP [24]</cell><cell>81.89</cell><cell>71.23</cell><cell>15.81</cell><cell>3.80</cell></row><row><cell>UA-MT [22]</cell><cell>84.25</cell><cell>73.48</cell><cell>13.84</cell><cell>3.36</cell></row><row><cell>SASSNet [8]</cell><cell>87.32</cell><cell>77.72</cell><cell>9.62</cell><cell>2.55</cell></row><row><cell>LG-ER-MT [5]</cell><cell>85.54</cell><cell>75.12</cell><cell>13.29</cell><cell>3.77</cell></row><row><cell>DUWM [18]</cell><cell>85.91</cell><cell>75.75</cell><cell>12.67</cell><cell>3.31</cell></row><row><cell>DTC [11]</cell><cell>86.57</cell><cell>76.55</cell><cell>14.47</cell><cell>3.74</cell></row><row><cell>MC-Net [20]</cell><cell>87.71</cell><cell>78.31</cell><cell>9.36</cell><cell>2.18</cell></row><row><cell cols="2">Uncertainty-Based [1] 86.58</cell><cell>76.34</cell><cell>11.82</cell><cell>-</cell></row><row><cell>MLB-Seg</cell><cell>88.69</cell><cell cols="2">79.86 8.99</cell><cell>2.61</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Comparison with existing methods under semi-supervision on PROMISE12. All methods included in the comparison have been re-implemented using our data split to ensure a fair evaluation, with the provided source codes.</figDesc><table><row><cell>Method</cell><cell>Dice (%)↑</cell></row><row><cell>UNet++ [26]</cell><cell>68.85</cell></row><row><cell>UA-MT [22]</cell><cell>65.05</cell></row><row><cell>DTC [11]</cell><cell>63.44</cell></row><row><cell>SASSNet [8]</cell><cell>73.43</cell></row><row><cell>MC-Net [20]</cell><cell>72.66</cell></row><row><cell>SS-Net [19]</cell><cell>73.19</cell></row><row><cell cols="2">Self-Paced [13] (UNet, 256) 74.02</cell></row><row><cell>MLB-Seg (UNet, 144)</cell><cell>76.41</cell></row><row><cell>MLB-Seg (UNet, 256)</cell><cell>76.15</cell></row><row><cell cols="2">MLB-Seg (UNet++, 144) 77.22</cell></row><row><cell cols="2">MLB-Seg (UNet++, 256) 78.27</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Ablation study on different components used in MLB-Seg based on PROMISE12.</figDesc><table><row><cell cols="4">MLB mean teacher 2× PLE 4× PLE Dice (%)↑ JI (%)↑ HD (voxel)↓ ASD (voxel)↓</cell></row><row><cell>70.85</cell><cell>55.85</cell><cell>10.02</cell><cell>4.35</cell></row><row><cell>73.97</cell><cell>59.71</cell><cell>8.49</cell><cell>3.49</cell></row><row><cell>73.76</cell><cell>59.37</cell><cell>8.04</cell><cell>3.00</cell></row><row><cell>75.01</cell><cell>60.92</cell><cell>7.58</cell><cell>2.70</cell></row><row><cell>73.10</cell><cell>58.45</cell><cell>9.42</cell><cell>3.57</cell></row><row><cell>76.68</cell><cell cols="2">63.14 7.85</cell><cell>2.64</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgment. This work is supported by the <rs type="funder">Stanford 2022 HAI</rs> Seed Grant and <rs type="funder">National Institutes of Health</rs> <rs type="grantNumber">1R01CA256890</rs> and <rs type="grantNumber">1R01CA275772</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_fbhVVt2">
					<idno type="grant-number">1R01CA256890</idno>
				</org>
				<org type="funding" xml:id="_3kM7J3E">
					<idno type="grant-number">1R01CA275772</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Leveraging labeling representations in uncertainty-based semi-supervised segmentation</title>
		<author>
			<persName><forename type="first">Adiga</forename><surname>Vasudeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dolz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lombaert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">13438</biblScope>
			<biblScope unit="page" from="265" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Cham</forename><surname>Springer</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16452-1_26</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16452-126" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning with pseudo-ensembles</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Alsharif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Precup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">MixMatch: a holistic approach to semi-supervised learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Multi-task learning for left atrial segmentation on GE-MRI</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STACOM 2018</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Pop</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">11395</biblScope>
			<biblScope unit="page" from="292" to="301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Cham</forename><surname>Springer</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-12029-0_32</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-12029-032" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Local and global structure-aware entropy regularized mean teacher model for 3D left atrium segmentation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59710-8_55</idno>
		<idno>978-3-030-59710-8 55</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">MIC-CAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12261</biblScope>
			<biblScope unit="page" from="562" to="571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Mask R-CNN</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2961" to="2969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Pseudo-label: the simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Challenges in Representation Learning</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">896</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Shape-aware semi-supervised 3D semantic segmentation for medical images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59710-8_54</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-59710-8" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12261</biblScope>
			<biblScope unit="page">54</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Evaluation of prostate segmentation algorithms for MRI: the PROMISE12 challenge</title>
		<author>
			<persName><forename type="first">G</forename><surname>Litjens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="359" to="373" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">ACPL: anticurriculum pseudo-labelling for semi-supervised medical image classification</title>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Belagiannis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Carneiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="20697" to="20706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Semi-supervised medical image segmentation through dual-task consistency</title>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.04448</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A survey on medical image segmentation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Masood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sharif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Masood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yasmin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Raza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="14" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Self-paced contrastive learning for semi-supervised medical image segmentation with meta-labels</title>
		<author>
			<persName><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Desrosiers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pedersoli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6596</idno>
		<title level="m">Training deep neural networks on noisy labels with bootstrapping</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning to reweight examples for robust deep learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4334" to="4343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">U-Net: convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-24574-4_28</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-24574-428" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2015</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hornegger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">9351</biblScope>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Double-uncertainty weighted method for semi-supervised learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">12261</biblScope>
			<biblScope unit="page" from="542" to="551" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Cham</forename><surname>Springer</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59710-8_53</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-59710-853" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Exploring smoothness and class-separation for semi-supervised medical image segmentation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16443-9_4</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16443-94" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13435</biblScope>
			<biblScope unit="page" from="34" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Semi-supervised left atrium segmentation with mutual consistency training</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87196-3_28</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87196-328" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12902</biblScope>
			<biblScope unit="page" from="297" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">FUSSNet: fusing two sources of uncertainty for semisupervised medical image segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16452-1_46</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16452-146" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13438</biblScope>
			<biblScope unit="page" from="481" to="491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Uncertainty-aware self-ensembling model for semi-supervised 3D left atrium segmentation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-W</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Heng</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-32245-8_67</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-32245-867" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2019</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11765</biblScope>
			<biblScope unit="page" from="605" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A deep learning model integrating FCNNs and CRFs for brain tumor segmentation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="98" to="111" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Semi-supervised segmentation of liver using adversarial learning with deep atlas prior</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-32226-7_17</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-32226-717" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2019</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11769</biblScope>
			<biblScope unit="page" from="148" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.04291</idno>
		<title level="m">Learning to bootstrap for combating label noise</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">UNet++: a nested U-Net architecture for medical image segmentation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Rahman Siddiquee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tajbakhsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-00889-5_1</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-00889-51" />
	</analytic>
	<monogr>
		<title level="m">DLMIA/ML-CDS 2018</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Stoyanov</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">11045</biblScope>
			<biblScope unit="page" from="3" to="11" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
