<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping</title>
				<funder ref="#_HSZpWPM #_bhY4GaX #_2EnQABm">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_S6TuuQQ">
					<orgName type="full">Natural Science Foundation of Henan Province for Excellent Young Scholars</orgName>
				</funder>
				<funder ref="#_3hExbZJ">
					<orgName type="full">Beijing Municipal Natural Science Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Zhenyu</forename><surname>Tang</surname></persName>
							<email>tangzhenyu@buaa.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<postCode>100191</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhenyu</forename><surname>Zhang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Neurosurgery</orgName>
								<orgName type="institution">The First Affiliated Hospital of Zhengzhou University</orgName>
								<address>
									<postCode>480082</postCode>
									<settlement>Zhengzhou, Henan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Huabing</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<postCode>100191</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dong</forename><surname>Nie</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Alibaba Inc</orgName>
								<address>
									<postCode>311121</postCode>
									<settlement>Hangzhou, Zhejiang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jing</forename><surname>Yan</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Department of MRI</orgName>
								<orgName type="institution">The First Affiliated Hospital of Zhengzhou University</orgName>
								<address>
									<postCode>480082</postCode>
									<settlement>Zhengzhou, Henan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="786" to="795"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">F9ADA4906EB4F728639DC0B108694D83</idno>
					<idno type="DOI">10.1007/978-3-031-43901-8_75</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-13T19:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Brain tumor</term>
					<term>Survival prediction</term>
					<term>Subtyping</term>
					<term>Ordinal mixup</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Pre-operative survival prediction for diffuse glioma patients is desired for personalized treatment. Clinical findings show that tumor types are highly correlated with the prognosis of diffuse glioma. However, the tumor types are unavailable before craniotomy and cannot be used in pre-operative survival prediction. In this paper, we propose a new deep learning based pre-operative survival prediction method. Besides the common survival prediction backbone, a tumor subtyping network is integrated to provide tumor-type-related features. Moreover, a novel ordinal manifold mixup is presented to enhance the training of the tumor subtyping network. Unlike the original manifold mixup, which neglects the feature distribution, the proposed method forces the feature distribution of different tumor types in the order of risk grade, by which consistency between the augmented features and labels can be strengthened. We evaluate our method on both in-house and public datasets comprising 1936 patients and demonstrate up to a 10% improvement in concordance-index compared with the state-of-the-art methods. Ablation study further confirms the effectiveness of the proposed tumor subtyping network and the ordinal manifold mixup. Codes are available at https:// github.com/ginobilinie/osPred.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Diffuse glioma is a common malignant tumor with highly variable prognosis across individuals. To improve survival outcomes, many pre-operative survival prediction methods have been proposed with success. Based on the prediction results, personalized treatment can be achieved. For instance, Isensee et al. <ref type="bibr" target="#b0">[1]</ref> proposed a random forest model <ref type="bibr" target="#b1">[2]</ref>, which adopts the radiomics features <ref type="bibr" target="#b2">[3]</ref> of the brain tumor images, to predict the overall survival (OS) time of diffuse glioma patients. Nie et al. <ref type="bibr" target="#b3">[4]</ref> developed a multi-channel 3D convolutional neural network (CNN) <ref type="bibr" target="#b4">[5]</ref> to learn features from multimodal MR brain images and classify OS time as long or short using a support vector machine (SVM) model <ref type="bibr" target="#b5">[6]</ref>. In <ref type="bibr" target="#b6">[7]</ref>, an end-to-end CNN-based method was presented that uses multimodal MR brain images and clinical features such as Karnofsky performance score <ref type="bibr" target="#b7">[8]</ref> to predict OS time. In <ref type="bibr" target="#b8">[9]</ref>, an imaging phenotype and genotype based survival prediction method (PGSP) was proposed, which integrates tumor genotype information to enhance prediction accuracy.</p><p>Despite the promising results of existing pre-operative survival prediction methods, they often overlook clinical knowledge that could aid in improving the prediction accuracy. Notably, tumor types have been found to be strongly correlated with the prognosis of diffuse glioma <ref type="bibr" target="#b9">[10]</ref>. Unfortunately, tumor type information is unavailable before craniotomy. To address this limitation, we propose a new pre-operative survival prediction method that integrates a tumor subtyping network into the survival prediction backbone. The subtyping network is responsible for learning tumor-type-related features from pre-operative multimodal MR brain images. Concerning the inherent issue of imbalanced tumor types in the training data collected in clinic, a novel ordinal manifold mixup based feature augmentation is presented and applied in the training stage of the tumor subtyping network. Unlike the original manifold mixup <ref type="bibr" target="#b10">[11]</ref>, which ignores the feature distribution of different classes, in the proposed ordinal manifold mixup, feature distribution of different tumor types is encouraged to be in the order of risk grade, and the augmented features are produced between neighboring risk grades. In this way, inconsistency between the augmented features and the corresponding labels can be effectively reduced.</p><p>Our method is evaluated using pre-operative multimodal MR brain images of 1726 diffuse glioma patients collected from cooperation hospitals and a public dataset BraTS2019 <ref type="bibr" target="#b11">[12]</ref> containing multimodal MR brain images of 210 patients. Our method achieves the highest prediction accuracy of all state-of-the-art methods under evaluation. In addition, ablation study further confirms the effectiveness of the proposed tumor subtyping network and the ordinal manifold mixup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>Diffuse glioma can be classified into three histological types: the oligodendroglioma, the astrocytoma, and the glioblastoma <ref type="bibr" target="#b9">[10]</ref>. The median survival times (in months) are 119 (oligodendroglioma), 36 (astrocytoma), and 8 (glioblastoma) <ref type="bibr" target="#b12">[13]</ref>. So the tumor types have strong correlation with the prognosis of diffused glioma. Based on this observation, we propose a new pre-operative survival prediction method (see Fig. <ref type="figure" target="#fig_0">1</ref>). Our network is composed of two parts: the survival prediction backbone and the tumor subtyping network. The survival prediction backbone is a deep Cox proportional hazard model <ref type="bibr" target="#b13">[14]</ref> which takes the multimodal MR brain images of diffuse glioma patients as inputs and predicts the corresponding risks. The tumor subtyping network is a classification network, which classifies the patient tumor types and feeds the learned tumor-type-related features to the backbone to enhance the survival prediction performance.</p><p>The tumor subtyping network is trained independently before being integrated into the backbone. To solve the inherent issue of imbalanced tumor type in the training data collected in clinic, a novel ordinal manifold mixup based feature augmentation is applied in the training of the tumor subtyping network. It is worth noting that the ground truth of tumor types, which is determined after craniotomy, is available in the training data, while for the testing data, tumor types are not required, because tumor-type-related features can be learned from the pre-operative multimodal MR brain images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The Survival Prediction Backbone</head><p>The architecture of the survival prediction backbone, depicted in Fig. <ref type="figure" target="#fig_0">1</ref> top, consists of an encoder E cox with four ResBlocks <ref type="bibr" target="#b14">[15]</ref>, a global average pooling layer (GAP), and three fully connected (FC) layers. Assume that D = {x 1 , ..., x N } is the dataset containing pre-operative multimodal MR brain images of diffuse glioma patients, and N is the number of patients. The backbone is responsible for deriving features from x i to predict the risk of the patient. Moreover, after the GAP of the backbone, the learned feature</p><formula xml:id="formula_0">f cox i ∈ R M is concatenated with the tumor-type-related feature f type i ∈ R M learned</formula><p>from the tumor subtyping network (discussed later), and M is the vector dimension which is set to 128. As f type i has strong correlation with prognosis, the performance of the backbone can be improved. In addition, information of patient age and tumor position is also used. To encode the tumor position, the brain is divided into 3 × 3 × 3 blocks, and the tumor position is represented by 27 binary values (0 or 1) with each value for one block. If a block contains tumors, then the corresponding binary value is 1, otherwise is 0. The backbone is based on the deep Cox proportional hazard model, and the loss function is defined as:</p><formula xml:id="formula_1">L Cox = - N i=1 δ i ⎛ ⎝ h θ (x i ) -log j∈R(ti) e h θ (xj ) ⎞ ⎠ ,<label>(1)</label></formula><p>where h θ (x i ) represents the risk of the i-th patient predicted by the backbone, θ stands for the parameters of the backbone, x i is the input multimodal MR brain images of the i-th patient, R(t i ) is the risk group at time t i , which contains all patients who are still alive before time t i , t i is the observed time (time of death happened) of x i , and δ i = 0/1 for censored/non-censored patient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">The Tumor Subtyping Network</head><p>The tumor subtyping network has almost the same structure as the backbone.</p><p>It is responsible for learning tumor-type-related features from each input preoperative multimodal MR brain image x i and classifying the tumor into oligodendroglioma, astrocytoma, or glioblastoma. The cross entropy is adopted as the loss function of the tumor subtyping network, which is defined as:</p><formula xml:id="formula_2">L CE = - N i=1 3 k=1 y k i log(p k i ),<label>(2)</label></formula><p>where y k i and p k i are the ground truth (0 or 1) and the prediction (probability) of the k-th tumor type (k = 1, 2, 3) of the i-th patient, respectively. The learned tumor-type-related feature f type i ∈ R M is fed to the survival prediction backbone and concatenated with f cox i learned in the backbone to predict the risk. In the in-house dataset, the proportions of the three tumor types are 20.9% (oligodendroglioma), 28.7% (astrocytoma), and 50.4% (glioblastoma), which is consistent with the statistical report in <ref type="bibr" target="#b12">[13]</ref>. To solve the imbalance issue of tumor types in the training of the tumor subtyping network, a novel ordinal manifold mixup based feature augmentation is presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">The Ordinal Manifold Mixup</head><p>In the original manifold mixup <ref type="bibr" target="#b10">[11]</ref>, features and the corresponding labels are augmented using linear interpolation on two randomly selected features (e.g., f i and f j ). Specifically, the augmented feature fi∼j and label ȳi∼j is defined as:</p><formula xml:id="formula_3">fi∼j = λf i + (1 -λ)f j ȳk i∼j = λy k i + (1 -λ)y k j ,<label>(3)</label></formula><p>where y k i and y k j stand for the labels of the k-th tumor type of the i-th and j-th patients, respectively, and λ ∈ [0, 1] is a weighting factor. For binary classification, the original manifold mixup can effectively enhance the network performance, however, for the classification of more than two classes, e.g., tumor types, there exists a big issue.</p><p>As shown in Fig. <ref type="figure" target="#fig_1">2</ref> left, assume that f i and f j are features of oligodendroglioma (green) and astrocytoma (yellow) learned in the tumor subtyping network, respectively. The augmented feature fi∼j (red) produced from the linear interpolation between f i and f j has the corresponding label ȳi∼j with high probabilities for the tumor types of oligodendroglioma and astrocytoma. However, since these is no constraint imposed on the feature distribution of different tumor types, fi∼j could fall into the distribution of glioblastoma (blue) as shown in Fig. <ref type="figure" target="#fig_1">2</ref> left. In this case, fi∼j and ȳi∼j are inconsistent, which could influence the training and degrade the performance of the tumor subtyping network. As aforementioned, the survival time of patients with different tumor types varies largely (oligodendroglioma &gt; astrocytoma &gt; glioblastoma), so the tumor types can be regarded as risk grade, which are ordered rather than categorical. Based on this assertion and inspired by <ref type="bibr" target="#b15">[16]</ref>, we impose an ordinal constraint on the tumor-type-related features to make the feature distribution of different tumor types in the order of risk grade. In this way, the manifold mixup strategy can be applied between each two neighboring tumor types to produce augmented features with consistent labels that reflect reasonable risk (see Fig. <ref type="figure" target="#fig_1">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>right).</head><p>Normally, the feature distribution of each tumor type is assumed to be independent normal distribution, so their joint distribution is given by:</p><formula xml:id="formula_4">Q(F 1 , F 2 , F 3 ) = 3 k=1 N (μ k , σ 2 k ),<label>(4)</label></formula><p>where F k , k = 1, 2, 3 represents the feature set of oligodendroglioma, astrocytoma, and glioblastoma, respectively, μ k and σ 2 k are mean and variance of F k . To impose the ordinal constraint, we define the desired feature distribution of each tumor type as N (μ 1 , σ2</p><p>1 ) for k = 1, and N (μ k-1 + Δ k , σ2 k ) for k = 2 and 3. In this way, the feature distribution of each tumor type depends on its predecessor, and the mean feature of each tumor type μk (except μ1 ) is equal to the mean feature of its predecessor μk-1 shifted by Δ k . Note that Δ k is set to be larger than 3 × σk to ensure the desired ordering <ref type="bibr" target="#b15">[16]</ref>. In this way, the conditional distribution under the ordinal constraint is defined as:</p><formula xml:id="formula_5">P(F 1 , F 2 , F 3 ) = P(F 1 )P(F 2 |F 1 )P(F 3 |F 2 ),<label>(5)</label></formula><p>which can be represented as:</p><formula xml:id="formula_6">N ⎛ ⎝ ⎡ ⎣ μ1 μ1 + Δ 2 μ1 + Δ 2 + Δ 3 ⎤ ⎦ , ⎡ ⎣ σ2 1 σ2 1 σ2 1 σ2 1 σ2 1 + σ2 2 σ2 1 + σ2 2 σ2 1 σ2 1 + σ2 2 σ2 1 + σ2 2 + σ2 3 ⎤ ⎦ ⎞ ⎠ , (<label>6</label></formula><formula xml:id="formula_7">)</formula><p>where μ1 and σk , k = 1, 2, 3 can be learned by the tumor subtyping network. Finally, the ordinal loss, which is in the form of KL divergence, is defined as:</p><formula xml:id="formula_8">L KL = KL( 3 k=1 N (μ k , σ 2 k ) || P(F 1 , F 2 , F 3 )).<label>(7)</label></formula><p>In our method, μ k and σ 2 k are calculated by</p><formula xml:id="formula_9">μ k = 1 N k xi∈D k G(Φ θ (x i )) σ 2 k = xi∈D k (x i -μ k ) 2 N k -1 , (<label>8</label></formula><formula xml:id="formula_10">)</formula><p>where Φ θ and G are the encoder and GAP of the tumor subtyping network, respectively, θ is the parameter set of the encoder,</p><formula xml:id="formula_11">D k = {x 1 , ..., x N k }, k = 1, 2, 3</formula><p>stands for the subset containing the pre-operative multimodal MR brain images of the patients with the k-th tumor type, N k is the patient number in D k . So we impose the ordinal loss L KL to the features after the GAP of the tumor subtyping network as shown in Fig. <ref type="figure" target="#fig_0">1</ref>. Since the ordinal constraint, feature distribution of different tumor types learned in the subtyping network is encouraged to be in the ordered of risk grade, and features can be augmented between neighboring tumor type. In this way, inconsistency between the resulting augmented features and labels can be effectively reduced.</p><p>The tumor subtyping network is first trained before being integrated into the survival prediction backbone. In the training stage of the tumor subtyping network, each input batch contains pre-operative multimodal MR brain images of N patients and can be divided into K = 3 subsets according to their corresponding tumor types, i.e., D k , k = 1, 2, 3. With the ordinal constrained feature distribution, high consistent features can be augmented between neighboring tumor types. Based on the original and augmented features, the performance of the tumor subtyping network can be enhanced.</p><p>Once the tumor subtyping network has been trained, it is then integrated into the survival prediction backbone, which is trained under the constraint of the cox proportional hazard loss L Cox .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>In our experiment, both in-house and public datasets are used to evaluate our method. Specifically, the in-house dataset collected in cooperation hospitals contains pre-operative multimodal MR images, including T1, T1 contrast enhanced (T1c), T2, and FLAIR, of 1726 patients (age 49.7 ± 13.1) with confirmed diffuse glioma types. The patient number of each tumor type is 361 (oligodendroglioma), 495 (astrocytoma), and 870 (glioblastoma), respectively. In the 1726 patients, 743 have the corresponding overall survival time (dead, non-censored), and 983 patients have the last visiting time (alive, censored). Besides the inhouse dataset, a public dataset BraTS2019, including pre-operative multimodal MR images of 210 non-censored patients (age 61.4 ± 12.2), is adopted as the external independent testing dataset. All images of the in-house and BraTS2019 datasets go through the same pre-processing stage, including image normalization and affine transformation to MNI152 <ref type="bibr" target="#b16">[17]</ref>. Based on the tumor mask of each image, tumor bounding boxes can be calculated. According to the bounding boxes of all 1936 patients, the size of input 3D image patch is set to 96 × 96 × 64 voxels, which can cover the entire tumor of every patient.</p><p>Besides our method, four state-of-the-art methods, including random forest based method (RF) <ref type="bibr" target="#b17">[18]</ref>, deep convolutional survival model (deepConvSurv) <ref type="bibr" target="#b18">[19]</ref>, multi-channel survival prediction method (MCSP) <ref type="bibr" target="#b19">[20]</ref>, and imaging phenotype and genotype based survival prediction method (PGSP) <ref type="bibr" target="#b8">[9]</ref>, are evaluated. It is worth noting that in the RF method, 100 decision trees and 390 handcrafted radiomics features are used. The output of RF, MCSP, and PGSP is the overall survival (OS) times in days, while for deepConvSurv and our method, the output is the risk (deep Cox proportional hazard models). Concordance index (C-index) is adopted to quantify the prediction accuracy:</p><formula xml:id="formula_12">C-index(D) = i,j∈D 1 Ti&lt;Tj • 1 Ri&lt;Rj • δ i i,j∈D 1 Ti&lt;Tj • δ i ,<label>(9)</label></formula><p>where D = {x 1 , ..., x N } is the dataset containing all patients, T i and T j are ground truth of survival times of the i-th and j-th patients, R i and R j are the days predicted by RF, MCSP, and PGSP or risks predicted by the deep Cox proportional hazard models (i.e., deepConvSurv and our method), 1 x&lt;y = 1 if x &lt; y, else 0, and δ i = 0 or 1 when the i-th patient is censored or non-censored. As RF, MCSP, and PGSP cannot use the censored data in the in-house dataset, 80% of the non-censored data (594 patients) are randomly selected as the training data, and the rest 20% non-censored data (149 patients) are for testing. While deepConvSurv and our method are deep Cox models, both censored and non-censored patients can be utilized. So besides the 80% non-censored patients, all censored data (983 patients) are also included in the training data.</p><p>Table <ref type="table" target="#tab_0">1</ref> shows the evaluation results of the in-house and the external independent (BraTS2019) testing datasets using all methods under evaluation. Our method achieves the highest C-index of all the methods under evaluation. Moreover, comparing with deepConvSurv, our method can improve the prediction accuracy up to 10% (in-house) and 8% (BraTS2019).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Ablation Study of Survival Prediction</head><p>To show the effect of the tumor subtyping network and the ordinal manifold mixup in survival prediction, our method without the tumor subtyping network (Baseline-1) and our method with the tumor subtyping network (using original manifold mixup instead, Baseline-2) are evaluated. For the in-house dataset, the resulting C-indices are 0.744 (Baseline-1) and 0.735 (Baseline-2). So our method make the improvement of C-index more than 8% comparing with Baseline-2. For the external independent testing dataset BraTS2019, the resulting C-indices are 0.738 (Baseline-1) and 0.714 (Baseline-2), and our method still has more than 6% improvement comparing with Baseline-2.</p><p>Figure <ref type="figure" target="#fig_2">3</ref> shows the distributions of tumor-type-related features (after the GAP) of the in-house testing data in Baseline-2, and our method. Principal component analysis <ref type="bibr" target="#b20">[21]</ref> is used to project features to a 2D plane. Since the ordinal constraint, the feature distribution of different tumor types is in the order of risk grade using our method, which cannot be observed in Baseline-2. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>We proposed a new method for pre-operative survival prediction of diffuse glioma patients, where a tumor subtyping network is integrated into the prediction backbone. Based on the tumor subtyping network, tumor type information, which are only available after craniotomy, can be derived from the pre-operative multimodal MR images to boost the survival prediction performance. Moreover, a novel ordinal manifold mixup was presented, where ordinal constraint is imposed to make feature distribution of different tumor types in the order of risk grade, and feature augmentation only takes place between neighboring tumor types. In this way, inconsistency between the augmented features and corresponding labels can be effectively reduced. Both in-house and public datasets containing 1936 patients were used in the experiment. Our method outperformed the state-of-the-art methods in terms of the concordance-index.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Structure of our survival prediction network. It is composed of a survival prediction backbone (top) and a tumor subtyping network (bottom). To solve the imbalanced tumor type issue, a novel ordinal manifold mixup is introduced in the training stage of the tumor subtyping network.</figDesc><graphic coords="3,43,29,53,75,337,36,115,96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Illustration of feature augmentation using original manifold mixup (left) and the proposed ordinal manifold mixup (right). (Color figure online)</figDesc><graphic coords="5,47,79,183,83,328,57,62,80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Feature distributions of the in-house testing data in Baseline-2, and Ours.</figDesc><graphic coords="8,67,47,319,22,317,86,107,77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Evaluation of the prediction results (C-Index) using the in-house and external independent (BraTS2019) testing datasets.</figDesc><table><row><cell></cell><cell>RF</cell><cell cols="2">deepConvSurv MCSP PGSP Ours</cell></row><row><cell>In-house</cell><cell cols="2">0.708 0.726</cell><cell>0.715 0.776 0.798</cell></row><row><cell cols="3">BraTS2019 0.619 0.705</cell><cell>0.700 0.738 0.762</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This work is supported in part by <rs type="funder">National Natural Science Foundation of China</rs> No. <rs type="grantNumber">62073012</rs>, <rs type="grantNumber">82102149</rs>, <rs type="grantNumber">82273493</rs>, <rs type="funder">Beijing Municipal Natural Science Foundation</rs> No. <rs type="grantNumber">7222307</rs>, and <rs type="funder">Natural Science Foundation of Henan Province for Excellent Young Scholars</rs> No. <rs type="grantNumber">232300421057</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_HSZpWPM">
					<idno type="grant-number">62073012</idno>
				</org>
				<org type="funding" xml:id="_bhY4GaX">
					<idno type="grant-number">82102149</idno>
				</org>
				<org type="funding" xml:id="_2EnQABm">
					<idno type="grant-number">82273493</idno>
				</org>
				<org type="funding" xml:id="_3hExbZJ">
					<idno type="grant-number">7222307</idno>
				</org>
				<org type="funding" xml:id="_S6TuuQQ">
					<idno type="grant-number">232300421057</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Brain tumor segmentation and radiomics survival prediction: contribution to the brats 2017 challenge</title>
		<author>
			<persName><forename type="first">F</forename><surname>Isensee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kickingereder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bendszus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Maier-Hein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>International MICCAI Brainlesion Workshop</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Radiomics: images are more than pictures, they are data</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Gillies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Kinahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hricak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">278</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="563" to="577" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">3D deep learning for multimodal imaging-guided survival time prediction of brain tumor patients</title>
		<author>
			<persName><forename type="first">D</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ehsan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
		<editor>MIC-CAI</editor>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">ImageNet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Support vector machine</title>
		<author>
			<persName><forename type="first">C</forename><surname>Saunders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deep learning for prediction of survival in idh wild-type gliomas</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Poisson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Filippi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurol. Sci</title>
		<imprint>
			<biblScope unit="volume">381</biblScope>
			<biblScope unit="page" from="172" to="173" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Karnofsky performance score</title>
		<idno type="DOI">10.1007/978-3-642-16483-5_3198</idno>
		<ptr target="https://doi.org/10.1007/978-3-642-16483-5_3198" />
	</analytic>
	<monogr>
		<title level="m">Encyclopedia of Cancer</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Schwab</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep learning of imaging phenotype and genotype for predicting overall survival time of glioblastoma patients</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2100" to="2109" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">WHO 2016 classification of gliomas</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wesseling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Capper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuropathol. Appl. Neurobiol</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="139" to="150" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Manifold mixup: better representations by interpolating hidden states</title>
		<author>
			<persName><forename type="first">V</forename><surname>Verma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6438" to="6447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The multimodal brain tumor image segmentation benchmark (BRATS)</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Menze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1993" to="2024" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">CBTRUS statistical report: primary brain and other central nervous system tumors diagnosed in the united states in 2013-2017</title>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">T</forename><surname>Ostrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cioffi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Waite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kruchko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Barnholtz-Sloan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuro-Oncol</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1" to="96" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Deep survival: a deep cox proportional hazards network</title>
		<author>
			<persName><forename type="first">J</forename><surname>Katzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Shaham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cloninger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kluger</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.00931</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Recursively conditional gaussian for ordinal unsupervised domain adaptation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="764" to="773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">BDCG: unbiased average age-appropriate atlases for pediatric studies</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Fonov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Botteron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Almli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Mckinstry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neu-roImage</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Classification and regression by randomForest</title>
		<author>
			<persName><forename type="first">A</forename><surname>Liaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wiener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">R News</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="18" to="22" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">WSISA: making survival prediction from whole slide histopathological images</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="6855" to="6863" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Multi-channel 3D deep feature learning for survival time prediction of brain tumor patients using multi-modal neuroimages</title>
		<author>
			<persName><forename type="first">D</forename><surname>Nie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1103</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Kurita</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-03243-2_649-1</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-03243-2_649-1" />
		<title level="m">Principal Component Analysis (PCA)</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
