<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Sheaf Theoretic Perspective for Robust Prostate Segmentation</title>
				<funder ref="#_f2byk8n">
					<orgName type="full">Cancer Research UK (CRUK)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Ainkaran</forename><surname>Santhirasekaram</surname></persName>
							<email>a.santhirasekaram19@ic.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Karen</forename><surname>Pinto</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Surgery and Cancer</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mathias</forename><surname>Winkler</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Surgery and Cancer</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andrea</forename><surname>Rockall</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Surgery and Cancer</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ben</forename><surname>Glocker</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Sheaf Theoretic Perspective for Robust Prostate Segmentation</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="249" to="259"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">1E540C3D7E9C20C26F30A5C98A6628BA</idno>
					<idno type="DOI">10.1007/978-3-031-43901-8_24</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-13T19:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep learning based methods have become the most popular approach for prostate segmentation in MRI. However, domain variations due to the complex acquisition process result in textural differences as well as imaging artefacts which significantly affects the robustness of deep learning models for prostate segmentation across multiple sites. We tackle this problem by using multiple MRI sequences to learn a set of low dimensional shape components whose combinatorially large learnt composition is capable of accounting for the entire distribution of segmentation outputs. We draw on the language of cellular sheaf theory to model compositionality driven by local and global topological correctness. In our experiments, our method significantly improves the domain generalisability of anatomical and tumour segmentation of the prostate. Code is available at https://github.com/AinkaranSanthi/A-Sheaf-Theoretic-Perspective-for-Robust-Segmentation.git.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Segmenting the prostate anatomy and detecting tumors is essential for both diagnostic and treatment planning purposes. Hence, the task of developing domain generalisable prostate MRI segmentation models is essential for the safe translation of these models into clinical practice. Deep learning models are susceptible to textural shifts and artefacts which is often seen in MRI due to variations in the complex acquisition protocols across multiple sites <ref type="bibr" target="#b12">[12]</ref>.</p><p>The most common approach to tackle domain shifts is with data augmentation <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b33">33,</ref><ref type="bibr" target="#b35">35]</ref> and adversarial training <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b30">30]</ref>. However, this increases training time and we propose to tackle the problem head on by learning shape only embedding features to build a shape dictionary using vector quantisation <ref type="bibr" target="#b31">[31]</ref> which can be sampled to compose the segmentation output. We therefore hypothesise by limiting the search space to a set of shape components, we can improve generalisability of a segmentation model. We also propose to correctly sample and compose shape components with local and global topological constraints by tracking topological features as we compose the shape components in an ordered manner. This is achieved using a branch of algebraic topology called cellular sheaf theory <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b19">19]</ref>. We hypothesise this approach will produce more anatomically meaningful segmentation maps and improve tumour localisation.</p><p>The contributions of this paper are summarized as follows: 1. This work considers shape compositionality to enhance the generalisability of deep learning models to segment the prostate on MRI. 2. We use cellular sheaves to aid compositionality for segmentation as well as improve tumour localisation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Persistent Homology</head><p>Topological data analysis is a field which extracts topological features from complex data structures embedded in a topological space. One can describe a topological space through its connectivity which can be captured in many forms. One such form is the cubical complex. The cubical complex C is naturally equipped to deal with topological spaces represented as volumetric grid structured data such as images <ref type="bibr" target="#b32">[32]</ref>. In a 3D image, a cubical complex consists of individual voxels serving as vertices, with information regarding their connections to neighboring voxels captured through edges, squares, and cubes. Matrix reduction algorithms enable us to represent the connectivity of C in terms of a series of mathematical groups, known as the homology groups. Each homology group encompasses a specific dimension, d of topological features, such as connected components (d = 0), holes (d = 1), and voids (d = 2). The number of topological features present in each group is quantified by the corresponding Betti number. Betti numbers provide useful topological descriptors of the binary label maps as it is a single scale topological descriptor. However, the output, Y from a segmentation model is continuous. Thus, the Betti number for a cubical complex where vertices are continuous will be a noisy topological descriptor. We therefore use persistent homology which tracks changes in the topological features at multiple scales <ref type="bibr" target="#b17">[17]</ref>. A cubical complex can be constructed at some threshold, τ over the output defined as: C τ = {y ∈ Y|Y ≥ τ }. We can now create q cubical complexes over q ordered thresholds. This leads to a sequence of nested cubical complexes shown in Eq. 1 known as a sublevel set filtration. The persistent homology defines d dimensional topological features such as connected components which are born at τ i and dies at τ j where τ j &gt; τ i . This creates tuples (τ i , τ j ) which are stored as points in a persistence diagram (Fig. <ref type="figure" target="#fig_1">2b</ref>).</p><formula xml:id="formula_0">∅ = C τ 1 ⊆ C τ 2 ... ⊆ C τ q = Y (1)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Cellular Sheaves</head><p>The homology of segmentation maps provides a useful tool for analysing global topology but does not describe how local topology is related to construct global topological features. Sheaf theory provides a way of composing or 'gluing' local data together to build a global object (new data) that is consistent with the local information <ref type="bibr" target="#b7">[8]</ref>. This lends well to modelling compositionality. Formally, a sheaf is a mathematical object which attaches to each open subset or subspace, U in a topological space, Y an algebraic object like a vector space or set (local data) such that it is well-behaved under restriction to smaller open sets <ref type="bibr" target="#b7">[8]</ref>.</p><p>We can consider a topological space, Y such as a segmentation output divided into a finite number of subspaces, {∅, Y 1 , Y 2 ...Y n } which are the base spaces for Y or equivalently the patches in a segmentation map. If we sequentially glue base spaces together in a certain order to form increasingly larger subspaces of Y starting with the ∅, one can construct a filtration of Y such that;</p><formula xml:id="formula_1">∅ ⊆ Y 1 ⊆ Y 1 ∪ Y 2 ... ⊆ Y 1 ∪ Y 2 ... ∪ Y n ⊆ Y .</formula><p>We neatly formalise the subspaces and how subspaces are glued together with a poset. A poset (P ) is a partially ordered set defined by a relation, ≤ between elements in P which is reflexive, antisymmetric, and transitive <ref type="bibr" target="#b19">[19]</ref>. In our work, we define a poset by the inclusion relation; p i ≤ p j implies p i ⊆ p j for p i , p j ∈ P . Hence, we can map each element in P with a subspace in X which satisfies the inclusion relations in P like in X.</p><p>A cellular sheaf, F over a poset is constructed by mapping, each element, p ∈ P to a vector space F(p) over a fixed field which preserves the ordering in P by linear transformations, ρ .,. which are inclusion maps in this case <ref type="bibr" target="#b19">[19]</ref>. In our work each element in P maps to the vector space, R 2 which preserves the inclusion relations in P . Specifically, we compute a persistence diagram, D for the subspace in X associated (homeomorphic) with p ∈ P whereby (τ i , τ j ) in the persistence diagram are a set of vectors in the vector space, R 2 . A cellular sheaf naturally arises in modelling the connectivity of a segmentation map and provides a mathematically precise justification for using cellular sheaves in our method. We show by approaching the composition of segmentation maps through this lens, one can significantly improved the robustness of segmentation models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related Work</head><p>There have been various deep learning based architectures developed for prostate tumour segmentation <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b15">15,</ref><ref type="bibr" target="#b18">18]</ref>. There is however no work looking at developing models which generalise well to target domains after training on one source domain known as single domain generalisation (SDG). Effective data augmentation techniques, such as CutOut <ref type="bibr" target="#b16">[16]</ref>, MixUp <ref type="bibr" target="#b34">[34]</ref> and BigAug <ref type="bibr" target="#b35">[35]</ref> offer a straightforward approach to enhance the generalisability of segmentation models across different domains. Recent methods have utilized adversarial techniques, such as AdvBias <ref type="bibr" target="#b10">[11]</ref>, which trains the model to generate bias field deformations and enhance its robustness.</p><p>RandConv <ref type="bibr" target="#b33">[33]</ref> incorporates a randomized convolution layer to learn textural invariant features. Self-supervised strategies such as JiGen <ref type="bibr" target="#b8">[9]</ref> can also improve generalisability. The principle of compositionality has been integrated into neural networks for tasks such as image classification <ref type="bibr" target="#b23">[23]</ref>, generation <ref type="bibr" target="#b1">[2]</ref> and more recently, segmentation <ref type="bibr" target="#b26">[26,</ref><ref type="bibr" target="#b28">28]</ref> to improve generalisability. The utilization of persistent homology in deep learning-based segmentation is restricted to either generating topologically accurate segmentations in the output space <ref type="bibr" target="#b21">[21]</ref> or as a subsequent processing step <ref type="bibr" target="#b14">[14]</ref>. The novel approach of topological auto-encoders <ref type="bibr" target="#b27">[27]</ref> marks the first instance of incorporating persistent homology to maintain the topological structure of the data manifold within the latent representation. Cellular sheaves were used to provide a topological insight into the poor performance of graph neural networks in the heterophilic setting <ref type="bibr" target="#b6">[7]</ref>. Recently, cellular sheaves were used as a method of detecting patch based merging relations in binary images <ref type="bibr" target="#b20">[20]</ref>. Finally, <ref type="bibr" target="#b3">[4]</ref> recently proposed using sheaf theory to construct a shape space which allows one to precisely define how to glue shapes together in this shape space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Shape Equivariant Learning</head><p>Given spatial, T s and textural, T i transformations of the input space, X , the goal is to learn an encoder, Φ e to map X to lower dimensional embedding features, E which are shape equivariant and texture invariant as shown in Eq. 2.</p><formula xml:id="formula_2">Φ e (T s (T i (X ))) = T s (E)<label>(2)</label></formula><p>We assume T2 and ADC MRI images share the same spatial information and only have textural differences. We exploit this idea in Fig. <ref type="figure" target="#fig_0">1</ref>, where firstly an ADC image under spatial transformation, T s is mapped with an encoder, Φ e to z 2 and the T 2 image is mapped with the same encoder to z 1 . Shape equivariance and texture invariance is enforced with the contrastive loss, L contr = T s (z 1 )z 2 2 2 . Specifically, we apply transformations from the dihedral group (D4) which consists of 90 • rotations in the z plane and 180 • rotations in the y plane. Note, a contrastive only learns equivariance as opposed to constraining the convolutional kernels to be equivariant. z 1 containing 128 channels is spatially quantised before passing into the composer. In the test phase, the ADC image is not required and only the T2 image is used as input. T2 segmentations are used as the label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Shape Component Learning</head><p>We posit that there is limited shape variation in the low dimensional embedding space across subjects which can be fully captured in N discrete shapes. N discrete shapes form a shape dictionary, D shown in Fig. <ref type="figure" target="#fig_0">1</ref> which is learnt with vector quantisation <ref type="bibr" target="#b31">[31]</ref>. Given we enforce a texture invariant continuous embedding space and hence only contains shape information, quantisation converts this continuous embedding space to discrete shape features, ẑ. The quantisation process involves minimising the Euclidean distance between the embedding space, z 1 divided into m features, z 1 i and its nearest shape component, e k ∈ D shown in Eq. <ref type="bibr" target="#b2">3</ref> where k = argmin j z 1</p><p>ie j 2 and m = 3048. Next, sampling D such that z 1 i is replaced by e k produces the spatially quantized embedding space ẑ. Straight-through gradient approximation is applied for backpropagation through the sampling process to update z 1 and D <ref type="bibr" target="#b31">[31]</ref>. Gradient updates are applied to only the appropriate operands using stop gradients (sg) during optimization.</p><formula xml:id="formula_3">L Quant = 1 m i=m-1 i=0 sg(z 1 i ) -e k 2 + β z 1 i -sg(e k ) 2<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Cellular Sheaves for Shape Composition</head><p>Shapes in D sampled with a uniform prior can lead to anatomically implausible segmentations after composition which we tackle through the language of cellular sheaves to model the connectivity of patches in an image which provides a connectivity-based loss function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Composition:</head><p>The quantised embedding space, ẑ, is split into c groups. The composition of each group in ẑ to form each class segmentation, Y c in the output, Y involves two steps. Initially, a decoder with grouped convolutions equal to the number of classes followed by the softmax function maps, ẑ ∈ R 128×16×16×12 to C ∈ R p×c×256×256×24 where p is the number of patches for each class c. The second step of the composition uses a cellular sheaf to model the composition of Y c by gluing the patches together in an ordered manner defined by a poset while tracking its topology using persistent homology. This in turn enforces D to be sampled in a topological preserving manner as input into the decoder/composer to improve both the local and global topological correctness of each class segmentation output, Y c after composition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Illustration:</head><p>We illustrate our methodology of using cellular sheaves with a simple example in Fig. <ref type="figure" target="#fig_1">2</ref>. Here, we show Y as perfectly matching the ground truth label (not one-hot encoded) divided into 2 patches. Y is a topological space with the subspaces,</p><formula xml:id="formula_4">V = {∅, Y 1 , Y 2 , Y 1 ∪ Y 2 }. A 4-element poset, P = {(0, 0), (1, 0), (0, 1), (1, 1)} is constructed where given (x 1 , x 2 ), (y 1 , y 2 ) ∈ P then (x 1 , x 2 ) ⊆ (y 1 , y 2 ) only if x 1 ≤ y 1 ∧x 2 ≤ y 2 .</formula><p>Each element in P is associated with a subspace in V such that the inclusion relationship is satisfied. Therefore, in Fig. <ref type="figure" target="#fig_1">2a</ref>, P defines that Y 1 and Y 2 associated with (1, 0) and (0, 1) respectively are glued together to form Y = Y 1 ∪ Y 2 which maps with (1, 1). A cellular sheaf F over P is created by assigning a vector space to p ∈ P by deriving a persistence diagram, D for each element in V associated with p as shown in Fig. <ref type="figure" target="#fig_1">2b</ref>. The arrows in Fig. <ref type="figure" target="#fig_1">2b</ref> are inclusion maps defined as ρ .,. . Persistence diagrams are computed from the sequence of nested cubical complexes of each subspace in V. The persistence diagrams in Fig. <ref type="figure" target="#fig_1">2b</ref> are formed by overlapping the persistence diagrams for each class segmentation. Note, persistence diagrams contain infinite points in the form (τ, τ ) (diagonal line in persistence diagrams) which always allows a bijection between two persistence diagrams. The main advantage of our approach is that in addition to ensuring correct local topology (patch level) and global topology (image level), we also force our network to produce topologically accurate patches correctly merged together in a topology preserving manner which matches the ground truth. For example in Fig. <ref type="figure" target="#fig_1">2b</ref>, Y 2 contains 3 connected components glued onto Y 1 containing 2 connected components to form Y , which also has 3 connected components. This means an extra connected component is added by Y 2 due to tumour which therefore improves patch-wise tumour localisation. It also indicates the other 2 connected components in Y 2 are merged into the 2 connected components in Y 1 to form 2 larger connected components (peripheral and transitional zone) in Y . Hence, the same 2 vectors present in both F(1, 0) and F(0, 1) representing the peripheral and transitional zone are also in F <ref type="bibr" target="#b0">(1,</ref><ref type="bibr" target="#b0">1)</ref>. This is also known as a local section in F.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation</head><formula xml:id="formula_5">, Y c 2 , Y c 3 , Y c 4 , Y c 1 ∪ Y c 2 , Y c 1 ∪ Y c 2 ∪ Y c 3 , Y c }.</formula><p>We construct cellular sheaves, F over P c and P c and minimise the distance between these cellular sheaves.</p><p>We firstly plot persistence diagrams, D from the set of vectors (τ i , τ j ) in F(P c i ) and F( P c i ). Next, we minimise the total p th Wasserstein distance (topological loss) between the persistence diagrams D(F(P c i )) and D(F( P c i )) shown in Eq. 4 where η : D(F(P c i )) → D(F( P c i )) is a bijection between the persistence diagrams <ref type="bibr" target="#b27">[27]</ref> and p = 2. This loss function is proven to be stable to noise <ref type="bibr" target="#b29">[29]</ref> and differentiable <ref type="bibr" target="#b9">[10]</ref>. We add a dice loss between Y and Ŷ . The total loss to train our entire framework is:</p><formula xml:id="formula_6">L total = L dice (Y, Ŷ ) + L contr + L quant + L top . L top = c=4 c=1 i=7 i=1 ⎛ ⎝ inf η:D(F (P c i ))→D(F ( P c i )) x∈D(F (P c i )) x -η(x) p ∞ ⎞ ⎠ 1 p (4)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results</head><p>In the task of anatomical segmentation, the first two columns of Table <ref type="table" target="#tab_1">1</ref> show the results for the domain shift from RUNMC in the decathlon dataset to BMC.</p><p>Here, we demonstrate that our method improves segmentation performance in all evaluation metrics compared to the baseline, nn-UNet and the other SDG methods. Similar findings are noted for the domain shift from the internal dataset to the RUNMC data in the ProstateX2 dataset (second two columns of Table <ref type="table" target="#tab_1">1</ref>).</p><p>In Table <ref type="table" target="#tab_2">2</ref>, we note our method significantly improves tumour segmentation and localisation performance. We visualise our findings with an example in Fig. <ref type="figure">3</ref>, where there is improved localisation of the tumour and the correct number of tumour components enforced by our topological loss. This significantly reduces the false positive rate highlighted in Table <ref type="table" target="#tab_2">2</ref>. Also, note the more anatomically plausible zonal segmentations. However, our method is restricted by the number of low dimensional shape components in the shape dictionary used to compose the high dimensional segmentation output. Therefore, our approach can fail to segment the finer details of prostate tumours due to its high shape variability which leads to coarser but better localised tumour segmentations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In conclusion, we propose shape compositionality as a way to improve the generalisability of segmentation models for prostate MRI. We devise a method to learn texture invariant and shape equivariant features used to create a dictionary of shape components. We use cellular sheaf theory to help model the composition of sampled shape components from this dictionary in order to produce more anatomically meaningful segmentations and improve tumour localisation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. Three part overview: 1. Use ADC maps to help learn shape equivariant features from T2 weighted images. 2. Construct a shape dictionary, D from the shape equivariant features. 3. Model the composition of the sampled shaped components to form the segmentation output using a cellular sheaf.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Figure 2a shows 2 patches (Y1, Y2) glued together in an ordered manner defined by the poset, P , via inclusions maps to form the prostate segmentation output Y = Y1 ∪ Y2. Figure 2b shows a cellular sheaf F over the poset P .</figDesc><graphic coords="5,86,64,59,51,110,20,88,30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>:</head><label></label><figDesc>In practise during training, a cellular sheaf is built for each class in the output Y and label Ŷ , denoted Y c and Ŷ c respectively. Y c and Ŷ c are divided into 2 × 2 × 1 patches. Starting with the top left patch, we sequentially glue on each patch in a zigzag manner until the entire image is formed which is formally defined by posets, P c for Y c and P c for Ŷ c , each containing 7 elements this time. Each element in the poset is associated with a patch i.e. Y c i or a sequences of patches glued together. For example, P c is</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Mean dice, Hausdorff distance (HD) Betti error±standard deviation using our method, several SDG methods and the nnUNet for zonal segmentation.</figDesc><table><row><cell></cell><cell cols="2">RU N M C → BM C</cell><cell cols="2">Internal → RU N M C</cell></row><row><cell></cell><cell>Dice</cell><cell>HD</cell><cell>Betti Error Dice</cell><cell>HD</cell><cell>Betti Error</cell></row><row><cell>Baseline</cell><cell cols="5">0.51±0.13 0.40±0.11 2.98±0.91 0.67±0.17 0.35±0.09 2.01±0.72</cell></row><row><cell>nnUNet [16]</cell><cell cols="5">0.57±0.15 0.32±0.10 1.90±0.82 0.72±0.15 0.30±0.12 1.10±0.44</cell></row><row><cell>AdvBias [11]</cell><cell cols="5">0.56±0.13 0.33±0.15 1.92±0.16 0.73±0.19 0.29±0.13 1.09±0.22</cell></row><row><cell cols="6">RandConv [33] 0.59±0.15 0.29±0.08 1.54±0.24 0.73±.017 0.23±0.11 0.99±0.20</cell></row><row><cell>BigAug [35]</cell><cell cols="5">0.63±0.15 0.25±0.12 1.39±0.49 0.75±0.18 0.21±0.07 0.86±0.38</cell></row><row><cell>Jigen [9]</cell><cell cols="5">0.54±0.25 0.38±0.17 2.72±1.17 0.68±0.13 0.33±0.15 1.89±0.93</cell></row><row><cell>vMFNet [26]</cell><cell cols="5">0.61±0.15 0.28±0.14 1.48±0.39 0.72±0.16 0.24±0.09 0.99±0.28</cell></row><row><cell>Ours</cell><cell cols="5">0.65±0.10 0.20±0.10 0.93±0.27 0.77±0.14 0.18±0.07 0.69±0.20</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>The average dice score, Betti error, Hausdorff distance(HD), sensitivity, specificity and positive predictive value (PPV) ± standard deviations using our method, several SDG methods and the nnUNet for tumour segmentation.</figDesc><table><row><cell></cell><cell>Dice</cell><cell>HD</cell><cell>Betti Error Sensitivity Specificity PPV</cell></row><row><cell>Baseline</cell><cell cols="3">0.38±0.17 1.03±0.32 5.11±2.90 0.37±0.11 0.60±0.20 0.29±0.11</cell></row><row><cell>nnUNet [16]</cell><cell cols="3">0.45±0.15 0.81±0.22 4.43±2.32 0.46±0.11 0.70±0.14 0.37±0.14</cell></row><row><cell>AdvBias [11]</cell><cell cols="3">0.42±0.10 0.90±0.19 4.41±2.16 0.45±0.13 0.66±0.21 0.35±0.17</cell></row><row><cell cols="4">RandConv [33] 0.43±0.18 0.80±0.27 4.19±2.01 0.47±0.16 0.65±0.17 0.35±0.19</cell></row><row><cell>BigAug [35]</cell><cell cols="3">0.47±0.12 0.68±0.19 4.03±1.89 0.48±0.18 0.73±0.22 0.40±0.19</cell></row><row><cell>Jigen [9]</cell><cell cols="3">0.42±0.11 0.88±0.21 4.51±2.43 0.42±0.18 0.65±0.13 0.33±0.09</cell></row><row><cell>vMFNet [26]</cell><cell cols="3">0.46±0.12 0.80 ±0.20 3.33±1.18 0.47±0.15 0.66±0.21 0.38±0.11</cell></row><row><cell>Ours</cell><cell cols="3">0.51±0.13 0.57±0.16 2.99±0.97 0.50±0.18 0.79±0.20 0.45±0.18</cell></row><row><cell cols="2">bijective with {Y c 1</cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This work was supported and funded by <rs type="funder">Cancer Research UK (CRUK)</rs> (<rs type="grantNumber">C309/A28804</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_f2byk8n">
					<idno type="grant-number">C309/A28804</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43901-8 24. Pre-processing: All images are resampled to 0.5 × 0.5 × 3 mm, centre cropped to 256 × 256 × 24 and normalised between 0 and 1.</p><note type="other">Image Label Ours nnUNet AdvBias Jigen Randconv BigAug vMFNet</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model:</head><p>In order to address the anisotropic characteristics of Prostate MRI images, we have chosen a hybrid 2D/3D UNet as our baseline model. We use the same encoder and decoder architecture as the baseline model in our method. See supplementary material for further details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison:</head><p>We compare our method with the nnUNet <ref type="bibr" target="#b22">[22]</ref> and several approaches to tackle SDG segmentation namely, RandConv <ref type="bibr" target="#b33">[33]</ref>, AdvBias <ref type="bibr" target="#b10">[11]</ref>, Jigen <ref type="bibr" target="#b8">[9]</ref> and BigAug <ref type="bibr" target="#b35">[35]</ref> applied to the baseline model. We also compare to a compositionality driven segmentation method called the vMFNet <ref type="bibr" target="#b26">[26]</ref>.</p><p>Training: In all our experiments, the models were trained using Adam optimization with a learning rate of 0.0001 and weight decay of 0.05. Training was run for up to 500 epochs on three NVIDIA RTX 2080 GPUs. The performance of the models was evaluated using the Dice score, Betti error <ref type="bibr" target="#b21">[21]</ref> and Hausdorff distance. We evaluate tumour localisation by determining a true positive if the tumour segmentation overlaps by a minimum of one pixel with the ground truth.</p><p>In our ablation studies, the minimum number of shape components required in D for the zonal and zonal + tumour segmentation experiments was 64 and 192 respectively before segmentation performance dropped. See supplementary material for ablation experiments analysing each component of our framework.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The medical segmentation decathlon</title>
		<author>
			<persName><forename type="first">M</forename><surname>Antonelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">4128</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Compositional transformers for scene generation</title>
		<author>
			<persName><forename type="first">Arad</forename><surname>Hudson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural. Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="9506" to="9520" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Clinically significant prostate cancer detection and segmentation in low-risk patients using a convolutional neural network on multi-parametric MRI</title>
		<author>
			<persName><forename type="first">M</forename><surname>Arif</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. Radiol</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="6582" to="6592" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Arya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Curry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mukherjee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.09020</idno>
		<title level="m">A sheaf-theoretic construction of shape space</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Bloch</surname></persName>
		</author>
		<idno type="DOI">10.7937/K9/TCIA.2015.zF0vlOPv</idno>
		<ptr target="http://doi.org/10.7937/K9/TCIA.2015.zF0vlOPv" />
		<title level="m">Cancer imaging archive Wiki</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">NCI-ISBI 2013 challenge: automated segmentation of prostate structures</title>
		<author>
			<persName><forename type="first">N</forename><surname>Bloch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer Imaging Arch</title>
		<imprint>
			<biblScope unit="volume">370</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Bodnar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Di Giovanni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">P</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.04579</idno>
		<title level="m">Neural sheaf diffusion: a topological perspective on heterophily and oversmoothing in GNNs</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Bredon</surname></persName>
		</author>
		<title level="m">Sheaf Theory</title>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">170</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Domain generalization by solving jigsaw puzzles</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Carlucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>D'innocente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tommasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2229" to="2238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Optimizing persistent homology based functions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Carriere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chazal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Glisse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Umeda</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1294" to="1303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Realistic adversarial data augmentation for MR image segmentation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">12261</biblScope>
			<biblScope unit="page" from="667" to="677" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Cham</forename><surname>Springer</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59710-8_65</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-59710-865" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Towards to robust and generalized medical image segmentation framework</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.03823</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The cancer imaging archive (TCIA): maintaining and operating a public information repository</title>
		<author>
			<persName><forename type="first">K</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Digit. Imaging</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1045" to="1057" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Byrne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Oksuz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">A</forename><surname>Zimmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Schnabel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>King</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.01877</idno>
		<title level="m">A topological loss function for deep-learning based image segmentation using persistent homology</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep learning regression for prostate cancer detection and grading in bi-parametric MRI</title>
		<author>
			<persName><forename type="first">C</forename><surname>De Vente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hosseinzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pluim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Veta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="374" to="383" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Improved regularization of convolutional neural networks with cutout</title>
		<author>
			<persName><forename type="first">T</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04552</idno>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Persistent homology-a survey</title>
		<author>
			<persName><forename type="first">H</forename><surname>Edelsbrunner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Harer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Contemp. Math</title>
		<imprint>
			<biblScope unit="volume">453</biblScope>
			<biblScope unit="issue">26</biblScope>
			<biblScope unit="page" from="257" to="282" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Explainable AI for CNN-based prostate tumor segmentation in multi-parametric MRI correlated to whole mount histopathology</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Gunashekar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiat. Oncol</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Hu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.09651</idno>
		<title level="m">A brief note for sheaf structures on posets</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A sheaf and topology approach to detecting local merging relations in digital images</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">M</forename><surname>Chung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4396" to="4405" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Topology-preserving deep image segmentation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Samaras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Isensee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Kohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Maier-Hein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="211" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Compositional convolutional neural networks: a deep architecture with innate robustness to partial occlusion</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kortylewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8940" to="8949" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Litjens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Debats</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Barentsz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Karssemeijer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huisman</surname></persName>
		</author>
		<idno type="DOI">10.7937/K9TCIA</idno>
		<ptr target="https://doi.org/10.7937/K9TCIA" />
		<title level="m">Cancer imaging archive Wiki</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A survey on deep learning in medical image analysis</title>
		<author>
			<persName><forename type="first">G</forename><surname>Litjens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="60" to="88" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">vMFNet: compositionality meets domain-generalised segmentation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thermos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Q</forename><surname>O'neil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Tsaftaris</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16449-1_67</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16449-167" />
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer Assisted Intervention-MICCAI 2022: 25th International Conference</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Singapore; Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022-09-22">18-22 September 2022. 2022</date>
			<biblScope unit="page" from="704" to="714" />
		</imprint>
	</monogr>
	<note>Proceedings, Part VII</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Topological autoencoders</title>
		<author>
			<persName><forename type="first">M</forename><surname>Moor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rieck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Borgwardt</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7045" to="7054" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Vector quantisation for robust segmentation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Santhirasekaram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Winkler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rockall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16440-8_63</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16440-863" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="663" to="672" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Skraba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Turner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.16824</idno>
		<title level="m">Wasserstein stability for persistence diagrams</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Adversarial training and robustness for multiple perturbations</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Boneh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Neural discrete representation learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Efficient computation of persistent homology for cubical data</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vuçini</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-23175-9_7</idno>
		<ptr target="https://doi.org/10.1007/978-3-642-23175-97" />
	</analytic>
	<monogr>
		<title level="m">Topological Methods in Data Analysis and Visualization II: Theory, Algorithms, and Applications</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Peikert</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Hauser</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Carr</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Fuchs</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="91" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Robust and generalizable visual representation learning via random convolutions</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Niethammer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.13003</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.09412</idno>
		<title level="m">mixup: beyond empirical risk minimization</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Generalizing deep learning for medical image segmentation to unseen domains via deep stacked transformation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2531" to="2540" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
