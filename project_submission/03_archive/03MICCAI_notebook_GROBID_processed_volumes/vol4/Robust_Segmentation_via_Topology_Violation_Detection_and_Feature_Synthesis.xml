<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Robust Segmentation via Topology Violation Detection and Feature Synthesis</title>
				<funder ref="#_eUzNvET">
					<orgName type="full">Erlangen National High Performance Computing Center (NHR@FAU) of the Friedrich-Alexander-Universität Erlangen-Nürnberg</orgName>
					<orgName type="abbreviated">FAU</orgName>
				</funder>
				<funder ref="#_E8hkpWy">
					<orgName type="full">European Research Council</orgName>
					<orgName type="abbreviated">ERC</orgName>
				</funder>
				<funder>
					<orgName type="full">German Research Foundation (DFG) -440719683</orgName>
				</funder>
				<funder ref="#_gS4H2PZ">
					<orgName type="full">Imperial College London</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Liu</forename><surname>Li</surname></persName>
							<email>liu.li20@imperial.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qiang</forename><surname>Ma</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Cheng</forename><surname>Ouyang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zeju</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<settlement>Oxford</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qingjie</forename><surname>Meng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Weitong</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mengyun</forename><surname>Qiao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vanessa</forename><surname>Kyriakopoulou</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">King&apos;s College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Joseph</forename><forename type="middle">V</forename><surname>Hajnal</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">King&apos;s College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Rueckert</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Technical University of Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bernhard</forename><surname>Kainz</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">FAU Erlangen-Nürnberg</orgName>
								<address>
									<settlement>Erlangen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Robust Segmentation via Topology Violation Detection and Feature Synthesis</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="67" to="77"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">87BB254F7E1FB9B3D4CFD07CCD9CDC92</idno>
					<idno type="DOI">10.1007/978-3-031-43901-8_7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-13T19:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Despite recent progress of deep learning-based medical image segmentation techniques, fully automatic results often fail to meet clinically acceptable accuracy, especially when topological constraints should be observed, e.g., closed surfaces. Although modern image segmentation methods show promising results when evaluated based on conventional metrics such as the Dice score or Intersection-over-Union, these metrics do not reflect the correctness of a segmentation in terms of a required topological genus. Existing approaches estimate and constrain the topological structure via persistent homology (PH). However, these methods are not computationally efficient as calculating PH is not differentiable. To overcome this problem, we propose a novel approach for topological constraints based on the multi-scale Euler Characteristic (EC). To mitigate computational complexity, we propose a fast formulation for the EC that can inform the learning process of arbitrary segmentation networks via topological violation maps. Topological performance is further facilitated through a corrective convolutional network block. Our experiments on two datasets show that our method can significantly improve topological correctness.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Performance of automated medical image segmentation methods is widely evaluated by pixel-wise metrics, e.g., the Dice score or the Intersection-over-Union <ref type="bibr" target="#b15">[16]</ref>. Taking the average accuracy of each pixel/voxel into account, these evaluation methods are well suited to describe the overall segmentation performance. However, errors in some regions may be more important than others, e.g., certain errors may lead to the misrepresented topology. In some cases, topological correctness is more important than pixel-wise classification correctness. For example, when segmentation is a fundamental step for surface reconstruction <ref type="bibr" target="#b3">[4]</ref>.</p><p>To address the above challenge, several methods explore the idea of topology constraints in image segmentation. Many utilize persistent homology (PH) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b23">24]</ref> by adding an additional topology loss term to the pixel-wise, e.g., cross entropy, loss. These methods manipulate the prediction probability of critical points that are sensitive to topological changes. However, the detection of these critical points is neither computationally efficient nor accurate.</p><p>In this work, we propose a novel deep learning (DL)-based topology-aware segmentation method, utilizing the concept of the Euler Characteristic (EC) <ref type="bibr" target="#b6">[7]</ref>, which is an integer defined as the number of connected components (β 0 ) minus the number of holes (β 1 ) in a 2D image. We develop a DL-compatible extension to the classical EC calculation approach, i.e., the Gray algorithm <ref type="bibr" target="#b6">[7]</ref>. Given the difference in EC between prediction and ground truth (GT), which we refer to as EC error, we can visualize topology violations in the predictions, denoted as a topology violation map, by backpropagating the EC error with respect to the segmentations. With the resulting topology violation map, we further design an efficient correction network that can improve the connectedness of foreground elements by synthesising plausible alternatives that preserve learned topological priors (i.e. the EC).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contributions.</head><p>(1) This paper presents a novel DL-based method for fast EC calculation, which, to the best of our knowledge, is the first paper introducing DL-compatible EC computation. <ref type="bibr" target="#b1">(2)</ref> The proposed EC calculation network enables the visualization of a topology violation map, by backpropagating the EC error between the predicted and GT segmentations. (3) Leveraging the topology violation map, we design a topology-aware feature synthesis network to correct regions with topological errors. It can be easily incorporated into any existing segmentation pipeline for topology correction. <ref type="bibr" target="#b3">(4)</ref> We demonstrate the effectiveness of our method on two datasets with different foreground structures, and achieve superior performance compared to existing methods. Related Work. Segmentation networks such as U-Net <ref type="bibr" target="#b20">[21]</ref> are typically trained using loss functions such as binary cross-entropy or soft Dice loss. These metrics measure the pixel-wise overlap between the prediction and the GT. However, they do not guarantee topological correctness. Shape priors have been explored to mitigate this issue, e.g., utilizing shape templates <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b18">19]</ref> with diffeomorphic deformation. These methods require the predictions to be very close to the shape priors, which is often unachievable in practice. Other methods inject shape information explicitly into the training process <ref type="bibr" target="#b19">[20]</ref>. Implicit shape awareness has also been explored in <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b21">22]</ref> based on boundary and centerline information that can model connectivity. Unfortunately, neither of these methods is directly based on insights from topology theory, nor do they guarantee the corrections of topology.</p><p>So far, topology in segmentation has only been explored through the use of PH <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b22">23]</ref>. PH extracts topological features by tracking the birth and death of connected components, holes, and voids, as the filtration varies. In practice, these PH-based methods first detect critical points that are related to changes in topology and then manipulate the values of these critical points to encourage a predicted topology that matches the GT topology. This loss term is differentiable since it only changes the probability of critical points in the segmentation. Despite the available packages for computing PH <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b17">18]</ref>, the polynomial computational complexity of the PH is a limitation that hinders its use in large-scale datasets. To address this unmet need, we propose an EC-based method that can serve as a guidance function for DL segmentation networks and can achieve real-time performance. Our code is publicly available here<ref type="foot" target="#foot_0">1</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>Preliminaries. Algebraic topology utilizes algebraic techniques to study the properties of topological spaces. This field aims to identify and characterize topological invariants, such as the number of holes, the connectivity, or the homotopy groups of a space. For image segmentation, gray-scale images defined on grids I ∈ R h×w can be modeled as cubical complexes K, which is a set consisting of points, line segments, squares, and cubes. We show the modeling process in Fig. <ref type="figure" target="#fig_1">1</ref> in the appendix.</p><p>Euler Characteristic (EC), denoted as χ ∈ Z, is a topological invariant that describes the structure and properties of a given topological space. For a cubical complex K defined in a n-dimensional space, EC χ is defined as the alternating sum of the number of k-dimensional cells N k , or alternating sum of the ranks of the k-dimensional homology groups, called Betti number β k . Mathematically, EC can be formalized as:</p><formula xml:id="formula_0">χ(K) = n k=0 (-1) k N k = n-1 k=0 (-1) k β k (K).<label>(1)</label></formula><p>Specifically, for 2-dimensional images, EC</p><formula xml:id="formula_1">χ(K) = N 0 -N 1 + N 2 = β 0 -β 1 ,</formula><p>where N 0 , N 1 and N 2 are the number of vertices, edges, and faces; and β 0 and β 1 are the number of connected components and holes.</p><p>Gray Algorithm for EC Calculation. The Gray algorithm is a conventional approach to calculate EC on binary images <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b25">26]</ref>. Specifically, instead of directly counting the number of vertices N 0 , edges N 1 , and faces N 2 , the Gray algorithm calculates the EC by counting the number of occurrences of 10 different 2 × 2 patterns, called bit-quads, which are categorized into K 1 , K 2 and K 3 . We show these patterns in Fig. <ref type="figure" target="#fig_1">1</ref>. The number of occurrences of all the bit-quads from K l is notated as M l , l ∈ {1, 2, 3}. The EC χ can then be calculated by a linear transformation f :  Overview. We illustrate our method in Fig. <ref type="figure" target="#fig_1">1</ref>, which consists of three components: (1) a segmentation network, (2) a topological violation detection (TVD) block and (3) a topology-aware feature synthesis (TFS) network.</p><formula xml:id="formula_2">χ = f (M 1 , M 2 , M 3 ) = (M 1 -M 2 -2 × M 3 )/4.<label>(2)</label></formula><formula xml:id="formula_3">EC = f (M 1 , M 2 , M 3 ) Visualization Net K 1 K 2 K 3 Linear transformation f EC map</formula><p>In (1), we utilize a U-Net to predict a segmentation probability map S ∈ [0, 1] h×w , with the supervision of GT segmentation S ∈ {0, 1} h×w . The predicted map may contain topological errors. ( <ref type="formula" target="#formula_2">2</ref>) is the main contribution of our approach, consisting of two sub-nets: an EC-Net and a Visualization Net. The EC-Net takes the predicted S and GT segmentation S as inputs and predicts their corresponding EC maps X ∈ Z h×w and X ∈ Z h×w . We then measure the Euler error e ∈ R by L1 distance as e = X -X 1 . The Visualization Net takes e as input and produces a topology violation map V ∈ R h×w that highlights the regions with topological errors. Finally, in (3), we design a TFS network, which learns to fill in the missing segmentation in the erroneous regions. This subnetwork takes the predicted segmentation S and violation map V as input and generates a topology-preserving segmentation , which is the final prediction.</p><p>During training, we use the TVD block (red arrows in Fig. <ref type="figure" target="#fig_1">1</ref>) to generate the violation maps V to further guide the next feature synthesis network. During inference, we only run the first segmentation network and TFS network, as indicated by the upper blue arrows in Fig. <ref type="figure" target="#fig_1">1</ref> to produce the final topology-preserving segmentation results.</p><p>Topology-violation Detection. TVD consists of two parts: an EC-Net and a Visualization Net (Fig. <ref type="figure" target="#fig_1">1 bottom</ref>). The Gray algorithm that calculates EC cannot be directly integrated into the gradient-based optimization process as is not differentiable. To overcome this problem, we propose a DL-compatible EC-Net as a CNN-based method that leverages the Gray algorithm to calculate the EC. The EC-Net serves as a function that maps the segmentation space to the Euler number space g : S → χ. It is worth mentioning that in order to preserve spatial information, for each segmentation S, EC-Net locally produces Euler numbers χ i,j with the input of a segmentation patch P i,j,Δ = S i:i+Δ,j:j+Δ , where Δ is the patch size. We can therefore obtain an Euler map X by combining all the local Euler numbers χ i,j .</p><p>EC-Net consists of three parts: 1) fixed kernel CNN layers, 2) an averaged pooling layer and 3) a linear transformation f . Following the Gray algorithm <ref type="bibr" target="#b6">[7]</ref>, we first utilize three CNN layers with fixed kernels to localize the bit-quads in the segmentation. The values of the kernels are the same as the bit-quads</p><formula xml:id="formula_4">K 1 ∈ {-1, 1} 2×2×4 , K 2 ∈ {-1, 1} 2×2×4 , and K 3 ∈ {-1, 1} 2×2×2 ,</formula><p>as shown in Fig. <ref type="figure" target="#fig_1">1</ref>. Note that we first binarize the prediction probability map S and further normalize it to {-1, 1}. Therefore, if and only if the prediction has the same pattern as the bit-quads, it will be activated to 4 after convolution. Subsequently, we apply an average pooling layer to obtain the local number of bit-quads M 1 , M 2 , and M 3 . The process can be summarized as:</p><formula xml:id="formula_5">M l,i,j,Δ = Δ 2 • AvgPool(1(P i,j,Δ * K l = 4)),<label>(3)</label></formula><p>where l ∈ {1, 2, 3}, * represents the convolutional operation, and 1(•) is an indicator function that equals 1 if and only if the input is true. Note that the patch size of average pooling is the same as the patch size of the segmentation Δ.</p><p>Finally, following Eq. 2, a linear transformation is used to calculate the EC χ.</p><p>During training, we separately take both S and S as the input of EC-Net and obtain their corresponding Euler maps X and X.</p><p>In the second part of TVD, we measure the Euler error by the L1 distance as e = X -X 1 . We can calculate the gradient of e with respect to the segmentation maps as the visualization of the EC error, called topology violation map V = ∂e/∂S, which is the output of TVD.</p><p>Topology-Aware Feature Synthesis. In this module, we aim to improve the segmentation's topological correctness by utilizing the detected topology violation maps. We observe that topological errors are often caused by poor feature representation in the input image, e.g. blurry boundary regions. These errors are difficult to be corrected when trained from the image space. Therefore, we propose a TFS network that directly learns how to repair the topological structures from the segmentations.</p><p>During training, we mask out the topological error regions in the segmentation map and send it as the input of the feature synthesis network. We then use the GT segmentation to supervise this network to learn to repair these error regions. The input S (with its element Si,j ) of the feature synthesis network is generated from the segmentation probability map S (with its element Ŝi,j ) and the topology violation map V (with its element V i,j ) as follows: We first filter out the coordinates {(i, j)} with severe topological errors if | V i,j |≥ t, where t is a filtration threshold. Then we replace the values of the segmentation at these coordinates by a random probability sampled from standard Gaussian distribution σ ∼ N (0, 1) and followed by a Sigmoid function to map it to (0, 1). The process of generating Si,j can be summarized as:</p><formula xml:id="formula_6">Si,j = ⎧ ⎨ ⎩ 1 1 + e -σ , | V i,j |≥ t, Ŝi,j , otherwise.<label>(4)</label></formula><p>During inference, we feed the feature synthesis network with pure predictions S. We show the effectiveness of our design in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head><p>Datasets: We conduct experiments on two datasets: CREMI for neuron boundary segmentation <ref type="bibr" target="#b5">[6]</ref> and the developing human connectome project (dHCP<ref type="foot" target="#foot_1">2</ref> ) dataset for fetal cortex segmentation. These datasets are employed to evaluate different topology challenges, where neuron boundaries in CREMI have a random and diverse number of holes β 1 and connected components β 0 , while the cortex in the dHCP dataset is expected to have fixed β 1 and β 0 . CREMI consists of 3 subsets, each of which consists of 125 1250 × 1250 grayscale images and corresponding label maps. We randomly selected 100 samples from each subset (300 samples in total) as the training set and use the remaining 25 samples (75 samples in total) as validation and test set. We further divided each 1250 × 1250 image into 25 256 × 256 patches with an overlap of 8 pixels, in order to fit the GPU memory and enlarge the size of the training set. Thus, training and test sets consist of 7,500 and 1,875 samples, respectively.</p><p>The dHCP dataset has 242 fetal brain T2 Magnetic Resonance Imaging (MRI) scans with gestational ages ranging from 20.6 to 38.2 weeks. All MR images were motion corrected and reconstructed to 0.8 mm isotropic resolution for the fetal head region of interest (ROI) <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b12">13]</ref>. The images are affinely aligned to the MNI-152 coordinate space and clipped to the size of 144 × 192 × 192. We randomly split the data into 145 samples for training, 73 for testing, and 24 for validation. The GT cortical gray matter label is first generated by DrawEM method <ref type="bibr" target="#b16">[17]</ref> and then refined manually to improve the segmentation accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Settings:</head><p>The hyper-parameters in Eq. 3 and Eq. 4 are empirically chosen as Δ = 32 for the CREMI dataset, Δ = 8 for the dHCP dataset, and t = 0.6 for both datasets. We choose Δ to be higher for CREMI than for dHCP because:</p><p>(1) the resolution of CREMI is higher and (2) the topology of the fetal cortex may change in smaller regions. We choose a default U-Net as the backbone for all methods for comparison, but our method can also be Incorporated into other segmentation frameworks. For the training process, we first use default crossentropy loss to train the first segmentation network, then the TFS network. Note that the parameters in TVD are fixed.</p><p>Implementation: We use PyTorch 1.13.1 and calculate the Betti number with the GUDHI package <ref type="bibr" target="#b17">[18]</ref>. The training time is evaluated on an NVIDIA RTX 3080 GPU with a batch size of 20.</p><p>Evaluation Metrics. Segmentation performance is evaluated by Dice score and averaged surface distance (ASD), and the performance of topology is evaluated by Betti errors, which is defined as: e i =| β pred i -β gt i |, where i ∈ {0, 1} indicates the dimension. We also report the mean Betti error as e = e 0 + e 1 .</p><p>Quantitative Evaluation. We compare the segmentation performance of our method with three baselines which are proposed to preserve shape and topology: cl-Dice loss <ref type="bibr" target="#b21">[22]</ref>, boundary loss <ref type="bibr" target="#b11">[12]</ref>, warp loss <ref type="bibr" target="#b7">[8]</ref> and PH loss <ref type="bibr" target="#b8">[9]</ref>. For pixel-wise accuracy, our method achieves the best Dice score on both datasets, as demonstrated in Tab. 1. Despite the comparable ASD score in the dHCP dataset, we achieve significant improvements in terms of Betti errors. Compared to all baseline methods, our approach achieves an average Betti error of 4.970 on the CREMI dataset, representing an improvement of at least 4.132 (45.25%) in the mean average Betti error. We observe similar improvements for the dHCP dataset. We also conduct Wilcoxon signed-rank tests <ref type="bibr" target="#b24">[25]</ref> comparing our method to all other baselines. The p-values are &lt;0.05 across all metrics. Note that compared to the PH based loss <ref type="bibr" target="#b8">[9]</ref>, which is a similarly well grounded concept in algebraic topology, our method is 46.4 times faster at 0.189 s/batch. Qualitative Evaluation. As highlighted in Fig. <ref type="figure" target="#fig_2">2</ref>, our method can effectively eliminate the topological errors in both the CREMI and dHCP datasets, outperforming all the other methods. For instance, in the first row of the CREMI dataset, none of the baseline methods could segment the tiny neuron structure when the boundary of the cells is blurry. Similarly, in the dHCP dataset, all the baseline methods fail to segment the fetal cortex as a closed surface, whereas our method can successfully resolve this issue. Second, we show the topology violation maps from the TVD block in the third column in Fig. <ref type="figure" target="#fig_2">2</ref>, which indicate the topology error regions between the GT (second column) and the prediction from our first segmentation network (fourth column). For example, in the second raw of the CREMI evaluation, we observe that the topology violation map can highlight the disconnected boundary, therefore driving our method to correct these errors. We provide more visual examples in the supplementary materials.</p><p>Ablation Study. We first evaluate the effectiveness of our TVD design. We train our pipeline without the TVD block. Instead, we use the difference map between the prediction and GT as a substitute for the topology violation map. We also summarize the qualitative results in Fig. <ref type="figure" target="#fig_2">2</ref>. Feature synthesis with the difference map can correct some of the false negative errors, however, the ring structure remains to be incorrect for the CREMI dataset. In contrast, our approach successfully predicts all the ring structures. Secondly, we further remove the TFS network. Quantitative results are provided in Tab. 1. The topology performance without TVD+TFS is significantly inferior to our method in terms of Betti errors, which illustrates the effectiveness of our design.</p><p>Discussion. This study sheds new light on improving and evaluation of topology-aware medical image segmentation. We observe that most existing methods either do not consider topological constraints, or are limited by their high computational complexity. As a computation-efficient block, our method can be easily integrated into existing segmentation methods to improve the topological structure. A limitation for topology-aware segmentation methods is that they are easy to be affected by noises, so they might be more suitable to datasets with clear topology structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We propose a novel EC-based method to include topology constraints in the segmentation network. Different from PH-based approaches, our method has a distinct advantage in computational efficiency while providing improved performance. In this paper, we generate a topology violation map from TVD and employ a post-processing feature synthesis network to correct topological errors. We believe this map is valuable and could be explored for other scenarios, such as serving as a spatial prior to regularize various loss functions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Overview of our method in three steps: (1) We first generate an initial prediction from the segmentation network, where topological errors may occur. (2) Second, we propose a TVD block to detect topology-violating regions. (3) Based on this violation map, we use a topology-aware feature synthesis network to correct errors and improve the segmentation.</figDesc><graphic coords="4,46,29,54,59,331,84,195,10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig.2. Generated topology violation maps and the segmentation results. Our method can correct the disconnected structures compared with the existing method.</figDesc><graphic coords="6,62,76,66,56,304,75,201,13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Segmentation performance of our method on CREMI and dHCP data with two ablation experiments (Ours without TVD and TFS). e, e0 and e1 represent Betti error, Betti error 0 and Betti error 1. ASD is average surface distance. The unit for training time is seconds per batch of images. Best values are highlighted in bold.</figDesc><table><row><cell cols="2">Data Method</cell><cell cols="2">Dice ↑ e ↓</cell><cell>e 0 ↓</cell><cell>e 1 ↓</cell><cell>ASD ↓ s/batch ↓</cell></row><row><cell></cell><cell>cl-Dice loss [22]</cell><cell>83.48</cell><cell cols="3">10.403 7.445 2.958</cell><cell>1.612</cell><cell>0.047</cell></row><row><cell>CREMI</cell><cell cols="2">Boundary loss [12] PH loss [9] Ours w/o TVD+TFS 83.92 84.00 84.07</cell><cell cols="3">9.877 6.938 2.939 9.102 6.213 2.889 10.787 7.926 2.861</cell><cell>1.612 1.690 1.571</cell><cell>0.041 8.772 0.041</cell></row><row><cell></cell><cell>Ours w/o TVD</cell><cell>85.17</cell><cell cols="3">5.183 2.968 2.215</cell><cell>1.245</cell><cell>0.083</cell></row><row><cell></cell><cell>Ours</cell><cell>85.25</cell><cell cols="3">4.970 2.793 2.177 1.241</cell><cell>0.189</cell></row><row><cell></cell><cell>cl-Dice loss [22]</cell><cell>88.21</cell><cell cols="3">2.573 1.081 1.492</cell><cell>0.232</cell><cell>0.022</cell></row><row><cell></cell><cell>Boundary loss [12]</cell><cell>88.52</cell><cell cols="3">2.470 0.999 1.471</cell><cell>0.210</cell><cell>0.024</cell></row><row><cell>dHCP</cell><cell cols="2">PH loss [9] Ours w/o TVD+TFS 88.14 88.17</cell><cell cols="3">2.546 1.075 1.471 2.542 1.091 1.451</cell><cell>0.232 0.227</cell><cell>3.300 0.021</cell></row><row><cell></cell><cell>Ours w/o TVD</cell><cell>88.45</cell><cell cols="3">2.220 0.824 1.395</cell><cell>0.228</cell><cell>0.042</cell></row><row><cell></cell><cell>Ours</cell><cell>88.56</cell><cell cols="3">2.032 0.737 1.295 0.218</cell><cell>0.109</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://github.com/smilell/Topology-aware-Segmentation-using-Euler-Character istic.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>www.developingconnectome.org.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This project is supported by <rs type="grantName">Lee Family Scholarship</rs> from <rs type="funder">Imperial College London</rs>. HPC resources are provided by the <rs type="funder">Erlangen National High Performance Computing Center (NHR@FAU) of the Friedrich-Alexander-Universität Erlangen-Nürnberg (FAU)</rs> under the <rs type="projectName">NHR</rs> project <rs type="grantNumber">b143dc</rs>. NHR funding is provided by federal and Bavarian state authorities. NHR@FAU hardware is partially funded by the <rs type="funder">German Research Foundation (DFG) -440719683</rs>. Support was also received by the <rs type="funder">ERC</rs> -project <rs type="projectName">MIA-NORMAL 101083647</rs> and <rs type="grantNumber">DFG KA 5801/2-1, INST 90/1351-1</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_gS4H2PZ">
					<orgName type="grant-name">Lee Family Scholarship</orgName>
				</org>
				<org type="funded-project" xml:id="_eUzNvET">
					<idno type="grant-number">b143dc</idno>
					<orgName type="project" subtype="full">NHR</orgName>
				</org>
				<org type="funded-project" xml:id="_E8hkpWy">
					<idno type="grant-number">DFG KA 5801/2-1, INST 90/1351-1</idno>
					<orgName type="project" subtype="full">MIA-NORMAL 101083647</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43901-8_7.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A persistent homology-based topological loss for CNN-based multiclass segmentation of CMR</title>
		<author>
			<persName><forename type="first">N</forename><surname>Byrne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Valverde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Montana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="14" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A topological loss function for deep-learning based image segmentation using persistent homology</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Byrne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Oksuz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">A</forename><surname>Zimmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Schnabel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="8766" to="8778" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Explicit topological priors for deep-learning based image segmentation using persistent homology</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Oksuz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Byrne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Schnabel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>King</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-20351-1_2</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-20351-1_2" />
	</analytic>
	<monogr>
		<title level="m">IPMI 2019</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">C S</forename><surname>Chung</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Gee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Yushkevich</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Bao</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11492</biblScope>
			<biblScope unit="page" from="16" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Cortical surface-based analysis: I. segmentation and surface reconstruction</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Dale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fischl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Sereno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="194" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Segmentation of the cortical plate in fetal brain MRI with a topological loss</title>
		<author>
			<persName><forename type="first">P</forename><surname>De Dumast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kebiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Atat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dunet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Koob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Cuadra</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87735-4_19</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87735-4_19" />
	</analytic>
	<monogr>
		<title level="m">UNSURE/PIPPI -2021</title>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Sudre</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12959</biblScope>
			<biblScope unit="page" from="200" to="209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Large scale image segmentation with structured loss based deep learning for connectome reconstruction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Funke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1669" to="1680" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Local properties of binary images in two dimensions</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Gray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="551" to="561" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Structure-aware image segmentation with homotopy warping</title>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural. Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="24046" to="24059" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Topology-preserving deep image segmentation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Samaras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Fast volume reconstruction from motion corrupted stacks of 2D slices</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kainz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1901" to="1913" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Kaji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sudo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ahara</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.12692</idno>
		<title level="m">Cubical Ripser: software for computing persistent homology of image and volume data</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Boundary loss for highly unbalanced segmentation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kervadec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bouchtiba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Desrosiers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Granger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dolz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">B</forename><surname>Ayed</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Imaging with Deep Learning</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="285" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Reconstruction of fetal brain MRI with intensity matching and complete outlier removal</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kuklisova-Murgasova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Quaghebeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Rutherford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Hajnal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Schnabel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1550" to="1564" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Tetris: Template transformer networks for image segmentation with shape priors</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Pawlowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schaap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2596" to="2606" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Ethical and Philosophical Issues in Medical Imaging, Multimodal Learning and Fusion Across Scales for Clinical Decision Support, and Topological Data Analysis for Biomedical Imaging</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-23223-7_11</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-23223-7_11" />
	</analytic>
	<monogr>
		<title level="m">EPIMI ML-CDS TDA4BiomedicalImaging 2022</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">S H</forename><surname>Baxter</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13755</biblScope>
		</imprint>
	</monogr>
	<note>Fetal cortex segmentation with topology and thickness loss constraints</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Metrics reloaded: pitfalls and recommendations for image analysis validation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Maier-Hein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Menze</surname></persName>
		</author>
		<idno>arXiv. org (2206.01653</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The developing human connectome project: a minimal processing pipeline for neonatal cortical surface reconstruction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Makropoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="page" from="88" to="112" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The Gudhi library: simplicial complexes and persistent homology</title>
		<author>
			<persName><forename type="first">C</forename><surname>Maria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-D</forename><surname>Boissonnat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Glisse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yvinec</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-662-44199-2_28</idno>
		<ptr target="https://doi.org/10.1007/978-3-662-44199-2_28" />
	</analytic>
	<monogr>
		<title level="m">ICMS 2014</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Hong</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Yap</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">8592</biblScope>
			<biblScope unit="page" from="167" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deformable models in medical image analysis: a survey</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mcinerney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Terzopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="108" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Anatomically constrained neural networks (acnns): application to cardiac image enhancement and segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Oktay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="384" to="395" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">U-Net: convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-24574-4_28</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-24574-4_28" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2015</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hornegger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">9351</biblScope>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">clDice-a novel topology-preserving loss function for tubular structure segmentation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="16560" to="16569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Topologically faithful image segmentation via induced matching of persistence barcodes</title>
		<author>
			<persName><forename type="first">N</forename><surname>Stucki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Paetzold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Menze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Bauer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.15272</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Topologically faithful image segmentation via induced matching of persistence barcodes</title>
		<author>
			<persName><forename type="first">N</forename><surname>Stucki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Paetzold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Menze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Bauer</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="32698" to="32727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Individual comparisons by ranking methods</title>
		<author>
			<persName><forename type="first">F</forename><surname>Wilcoxon</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-1-4612-4380-9_16</idno>
		<ptr target="https://doi.org/10.1007/978-1-4612-4380-9_16" />
	</analytic>
	<monogr>
		<title level="m">Breakthroughs in Statistics. Springer Series in Statistics</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Kotz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">L</forename><surname>Johnson</surname></persName>
		</editor>
		<meeting><address><addrLine>NY</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A novel bit-quad-based Euler number computing algorithm</title>
		<author>
			<persName><forename type="first">B</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Springerplus</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
