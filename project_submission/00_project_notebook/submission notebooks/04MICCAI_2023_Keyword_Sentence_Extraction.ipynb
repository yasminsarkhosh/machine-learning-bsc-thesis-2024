{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective of the Notebook\n",
    "The notebook aims to extract sentences from already preprocessed MICCAI 2023 research papers based on a list of relevant keywords. The sentences are organized by paper titles and focus on extracting text that might contain specific information related to demographics and other significant categories.\n",
    "\n",
    "### Input Data Expected\n",
    "- **CSV File**: The input for this notebook is a CSV file containing preprocessed text from research papers. This data is expected to be structured with columns for paper titles and text content, which were processed in a previous step (as indicated by a linked notebook).\n",
    "\n",
    "### Output Data/Files Generated\n",
    "- **CSV Files**: For each category of interest (like age, gender, ethnicity, dataset info), the notebook will generate CSV files containing extracted sentences or keywords. These files will help in further analysis or machine learning tasks focused on these categories.\n",
    "- **Directories**: The extracted data will be saved into directories specified for cancer-related content, patient-related content, etc., facilitating organized access to this information for further use.\n",
    "\n",
    "### Assumptions or Important Notes\n",
    "- **Preprocessing Required**: It assumes that the data has been preprocessed for extraction, meaning any necessary cleaning, formatting, or preliminary analysis has been completed beforehand.\n",
    "- **Keyword Relevance**: The effectiveness of the extraction process heavily depends on the relevance and comprehensiveness of the keyword list used for extraction. Misclassification or omission of relevant keywords might lead to incomplete or skewed data analysis.\n",
    "- **Text Structure**: The notebook assumes that the text in the input CSV is well-structured and correctly segmented into sentences. Any irregularities in text structuring might affect the accuracy of sentence extraction.\n",
    "- **Error Handling**: There seems to be minimal error handling regarding file reading and writing, which could lead to issues if files are not found or directories do not exist. It's crucial to ensure that the input paths are correct and accessible.\n",
    "- **Scalability**: Depending on the volume of data (number of papers and the length of text in them), the process might be computationally intensive, requiring optimization for handling large datasets efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword-Based Sentence Extraction from Selected MICCAI 2023 Research Articles\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/project_submission/00_project_notebook/submission notebooks/03MICCAI_notebook_papers_with_patients.csv'\n",
    "selected_papers = pd.read_csv(filename)\n",
    "len(selected_papers['title'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract keyword-related sentences from selected papers\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Short keywords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of keywords\n",
    "keywords_age        = ['age']\n",
    "\n",
    "keywords_gender     = ['gender', 'sex', 'women', 'woman', 'female', 'male']\n",
    "\n",
    "keywords_etnicity   = ['etnicity', 'etnicities', 'race', 'white patients', 'black patients']\n",
    "\n",
    "keywords_geoloc     = ['geolocation', 'geographical', 'geographic', 'country', 'countries', 'city', 'cities', \n",
    "                        'hospital', 'hospitals', 'clinic', 'clinics']\n",
    "\n",
    "keywords_bias       = ['bias', 'biases']\n",
    "\n",
    "keywords_fairness   = ['fairness']\n",
    "\n",
    "keywords_patients   = ['patient', 'patients']\n",
    "\n",
    "keywords_data       = ['dataset', 'datasets', 'data collection', 'data collections']\n",
    "\n",
    "keywords_collected  = ['collected']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Split the text into words and extract keyword-matches. Group each keyword-match by relatd paper \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_text(text, width=100):\n",
    "    \"\"\"\n",
    "    A simple function to wrap text at a given width.\n",
    "    \"\"\"\n",
    "    if pd.isnull(text):\n",
    "        return text  # Handle NaN values\n",
    "    \n",
    "    wrapped_lines = []\n",
    "    for paragraph in text.split('\\n'):  # Splitting by existing newlines to preserve paragraph breaks\n",
    "        line = ''\n",
    "        for word in paragraph.split():\n",
    "            if len(line) + len(word) + 1 > width:\n",
    "                wrapped_lines.append(line)\n",
    "                line = word\n",
    "            else:\n",
    "                line += (' ' + word if line else word)\n",
    "        wrapped_lines.append(line)\n",
    "    return '\\n'.join(wrapped_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords search only\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text into sentences and search for the keywords\n",
    "\n",
    "def extract_keywords(df, keywords):\n",
    "    # Search for the whole word in the text\n",
    "    pattern = r'\\b(' + '|'.join(re.escape(keyword) for keyword in keywords) + r')\\b'\n",
    "\n",
    "    # Initialize a dictionary to hold sentences organized by paper title\n",
    "    sentences_by_paper = {}\n",
    "\n",
    "    # Loop through each row in the dataframe\n",
    "    for index, row in df_cancer_related.iterrows():\n",
    "        # Find all sentences that contain any of the keywords\n",
    "        sentences = re.findall(pattern, row['text'], flags=re.IGNORECASE | re.DOTALL)\n",
    "        \n",
    "        # If there are matching sentences, add them to the dictionary under the paper title\n",
    "        if sentences:\n",
    "            paper_title = row['title']\n",
    "            if paper_title not in sentences_by_paper:\n",
    "                sentences_by_paper[paper_title] = []\n",
    "            sentences_by_paper[paper_title].extend(sentences)\n",
    "\n",
    "    # Sentences_by_paper contains all the sentences that contain keywords, organized by paper title\n",
    "\n",
    "    # Convert this dictionary into a DataFrame:\n",
    "    # Create a list of tuples (paper title, sentence)        \n",
    "    keywords_data = [(title, keyword_sentence) for title, related_group in sentences_by_paper.items() for keyword_sentence in related_group]\n",
    "    keywords_df = pd.DataFrame(keywords_data, columns=['title', 'keyword']) \n",
    "\n",
    "    return keywords_df       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_df = extract_keywords(selected_papers, keywords_age)\n",
    "keywords_df = extract_keywords(selected_papers, keywords_gender)\n",
    "keywords_df = extract_keywords(selected_papers, keywords_etnicity)\n",
    "keywords_df = extract_keywords(selected_papers, keywords_geoloc)\n",
    "keywords_df = extract_keywords(selected_papers, keywords_patients)\n",
    "keywords_df = extract_keywords(selected_papers, keywords_bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keywords_df.to_csv(\"/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/outputs/data/bias_related_keywords_.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Sentence search only by list of keywords\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudo code\n",
    "# regex to split the text into sentences. A sentence is defined as a sequence of characters that ends with a period, question mark, or exclamation mark.\n",
    "# iterate through the sentences to find those with a keyword from the list of keywords. \n",
    "# for each match\n",
    "    # option 1) concatentinate the previous and next sentences to the sentence with the keyword (if they haven't been added already)\n",
    "    # option 2) extract sentence with keyword only\n",
    "# keep track of the sentences already added for each paper title.\n",
    "# if no matches are found for a paper title, add 'none'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT SENTS WITH KEYWORDS    \n",
    "# Option 2) Storing keyword sentence only \n",
    "\n",
    "def extract_keyword_sentences(df, keywords):\n",
    "    \"\"\"\n",
    "    Extract sentences containing specified keywords from DataFrame and organize by paper title.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the text to search through.\n",
    "    - keywords: List of keywords to search for in the text.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with paper titles as keys and lists of sentences containing the keywords as values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compile the regular expression for matching sentences containing the keywords\n",
    "    keyword_pattern = re.compile(r'\\b(?:' + '|'.join(keywords) + r')\\b', flags=re.IGNORECASE)\n",
    "\n",
    "    # Initialize a dictionary to hold sentences organized by paper title\n",
    "    sentences_by_paper = {}\n",
    "\n",
    "    # Loop through each paper title in the DataFrame\n",
    "    for title in df['title'].unique():\n",
    "        # Get the full text for the current title\n",
    "        text = ' '.join(df[df['title'] == title]['text'])\n",
    "        # Split the text into sentences\n",
    "        sentences = re.split(r'(?<=[.?!])\\s+', text)\n",
    "\n",
    "        # List to store sentences that contain the keyword\n",
    "        keyword_sentences_buffer = []\n",
    "\n",
    "        # Iterate through sentences to find and store sentences that contain the keyword\n",
    "        for sentence in sentences:\n",
    "            if keyword_pattern.search(sentence):\n",
    "                # Add only the sentence with the keyword to the buffer\n",
    "                keyword_sentences_buffer.append(sentence)\n",
    "\n",
    "        # Add the sentences to the dictionary, use 'none' if there are no matches\n",
    "        sentences_by_paper[title] = keyword_sentences_buffer if keyword_sentences_buffer else ['none']\n",
    "    \n",
    "    extracted_data = [(title, keyword_sentence) for title, related_group in sentences_by_paper.items() for keyword_sentence in related_group]\n",
    "    extracted_df = pd.DataFrame(extracted_data, columns=['title', 'extracted_keyword_sent'])\n",
    "    \n",
    "    # Wrap title and the extracted sentences to a maximum width of n-characters for better readability\n",
    "    extracted_df['extracted_keyword_sent'] = extracted_df['extracted_keyword_sent'].apply(wrap_text, width=80)\n",
    "\n",
    "    return extracted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_data = extract_keyword_sentences(df_cancer_related, keywords_age).to_csv('age_related_sentences.csv')\n",
    "# extracted_data = extract_keyword_sentences(df_cancer_related, keywords_gender).to_csv('gender_related_sentences.csv')\n",
    "# extracted_data = extract_keyword_sentences(df_cancer_related, keywords_etnicity).to_csv('etnicity_related_sentences.csv')\n",
    "# extracted_data = extract_keyword_sentences(df_cancer_related, keywords_geoloc).to_csv('geoloc_related_sentences.csv')\n",
    "# extracted_data = extract_keyword_sentences(df_cancer_related, keywords_patients).to_csv('patient_related_sentences.csv')\n",
    "# extracted_data = extract_keyword_sentences(df_cancer_related, keywords_bias).to_csv('bias_related_sentences.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_demo = pd.read_csv('/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/outputs/databases/annotations/anno_demographics.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_demo = anno_demo.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_demo['volume'] = anno_demo['volume'].astype(int)\n",
    "anno_demo['etnicity is used'] = anno_demo['etnicity is used'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_demo.to_csv('/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/outputs/databases/annotations/anno_demographics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
