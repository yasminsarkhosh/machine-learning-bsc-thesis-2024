<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">StructuRegNet: Structure-Guided Multimodal 2D-3D Registration</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Amaury</forename><surname>Leroy</surname></persName>
							<email>a.leroy@therapanacea.eu</email>
							<affiliation key="aff0">
								<orgName type="institution">Therapanacea</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Gustave Roussy</orgName>
								<orgName type="institution">Paris-Saclay University</orgName>
								<address>
									<addrLine>Inserm 1030</addrLine>
									<settlement>Villejuif</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Department of Radiation Oncology</orgName>
								<orgName type="department" key="dep2">Centre Léon Bérard</orgName>
								<address>
									<settlement>Lyon</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexandre</forename><surname>Cafaro</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Therapanacea</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Gustave Roussy</orgName>
								<orgName type="institution">Paris-Saclay University</orgName>
								<address>
									<addrLine>Inserm 1030</addrLine>
									<settlement>Villejuif</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Department of Radiation Oncology</orgName>
								<orgName type="department" key="dep2">Centre Léon Bérard</orgName>
								<address>
									<settlement>Lyon</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Grégoire</forename><surname>Gessain</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Pathology</orgName>
								<orgName type="institution">Gustave Roussy</orgName>
								<address>
									<settlement>Villejuif</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anne</forename><surname>Champagnac</surname></persName>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Department of Pathology</orgName>
								<orgName type="department" key="dep2">Centre Léon Bérard</orgName>
								<address>
									<settlement>Lyon</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vincent</forename><surname>Grégoire</surname></persName>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Department of Radiation Oncology</orgName>
								<orgName type="department" key="dep2">Centre Léon Bérard</orgName>
								<address>
									<settlement>Lyon</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Eric</forename><surname>Deutsch</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Gustave Roussy</orgName>
								<orgName type="institution">Paris-Saclay University</orgName>
								<address>
									<addrLine>Inserm 1030</addrLine>
									<settlement>Villejuif</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vincent</forename><surname>Lepetit</surname></persName>
							<affiliation key="aff5">
								<orgName type="institution">Ecole des Ponts ParisTech</orgName>
								<address>
									<settlement>Marne-la-Vallée</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nikos</forename><surname>Paragios</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Therapanacea</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">StructuRegNet: Structure-Guided Multimodal 2D-3D Registration</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="771" to="780"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">32E21B3B61795C60CC69406D86B9066F</idno>
					<idno type="DOI">10.1007/978-3-031-43999-5_73</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-01T10:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Multimodal</term>
					<term>Registration</term>
					<term>2D-3D</term>
					<term>Histopathology</term>
					<term>Radiology</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Multimodal 2D-3D co-registration is a challenging problem with numerous clinical applications, including improved diagnosis, radiation therapy, or interventional radiology. In this paper, we present Struc-tuRegNet, a deep-learning framework that addresses this problem with three novel contributions. First, we combine a 2D-3D deformable registration network with an adversarial modality translation module, allowing each block to benefit from the signal of the other. Second, we solve the initialization challenge for 2D-3D registration by leveraging tissue structure through cascaded rigid areas guidance and distance field regularization. Third, StructuRegNet handles out-of-plane deformation without requiring any 3D reconstruction thanks to a recursive plane selection. We evaluate the quantitative performance of StructuRegNet for head and neck cancer between 3D CT scans and 2D histopathological slides, enabling pixel-wise mapping of low-quality radiologic imaging to goldstandard tumor extent and bringing biological insights toward homogenized clinical guidelines. Additionally, our method can be used in radiation therapy by mapping 3D planning CT into the 2D MR frame of the treatment day for accurate positioning and dose delivery. Our framework demonstrates superior results to traditional methods for both applications. It is versatile to different locations or magnitudes of deformation and can serve as a backbone for any relevant clinical context.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>2D-3D registration refers to the highly challenging process of aligning an input 2D image to its corresponding slice inside a given 3D volume <ref type="bibr" target="#b3">[4]</ref>. It has received growing attention in medical imaging due to the various contexts where it applies, like image fusion between 2D real-time acquisitions and either pre-operative 3D images for guided interventions or reference planning volumes for patient positioning in radiation therapy (RT). Another important task is the volumetric reconstruction of a sequence of misaligned slices ex vivo, enabling multimodal comparison toward improved diagnosis. In this respect, overlaying 3D radiology and 2D histology could significantly enhance radiologists' understanding of the links between tissue characteristics and radiologic signals <ref type="bibr">[9]</ref>. Indeed, MRI or CT scans are the baseline source of information for cancer treatment but fail to provide an accurate assessment of disease proliferation, leading to high variability in tumor detection <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b16">17]</ref>. On the other hand, high-resolution digitized histopathology, called Whole Slide Imaging (WSI), provides cell-level information on the tumor environment from the surgically resected specimens. However, the registration process is substantially difficult due to the visual characteristics, resolution scale, and dimensional differences between the two modalities. In addition, histological preparation involves tissue fixation and slicing, leading to severe collapse and out-of-plane deformations. (Semi-)automated methods have been developed to avoid time-consuming and biased manual mapping, including protocols with 3D mold or landmarks <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b21">22]</ref>, volume reconstruction to perform 3D registration <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b22">23]</ref>, or optimization algorithms for direct multimodal comparison <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b14">15]</ref>. More recently, deep learning (DL) has been introduced but is limited to 2D/2D and requires prior plane selection <ref type="bibr" target="#b19">[20]</ref>. On the other hand, successful DL methods have been proposed to address the 2D/3D mapping problem for other medical modalities <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b20">21]</ref>. However, given the extreme deformation that the tissue undergoes during the histological process, additional guidance is needed. One promising solution is to rely on rigid structures that are supposedly more robust during the preparation. Structural information to guide image registration has been studied with the help of segmentations into the training loop <ref type="bibr" target="#b10">[11]</ref>, or by learning new image representations for refined mapping <ref type="bibr" target="#b11">[12]</ref>.</p><p>In this paper, we propose to leverage the structural features of tissue and more particularly the rigid areas to guide the registration process with two distinct contributions: (1) a cascaded rigid alignment driven by stiff regions and coupled with recursive plane selection, and (2) an improved 2D/3D deformable motion model with distance field regularization to handle out-of-plane deformation. To our knowledge, no previous study proposed 2D/3D registration combined with structure awareness. We also use the CycleGAN for image translation and direct monomodal signal comparison <ref type="bibr" target="#b24">[25]</ref>. Like <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b23">24]</ref>, we combine registration with modality translation and integrate the two aforementioned components. We demonstrate superior quantitative results for Head and Neck (H&amp;N) 3D CT and 2D WSIs than traditional approaches failing due to the histological constraints. In addition, we show that StructuRegNet performs better than the state-of-the-art model from <ref type="bibr" target="#b13">[14]</ref> on 3D CT/2D MR for the pelvis in RT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Histology-to-CT Modality Translation</head><p>Our three-step structure-aware pipeline is thoroughly detailed in Fig. <ref type="figure" target="#fig_0">1</ref>. For clarity, we focus on the radiology-histology application but the pipeline is versatile to any 2D/3D setting. The modality transfer is a 2D image-to-image translation problem defined as follows: Given a sequence of n slices H = {h 1 , ..., h n } and a volume considered as a full stack of m axial slices CT = {ct 1 , ..., ct m }, we build a CycleGAN with two generators and two discriminators G H→CT , G CT →H , D H and D CT . With a symmetric situation for G CT →H , G H→CT outputs a synthetic CT image, which is then processed by D CT along with randomly sampled original input slices with an associated adversarial loss L adv . The cyclical pattern lies in the similarity between the original images and the reconstructed samples G CT →H • G H→CT (h i ) through a pixel-wise cycle loss L cyc . Finally, we employ two additional metrics: an identity loss L Id to encourage modality-specific feature representation when considering h i being the input for G CT →H with an expected identity synthesis; and a structure consistency MIND loss from <ref type="bibr" target="#b6">[7]</ref> to ensure style transfer without content alteration. These losses are the classical implementations for CycleGAN and are detailed in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Recursive Cascaded Plane Selection</head><p>We replace the volume reconstruction step with a recursive dual model. We first rotate and translate the 3D CT to match the stack of slices H, which is crucial as an initialization step to help the 2D-3D network to focus on small out-of-plane deformations and avoid local minima. Then, we perform a precise plane selection and solve the spacing gap by adjusting the z-position of each slice to its most similar CT section. These two steps are performed iteratively until convergence, with a recursive algorithm to reduce computational cost (Fig. <ref type="figure">2</ref>).</p><p>For rigid initialization, the hypothesis is that the histological specimen is cut with an unknown spacing and angle, but the latter is supposed constant between WSIs. A rigid alignment is thus sufficient to reorient moving CT onto fixed H. Based on a theoretical axial slice sequence Z = (Z 1 , ..., Z m ), we define Fig. <ref type="figure">2</ref>. Cascaded alignment through rigid structure-aware warping followed by recursive plane selection. The deformed CT from 1. is the input for 2., along with sCT and slice sequence Z. The updated Z from 2. is applied to M h while the rigid deformation is applied to MCT so that new inputs can feed 1. again as iterative refining.</p><p>H as a sparse 3D volume the same size as CT , filled in with h i at z = Z i and zeros elsewhere (the same applies for the corresponding sCT from the previous module). Because soft tissues undergo too large out-of-plane deformations, we leverage the rigid structures which are supposed not to be distorted or shrunk during the histological process. We extract their segmentation masks M ct , M h for both modalities (see preprocessing in Sect. 3), concatenate and fed them into an encoder followed by a fully connected layer that outputs six transformation parameters (3 rotations, 3 translations). A differentiable spatial transform R finally warps M ct for similarity optimization with M h . Similarly to <ref type="bibr" target="#b13">[14]</ref>, we adopt a loss L rigid masked on empty slices to avoid the introduction of noise at slices within the gradient where no data is provided, and directly train on the Dice Similarity Coefficient (DSC) between rigid areas:</p><formula xml:id="formula_0">L rigid (M h , R(M h , M ct )) = i∈[1,m] DSC(M hZ i , R(M h , M ct )(M ctZ i )) . (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>Additionally, R also warps CT without gradient backpropagation and is the input with sCT for plane selection. We then introduce a sequence alignment problem, the objective being to update the slice sequence Z of sCT by mapping it to a corresponding sequence J of 2D images from CT . We define S a similarity matrix, where S(i, j) is the total similarity (measured with MI) when mapping sct Z1 , ..., sct Zi with ct J1 , ..., ct</p><formula xml:id="formula_2">Jj for i ∈ [1, n], j ∈ [1, m]: S(i, j) = MI(sct Zi , ct Jj ) i f i = 1 max k S(i -1, k) + MI(sct Zi , ct Jj ) else , (<label>2</label></formula><formula xml:id="formula_3">)</formula><p>which means that each row of S will be filled by computing the sum of the MI for the corresponding column j and the maximum similarity from the last row. Like any dynamic programming method, we want to find the optimal sequence J by following the backward path of S building. To do so, we retrieve the new index j that yielded the maximized similarity for each step J = [max i (S(i, j)] j , and we update Z ← J accordingly. In addition, the J sequence cannot be too different from Z as it would induce overlap between ordered WSIs. We thus constrained the possible matching values with k ∈ [Z i -2, Z i + 2]. Based on these rigid registration and plane selection blocks, we build a cascaded module to iteratively refine the alignment where the intermediate warping becomes the new input. We defined the number of iterations as a hyperparameter to reach a good balance between computational time and similarity maximization. This dual model is crucial for initialization but does not take into account out-ofplane deformations and a perfect alignment is not accessible yet. The deformable framework bridges this gap by focusing on irregular displacements caused by tissue manipulation and refining the rigid warping.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Deformable 2D-3D Registration</head><p>Given one fixed multi-slice sCT and a moving rigidly warped R(CT ) from the previous module, we adopt an architecture close to Voxelmorph <ref type="bibr" target="#b0">[1]</ref>. Still, the rigidly warped CT = R(CT ) and the plane-adjusted sparse sCT are fed through two different encoders for independent feature extraction. The architecture is depicted in Fig. <ref type="figure" target="#fig_1">3</ref>. Both latent representations are element-wise subtracted. A decoder is connected to both encoders and generates a displacement field Φ the same size as input images but with (x, y, z)-channels corresponding to the displacement in each spatial coordinate. A differentiable sampler D warps CT in a deformable setting, which is then compared to sCT through a masked Normalized Cross-Correlation (NCC) loss L defo :</p><formula xml:id="formula_4">L defo (sCT , D(sCT , CT )) = i∈[1,m] NCC(sCT Zi , D(sCT , CT )(CT Zi )) . (3)</formula><p>Finally, we add two sources of regularization. Soft tissues away from bones and cartilage are more subject to shrinkage or disruption, so we harness the information from the cartilage segmentation mask of CT to generate a distance transform map Δ defined as Δ(v) = min m∈MCT ||v -m|| 2 . It maps each voxel v of CT to its distance with the closest point m to the rigid area M CT . We can then control the displacement field, with close tissue being more highly constrained than isolated areas: Φ = Φ (Δ + ), where is the Hadamard product and is a hyperparameter matrix allowing small displacement even for cartilage areas for which distance transform is null. A second regularization takes the form of a loss L regu (Φ ) = v∈R 3 ||∇Φ (v)|| 2 on the volume to constrain spatial gradients and thus encourage smooth deformation, which is essential for empty slices which are excluded from L defo . The total loss is a weighted sum of L defo and L regu . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>Dataset and Preprocessing. Our clinical dataset consists of 108 patients for whom were acquired both a pre-operative H&amp;N CT scan and 4 to 11 WSIs after laryngectomy (with a total amount of 849 WSIs). The theoretical spacing between each slice is 5 mm, and the typical pixel size before downsampling is 100K × 100K. Two expert radiation oncologists on CT delineated both the thyroid and cricoid cartilages for structure awareness and the Gross Tumor Volume (GTV) for clinical validation, while two expert pathologists did the same on WSIs. They then meet and agreed to place 6 landmarks for each slice at important locations (not used for training). We ended up with images of size 256 × 256 (×64 for 3D CT) of 1 mm isotropic grid space. We split the dataset patient-wise into three groups for training (64), validation <ref type="bibr" target="#b19">(20)</ref>, and testing <ref type="bibr" target="#b23">(24)</ref>. To demonstrate the performance of our model on another application, we also retrieved the datasets from <ref type="bibr" target="#b13">[14]</ref> for pelvis 3D CT/2D MR. It is made of 451 pairs between CT and TrueFISP sequences, and 217 other pairs between CT and T2 sequences. We guided the registration thanks to the rigid left/right femoral heads and computed similarity metrics on the 7 additional organs at risk (anal canal, bladder, rectum, penile bulb, seminal vesicle, and prostate). All masks were provided by the authors and were originally segmented by internal experts.</p><p>Hyperparameters. We drew our code from CycleGAN and Voxelmorph implementations with modifications explained above, and we thank the authors of MSV-RegSynNet for making their code and data available to us <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b24">25]</ref>. A detailed description of architectures and hyperparameters can be found in the supplementary material. We implemented our model with Pytorch1.13 framework and trained for 600 (800 for MR/CT) epochs with a batch size of 8 (4 for MR/CT) patients parallelized over 4 NVIDIA GTX 1080 Tis.</p><p>Evaluation. We benchmarked our method against three baselines: First, to assess the benefit of modality translation over the multimodal loss, we re-used the original 3D VoxelMorph model with MIND as a multimodal metric for optimization. We also modified this approach by masking the loss function to account for the 2D-3D setting. Next, we implemented the modality translation-based MSV-RegSyn-Net and modified it for our application to measure the importance of joint structure-aware initialization and regularization. Finally, to differentiate the latter contributions, we tested two ablation studies: without the cascaded rigid mapping or without the distance field control. According to the MR/CT application in RT, we compared our model against the state-of-the-art results of MSV-RegSynNet which were computed on the same dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Modality Translation</head><p>Three samples from the test set are displayed in Fig. <ref type="figure" target="#fig_0">1</ref>. From a qualitative perspective, the densities of the different tissues are well reconstructed, with rigid structures like cartilage being lighter than soft tissues or tumors. The general shape of the larynx also complies with the original radiologic images. We achieve a mean Structural Similarity (SSIM) index of 0.76/1 between both modalities, demonstrating the strong synthesis capabilities of our network compared to MSV-RegSynNet and our ablative study without initialization process, with an SSIM of 0.72 (respectively 0.69). Therefore, the cascaded rigid initialization is crucial and helps the modality translation module in getting more similar pairs of images for eased synthesis on the next pass.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Registration</head><p>We present visual results in Fig. <ref type="figure" target="#fig_2">4</ref>. The initialization enables an accurate plane selection as proved by the similar shape of cartilages in (b). Even for some severe  difficulties inherent to the histological process like a cut larynx, the model successfully maps both cartilage and soft tissue without completely tearing the CT image thanks to regularization (c-d-e). For quantitative assessment, we computed the DSC as well as the Hausdorff Distance between cartilages, and the average distance between characteristic landmarks disposed before registration(Table <ref type="table" target="#tab_0">1</ref>).</p><p>Our method outperforms all baselines, proving the necessity of a singular approach to handle the specific case of histology. The popular Voxelmorph framework fails, and the 2D-3D adaptation demonstrates the value of the masked loss function. The superior performance of MSV-RegSynNet advocates for a modality translation-based method compared to a direct multimodal similarity criterion. In addition, the ablation studies prove the benefit of the distance field regularization and more importantly the cascaded initialization. Concerning the GPU runtime, with a 3-step cascade for initialization, the inference remains in a similar time scale to baseline methods and performs mapping in less than 3s. We also compared against MSV-RegSynNet on its own validation dataset for generalization assessment: we yielded comparable results for the first cohort and significantly better ones for the second, which proves that StructuRegNet behaves well on other modalities and that the structure awareness is an essential asset for better registration, as pelvis is a location where organs are moving. Visuals of registration results are displayed in the supplementary material. Eventually, an important clinical endpoint of our study is to compare the GTV delineated on CT with gold-standard tumor extent after co-registration to highlight systematic errors and better understand the biological environment from the radiologic signals. We show in (f) that the GTV delineated on CT overestimates the true tumor extent of around 31%, but does not always encompass the tumor with a proportion of histological tumor contained within the CT contour of 0.86. The typical error cases are the inclusion of cartilage or edema, which highlights the limitations and variability of radiology-based examinations, leading to increased toxicity or untreated areas in RT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion and Conclusion</head><p>We introduced a novel framework for 2D/3D multimodal registration. Struc-tuRegNet leverages the structure of tissues to guide the registration through both initial plane selection and deformable regularization; it combines adversarial training for modality translation with a 2D-3D mapping setting and does not require any protocol for 3D reconstruction. It is worth noticing that even if the annotation of cartilage was manual, automating this process is not a bottleneck as the difference in contrast between soft tissue and stiff areas is clear enough to leverage any image processing tool for this task. Finally, it is entirely versatile as we designed our experiments for CT-WSI but any 3D radiological images are suitable. We achieve superior results than state-of-the-art methods in DL-based registration in a similar time scale, allowing precise mapping of both modalities and a better understanding of the tumor microenvironment. The main limitation lies in the handling of organs without any rigid areas like the prostate. Future work also includes a study with biomarkers from immunohistochemistry mapped onto radiology to go beyond binary tumor masks and move toward virtual biopsy.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Overview of StructuRegNet, where the WSIs are first translated into synthetic CTs (2.1) before getting matched with the most similar CT slices thanks to a cascaded structure-aware plane selection (2.2). Finally, the rigid transformation is refined through a deformable network to handle out-of-plane distortions (2.3).</figDesc><graphic coords="3,58,98,54,02,334,54,132,67" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Deformable 2D-3D registration pipeline, made of two encoders and a shared decoder, with regularization applied on the displacement field Φ thanks to the distance map from CT.</figDesc><graphic coords="6,42,30,59,30,261,88,70,63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Visual results for two samples. (a) Original CT, (b) warped CT after rigid initialization and plane selection, (c) warped CT after deformable registration, (d) original histology with landmarks from pathologist (black) and warped projected landmarks from radiologists (yellow), (e) overlaid cartilage masks after registration of histology (filled blue) and radiology (red for our method, yellow for MSV-RegSynNet), (f) Overlaid contours between warped CT (GTV, red) and WSI (true tumor extent, blue). (Color figure online)</figDesc><graphic coords="7,70,98,394,46,310,93,113,23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="4,56,79,54,56,310,81,175,15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Mean and stand. dev. registration performance in terms of Dice Score (%), Hausdorff Distance (mm) and Landmark Error (mm). Inference runtime is in seconds.</figDesc><table><row><cell>Method</cell><cell>Dice</cell><cell>Hausdorff</cell><cell>Landmark</cell><cell>Runtime</cell></row><row><cell>VoxelMorph 3D</cell><cell cols="2">68.4 ± 0.6 8.53 ± 0.32</cell><cell cols="2">6.71 ± 0.16 1.3</cell></row><row><cell cols="3">VoxelMorph 2/3D 71.9 ± 1.7 7.19 ± 0.24</cell><cell cols="2">5.99 ± 0.22 1.4</cell></row><row><cell cols="3">MSV-RegSynNet 76.3 ± 1.4 6.88 ± 0.28</cell><cell cols="2">4.98 ± 0.15 2.1</cell></row><row><cell>Ours (no init)</cell><cell cols="2">77.9 ± 1.9 6.91 ± 0.19</cell><cell cols="2">4.73 ± 0.31 2.1</cell></row><row><cell>Ours (no regu)</cell><cell cols="2">85.1 ± 0.8 4.23 ± 0.27</cell><cell cols="2">3.71 ± 0.19 2.8</cell></row><row><cell>Ours</cell><cell cols="4">86.9 ± 1.3 3.81 ± 0.20 3.28 ± 0.16 2.9</cell></row><row><cell>3D CT/2D MR</cell><cell cols="4">0.35T TrueFISP → 3D CT 1.5T T2 → 3D CT</cell></row><row><cell></cell><cell>Dice</cell><cell>Hausdorff</cell><cell>Dice</cell><cell>Hausdorff</cell></row><row><cell cols="3">MSV-RegSynNet 84.6 ± 0.9 7.25 ± 0.05</cell><cell>86.1 ± 1.0</cell><cell>5.84 ± 0.15</cell></row><row><cell>Ours</cell><cell cols="4">84.8 ± 1.1 7.12 ± 0.08 87.9 ± 1.2 5.21 ± 0.09</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43999-5 73.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">VoxelMorph: a learning framework for deformable medical image registration</title>
		<author>
			<persName><forename type="first">G</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Sabuncu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guttag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Dalca</surname></persName>
		</author>
		<idno type="DOI">10.1109/TMI.2019.2897538</idno>
		<ptr target="https://doi.org/10.1109/TMI.2019.2897538" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1788" to="1800" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The accuracy of target delineation in laryngeal and hypopharyngeal cancer</title>
		<author>
			<persName><forename type="first">J</forename><surname>Caldas-Magalhaes</surname></persName>
		</author>
		<idno type="DOI">10.3109/0284186X.2015.1006401</idno>
		<ptr target="https://doi.org/10.3109/0284186X.2015.1006401" />
	</analytic>
	<monogr>
		<title level="j">Acta Oncologica</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1181" to="1187" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Elastic registration of multimodal prostate MRI and histology via multiattribute combined mutual information</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chappelow</surname></persName>
		</author>
		<idno type="DOI">10.1118/1.3560879</idno>
		<ptr target="https://doi.org/10.1118/1.3560879" />
	</analytic>
	<monogr>
		<title level="j">Med. Phys</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2005">2005-2018 (2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Slice-to-volume medical image registration: a survey</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ferrante</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Paragios</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.media.2017.04.010</idno>
		<ptr target="https://doi.org/10.1016/j.media.2017.04.010" />
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="101" to="123" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Inter-observer variability in the delineation of pharyngo-laryngeal tumor, parotid glands and cervical spinal cord: comparison between CT-scan and MRI</title>
		<author>
			<persName><forename type="first">X</forename><surname>Geets</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.radonc.2005.04.010</idno>
		<ptr target="https://doi.org/10.1016/j.radonc.2005.04.010" />
	</analytic>
	<monogr>
		<title level="j">Radiother. Oncol.: J. Eur. Soc. Ther. Radiol. Oncol</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="31" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yan</surname></persName>
		</author>
		<title level="m">End-to-end ultrasound frame to volume registration</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">MIND: modality independent neighbourhood descriptor for multi-modal deformable registration</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Heinrich</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.media.2012.05.008</idno>
		<ptr target="https://doi.org/10.1016/j.media.2012.05.008" />
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1423" to="1435" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Jaganathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Borsdorf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shetty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Maier</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87202-1_37</idno>
		<idno type="arXiv">arXiv:2107.10004</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87202-137" />
		<title level="m">Deep iterative 2D/3D registration</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12904</biblScope>
			<biblScope unit="page" from="383" to="392" />
		</imprint>
	</monogr>
	<note>cs, eess</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Interobserver variation among pathologists for delineation of tumor on H&amp;E-sections of laryngeal and hypopharyngeal carcinoma. How good is the gold standard?</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Jager</surname></persName>
		</author>
		<idno type="DOI">10.3109/0284186X.2015.1049661</idno>
		<ptr target="https://doi.org/10.3109/0284186X.2015.1049661" />
	</analytic>
	<monogr>
		<title level="j">Acta Oncologica</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="391" to="395" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Methods for registration of magnetic resonance images of ex vivo prostate specimens with histology</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Kimm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Magn. Reson. Imaging</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="206" to="212" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning deformable image registration with structure guidance constraints for adaptive radiotherapy</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kuckertz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Papenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Honegger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Morgas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Haas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Heldmann</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-50120-4_5</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-50120-45" />
	</analytic>
	<monogr>
		<title level="m">WBIR 2020</title>
		<editor>
			<persName><forename type="first">Ž</forename><surname>Špiclin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Mcclelland</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Kybic</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">O</forename><surname>Goksel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12120</biblScope>
			<biblScope unit="page" from="44" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Image-and-spatial transformer networks for structure-guided image registration</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Oktay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schuh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schaap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.1907.09200</idno>
		<ptr target="https://doi.org/10.48550/arXiv.1907.09200" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">MO-0476 statistical discrepancies in GTV delineation for H&amp;N cancer across expert centers</title>
		<author>
			<persName><forename type="first">A</forename><surname>Leroy</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0167-8140(22)02370-2</idno>
		<ptr target="https://doi.org/10.1016/S0167-8140(22)02370-2" />
	</analytic>
	<monogr>
		<title level="j">Radiother. Oncol</title>
		<imprint>
			<biblScope unit="volume">170</biblScope>
			<biblScope unit="page" from="426" to="S427" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">End-to-end multi-slice-to-volume concurrent registration and multimodal generation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Leroy</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16446-0_15</idno>
		<idno>978-3-031-16446-0 15</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="152" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Co-registration of ex vivo surgical histopathology and in vivo T2 weighted MRI of the prostate via multi-scale spectral embedding representation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-017-08969-w</idno>
		<ptr target="https://doi.org/10.1038/s41598-017-08969-w" />
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">8717</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Markova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ronchetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Zettinig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Prevost</surname></persName>
		</author>
		<title level="m">Global multimodal 2D/3D registration via local descriptors learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Tumor delineation: the weakest link in the search for accuracy in radiotherapy</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Njeh</surname></persName>
		</author>
		<idno type="DOI">10.4103/0971-6203.44472</idno>
		<ptr target="https://doi.org/10.4103/0971-6203.44472" />
	</analytic>
	<monogr>
		<title level="j">J. Med. Phys./Assoc. Med. Physicists India</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="136" to="140" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deformable image registration between pathological images and MR image via an optical macro image</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ohnishi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.prp.2016.07.018</idno>
		<ptr target="https://doi.org/10.1016/j.prp.2016.07.018" />
	</analytic>
	<monogr>
		<title level="j">Pathol. Res. Pract</title>
		<imprint>
			<biblScope unit="volume">212</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="927" to="936" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Registration of presurgical MRI and histopathology images from radical prostatectomy via RAPSODI</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rusu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Phys</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4177" to="4188" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">ProsRegNet: a deep learning framework for registration of MRI and histopathology images of the prostate</title>
		<author>
			<persName><forename type="first">W</forename><surname>Shao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.00991</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Z</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S J</forename><surname>Estépar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Niethammer</surname></persName>
		</author>
		<title level="m">LiftReg: limited angle 2D/3D deformable registration</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Prostate: registration of digital histopathologic images to in vivo MR images acquired by using endorectal receive coil</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Ward</surname></persName>
		</author>
		<idno type="DOI">10.1148/radiol.12102294</idno>
		<ptr target="https://doi.org/10.1148/radiol.12102294" />
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">263</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="856" to="864" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Determining histology-MRI slice correspondences for defining MRIbased disease signatures of prostate cancer</title>
		<author>
			<persName><forename type="first">G</forename><surname>Xiao</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.compmedimag.2010.12.003</idno>
		<ptr target="https://doi.org/10.1016/j.compmedimag.2010.12.003" />
	</analytic>
	<monogr>
		<title level="j">Comput. Med. Imaging Graph</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="568" to="578" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Adversarial uni-and multi-modal stream networks for multimodal image registration</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.02790</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>cs, eess</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Unpaired image-to-image translation using cycle-consistent adversarial networks</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.10593</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
