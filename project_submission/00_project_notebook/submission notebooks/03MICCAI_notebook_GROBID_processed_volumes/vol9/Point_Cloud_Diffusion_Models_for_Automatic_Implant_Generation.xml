<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Point Cloud Diffusion Models for Automatic Implant Generation</title>
				<funder ref="#_APdUczn">
					<orgName type="full">Werner Siemens Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Paul</forename><surname>Friedrich</surname></persName>
							<email>paul.friedrich@unibas.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Biomedical Engineering</orgName>
								<orgName type="institution">University of Basel</orgName>
								<address>
									<settlement>Allschwil</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Julia</forename><surname>Wolleb</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Biomedical Engineering</orgName>
								<orgName type="institution">University of Basel</orgName>
								<address>
									<settlement>Allschwil</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Florentin</forename><surname>Bieder</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Biomedical Engineering</orgName>
								<orgName type="institution">University of Basel</orgName>
								<address>
									<settlement>Allschwil</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Florian</forename><forename type="middle">M</forename><surname>Thieringer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Biomedical Engineering</orgName>
								<orgName type="institution">University of Basel</orgName>
								<address>
									<settlement>Allschwil</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Oral and Cranio-Maxillofacial Surgery</orgName>
								<orgName type="institution">University Hospital Basel</orgName>
								<address>
									<settlement>Basel</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Philippe</forename><forename type="middle">C</forename><surname>Cattin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Biomedical Engineering</orgName>
								<orgName type="institution">University of Basel</orgName>
								<address>
									<settlement>Allschwil</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Point Cloud Diffusion Models for Automatic Implant Generation</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="112" to="122"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">84916CEC367EDBFEC333152F7D166B3B</idno>
					<idno type="DOI">10.1007/978-3-031-43996-4_11</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-01T10:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Automatic Implant Generation</term>
					<term>Diffusion Models</term>
					<term>Point Clouds</term>
					<term>Voxelization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Advances in 3D printing of biocompatible materials make patient-specific implants increasingly popular. The design of these implants is, however, still a tedious and largely manual process. Existing approaches to automate implant generation are mainly based on 3D U-Net architectures on downsampled or patch-wise data, which can result in a loss of detail or contextual information. Following the recent success of Diffusion Probabilistic Models, we propose a novel approach for implant generation based on a combination of 3D point cloud diffusion models and voxelization networks. Due to the stochastic sampling process in our diffusion model, we can propose an ensemble of different implants per defect, from which the physicians can choose the most suitable one. We evaluate our method on the SkullBreak and Skull-Fix datasets, generating high-quality implants and achieving competitive evaluation scores. The project page can be found at https://pfriedri. github.io/pcdiff-implant-io.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The design of 3D-printed patient-specific implants, commonly used in cranioplasty and maxillofacial surgery, is a challenging and time-consuming task that is usually performed manually. To speed up the design process and enable point-ofcare implant generation, approaches for automatically deriving suitable implant designs from medical images are needed. This paper presents a novel approach based on a Denoising Diffusion Probabilistic Model for 3D point clouds that reconstructs complete anatomical structures S c from segmented CT images of subjects showing bone defects S d . An overview of the proposed method is shown in Fig. <ref type="figure" target="#fig_0">1</ref>. Since performing the anatomy reconstruction task in a high resolution voxel space would be memory inefficient and computationally expensive, we propose a method that builds upon a sparse surface point cloud representation of the input anatomy. This point cloud c 0 , which can be obtained from the defective segmentation mask S d , serves as input to a Denoising Diffusion Probabilistic Model <ref type="bibr" target="#b38">[37]</ref> that, conditioned on this input c 0 , reconstructs the complete anatomy x 0 by generating missing points x0 . The second network transforms the point cloud x 0 back into voxel space using a Differentiable Poisson Solver <ref type="bibr" target="#b23">[23]</ref>. The final implant I is generated by the Boolean subtraction of the completed and defective anatomical structure. We thereby ensure a good fit at the junction between implant and skull. Our main contributions are:</p><p>-We employ 3D point cloud diffusion models for an automatic patient-specific implant generation task. The stochastic sampling process of diffusion models allows for the generation of multiple anatomically reasonable implant designs per subject, from which physicians can choose the most suitable one. -We evaluate our method on the SkullBreak and SkullFix datasets, generating high-quality implants and achieving competitive evaluation scores.</p><p>Related Work. Previous work on automatic implant generation methods mainly derived from the AutoImplant challenges <ref type="bibr" target="#b11">[11]</ref><ref type="bibr" target="#b12">[12]</ref><ref type="bibr" target="#b13">[13]</ref> at the 2020/21 MICCAI conferences. Most of the proposed methods were based on 2D slice-wise U-Nets <ref type="bibr" target="#b27">[27]</ref> and 3D U-Nets on downsampled <ref type="bibr" target="#b8">[8,</ref><ref type="bibr" target="#b20">20,</ref><ref type="bibr" target="#b32">31]</ref> or patch-wise data <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b14">14,</ref><ref type="bibr" target="#b22">22]</ref>. Other approaches were based on Statistical Shape Models <ref type="bibr" target="#b35">[34]</ref>, Generative Adversarial Networks <ref type="bibr" target="#b24">[24]</ref> or Variational Autoencoders <ref type="bibr" target="#b31">[30]</ref>. This work is based on Diffusion Models <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b29">28]</ref>, which achieved good results in 2D reconstruction tasks like image inpainting <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b26">26]</ref> and were also already applied to 3D generative tasks like point cloud generation <ref type="bibr" target="#b18">[18,</ref><ref type="bibr" target="#b21">21,</ref><ref type="bibr" target="#b37">36]</ref> and point cloud completion <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b38">37]</ref>.</p><p>For retrieving a dense voxel representation of a point cloud, many approaches rely on a combination of surface meshing <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b7">7]</ref> and ray casting algorithms. Since surface meshing of unoriented point clouds with a non-uniform distribution is challenging and ray casting implies additional computational effort, we look at point cloud voxelization based on a Differentiable Poisson Solver <ref type="bibr" target="#b23">[23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>As presented in Fig. <ref type="figure" target="#fig_0">1</ref>, we propose a multi-step approach for generating an implant I from a binary voxel representation S d of a defective anatomical structure.</p><p>Point Cloud Generation. Since the proposed method for shape reconstruction works in the point cloud space, we first need to derive a point cloud c 0 ∈ R N ×3 from S d . We therefore create a surface mesh of S d using Marching Cubes <ref type="bibr" target="#b16">[16]</ref>.</p><p>Then we sample N points from this surface mesh using Poisson Disk Sampling <ref type="bibr" target="#b36">[35]</ref>. During training, we generate the ground truth point cloud x0 ∈ R M ×3 by sampling M points from the ground truth implant using the same approach.</p><p>Diffusion Model for Shape Reconstruction. Reconstructing the shape of an anatomical structure can be seen as a conditional generation process. We train a diffusion model θ to reconstruct the point cloud x 0 = (x 0 , c 0 ) that describes the complete anatomical structure S c . The generation process is conditioned on the points c 0 belonging to the known defective anatomical structure S d . An overview is given in Fig. <ref type="figure" target="#fig_1">2</ref>. For describing the diffusion model, we follow the formulations in <ref type="bibr" target="#b38">[37]</ref>. Starting from x 0 , we first define the forward diffusion process, that gradually adds small amounts of noise to x0 , while keeping c 0 unchanged and thus produces a series of point clouds {x 0 = (x 0 , c 0 ),</p><formula xml:id="formula_0">x 1 = (x 1 , c 0 ), ..., x T = (x T , c 0 )}.</formula><p>This conditional forward diffusion process can be modeled as a Markov chain with a defined number of timesteps T and transfers x0 into a noise distribution:</p><formula xml:id="formula_1">q(x 0:T ) = q(x 0 ) T t=1 q(x t |x t-1 ). (<label>1</label></formula><formula xml:id="formula_2">)</formula><p>Each transition is modeled as a parameterized Gaussian and follows a predefined variance schedule β 1 , ..., β T that controls the diffusion rate of the process:</p><formula xml:id="formula_3">q(x t |x t-1 ) := N ( 1 -β t xt-1 , β t I). (<label>2</label></formula><formula xml:id="formula_4">)</formula><p>The goal of the diffusion model is to learn the reverse diffusion process that is able to gradually remove noise from xT ∼ N (0, I). This reverse process is also modeled as a Markov chain</p><formula xml:id="formula_5">p θ (x 0:T ) = p(x T ) T t=1 p θ (x t-1 |x t , c 0 ),<label>(3)</label></formula><p>with each transition being defined as a Gaussian, with the estimated mean μ θ :</p><formula xml:id="formula_6">p θ (x t-1 |x t , c 0 ) := N (μ θ (x t , c 0 , t), β t I).<label>(4)</label></formula><p>As derived in <ref type="bibr" target="#b38">[37]</ref>, the network θ can be adapted to predict the noise θ (x t , c 0 , t) to be removed from a noisy point cloud xt . During training, we compute xt at a random timestep t ∈ {1, ..., T } and optimize a Mean Squared Error (MSE) loss</p><formula xml:id="formula_7">L t = -θ (x t , c 0 , t) 2 , where xt = αt x0 + 1 -αt ,<label>(5)</label></formula><p>with ∼ N (0, I), α t = 1β t , and αt = t s=1 α s . To perform shape reconstruction with the trained network, we start with a point cloud x T = (x T , c 0 ) with xT ∼ N (0, I). This point cloud is then passed through the reverse diffusion process</p><formula xml:id="formula_8">xt-1 = 1 √ α t xt - 1 -α t √ 1 -αt θ (x t , c 0 , t) + β t z, (<label>6</label></formula><formula xml:id="formula_9">)</formula><p>with z ∼ N (0, I), for t = T, ..., 1. While this reverse diffusion process gradually removes noise from xT , the points belonging to the defective anatomical structure c 0 remain unchanged. As proposed in <ref type="bibr" target="#b38">[37]</ref>, our network θ is based on a PointNet++ <ref type="bibr" target="#b25">[25]</ref> architecture with Point-Voxel Convolutions <ref type="bibr" target="#b15">[15]</ref>. Details on the network architecture can be found in the supplementary material.</p><p>Voxelization. To create an implant, the point cloud of the restored anatomy must be converted back to voxel space. We follow a learning-based pipeline proposed in <ref type="bibr" target="#b23">[23]</ref>. The pipeline shown in Fig. <ref type="figure" target="#fig_2">3</ref> takes an unoriented point cloud x 0 as input and learns to predict an upsampled, oriented point cloud x with normal vectors n. From this upsampled point cloud, an indicator grid χ can be produced using a Differentiable Poisson Solver (DPSR). The complete voxel representation S c can then be obtained by evaluating the following equation for every voxel position i:</p><formula xml:id="formula_10">S c (i) = 1, if χ(i) ≤ 0 0, if χ(i) &gt; 0 . (<label>7</label></formula><formula xml:id="formula_11">)</formula><p>During training, the ground truth indicator grid χ can be obtained directly from the ground truth voxel representation S c and, as described in <ref type="bibr" target="#b6">[6]</ref>, is defined as:</p><formula xml:id="formula_12">χ(i) = 0.5, if S c (i) = 0 -0.5, if S c (i) = 1 . (<label>8</label></formula><formula xml:id="formula_13">)</formula><p>Due to the differentiability of the used Poisson solver, the networks can be trained with an MSE loss between the estimated and ground truth indicator grid:</p><formula xml:id="formula_14">L v = χ -χ 2 . (<label>9</label></formula><formula xml:id="formula_15">)</formula><p>For further information on the used network architectures, we refer to <ref type="bibr" target="#b23">[23]</ref>.</p><p>Implant Generation. With the predicted complete anatomical structure S c and the defective input structure S d , an implant geometry I can be derived by the Boolean subtraction between S c and S d :</p><formula xml:id="formula_16">I = S c -S d . (<label>10</label></formula><formula xml:id="formula_17">)</formula><p>To further improve the implant quality and remove noise, we apply a median filter as well as binary opening to the generated implant.</p><p>Ensembling. As the proposed point cloud diffusion model features a stochastic generation process, we can sample multiple anatomically reasonable implant designs for each defect. This offers physicians the opportunity of selecting from various possible implants and allows the determination of a mean implant from a previously generated ensemble of n different implants. As presented in <ref type="bibr" target="#b33">[32]</ref>, the ensembling strategy can also be used to create voxel-wise variance over an ensemble. These variance maps highlight areas with high differences between multiple anatomically reasonable implants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>We evaluated our method on the publicly available parts of the SkullBreak and SkullFix datasets. For the point cloud diffusion model we chose a total number of 30 720 points (N = 27 648, M = 3072), set T = 1000, followed a linear variance schedule between β 0 = 10 -4 and β T = 0.02, used the Adam optimizer with a learning rate of 2 × 10 -4 , a batch size of 8, and trained the network for 15 000 epochs. This took about 20 d/4 d for the SkullBreak/SkullFix dataset. For training the voxelization network, we used the Adam optimizer with a learning rate of 5 × 10 -4 , a batch size of 2 and trained the networks for 1300/500 epochs on the SkullBreak/SkullFix dataset. This took about 72 h/5 h. All experiments were performed on an NVIDIA A100 GPU using PyTorch as the framework.</p><p>SkullBreak/SkullFix. Both datasets, SkullBreak and SkullFix <ref type="bibr" target="#b9">[9]</ref>, contain binary segmentation masks of head CT images with artificially created skull defects. While the SkullFix dataset mainly features rectangular defect patterns with additional craniotomy drill holes, SkullBreak offers more diverse defect patterns. The SkullFix dataset was resampled to an isotropic voxel size of 0.45 mm, zero padded to a volume size of 512 × 512 × 512, and split into a training set with 75 and a test set with 25 volumes. The SkullBreak dataset already has an isotropic voxel size of 0.4 mm and a volume size of 512 × 512 × 512. We split the SkullBreak dataset into a training set with 430 and a test set with 140 volumes. All point clouds sampled from these datasets were normalized to a range between <ref type="bibr">[-3, 3]</ref> in all spatial dimensions. The SkullBreak and SkullFix datasets were both adapted from the publicly available head CT dataset CQ500, which is licensed under a CC-BY-NC-SA 4.0 and End User License Agreement (EULA). The SkullBreak and SkullFix datasets were adapted and published under the same licenses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Discussion</head><p>For evaluating our approach, we compared it to three methods from AutoImplant 2021 challenge: the winning 3D U-Net based approach <ref type="bibr" target="#b32">[31]</ref>, a 3D U-Net based approach with sparse convolutions <ref type="bibr" target="#b10">[10]</ref> and a slice-wise 2D U-Net approach <ref type="bibr" target="#b34">[33]</ref>. We also evaluated the mean implant produced by the proposed ensembling  strategy (n = 5). The implant generation time ranges from ∼1000 s for Skull-Break (n = 1) to ∼1200 s for SkullFix (n = 5), with the diffusion model requiring most of this time. In Table <ref type="table" target="#tab_0">1</ref>, the Dice score (DSC), the 10 mm boundary DSC (bDSC), as well as the 95 percentile Hausdorff Distance (HD95) are presented as mean values over the respective test sets.</p><p>Qualitative results of the different implant generation methods are shown in Fig. <ref type="figure" target="#fig_3">4</ref> and Fig. <ref type="figure" target="#fig_4">5</ref>, as well as in the supplementary material. Implementation detail for the comparing methods, more detailed runtime information, as well as the used code can be found at https://github.com/pfriedri/pcdiff-implant. We outperformed the sparse 3D U-Net, while achieving comparable results to the challenge winning 3D U-Net and the 2D U-Net based approach. By visually comparing the results in Fig. <ref type="figure" target="#fig_3">4</ref>, our method produces significantly smoother surfaces that are more similar to the ground truth implant. In Fig. <ref type="figure" target="#fig_4">5</ref>, we show that our method reliably reconstructs defects of various sizes, as well as complicated geometric structures. For large defects, however, we achieve lower evaluation scores, which can be explained with multiple anatomically reasonable implant solutions. This was also reported in <ref type="bibr" target="#b32">[31]</ref> and <ref type="bibr" target="#b35">[34]</ref>. In Fig. <ref type="figure" target="#fig_5">6</ref>, we present the proposed ensembling strategy for an exemplary defect. Apart from generating multiple implants, we can compute the mean implant and the variance map. To the best of our knowledge, we are the first to combine such an approach with an automatic implant generation method. Not only do we offer a choice of implants, but we can also provide physicians with information about implant areas with more anatomical variation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We present a novel approach for automatic implant generation based on a combination of a point cloud diffusion model and a voxelization network. Due to the sparse point cloud representation of the anatomical structure, the proposed approach can directly handle high resolution input images without losing context information. We achieve competitive evaluation scores, while producing smoother, more realistic surfaces. Furthermore, our method is capable of producing different implants per defect, accounting for the anatomical variation seen in the training population. Thereby, we can propose several solutions to the physicians, from which they can choose the most suitable one. For future work, we plan to speed up the sampling process by using different sampling schemes, as proposed in <ref type="bibr" target="#b5">[5,</ref><ref type="bibr" target="#b30">29]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Proposed implant generation method with shape reconstruction in point cloud space. The implant geometry I is defined as the Boolean subtraction between completed output Sc and defective input S d in voxel space.</figDesc><graphic coords="2,81,96,53,72,288,40,181,00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Conditional diffusion model for anatomy reconstruction in point cloud space. Points belonging to the defective anatomical structure c0 are shown in color and remain unchanged throughout the whole process. The forward and reverse diffusion processes therefore only affect the gray points x0:T belonging to the implant.</figDesc><graphic coords="4,56,46,53,87,339,88,115,84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Voxelization pipeline based on a trainable network and a Differentiable Poisson Solver (DPSR). The trainable part learns to produce an upsampled point cloud x with estimated normal vectors n. The DPSR transforms (x, n) into an indicator function χ from which a voxel representation can be derived.</figDesc><graphic coords="5,46,80,125,18,330,76,54,52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Predicted implants for a skull defect from the SkullFix dataset.</figDesc><graphic coords="7,90,18,184,67,254,68,382,72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Results of our method for the five defect classes of the SkullBreak dataset.</figDesc><graphic coords="8,58,47,293,60,335,08,65,80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Different implants, mean implant and variance map for a single skull defect.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Mean evaluation scores on SkullBreak and SkullFix test sets.</figDesc><table><row><cell>Model</cell><cell cols="2">SkullBreak</cell><cell></cell><cell cols="2">SkullFix</cell><cell></cell></row><row><cell></cell><cell cols="6">DSC ↑ bDSC ↑ HD95 ↓ DSC ↑ bDSC ↑ HD95 ↓</cell></row><row><cell>3D U-Net [31]</cell><cell>0.87</cell><cell>0.91</cell><cell>2.32</cell><cell>0.91</cell><cell>0.95</cell><cell>1.79</cell></row><row><cell cols="2">3D U-Net (sparse) [10] 0.71</cell><cell>0.80</cell><cell>4.60</cell><cell>0.81</cell><cell>0.87</cell><cell>3.04</cell></row><row><cell>2D U-Net [33]</cell><cell>0.87</cell><cell>0.89</cell><cell>2.13</cell><cell>0.89</cell><cell>0.92</cell><cell>1.98</cell></row><row><cell>Ours</cell><cell>0.86</cell><cell>0.88</cell><cell>2.51</cell><cell>0.90</cell><cell>0.92</cell><cell>1.73</cell></row><row><cell>Ours (n=5)</cell><cell>0.87</cell><cell>0.89</cell><cell>2.45</cell><cell>0.90</cell><cell>0.93</cell><cell>1.69</cell></row><row><cell>Axial</cell><cell cols="2">Coronal</cell><cell cols="2">Sagittal</cell><cell cols="2">Overview</cell></row><row><cell>U-Net</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>3D</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>3D U-Net (sparse)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2D U-Net</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Ours</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Ours (n=5)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Ground Truth</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. This work was financially supported by the <rs type="funder">Werner Siemens Foundation</rs> through the <rs type="projectName">MIRACLE II</rs> project.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_APdUczn">
					<orgName type="project" subtype="full">MIRACLE II</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43996-4 11.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Implicit geometric regularization for learning shapes</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gropp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yariv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Haim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Atzmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lipman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Machine Learning and Systems</title>
		<meeting>Machine Learning and Systems</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3569" to="3579" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Point2mesh: a self-prior for deformable meshes</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hanocka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Metzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Giryes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
		<idno>Article-Nr. 126</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Denoising diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">High-resolution cranial implant prediction via patchwise training</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Egger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AutoImplant 2020</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Egger</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">12439</biblScope>
			<biblScope unit="page" from="94" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Cham</forename><surname>Springer</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-64327-0_11</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-64327-011" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Elucidating the design space of diffusionbased generative models</title>
		<author>
			<persName><forename type="first">T</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aittala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Poisson surface reconstruction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kazhdan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bolitho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hoppe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics Symposium on Geometry Processing</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Screened poisson surface reconstruction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kazhdan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hoppe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Cranial defect reconstruction using cascaded CNN with alignment</title>
		<author>
			<persName><forename type="first">O</forename><surname>Kodym</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Španěl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Herout</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-64327-0_7</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-64327-07" />
	</analytic>
	<monogr>
		<title level="m">AutoImplant 2020</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Egger</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12439</biblScope>
			<biblScope unit="page" from="56" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Skullbreak/skullfix -dataset for automatic cranial implant design and a benchmark for volumetric shape learning tasks</title>
		<author>
			<persName><forename type="first">O</forename><surname>Kodym</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Brief</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page">106902</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Sparse convolutional neural network for skull reconstruction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kroviakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Egger</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-92652-6_7</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-92652-67" />
	</analytic>
	<monogr>
		<title level="m">AutoImplant 2021</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Egger</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">13123</biblScope>
			<biblScope unit="page" from="80" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<idno type="DOI">10.1007/978-3-030-64327-0</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-64327-0" />
		<title level="m">Towards the Automatization of Cranial Implant Design in Cranioplasty</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Egger</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12439</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<idno type="DOI">10.1007/978-3-030-92652-6</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-92652-6" />
		<title level="m">Towards the Automatization of Cranial Implant Design in Cranioplasty II</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Egger</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">13123</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Autoimplant 2020-first MICCAI challenge on automatic cranial implant design</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2329" to="2342" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Automatic skull defect restoration and cranial implant generation for cranioplasty</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page">102171</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Point-voxel CNN for efficient 3D deep learning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Marching cubes: a high resolution 3D surface construction algorithm</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Lorensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Cline</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGGRAPH Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="163" to="169" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Repaint: inpainting using denoising diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lugmayr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">V</forename><surname>Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Diffusion probabilistic models for 3D point cloud generation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A conditional point diffusion-refinement paradigm for 3D point cloud completion</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Cranial implant design via virtual craniectomy with shape priors</title>
		<author>
			<persName><forename type="first">F</forename><surname>Matzkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Newcombe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ferrante</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-64327-0_5</idno>
		<idno>978-3-030-64327-0 5</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">AutoImplant 2020</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Egger</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12439</biblScope>
			<biblScope unit="page" from="37" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.08751</idno>
		<title level="m">Point-e: a system for generating 3D point clouds from complex prompts</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Cranial implant design using V-Net based region of interest reconstruction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sindhura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K S S</forename><surname>Gorthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">V</forename><surname>Kiran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gorthi</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-92652-6_10</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-92652-610" />
	</analytic>
	<monogr>
		<title level="m">AutoImplant 2021</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Egger</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">13123</biblScope>
			<biblScope unit="page" from="116" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Shape as points: a differentiable Poisson solver</title>
		<author>
			<persName><forename type="first">S</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Niemeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Automated virtual reconstruction of large skull defects using statistical shape models and generative adversarial networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Pimentel</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-64327-0_3</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-64327-03" />
	</analytic>
	<monogr>
		<title level="m">AutoImplant 2020</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Egger</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12439</biblScope>
			<biblScope unit="page" from="16" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Pointnet++: deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Palette: image-to-image diffusion models</title>
		<author>
			<persName><forename type="first">C</forename><surname>Saharia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH 2022 Conference Proceedings</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Cranial implant design through multiaxial slice inpainting using deep learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AutoImplant 2020</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Egger</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">12439</biblScope>
			<biblScope unit="page" from="28" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Cham</forename><surname>Springer</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-64327-0_4</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-64327-04" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep unsupervised learning using nonequilibrium thermodynamics</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Maheswaranathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ganguli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning</title>
		<meeting>the 32nd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Denoising diffusion implicit models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Cranial implant design using a deep learning method with anatomical regularization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-64327-0_10</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-64327-010" />
	</analytic>
	<monogr>
		<title level="m">AutoImplant 2020</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Egger</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12439</biblScope>
			<biblScope unit="page" from="85" to="93" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Improving the automatic cranial implant design in cranioplasty by linking different datasets</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wodzinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Daniol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hemmerling</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-92652-6_4</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-92652-64" />
	</analytic>
	<monogr>
		<title level="m">AutoImplant 2021</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Egger</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">13123</biblScope>
			<biblScope unit="page" from="29" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Diffusion models for implicit image segmentation ensembles</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wolleb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sandkühler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bieder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valmaggia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Cattin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Machine Learning Research</title>
		<meeting>Machine Learning Research</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Cranial implant prediction by learning an ensemble of slice-based skull completion networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-92652-6_8</idno>
		<idno>978-3-030-92652-6 8</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">AutoImplant 2021</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Egger</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">13123</biblScope>
			<biblScope unit="page" from="95" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">PCA-Skull: 3D skull shape modelling using principal component analysis</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Egger</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-92652-6_9</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-92652-69" />
	</analytic>
	<monogr>
		<title level="m">AutoImplant 2021</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Egger</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">13123</biblScope>
			<biblScope unit="page" from="105" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Sample elimination for generating poisson disk sample sets</title>
		<author>
			<persName><forename type="first">C</forename><surname>Yuksel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graph. Forum</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="25" to="32" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">LION: latent point diffusion models for 3D shape generation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">3D shape generation and completion through point-voxel diffusion</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="5826" to="5835" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
