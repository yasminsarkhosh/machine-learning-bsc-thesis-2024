<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-scope Analysis Driven Hierarchical Graph Transformer for Whole Slide Image Based Cancer Survival Prediction</title>
				<funder ref="#_JkKaP9q">
					<orgName type="full">Ministry of Science and Technology of the People&apos;s Republic of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Wentai</forename><surname>Hou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Information and Communication Engineering at School of Informatics</orgName>
								<orgName type="institution">Xiamen University</orgName>
								<address>
									<settlement>Xiamen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yan</forename><surname>He</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science at School of Informatics</orgName>
								<orgName type="institution">Xiamen University</orgName>
								<address>
									<settlement>Xiamen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bingjian</forename><surname>Yao</surname></persName>
							<email>yaobingjian@stu.xmu.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science at School of Informatics</orgName>
								<orgName type="institution">Xiamen University</orgName>
								<address>
									<settlement>Xiamen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lequan</forename><surname>Yu</surname></persName>
							<email>lqyu@hku.hk</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Statistics and Actuarial Science</orgName>
								<orgName type="institution">The University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong SAR</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rongshan</forename><surname>Yu</surname></persName>
							<email>rsyu@xmu.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science at School of Informatics</orgName>
								<orgName type="institution">Xiamen University</orgName>
								<address>
									<settlement>Xiamen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Feng</forename><surname>Gao</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">The Sixth Affiliated Hospital</orgName>
								<orgName type="institution" key="instit2">Sun Yat-sen University</orgName>
								<address>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Liansheng</forename><surname>Wang</surname></persName>
							<email>lswang@xmu.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science at School of Informatics</orgName>
								<orgName type="institution">Xiamen University</orgName>
								<address>
									<settlement>Xiamen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multi-scope Analysis Driven Hierarchical Graph Transformer for Whole Slide Image Based Cancer Survival Prediction</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="745" to="754"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">53A14C919A86D42344D970994BB30CF2</idno>
					<idno type="DOI">10.1007/978-3-031-43987-2_72</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-01T10:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Whole slide image</term>
					<term>Survival prediction</term>
					<term>Contextual interaction</term>
					<term>Graph neural network</term>
					<term>Transformer</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Cancer survival prediction requires considering not only the biological morphology but also the contextual interactions of tumor and surrounding tissues. The major limitation of previous learning frameworks for whole slide image (WSI) based survival prediction is that the contextual interactions of pathological components (e.g., tumor, stroma, lymphocyte, etc.) lack sufficient representation and quantification. In this paper, we proposed a multi-scope analysis driven Hierarchical Graph Transformer (HGT) to overcome this limitation. Specifically, we first utilize a multi-scope analysis strategy, which leverages an in-slide superpixel and a cross-slide clustering, to mine the spatial and semantic priors of WSIs. Furthermore, based on the extracted spatial prior, a hierarchical graph convolutional network is proposed to progressively learn the topological features of the variant microenvironments ranging from patchlevel to tissue-level. In addition, guided by the identified semantic prior, tissue-level features are further aggregated to represent the meaningful pathological components, whose contextual interactions are established and quantified by the designed Transformer-based prediction head. We evaluated the proposed framework on our collected Colorectal Cancer (CRC) cohort and two public cancer cohorts from the TCGA project, i.e., Liver Hepatocellular Carcinoma (LIHC) and Kidney Clear Cell Carcinoma (KIRC). Experimental results demonstrate that our proposed method yields superior performance and richer interpretability compared to the state-of-the-art approaches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The ability to predict the future risk of patients with cancer can significantly assist clinical management decisions, such as treatment and monitoring <ref type="bibr" target="#b20">[21]</ref>. Generally, pathologists need to manually assess the pathological images obtained by whole-slide scanning systems for clinical decision-making, e.g., cancer diagnosis and prognosis <ref type="bibr" target="#b19">[20]</ref>. However, due to the complex morphology and structure of human tissues and the continuum of histologic features phenotyped across the diagnostic spectrum, it is a tedious and time-consuming task to manually assess the whole slide image (WSI) <ref type="bibr" target="#b11">[12]</ref>. Moreover, unlike cancer diagnosis and subtyping tasks, survival prediction is a future state prediction task with higher difficulty. Therefore, automated WSI analysis method for survival prediction task is highly demanded yet challenging in clinical practice.</p><p>Over the years, deep learning has greatly promoted the development of computational pathology, including WSI analysis <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b23">24]</ref>. Due to the huge size, WSIs are generally cropped to numerous patches with a fixed size and encoded to patch features by a CNN encoder (e.g., Imagenet pretrained ResNet50 <ref type="bibr" target="#b10">[11]</ref>) for further analysis. The attention-dominated learning frameworks (e.g., ABMIL <ref type="bibr" target="#b12">[13]</ref>, CLAM <ref type="bibr" target="#b17">[18]</ref>, DSMIL <ref type="bibr" target="#b15">[16]</ref>, TransMIL <ref type="bibr" target="#b18">[19]</ref>, SCL-WC <ref type="bibr" target="#b24">[25]</ref>, HIPT <ref type="bibr" target="#b3">[4]</ref>, NAGCN <ref type="bibr" target="#b8">[9]</ref>) mainly aim to find the key instances (e.g., patches and tissues) for WSI representation and decision-making, which prefers the needle-ina-haystack tasks, e.g., cancer diagnosis, cancer subtyping, etc. To handle cancer survival prediction, some researchers integrated some attribute priors into the network design <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b25">26]</ref>. For example, Patch-GCN <ref type="bibr" target="#b4">[5]</ref> treated the WSI as point cloud data, and the patch-level adjacent relationship of WSI is learned by a graph convolutional network (GCN). However, the fixed-size patches cropped from WSI mainly contain single-level biological entities (e.g., cells), resulting in limited structural information. DeepAttnMISL <ref type="bibr" target="#b25">[26]</ref> extracted the phenotype patterns of the patient via a clustering algorithm, which provides meaningful medical prior to guide the aggregation of patch features. However, this cluster analysis strategy only focuses on a single sample, which cannot describe the whole picture of the pathological components specific to the cancer type. Additionally, existing learning frameworks often ignore the capture of contextual interactions of pathological components (e.g., tumor, stroma, lymphocyte, etc.), which is considered as important evidence for cancer survival prediction tasks <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b5">6]</ref>. Therefore, WSI-based cancer survival prediction still remains a challenging task.</p><p>In summary, to better capture the prognosis-related information in WSI, two technical key points should be fully investigated: <ref type="bibr" target="#b0">(1)</ref> an analysis strategy to mine more comprehensive and in-depth prior of WSIs, and (2) a promising learning network to explore the contextual interactions of pathological components. To this end, this paper presents a novel multi-scope analysis driven learning framework, called Hierarchical Graph Transformer (HGT), to pertinently resolve the above technical key points for more reliable and interpretable W. Hou and Y. He-Contributed equally to this work. WSI-based survival prediction. First, to mine more comprehensive and in-depth attribute priors of WSI, we propose a multi-scope analysis strategy consisting of in-slide superpixels and cross-slide clustering, which can not only extract the spatial prior but also identify the semantic prior of WSIs. Second, to explore the contextual interactions of pathological components, we design a novel learning network, i.e., HGT, which consists of a hierarchical graph convolution layer and a Transformer-based prediction head. Specifically, based on the extracted spatial topology, the hierarchical graph convolution layer in HGT progressively aggregate the patch-level features to the tissue-level features, so as to learn the topological features of variant microenvironments ranging from fine-grained (e.g., cell) to coarse-grained (e.g., necrosis, epithelium, etc.). Then, under the guidance of the identified semantic prior, the tissue-level features are further sorted and assigned to form the feature embedding of pathological components. Furthermore, the contextual interactions of pathological components are captured with the Transformer-based prediction head, leading to reliable survival prediction and richer interpretability. Extensive experiments on three cancer cohorts (i.e., CRC, TCGA-LIHC and TCGA-KIRC) demonstrates the effectiveness and interpretability of our framework. Our codes are available at https:// github.com/Baeksweety/superpixel transformer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>Figure <ref type="figure" target="#fig_0">1</ref> illustrates the pipeline of the proposed framework. Due to the huge size, WSIs are generally cropped to numerous patches with a fixed size (i.e., 256×256) and encoded to patch features V patch ∈ R n×d in the embedding space D by a CNN encoder (i.e., ImageNet pretrained ResNet50 <ref type="bibr" target="#b10">[11]</ref>) for further analysis, where n is the number of patches, d = 1024 is the feature dimension. The goal of WSI-based cancer survival prediction is to learn the feature embedding of V in a supervised manner and output the survival risk O ∈ R 1 .</p><p>However, conventional patch-level analysis cannot model complex pathological patterns (e.g., tumor lymphocyte infiltration, immune cell composition, etc.), resulting in limited cancer survival prediction performance. To this end, we proposed a novel learning network, i.e., HGT, which utilized the spatial and semantic priors mined by a multi-scope analysis strategy (i.e., in-slide superpixel and cross-slide clustering) to represent and capture the contextual interaction of pathological components. Our framework consists two modules: a hierarchical graph convolutional network and a Transformer-based prediction head.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Hierarchical Graph Convolutional Network</head><p>Unlike cancer diagnosis and subtyping, cancer survival prediction is a quite more challenging task, as it is a future event prediction task which needs to consider complex pathological structures <ref type="bibr" target="#b19">[20]</ref>. However, the conventional patch-level analysis is difficult to meet this requirement. Therefore, it is essential to extract and combine higher-level topology information for better WSI representation. In-slide Superpixel. As shown in Fig . <ref type="figure" target="#fig_0">1</ref>, we first employ a Simple Linear Iterative Clustering (SLIC) <ref type="bibr" target="#b1">[2]</ref> algorithm to detect non-overlapping homogeneous tissues of the foreground of WSI at a low magnification, which can be served as the spatial prior to mine the hierarchical topology of WSI. Intuitively, the cropped patches and segmented tissues in a WSI can be considered as hierarchical entities ranging from fine-grained level (e.g., cell) to coarse-grained level (e.g., necrosis, epithelium, etc.). Based on the in-slide superpixel, the tissue adjacency matrix E tissue ∈ R m×m can be obtained, where m denote the number of superpixels. Then, the patches in each superpixel are further connected in an 8-adjacent manner, thus generating patch adjacency matrix E patch ∈ R n×n . The spatial assignment matrix between cropped patches and segmented tissues is denoted as</p><formula xml:id="formula_0">A spa ∈ R n×m .</formula><p>Patch Graph Convolutional Layer. Based on the spatial topology extracted by in-slide superpixel, the patch graph convolutional layer (Patch GCL) is designed to learn the feature of the fine-grained microenvironment (e.g., cell) through the message passing between adjacent patches, which can be represented as:</p><formula xml:id="formula_1">V patch = σ(GraphConv(V patch , E patch )),<label>(1)</label></formula><p>where σ(•) denotes the activation function, such as ReLU. GraphConv denotes the graph convolutional operation, e.g., GCNConv <ref type="bibr" target="#b14">[15]</ref>, GraphSAGE <ref type="bibr" target="#b9">[10]</ref>, etc.</p><p>Tissue Graph Convolutional Layer. Third, based on the spatial assignment matrix A spa , the learned patch-level features can be aggregated to the tissue-level features which contain the information of necrosis, epithelium, etc.</p><formula xml:id="formula_2">V tissue = [A spa ] T V patch ,<label>(2)</label></formula><p>where [•] T denote the matrix transpose operation. The tissue graph convolutional layer (Tissue GCL) is further designed to learn the feature of this coarse-grained microenvironment, which can be represented as:</p><formula xml:id="formula_3">V tissue = σ(GraphConv(V tissue , E tissue )).<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Transformer-Based Prediction Head</head><p>Clinical studies have shown that cancer survival prediction requires considering not only the biological morphology but also the contextual interactions of tumor and surrounding tissues <ref type="bibr" target="#b0">[1]</ref>. However, existing analysis frameworks for WSI often ignore the capture of contextual interactions of pathological components (e.g., tumor, stroma, lymphocyte, etc.), resulting in limited performance and interpretability. Therefore, it is necessary to determine the feature embedding of pathological components and investigate their contextual interactions for more reliable predictions.</p><p>Cross-Slide Clustering. As shown in Fig. <ref type="figure" target="#fig_0">1</ref>, we perform the k-means algorithm on the encoded patch features of all training WSIs to generate k pathological components P ∈ R k×d in the embedding space D. P represents different pathological properties specific to the cancer type. Formally, the feature embedding of each tissue in space D is defined as the mean feature embeddings of the patches within the tissue. And then, the pathological component label of each tissue is determined as the component closest to the Euclidean distance of the tissue in space D. The semantic assignment matrix between segmented tissues and pathological components is denoted as A sem ∈ R m×k .</p><p>Transformer Architecture. Under the guidance of the semantic prior identified by cross-slide clustering, the learned tissue features V tissue can be further aggregated, forming a series meaningful component embeddings P specific to the cancer type.</p><formula xml:id="formula_4">P = [A sem ] T V tissue . (<label>4</label></formula><formula xml:id="formula_5">)</formula><p>Then we employed a Transformer <ref type="bibr" target="#b21">[22]</ref> architecture to mine the contextual interactions of P and output the predicted survival risk. As shown in Fig. <ref type="figure" target="#fig_0">1</ref>, P is concatenated with an extra learnable regression token R and attached with positional embeddings E P os , which are processed by:</p><formula xml:id="formula_6">P out = MLP(LN(MHSA(LN([R; P ] + E P os )))). (<label>5</label></formula><formula xml:id="formula_7">)</formula><p>where P out is the output of Transformer, MHSA is the Multi-Headed Self-Attention <ref type="bibr" target="#b21">[22]</ref>, LN is Layer Normalization and MLP is Multilayer Perceptron. Finally, the representation of the regression token at the output layer of the Transformer, i.e., [P out ] 0 , is served as the predicted survival risk O.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Loss Function and Training Strategy.</head><p>For the network training, Cox loss <ref type="bibr" target="#b25">[26]</ref> is adopted for the survival prediction task, which is defined as:</p><formula xml:id="formula_8">L Cox = B i=1 δ i ⎛ ⎝ -O(i) + log j:tj &gt;=ti exp (O(j)) ⎞ ⎠ , (<label>6</label></formula><formula xml:id="formula_9">)</formula><p>where δ i denote the censorship of i-th patient, O(i) and O(j) denote the survival output of i-th and j-th patient in a batch, respectively. GPUs. Our graph convolutional model is implemented by Pytorch Geometric <ref type="bibr" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>The initial number of superpixels of SLIC algorithm is set to {600, 700, 600}, and the number of clusters of k-means algorithm is set to {16, 16, 16} for CRC, TCGA-LIHC and TCGA-KICA cohorts. The non linearity of GCN is ReLU. The number of Transformer heads is 8, and the attention scores of all heads are averaged to produce the heatmap of contextual interactions. HGT is trained with a mini-batch size of 16, and a learning rate of 1e -5 with Adam optimizer for 30 epochs.</p><p>Evaluation Metric. The concordance index (CI) <ref type="bibr" target="#b22">[23]</ref> is used to measure the fraction of all pairs of patients whose survival risks are correctly ordered. CI ranges from 0 to 1, where a larger CI indicates better performance. Moreover, to evaluate the ability of patients stratification, the Kaplan-Meier (KM) analysis is used <ref type="bibr" target="#b22">[23]</ref>. In this study, we conduct a 5-fold evaluation procedure with 5 runs to evaluate the survival prediction performance for each method. The result of mean ± std is reported.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Comparative Results</head><p>We compared seven state-of-the-art methods (SOTAs), i.e., DeepSets <ref type="bibr" target="#b26">[27]</ref>, ABMIL <ref type="bibr" target="#b12">[13]</ref>, DeepAttnMISL <ref type="bibr" target="#b25">[26]</ref>, CLAM <ref type="bibr" target="#b17">[18]</ref>, DSMIL <ref type="bibr" target="#b15">[16]</ref>, PatchGCN <ref type="bibr" target="#b4">[5]</ref>, and TransMIL <ref type="bibr" target="#b18">[19]</ref>. We also compared three baselines of our method, i.e., w/o Patch GCL, w/o Tissue GCL and w/o Transformer. For fair comparison, same CNN extractor (i.e. ImageNet pretrained Resnet50 <ref type="bibr" target="#b10">[11]</ref>), and survival prediction loss (i.e. Cox loss <ref type="bibr" target="#b25">[26]</ref>) is adopt for all methods. Table <ref type="table" target="#tab_1">1</ref> and Fig. <ref type="figure">2</ref> show the results of CI and KM-analysis of each method, respectively. Generally, most MIL methods, i.e., DeepSets, ABMIL, DSMIL, TransMIL mainly focus on a few key instances for prediction, but they do not have significant advantages in cancer prognosis. Furthermore, due to the large size of CRC dataset and relatively high model complexity, Patch-GCN and TransMIL encountered a memory overflow when processing the CRC dataset, which limits their clinical application. DeepAttnMISL has a certain semantic perception ability for patch, which achieves better performance in LIHC cohort. PatchGCN is capable to capture the local contextual interactions between patch, which also achieves satisfied performance in KIRC cohort. As our method has potential to explore the contextual interactions of pathological components, which more in line with the thinking of pathologists for cancer prognosis. Our method achieves higher CI and relatively low P-Value (&lt; 0.05) of KM analysis on both three cancer cohorts, which consistently outperform the SOTAs and baselines. In addition, the feature aggregation of the lower levels (i.e., patch and tissue) are guided by the priors, and the MHSA is only executed on pathological components, resulting in high efficiency even on the CRC dataset.  <ref type="bibr" target="#b12">[13]</ref> 0.580 ± 0.005 0.634 ± 0.005 0.617 ± 0.094 DeepAttnMISL <ref type="bibr" target="#b25">[26]</ref> 0.570 ± 0.001 0.644 ± 0.009 0.584 ± 0.019 CLAM <ref type="bibr" target="#b17">[18]</ref> 0.575 ± 0.010 0.641 ± 0.002 0.635 ± 0.006 DSMIL <ref type="bibr" target="#b15">[16]</ref> 0.550 ± 0.016 0.626 ± 0.005 0.603 ± 0.022 PatchGCN <ref type="bibr">[</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Interpretability of the Proposed Framework</head><p>We selected the CRC dataset for further interpretable analysis, as it is one of the leading causes of mortality in industrialized countries, and its prognosis-related factors have been widely studied <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b7">8]</ref>. We trained an encoded feature based classification model (i.e., a MLP) on a open-source colorectal cancer dataset (i.e., NCT-CRC-HE-100K <ref type="bibr" target="#b13">[14]</ref>), which is annotated with 9 classes, including: adipose tissue (ADI); background (BACK); debris (DEB); lymphocytes (LYM); mucus (MUC); muscle (MUS); normal colon mucosa (NORM); stroma (STR); tumor (TUM). The trained classification model can be used to determine the biological semantics of the pathological components extracted by our model with a major voting rule. Figure <ref type="figure">3</ref> shows the original image, spatial topology, proportion and biological meaning of pathological components, and its contextual interactions of a typical case from CRC cohort. It can be seen that the interaction between component 1 (TUM) and component 9 (STR) has gained the highest attention of the network, which is consistent with the existing knowledge <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b7">8]</ref>. Moreover, there is also concentration of interaction in some other interactions, which may potentially imply some new biomarkers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we propose a novel learning framework, i.e., multi-scope analysis driven HGT, to effectively represent and capture the contextual interaction of pathological components for improving the effectiveness and interpretability of WSI-based cancer survival prediction. Experimental results on three clinical cancer cohorts demonstrated our model achieves better performance and richer interpretability over the existing models. In the future, we will evaluate our framework on more tasks and further statistically analyze the interpretability of our model to find more pathological biomarkers related to cancer prognosis.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Overview of the proposed multi-scope analysis (i.e., in-slide superpixel and cross-slide clustering) driven Hierarchical Graph Transformer (HGT). Note that not all nodes and adjacent relationships are shown for visual clarity.</figDesc><graphic coords="4,44,79,53,78,334,57,171,94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .Fig. 3 .</head><label>23</label><figDesc>Fig. 2. KM analysis of second best SOTA method and our proposed framework for different datasets. All the patients across the five test folds are combined and analysis here. For each cohort, patients were stratified into high-risk (red curves) and low-risk (green curves) groups by the median score output by predictive models. (Color figure online)</figDesc><graphic coords="8,43,29,452,21,337,33,123,58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Experimental results of CI. Results not significantly worse than the best (P-Value &gt; 0.05, Two-sample t-test) are shown in bold. The second best results of SOTA methods are underlined. "-" denotes that the algorithm cannot be executed in this cohort due to memory overflow.</figDesc><table><row><cell>Type</cell><cell>Method</cell><cell>CRC</cell><cell>TCGA-LIHC TCGA-KIRC</cell></row><row><cell>SOTAs</cell><cell>DeepSets [27]</cell><cell cols="2">0.504 ± 0.004 0.511 ± 0.011 0.483 ± 0.033</cell></row><row><cell></cell><cell>ABMIL</cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement. This work was supported by <rs type="funder">Ministry of Science and Technology of the People's Republic of China</rs> (<rs type="grantNumber">2021ZD0201900</rs>)(2021ZD0201903).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_JkKaP9q">
					<idno type="grant-number">2021ZD0201900</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Geospatial immune variability illuminates differential evolution of lung adenocarcinoma</title>
		<author>
			<persName><forename type="first">K</forename><surname>Abduljabbar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1054" to="1062" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">SLIC superpixels compared to state-of-the-art superpixel methods</title>
		<author>
			<persName><forename type="first">R</forename><surname>Achanta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shaji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lucchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Süsstrunk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2274" to="2282" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Development and validation of a weakly supervised deep learning framework to predict the status of molecular pathways and key mutations in colorectal cancer from routine histology images: a retrospective study</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bilal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lancet Digit. Health</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="763" to="e772" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Scaling vision transformers to gigapixel images via hierarchical self-supervised learning</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="16144" to="16155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Whole slide images are 2D point clouds: context-aware survival prediction using patch-based graph convolutional networks</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87237-3_33</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87237-333" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12908</biblScope>
			<biblScope unit="page" from="339" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Human-interpretable image features derived from densely mapped cancer pathology slides predict diverse molecular phenotypes</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Diao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1613</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fast graph representation learning with PyTorch geometric</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Lenssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR Workshop on Representation Learning on Graphs and Manifolds</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multistain deep learning for prediction of prognosis and therapy response in colorectal cancer</title>
		<author>
			<persName><forename type="first">S</forename><surname>Foersch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Node-aligned graph convolutional network for whole-slide image representation and classification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Guan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="18813" to="18823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1024" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">H 2 -mil: exploring hierarchical representation with heterogeneous multiple instance learning for whole slide image analysis</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="933" to="941" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Attention-based deep multiple instance learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ilse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tomczak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2127" to="2136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Predicting survival from colorectal cancer histology slides using deep learning: a retrospective multicenter study</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Kather</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Med</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1002730</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=SJU4ayYgl" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Dual-stream multiple instance learning network for whole slide image classification with self-supervised contrastive learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Eliceiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference On Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference On Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="14318" to="14328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">DSCA: a dual-stream network with crossattention on whole-slide image pyramids for cancer prognosis</title>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">227</biblScope>
			<biblScope unit="page">120280</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Data-efficient and weakly supervised computational pathology on whole-slide images</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Barbieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mahmood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="555" to="570" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">TransMIL: Transformer based correlated multiple instance learning for whole slide image classification</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural. Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="2136" to="2147" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Multidisciplinary Treatment of Colorectal Cancer</title>
		<author>
			<persName><forename type="first">W</forename><surname>Sterlacci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vieth</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-58846-5_28</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-58846-528" />
		<editor>Baatrup, G.</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="263" to="277" />
			<pubPlace>Cham</pubPlace>
		</imprint>
	</monogr>
	<note>Early colorectal cancer</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Global cancer statistics 2020: GLOBOCAN estimates of incidence and mortality worldwide for 36 cancers in 185 countries</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sung</surname></persName>
		</author>
		<idno type="DOI">10.3322/caac.21660</idno>
		<ptr target="https://doi.org/10.3322/caac.21660" />
	</analytic>
	<monogr>
		<title level="j">CA Cancer J. Clin</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="209" to="249" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Machine learning for survival analysis: a survey</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Reddy</surname></persName>
		</author>
		<idno type="DOI">10.1145/3214306</idno>
		<ptr target="https://doi.org/10.1145/3214306" />
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">3214306</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">RetCCL: clustering-guided contrastive learning for whole-slide image retrieval</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page">102645</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">SCL-WC: cross-slide contrastive learning for weakly-supervised whole-slide image classification</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Sixth Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Whole slide images based cancer survival prediction using attention guided deep multiple instance learning networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jonnagaddala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hawkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page">101789</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep sets</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kottur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ravanbakhsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Poczos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
