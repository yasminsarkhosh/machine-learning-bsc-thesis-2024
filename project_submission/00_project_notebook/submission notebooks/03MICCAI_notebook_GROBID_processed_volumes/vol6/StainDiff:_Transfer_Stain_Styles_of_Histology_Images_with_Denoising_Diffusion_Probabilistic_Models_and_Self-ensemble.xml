<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">StainDiff: Transfer Stain Styles of Histology Images with Denoising Diffusion Probabilistic Models and Self-ensemble</title>
				<funder ref="#_UxG4td2">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_Axd9zfz">
					<orgName type="full">Natural Science Foundation of Shanghai</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yiqing</forename><surname>Shen</surname></persName>
							<idno type="ORCID">0000-0001-7866-3339</idno>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Johns Hopkins University</orgName>
								<address>
									<settlement>Baltimore</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Jing</forename><surname>Ke</surname></persName>
							<email>kejing@sjtu.edu.cn</email>
							<idno type="ORCID">0000-0001-7459-257X</idno>
							<affiliation key="aff1">
								<orgName type="department">School of Electronic Information and Electrical Engineering</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">University of New South Wales</orgName>
								<address>
									<settlement>Kensingt</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">StainDiff: Transfer Stain Styles of Histology Images with Denoising Diffusion Probabilistic Models and Self-ensemble</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="549" to="559"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">838CE1EE1A6C22427DB148C2A70D5746</idno>
					<idno type="DOI">10.1007/978-3-031-43987-2_53</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-01T10:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Diffusion Probabilistic Model â€¢ Histology Stain Transfer</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The commonly presented histology stain variation may moderately obstruct the diagnosis of human experts, but can considerably downgrade the reliability of deep learning models in various diagnostic tasks. Many stain style transfer methods have been proposed to eliminate the variance of stain styles across different medical institutions or even different batches. However, existing solutions are confined to Generative Adversarial Networks (GANs), AutoEncoders (AEs), or their variants, and often fell into the shortcomings of mode collapses or posterior mismatching issues. In this paper, we make the first attempt at a Diffusion Probabilistic Model to cope with the indispensable stain style transfer in histology image context, called StainDiff. Specifically, our diffusion framework enables learning from unpaired images by proposing a novel cycle-consistent constraint, whereas existing diffusion models are restricted to image generation or fully supervised pixel-to-pixel translation. Moreover, given the stochastic nature of StainDiff that multiple transferred results can be generated from one input histology image, we further boost and stabilize the performance by the proposal of a novel self-ensemble scheme. Our model can avoid the challenging issues in mainstream networks, such as the mode collapses in GANs or alignment between posterior distributions in AEs. In conclusion, StainDiff suffices to increase the stain style transfer quality, where the training is straightforward and the model is simplified for real-world clinical deployment.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Staining is a vital process in preparing tissue samples for histology studies. Specifically, with dyes such as Hematoxylin and Eosin, transparent tissue elements can be transformed into distinguishable features <ref type="bibr" target="#b0">[1]</ref>. However, stain styles can vary significantly across different pathology labs or institutions. These variations can be due to the difference in staining materials, protocols, or processes among different pathologists or digital scanners <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b22">23]</ref>. Yet, the stain variations can cause inconsistencies between human domain experts <ref type="bibr" target="#b10">[11]</ref>; and also hinder the performance of computer-aided diagnostic (CAD) systems <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7]</ref>. Moreover, experiments have shown that stain variations can lead to a significant decrease in the accuracy and reproducibility of deep learning algorithms in histology analysis. Consequently, it is crucial to minimize staining variations to ensure reliable, consistent, and accurate CAD systems.</p><p>To address the issue of stain variations between different domains, stain style transfer has been proposed. While the conventional color matching <ref type="bibr" target="#b21">[22]</ref> and stain separation methods <ref type="bibr" target="#b18">[19]</ref> used to be popular; learning-based approaches have become increasingly dominant, because they eliminate the need for challenging manual selection of the template images. For example, Stain-to-Stain Translation (STST) <ref type="bibr" target="#b24">[25]</ref> approaches stain style transfer within a fully supervised 'pix2pix' framework <ref type="bibr" target="#b11">[12]</ref>. Another approach, called StainGAN <ref type="bibr" target="#b25">[26]</ref>, improves on STST by tailoring a CycleGAN <ref type="bibr" target="#b33">[34]</ref> to get rid of the dependence on learning from paired histology images and enable an unsupervised learning manner. These methods have shown promising results in reducing staining variations. Existing learning-based methods for stain style transfer are primarily confined to Generative Adversarial Networks (GANs) <ref type="bibr" target="#b5">[6]</ref> and AutoEncoder (AE) <ref type="bibr" target="#b1">[2]</ref>, as depicted in Fig. <ref type="figure" target="#fig_0">1</ref>(a) and (b) respectively. However, GAN approaches and AE suffer from the training of extra discriminators and challenging alignment of the posterior distributions, respectively <ref type="bibr" target="#b26">[27]</ref>. In contrast, diffusion models, such as the prevalent denoising diffusion probabilistic model (DDPM) <ref type="bibr" target="#b8">[9]</ref>, have emerged as an alternative approach that can achieve competitive performance in various image-related tasks, such as image generation, inpainting, super-resolution, and etc <ref type="bibr" target="#b2">[3]</ref>. Importantly, diffusion models offer several advantages over GANs and AEs, including tractable probabilistic parameterization, stable training procedures, and theoretical guarantees <ref type="bibr" target="#b2">[3]</ref>. Additionally, they can avoid some of the challenges encountered by GANs and AEs, such as the alignment of posterior distributions or training extra discriminators, leading to a simpler model and training process. However, the applicability of diffusion models to histology stain style transfer remains unexplored. While the current diffusion models focus on image synthesis <ref type="bibr" target="#b8">[9]</ref> or supervised image-to-image transaction <ref type="bibr" target="#b23">[24]</ref>, they are not applicable to our circumstance, as obtaining paired histology slides with different stain styles is not feasible in real clinical practice <ref type="bibr" target="#b26">[27]</ref>. Therefore, we design an innovative cycle-consistent diffusion model that allows the transfer of representations between latent spaces at different time steps with the same morphological structure preserved in an unsupervised manner, as shown in Fig. <ref type="figure" target="#fig_0">1(c)</ref>.</p><p>The major contributions are three-fold, summarized as follows.</p><p>(1) We propose StainDiff, which is the first attempt at a pure denoising diffusion probabilistic model for stain transfer. More innovatively, unlike existing diffusion models, StainDiff is capable of learning from unpaired histology images, making it a more flexible and practical solution. The model is superior to GAN-based methods as the training of additional discriminators is free, and also spares for the difficulty in the alignment of posterior probabilities in AE-based approaches.</p><p>(2) We also propose a self-ensemble scheme to further improve and stabilize the style transfer performance in StainDiff. This scheme utilizes the stochastic property of the diffusion model to generate multiple slightly different outputs from one input at the inference stage. (3) A broad range of histology tasks, such as stain normalization between multiple clients, can be conveniently achieved with minor adjustment to the loss in StainDiff.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>Overview. The goal of this work is to design a diffusion model <ref type="bibr" target="#b8">[9]</ref> to transfer the stain style between two domains, i.e., X A , X B . However, the traditional training paradigm of conditional DDPMs with paired images (x A 0 , x B 0 ) âˆˆ X A Ã— X B is not feasible, as they are unavailable in the context of histology. To overcome this limitation, we design an innovative diffusion framework for stain style transfer, named StainDiff, which leverages the success of CycleGAN <ref type="bibr" target="#b33">[34]</ref> and Style-GAN <ref type="bibr" target="#b25">[26]</ref> and thus can be trained in an unsupervised manner with a novel cycle-consistency constraint. Specifically, StainDiff comprises two forward processes that perturb the histology image of two stain style domains to noise respectively, and two corresponding reverse processes that attempt to reconstruct noise back to original images from the perturbed ones. The overall training process is depicted in Fig. <ref type="figure" target="#fig_1">2</ref>. Forward Process. Parameterized by the Markov chain, the forward process in StainDiff follows the vanilla DDPM by perturbing the histology images gradually with Gaussian noise, until all structures and morphological context information are lost. Formally, given a histology image x A 0 with respect to the stain style domain A, a transition kernel q progressively generates a sequence of</p><formula xml:id="formula_0">T latent variables x A 1 , x A 2 , â€¢ â€¢ â€¢ , x A</formula><p>T thorough the following equation:</p><formula xml:id="formula_1">q(x A t |x A t-1 ) = N (x A t ; 1 -Î² t x A t-1 , Î² t I),<label>(1)</label></formula><p>where N (â€¢) denotes the Gaussian distribution, I is the identity matrix. The hyper-parameters Î² t s follow a linear rule as defined in DDPM <ref type="bibr" target="#b8">[9]</ref> to guarantee ) learns to reverse the Eq. ( <ref type="formula" target="#formula_1">1</ref>) and generate images characterized by stain style A and B respectively, by gradually removing the noise initialized from Gaussian prior. To ensure conservative outputs <ref type="bibr" target="#b23">[24]</ref>, L1-norm denoising objective L d <ref type="bibr" target="#b3">[4]</ref> is leveraged to train the denoising networks in the transition kernels. Due to the absence of pixel-topixel paired histology of both stain styles, it is infeasible to learn the interplay between them in a supervised manner as in most previous works. Consequently, a pair of auxiliary transform networks</p><formula xml:id="formula_2">q(x A T ) = q(x A T |x A 0 )q(x A 0 )dx A 0 â‰ˆ N (x</formula><formula xml:id="formula_3">G A : x B t â†’ x A t and G B : x A t â†’ x B t</formula><p>are designed to learn the transfer between the latent variables across the two domains in an unsupervised fashion, using a novel cycle-consistency constraint. Formally, this constraint ensures that two cycles as depicted in Fig. <ref type="figure" target="#fig_1">2</ref>(b), derive an identity mapping, i.e.,</p><formula xml:id="formula_4">x A t+1 = q â€¢ G A â€¢ p Î¸ B â€¢ G B (x A t+1 ), x B t+1 = q â€¢ G B â€¢ p Î¸ A â€¢ G A (x B t+1 ),<label>(2)</label></formula><p>where â€¢ denotes the composition of operations. It follows the cycle-consistency constraint formulated by</p><formula xml:id="formula_5">L c = E t,x A 0 xA t+1 -x A t+1 + E t,x B 0 xB t+1 -x B t+1 , (<label>3</label></formula><formula xml:id="formula_6">)</formula><p>where xA t+1 and xB t+1 are defined by Eq. ( <ref type="formula" target="#formula_4">2</ref>); E denotes the expectation; â€¢ is the L1-norm. Finally, the overall loss function is L = L d + Î³L c , balanced by the coefficient Î³. Inference Process and Self-ensemble. We describe the inference stage of StainDiff by transferring the histology images from stain style A to B; while the inverse, namely from B to A, is similar. Given a histology image input x A 0 characterized by stain style A, we begin by perturbing it s steps with Eq. (1) to derive x A s . Choosing the optimal value for s is important, as a large s (e.g., s = T ) leads to the loss of the contextual and structural information; while a small valued s (e.g., s = 1) fails to inject sufficient noise for StainDiff to transfer style. An ideal range for s is a small subset from [1, T ] that is centered by xB 0,i . The graphical model for the inference process and the proposed self-ensemble scheme are summarized in Fig. <ref type="figure" target="#fig_2">3</ref>.</p><p>Extension to Stain Normalization. The stain transfer primarily addresses the domain gap between two stain styles, which is mathematically formulated as a one-to-one mapping. Meanwhile, in some clinical settings, multiple institutions or hospitals are involved, where stain normalization is usually employed for multiple stain styles to one style alignment. The proposed symmetric StainDiff structure can be easily adapted to support stain normalization, with minimal change to the loss in Eq. ( <ref type="formula" target="#formula_5">3</ref>). Concretely, we assume that domain A comprises multiple stain styles and domain B identifies the targeted stain style. By discarding the second term in Eq. ( <ref type="formula" target="#formula_5">3</ref>), StainDiff becomes asymmetric and focuses specifically on the transfer from domain A to B. This modification allows us to use StainDiff for stain normalization without any other adjustments to the inference process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets. Evaluations of StainDiff are conducted on two datasets. (1)</head><p>Dataset-A: MITOS-ATYPIA 14 Challenge<ref type="foot" target="#foot_0">1</ref> . This dataset aims to measure the style transfer performance on 284 histology frames. Each slide is digitized by two different scanners, resulting in stain style variations. For a fair comparison, we follow the settings in previous work <ref type="bibr" target="#b25">[26]</ref> by using 10,000 unpaired patches randomly cropped from the first 184 slides of both scanners as the training set. Meanwhile, 500 paired patches are generated from the remaining 100 slides as the test set, where we use Pearson correlation coefficient (PC), Structural Similarity index (SSIM) <ref type="bibr" target="#b30">[31]</ref> and Feature Similarity Index for Image Quality Assessment (FSIM) <ref type="bibr" target="#b32">[33]</ref> as the evaluation metrics. ( <ref type="formula" target="#formula_4">2</ref>) Dataset-B: The Cancer Genome Atlas (TCGA). This dataset evaluates the performance of stain normalization quantified by the downstream nine-category tissue structure classification accuracy <ref type="bibr" target="#b26">[27]</ref>. Domain A contains histology of multiple stain styles, which are collected from 186 WSIs from TCGA-COAD and NCT-CRC-HE-100K <ref type="bibr" target="#b13">[14]</ref>; and domain B is the target style, curated from 25 WSIs in CRC-VAL-HE-7K <ref type="bibr" target="#b13">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementations.</head><p>All experiments are implemented in Python 3.8.13 with Pytorch 1.12.1 on two NVIDIA GeForce RTX 3090 GPU cards with 24GiB of memory each in parallel. We leverage the Adam optimizer with a learning rate of 2 Ã— 10 -4 , and a batch size of 4. The learning scheme follows previous work <ref type="bibr" target="#b17">[18]</ref>, where the training process continues for 100 epochs if the overall loss did not decrease to the average loss of the previous 20 epochs. For StainDiff, we set the diffusion time T = 1000, the balancing coefficient Î³ = 1, and ensemble number m = 10. All experiments are repeated for 7 runs with different fixed random seeds i.e., {0, 1, 2, 3, 4, 5, 6}; and metrics are reported in the form of meanÂ±standard deviation. Ablation Study. Table <ref type="table">1</ref> and 2 show that incorporating a self-ensemble scheme can both boost the performance of StainDiff, and bring down the variations, demonstrating its effectiveness in stabilizing the stain transfer and normalization. To further investigate the effect of ensemble number m, we conduct ablation on Dataset-A. Experimentally, the FSIM when m = 1, 5, 10, 15, 20, 50 are 0.742, 0.749, 0.753, 0.756, 0.759, 0.759 respectively. While a slight performance gain can be achieved with higher m values than 10, the ensemble becomes more timeconsuming, as the cost time is linear to m. It implies an optimal m should be selected as a trade-off between the performance and computational time, such as 10 in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we propose StainDiff, a denoising diffusion model for histological stain style transfer, hence a model can get rid of the challenging issues in mainstream networks, such as the mode collapses in GANs or alignment between posterior distributions in AEs. Innovatively, by imposing a cycle-consistent constraint imposed on latent spaces, StainDiff enables learning from unpaired histology images, making it widely applicable to real clinical settings. One future work will explore efficient sampling diffusion models, e.g., DDIM <ref type="bibr" target="#b27">[28]</ref>, to address the long sampling time issue as inherited from DDPM. Another direction is to investigate other formulations of the diffusion model in the context of stain transfer, such as score-based or score-SDE diffusion models <ref type="bibr" target="#b31">[32]</ref>. These extensions will fully expand the scope of our work, hence further advancing towards a comprehensive solution of stain style transfer in histology images.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Different generative model based stain style transfer solutions. (a) AutoEncoder (AE). (b) GAN. (c) Our proposed diffusion based StainDiff.</figDesc><graphic coords="2,56,79,364,01,310,87,95,23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. (a) The directed graphical model for the training process of the proposed StainDiff. It comprises two diffusion paths, that each learns the histology image generation with respect to one stain style domain. The interplay between two domains is learned by a paired auxiliary transform network GA and GB through a cycleconsistency constraint. (b) We specify the consistency cycles to impose the regularization.</figDesc><graphic coords="4,59,79,54,32,304,90,119,38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The directed graphical model for the inference stage with self-ensemble scheme of the StainDiff.</figDesc><graphic coords="5,98,97,248,69,254,35,141,85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Table 1 .Fig. 4 .</head><label>14</label><figDesc>Fig. 4. Visualization of the progressive stain style transfer process in StainDiff.</figDesc><graphic coords="7,55,98,283,43,340,18,151,00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Reverse Process and Cycle-Consistency Constraint.</head><label></label><figDesc>The reverse process in StainDiff optimizes two conditional diffusion models, namely p(x A |x B ) and p(x B |x A ), to transfer the stain style between two domains A and B. Concretely, two learnable transition kernels p Î¸ A (x A t |x A t+1 ) and p Î¸ B (x B t |x B t+1</figDesc><table /><note><p><p><p><p><p>A T ; 0, I). Identically, we can progress the latent variables</p>x B 1 , x B 2 , â€¢ â€¢ â€¢ , x B</p>T for the histology image x B 0 from the stain style domain B in the same fashion as Eq. (</p>1</p>).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>1  2 T . Consequently, in this work, we fix s in the range of [S 1 , S 2 ] with S 1 = 2 5 T and S values of s result in a slight difference in the transferred output. We exploit this property and propose a novel self-ensemble method that can implicitly generate an ensemble of transferred output without the need to train extra models. Specifically, we repeat the above process for m times with different s i.e., s 1 , â€¢ â€¢ â€¢ , s m âˆˆ [S 1 , S 2 ], and come to m outputs xB 0,i with i = 1, â€¢ â€¢ â€¢ , m.</figDesc><table><row><cell>The self-ensemble transferred output is then given by xB 0,SE =</cell><cell>m i=1</cell></row></table><note><p>2 = 3 5 T . Afterwards, the latent variable x A s is transferred into the corresponding latent space with respect to stain style B with auxiliary transform network G B , which gives us xB s = G B (x A s ). Next, we use the p-sample [9] iteratively to denoise the xB s and obtain the transferred image xB 0 . As the sampling is a stochastic process, different</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Comparison of the downstream classification task w.r.t. accuracy (%). 'w/o SE' denotes excluding the self-ensemble scheme from the inference stage. The superiority of our diffusion model to GANs and AEs in histology stain style transfer is quantitatively reflected in Table1. Specifically, on Dataset-A, StainDiff can surpass its counterparts with a large margin regarding all three metrics. Notably, StainDiff achieves the highest SSIM of 0.717 and FSIM of 0.753, which improves the state-of-the-art CL-StainGAN<ref type="bibr" target="#b14">[15]</ref> by 0.016 and 0.019 respectively, without reliance on timecostly self-supervised pre-training. Moreover, the statistical significance of our performance boost is validated by the p-values that are consistently smaller than 0.005, as computed from the Wilcoxon signed-rank test. The progressive transfer process of StainDiff over time is visualized in Fig.4. Table2presents the comparison results of the downstream classification task, where the histology images in Dataset-B are normalized using different methods. The table clearly shows that StainDiff outperforms all the other methods and achieves the highest test accuracy across all five network architectures<ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b28">29]</ref>. Consequently, it yields the superiority of StainDiff in terms of stain normalization is model-agnostic.</figDesc><table><row><cell>Method</cell><cell>ResNet-18</cell><cell>ResNet-50</cell><cell cols="2">DenseNet-121 DenseNet-169 EfficientNet</cell></row><row><cell>Reinhard [22]</cell><cell cols="3">92.10Â±0.58 93.11Â±0.39 92.04Â±0.74</cell><cell>91.17Â±0.33</cell><cell>92.48Â±0.99</cell></row><row><cell>Macenko [19]</cell><cell cols="3">90.35Â±1.20 90.55Â±1.43 90.47Â±1.53</cell><cell>89.99Â±1.04</cell><cell>91.24Â±0.85</cell></row><row><cell>Khan [17]</cell><cell cols="3">91.89Â±0.83 92.04Â±0.63 92.22Â±0.75</cell><cell>92.54Â±0.55</cell><cell>93.04Â±0.81</cell></row><row><cell>Vahadane [30]</cell><cell cols="3">92.87Â±0.35 93.01Â±0.42 92.94Â±0.50</cell><cell>93.31Â±0.52</cell><cell>93.51Â±0.39</cell></row><row><cell>StaNoSa [13]</cell><cell cols="3">93.25Â±0.78 93.88Â±0.21 94.41Â±0.78</cell><cell>94.60Â±0.99</cell><cell>94.48Â±0.53</cell></row><row><cell>StainGAN [26]</cell><cell cols="3">93.98Â±0.28 94.21Â±0.47 93.89Â±0.21</cell><cell>93.99Â±0.36</cell><cell>94.52Â±0.32</cell></row><row><cell>Harshal [21]</cell><cell cols="3">94.17Â±0.72 94.58Â±0.54 93.85Â±0.80</cell><cell>93.96Â±0.65</cell><cell>95.03Â±0.99</cell></row><row><cell>MWB [20]</cell><cell cols="3">94.56Â±0.93 95.15Â±0.79 94.14Â±0.68</cell><cell>94.32Â±0.39</cell><cell>95.25Â±0.55</cell></row><row><cell cols="4">CL-StainGAN [15] 96.22Â±0.73 96.89Â±0.38 95.98Â±0.58</cell><cell>96.04Â±0.29</cell><cell>96.49Â±0.57</cell></row><row><cell cols="4">StainDiff (w/o SE) 96.79Â±0.23 97.54Â±0.47 96.01Â±0.30</cell><cell>97.00Â±0.21</cell><cell>97.32Â±0.35</cell></row><row><cell>StainDiff (Full)</cell><cell cols="3">97.48Â±0.10 98.12Â±0.09 96.98Â±0.07</cell><cell>97.93Â±0.11</cell><cell>98.42Â±0.08</cell></row><row><cell cols="4">Evaluations on Style Transfer. Evaluations on Stain Normalization.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://mitos-atypia-14.grand-challenge.org.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement. J. Ke was supported by <rs type="funder">National Natural Science Foundation of China</rs> (Grant No. <rs type="grantNumber">62102247</rs>) and <rs type="funder">Natural Science Foundation of Shanghai</rs> (No. <rs type="grantNumber">23ZR1430700</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_UxG4td2">
					<idno type="grant-number">62102247</idno>
				</org>
				<org type="funding" xml:id="_Axd9zfz">
					<idno type="grant-number">23ZR1430700</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">An introduction to routine and special staining</title>
		<author>
			<persName><forename type="first">J</forename><surname>Anderson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011-08-18">2011. 18 Aug 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Greedy layer-wise training of deep networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Cao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.02646</idno>
		<title level="m">A survey on generative diffusion model</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Wavegrad: estimating gradients for waveform generation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The importance of stain normalization in colorectal tissue classification with convolutional networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Ciompi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 14th International Symposium on Biomedical Imaging</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017. 2017. 2017</date>
			<biblScope unit="page" from="160" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Generative adversarial networks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="139" to="144" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Automated classification for breast cancer histopathology images: is stain normalization important?</title>
		<author>
			<persName><forename type="first">V</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhavsar</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-67543-5_16</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-67543-516" />
	</analytic>
	<monogr>
		<title level="m">CARE/CLIP -2017</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Cardoso</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">10550</biblScope>
			<biblScope unit="page" from="160" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Denoising diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6840" to="6851" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="4700" to="4708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Observer variation in histopathological diagnosis and grading of cervical intraepithelial neoplasia</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Ismail</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brit. Med. J</title>
		<imprint>
			<biblScope unit="volume">298</biblScope>
			<biblScope unit="issue">6675</biblScope>
			<biblScope unit="page" from="707" to="710" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Image-to-image translation with conditional adversarial networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1125" to="1134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Stain normalization using sparse autoencoders (stanosa): application to digital pathology</title>
		<author>
			<persName><forename type="first">A</forename><surname>Janowczyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Med. Imaging Graph</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="50" to="61" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">100,000 histological images of human colorectal cancer and healthy tissue</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Kather</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Halama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Marx</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Zenodo</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Contrastive learning based stain normalization across multiple tumor in histopathology</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87237-3_55</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87237-355" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12908</biblScope>
			<biblScope unit="page" from="571" to="580" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Multiple-datasets and multiple-label based color normalization in histopathology with cgan</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital Pathology</title>
		<imprint>
			<biblScope unit="volume">11603</biblScope>
			<biblScope unit="page" from="263" to="268" />
			<date type="published" when="2021">2021. 2021</date>
			<publisher>SPIE</publisher>
		</imprint>
	</monogr>
	<note>Medical Imaging</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A nonlinear mapping approach to stain normalization in digital histopathology images using image-specific color deconvolution</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Khan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1729" to="1738" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Conversion between ct and mri images using diffusion and score-matching models</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.12104</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A method for normalizing histology slides for quantitative analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Macenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on Biomedical Imaging: From Nano to Macro</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009. 2009</date>
			<biblScope unit="page" from="1107" to="1110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Multimarginal wasserstein barycenter for stain normalization and augmentation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nadeem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hollmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tannenbaum</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59722-1_35</idno>
		<idno>978-3-030-59722-1 35</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12265</biblScope>
			<biblScope unit="page" from="362" to="371" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Histopathological stain transfer using style transfer network with adversarial loss</title>
		<author>
			<persName><forename type="first">H</forename><surname>Nishar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chavanke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Singhal</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59722-1_32</idno>
		<idno>978-3-030-59722-1 32</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12265</biblScope>
			<biblScope unit="page" from="330" to="340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Color transfer between images</title>
		<author>
			<persName><forename type="first">E</forename><surname>Reinhard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Graph. Appl</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="34" to="41" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Rubin&apos;s pathology: clinicopathologic foundations of medicine</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Strayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rubin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Lippincott Williams &amp; Wilkins</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Palette: image-to-image diffusion models</title>
		<author>
			<persName><forename type="first">C</forename><surname>Saharia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH 2022 Conference Proceedings</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Pix2pix-based stain-to-stain translation: a solution for robust stain normalization in histopathology images analysis</title>
		<author>
			<persName><forename type="first">P</forename><surname>Salehi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chalechale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 International Conference on Machine Vision and Image Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Staingan: stain style transfer for digital histological images</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Shaban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="953" to="956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A federated learning system for histopathology image analysis with an orchestral stain-normalization gan</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="1969" to="1981" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.02502</idno>
		<title level="m">Denoising diffusion implicit models</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Efficientnet: rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6105" to="6114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Structure-preserving color normalization and sparse stain separation for histological images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vahadane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1962" to="1971" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Image quality assessment: from error visibility to structural similarity</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="600" to="612" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.00796</idno>
		<title level="m">Diffusion models: a comprehensive survey of methods and applications</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Fsim: a feature similarity index for image quality assessment</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2378" to="2386" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Unpaired image-to-image translation using cycle-consistent adversarial networks</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2223" to="2232" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
