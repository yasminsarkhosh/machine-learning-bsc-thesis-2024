<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Polar Eyeball Shape Net for 3D Posterior Ocular Shape Representation</title>
				<funder ref="#_XDmkJug">
					<orgName type="full">Agency for Science, Technology and Research (A*STAR) Advanced Manufacturing and Engineering</orgName>
					<orgName type="abbreviated">AME</orgName>
				</funder>
				<funder>
					<orgName type="full">Central Research Fund</orgName>
					<orgName type="abbreviated">CRF</orgName>
				</funder>
				<funder ref="#_JbPzdgU #_jSBnRka">
					<orgName type="full">General Program of National Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_t8vMmCS #_7k99dvr">
					<orgName type="full">Shenzhen Stable Support Plan Program</orgName>
				</funder>
				<funder ref="#_8atzSY5">
					<orgName type="full">Guangdong Basic and Applied Basic Research Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jiaqi</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Hong Kong</orgName>
								<address>
									<settlement>Pokfulam, Hong Kong</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution" key="instit1">Research Institute of Trustworthy Autonomous Systems</orgName>
								<orgName type="institution" key="instit2">Southern University of Science and Technology</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yan</forename><surname>Hu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution" key="instit1">Research Institute of Trustworthy Autonomous Systems</orgName>
								<orgName type="institution" key="instit2">Southern University of Science and Technology</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Hong Kong</orgName>
								<address>
									<settlement>Pokfulam, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ting</forename><surname>Meng</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Ophthalmology</orgName>
								<orgName type="institution">Shenzhen People&apos;s Hospital</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lihui</forename><surname>Wang</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Institute of Semiconductors</orgName>
								<orgName type="institution">Guangdong Academy of Sciences</orgName>
								<address>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Huazhu</forename><surname>Fu</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Agency for Science, Technology and Research</orgName>
								<orgName type="institution">Institute of High Performance Computing</orgName>
								<address>
									<country>Singapore, Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mingming</forename><surname>Yang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Ophthalmology</orgName>
								<orgName type="institution">Shenzhen People&apos;s Hospital</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Jiang</forename><surname>Liu</surname></persName>
							<email>liuj@sustech.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution" key="instit1">Research Institute of Trustworthy Autonomous Systems</orgName>
								<orgName type="institution" key="instit2">Southern University of Science and Technology</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Polar Eyeball Shape Net for 3D Posterior Ocular Shape Representation</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="180" to="190"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">9E900FC6313C70DC5A0933E7F341F245</idno>
					<idno type="DOI">10.1007/978-3-031-43987-2_18</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-01T10:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Posterior eyeball shape</term>
					<term>3D reconstruction</term>
					<term>Polar transformation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The shape of the posterior eyeball is a crucial factor in many clinical applications, such as myopia prevention, surgical planning, and disease screening. However, current shape representations are limited by their low resolution or small field of view, providing insufficient information for surgeons to make accurate decisions. This paper proposes a novel task of reconstructing complete 3D posterior shapes based on small-FOV OCT images and introduces a novel Posterior Eyeball Shape Network (PESNet) to accomplish this task. The proposed PESNet is designed with dual branches that incorporate anatomical information of the eyeball as guidance. To capture more detailed information, we introduce a Polar Voxelization Block (PVB) that transfers sparse input point clouds to a dense representation. Furthermore, we propose a Radius-wise Fusion Block (RFB) that fuses correlative hierarchical features from the two branches. Our qualitative results indicate that PESNet provides a wellrepresented complete posterior eyeball shape with a chamfer distance of 9.52, SSIM of 0.78, and Density of 0.013 on the self-made posterior ocular shape dataset. We also demonstrate the effectiveness of our model by testing it on patients' data. Overall, our proposed PESNet offers a significant improvement over existing methods in accurately reconstructing the complete 3D posterior eyeball shape. This achievement has important implications for clinical applications.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Posterior eyeball shape (PES) is related to various ophthalmic diseases, such as glaucoma, high myopia, and retinoblastoma <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b24">25]</ref>. Ophthalmologists often define the retinal pigment epithelium (RPE) layer represented as the shape of the posterior eyeball <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b18">19]</ref>. The changes in PES are helpful for surgeons to further specifically optimize the treatments of myopia, surgical planning, and diagnosis result <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b19">20]</ref>. For example, the PES can assist ophthalmologists to determine the expansion types of myopia, 6 types inferred to <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b21">22]</ref>, in order to prevent further increase of myopic degree at an early stage <ref type="bibr" target="#b4">[5]</ref>. Besides, the precise PES facilitates surgeons to estimate the cut length of the rectus during surgical planning, optimizing operative outcomes and avoiding refractive error after strabismus surgery <ref type="bibr" target="#b13">[14]</ref>. Moreover, posterior eyeball shape is a sensitive indicator to facilitate fundus disease screening, such as glaucoma and tilted disc syndrome (TDS) <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b11">12]</ref>.</p><p>In ophthalmic clinics, existing representations of posterior eyeball shape are mainly based on two medical imaging devices, including Magnetic Resonance Imaging (MRI) and Optical Coherence Tomography (OCT). MRI cannot become the preferred screening device in ophthalmic clinics due to its being expensive and time-consuming. Even most ophthalmic hospitals do not equip MR devices. Moreover, the resolution of ocular MRI is 0.416 × 0.416 × 0.399 mm 2 , while the depth of the retina is around 250 µm <ref type="bibr" target="#b0">[1]</ref>. Thus, limited by the resolution of MRI, surgeons only infer the approximate posterior shape from the outer edge of the sclera or inner edge of the retina, as the retinal layers cannot be distinguished from MR images <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b25">26]</ref>. Most common OCT devices applied in eye hospitals can provide clear retinal layer imaging, but their field of view (FOV) is very limited, ranging from 4.5*4.5 to 13*13 mm, which nearly equals 2%-19% area of the entire posterior eyeball. Unlike OCT volume correlation tasks that are impacted by flatten distortion of A-scans <ref type="bibr" target="#b12">[13]</ref>, some researchers proposed to roughly infer shape changes of the posterior eyeball based on the simplified geometric shapes or non-quantitative topography in 2-dimensional (2D) obtained from retinal landmarks or RPE segmented lines <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b26">27]</ref>. However, such 2D expressions can not assist surgeons in making decisions. Therefore, we propose a novel task constructing a 3-dimensional (3D) posterior eyeball shape based on small-FOV OCT images.</p><p>As far as we know, there is no existing work on 3D eyeball reconstruction just using local OCT images. We refer several 3D reconstruction methods using natural images. For example, NeRF and Multi-View Stereo <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref> need multiview images, which are difficult to obtain in the ophthalmic field. The point cloud completion task <ref type="bibr" target="#b27">[28]</ref> recovers local details based on global information, which is different from our target. As the limited FOV of common retinal imaging devices makes capturing global eyeballs difficult, we reconstruct global shapes from local OCT information. Moreover, the curved shape of the eyeball determines that its imaging information is often concentrated in a local area of the image where most of the pixels are empty, resulting in sparse information. Directly downsampling as in most existing point-based algorithms often leads to surface details lost limited by the number of input points. Therefore, to address the above problems, we first propose to adopt a standard posterior eyeball template to provide medical prior knowledge for the construction; then we propose coordinate transformation to handle the sparse representations of retinal in OCT images in this paper. Our main contributions are summarized as follows: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>The overview of our proposed Posterior Eyeball Shape Network (PESNet) is shown in Fig. <ref type="figure" target="#fig_0">1</ref>(a). The subarea point cloud (size N 1 * 3) from local OCT images and the template point cloud (size N 2 * 3) from the template OCT images are taken as inputs. N 1 and N 2 are points number. The inputs are transformed to the polar grid with size (B, C, R, U, V ) by our proposed Polar Voxelization Block (PVB), respectively. Then two polar grids are input into the dual-branch architecture of PESNet, whose detail is shown in Fig. <ref type="figure" target="#fig_0">1(b</ref>). After a 2D ocular surface map (OSM) is predicted from the network, we convert it to a 3D point cloud as our predicted posterior eyeball shape using inverse polar transformation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Dual-Branch Architecture of PESNet</head><p>The input point cloud is derived from limited FOV OCT images, and the structures between the local area and the complete posterior eyeball are totally different. Thus, considering the structural regularity of ocular shape in OCT images, we propose to aggregate structural prior knowledge for the reconstruction. As shown in Fig. <ref type="figure" target="#fig_0">1</ref>(b), the proposed PESNet is constructed by the Shape regression branch (S-branch) and Anatomical prior branch (A-branch) with the same RBs, whose details are shown in Fig. <ref type="figure" target="#fig_0">1(c</ref>). Inspired by ResNet <ref type="bibr" target="#b8">[9]</ref>, we propose the RBs to gradually extract hierarchical features from the R-channel of input grids with the reduction of the R-dimension. The last layer of RB1 to RB4 uses anisotropic 3D convolution layer with (2 × 3 × 3) kernel, (2, 3, 3) stride, and (0, 1, 1) padding. Features from every RB in S-branch are fused with corresponding features from A-branch by our RFB. For RB5, the last layer adopts a maxpooling layer by setting kernel as (4, 1, 1) to reduce the R-dimension to 1 for reducing the computational cost. Then (1 × 1 × 1) convolution layers are adopted to further reduce the feature channels from 128 to 32. Finally, a 2D OSM with size (B, 1, 1, N, N) is predicted from the dual-branch architecture (B = batch size, N = 180 in this paper) by the last RFB5. For the loss of our PESNet, we adopt the combination of smooth L1 loss L1 smooth and perceptual loss L percep <ref type="bibr" target="#b10">[11]</ref> as Loss = αL1 s + L perc , and smooth L1 loss is defined as:</p><formula xml:id="formula_0">L1 s = 1 UV N -1 u=0 N -1 v=0 (O(u, v) -Ô(u, v)) 2 * 0.5, if|O(u, v) -Ô(u, v)| &lt; 1 |O(u, v) -Ô(u, v)| -0.5, otherwise<label>(1)</label></formula><p>where O(u, v) and Ô(u, v) denote the predicted and ground truth (GT) OSM, respectively. The (u, v) and U, V represent the positional index and size of OSM.</p><p>The α denotes a manual set weight value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Polar Voxelization Block and R-Wise Fusion Block</head><p>Polar Voxelization Block (PVB). The curve shape of the eyeball determines the sparse layer labels of OCT in cartesian coordinates. Sparse convolution significantly increases memory. Inspired by the shape of the eyeball, we propose to use polar transformation to obtain the dense representation of the input. Due to the hierarchical and regular distribution of RPE points in polar grid, the 3D grid is parameterized into a 2D OSM by anisotropic convolution. Therefore, we design the PVB to perform polar transformation and voxelization jointly for two input point clouds P s and P t and output two 3D grids of voxels G s and G t .</p><p>Given the center coordinate c = (c x , c y , c z ) of the top en-face slice of OCT images as polar origin, the transformation between the cartesian coordinate (x, y, z) and the polar coordinates (r, u, v) can be expressed as Eq. 2. Besides, given a polar point set P : {(r i , u i , v i )|i = 1, . . . , n} and a 3D polar grid G(r, u, v) ∈ {0, 1}, the voxelization process of PVB is defined in Eq. 3:</p><formula xml:id="formula_1">⎧ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎩ r = (x -c x ) 2 + (y -c y ) 2 + (z -c z ) 2 u = arctan z-cz √ (x-cx) 2 +(y-cy) 2 + π 2 v = arctan y-cy x-cx + π 2 and ⎧ ⎨ ⎩ r ∈ [0, 370) u ∈ [0, π) v ∈ [0, π)<label>(2)</label></formula><formula xml:id="formula_2">G R×U ×V round ri φ , round ui×180 π , round vi×180 π = 1 (<label>3</label></formula><formula xml:id="formula_3">)</formula><formula xml:id="formula_4">OSM U ×V (u i , v i ) = G(r, u i , v i ), i ∈ [0, 180)<label>(4)</label></formula><p>where u,v and r are the elevation angle, azimuth angle, and radius in polar coordinates. The extra π 2 term is added to make the angle range correspond to the integer index of height and width of OSM. Besides, R,U ,V denote the depth, height, and width of the 3D grid (R = 64, U and V = 180 in our paper), which make grid G hold enough resolution with acceptable memory overhand. In addition, φ is a manual set number to control the depth-dimension of G. Since we choose the center of the top en-face slice as the origin, the RPE voxels distribute in layers along the R-axis of G. Therefore, we can compress the 3D polar grid G(r, u, v) into a 2D OSM along the R-axis of grid using Eq. 4, where OSM (u, v) denotes the pixel value at position (u, v), which represents the radius from the polar origin to an ocular surface point along the elevation and azimuth angles specified by index (u, v). The entire posterior eyeball shape can be reconstructed once given OSM and the center coordinate C. This representation of ocular shape is not only much denser than a conventional voxel-based grid (370 * 300 * 256 in our paper) in cartesian coordinates but also maintains more points and spatial structure than common point-based methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R-wise Fusion Block (RFB)</head><p>The conventional feature fusion methods (denoted as F in Table <ref type="table" target="#tab_1">1</ref>) often concatenate two feature volumes along a certain axis and simultaneously compute the correlation among R-, U-, and V-dimensions with convolution. They do not consider the feature distribution in the dimension. However, for our task, the hierarchical features distributed in the same channel along R-axis have a higher relevance. Separately computing relevance between features inside the R channel is able to enhance the structure guidance of prior information. Thus, we propose RFBs to fuse the feature volumes from S-branch and A-branch. As shown in Fig. <ref type="figure" target="#fig_0">1(c</ref>), the first four blocks (RFB1 to RFB4) first concatenate two feature volumes along the R-dimension and then rearrange the channel order in the R-dimension of combined volume to place the correlated features together. Finally, the relevant hierarchical features from S-and A-branches are fused by a convolution layer with (2 × 3 × 3) kernel and (2, 1, 1) stride followed by Batch-Norm and ReLU layers. The output volume of RFB has the same size as each input one. It's worth noting that the last RFB rearranges the order in featureinstead of R-dimension, since R-dimension is already equal to 1, and the last activation layer is Sigmoid to ensure the intensity values of output OSM ranging in [0, 1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>Dataset: We build a Posterior Ocular Shape (POS) dataset based on Ultrawidefield (24 × 20 mm 2 ) swept-source OCT device (BM-400K BMizar; TowardPi Medical Technology). The POS dataset contains 55 eyes of thirty-three healthy participants. Simulating local regions captured by common OCT devices, we sample five subareas from every ultra-widefield sample. Both subarea point clouds and ground truth of OSM are derived from segmented RPE label images from all samples (more details are in supplementary). The POS dataset is randomly split into training, validation, and test sets with 70%, 20% and 10%, respectively. Referring to <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b23">24]</ref>, the template is obtained by averaging 7 highquality GT OSMs without scanning defects and gaps from the training set and then perform Gaussian smoothing to reduce textual details until it does not change further. Finally, the averaged OSM is converted into the template point cloud by inverse polar transformation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation Details:</head><p>The intensity values of all GT OSMs are normalized from [0, 63] to [0, 1] for loss calculation. We use unified center coordinates as the polar origin for polar transformation since all OCT samples are aligned to the macular fovea during acquisition. Since the background pixels in predicted OSM are hardly equal to 0, which cause many noise points in reconstructed point cloud, only intensity values that are not equal to OSM <ref type="bibr" target="#b4">(5,</ref><ref type="bibr" target="#b4">5)</ref> are converted to points. During training, we set α in the loss function as a linear decay weight after the first 50 epochs, adam optimizer with a base learning rate of 0.001, and a batch size of 10 for 300 epochs. The model achieving the lowest loss on the validation set is saved for evaluation on the testing set. We implemented our PESNet using the PyTorch framework and trained on 2 A100 GPUs.</p><p>Evaluation Metrics: Since our proposal employs 2D OSM regression in polar coordinates to achieve 3D reconstruction in cartesian coordinates, we evaluate its performance using both 2D and 3D metrics. Specifically, we use Chamfer Distance (CD) to measure the mean distance between predicted point clouds and its GT point cloud, and Structural Similarity Index Measure (SSIM) as 2D metrics to evaluate the OSM regression performance. Additionally, we introduce point density (Density) as an extra metric to evaluate the number ratio of total points between predicted and GT point clouds, defined as Density = |1 -N pred /N GT |, where N pred is the number of predicted point clouds, N GT is the number of GT point clouds. The lower Density, the fewer defects in the valid region of OSMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method Comparison and Ablation Study:</head><p>The effectiveness of the key components of PESNet is investigated through a comparison and ablation study, as presented in Fig. <ref type="figure" target="#fig_1">2</ref> (other samples are shown in supplementary) and Table <ref type="table" target="#tab_1">1</ref>. To provide a benchmark, we re-implemented PointNet, a pioneering pointbased method (details in the supplementary material). Compared to PointNet (Fig. <ref type="figure" target="#fig_1">2(a)</ref>), the visual results in OSM and a reconstructed point cloud of 1-branch or 2-branch networks show more details in the valid region and reasonable shape, with better evaluation metrics, as hierarchical structure information is preserved in the dense representation by PVB. Compared to that by 1-branch (Fig. <ref type="figure" target="#fig_1">2(b)</ref>), the visual results by 2-branch networks are much closer to the posterior eyeball shape, as the adopted prior knowledge provides structure assistance for reconstruction. As shown in Fig. <ref type="figure" target="#fig_1">2</ref>, after incorporating RFB and unshare-weight, the 2D and 3D figures express the curve structure of the eyeball with more information, especially the macular and disc (in the bottom of the eyeball) are back to    the right position. The visualization shows that multi-state fusion can extract more structural details in R-dimension from multi-scale feature volumes of two branches, which can improve the scope and textual details of the valid regions in OSMs. As shown in Table <ref type="table" target="#tab_1">1</ref>, our 2-branch variant exceeds 1-branch ones by 3.43, 0.19, 0.57 at CD, SSIM, and Density after adding A-branch, which further proves that prior knowledge guides to reconstruct a more complete valid region. If incorporating the RFB, the 3D shape (expressed by CD) can be closer to GT.</p><p>In our PESNet, we adopt unshare-weight for two branches, which produces the best metrics in the last row. Therefore, our proposed algorithm reconstructs the eyeball close to GT considering the specificity of the eyeball.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation Study About Loss Function:</head><p>We compare different loss functions applied in our task, and the results as shown in Table <ref type="table" target="#tab_2">2</ref>. The results reveal two trends: 1): L1 smooth can ensure the correct optimization direction, impelling the OSMs area other than the background close 1, but we find it cannot effectively learn the accurate scope of OSMs from experiments. 2): L perc can achieve suboptimal results, but is too unstable to keep the right direction of optimization, which highly increase training time and decrease reproducibility. For other combinations, their OSMs show either wrong optimization direction or limited scope of valid regions which are also revealed by metrics. Therefore, our loss function combine the advantages of L1 smooth and L perc , and the extra α makes L perc further descent stably. Our combination obtains the best metrics and visualization results, proving that it is the most suitable choice for our task.</p><p>Validation on Disease Sample: Although our POS dataset only contains the data of healthy eyeballs, we still test our PESNet on two disease cases: one is high myopia and the other is Diabetic Macular Edema. As shown in Fig. <ref type="figure" target="#fig_2">3</ref>, although the template lack of priors from the disease eyeball, the range of pixel value and scope of region are close to GT. The result shows the potential of our PESNet to handle the posterior shape reconstruction for the diseased eyeballs. We are collecting more patients' data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this study, we introduced the task of posterior eyeball shape 3D reconstruction using small-FOV OCT images, and proposed a Posterior Eyeball Shape Network (PESNet) that utilizes polar coordinates to perform 2D ocular surface map (OSM) regression. Our experiments on a self-made posterior ocular shape dataset demonstrate the feasibility of this novel task and confirm that PESNet is capable of leveraging local and anatomical prior information to reconstruct the complete posterior eyeball shape. Additionally, our validation experiment with disease data highlights the potential of PESNet for reconstructing the eyeballs of patients with ophthalmic diseases.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The proposed PESNet for posterior eyeball reconstruction based on the local point cloud derived from OCT images. (a) The whole pipeline of the reconstruction process. (b) Dual-branch structure of PESNet, including an anatomical prior branch to extract structure features from the ocular template. (c) The key components of PESNet include R-wise Fusion Block (RFB), Residual-Block (RB), and used layers.</figDesc><graphic coords="4,61,98,54,53,328,36,193,18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The visualization results of the comparison. The main-and sub-images show the reconstructed point clouds in cartesian coordinate and its corresponding output OSMs, respectively, where F 5 and F 1-5 denote common late-and multi-state fusion, RF B 5 and RF B 1-5 denotes late-and multi-state RFB, and * means unshare-weight.</figDesc><graphic coords="7,43,29,411,20,337,36,131,80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The test results with the data from a high myopia case and a diabetic macular edema (DME) case, the shape point cloud and its OSM of GT are shown on the left side, and those of predicted results are shown on the right side.</figDesc><graphic coords="8,56,97,197,72,338,08,72,76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Method comparison and ablation studies on Posterior Ocular Shape Dataset.</figDesc><table><row><cell>Method</cell><cell cols="2">CD ↓ SSIM ↑ Density ↓</cell></row><row><cell>PointNet [21]</cell><cell>59.81 0.433</cell><cell>0.669</cell></row><row><cell>1-branch</cell><cell>13.57 0.310</cell><cell>0.714</cell></row><row><cell>2-branch F 5</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Ablation study about loss functions.</figDesc><table><row><cell>Loss function</cell><cell cols="2">CD ↓ SSIM ↑ Density ↓</cell></row><row><cell>L1 smooth</cell><cell>65.49 0.287</cell><cell>0.446</cell></row><row><cell>Lperc</cell><cell>9.95 0.729</cell><cell>0.085</cell></row><row><cell>L1 smooth + Lssim</cell><cell>49.14 0.259</cell><cell>1.615</cell></row><row><cell>L1 smooth + L grad</cell><cell>56.04 0.305</cell><cell>0.544</cell></row><row><cell>L1 grad + Lperc</cell><cell>38.47 0.239</cell><cell>0.099</cell></row><row><cell cols="2">L1 smooth + Lssim + L grad + Lperc 74.65 0.161</cell><cell>0.824</cell></row><row><cell>L1 smooth + Lperc</cell><cell cols="2">9.52 0.781 0.013</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgment. This work was supported in part by <rs type="funder">General Program of National Natural Science Foundation of China</rs> (<rs type="grantNumber">82272086</rs> and <rs type="grantNumber">82102189</rs>), <rs type="funder">Guangdong Basic and Applied Basic Research Foundation</rs> (<rs type="grantNumber">2021A1515012195</rs>), <rs type="funder">Shenzhen Stable Support Plan Program</rs> (<rs type="grantNumber">20220815111736001</rs> and <rs type="grantNumber">20200925174052004</rs>), and <rs type="funder">Agency for Science, Technology and Research (A*STAR) Advanced Manufacturing and Engineering (AME) Programmatic Fund</rs> (<rs type="grantNumber">A20H4b0141</rs>) and <rs type="funder">Central Research Fund (CRF)</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_JbPzdgU">
					<idno type="grant-number">82272086</idno>
				</org>
				<org type="funding" xml:id="_jSBnRka">
					<idno type="grant-number">82102189</idno>
				</org>
				<org type="funding" xml:id="_8atzSY5">
					<idno type="grant-number">2021A1515012195</idno>
				</org>
				<org type="funding" xml:id="_t8vMmCS">
					<idno type="grant-number">20220815111736001</idno>
				</org>
				<org type="funding" xml:id="_7k99dvr">
					<idno type="grant-number">20200925174052004</idno>
				</org>
				<org type="funding" xml:id="_XDmkJug">
					<idno type="grant-number">A20H4b0141</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43987-2 18.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Retinal thickness decreases with age: an oct study</title>
		<author>
			<persName><forename type="first">B</forename><surname>Alamouti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Funk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Br. J. Ophthalmol</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="899" to="901" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Eye shape in emmetropia and myopia</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Atchison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Investig. Ophthalmol. Vis. Sci</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3380" to="3386" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Structural change can be detected in advanced-glaucoma eyes</title>
		<author>
			<persName><forename type="first">A</forename><surname>Belghith</surname></persName>
		</author>
		<idno>OCT511-OCT518</idno>
	</analytic>
	<monogr>
		<title level="j">Investig. Ophthalmol. Vis. Sci</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Vox2cortex: fast explicit reconstruction of cortical surfaces from 3D MRI scans with geometric deep neural networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bongratz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rickmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pölsterl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wachinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="20773" to="20783" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Efficacy in myopia control</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Brennan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">M</forename><surname>Toubouti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Bullimore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Prog. Retin. Eye Res</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page">100923</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multi-channel MRI segmentation of eye structures and tumors using patient-specific features</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ciller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">173900</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Automatic segmentation of the eye in 3D magnetic resonance imaging: a novel statistical shape model for treatment planning of retinoblastoma</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ciller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Radiat. Oncol. Biol. Phys</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="794" to="802" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Three-dimensional eye shape, myopic maculopathy, and visual acuity: the Zhongshan ophthalmic center-brien holden vision institute high myopia cohort study</title>
		<author>
			<persName><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ophthalmology</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="679" to="687" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Quantitative evaluation of changes in eyeball shape in emmetropization and myopic changes based on elliptic fourier descriptors</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ishii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Iwata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Oshika</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Investig. Ophthalmol. Vis. Sci</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="8585" to="8591" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Perceptual losses for real-time style transfer and super-resolution</title>
		<author>
			<persName><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-46475-6_43</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-46475-6" />
	</analytic>
	<monogr>
		<title level="m">ECCV 2016</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Leibe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Matas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Sebe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">9906</biblScope>
			<biblScope unit="page">43</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Three dimensional evaluation of posterior pole and optic nerve head in tilted disc</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y L</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Correction of ocular shape in retinal optical coherence tomography and effect on current clinical measures</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Kuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Ophthalmol</title>
		<imprint>
			<biblScope unit="volume">156</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="304" to="311" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A paired comparison study on refractive changes after strabismus surgery</title>
		<author>
			<persName><forename type="first">A</forename><surname>Leshno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mezad-Koursh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ziv-Baran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Stolovitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Assoc. Pediatr. Ophthalmol. Strabismus</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="460" to="462" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Planemvs: 3D plane reconstruction from multi-view stereo</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="8665" to="8675" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">NERF: representing scenes as neural radiance fields for view synthesis</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mildenhall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tancik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ramamoorthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="99" to="106" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Analysis of fundus shape in highly myopic eyes by using curvature maps constructed from optical coherence tomography</title>
		<author>
			<persName><forename type="first">M</forename><surname>Miyake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">107923</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Topographic analyses of shape of eyes with pathologic myopia by high-resolution three-dimensional magnetic resonance imaging</title>
		<author>
			<persName><forename type="first">M</forename><surname>Moriyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ophthalmology</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1626" to="1637" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Precise retinal shape measurement by alignment error and eye model calibration</title>
		<author>
			<persName><forename type="first">K</forename><surname>Palchunova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Opt. Rev</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="188" to="196" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Morphological change of the posterior pole following the horizontal strabismus surgery with swept source optical coherence tomography</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">J</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Pointnet: deep learning on point sets for 3D classification and segmentation</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="652" to="660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Axial growth and lens power loss at myopia onset in Singaporean children</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rozema</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dankert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Iribarren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lanca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Saw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Investig. Ophthalmol. Vis. Sci</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3091" to="3099" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Three-dimensional modeling of the human eye based on magnetic resonance imaging</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Logan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gilmartin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Investig. Ophthalmol. Vis. Sci</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2272" to="2279" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Anatomical attention guided deep networks for ROI segmentation of brain MR images</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2000" to="2012" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Morphological prediction of glaucoma by quantitative analyses of ocular shape and volume using 3-dimensional T2-weighted MR images</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tatewaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">15148</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Eye shape and retinal shape, and their relation to peripheral refraction</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Verkicharla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mathur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Mallen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Pope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Atchison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ophthalmic Physiol. Opt</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="184" to="199" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Optic nerve head anatomy in myopia and glaucoma, including parapapillary zones alpha, beta, gamma and delta: histology and clinical features</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Panda-Jonas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Jonas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Prog. Retin. Eye Res</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page">100933</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Snowflake point deconvolution for point cloud completion and generation with skip-transformer</title>
		<author>
			<persName><forename type="first">P</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="6320" to="6338" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
