<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Wall Thickness Estimation from Short Axis Ultrasound Images via Temporal Compatible Deformation Learning</title>
				<funder ref="#_FfE9kVD">
					<orgName type="full">Medical Scientific Research Foundation of Guangdong Province</orgName>
				</funder>
				<funder ref="#_T4tZ64f">
					<orgName type="full">Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_ZtYQA8J #_Stp8zvc">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_2D43hrT">
					<orgName type="full">Shenzhen Science and Technology Program</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ang</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Biomedical Engineering</orgName>
								<orgName type="laboratory">National-Regional Key Technology Engineering Laboratory for Medical Ultrasound</orgName>
								<orgName type="institution">Shenzhen University Medical School</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Shenzhen University</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">Medical Ultrasound Image Computing (MUSIC) Laboratory</orgName>
								<orgName type="institution">Shenzhen University</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Marshall Laboratory of Biomedical Engineering</orgName>
								<orgName type="institution" key="instit2">Shenzhen University</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Guijuan</forename><surname>Peng</surname></persName>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Department of Ultrasound</orgName>
								<orgName type="department" key="dep2">The Second Clinical Medical College</orgName>
								<orgName type="department" key="dep3">The First Affiliated Hospital</orgName>
								<orgName type="institution" key="instit1">Shenzhen People&apos;s Hospital</orgName>
								<orgName type="institution" key="instit2">Jinan University</orgName>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">Southern University of Science and Technology)</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jialan</forename><surname>Zheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Biomedical Engineering</orgName>
								<orgName type="laboratory">National-Regional Key Technology Engineering Laboratory for Medical Ultrasound</orgName>
								<orgName type="institution">Shenzhen University Medical School</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Shenzhen University</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">Medical Ultrasound Image Computing (MUSIC) Laboratory</orgName>
								<orgName type="institution">Shenzhen University</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Marshall Laboratory of Biomedical Engineering</orgName>
								<orgName type="institution" key="instit2">Shenzhen University</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jun</forename><surname>Cheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Biomedical Engineering</orgName>
								<orgName type="laboratory">National-Regional Key Technology Engineering Laboratory for Medical Ultrasound</orgName>
								<orgName type="institution">Shenzhen University Medical School</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Shenzhen University</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">Medical Ultrasound Image Computing (MUSIC) Laboratory</orgName>
								<orgName type="institution">Shenzhen University</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Marshall Laboratory of Biomedical Engineering</orgName>
								<orgName type="institution" key="instit2">Shenzhen University</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaohua</forename><surname>Liu</surname></persName>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Department of Ultrasound</orgName>
								<orgName type="department" key="dep2">The Second Clinical Medical College</orgName>
								<orgName type="department" key="dep3">The First Affiliated Hospital</orgName>
								<orgName type="institution" key="instit1">Shenzhen People&apos;s Hospital</orgName>
								<orgName type="institution" key="instit2">Jinan University</orgName>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">Southern University of Science and Technology)</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qian</forename><surname>Liu</surname></persName>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Department of Ultrasound</orgName>
								<orgName type="department" key="dep2">The Second Clinical Medical College</orgName>
								<orgName type="department" key="dep3">The First Affiliated Hospital</orgName>
								<orgName type="institution" key="instit1">Shenzhen People&apos;s Hospital</orgName>
								<orgName type="institution" key="instit2">Jinan University</orgName>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">Southern University of Science and Technology)</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuanyuan</forename><surname>Sheng</surname></persName>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Department of Ultrasound</orgName>
								<orgName type="department" key="dep2">The Second Clinical Medical College</orgName>
								<orgName type="department" key="dep3">The First Affiliated Hospital</orgName>
								<orgName type="institution" key="instit1">Shenzhen People&apos;s Hospital</orgName>
								<orgName type="institution" key="instit2">Jinan University</orgName>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">Southern University of Science and Technology)</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yingqi</forename><surname>Zheng</surname></persName>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Department of Ultrasound</orgName>
								<orgName type="department" key="dep2">The Second Clinical Medical College</orgName>
								<orgName type="department" key="dep3">The First Affiliated Hospital</orgName>
								<orgName type="institution" key="instit1">Shenzhen People&apos;s Hospital</orgName>
								<orgName type="institution" key="instit2">Jinan University</orgName>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">Southern University of Science and Technology)</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yumei</forename><surname>Yang</surname></persName>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Department of Ultrasound</orgName>
								<orgName type="department" key="dep2">The Second Clinical Medical College</orgName>
								<orgName type="department" key="dep3">The First Affiliated Hospital</orgName>
								<orgName type="institution" key="instit1">Shenzhen People&apos;s Hospital</orgName>
								<orgName type="institution" key="instit2">Jinan University</orgName>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">Southern University of Science and Technology)</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jie</forename><surname>Deng</surname></persName>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Department of Ultrasound</orgName>
								<orgName type="department" key="dep2">The Second Clinical Medical College</orgName>
								<orgName type="department" key="dep3">The First Affiliated Hospital</orgName>
								<orgName type="institution" key="instit1">Shenzhen People&apos;s Hospital</orgName>
								<orgName type="institution" key="instit2">Jinan University</orgName>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">Southern University of Science and Technology)</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Yingying</forename><surname>Liu</surname></persName>
							<email>yingyingliu@ext.jnu.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Wufeng</forename><surname>Xue</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Biomedical Engineering</orgName>
								<orgName type="laboratory">National-Regional Key Technology Engineering Laboratory for Medical Ultrasound</orgName>
								<orgName type="institution">Shenzhen University Medical School</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Shenzhen University</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">Medical Ultrasound Image Computing (MUSIC) Laboratory</orgName>
								<orgName type="institution">Shenzhen University</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Marshall Laboratory of Biomedical Engineering</orgName>
								<orgName type="institution" key="instit2">Shenzhen University</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Department of Ultrasound</orgName>
								<orgName type="department" key="dep2">The Second Clinical Medical College</orgName>
								<orgName type="department" key="dep3">The First Affiliated Hospital</orgName>
								<orgName type="institution" key="instit1">Shenzhen People&apos;s Hospital</orgName>
								<orgName type="institution" key="instit2">Jinan University</orgName>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">Southern University of Science and Technology)</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dong</forename><surname>Ni</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Biomedical Engineering</orgName>
								<orgName type="laboratory">National-Regional Key Technology Engineering Laboratory for Medical Ultrasound</orgName>
								<orgName type="institution">Shenzhen University Medical School</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Shenzhen University</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">Medical Ultrasound Image Computing (MUSIC) Laboratory</orgName>
								<orgName type="institution">Shenzhen University</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Marshall Laboratory of Biomedical Engineering</orgName>
								<orgName type="institution" key="instit2">Shenzhen University</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Wall Thickness Estimation from Short Axis Ultrasound Images via Temporal Compatible Deformation Learning</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="213" to="222"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">6A1F9035BC530FEAE9DCF0F8862A07FD</idno>
					<idno type="DOI">10.1007/978-3-031-43987-2_21</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-01T10:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Wall thickness</term>
					<term>Segmentation</term>
					<term>Deformation learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Structural parameters of the heart, such as left ventricular wall thickness (LVWT), have important clinical significance for cardiac disease. In clinical practice, it requires tedious labor work to be obtained manually from ultrasound images and results in large variations between experts. Great challenges exist to automatize this procedure: the myocardium boundary is sensitive to heavy noise and can lead to irregular boundaries; the temporal dynamics in the ultrasound video are not well retained. In this paper, we propose a Temporally Compatible Deformation learning network, named TC-Deformer, to detect the myocardium boundaries and estimate LVWT automatically. Specifically, we first propose a two-stage deformation learning network to estimate the myocardium boundaries by deforming a prior myocardium template. A global affine transformation is first learned to shift and scale the template. Then a dense deformation field is learned to adjust locally the template to match the myocardium boundaries. Second, to make the deformation learning of different frames become compatible in the temporal dynamics, we adopt the mean parameters of affine transformation for all frames and propose a bi-direction deformation learning to guarantee that the deformation fields across the whole sequences can be applied to both the myocardium boundaries and the ultrasound images. Experimental results on an ultrasound dataset of 201 participants show that the proposed method can achieve good boundary detection of basal, middle, and apical myocardium, and lead to accurate estimation of the LVWT, with a mean absolute error of less than 1.00 mm. When compared with</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Cardiovascular disease is a leading cause of death in the world. Accurate quantification of left ventricular wall thicknesses (LVWT) from ultrasound images is among the most clinically important and significant indices for evaluating cardiac function and diagnosis of cardiac diseases <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6]</ref>. Figure <ref type="figure" target="#fig_0">1</ref> illustrates short axis (SAX) ultrasound images of basal, middle, and apical myocardium, with the corresponding LVWTs according to the 16-segment myocardium model. In clinical practice, obtaining reliable clinical information mainly depends on radiologists to manually draw the contours of the endocardium and epicardium of the left ventricle (LV). It is time-consuming and laborious. Efforts have been devoted to the automatic estimation of LVWTs, where great challenge exists. First, the myocardium boundary is sensitive to heavy noise, especially for the apical and basal SAX images, and can lead to irregular boundaries and undermine the estimation of LVWTs. Second, the temporal dynamics in the ultrasound video are difficult to be modeled, leading to prediction results that are not well compatible with the temporal dynamics of the whole video.</p><p>Existing work can be divided into two categories: segmentation-based and direct-regression methods. The direct-regression methods to learn the regress LVWTs from cardiac images directly without identifying the contours first. <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b14">15]</ref> proposed end-to-end cardiac index quantification frameworks based on cascaded convolutional autoencoders and regression networks, using only the values of cardiac indices for supervision. <ref type="bibr" target="#b3">[4]</ref> proposed a two-stage network that learns the LV contours first and then estimates the LV indices with a new network. <ref type="bibr" target="#b15">[16]</ref> proposed a residual recurrent neural network further improves the estimation by modeling the temporal and spatial of the LV myocardium to achieve accurate frame-by-frame LVWT estimation. However, these models lack explicit temporal dynamic modeling of the whole sequence.</p><p>Segmentation-based methods segment the myocardium first and then calculate cardiac parameters. To the best of our knowledge, existing segmentation work mainly focus on apical views to evaluate the ejection fraction, and rare work exists for short-axis views. <ref type="bibr" target="#b13">[14]</ref> utilizes the underlying motion information to assist in improving segmentation results by accurately predicting optical flow fields. <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref> proposed appearance-level and shape-level co-learning (CLAS) to enhance the temporal consistency of the predicted masks across the whole sequence and accuracy. This method effectively improves the accuracy and consistency of myocardial segmentation. <ref type="bibr" target="#b0">[1]</ref> proposed to introduce residual structure into U-net and <ref type="bibr" target="#b2">[3]</ref> proposed a hybrid framework combining a convolutional encoder-decoder structure and a transformer. <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b16">17]</ref> proposed a multi-attention mechanism to guide the network to capture features effectively while suppressing noise, and integrated deep supervision mechanism and spatial pyramid feature fusion to enhance feature extraction. However, these models are not robust to the heavy noise in the SAX images, which may lead to irregular boundaries and undermines the estimation of LVWT.</p><p>To overcome the above mention challenges and inspired <ref type="bibr" target="#b7">[8]</ref> where template transformer was employed for image segmentation, we propose a novel Temporal-Compatible Deformation learning network for myocardium boundary detection from ultrasound SAX images. The primary contributions of this paper are as follows. 1) To overcome the irregular boundaries caused by the heavy noise, we propose a two-stage deformation learning network for myocardium boundary detection. A global affine transformation and a local deformation are used to deform the prior myocardium template to match the myocardium boundary. 2) To make the template-deformed myocardium boundaries compatible across the whole sequence, we propose a bi-direction deformation learning to guarantee that the deformation fields across the whole sequences can be applied to both the myocardium boundaries and the ultrasound images. 3) The proposed TCdeformer achieves excellent performance for LVWT estimation, with an error of less than 1.00 mm, and is comparable with middle-level cardiologists.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>The structures of the myocardium in ultrasound SAX images generally follow a circular ring shape, which is a vital characteristic of prior knowledge in shortaxis myocardial segmentation, especially for ultrasound images with heavy noisy myocardium boundaries. In this paper, we propose a novel method, Temporal Compatibility Deformation Learning, named TC-Deformer, to achieve accurate and plausible myocardium contours and LVWTs estimation. The details are described as follows. Global Affine Transformation. Our deformation learning consists of two stages: global affine transformation and local deformation learning. In this subsection, we will describe our global affine transformation. Considering the diversity of the cardiac structure and data gaps from different machines, we compute the mean value of the thickness measurements and the center position of the circle according to the annotated information to generate the prior template. As shown in Fig. <ref type="figure" target="#fig_1">2</ref>(a), the prior template (P) is first concatenated with the convolution features extracted from the SAX image to learn the global affine parameters θ = {(Δx, Δy), s}, which represent the shift and scale from the prior template to the myocardium boundaries in the SAX image. Then we get the affine prior (AT) S AT = φ G (P ) by warping the prior template (P) with the global affine parameters θ. The loss function is as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Deformation Learning</head><formula xml:id="formula_0">Loss AT = -S • logS AT + (1 - |S • S AT | |S| + |S AT | ) (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where S is the ground truth of the myocardium segmentation. However, the shapes warping from the prior template with global affine parameters are far from precise due to the individual variation. So, we introduce the local deformation learning to get a precise myocardium shape with the learned dense deformation field.</p><p>Local Deformation Learning. In this part, we aim to learn a dense deformation field to adjust the AT prior locally to match the myocardium boundaries.</p><p>As shown in Fig. <ref type="figure" target="#fig_1">2</ref>(b), the AT prior is first concatenated with the image convolution feature to learn a dense deformation field φ L ∈ R 256×256×2 , which represents the pixel-level displacement along both horizontal and vertical directions. Our local deformation learning considers the prior shape, the prior position, and the image feature simultaneously, which can help the network learn a more precise deformation field and get a local adjustment of the template. Finally, we take the segmentation Ŝ = φ L (S AT ) warping from the AT prior with the dense deformation filed as the final myocardium segmentation result. The loss function is as follows:</p><formula xml:id="formula_2">Loss seg = -S • log Ŝ + (1 - |S • Ŝ| |S| + | Ŝ| ) (<label>2</label></formula><formula xml:id="formula_3">)</formula><p>where S is the ground truth of the myocardium segmentation. In this work, only frames at the end-systolic (ED) and end-diastolic (ES) phases are annotated by cardiologists for each ultrasound SAX video. To make the template-deformed myocardium boundaries compatible across the whole sequence, we propose a bi-direction deformation learning to guarantee that the deformation fields across the whole sequence can be applied to both the myocardium boundaries and the ultrasound images in the sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">TC-Deformer</head><p>As shown in Fig. <ref type="figure" target="#fig_2">3</ref>, first of all, we use the mean θ of the affine transformation parameters {θ 1 , θ 2 , θ 3 , ..., θ T -2 , θ T -1 , θ T } of all frames in the sequence as a videolevel parameter and obtain the mean affine transformation prior template (MAT prior). Next, the MAT prior is combined with the sequential images to learn a series of dense bi-direction deformation fields. Let φ t F be the forward deformation and φ t B the backward deformation for the frame t. Our bi-direction deformation learning (as shown in Fig. <ref type="figure" target="#fig_2">3(b)</ref>) aims to constrain that for each frame X t , after forward deformation and backward deformation, we can still obtain the original images. We adopt the structural similarity metric (SSIM) <ref type="bibr" target="#b10">[11]</ref> in image quality assessment to quantify the deformation error. For the image cycle, the loss function is as follows:</p><formula xml:id="formula_4">Loss imgcycle = T t=1 1 -SSIM (X t , φ t F φ t B (X t )<label>(3)</label></formula><p>Similarly, for the MAT prior S MAT , we can have the shape consistency constraint when applied to the bi-direction deformation procedure:</p><formula xml:id="formula_5">Loss shapecycle = T t=1 (1 - |S MAT • φ t B (φ t F (S MAT )) | |S MAT | + |φ t B (φ t F (S MAT )) | ) (<label>4</label></formula><formula xml:id="formula_6">)</formula><p>As the temporally compatible deformation started with a common template, we assume that when warped backward, all the frames will have a similar appearance. So, we introduce a centralization loss, to minimize the deviation between those backward deformed frames:</p><formula xml:id="formula_7">Loss cent = T t=1 |φ t B (X t ) -φB (X t )| 2<label>(5)</label></formula><p>where T represents the time.</p><p>The total loss function of our TC-Deformer is as follows:</p><formula xml:id="formula_8">Loss total = Loss seg + αLoss cent + βLoss imgcycle + γLoss shapecycle<label>(6)</label></formula><p>where α, β and γ is the hyper-parameters.</p><p>After myocardial segmentation, we use neural networks to determine two key points, combined with the centroid of the segmentation, to divided it into 16segments according to the 16-segment model of the American Heart Association and calculated the corresponding LVWTs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset Description and Experimental Setup</head><p>Datasets. In this experiment, we trained our method on ultrasound SAX videos of 141 participants and tested with 60 participants. All the data was collected with the GE Vivid E95 from the Shenzhen People's Hospital and this study was approved by local institutional review boards. For each participant, videos of the basal, middle, and apical SAX views were acquired with multiple cardiac cycles. The mask of the myocardium at the ED and ES phases from one cardiac cycle was annotated by experts (including two senior, three middle-level, and three junior cardiologists). We compare the LVWT of each group with the average wall thickness of the senior doctors to get the average of the errors for different doctors as result. For the training dataset, the senior cardiologists conducted quality control for junior and middle-level cardiologists. All images were annotated by experienced doctors using the Pair annotation software package <ref type="bibr" target="#b8">[9]</ref>(https://www.aipair.com.cn/en/, Version 2.7, RayShape, Shenzhen, China).</p><p>Experimental Setup. We resized the images to the same size 256 × 256 and used the Adam optimization strategy during model training. The training is in two stages and the initial learning rate was 0.0001, the total epoch number is 100, and the batch size is 4. The hyperparameters α, β, and γ were set to be 0.1, 0.5, and 0.5, respectively, according to a small validation set. The models are implemented with PyTorch on the NVIDIA A100 Tensor Core GPU. Table <ref type="table" target="#tab_0">1</ref> shows the segmentation performance on the test set in terms of Dice, Hausdorff distance (HD), and floating-point operations per second (FLOPs). We can conclude that the proposed method achieves excellent segmentation performance and outperforms U-net and the state-of-the-art CLAS, while costing much less computation. Figure <ref type="figure" target="#fig_3">4</ref> shows the segmentation results of myocardium compared with four methods. It indicates that our method has a more reasonable myocardium shape than others, which is important to LVWT. Figure <ref type="figure" target="#fig_4">5</ref> shows the segmentation results of the myocardium in one cardiac cycle. It indicates that our method can obtain smoother contours for the middle frames than CLAS, implying that the temporally compatible deformation learning has a better temporal consistency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head><p>Table <ref type="table" target="#tab_1">2</ref> shows the MAE of the measurements in LVWT for middle-level and junior cardiologists, as while as for the proposed TD-Deformer. It indicates our results of the measurements are better than the junior groups and comparable with the middle-level group. The error of LVWT estimation is less than 1.00 mm. Figure <ref type="figure" target="#fig_5">6</ref> shows the absolute error of the predicted results for 16 segments. We can conclude that for all 16 segments, the prediction results of TC-Deformer are stable and accurate.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, We propose a Temporally Compatible Deformation learning network, named TC-Deformer, to detect the myocardium boundaries and estimate regional left ventricle wall thickness. Our method is designed to avoid the irregular contours that can happen in ultrasound images with heavy noise and can incorporate the temporal dynamics of the myocardium in one cardiac cycle into the deformation field learning. When validated with a dataset of 201 patients, our method achieves less than 1.00 mm estimation error for all 16 myocardium segments and outperforms existing state-of-the-art methods.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Illustration of LVWT to be quantified for short-axis view cardiac image and 16 segments.Basal (left), middle (middle), and apical (right). Regional wall thicknesses (black arrows). 1-16: 16 segments.</figDesc><graphic coords="3,88,98,53,81,274,90,85,90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. (a)Overview of the proposed global affine transformation. (b)Overview of the proposed local deformation learning.</figDesc><graphic coords="4,75,30,82,91,273,37,152,80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. (c) Overview of the proposed TC-Deformer network framework. (d) Schematic diagram of bi-directional consistency loss for images and segmentation.</figDesc><graphic coords="5,57,48,248,72,337,45,93,19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Visualization results of four segmentation methods.</figDesc><graphic coords="7,89,46,391,94,273,82,75,73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Visualization of the segmentation results for one cardiac cycle.</figDesc><graphic coords="8,74,79,54,23,274,36,98,47" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. The MAE of prediction LVWT indices as well as their corresponding standard deviation.</figDesc><graphic coords="9,68,97,54,08,314,86,57,64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Quantitative comparison results of the average Dice, Hausdorff distance(HD), FLOPs.</figDesc><table><row><cell></cell><cell cols="2">Dice HD (mm) FLOPs (G)</cell></row><row><cell>Unet [10]</cell><cell>0.827 3.73</cell><cell>40.46</cell></row><row><cell>CLAS [12]</cell><cell>0.842 2.98</cell><cell>208.47</cell></row><row><cell>Deformer</cell><cell>0.852 2.64</cell><cell>41.46</cell></row><row><cell cols="2">TC-Deformer 0.854 2.92</cell><cell>41.46</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>The MAE of LVWT (mm)</figDesc><table><row><cell></cell><cell>Basal</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell></row><row><cell>Mid-level</cell><cell cols="6">0.86 0.67 0.93 0.89 0.87 0.85</cell></row><row><cell>Junior</cell><cell cols="6">1.02 0.87 1.03 0.87 0.91 0.90</cell></row><row><cell cols="7">TC-Deformer 0.80 0.80 0.86 0.91 0.92 0.85</cell></row><row><cell></cell><cell cols="2">Middle</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>10</cell><cell>11</cell><cell>12</cell></row><row><cell>Mid-level</cell><cell cols="6">0.67 0.95 0.86 0.87 1.04 0.83</cell></row><row><cell>Junior</cell><cell cols="6">0.73 0.95 1.02 0.81 1.02 0.93</cell></row><row><cell cols="7">TC-Deformer 1.02 0.82 0.90 1.04 0.82 0.83</cell></row><row><cell></cell><cell cols="2">Apical</cell><cell></cell><cell></cell><cell cols="2">16-segments</cell></row><row><cell></cell><cell>13</cell><cell>14</cell><cell>15</cell><cell>16</cell><cell>mean</cell></row><row><cell>Mid-level</cell><cell cols="5">0.90 0.89 0.96 0.97 0.88</cell></row><row><cell>Junior</cell><cell cols="5">1.20 1.22 1.08 1.36 0.99</cell></row><row><cell cols="6">TC-Deformer 0.87 0.97 0.94 1.18 0.91</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement. The work is partially supported by the <rs type="funder">Natural Science Foundation of China</rs> (<rs type="grantNumber">62171290</rs>), the <rs type="funder">Shenzhen Science and Technology Program</rs> (<rs type="grantNumber">20220810145705001</rs>, <rs type="grantNumber">JCYJ20190808115419619</rs>, <rs type="grantNumber">SGDX20201103095613036</rs>), <rs type="funder">Medical Scientific Research Foundation of Guangdong Province</rs> (No. <rs type="grantNumber">A2021370</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_T4tZ64f">
					<idno type="grant-number">62171290</idno>
				</org>
				<org type="funding" xml:id="_2D43hrT">
					<idno type="grant-number">20220810145705001</idno>
				</org>
				<org type="funding" xml:id="_ZtYQA8J">
					<idno type="grant-number">JCYJ20190808115419619</idno>
				</org>
				<org type="funding" xml:id="_FfE9kVD">
					<idno type="grant-number">SGDX20201103095613036</idno>
				</org>
				<org type="funding" xml:id="_Stp8zvc">
					<idno type="grant-number">A2021370</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">ResDUnet: a deep learning-based left ventricle segmentation method for echocardiography</title>
		<author>
			<persName><forename type="first">A</forename><surname>Amer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Janan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="159755" to="159763" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Clinical study on LVO-based evaluation of left ventricular wall thickness and volume of AHCM patients</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Radiat. Res. Appl. Sci</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">100545</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">TransBridge: a lightweight transformer for left ventricle segmentation in echocardiography</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deng</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87583-1_7</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87583-17" />
	</analytic>
	<monogr>
		<title level="m">ASMUS 2021</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Noble</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Aylward</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Grimwood</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Min</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S.-L</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12967</biblScope>
			<biblScope unit="page" from="63" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Direct segmentation-based full quantification for left ventricle via deep multi-task regression learning network</title>
		<author>
			<persName><forename type="first">X</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Biomed. Health Inf</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="942" to="948" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">PV-LVNet: direct left ventricle multitype indices estimation from 2d echocardiograms of paired apical views with deep neural networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page">101554</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The role of cardiovascular magnetic resonance imaging in heart failure</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Karamitsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Myerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Selvanayagam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Neubauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Coll. Cardiol</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="1407" to="1424" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">LU-Net: a multistage attention network to improve the robustness of segmentation of left ventricular structures in 2-D echocardiography</title>
		<author>
			<persName><forename type="first">S</forename><surname>Leclerc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Ultrason. Ferroelectr. Freq. Control</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2519" to="2530" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">TeTrIS: template transformer networks for image segmentation with shape priors</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Pawlowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schaap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2596" to="2606" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Sketch guided and progressive growing GAN for realistic and editable ultrasound image synthesis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page">102461</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">U-Net: convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-24574-4_28</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-24574-428" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2015</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hornegger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">9351</biblScope>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Image quality assessment: from error visibility to structural similarity</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="600" to="612" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Temporal-consistent segmentation of echocardiography with co-learning from appearance and shape</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59713-9_60</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-59713-960" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12262</biblScope>
			<biblScope unit="page" from="623" to="632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Co-learning of appearance and shape for precise ejection fraction estimation from echocardiographic sequences</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page">102686</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Improved segmentation of echocardiography with orientation-congruency of optical flow and motion-enhanced segmentation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Biomed. Health Inf</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="6105" to="6115" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Direct multitype cardiac indices estimation via joint representation and regression learning</title>
		<author>
			<persName><forename type="first">W</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bhaduri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2057" to="2067" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Direct estimation of regional wall thicknesses via residual recurrent neural network</title>
		<author>
			<persName><forename type="first">W</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">B</forename><surname>Nachum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Warrington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-59050-9_40</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-59050-940" />
	</analytic>
	<monogr>
		<title level="m">IPMI 2017</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Niethammer</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">10265</biblScope>
			<biblScope unit="page" from="505" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">MAEF-Net: multi-attention efficient feature fusion network for left ventricular segmentation and quantitative analysis in two-dimensional echocardiography</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ultrasonics</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="page">106855</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
