<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SCOL: Supervised Contrastive Ordinal Loss for Abdominal Aortic Calcification Scoring on Vertebral Fracture Assessment Scans</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Afsah</forename><surname>Saleem</surname></persName>
							<email>afsah.saleem@ecu.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">School of Science</orgName>
								<orgName type="institution" key="instit1">Centre for AI &amp; ML</orgName>
								<orgName type="institution" key="instit2">Edith Cowan University</orgName>
								<address>
									<settlement>Joondalup</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Nutrition and Health Innovation Research Institute</orgName>
								<orgName type="institution" key="instit2">Edith Cowan University</orgName>
								<address>
									<settlement>Joondalup</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zaid</forename><surname>Ilyas</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Science</orgName>
								<orgName type="institution" key="instit1">Centre for AI &amp; ML</orgName>
								<orgName type="institution" key="instit2">Edith Cowan University</orgName>
								<address>
									<settlement>Joondalup</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Nutrition and Health Innovation Research Institute</orgName>
								<orgName type="institution" key="instit2">Edith Cowan University</orgName>
								<address>
									<settlement>Joondalup</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Suter</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Science</orgName>
								<orgName type="institution" key="instit1">Centre for AI &amp; ML</orgName>
								<orgName type="institution" key="instit2">Edith Cowan University</orgName>
								<address>
									<settlement>Joondalup</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Nutrition and Health Innovation Research Institute</orgName>
								<orgName type="institution" key="instit2">Edith Cowan University</orgName>
								<address>
									<settlement>Joondalup</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ghulam</forename><forename type="middle">Mubashar</forename><surname>Hassan</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Computer Science and Software Engineering</orgName>
								<orgName type="institution">The University of Western Australia</orgName>
								<address>
									<settlement>Perth</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Siobhan</forename><surname>Reid</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Manitoba</orgName>
								<address>
									<settlement>Winnipeg</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">John</forename><forename type="middle">T</forename><surname>Schousboe</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Richard</forename><surname>Prince</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Computer Science and Software Engineering</orgName>
								<orgName type="institution">The University of Western Australia</orgName>
								<address>
									<settlement>Perth</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">William</forename><forename type="middle">D</forename><surname>Leslie</surname></persName>
							<affiliation key="aff5">
								<orgName type="department">Departments of Medicine and Radiology</orgName>
								<orgName type="institution">University of Manitoba</orgName>
								<address>
									<settlement>Winnipeg</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Joshua</forename><forename type="middle">R</forename><surname>Lewis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Science</orgName>
								<orgName type="institution" key="instit1">Centre for AI &amp; ML</orgName>
								<orgName type="institution" key="instit2">Edith Cowan University</orgName>
								<address>
									<settlement>Joondalup</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Nutrition and Health Innovation Research Institute</orgName>
								<orgName type="institution" key="instit2">Edith Cowan University</orgName>
								<address>
									<settlement>Joondalup</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Syed</forename><forename type="middle">Zulqarnain</forename><surname>Gilani</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Science</orgName>
								<orgName type="institution" key="instit1">Centre for AI &amp; ML</orgName>
								<orgName type="institution" key="instit2">Edith Cowan University</orgName>
								<address>
									<settlement>Joondalup</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Nutrition and Health Innovation Research Institute</orgName>
								<orgName type="institution" key="instit2">Edith Cowan University</orgName>
								<address>
									<settlement>Joondalup</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Computer Science and Software Engineering</orgName>
								<orgName type="institution">The University of Western Australia</orgName>
								<address>
									<settlement>Perth</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Nicollet Clinic and HealthPartners Institute, HealthPartners</orgName>
								<address>
									<region>Minneapolis</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SCOL: Supervised Contrastive Ordinal Loss for Abdominal Aortic Calcification Scoring on Vertebral Fracture Assessment Scans</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4ACB481D0DA6DE7F6EF0018EEA9F0F91</idno>
					<idno type="DOI">10.1007/978-3-031-43987-227.</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-01T10:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Supervised contrastive ordinal learning</term>
					<term>Distance-metric learning</term>
					<term>Cardiovascular Diseases</term>
					<term>VFA DXA scans</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Abdominal Aortic Calcification (AAC) is a known marker of asymptomatic Atherosclerotic Cardiovascular Diseases (ASCVDs). AAC can be observed on Vertebral Fracture Assessment (VFA) scans acquired using Dual-Energy X-ray Absorptiometry (DXA) machines. Thus, the automatic quantification of AAC on VFA DXA scans may be used to screen for CVD risks, allowing early interventions. In this research, we formulate the quantification of AAC as an ordinal regression problem. We propose a novel Supervised Contrastive Ordinal Loss (SCOL) by incorporating a label-dependent distance metric with existing supervised contrastive loss to leverage the ordinal information inherent in discrete AAC regression labels. We develop a Dual-encoder Contrastive Ordinal Learning (DCOL) framework that learns the contrastive ordinal representation at global and local levels to improve the feature separability and class diversity in latent space among the AAC-24 genera. We evaluate the performance of the proposed framework using two clinical VFA DXA scan datasets and compare our work with state-of-the-art methods. Furthermore, for predicted AAC scores, we provide a clinical analysis to predict the future risk of a Major Acute Cardiovascular Event (MACE).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Abdominal Aortic Calcification (AAC) is an established marker of atherosclerotic cardiovascular disease (CVD) <ref type="bibr" target="#b18">[19]</ref> and can help in identifying asymptomatic cases at risk for CVD-related hospitalizations and deaths <ref type="bibr" target="#b13">[14]</ref>. CVDs are responsible for 32% of global deaths, with atherosclerotic CVD events being the leading cause <ref type="bibr" target="#b16">[17]</ref>. Therefore, early detection and management of AAC can improve CVD prevention, and management <ref type="bibr" target="#b13">[14]</ref>. AAC can be seen on lateral spine Vertebral Fracture Assessment (VFA) images acquired using Dual-energy X-ray Absorptiometry (DXA), X-rays or Computed Tomography (CT) <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b18">19]</ref>. However, DXA imaging is the most recommended and cost-effective approach for VF assessment, with the least radiation exposure <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b22">23]</ref>. In VFA DXA scans, AAC can be calculated manually using the Kauppila AAC-24 semi-quantitative scale <ref type="bibr" target="#b9">[10]</ref>. However, the manual scoring of AAC in VFA images is arduous and subjective <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref>. Thus, designing an automated system for detecting and quantifying AAC in VFA DXA scans may be the most feasible approach for obtaining valuable CVD risk information in asymptomatic individuals.</p><p>Very few attempts have been made for automated AAC scoring in VFA DXA scans <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b17">18]</ref>. Reid et al. <ref type="bibr" target="#b17">[18]</ref> trained two CNN models using VFA DXA scans and reported results via ensembling on a limited test set. Gilani et al. <ref type="bibr" target="#b6">[7]</ref> performed sequential scoring using a vision-to-language model, but achieved low sensitivity for a moderate-risk class, indicating difficulty in handling complex cases near class boundaries. These works <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b17">18]</ref> considered automated AAC scoring a regression task. However, simple regression losses depend on continuous regression labels and, thus, cannot make feature embeddings separable. Moreover, inter-class similarities, intra-class variations and image artifacts in lowresolution VFA DXA scan further complicate the task. Therefore, using these losses directly for AAC-24 score regression may not be optimal.</p><p>Contrastive representation learning has shown promising results in medical image classification <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b15">16]</ref> and segmentation tasks <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b23">24]</ref>. In the classification tasks, supervised contrastive learning (SupCon) <ref type="bibr" target="#b10">[11]</ref> aims to bring feature embeddings with the same labels closer together in the latent space and move the dissimilar ones apart. However, SupCon cannot preserve the ordinal information of the regression labels in the latent space <ref type="bibr" target="#b4">[5]</ref>. To address this, Dai et al. <ref type="bibr" target="#b4">[5]</ref> propose supervised Adaptive Contrastive loss (AdaCon), which depends on an adaptive margin. For calculating the adaptive margin, they assumed that a regression label could be replaced with its Empirical Cumulative Distribution Function (ECDF) <ref type="bibr" target="#b21">[22]</ref>. Though this assumption might be valid for large datasets, it may not work with highly skewed, imbalanced and limited-size datasets <ref type="bibr" target="#b4">[5]</ref>.</p><p>To this end, we propose a novel Supervised Contrastive Ordinal Loss (SCOL), considering AAC scoring as an ordinal regression problem. We integrate a labeldependent distance metric with the supervised contrastive loss. Unlike AdaCon <ref type="bibr" target="#b4">[5]</ref>, this metric relies exclusively on discrete regression labels, making it possible to utilize the ordinal information inherent in these labels. Using SCOL, we design an effective Dual-encoder Contrastive Ordinal Learning (DCOL) framework. Unlike previous methods, which either use global <ref type="bibr" target="#b17">[18]</ref> or local attentionbased features <ref type="bibr" target="#b6">[7]</ref>, DCOL assimilates global and local feature embeddings to increase feature diversity, and class separability in latent space.</p><p>To the best of our knowledge, this is the first framework that explores contrastive learning for automated detection of AAC. Our contributions are summarized as follows: 1) We propose a novel supervised contrastive ordinal loss by incorporating distance metric learning with the supervised contrastive loss to improve inter-class separability and handle intra-class diversity among the AAC genera. 2) We design a Dual-Encoder Contrastive Ordinal Learning framework using the proposed loss to learn separable feature embeddings at global and local levels. 3) We achieve state-of-the-art results on two clinical datasets acquired using DXA machines from multiple manufacturers, demonstrating the generalizability and efficacy of our approach. 4) We compare the Major Adverse Cardiovascular Event (MACE) outcomes for machine-predicted AAC scores and the human-measured scores to explore the clinical relevance of our method. This work aims to contribute clinically in refining automated AAC prediction methods using low-energy VFA scans. Our code is available at <ref type="bibr" target="#b0">[1]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Supervised Contrastive Ordinal Learning</head><p>Consider a training set T of M image-label pairs, such that T = {(x i , y i )} M i=1 where x i is the i th VFA DXA scan and y i is the corresponding AAC score. Let a, p and n denote the indices of anchor, positive sample, and negative samples in a batch I. P (i) is the set of indices of all the positive samples, i.e., having the same AAC score as y a and N (i) is the set of all other negative indices. Consider an encoder-projector network that maps the anchor image x a in the embedding space such that z a = P roj(Enc(x a )), then the similarity between any two projections z i and z k in the latent space is: sim(z i , z k ) = z T i .z k . Supervised contrastive loss <ref type="bibr" target="#b10">[11]</ref> pulls images of the same class (positive samples) close together and pushes the negative ones apart. Following this strategy, we propose contrastive ordinal loss to move the negative sample x n apart from the anchor x a by a distance r (a,n) : such that if a &lt; b &lt; c then r(a, b) must be less than r(a, c) and vice versa. By incorporating this ordinal distance metric with the similarity function, we can maximize the benefit of ordinal information present in regression labels. Furthermore, in our AAC scoring task, this ordinal distance metric can help to increase inter-class separability and minimize the effect of intra-class variations. (For visualization see SM). Inspired by <ref type="bibr" target="#b4">[5]</ref>, we propose Supervised Contrastive Ordinal Loss (SCOL) for ordinal regression as:</p><formula xml:id="formula_0">L SCOL = i∈I -1 |P (i)| p∈P (i) log exp(z a .z p /τ ) n∈N (i)(n =a) exp((z a .z n + r a,n )/τ )<label>(1)</label></formula><p>where τ is a scaling hyper-parameter for contrastive loss and r (a,n) is the distance metric between two labels y (a) and y (n) . If C is the number of ordinal labels in training set T, then r (a,n) is calculated as:</p><formula xml:id="formula_1">r a,n = ||y a -y n || 2 × 2/C.</formula><p>From the above equation, it can be seen that our ordinal distance metric is monotonically increasing, i.e., if a &lt; b &lt; c, then r a,b must be less than r a,c and vice versa. This property allows the metric to maintain the ordinality of the data while improving the class separability in the latent space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Dual-Encoder Contrastive Ordinal Learning</head><p>The proposed Dual-Encoder Contrastive Ordinal Learning (DCOL) framework consists of two stages: Stage-I: contrastive ordinal feature learning and Stage-II: relevant AAC risk class prediction via AAC-24 score regression (Fig. <ref type="figure" target="#fig_0">1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stage-I: It consists of two modules: Local Contrastive Ordinal Learning (LCOL)</head><p>and Global Contrastive Ordinal Learning (GCOL). In these modules, we train the global and local encoder-projector networks individually in an end-to-end manner to extract contrastive feature embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Local Contrastive Ordinal Learning:</head><p>In practice, to quantify AAC, clinicians focus on the aortic region adjacent to lumbar vertebrae L1-L4. Following this, in the Localized feature-based Contrastive Ordinal Learning module, LCOL, we integrate a simple yet effective localized attention block with the baseline encoder E l to roughly localize the aorta's position using only regression labels. This attention block is attached with E l after extracting the deep feature map f m from the last convolution layer. Our localized attention block consists of two 2D convolutional layers, followed by batch normalization and ReLu activation layers. This set of layers is then followed by an average pooling layer and sigmoid activation to create an activation map f s for the most salient features in the given image. Multiplying this activation map f s with the initial feature map f m results in extracting the most significant features from f m . These features are then projected into the latent space for processing by our SCOL loss. SCOL encourages the local contrastive embeddings with the same AAC score to move closer and the dissimilar ones apart based on the distance between their labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Global Contrastive Ordinal Learning: In the Global Contrastive Ordinal</head><p>Learning module, we extract the global representation of a given VFA DXA scan. In encoder E g , we replace the fully connected layers of the vanilla CNN model with a global average pooling (GAP ) layer for feature extraction. These feature embeddings are then passed to the projection network P g . SCOL operates on projected embeddings extracted from the whole lumbar region to maximize the feature separability while preserving the ordinal information in latent space. Both projector networks, P l and P g , consist of two Dense layers with 1280 and 128 neurons each, followed by ReLu activation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stage-II:</head><p>In AAC-24 score regression, a small change in pixel-level information can move the patient from low to moderate or moderate to high-risk AAC class. Thus, to decrease the effect of intra-class variations and to increase the inter-class separability, we assimilate the features extracted from encoders E l and E g . The resultant feature vector is fed as input to a feed-forward network consisting of two Dense layers with 1280 and 128 neurons each, followed by ReLu activation. Finally, a linear layer predicts the final AAC regression score. This module is trained using root mean squared error loss L rmse calculated as:</p><formula xml:id="formula_2">L rmse = i∈m (y i -y i ) 2 /m</formula><p>, where m is the number of samples, y i are actual and y i are predicted AAC scores. The resulting AAC scores are then further classified into three AAC risk classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset and Annotations:</head><p>We conducted experiments on two de-identified clinical datasets acquired using the Hologic 4500A and GE iDXA scanners. Both datasets are manually annotated by clinicians using the AAC-24 scale <ref type="bibr" target="#b9">[10]</ref> which divides the aortic walls into four segments based on the lumbar vertebrae bodies (L1 -L4). Each segment is assigned an AAC score 0: if no calcification (Cal), 1: Cal ≤ 1/3 of aortic wall, 2: Cal &gt; 1/3 but &lt; 2/3 of aortic wall and 3: Cal ≥ 2/3 of aortic wall. The total AAC-24 score can range from 0 to 24 and is further classified into three AAC risk classes using clinical thresholds <ref type="bibr" target="#b14">[15]</ref>: Lowrisk (AAC &lt; 2), Moderate-risk (2 ≤ AAC ≤ 5), and High-risk (AAC &gt; 5).</p><p>The Hologic Dataset <ref type="bibr" target="#b13">[14]</ref> has 1,914 single-energy DXA scans acquired using a Hologic 4500A machine. Each scan has dimensions of at least 800 × 287 pixels. Among 1,914 scans, there are 764 scans belonging to the low-risk, 714 to moderate-risk and 436 scans to the high-risk AAC group. The iDXA GE Dataset <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b17">18]</ref> has 1,916 dual-energy VFA DXA scans. Among these, there are 829 belonging to low-risk, 445 to moderate-risk and 642 scans to the high-risk AAC group. These scans are acquired using an iDXA GE machine. These scans have dimensions of 1600 × 300 pixels.</p><p>Implementation Details: Each VFA scan in both datasets contains a full view of the thoracolumbar spine. To extract the region of interest (ROI), i.e., the abdominal aorta near the lumbar spine, we crop the upper half of the image, resize it to 300×300 pixels and rescale it between 0 and 1. We apply data augmentations including rotation, shear and translation. We implement all experiments in TensorFlow <ref type="bibr" target="#b20">[21]</ref>, using stratified 10-fold cross-validation on a workstation with NVIDIA RTX 3080 GPU. (For details, see SM.) In stage-I, we adopted an efficient, smaller and faster pre-trained model, EfficientNet-V2S <ref type="bibr" target="#b19">[20]</ref>, as the backbone for both encoders. We train stage-I for 200 epochs and stage II for 75 epochs using the RMSprops optimizer with the initial learning rate of 3 × 10 -4 and a batch size of 16. τ in the proposed SCOL is 0.2. The inference time for each scan is less than 15 ms. To avoid overfitting, we used early stopping and reduce LR on the plateau while optimizing the loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation Metrics:</head><p>The performance of the AAC regression score is evaluated in terms of Pearson's correlation, while for AAC risk classification task Accuracy, F1-Score, Sensitivity, Specificity, Negative Predictive Value (NPV) and Positive Predictive Value (PPV) are used in One Vs. Rest (OvR) setting. Baseline: EfficientNet-V2S model trained in regression mode using RMSE loss. Ablation Study: Table <ref type="table" target="#tab_0">1</ref> highlights the efficacy of our proposed loss SCOL. We train our dual-encoder contrastive learning framework with proposed SCOL, SupCon <ref type="bibr" target="#b10">[11]</ref> and AdaCon <ref type="bibr" target="#b4">[5]</ref>, individually, on the Hologic dataset. We also evaluate the performance of the local and global contrastive modules (LCL and GCL) with each contrastive loss. Table <ref type="table" target="#tab_0">1</ref> also shows the strength of integrating the localized attention block with the baseline model trained with RMSE loss.</p><p>Comparison with the Baseline: In Table <ref type="table" target="#tab_1">2</ref>, we compare the performance of our framework with the baseline on both datasets. For the Hologic dataset, our proposed method improved Pearson's correlation coefficient from a baseline of 0.87 to 0.89 and 3-class classification accuracy from 73%±3.82 to 78%±3.65 with (p &lt; 0.001). While, for the iDXA GE dataset, the proposed method enhanced the Pearson's correlation from a baseline of 0.89 to 0.91 and averaged 3-class classification accuracy from 77% ± 3.9 to 80% ± 5.12 with (p &lt; 0.001). Comparison with the State-of-the-Art (SOTA): Table <ref type="table" target="#tab_2">3</ref> shows the comparison of our proposed framework with two SOTA methods <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b17">18]</ref> using the iDXA GE dataset. Our approach outperforms <ref type="bibr" target="#b17">[18]</ref> by an average of 15.62% in accuracy and 20.7% in sensitivity with (p &lt; 0.001), while in comparison to <ref type="bibr" target="#b6">[7]</ref>, accuracy is improved by 4.41% and sensitivity by 9.21%, with (p &lt; 0.001).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Clinical Analysis and Discussion:</head><p>To signify the clinical significance, we estimate the AUCs (Fig. For the iDXA GE Dataset, in the cohort of 1877 patients with clinical followup, 160 experienced a MACE event. The AUCs of predicted AAC-24 scores were similar AUC to human AAC-24 (0.64 95%CI 0.60-0.69 vs. 0.63 95%CI 0.59-0.68). The predicted AAC groups had 877 (46.7%), 468 (24.9%), and 532 (28.3%) of people in the low, moderate, and high AAC groups, respectively, with MACE events occurring in 5.1%, 7.5%, and 15.0% of these groups, respectively. The age and sex-adjusted HR for MACE in the moderate AAC group was 1.21 95%CI 0.77-1.89, and 2.64 95% CI 1.80-3.86 for the high AAC group, compared to the low predicted AAC group, which were similar to the HRs of human AAC groups, i.e., for moderate and high AAC groups HR 1.15 95%CI 0.72-1.84 and 2.32 95% CI 1.59-3.38, respectively, compared to the human low AAC group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We propose a novel Supervised Contrastive Ordinal Loss and developed a Dualencoder Contrastive Ordinal Learning framework for AAC scoring and relevant AAC risk classification in low-energy VFA DXA scans. Our framework learns contrastive feature embeddings at the local and global levels. Our results demonstrate that the contrastive ordinal learning technique remarkably enhanced interclass separability and strengthened intra-class consistency among the AAC-24 genera, which is particularly beneficial in handling challenging cases near the class boundaries. Our framework with SCOL loss demonstrates significant performance improvements, compared to state-of-the-art methods. Moreover, the ablation studies also establish the effectiveness of our dual-encoder strategy and localized attention block. These results suggest that our approach has great clinical potential for accurately predicting AAC scores and relevant risk classes.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Framework of our dual-encoder contrastive ordinal learning framework.</figDesc><graphic coords="3,71,46,376,16,309,82,129,61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Comparison of AUCs for Major Adverse Cardiovascular Events (MACE) associated with our predicted AAC-24 scores and human-measured AAC-24 scores.</figDesc><graphic coords="8,85,29,54,53,253,66,123,16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Comparison of proposed loss SCOL with different losses using Hologic Dataset</figDesc><table><row><cell>Loss</cell><cell>Method</cell><cell cols="5">Pearson (%) Accuracy (%) F1-Score (%) Sensitivity (%) Specificity (%)</cell></row><row><cell></cell><cell>GCL LCL</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>RMSE</cell><cell>-</cell><cell>87.02</cell><cell>81.92</cell><cell>75.88</cell><cell>74.93</cell><cell>85.36</cell></row><row><cell>RMSE</cell><cell>-</cell><cell>87.34</cell><cell>82.5</cell><cell>76.71</cell><cell>76.06</cell><cell>85.88</cell></row><row><cell>RMSE</cell><cell></cell><cell>88.12</cell><cell>83.52</cell><cell>77.91</cell><cell>77.00</cell><cell>86.64</cell></row><row><cell>SupCon [11]</cell><cell>-</cell><cell>87.26</cell><cell>83.52</cell><cell>77.97</cell><cell>77.14</cell><cell>86.64</cell></row><row><cell>SupCon [11]</cell><cell>-</cell><cell>86.39</cell><cell>83.38</cell><cell>77.74</cell><cell>77.02</cell><cell>86.60</cell></row><row><cell>SupCon [11]</cell><cell></cell><cell>88.24</cell><cell>83.94</cell><cell>78.69</cell><cell>77.82</cell><cell>87.00</cell></row><row><cell>AdaCon [5]</cell><cell>-</cell><cell>88.14</cell><cell>82.51</cell><cell>76.67</cell><cell>75.82</cell><cell>85.86</cell></row><row><cell>AdaCon [5]</cell><cell>-</cell><cell>88.60</cell><cell>83.69</cell><cell>78.16</cell><cell>77.28</cell><cell>86.79</cell></row><row><cell>AdaCon [5]</cell><cell></cell><cell>88.40</cell><cell>83.98</cell><cell>78.80</cell><cell>77.91</cell><cell>87.03</cell></row><row><cell>SCOL (This paper)</cell><cell>-</cell><cell>88.74</cell><cell>84.08</cell><cell>78.82</cell><cell>78.13</cell><cell>87.10</cell></row><row><cell cols="2">SCOL (This paper) -</cell><cell>88.92</cell><cell>84.36</cell><cell>78.90</cell><cell>77.93</cell><cell>87.34</cell></row><row><cell>SCOL (This paper)</cell><cell></cell><cell>89.04</cell><cell>85.27</cell><cell>80.25</cell><cell>79.46</cell><cell>88.05</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Class-wise performance comparison of the proposed framework with baseline. NPV: Negative Predicted Value, PPV: Positive Predicted Value</figDesc><table><row><cell></cell><cell cols="2">AAC Class Method Accuracy</cell><cell>F1-Score</cell><cell>NPV (%)</cell><cell>PPV (%)</cell><cell>Sensitivity</cell><cell>Specificity</cell></row><row><cell></cell><cell></cell><cell>(%)</cell><cell>(%)</cell><cell></cell><cell></cell><cell>(%)</cell><cell>(%)</cell></row><row><cell>Hologic Dataset</cell><cell>Low</cell><cell>Baseline 75.96</cell><cell>69.00</cell><cell>78.89</cell><cell>71.11</cell><cell>67.01</cell><cell>81.91</cell></row><row><cell></cell><cell>(n = 764)</cell><cell>DCOL 80.56</cell><cell>75.52</cell><cell>83.59</cell><cell>75.93</cell><cell>75.13</cell><cell>84.17</cell></row><row><cell></cell><cell>Moderate</cell><cell>Baseline 72.94</cell><cell>65.92</cell><cell>80.78</cell><cell>62.16</cell><cell>70.17</cell><cell>74.58</cell></row><row><cell></cell><cell>(n = 714)</cell><cell>DCOL 77.90</cell><cell>71.36</cell><cell>83.75</cell><cell>69.06</cell><cell>73.80</cell><cell>80.33</cell></row><row><cell></cell><cell>High</cell><cell>Baseline 96.89</cell><cell>92.71</cell><cell>96.46</cell><cell>98.45</cell><cell>87.61</cell><cell>99.50</cell></row><row><cell></cell><cell>(n = 436)</cell><cell>DCOL 97.33</cell><cell>93.86</cell><cell>96.97</cell><cell>98.73</cell><cell>89.45</cell><cell>99.66</cell></row><row><cell></cell><cell>Average</cell><cell>Baseline 81.92</cell><cell>75.88</cell><cell>77.24</cell><cell>85.38</cell><cell>74.93</cell><cell>85.36</cell></row><row><cell></cell><cell cols="2">(n = 1,914) DCOL 85.27</cell><cell>80.25</cell><cell>81.24</cell><cell>88.10</cell><cell>79.46</cell><cell>88.05</cell></row><row><cell cols="2">iDXA GE Dataset Low</cell><cell>Baseline 85.44</cell><cell>82.97</cell><cell>83.95</cell><cell>86.53</cell><cell>82.02</cell><cell>88.04</cell></row><row><cell></cell><cell>(n = 829)</cell><cell>DCOL 87.63</cell><cell>85.76</cell><cell>85.40</cell><cell>89.35</cell><cell>86.12</cell><cell>88.37</cell></row><row><cell></cell><cell>Moderate</cell><cell>Baseline 77.60</cell><cell>55.35</cell><cell>51.55</cell><cell>87.21</cell><cell>59.77</cell><cell>83.00</cell></row><row><cell></cell><cell>(n = 445)</cell><cell>DCOL 80.63</cell><cell>60.15</cell><cell>57.61</cell><cell>88.46</cell><cell>62.92</cell><cell>85.99</cell></row><row><cell></cell><cell>High</cell><cell>Baseline 90.18</cell><cell>84.74</cell><cell>88.47</cell><cell>90.95</cell><cell>81.30</cell><cell>94.66</cell></row><row><cell></cell><cell>(n = 642)</cell><cell>DCOL 90.92</cell><cell>85.99</cell><cell>89.39</cell><cell>91.60</cell><cell>82.71</cell><cell>95.05</cell></row><row><cell></cell><cell>Average</cell><cell>Baseline 84.41</cell><cell>74.35</cell><cell>74.65</cell><cell>88.23</cell><cell>74.37</cell><cell>88.56</cell></row><row><cell></cell><cell cols="2">(n = 1,916) DCOL 86.39</cell><cell>77.28</cell><cell>77.47</cell><cell>89.80</cell><cell>77.25</cell><cell>89.94</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Comparison of the proposed DCOL with State-of-the-Art methods [7, 18] on iDXA GE Dataset. NPV: Negative Predicted Value, PPV: Positive Predicted Value</figDesc><table><row><cell cols="2">Risk Class Method</cell><cell cols="2">Pearson (%) Accuracy</cell><cell>Sens. (%)</cell><cell>Spec. (%)</cell><cell>NPV (%)</cell><cell>PPV (%)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>(%)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Low</cell><cell>Reid et al. [18]</cell><cell>-</cell><cell>71.14</cell><cell>55.49</cell><cell>83.07</cell><cell>70.99</cell><cell>71.43</cell></row><row><cell></cell><cell>Gilani et al. [7]</cell><cell>-</cell><cell>82.52</cell><cell>86.37</cell><cell>79.58</cell><cell>88.45</cell><cell>76.33</cell></row><row><cell></cell><cell cols="2">DCOL (This paper) -</cell><cell>87.63</cell><cell>86.12</cell><cell>88.77</cell><cell>89.35</cell><cell>85.40</cell></row><row><cell cols="2">Moderate Reid et al. [18]</cell><cell>-</cell><cell>62.06</cell><cell>59.33</cell><cell>62.88</cell><cell>83.63</cell><cell>32.59</cell></row><row><cell></cell><cell>Gilani et al. [7]</cell><cell>-</cell><cell>75.52</cell><cell>37.53</cell><cell>87.02</cell><cell>82.16</cell><cell>46.65</cell></row><row><cell></cell><cell cols="2">DCOL (This paper) -</cell><cell>80.63</cell><cell>62.90</cell><cell>85.99</cell><cell>88.46</cell><cell>57.60</cell></row><row><cell>High</cell><cell>Reid et al. [18]</cell><cell>-</cell><cell>79.12</cell><cell>54.83</cell><cell>91.37</cell><cell>80.06</cell><cell>76.19</cell></row><row><cell></cell><cell>Gilani et al. [7]</cell><cell>-</cell><cell>87.89</cell><cell>80.22</cell><cell>91.76</cell><cell>90.20</cell><cell>83.06</cell></row><row><cell></cell><cell cols="2">DCOL (This paper) -</cell><cell>90.90</cell><cell>82.70</cell><cell>95.05</cell><cell>91.60</cell><cell>89.39</cell></row><row><cell>Average</cell><cell>Reid et al. [18]</cell><cell>65.00</cell><cell>70.77</cell><cell>56.55</cell><cell>79.11</cell><cell>78.23</cell><cell>60.07</cell></row><row><cell></cell><cell>Gilani et al. [7]</cell><cell>84.00</cell><cell>81.98</cell><cell>68.04</cell><cell>86.12</cell><cell>86.93</cell><cell>68.68</cell></row><row><cell></cell><cell cols="2">DCOL (This paper) 91.03</cell><cell>86.39</cell><cell>77.25</cell><cell>89.94</cell><cell>89.80</cell><cell>77.47</cell></row></table></figure>
		</body>
		<back>

			
			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement and Data Use Declaration. De-identified labelled images</head></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>were sourced for the ML (Project no: 03349 LEWIS) from a number of existing studies collecting VFAs. For Hologic dataset, written informed consent was obtained from all participants. The Human Ethics Committee of the University of Western Australia approved the study protocol and consent form (approval no. 05/06/004/H50). The Human Research Ethics Committee of the Western Australian Department of Health also approved the data linkage study (approval no. 2009/24). For the GE images the study was approved by the Health Research Ethics Board for the University of Manitoba (HREB H2004:017L, HS20121). The Manitoba Health Information Privacy Committee approved access to the iDXA GE data and waived the requirement for signed consent (HIPC 2016/2017-29).</p><p>The study was supported by a National Health and Medical Research Council of Australia Ideas grant (APP1183570) and the Rady Innovation Fund, Rady Faculty of Health Sciences, University of Manitoba. The results and conclusions are those of the authors and no official endorsement by Manitoba Health and Seniors Care, or other data providers is intended or should be inferred. The salary of JRL is supported by a National Heart Foundation of Australia Future Leader Fellowship (ID: 102817). Also, SZG was partially funded by the Raine Priming Grant awarded by Raine Medical Research Foundation.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">AS: Supervised-contrastive-ordinal-loss</title>
		<ptr target="https://github.com/AfsahS/Supervised-Contrastive-Ordinal-Loss" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Supervised contrastive learning to classify paranasal anomalies in the maxillary sinus</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bhattacharya</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16437-8_41</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16437-841" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13433</biblScope>
			<biblScope unit="page" from="42" to="438" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Contrastive learning of global and local features for medical image segmentation with limited annotations</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chaitanya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Erdil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Karani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Konukoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Automated scoring of aortic calcification in vertebral fracture assessment images</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chaplin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Cootes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer-Aided Diagnosis</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note>Medical Imaging</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Adaptive contrast for image regression in computer-aided disease assessment</title>
		<author>
			<persName><forename type="first">W</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H K</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">T</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1255" to="1268" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Automatic detection and quantification of abdominal aortic calcification in dual energy x-ray absorptiometry</title>
		<author>
			<persName><forename type="first">K</forename><surname>Elmasri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pettit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Procedia Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="1011" to="1021" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Show, attend and detect: towards fine-grained assessment of abdominal aortic calcification on vertebral fracture assessment scans</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Gilani</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16437-8_42</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16437-8" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13433</biblScope>
			<biblScope unit="page">42</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Uncertainty-guided voxel-level supervised contrastive learning for semi-supervised medical image segmentation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Neural Syst</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">04</biblScope>
			<biblScope unit="page">2250016</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Scalp-supervised contrastive learning for cardiopulmonary disease classification and localization in chest X-rays using patient metadata</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jaiswal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE International Conference on Data Mining (ICDM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">New indices to classify location, severity and progression of calcific lesions in the abdominal aorta: a 25-year follow-up study</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">I</forename><surname>Kauppila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Polak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Cupples</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Hannan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kiel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Atherosclerosis</title>
		<imprint>
			<biblScope unit="volume">132</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="245" to="250" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Supervised contrastive learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Khosla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Vertebral fracture: epidemiology, impact and use of DXA vertebral fracture assessment in fracture liaison services</title>
		<author>
			<persName><forename type="first">W</forename><surname>Lems</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Osteoporos. Int</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="399" to="411" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Prognostic value of abdominal aortic calcification: a systematic review and meta-analysis of observational studies</title>
		<author>
			<persName><forename type="first">K</forename><surname>Leow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Heart Assoc</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">17205</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Long-term atherosclerotic vascular disease risk and prognosis in elderly women with abdominal aortic calcification on lateral spine images captured during bone density testing: a prospective study</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Bone Mineral Res</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1001" to="1010" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Abdominal aortic calcification identified on lateral spine images from bone densitometers are a marker of generalized atherosclerosis in elderly women</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Arterioscler. Thromb. Vasc. Biol</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="166" to="173" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Dual-stream multiple instance learning network for whole slide image classification with self-supervised contrastive learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Eliceiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">World Health Organization: Cardiovascular diseases (CVDS</title>
		<ptr target="https://www.who.int/en/news-room/fact-sheets/detail/cardiovascular-diseases-(cvds" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Machine learning for automated abdominal aortic calcification scoring of DXA vertebral fracture assessment images: a pilot study</title>
		<author>
			<persName><forename type="first">S</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Schousboe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kimelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Monchka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Jozani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">D</forename><surname>Leslie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bone</title>
		<imprint>
			<biblScope unit="volume">148</biblScope>
			<biblScope unit="page">115943</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Schousboe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kiel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Abdominal aortic calcification on dualenergy X-ray absorptiometry: methods of assessment and clinical significance</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="91" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Efficientnetv2: smaller models and faster training</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title/>
		<ptr target="https://www.tensorflow.org/" />
	</analytic>
	<monogr>
		<title level="j">Tensorflow.org: Tensorflow</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Van Der Vaart</surname></persName>
		</author>
		<title level="m">Asymptotic statistics</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Vertebral fracture assessment (VFA) for osteoporosis screening in us postmenopausal women: is it cost-effective?</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cosman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nieves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Osteoporos. Int</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="2321" to="2335" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Cross-level contrastive learning and consistency constraint for semi-supervised medical image segmentation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 19th International Symposium on Biomedical Imaging (ISBI)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
