<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Reversing the Abnormal: Pseudo-Healthy Generative Networks for Anomaly Detection</title>
				<funder ref="#_HE2zteK">
					<orgName type="full">Helmholtz Association</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Cosmin</forename><forename type="middle">I</forename><surname>Bercea</surname></persName>
							<email>cosmin.bercea@tum.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Technical University of Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Helmholtz AI and Helmholtz Center Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Benedikt</forename><surname>Wiestler</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Klinikum Rechts der Isar</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Rueckert</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Technical University of Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Klinikum Rechts der Isar</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Julia</forename><forename type="middle">A</forename><surname>Schnabel</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Technical University of Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Helmholtz AI and Helmholtz Center Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">King&apos;s College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Reversing the Abnormal: Pseudo-Healthy Generative Networks for Anomaly Detection</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="293" to="303"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">8C5EBE112EE345E1BEDC596E99ABE9A2</idno>
					<idno type="DOI">10.1007/978-3-031-43904-9_29</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-01T10:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Unsupervised Anomaly Detection â€¢ Generative Networks</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Early and accurate disease detection is crucial for patient management and successful treatment outcomes. However, the automatic identification of anomalies in medical images can be challenging. Conventional methods rely on large labeled datasets which are difficult to obtain. To overcome these limitations, we introduce a novel unsupervised approach, called PHANES (Pseudo Healthy generative networks for ANomaly Segmentation). Our method has the capability of reversing anomalies, i.e., preserving healthy tissue and replacing anomalous regions with pseudo-healthy (PH) reconstructions. Unlike recent diffusion models, our method does not rely on a learned noise distribution nor does it introduce random alterations to the entire image. Instead, we use latent generative networks to create masks around possible anomalies, which are refined using inpainting generative networks. We demonstrate the effectiveness of PHANES in detecting stroke lesions in T1w brain MRI datasets and show significant improvements over state-of-the-art (SOTA) methods. We believe that our proposed framework will open new avenues for interpretable, fast, and accurate anomaly segmentation with the potential to support various clinical-oriented downstream tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The early detection of lesions in medical images is critical for the diagnosis and treatment of various conditions, including neurological disorders. Stroke is a leading cause of death and disability, where early detection and treatment can significantly improve patient outcomes. However, the quantification of lesion burden is challenging and can be time-consuming and subjective when performed manually by medical professionals <ref type="bibr" target="#b13">[14]</ref>. While supervised learning methods <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref> have proven to be effective in lesion segmentation, they rely heavily on large Fig. <ref type="figure">1</ref>. Overview of PHANES (see Fig. <ref type="figure" target="#fig_0">2</ref>). Our method can use both expert annotatedor unsupervised generated masks to reverse and segment anomalies annotated datasets for training and tend to generalize poorly beyond the learned labels <ref type="bibr" target="#b20">[21]</ref>. On the other hand, unsupervised methods focus on detecting patterns that significantly deviate from the norm by training only on normal data.</p><p>One widely used category of unsupervised methods is latent restoration methods. They involve autoencoders (AEs) that learn low-dimensional representations of data and detect anomalies through inaccurate reconstructions of abnormal samples <ref type="bibr" target="#b16">[17]</ref>. However, developing compact and comprehensive representations of the healthy distribution is challenging <ref type="bibr" target="#b0">[1]</ref>, as recent studies suggest AEs perform better reconstructions on out-of-distribution (OOD) samples than on training samples <ref type="bibr" target="#b22">[23]</ref>. Various techniques have been introduced to enhance representation learning, including discretizing the latent space <ref type="bibr" target="#b14">[15]</ref>, disentangling compounding factors <ref type="bibr" target="#b1">[2]</ref>, and variational autoencoders (VAEs) that introduce a prior into the latent distribution <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b28">29]</ref>. However, methods that can enforce the reconstruction of healthy generally tend to produce blurry reconstructions.</p><p>In contrast, generative adversarial networks (GANs) <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b23">24]</ref> are capable of producing high-resolution images. New adversarial AEs combine VAEs' latent representations with GANs' generative abilities, achieving SOTA results in image generation and outlier detection <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b18">19]</ref>. Nevertheless, latent methods still face difficulties in accurately reconstructing data from their low-dimensional representations, causing false positive detections on healthy tissues.</p><p>Several techniques have been proposed that make use of the inherent spatial information in the data rather than relying on constrained latent representations <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b29">30]</ref>. These methods are often trained on a pretext task, such as recovering masked input content <ref type="bibr" target="#b29">[30]</ref>. De-noising AEs <ref type="bibr" target="#b11">[12]</ref> are trained to eliminate synthetic noise patterns, utilizing skip connections to preserve the spatial information and achieve SOTA brain tumor segmentation. However, they heavily rely on a learned noise model and may miss anomalies that deviate from the noise distribution <ref type="bibr" target="#b0">[1]</ref>. More recently, diffusion models <ref type="bibr" target="#b8">[9]</ref> apply a more complex de-noising process to detect anomalies <ref type="bibr" target="#b24">[25]</ref>. However, the choice and granularity of the applied noise is crucial for breaking the structure of anomalies <ref type="bibr" target="#b24">[25]</ref>. Adapting the noise distribution to the diversity and heterogeneity of pathology is inherently difficult, and even if achieved, the noising process disrupts the structure of both healthy and anomalous regions throughout the entire image.</p><p>In related computer vision areas, such as industrial inspection <ref type="bibr" target="#b2">[3]</ref>, the topperforming methods do not focus on reversing anomalies, but rather on detecting them by using large nominal banks <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b19">20]</ref>, or pre-trained features from large natural imaging datasets like ImageNet <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b21">22]</ref>. Salehi et al. <ref type="bibr" target="#b21">[22]</ref> have employed multi-scale knowledge distillation to detect anomalies in industrial and medical imaging. However, the application of these networks in medical anomaly segmentation, particularly in brain MRI, is limited by various challenges specific to the medical imaging domain. They include the variability and complexity of normal data, subtlety of anomalies, limited size of datasets, and domain shifts.</p><p>This work aims to combine the advantages of constrained latent restoration for understanding healthy data distribution with generative in-painting networks. Unlike previous methods, our approach does not rely on a learned noise model, but instead creates masks of probable anomalies using latent restoration. These guide generative in-painting networks to reverse anomalies, i.e., preserve healthy tissues and produce pseudo-healthy in-painting in anomalous regions. We believe that our proposed method will open new avenues for interpretable, fast, and accurate anomaly segmentation and support various clinical-oriented downstream tasks, such as investigating progression of disease, patient stratification and treatment planning. In summary our main contributions are:</p><p>â€¢ We investigate and measure the ability of SOTA methods to reverse synthetic anomalies on real brain T1w MRI data. â€¢ We propose a novel unsupervised segmentation framework, that we call PHANES, that is able to preserve healthy regions and utilize them to generate pseudo-healthy reconstructions on anomalous regions. â€¢ We demonstrate a significant advancement in the challenging task of unsupervised ischemic stroke lesion segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>Latent restoration methods use neural networks to estimate the parameters Î¸, Ï† of an encoder E Î¸ and a decoder D Ï† . The aim is to restore the input from its lower-dimensional latent representation with minimal loss. The standard objective is to minimize the residual, e.g., using mean squared error (MSE) loss:</p><formula xml:id="formula_0">min Î¸,Ï† N i=1 x i -D Ï† (E Î¸ (x i )) 2 .</formula><p>In the context of variational inference <ref type="bibr" target="#b12">[13]</ref>, the goal is to optimize the parameters Î¸ of a latent variable model p Î¸ (x) by maximizing the log-likelihood of the observed samples x: log p Î¸ (x). The term is intractable, but the true posterior p Î¸ (z|x) can be approximated by q Ï† (z|x):</p><formula xml:id="formula_1">log p Î¸ (x) â‰¥ E q(z|x) [log p Î¸ (x|z)] -KL[q Ï† (z|x)||p(z)] = ELBO(x).</formula><p>(</p><formula xml:id="formula_2">)<label>1</label></formula><p>KL is the Kullback-Leibler divergence; q Ï† (z|x) and p Î¸ (x|z) are usually known as the encoder E Ï† and decoder D Î¸ ; the prior p(z) is usually the normal distribution N (Î¼ 0 , Ïƒ 0 ); and the ELBO denotes the Evidence Lower Bound. In unsupervised anomaly detection, the networks are trained only on normal samples x âˆˆ X âŠ‚ R N . Given an anomalous input x / âˆˆ X , it is assumed that the reconstruction x ph = (D Ï† (E Î¸ (x))) âˆˆ X represents its pseudo-healthy version. The aim of the pseudo-healthy reconstructions is to accurately reverse abnormalities present in the input images. This is achieved by preserving the healthy regions while generating healthy-like tissues in anomalous regions. Thus, anomalies can ideally be directly localized by computing the difference between the anomalous input and the pseudo-healthy reconstructions: s(x) = |x -x ph |.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>Figure <ref type="figure" target="#fig_0">2</ref> shows an overview of our proposed method. We introduce an innovative approach by utilizing masks produced by latent generative networks to condition generative inpainting networks only on healthy tissues. Our framework is modular, which allows for the flexibility of choosing a preferred generative network, such as adversarial, or diffusion-based models for predicting the pseudo-healthy reconstructions. In the following we describe each component in detail. Latent Generative Network. The first step involves generating masks to cover potential anomalous regions in the input image. The goal of this step is to achieve unbiased detection of various pathologies and minimize false positives. It is therefore important to use a method that is restricted to in-distribution samples, particularly healthy samples, while also accurately reconstructing inputs. Here, we have adopted our previous work <ref type="bibr" target="#b0">[1]</ref> that augments a soft introspective variational auto-encoder with a reversed embedding similarity loss with the aim to enforcing more accurate pseudo-healthy reconstructions. The training process encourages the encoder to distinguish between real and generated samples by minimizing the Kullback-Leibler (KL) divergence of the latent distribution of real samples and the prior, and maximizing the KL divergence of generated samples. On the other hand, the decoder is trained to deceive the encoder by reconstructing real data samples using the standard ELBO and minimizing the KL divergence of generated samples compressed by the encoder:</p><formula xml:id="formula_3">L E Ï† (x, z) = ELBO(x) - 1 Î± (exp(Î±ELBO(D Î¸ (z)) + Î»L Reversed (x),<label>(2)</label></formula><formula xml:id="formula_4">L Reversed (x) = L l=0 (1 -L Sim (E l Ï† (x), E l Ï† (x cph )) + 1 2 MSE(E l Ï† (x), E l Ï† (x cph )), L D Î¸ (x, z) = ELBO(x) + Î³ELBO(D Î¸ (z)),</formula><p>where E l Ï† is the l-th embedding of the L encoder layers,</p><formula xml:id="formula_5">x cph = D Î¸ (E Ï† (x))</formula><p>, and L Sim is the cosine similarity. Mask Generation. Simple residual errors have a strong dependence on the underlying intensities <ref type="bibr" target="#b15">[16]</ref>. As it is important to assign higher values to (subtle) pathological structures, we compute anomaly masks as proposed in <ref type="bibr" target="#b0">[1]</ref> by applying adaptive histogram equalization (eq), normalizing with the 95th percentile, and augmenting the errors with perceptual differences for robustness:</p><formula xml:id="formula_6">m(x) = norm 95 (|(eq(x cph ) -eq(x)|) * S lpips (eq(x cph ), eq(x)),<label>(3)</label></formula><p>with S lpips being the learned perceptual image patch similarity <ref type="bibr" target="#b27">[28]</ref>. Finally, we binarize the masks using the 99th percentile value on the healthy validation set.</p><p>Inpainting Generative Network. The objective of the refined PH generative network is to complete the masked image by utilizing the remaining healthy tissues to generate a full PH version of the input. Considering computational efficiency, we have employed the recent in-painting AOT-GAN <ref type="bibr" target="#b26">[27]</ref>. The method uses a generator (G) and discriminator neural network to optimize losses based on residual and perceptual differences, resulting in accurate and visually precise inpainted images. Additionally, the discriminator predicts the input mask from the inpainted image to improve the synthesis of fine textures. Anomaly Maps. The PH reconstruction is computed as follows:</p><formula xml:id="formula_7">x ph = x (1 -m) + G(x (1 -m), m</formula><p>) m, with being the pixel-wise multiplication. We compute the final anomaly maps based on residual and perceptual differences:</p><formula xml:id="formula_8">s(x) = |x ph -x| * S lpips (x ph , x) (4)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Datasets. We trained our model using two publicly available brain T1w MRI datasets, including FastMRI+ (131 train, 15 val, 30 test) and IXI (581 train samples), to capture the healthy distribution. Performance evaluation was done on a large stroke T1-weighted MRI dataset, ATLAS v2.0 <ref type="bibr" target="#b13">[14]</ref>, containing 655 images  with manually segmented lesion masks for training and 355 test images with hidden lesion masks. We evaluated the model using the 655 training images with public annotations. The mid axial slices were normalized to the 98 th percentile, padded, and resized to 128 Ã— 128 resolution. During training, we performed random rotations up to 10 â€¢ , translations up to 0.1, scaling from 0.9 to 1.1, and horizontal flips with a 0.5 probability. We trained for 1500 epochs, with a batch size of 8, lr of 5e -5 , and early stopping.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Reversing Synthetic Anomalies</head><p>In this section, we test whether reconstruction-based methods can generate pseudo-healthy images and reverse synthetic anomalies. Results are evaluated in Table <ref type="table" target="#tab_0">1</ref> and Fig. <ref type="figure" target="#fig_1">3</ref> using 30 test images and synthetic masks as reference.</p><p>VAEs produce blurry results that lead to poor reconstruction of both healthy and anomalous regions (LPIPS) and thus poor segmentation performance. While DAEs preserve the healthy tissues well with an LPIPS of 3.94, they do not gen- erate pseudo-healthy reconstructions in anomalous regions (LPIPS â‰ˆ 20). However, they change the intensity of some structures, e.g., hypo-intensities, allowing for improved detection accuracy (see AUPRC and Dice). Simplex noise in <ref type="bibr" target="#b24">[25]</ref> is designed to detect large hypo-intense lesions, leaving small anomalies undetected by AnoDDPM. SI-VAEs and RA produce pseudo healthy versions of the abnormal inputs, with the latter achieving the best results among the baselines. Our proposed method, PHANES, successfully reverses the synthetic anomalies, with its reconstructions being the most similar to ground truth healthy samples, as can be seen in Fig. <ref type="figure" target="#fig_1">3</ref>. It achieved an improvement of 77% and 47% in generating pseudo-healthy samples in healthy and anomalous regions, respectfully. This enables the precised localization of anomalies (see bottom row in Fig. <ref type="figure" target="#fig_1">3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Ischemic Stroke Lesion Segmentation on T1w Brain MRI</head><p>In this section, we evaluate the performance of our approach in segmenting stroke lesions and show the results in Table <ref type="table" target="#tab_1">2</ref> and Fig. <ref type="figure" target="#fig_2">4</ref>. For completeness, we compare our approach to teacher-student methods that use multi-scale knowledge distillation (MKD) for anomaly segmentation. The unsupervised detection of (subtle) stroke lesions is challenging. The lack of healthy data from the same scanner and the limited size of the healthy datasets limit the successful application of such methods, with a maximum achievable Dice score of just under 6%. On the other hand, PatchCore, which is currently the SOTA method in industrial anomaly detection, has demonstrated comparable performance to the top-performing baselines. VAEs yield many false positive detections due to the blurry reconstructions and achieve poor localization results. DAEs can identify anomalies that resemble the learned noise distribution and improve segmentation results (AUPRC of 9.22), despite not producing pseudo-healthy reconstructions of abnormal samples (see Subsect. 4.1). The best performing latent restoration method is RA, achieving a remarkable 79% improvement over SI-VAE. Unlike experiments in Subsect. 4.1, the Simplex noise aligns more closely with the hypointense pathology distribution of stroke in T1w brain MRI. As a result, AnoD-DPM achieves the highest detection accuracy among the baselines. Compared to AnoDDPM, PHANES increases the detection results by 22% AUPRC. Figure <ref type="figure" target="#fig_2">4</ref> shows a visual comparison between the two approaches. Diffusion models tend to be more susceptible to domain shifts (first three rows) and yield more false positives. In contrast, PHANES demonstrates more precise localization, especially for subtle anomalies (bottom rows). Generally, unsupervised methods tend to have lower Dice scores partly due to unlabeled artefacts in the dataset. These include non-pathological (rows 1,2) as well as other pathological effects, such as changes in ventricle structure (rows 3,4). PHANES correctly identifies these as anomalous, but their lack of annotation limits numerical evaluations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>This paper presents a novel unsupervised anomaly segmentation framework, called PHANES. It possesses the ability to reverse anomalies in medical images by preserving healthy tissues and substituting anomalous regions with pseudohealthy reconstructions. By generating pseudo-healthy versions of images containing anomalies, PHANES can be a useful tool in supporting clinical studies. While we are encouraged by these achievements, we also recognize certain limitations and areas for improvement. For example, the current binarization of anomaly maps does not account for the inherent uncertainty in the maps, which we aim to explore in future research. Additionally, our method relies on accurate initial estimates of the latent restoration and anomaly maps. Nevertheless, our proposed concept is independent of specific approaches and can leverage advancements in both domains. Our method is not optimized for detecting a certain anomaly distribution but rather demonstrates robustness in handling various small synthetic anomalies and diverse stroke lesions. We look forward to generalizing our method to other anatomies and imaging modalities, paving the way for exciting future research in the field of anomaly detection.</p><p>In conclusion, we demonstrated exceptional performance in reversing synthetic anomalies and segmenting stroke lesions on brain T1w MRIs. We believe that deliberate masking of (possible) abnormal regions will pave new ways for novel anomaly segmentation methods and empower further clinical applications.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. PHANES overview. Our framework offers modularity, enabling the choice of preferred generative networks, such as adversarial or diffusion-based models. First, we use latent generative networks to learn the healthy data distribution and provide approximate pseudo-healthy reconstructions x cph . Anomaly maps m obtained from this step are then used to mask out possible anomalous regions in the input. The remaining healthy tissues are used to condition the refined generative networks, which complete the image and replace anomalous regions with pseudo-healthy tissues. This results in accurate PH reconstructions x ph , which enables the precise localization of diseases, as shown on the right.</figDesc><graphic coords="4,44,79,54,38,334,48,95,32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Reversing synthetic anomalies. PHANES successfully removes synthetic anomalies and produces the most accurate pseudo-healthy reconstructions.</figDesc><graphic coords="6,73,80,265,94,276,28,88,60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig.4. Stroke lesion segmentation. We show input images with expert annotations in red along with masked images generated by the latent generative networks in Fig.2, pseudo-healthy reconstructions, and anomaly maps. On the right, we show the performance of diffusion models on the same inputs. Different rows show cases ranging from large anomalies at the top to more subtle ones at the bottom. Green arrows mark unlabeled anomalies. PHANES successfully reverses the anomalies and accurately localizes even very subtle anomalies.</figDesc><graphic coords="8,44,79,53,87,334,51,277,84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Reversing synthetic anomalies. We evaluate the pseudo-healthy (PH) reconstruction on healthy and anomalous regions using the learned perceptual image patch similarity (LPIPS)<ref type="bibr" target="#b27">[28]</ref> and the anomaly segmentation performance. PHANES GT represents an upper bound and uses the ground truth anomalies to mask the image for inpainting. x% shows improvement over best baseline (RA) and x% shows the decrease in performance compared to PHANES.485%  19.01 135% 17.91 77% 31.30 59% AnoDDPM [25] 6.64 195% 19.46 140% 14.85 81% 19.89 74% DAE [12] 3.94 75% 20.05 148% 35.73 54% 37.76 50% VAE [29] 33.22 1376% 44.00 443% 22.86 71% 28.46 62%</figDesc><table><row><cell>Method</cell><cell cols="4">PH Reconstruction (LPIPS) Anomaly Segmentation</cell></row><row><cell></cell><cell>Healthy â†“</cell><cell>Anomaly â†“</cell><cell>AUPRC â†‘</cell><cell>DICE â†‘</cell></row><row><cell cols="2">PHANES GT (ours) 0.09 N/A</cell><cell>0.94 94%</cell><cell cols="2">100 37% 100 46%</cell></row><row><cell>PHANES (ours)</cell><cell>2.25 77%</cell><cell>8.10 47%</cell><cell cols="2">77.93 7% 75.47 10%</cell></row><row><cell>RA [1]</cell><cell>9.74 333%</cell><cell>15.27 89%</cell><cell cols="2">73.01 6% 68.52 9%</cell></row><row><cell>SI-VAE [6]</cell><cell>13.16</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Ischemic stroke lesion segmentation on real T1w brain MRIs. x% shows improvement over AnoDDPM, and x% shows the decrease in performance compared to PHANES. * marks statistical significance (p &lt; 0.05).</figDesc><table><row><cell>Method</cell><cell>AUPRC â†‘</cell><cell>DICE â†‘</cell></row><row><cell cols="3">PHANES (ours) 19.96 Â± 2.3  *  22% 32.17 Â± 2.0  *  16%</cell></row><row><cell>AnoDDPM [25]</cell><cell>16.33 Â± 1.7 18%</cell><cell>27.64 Â± 1.4 14%</cell></row><row><cell>RA [1]</cell><cell>12.30 Â± 1.0 38%</cell><cell>22.20 Â± 1.5 31%</cell></row><row><cell>PatchCore [20]</cell><cell>12.24 Â± 0.7 39%</cell><cell>24.79 Â± 1.2 23%</cell></row><row><cell>DAE [12]</cell><cell>9.22 Â± 1.3 54%</cell><cell>15.62 Â± 2.1 53%</cell></row><row><cell>SI-VAE [6]</cell><cell>6.86 Â± 0.6 66%</cell><cell>13.57 Â± 0.9 58%</cell></row><row><cell>MKD [22]</cell><cell>2.93 Â± 0.3 85%</cell><cell>5.91 Â± 0.6 82%</cell></row><row><cell>VAE [29]</cell><cell>2.76 Â± 0.2 86%</cell><cell>5.96 Â± 0.3 81%</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement. C.I.B. is in part supported by the <rs type="funder">Helmholtz Association</rs> under the joint research school "<rs type="programName">Munich School for Data Science -MUDS</rs>".</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_HE2zteK">
					<orgName type="program" subtype="full">Munich School for Data Science -MUDS</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Generalizing unsupervised anomaly detection: towards unbiased pathology screening</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">I</forename><surname>Bercea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wiestler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Schnabel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Conference on Medical Imaging with Deep Learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Federated disentangled representation learning for unsupervised brain anomaly detection</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">I</forename><surname>Bercea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wiestler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Albarqouni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="685" to="695" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">MVTec AD -a comprehensive real-world dataset for unsupervised anomaly detection</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sattlegger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Steger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="9584" to="9592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Uninformed students: studentteacher anomaly detection with discriminative latent embeddings</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sattlegger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Steger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4183" to="4192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Unsupervised detection of lesions in brain MRI using constrained adversarial auto-encoders</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Konukoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Imaging with Deep Learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Soft-IntroVAE: analyzing and improving the introspective variational autoencoder</title>
		<author>
			<persName><forename type="first">T</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tamar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4391" to="4400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">PaDiM: a patch distribution modeling framework for anomaly detection and localization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Defard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Setkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Loesch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Audigier</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-68799-1_35</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-68799-1_35" />
	</analytic>
	<monogr>
		<title level="m">ICPR 2021</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Del Bimbo</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12664</biblScope>
			<biblScope unit="page" from="475" to="489" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Denoising diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6840" to="6851" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">DeepMedic for brain tumor segmentation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kamnitsas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Computing and Computer Assisted Intervention BrainLes Workshop</title>
		<imprint>
			<biblScope unit="page" from="138" to="149" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kamnitsas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="61" to="78" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Denoising autoencoders for unsupervised anomaly detection in brain MRI</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kascenas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Pugeault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Q</forename><surname>O'neil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Imaging with Deep Learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<title level="m">Auto-encoding variational bayes</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A large, curated, open-source stroke neuroimaging dataset to improve lesion segmentation algorithms</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Liew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">P</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Miarnda</surname></persName>
		</author>
		<author>
			<persName><surname>Donnelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Data</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">230</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Abnormality detection in chest x-ray images using uncertainty prediction autoencoders</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F.-F</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59725-2_51</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-59725-2_51" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12266</biblScope>
			<biblScope unit="page" from="529" to="538" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">On the pitfalls of using the residual error as anomaly score</title>
		<author>
			<persName><forename type="first">F</forename><surname>Meissen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wiestler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kaissis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.03826</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Unsupervised lesion detection in brain CT using Bayesian convolutional autoencoders</title>
		<author>
			<persName><forename type="first">N</forename><surname>Pawlowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Imaging with Deep Learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">OCGAN: one-class novelty detection using GANs with constrained latent representations</title>
		<author>
			<persName><forename type="first">P</forename><surname>Perera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2898" to="2906" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Unsupervised brain imaging 3d anomaly detection and segmentation with transformers</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Pinaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page">102475</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Towards total recall in industrial anomaly detection</title>
		<author>
			<persName><forename type="first">K</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pemula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zepeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>SchÃ¶lkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gehler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="14318" to="14328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A unifying review of deep and shallow anomaly detection</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ruff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multiresolution knowledge distillation for anomaly detection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Salehi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sadjadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baselizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Rohban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Rabiee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="14902" to="14912" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Understanding anomaly detection with deep invertible networks through hierarchies of distributions and features</title>
		<author>
			<persName><forename type="first">R</forename><surname>Schirrmeister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Proc. Syst</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="21038" to="21049" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">f-AnoGAN: fast unsupervised anomaly detection with generative adversarial networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Schlegl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>SeebÃ¶ck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Waldstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Langs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Schmidt-Erfurth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="30" to="44" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Anoddpm: anomaly detection with denoising diffusion probabilistic models using simplex noise</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wyatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Leach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Schmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Willcocks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2022-06">June 2022</date>
			<biblScope unit="page" from="650" to="656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Unsupervised lesion detection via image restoration with a normative prior</title>
		<author>
			<persName><forename type="first">S</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Tezcan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Konukoglu</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Imaging with Deep Learning</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="540" to="556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Aggregated contextual transformations for high-resolution image inpainting</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="3266" to="3280" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The unreasonable effectiveness of deep features as a perceptual metric</title>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="586" to="595" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Unsupervised anomaly localization using variational auto-encoders</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zimmerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Isensee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Maier-Hein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-32251-9_32</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-32251-9_32" />
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer Assisted Intervention -MICCAI 2019</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11767</biblScope>
			<biblScope unit="page" from="289" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Zimmerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Kohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Isensee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Maier-Hein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.05941</idno>
		<title level="m">Contextencoding variational autoencoder for unsupervised anomaly detection</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
