<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multimodal Brain Age Estimation Using Interpretable Adaptive Population-Graph Learning</title>
				<funder ref="#_FmwSyCg">
					<orgName type="full">EPSRC Centre for Doctoral Training in Medical Imaging</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Kyriaki-Margarita</forename><surname>Bintsi</surname></persName>
							<email>m.bintsi19@imperial.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vasileios</forename><surname>Baltatzis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Biomedical Engineering and Imaging Sciences</orgName>
								<orgName type="institution">King&apos;s College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rolandos</forename><forename type="middle">Alexandros</forename><surname>Potamias</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexander</forename><surname>Hammers</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Biomedical Engineering and Imaging Sciences</orgName>
								<orgName type="institution">King&apos;s College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Rueckert</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Technical University of Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multimodal Brain Age Estimation Using Interpretable Adaptive Population-Graph Learning</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="195" to="204"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">90F8C5B04A501AB6D93A92284EBBD4FC</idno>
					<idno type="DOI">10.1007/978-3-031-43993-3_19</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-01T10:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Brain age regression</term>
					<term>Interpretability</term>
					<term>Graph Convolutional Networks</term>
					<term>Adaptive graph learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Brain age estimation is clinically important as it can provide valuable information in the context of neurodegenerative diseases such as Alzheimer's. Population graphs, which include multimodal imaging information of the subjects along with the relationships among the population, have been used in literature along with Graph Convolutional Networks (GCNs) and have proved beneficial for a variety of medical imaging tasks. A population graph is usually static and constructed manually using non-imaging information. However, graph construction is not a trivial task and might significantly affect the performance of the GCN, which is inherently very sensitive to the graph structure. In this work, we propose a framework that learns a population graph structure optimized for the downstream task. An attention mechanism assigns weights to a set of imaging and non-imaging features (phenotypes), which are then used for edge extraction. The resulting graph is used to train the GCN. The entire pipeline can be trained end-to-end. Additionally, by visualizing the attention weights that were the most important for the graph construction, we increase the interpretability of the graph. We use the UK Biobank, which provides a large variety of neuroimaging and non-imaging phenotypes, to evaluate our method on brain age regression and classification. The proposed method outperforms competing static graph approaches and other state-of-the-art adaptive methods. We further show that the assigned attention scores indicate that there are both imaging and non-imaging phenotypes that are informative for brain age estimation and are in agreement with the relevant literature.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Healthy brain aging follows specific patterns <ref type="bibr" target="#b1">[2]</ref>. However, various neurological diseases, such as Alzheimer's disease <ref type="bibr" target="#b7">[8]</ref>, Parkinson's disease <ref type="bibr" target="#b22">[23]</ref>, and schizophrenia <ref type="bibr" target="#b17">[18]</ref>, are accompanied by an abnormal accelerated aging of the human brain. Thus, the difference between the biological brain age of a person and their chronological age can show the deviation from the healthy aging trajectory, and may prove to be an important biomarker for neurodegenerative diseases <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b8">9]</ref>.</p><p>Recently, graph-based methods have been explored for brain age estimation as graphs can inherently combine multimodal information by integrating the subjects' neuroimaging information as node features and, through a similarity metric, the associations among subjects through as edges that connect these nodes <ref type="bibr" target="#b20">[21]</ref>. However, in medical applications, the construction of a population-graph is not always simple as there are various ways subjects could be considered similar.</p><p>GCNs <ref type="bibr" target="#b15">[16]</ref> have been extensively <ref type="bibr" target="#b0">[1]</ref> used in the medical domain for node classification tasks, such as Alzheimer's prediction <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b20">21]</ref> and Autism classification <ref type="bibr" target="#b3">[4]</ref>. They take graphs as input and, in most cases, the graph structure is predefined and static. GCN performance is highly dependent on the graph structure. This has been correlated in related literature with the heterophily of graphs in the semi-supervised node classification tasks, which refers to the case when the nodes of a graph are connected to nodes that have dissimilar features and different class labels <ref type="bibr" target="#b29">[29]</ref>. It has been shown that if the homophily ratio is very low, a simple Multi-Layer Perceptron (MLP) that completely ignores the structure, can outperform a GCN <ref type="bibr" target="#b30">[30]</ref>.</p><p>A way to address this problem is through adaptive graph learning <ref type="bibr" target="#b27">[27]</ref>, which learns the graph structure through training. In the medical domain, there is little ongoing research on the topic <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b28">28]</ref>. However, the adaptive graphs in <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14]</ref> Fig. <ref type="figure">1</ref>. Proposed methodology: The non-imaging features q i and a subset of the imaging features si ⊆ xi per subject i are used as input to a MLP, which produces attention weights for each one of these features. Based on these, the edges of the graph are stochastically sampled using the Gumbel-Top-k trick. The constructed graph, which uses the imaging features X as node features is used to train a GCN for brain age estimation tasks.</p><p>are connected based on the imaging features and do not take advantage of the associations of the non-imaging information for the edges. In <ref type="bibr" target="#b10">[11]</ref>, non-imaging information is used for graph connectivity, but the edges are already pre-pruned similar to <ref type="bibr" target="#b20">[21]</ref>, and only the weights of the edges can be modified. In <ref type="bibr" target="#b26">[26]</ref>, even though the graph is dynamic, it is not being learnt. While the extracted graphs in these studies are optimized for the task at hand, there is no explanation for the node connections that were proposed. Given that interpretability is essential in the medical domain <ref type="bibr" target="#b23">[24]</ref>, since the tools need to be trusted by the clinicians, an adaptive graph learnt during the training, whose connections are also interpretable and clear can prove important. Additionally, most existing works focus on brain age classification in four bins, usually classifying the subjects per decade <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14]</ref>. Age regression, which is a more challenging task, has not been extensively explored with published results not reaching sufficient levels of performance <ref type="bibr" target="#b25">[25]</ref>.</p><p>Contributions. This paper has the following contributions: 1) We combine imaging and non-imaging information in an attention-based framework to learn adaptively an optimized graph structure for brain age estimation. 2) We propose a novel graph loss that enables end-to-end training for the task of brain age regression. 3) Our framework is inherently interpretable as the attention mechanism allows us to rank all imaging and non-imaging phenotypes according to their significance for the task. 4) We evaluate our method on the UK Biobank (UKBB) and achieve state-of-the-art results on the tasks of brain age regression and classification. The code can be found on GitHub at: https://github.com/ bintsi/adaptive-graph-learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>Given a set of N subjects with M features X = [x 1 , ..., x N ] ∈ R N ×M and labels y ∈ R N , a population graph is defined as G = {V, E}, where V is a set of nodes, one per subject, and E is a set of paired nodes that specifies the connectivity of the graph, meaning the edges of the graph. To create an optimized set of edges for the task of brain age estimation, we leverage a set of non-imaging phenotypes q i ∈ R Q and a set of imaging phenotypes s i ∈ R S per subject i through an attention-based framework. The imaging phenotypes are a subset of the imaging features s i ⊆ x i . The phenotypes are selected according to <ref type="bibr" target="#b4">[5]</ref>. The resulting graph is used as input in a GCN that performs node-level prediction tasks. Here, we give a detailed description of the proposed architecture, in which the connectivity of the graph E, is learnt through end-to-end training in order to find the optimal graph structure for the task of brain age estimation. An outline of the proposed pipeline may be found in Fig. <ref type="figure">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Attention Weights Extraction.</head><p>Based on the assumption that not all phenotypes are equally important for the construction of the graph, we train a MLP g θ , with parameters θ, which takes as input both the non-imaging features q i and the imaging features s i for every subject i and outputs an attention weight vector a ∈ R Q+S , where every element of a corresponds to a specific phenotype. Intuitively, we expect that the features that are relevant to brain age estimation will get attention weights close to 1, and close to 0 otherwise. Since we are interested in the overall relevance of the phenotypes for the task, the output weights need to be global and apply to all of the nodes. To do so, we average the attention weights across subjects and normalize them between 0 and 1.</p><p>Edge Extraction. The weighted phenotypes for each subject i are calculated as f i = a (q i s i ), where f i ∈ R Q+S , a are the attention weights produced by the MLP g θ , (• •) denotes the concatenation function between two vectors and denotes the Hadamard product. We further define the probability p ij (f i , f j ; θ, t) of a pair of nodes (i, j) ∈ V to be connected in Eq. ( <ref type="formula">1</ref>):</p><formula xml:id="formula_0">p ij (f i , f j ; θ, t) = e -td(fi,fj ) 2 (1)</formula><p>where t is a learnable parameter and d is a distance function that calculates the distance between the weighted phenotypes of two nodes. To keep the memory cost low, we create a sparse k-degree graph. We use the Gumbel-Top-k trick <ref type="bibr" target="#b16">[17]</ref>, which acts as a stochastic relaxation of the kNN rule, in order to sample k edges for every node according to the probability matrix P ∈ R N ×N . Since there is stochasticity in the sampling scheme, multiple runs are performed at inference time and the predictions are averaged.</p><p>Optimization. The extracted graph is used as input, along with the imaging features X, which are used as node features, to a GCN g ψ , with parameters ψ, which comprises of a number of graph convolutional layers, followed by fully connected layers. The pipeline is trained end-to-end with a loss function L that consists of two components and is defined as in Eq. ( <ref type="formula" target="#formula_1">2</ref>).</p><formula xml:id="formula_1">L = L GCN + L graph . (<label>2</label></formula><formula xml:id="formula_2">)</formula><p>The first component, L GCN , is optimizing the GCN, g ψ . For regression we use the Huber loss <ref type="bibr" target="#b11">[12]</ref>, while for classification we use the Cross Entropy loss function.</p><p>The second component, L graph , optimizes the MLP g θ , whose output are the phenotypes' attention weights. However, the graph is sparse with discrete edges and hence the network cannot be trained with backpropagation as is. To alleviate this issue, we formulate our graph loss in a way that rewards edges that lead to correct predictions and penalize edges that lead to wrong predictions. Inspired by <ref type="bibr" target="#b12">[13]</ref>, where a similar approach was used for classification, the proposed graph loss function is designed for regression instead and is defined in Eq. ( <ref type="formula" target="#formula_3">3</ref>):</p><formula xml:id="formula_3">L graph = (i,j)∈E ρ(y i , g ψ (x i )) log(p ij ),<label>(3)</label></formula><p>where ρ(•, •) is the reward function which is defined in Eq. (4):</p><formula xml:id="formula_4">ρ(y i , g ψ (x i )) = |y i -g ψ (x i )| -ε (<label>4</label></formula><formula xml:id="formula_5">)</formula><p>Here ε is the null model's prediction (i.e. the average brain age of the training set). Intuitively, when the prediction error |y ig ψ (x i )| is smaller than the null model's prediction then the reward function will be negative. In turn, this will encourage the maximization of p ij so that L graph is minimized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>Dataset. The proposed framework is evaluated on the UKBB <ref type="bibr" target="#b2">[3]</ref>, which provides not only a wide collection of images of vital organs, including brain scans, but also various non-imaging information, such as demographics, and biomedical, lifestyle, and cognitive performance measurements. Hence, it is perfectly suitable for brain age estimation tasks that incorporate the integration of imaging and non-imaging information. Here, we use 68 neuroimaging phenotypes and 20 non-imaging phenotypes proposed by <ref type="bibr" target="#b4">[5]</ref> as the ones most relevant to brain age in UKBB. The neuroimaging features are provided by UKBB, and include measurements extracted from structural MRI and diffusion weighted MRI. All phenotypes are normalized from 0 to 1. The age range of the subjects is 47-81 years. We only keep the subjects that have available the necessary phenotypes ending up with about 6500 subjects. We split the dataset into 75% for the training set, 5% for the validation set, and 20% for the test set. Our pipeline has been primarily designed to tackle the challenging regression task and therefore the main experiment is brain age regression. We also evaluate our framework on the 4-class classification task that has been used in other related papers.</p><p>Baselines. Given that a GCN trained on a meaningless graph can perform even worse than a simple regressor/classifier, our first baseline is a Linear/Logistic Regression model. For the second baseline, we construct a static graph based on a similarity metric, more specifically cosine similarity, of a set of features (either node features or non-imaging and imaging phenotypes) using the kNN rule with k = 5 and train a GCN on that graph. Using euclidean distance as the similarity metric leads to worse performance and is therefore not explored for the baselines. We also compare our method with DGM, which is the state-ofthe-art on graph learning for medical applications <ref type="bibr" target="#b12">[13]</ref>. Since this work is only applicable for classification tasks, we extend it to regression, implementing the graph loss function we used for our pipeline as well.</p><p>Implementation Details. The GCN architecture uses ReLU activations and consists of one graph convolutional layer with 512 units and one fully connected layer with 128 units before the regression/classification layer. The number and the dimensions of the layers are determined through hyperparameter search based on validation performance. The networks are trained with the AdamW optimizer <ref type="bibr" target="#b19">[20]</ref>, with a learning rate of 0.005 for 300 epochs and utilize an early stopping scheme. The average brain age of the training set, which is used in Eq.</p><p>(3), is ε = 6. We use PyTorch <ref type="bibr" target="#b21">[22]</ref> and a Titan RTX GPU. The reported results are computed by averaging 10 runs with different initializations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Results</head><p>Regression. For the evaluation of the pipeline in the regression task, we use Mean Absolute Error (MAE), and the Pearson Correlation Coefficient (r score). A summary of the performance of the proposed and competing methods is available at Table <ref type="table" target="#tab_0">1</ref>. Linear regression (MAE = 3.82) outperforms GCNs trained on static graphs whether these are based on the node features (MAE = 3.87) or leverage the phenotypes (MAE = 3.98). The DGM outperforms the baselines (MAE = 3.72). The proposed method outperforms all others (MAE = 3.61).</p><p>Classification. For the classification task, we divide the subjects into four balanced classes. The metrics used for the classification task to evaluate the performance of the model are accuracy, the area under the ROC curve (AUC), which is defined as the average of the AUC curve of every class, and the Macro F1-score (Table <ref type="table" target="#tab_0">1</ref>). A similar trend to the regression task appears here, with the proposed method reaching top performance with 58% accuracy. Our hypothesis that the construction of a pre-defined graph structure is suboptimal, and might even hurt performance, is confirmed. Both for the classification and regression tasks, GCNs trained on static graphs do not outperform a simple linear model that ignores completely the structure of the graph. The proposed approach proves that not all phenotypes are equally important for the construction of the graph, and that giving attention weights accordingly increases the performance for both tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Ablation Studies</head><p>Number of Phenotypes. We perform an ablation test to investigate the effect of the number of features used for the extraction of the edges. We used only non-imaging phenotypes, only imaging phenotypes, or a combination of both (Table <ref type="table" target="#tab_1">2</ref>). The combination of imaging and non-imaging phenotypes (MAE = 3.61) performs better than using either one of them, while adding more imaging phenotypes does not necessarily improve performance.</p><p>Distance Metrics. Moreover, we explore how different distance metrics affect performance. Here, euclidean, cosine, and hyperbolic <ref type="bibr" target="#b18">[19]</ref> distances are explored. We also include a random edge selection to examine whether using the phenotypic information improves the results. The results (Table <ref type="table" target="#tab_1">2</ref>) indicate that euclidean distance performs the best, closely followed by cosine similarity. Hyperbolic performed a bit worse (MAE = 4 years), while random edges gave a MAE of 5.59. Regardless of the distance metric, phenotypes do incorporate valuable information as performance is considerably better than using random edges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Interpretability</head><p>A very important advantage of the pipeline is that the graph extracted through the training is interpretable, in terms of why two nodes are connected or not. Visualizing the attention weights given to the phenotypes, we get an understanding of the features that are the most relevant to brain aging. The regression problem is clinically more important, thus we will focus on this in this section. A similar trend was presented for the classification task as well.</p><p>The imaging and non-imaging phenotypes that were given the highest attention scores in the construction of the graph can be seen in Fig. <ref type="figure" target="#fig_0">2</ref>. We color the non-imaging phenotypes in pink, and the imaging ones in blue. A detailed list of the names of the phenotypes along with the attention weights given by the pipeline can be found in the Supplementary Material. The non-imaging phenotypes that were given the highest attention weights, were two cognitive tasks, the numeric and the alphanumeric trail making tasks. Systolic blood pressure, and stroke, were the next most important non-imaging phenotypes, even though they were not as important as some of the imaging features. Various neuroimaging phenotypes were considered important, such as information regarding the tract anterior thalamic radiaton, the volume of white matter hyperintensities, gray matter volumes, as well as measurements extracted from the FA (fractional anisotropy, a measure of the connectivity of the brain) skeleton. Our findings are in agreement with the relevant literature <ref type="bibr" target="#b4">[5]</ref>.</p><p>Apart from the attention weights, we also visualize the population graph that was used as the static graph of the baseline (Fig. <ref type="figure" target="#fig_1">3</ref>(left)). This population graph is constructed based on the cosine similarity of the phenotypes, with all the phenotypes playing an equally important role for the connectivity. In addition, we visualize the population graph using the cosine similarity of the weighted phenotypes (Fig. <ref type="figure" target="#fig_1">3</ref>(right)), with the attention weights provided by our trained pipeline. In both of the graph visualizations, the color of each node corresponds to the subject's age. It is clear that learning the graph through our pipeline results in a population graph where subjects with similar ages end up in more compact clusters, whereas the static graph does not demonstrate any form of organization. Since GCNs are affected by a graph construction with low homophily, it is reasonable that the static graphs perform worse than a simple machine learning method, and why the proposed approach manages to produce state-of-the-art results. Using a different GNN architecture that is not as dependent on the constructed graph's homophily could prove beneficial <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b29">29]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we propose an end-to-end pipeline for adaptive population-graph learning that is optimized for brain age estimation. We integrate multimodal information and use attention scores for the construction of the graph, while also increasing interpretability. The graph is sparse, which minimizes the computational costs. We implement the approach both for node regression and node classification and show that we outperform both the static graph-based and state-of-the-art approaches. We finally provide an insight into the most important phenotypes for graph construction, which are in agreement with related neurobiological literature.</p><p>In future work, we plan to extract node features from the latent space of a CNN. Training end-to-end will focus on latent imaging features that are also important for the GCN. Such features would potentially be more expressive and improve the overall performance. Finally, we leverage the UKBB because of the wide variety of multimodal data it contains, which makes it a perfect fit for brain age estimation but as a next step we also plan to evaluate our framework on different tasks and datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Attention weights for the top 5 imaging (blue) and top 5 non-imaging phenotypes (pink) averaged across 10 runs of the pipeline. (Color figure online)</figDesc><graphic coords="6,49,80,54,50,324,25,107,20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Population-graph visualizations. Left: graph constructed based on the cosine similarity of the phenotypes. Right: graph constructed based on the cosine similarity of the weighted phenotypes, where the attention weights are the ones extracted from the proposed pipeline. The color of the nodes corresponds to the subject's age. It is evident that using the attention weights increases the homophily of the graph.</figDesc><graphic coords="7,62,97,53,87,326,65,119,83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Performance of the proposed approach in comparison with a traditional machine learning model, static graph baselines, and the state-of-the-art for age regression (left), and 4-class age classification (right). (MAE in years)</figDesc><table><row><cell>Method</cell><cell cols="2">MAE r score</cell><cell>Method</cell><cell cols="2">Accuracy AUC F1</cell></row><row><cell>Linear Regression</cell><cell>3.82</cell><cell>0.75</cell><cell>Logistic Regression</cell><cell>0.54</cell><cell>0.79 0.54</cell></row><row><cell cols="2">Static (Node features) 3.87</cell><cell>0.75</cell><cell>Static (Node features)</cell><cell>0.53</cell><cell>0.75 0.52</cell></row><row><cell>Static (Phenotypes)</cell><cell>3.98</cell><cell>0.74</cell><cell>Static (Phenotypes)</cell><cell>0.52</cell><cell>0.75 0.51</cell></row><row><cell>DGM</cell><cell>3.72</cell><cell>0.75</cell><cell>DGM</cell><cell>0.55</cell><cell>0.80 0.55</cell></row><row><cell>Proposed</cell><cell cols="2">3.61 0.79</cell><cell>Proposed</cell><cell>0.58</cell><cell>0.80 0.56</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Ablation studies. Left: Effect of the choice of phenotypes used for the connection of the edges. Right: Performance of the proposed using different distances on the phenotypes to connect the edges. (MAE in years)</figDesc><table><row><cell>No. of phenotypes</cell><cell cols="2">MAE r score</cell><cell cols="3">Similarity Metric MAE r score</cell></row><row><cell>20 (non-imaging only)</cell><cell>4.63</cell><cell>0.68</cell><cell>Random</cell><cell>5.59</cell><cell>0.61</cell></row><row><cell cols="3">35 (non-imaging &amp; imaging) 3.61 0.79</cell><cell>Euclidean</cell><cell cols="2">3.61 0.79</cell></row><row><cell>50 (non-imaging &amp; imaging)</cell><cell>3.65</cell><cell>0.78</cell><cell>Cosine</cell><cell>3.7</cell><cell>0.78</cell></row><row><cell>68 (imaging only)</cell><cell>3.73</cell><cell>0.77</cell><cell>Hyperbolic</cell><cell>4.08</cell><cell>0.72</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. KMB would like to acknowledge funding from the <rs type="funder">EPSRC Centre for Doctoral Training in Medical Imaging</rs> (<rs type="grantNumber">EP/L015226/1</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_FmwSyCg">
					<idno type="grant-number">EP/L015226/1</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43993-3 19.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Graph-based deep learning for medical diagnosis and analysis: past, present and future</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ahmedt-Aristizabal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Armin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Denman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fookes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Petersson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page">4758</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Morphological changes of aging brain structure in MRI analysis</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nakano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kamiura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kobashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint 7th International Conference on Soft Computing and Intelligent Systems (SCIS) and 15th International Symposium on Advanced Intelligent Systems (ISIS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="683" to="687" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Image processing and quality control for the first 10,000 brain imaging datasets from UK biobank</title>
		<author>
			<persName><forename type="first">F</forename><surname>Alfaro-Almagro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">166</biblScope>
			<biblScope unit="page" from="400" to="424" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Bootstrapping graph convolutional neural networks for autism spectrum disorder classification</title>
		<author>
			<persName><forename type="first">R</forename><surname>Anirudh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Thiagarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3197" to="3201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Multimodality neuroimaging brain-age in UK biobank: relationship to biomedical, lifestyle, and cognitive factors</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Cole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurobiol. Aging</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="34" to="42" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Predicting brain age with deep learning from raw imaging data results in a reliable and heritable biomarker</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Cole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">163</biblScope>
			<biblScope unit="page" from="115" to="124" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Latent-graph learning for disease prediction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Cosmo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-A</forename><surname>Ahmadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bronstein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59713-9_62</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-59713-962" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12262</biblScope>
			<biblScope unit="page" from="643" to="653" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Prediction of MCI to ad conversion, via MRI, CSF biomarkers, and pattern classification</title>
		<author>
			<persName><forename type="first">C</forename><surname>Davatzikos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bhatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>Batmanghelich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Q</forename><surname>Trojanowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurobiol. Aging</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2322" to="e2341" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Ten years of brainage as a neuroimaging biomarker of brain aging: what insights have we gained?</title>
		<author>
			<persName><forename type="first">K</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gaser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Neurol</title>
		<imprint>
			<biblScope unit="volume">789</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Edge-variational graph convolutional networks for uncertainty-aware disease prediction</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C S</forename><surname>Chung</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59728-3_55</idno>
		<idno>978-3-030-59728-3 55</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12267</biblScope>
			<biblScope unit="page" from="562" to="572" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Robust estimation of a location parameter</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Huber</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-1-4612-4380-9_35</idno>
		<ptr target="https://doi.org/10.1007/978-1-4612-4380-935" />
	</analytic>
	<monogr>
		<title level="m">Breakthroughs in Statistics: Methodology and Distribution</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Kotz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">L</forename><surname>Johnson</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="492" to="518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Differentiable graph module (DGM) for graph convolutional networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cosmo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Ahmadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bronstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1606" to="1617" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">IA-GCN: interpretable attention based graph convolutional network for disease prediction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Farghadani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.15587</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">InceptionGCN: receptive field aware graph convolutional network for disease prediction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kazi</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-20351-1_6</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-20351-16" />
	</analytic>
	<monogr>
		<title level="m">IPMI 2019</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">C S</forename><surname>Chung</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Gee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Yushkevich</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Bao</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11492</biblScope>
			<biblScope unit="page" from="73" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Stochastic beams and where to find them: the gumbel-top-k trick for sampling sequences without replacement</title>
		<author>
			<persName><forename type="first">W</forename><surname>Kool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Van Hoof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3499" to="3508" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Accelerated brain aging in schizophrenia and beyond: a neuroanatomical marker of psychiatric disorders</title>
		<author>
			<persName><forename type="first">N</forename><surname>Koutsouleris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Schizophr. Bull</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1140" to="1153" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Hyperbolic geometry of complex networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Krioukov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Papadopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kitsak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vahdat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Boguná</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. E</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">36106</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05101</idno>
		<title level="m">Decoupled weight decay regularization</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Disease prediction using graph convolutional networks: application to autism spectrum disorder and Alzheimer&apos;s disease</title>
		<author>
			<persName><forename type="first">S</forename><surname>Parisot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="117" to="130" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">PyTorch: an imperative style, high-performance deep learning library</title>
		<author>
			<persName><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Ageing and Parkinson&apos;s disease: why is advancing age the biggest risk factor?</title>
		<author>
			<persName><forename type="first">A</forename><surname>Reeve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Simcox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Turnbull</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ageing Res. Rev</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="19" to="30" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Explainability and interpretability: keys to deep medicine</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shaban-Nejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Michalowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Buckeridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Explainable AI in Healthcare and Medicine. SCI</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Shaban-Nejad</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Michalowski</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Buckeridge</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">914</biblScope>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Cham</forename><surname>Springer</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-53352-6_1</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-53352-61" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Population graph GNNs for brain age prediction</title>
		<author>
			<persName><forename type="first">K</forename><surname>Stankeviciute</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Azevedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bethlehem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Workshop on Graph Representation Learning and Beyond</title>
		<imprint>
			<publisher>GRL+</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="17" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Dynamic graph CNN for learning on point clouds</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Solomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph. (tog)</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.08966</idno>
		<title level="m">Graph learning: a comprehensive survey and future directions</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Multi-modal graph learning for disease prediction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2207" to="2216" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.07082</idno>
		<title level="m">Graph neural networks for graphs with heterophily: a survey</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Beyond homophily in graph neural networks: current limitations and effective designs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Heimann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Akoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koutra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural. Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="7793" to="7804" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
