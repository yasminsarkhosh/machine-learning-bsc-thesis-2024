<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Shape-Based Pose Estimation for Automatic Standard Views of the Knee</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Lisa</forename><surname>Kausch</surname></persName>
							<email>l.kausch@dkfz-heidelberg.de</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Division of Medical Image Computing</orgName>
								<orgName type="department" key="dep2">German Cancer Research Center (DKFZ)</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">National Center for Tumor Diseases (NCT)</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Radiation Oncology</orgName>
								<orgName type="laboratory">Pattern Analysis and Learning Group</orgName>
								<orgName type="institution">Heidelberg University Hospital</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sarina</forename><surname>Thomas</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="institution">University of Oslo</orgName>
								<address>
									<settlement>Oslo</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Holger</forename><surname>Kunze</surname></persName>
							<affiliation key="aff4">
								<orgName type="laboratory">Advanced Therapy Systems Division</orgName>
								<orgName type="institution">Siemens Healthineers</orgName>
								<address>
									<settlement>Erlangen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jan</forename><forename type="middle">Siad</forename><surname>El Barbari</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Klaus</forename><forename type="middle">H</forename><surname>Maier-Hein</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Division of Medical Image Computing</orgName>
								<orgName type="department" key="dep2">German Cancer Research Center (DKFZ)</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">National Center for Tumor Diseases (NCT)</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Radiation Oncology</orgName>
								<orgName type="laboratory">Pattern Analysis and Learning Group</orgName>
								<orgName type="institution">Heidelberg University Hospital</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Shape-Based Pose Estimation for Automatic Standard Views of the Knee</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="476" to="486"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">E1E921BF67E13232AE6A87E51A956A93</idno>
					<idno type="DOI">10.1007/978-3-031-43990-2_45</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-01T10:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Shape-based pose estimation</term>
					<term>Standard projections</term>
					<term>Knee</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Surgical treatment of complicated knee fractures is guided by real-time imaging using a mobile C-arm. Immediate and continuous control is achieved via 2D anatomy-specific standard views that correspond to a specific C-arm pose relative to the patient positioning, which is currently determined manually, following a trial-and-error approach at the cost of time and radiation dose. The characteristics of the standard views of the knee suggests that the shape information of individual bones could guide an automatic positioning procedure, reducing time and the amount of unnecessary radiation during C-arm positioning. To fully automate the Carm positioning task during knee surgeries, we propose a complete framework that enables (1) automatic laterality and standard view classification and (2) automatic shape-based pose regression toward the desired standard view based on a single initial X-ray. A suitable shape representation is proposed to incorporate semantic information into the pose regression pipeline. The pipeline is designed to handle two distinct standard views with one architecture. Experiments were conducted to assess the performance of the proposed system on 3528 synthetic and 1386 real X-rays for the a.-p. and lateral standard. The view/laterality classificator resulted in an accuracy of 100%/98% on the simulated and 99%/98% on the real Xrays. The pose regression performance was dθa.-p = 5.8±3.3 • , dθ lateral = 3.7 ± 2.0 • on the simulated data and dθa.-p = 7.4 ± 5.0 • , dθ lateral = 8.4 ± 5.4 • on the real data outperforming intensity-based pose regression.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Intraoperative imaging employing a mobile C-arm enables immediate and continuous control during orthopedic and trauma interventions. For optimal fracture reduction and implant placement, correct acquisition of standard views that correspond to a specific C-arm pose relative to the patient is essential <ref type="bibr" target="#b17">[18]</ref>. Incorrect standard views can exhibit superimposed anatomical structures, leading to overlooked errors that can result in malunion of fractures, functional impairment, or require revision surgeries. To enable deducing all three dimensions of the trauma case, at least two 2D fluoroscopic views are acquired in two distinct planes usually at right angles to each other. The current manual C-arm positioning procedure results in only 20% surgically relevant acquisitions while the remaining 80% are caused by the iterative positioning process, exposing patients and clinical staff to unnecessary radiation <ref type="bibr" target="#b15">[16]</ref>. Recent developments towards robotic C-arms ask for automatic positioning methods. Many state of the art approaches require a patient-specific CT for intraoperative real-time simulation <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b7">8]</ref> or 2D-3D registration <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b16">17]</ref>, external tracking equipment <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b15">16]</ref>, manual landmark annotation <ref type="bibr" target="#b0">[1]</ref> or do not estimate an optimal pose but reproduce intraoperatively recorded C-arm views employing augmented reality <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b19">20]</ref>. The inherent prior assumptions and severe inference with the clinical workflow hinder broad clinical applicability until today. In contrast to the majority of anatomical regions, the standard planes of the knee are not orthogonal to each other. The a.-p. standard view is characterized by symmetric projection of the joint gap, femoral and tibial condyles. The tibia surface projects line-shaped and the medial half of the fibula head is superimposed by the tibia. In the lateral standard view, both femoral condyles are aligned and the joint gap is maximized. Automatic deep learning-based positioning for standard views involves specific challenges for image understanding due to overlapping anatomical structures, the presence of surgical implants, and changing viewing directions and showed to benefit from extracting semantic information <ref type="bibr" target="#b9">[10]</ref>. Inspired by that and considering that standard views of the knee anatomy are characterized by the shape information of the individual projected bones, we propose a complete framework to fully automate the C-arm positioning tasks during knee surgeries (Fig. <ref type="figure" target="#fig_0">1</ref>). Our contribution is 4-fold: (1) We propose a novel framework that enables simultaneous automatic standard view classification, laterality classification, in-plane rotation correction, and subsequent view-independent shape-based C-arm positioning to the desired standard view while requiring only a single initial X-ray projection. One pose regression network can handle two distinct standard views of the knee anatomy. A suitable segmentation representation for the knee anatomy is proposed to recognize correct standard views, which explicitly incorporates semantic information to reflect on the actual clinical decision-making of surgeons. Since intraoperative X-rays with reference pose annotations do not exist due to the mobile surgical setup, the proposed framework is solely trained on simulated data with automatically generated pose annotations. <ref type="bibr" target="#b1">(2)</ref> We show that the proposed approach outperforms view-specific shape-based and intensity-based pose regression. <ref type="bibr" target="#b2">(3)</ref> We show that the proposed shape representation and augmentation strategies aid generalization from simulated training data to real cadaver X-rays. (4) We investigate the importance of individual knee bones on the overall positioning performance for two distinct standard views.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Materials and Methods</head><p>An overview of the complete framework for fully automated C-arm positioning towards desired standard views during knee surgeries is given in Fig. <ref type="figure" target="#fig_0">1</ref>. The anterior-posterior (a.-p.) and the lateral standard view showed to be sufficient for various diagnostic entities <ref type="bibr" target="#b2">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Training Data Simulation</head><p>To address the interventional data scarcity problem, simulated training data was generated from a collection of CT and C-arm volumes using a realistic DRR simulation framework <ref type="bibr" target="#b20">[21]</ref> complemented with corresponding 2D segmentations. Preprocessing involved the following steps: (1) Field-of-view cropping: Prevents superposition of the other laterality in the projection domain.   <ref type="bibr" target="#b22">[22]</ref> with interactive plane positioning. They serve as ground truth pose reference during simulation. (4) 3D automatic bone segmentation: To compute automatic 3D segmentations, a 3D nnU-Net <ref type="bibr" target="#b8">[9]</ref> is trained on a subset of 10 manually annotated CTs for the task of multilabel bone segmentation, segmenting the femur, tibia, fibula, and patella. (5) Suitable segmentation representation: The two femur condyles are not distinguishable in the shape-based representation, however, this is relevant for optimal lateral positioning. In an optimal lateral view, femur condyles would overlap. Annotating the condyles as line features would result in an increased manual labeling effort in the projection domain. Alternatively, we propose to incorporate this information in the segmentation by separating the femur annotation symmetrically along the femoral shaft (Fig. <ref type="figure" target="#fig_2">2a</ref>). This results in one additional segmentation label for the lateral standard to recognize condyles' congruence and derive the directional pose offset. (6) DRR and mask simulation: DRRs are simulated for varying angulations of orbital and angular rotation α, β ∈ [-40 • , 40 • ] around the defined reference standard. The system parameters are defined according to a Siemens Cios Spin R with 300 mm detector and 1164 mm source-detector distance. Simulation was performed for an increased field-of-view to create in-plane γ augmentations without introducing cut-off regions at the image borders. The DeepDRR simulation framework was extended to allow the forward projection of corresponding masks (Fig. <ref type="figure" target="#fig_2">2b</ref>). A set of augmentations is applied to the simulated dataset, to bridge the domain gap from synthetic data to real X-rays (Fig. <ref type="figure">3</ref>). The in-plane rotation augmentation accounts for variable patient to C-arm alignment, the translation bridges the gap to the validation data where the joint gap is not centered like in the training data, random region dropout reflects superposition artifacts, transparent edge overlays reflect projection artifacts resulting from, e.g., the operating table, and border overlays account for the gamma correction interpolation artifacts. For simulation, a set of 24 CTs was considered, 15 CTs without metal and 9 Carm volumes with metal. The data was divided 60 -20 -20 % for training (15 CTs), validation (5 CTs), test (4 CTs).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Shape-Based Positioning Framework:</head><p>The proposed shape-based positioning framework was trained jointly for both standard views (Fig. <ref type="figure" target="#fig_0">1</ref>). It consists of two modules: The first is responsible for a view classification, in-plane rotation and laterality alignment, directly estimated from the image intensities. Thereby, pose ambiguities and data variation are addressed, simplifying the task for the subsequent module to estimate the optimal C-arm positioning for the desired standard view, employing shape features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(1) Intensity-based multi-task classification and regression module:</head><p>For simultaneous in-plane rotation regression, view recognition, and laterality classification, an EfficientNet-B0 feature extractor <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b18">19]</ref> was extended with two binary classification heads with one output neuron, followed by sigmoid activation, and one regression head, with the same architecture, but 2 outputs, omitting the activation. The in-plane rotation γ is mapped to sin/cos-space to ensure a continuous Loss function during optimization. All training examples were aligned with the same laterality during data simulation which would otherwise result in pose ambiguities. Thus, to train the laterality classifier, the training examples were randomly flipped horizontally with p = 0.5 and the corresponding γ label was adapted accordingly. The weights were optimized using Binary Cross Entropy Loss for the classification heads, and Mean Squared Error for the regression head.</p><p>(2) Shape-based pose regression: Following surgical characteristics for recognizing correct standard views of the knee, a view-independent shape-based pose regression framework was developed. The architecture is based on a 2D U-Net <ref type="bibr" target="#b11">[12]</ref> with two view-specific segmentation heads, because the segmentation labels differ for both views. Considering the results of the view classification, the extracted segmentation map of the corresponding segmentation head are used as input for the pose regression network that outputs the necessary C-arm pose update (α, β, γ, t)∈ R 6 to acquire the desired standard view <ref type="bibr" target="#b10">[11]</ref>. To ensure equal number of input channels to the PoseNet for both standard views, a zero channel is appended to the a.-p. multi-label segmentation head output. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Real X-Ray Test Data:</head><p>Real X-rays for validation were sampled from single Siemens Cios Spin R sequences generated during 3D acquisition of 6 knee cadavers. Preprocessing consisted of (1) definition of 3D standard reference planes, (2) laterality check, (3) sampling of X-rays around the defined reference standards in the interval α, β ∈ [-30 • , 30 • ], and generation of ground truth pose labels. Since the Spin sequences are orbital acquisition sequences, only the orbital rotation is equidistantly covered in the test set, while the angular rotation is constant for all X-rays sampled from the same sequence. The number of sampled X-rays per standard and view may differ, if the reference standard is located close to the edge of the orbital sequence (range: 102-124). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Importance of Pipeline Design Choices (RQ1)</head><p>In an ablation study, the proposed shape-based view-independent pose regression was compared to view-specific direct intensity-based pose regression <ref type="bibr" target="#b10">[11]</ref>. Further, the complete pipeline (2-step) is compared to a 1-step segmentationbased approach trained view-specific and view-independent (Fig. <ref type="figure" target="#fig_3">4</ref>). Evaluation was performed on the simulated test DRRs and cadaveric X-rays (Fig. <ref type="figure" target="#fig_4">5</ref>). Significant performance differences were confirmed by a paired t-test. View-independent vs. view-specific networks: While the view-specific networks perform significantly better (lateral) or comparable (a.-p.) on the simulated data, the view-independent networks perform significantly better (a.-p.) or comparable (lateral) on the real data. 1-step vs. 2-step: The proposed 2-step approach performs significantly better or comparable than a 1-step shape-based pose regression approach on most validation cases (8/12) in viewing direction θ. Regarding the γ rotation, the 2-step approach improves performance across all validation cases. Generalization from DRR to X-ray: The shape-based pose regression network combined with joint view-independent training clearly boosts the performance compared to direct intensity-based pose regression from dθ X-ray a.-p = 12.2±6.8 • , dθ X-ray lateral = 14.4±7.6 • to dθ X-ray a.-p = 7.4±5.0 • , dθ X-ray lateral = 8.4±5.4 • . Figure <ref type="figure" target="#fig_5">6</ref> shows qualitative results on exemplary real test X-rays.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Importance of Individual Bones on Overall Performance (RQ2)</head><p>Figure <ref type="figure" target="#fig_6">7</ref> shows the importance of individual segmented bone classes on the overall positioning performance evaluated on the test DRRs (3528 DRRs). The fibula has very little influence on the positioning for both views. The patella is only important for the a.-p. view, while tibia and femur are relevant for both views. The condyle assignment for the lateral view determines the rotation direction for the orbital and angular rotation (α, β). Inverting the assignment of left and right femur condyle results in a sign flip in α, β. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Accuracy of View and Laterality Classification (RQ3)</head><p>The classificator performances were assessed on the synthetic (3528 DRRs, 4 CTs) and real data (1386 X-rays, 6 C-arm scans). The view classificator (a.-p. / lateral) achieved an accuracy of 100% on the test DRRs and 99% on the X-rays. The laterality classificator (left / right) resulted in an accuracy of 98% on the test DRRs and 98% on the X-rays.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion and Conclusion</head><p>A complete framework for automatic acquisition of standard views of the knee is proposed that can handle several standard views with a single architecture.</p><p>The complete pipeline is trained on simulated data with automatically generated annotations and evaluated on real intraoperative X-rays. To bridge the domain gap, different augmentation strategies are suggested that address intraoperative confounding factors, e.g., the OR table. View-independent training and multilabel shape features improve the generalization from simulated training to real X-rays and outperform direct intensity-based approaches. View-independent networks result in more training data which showed to improve the generalization from simulated training to real X-rays. The 2-step approach increases robustness and simultaneously automates necessary preprocessing tasks like laterality and standard view recognition, which can be performed with very high accuracy on simulated (100%, 98%) and real data (99%, 98%). The approach is fast and easy to translate into the operating room as it does not require any additional technical equipment. Assuming that the surgeon acquires the initial X-ray Data use declaration: The data was obtained retrospectively from anonymized databases and not generated intentionally for the study. The acquisition of data from living patients had a medical indication and informed consent was not required. The corresponding consent for body donation for these purposes has been obtained.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Proposed shape-based pose estimation framework for automatic acquisition of standard views. A single architecture is trained for the representation of 2 distinct standard views simultaneously. The 2-step pipeline consists of a direct intensity-based combined view classification and in-plane rotation regression, followed by a segmentationbased pose regression focusing on the out-of-plane rotation. The pipeline is solely trained on synthetic data with automatically generated ground truth annotations and evaluated on real X-rays.</figDesc><graphic coords="2,56,97,254,15,338,08,176,08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .Fig. 3 .</head><label>23</label><figDesc>Fig. 2. Suitable segmentation representation to recognize the lateral standard view of the knee: In an ideal standard view the condyles' overlap each other.</figDesc><graphic coords="4,56,46,192,35,339,40,56,68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>( 2 )</head><label>2</label><figDesc>Laterality alignment: Based on the laterality classification left knees are horizontally flipped to mirror the right anatomy, simplify the pose estimation task, and prohibit ambiguities during pose estimation. (3) Definition of 3D reference planes: Two independent raters defined the 3D reference planes in the CT volumes utilizing a DRR preview integrated into the open-source Medical Imaging Toolkit</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Variants for performance comparison.</figDesc><graphic coords="6,104,97,54,23,242,44,55,48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Pose regression performance on simulated and real X-rays compared for different pipeline variants.</figDesc><graphic coords="7,42,30,54,38,339,52,122,32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Exemplary visual results on the real X-ray test dataset for the a.-p. and lateral standard positioning with good, average, and bad performance measured with respect to the orbital rotation offset α to the reference standard pose. The initial X-ray projection is visualized along with the in-plane corrected projection with the overlaid segmentation mask, and the predicted standard view side-by-side with the desired reference standard.</figDesc><graphic coords="8,56,46,53,93,339,40,141,04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Importance of individual bones on positioning performance (3528 test DRRs). One segmentation channel was set to zero at a time during inference, 'none' corresponds to the reference performance utilizing all channels.</figDesc><graphic coords="9,42,30,54,29,339,40,55,60" type="bitmap" /></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43990-2 45.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head><p>The proposed pipeline was evaluated considering the following research questions:</p><p>(RQ1) Does the proposed shape-based pipeline outperform view-specific intensity-based and shape-based pose regression? How does it influence the generalization from synthetic to real data? (Sect. 3.1) (RQ2) How do individual bones influence the overall positioning performance? (Sect. 3.2) (RQ3) How accurate is the performance of the view and laterality classification?</p><p>(Sect. 3.3)</p><p>Positioning performance was evaluated based on the angle θ = arccos v pred , v gt between the principal rays of the ground truth v gt and predicted pose v pred and the mean absolute error (AE) of in-plane rotation γ. The interrater variation of the reference standard planes defined by two independent raters serves as an upper bound for the reachable accuracy of a C-arm positioning approach trained on the reference annotations. It was assessed in terms of orientation differences θ (θ a.-p. = 4.1 ± 2.6 • , θ lateral = 1.8 ± 1.3 • ). The models were implemented using PyTorch 1.6.0, trained with an 11 GB GeForce RTX 2080 Ti, and optimized with the Adam optimizer with a base learning rate of η = 10 -4 and batchsize 8, pre-trained independently, and jointly fine-tuned until convergence.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Image guided positioning for an interactive c-arm fluoroscope</title>
		<author>
			<persName><forename type="first">N</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bodensteiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Matthäus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Burgkart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schweikard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Assist. Radiol. Surg</title>
		<imprint>
			<biblScope unit="page" from="5" to="7" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Use of a C-arm fluoroscopy simulator to support training in intraoperative radiography</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">J</forename><surname>Bott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dresing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Raab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Teistler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiographics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="31" to="E41" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Use of radiographic projections of knee</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">P</forename><surname>Cockshott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Racoveanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Burrows</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ferrier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Skeletal Radiol</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="131" to="133" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">C-arm positioning using virtual fluoroscopy for image-guided surgery</title>
		<author>
			<persName><forename type="first">De</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Imaging: Image-guided Procedures, Robotic Interventions, and Modeling</title>
		<imprint>
			<publisher>International Society for Optics and Photonics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">10135</biblScope>
			<biblScope unit="page">101352</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Desired-View controlled positioning of angiographic C-arms</title>
		<author>
			<persName><forename type="first">P</forename><surname>Fallavollita</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-10470-6_82</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-10470-682" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2014</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Golland</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Hata</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Barillot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hornegger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Howe</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">8674</biblScope>
			<biblScope unit="page" from="659" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Interactive flying frustums (IFFs): spatially aware surgical data visualization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fotouhi</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11548-019-01943-z</idno>
		<ptr target="https://doi.org/10.1007/s11548-019-01943-z" />
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Assist. Radiol. Surg</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="913" to="922" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A cost effective and high fidelity fluoroscopy simulator using the image-guided surgery toolkit (IGSTK)</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jenkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Sze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yaniv</surname></persName>
		</author>
		<idno type="DOI">10.1117/12.2044112</idno>
		<ptr target="https://doi.org/10.1117/12.2044112" />
	</analytic>
	<monogr>
		<title level="m">Medical Imaging: Image-Guided Procedures, Robotic Interventions, and Modeling</title>
		<imprint>
			<publisher>International Society for Optics and Photonics</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">9036</biblScope>
			<biblScope unit="page">903618</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Automatic C-arm positioning using multi-functional user interface</title>
		<author>
			<persName><forename type="first">M</forename><surname>Haiderbhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Turrubiates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gutta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fallavollita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Canadian Medical and Biological Engineering Society Proceedings</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Isensee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Kohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Maier-Hein</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41592-020-01008-z</idno>
		<ptr target="https://doi.org/10.1038/s41592-020-01008-z" />
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="211" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">C-arm positioning for spinal standard projections in different intra-operative setting</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kausch</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87202-1_34</idno>
		<idno>978-3-030-87202-1 34</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="352" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Toward automatic C-arm positioning for standard projections in orthopedic surgery</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kausch</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11548-020-02204-0</idno>
		<ptr target="https://doi.org/10.1007/s11548-020-02204-0" />
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Assist. Radiol. Surg</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1095" to="1105" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wasserthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Greiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zimmerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Maier-Hein</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.2552439</idno>
		<ptr target="https://doi.org/10.5281/zenodo.2552439" />
		<title level="m">basic unet example</title>
		<imprint>
			<date type="published" when="2019-01">v2019.01. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">CNN-based pose estimation for assessing quality of ankle-joint X-ray images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Krönke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Imaging 2022: Image Processing</title>
		<imprint>
			<publisher>SPIE</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">12032</biblScope>
			<biblScope unit="page" from="344" to="352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An AI-based framework for diagnostic quality assessment of ankle radiographs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mairhöfer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Imaging with Deep Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Intraoperative adjustment of radiographic standard projections of the spine: interrater-and intrarater variance and consequences of &apos;fluorohunting&apos;considering time and radiation exposure-a cadaveric study</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mandelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">medRxiv</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Navigating the fluoroscope&apos;s C-arm back into position: an accurate and practicable solution to cut radiation and optimize intraoperative workflow</title>
		<author>
			<persName><forename type="first">F</forename><surname>Matthews</surname></persName>
		</author>
		<idno type="DOI">10.1097/BOT.0b013e318158fd42</idno>
		<idno>1097/BOT.0b013e318158fd42</idno>
		<ptr target="https://doi.org/10" />
	</analytic>
	<monogr>
		<title level="j">J. Orthopaedic Trauma</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="687" to="692" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Dilated FCN for multi-agent 2D/3D medical image registration</title>
		<author>
			<persName><forename type="first">S</forename><surname>Miao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Intraoperative fluoroscopy to evaluate fracture reduction and hardware placement during acetabular surgery</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Norris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Hahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Bosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Kellam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Sims</surname></persName>
		</author>
		<idno type="DOI">10.1097/00005131-199908000-00004</idno>
		<ptr target="https://doi.org/10.1097/00005131-199908000-00004" />
	</analytic>
	<monogr>
		<title level="j">J. Orthopaedic Trauma</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="414" to="417" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">EfficientNet: rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6105" to="6114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Augmented reality-based feedback for technician-in-the-loop C-arm repositioning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Unberath</surname></persName>
		</author>
		<idno type="DOI">10.1049/htl.2018.5066</idno>
		<ptr target="https://doi.org/10.1049/htl.2018.5066" />
	</analytic>
	<monogr>
		<title level="j">Healthc. Technol. Lett</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="143" to="147" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">DeepDRR -a catalyst for machine learning in fluoroscopyguided procedures</title>
		<author>
			<persName><forename type="first">M</forename><surname>Unberath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI 2018</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Schnabel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Davatzikos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Alberola-López</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Fichtinger</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">11073</biblScope>
			<biblScope unit="page" from="98" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-00937-3_12</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-00937-312" />
		<imprint>
			<date type="published" when="2018">2018</date>
			<pubPlace>Cham</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The medical imaging interaction toolkit</title>
		<author>
			<persName><forename type="first">I</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="594" to="604" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
