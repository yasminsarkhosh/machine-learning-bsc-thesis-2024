<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Medical Image Computing and Computer Assisted Intervention â€“ MICCAI 2023</title>
				<funder ref="#_PEApgG2 #_3ZgXF4e #_nBpbhay #_5EtcDEw">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xiaoxiao</forename><surname>He</surname></persName>
							<idno type="ORCID">0000-0003-4581-0712</idno>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Rutgers University</orgName>
								<address>
									<settlement>Piscataway</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chaowei</forename><surname>Tan</surname></persName>
							<idno type="ORCID">0000-0003-4581-0712</idno>
							<affiliation key="aff1">
								<orgName type="institution">FocusAI Inc</orgName>
								<address>
									<settlement>Sunnyvale</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ligong</forename><surname>Han</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Rutgers University</orgName>
								<address>
									<settlement>Piscataway</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bo</forename><surname>Liu</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Walmart Global Tech</orgName>
								<address>
									<settlement>San Bruno</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Leon</forename><surname>Axel</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">School of Medicine</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<region>New York</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Li</forename><surname>Kang</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Biomedical Big Data Center</orgName>
								<orgName type="institution">Sichuan University West China Hospital</orgName>
								<address>
									<settlement>Chengdu</settlement>
									<country>China, China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dimitris</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Rutgers University</orgName>
								<address>
									<settlement>Piscataway</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DMCVR: Morphology-Guided Diffusion Model for 3D Cardiac Volume Reconstruction</title>
					</analytic>
					<monogr>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">99D4C3570B90B16C0F8CA2ABD622C10D</idno>
					<idno type="DOI">10.1007/978-3-031-43990-2</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-01T14:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Diffusion model</term>
					<term>3D Reconstruction</term>
					<term>Generative model</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Accurate 3D cardiac reconstruction from cine magnetic resonance imaging (cMRI) is crucial for improved cardiovascular disease diagnosis and understanding of the heart's motion. However, current cardiac MRI-based reconstruction technology used in clinical settings is 2D with limited through-plane resolution, resulting in low-quality reconstructed cardiac volumes. To better reconstruct 3D cardiac volumes from sparse 2D image stacks, we propose a morphology-guided diffusion model for 3D cardiac volume reconstruction, DMCVR, that synthesizes highresolution 2D images and corresponding 3D reconstructed volumes. Our method outperforms previous approaches by conditioning the cardiac morphology on the generative model, eliminating the time-consuming iterative optimization process of the latent code, and improving generation quality. The learned latent spaces provide global semantics, local cardiac morphology and details of each 2D cMRI slice with highly interpretable value to reconstruct 3D cardiac shape. Our experiments show that DMCVR is highly effective in several aspects, such as 2D generation and 3D reconstruction performance. With DMCVR, we can produce high-resolution 3D cardiac MRI reconstructions, surpassing current techniques. Our proposed framework has great potential for improving the accuracy of cardiac disease diagnosis and treatment planning. Code can be accessed at https://github.com/hexiaoxiao-cs/DMCVR.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Medical imaging technology has revolutionized the field of cardiac disease diagnosis, enabling the assessment of both cardiac anatomical structures and motion, including the creation of 3D models of the heart <ref type="bibr" target="#b4">[5]</ref>. Cardiac cine magnetic resonance imaging (cMRI) <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b19">20]</ref> is widely used in clinical diagnosis <ref type="bibr" target="#b13">[14]</ref>, allowing for non-invasive visualization of the heart in motion with detailed information on cardiac function and anatomy <ref type="bibr" target="#b16">[17]</ref>. While cMRI has great potential in helping doctors understand and analyze cardiac function <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b14">15]</ref>, the imaging technique has certain drawbacks including low through-plane resolution to accommodate for the limited scanning time, as visualized in Fig. <ref type="figure" target="#fig_0">1</ref>. Recently, researchers have approached the problem of cardiac volume reconstruction with learning-based generative models <ref type="bibr" target="#b1">[2]</ref>. However, most of the methods suffer from low generation quality, missing key cardiac structures and long generation times. This paper focuses on improving the cardiac model generation quality, while reducing the generation time, aiming to better reconstruct the missing structure of the cardiac model from low through-plane resolution cMRI. Conventional 3D cardiac modeling <ref type="bibr" target="#b11">[12]</ref> consists of 2D cardiac image segmentation followed by 3D cardiac volume reconstruction. Recent advances in deep learning methods have shown great success in medical image segmentation <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b22">23]</ref>. After obtaining 2D labels, the neighboring labels are stacked to reconstruct the 3D model. Nevertheless, due to the low inter-slice spatial cMRI resolution, a significant amount of structural information is lost in the resulting 3D volume. Thus, the interpolation between cMRI slices is necessary. Traditional intensity-based interpolation methods often yield blurring effects and unrealistic results. Conventional deformable model-based method <ref type="bibr" target="#b12">[13]</ref> does not need consistency across images of the corresponding cardiac structures, but requires image-based structure segmentation which is nontrivial and hinders their ability to generalize. To overcome these limitations, an end-to-end pipeline based on generative adversarial networks (GANs), DeepRecon, was recently proposed in <ref type="bibr" target="#b1">[2]</ref> that utilizes the latent space to interpolate the missing information between adjacent 2D slices. The generative network is first trained and a semantic image embedding in the W + space <ref type="bibr" target="#b0">[1]</ref> is computed. Evidently, the acquired semantic latent code is not optimal and needs iterative optimization with segmentation information for improving image qualities. However, even with the optimization step, the generated images still miss details in the cardiac region, which indicates the W + space DeepRecon found does not represent the heart accurately.</p><p>In order to eliminate the step for optimizing the latent code and improve the image generation quality, we propose a morphology-guided diffusion-based 3D cardiac volume reconstruction method that improves the axial resolution of 2D cMRIs through global semantic and regional morphology latent code interpolation as indicated in Fig. <ref type="figure" target="#fig_0">1</ref>. Inspired by <ref type="bibr" target="#b18">[19]</ref>, we utilize the global semantic latent code to encode the image into a high-level meaningful representation of the image. To improve the cardiac volume reconstruction, our approach needs to focus on the cardiac region. Therefore, we introduce the regional morphology latent code which represents the shapes and locations of LVC, LVM and RVC, which will help generating the cardiac region. The method consists of three parts: an implicit diffusion model, a global semantic encoder and a segmentation network that encodes an image to regional morphology embeddings. The proposed method does not require iteratively fine-tuning the latent codes. Our contributions are: 1) the first diffusion-based method for 3D cardiac volume reconstruction, 2) introducing the local morphology-based latent code for improved conditioning on the image generation process, 3) 8% improvement of left ventricle myocardium (LVM) segmentation accuracy and 35% improvement of structural similarity index compared to previous methods, and 4) improved efficiency by eliminating the iterative step for optimizing the latent code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>Figure <ref type="figure" target="#fig_1">2</ref> demonstrates the structure of our DMCVR approach that learns the global semantic, regional morphology, and stochastic latent spaces from MR images to yield a broad range of outcomes, including generation of high-quality 2D image and high-resolution 3D reconstructed volume. In this section, we will first describe the architecture of our DMCVR method and then elaborate on the latent space-based 3D volume generation which enables 3D volume reconstruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">DMCVR Architecture</head><p>Our DMCVR is composed of a global semantic encoder E sem , a regional moprphology network (E mor , D mor ) and a diffusion-based generator G. The generating process G is defined as follows: given input x T , sem , mor , which are the stochastic, global semantic and regional morphology latent codes, we want to reconstruct the image x 0 recursively as follows:</p><formula xml:id="formula_0">x t-1 = âˆš Î± t-1 f Î¸ (x t , t, sem , mor ) + 1 -Î± t-1 Î¸ (x t , t, sem , mor ),<label>(1)</label></formula><p>where Î¸ (x t , t, sem , mor ) is the noise prediction network and f Î¸ is defined as removing the noise from x t or Tweedie's formula <ref type="bibr" target="#b2">[3]</ref>:</p><formula xml:id="formula_1">f Î¸ (x t , t, sem , mor ) = 1 âˆš Î± t (x t - âˆš 1 -Î± t Î¸ (x t , t, sem , mor ))<label>(2)</label></formula><p>Here, the term Î± t is a function of t affecting the sampling quality.</p><p>The forward diffusion process takes the noise x T as input and produces x 0 the target image. Since the change in x T will affect the details of the output images, we can treat x T as the stochastic latent code. Therefore, finding the correct stochastic latent code is crucial for generating image details. Thanks to DDIM proposed by Song et al. <ref type="bibr" target="#b20">[21]</ref>, it is possible to get x T in a deterministic fashion by running the generative process backwards to obtain the stochastic latent code x T for a given image x 0 . This process is viewed as a stochastic encoder x T = E sto (x 0 , sem , mor ), which is conditioned on sem and mor . This conditioning helps us to remove the iterative optimization step used by previous method. We formulate the inversion process from x 0 to x T as follows:</p><formula xml:id="formula_2">x t+1 = âˆš Î± t+1 f Î¸ (x t , t, sem , mor ) + 1 -Î± t+1 Î¸ (x t , t, sem , mor )<label>(3)</label></formula><p>Although using the stochastic latent variables we are able to reconstruct the image accurately, the stochastic latent space does not contain interpolatable high-level semantics. Here we utilize a semantic encoder proposed by Preechakul et al. <ref type="bibr" target="#b18">[19]</ref> to encode the global high-level semantics into a descriptive vector for conditioning the diffusion process, similar to the style vector in StyleGAN <ref type="bibr" target="#b9">[10]</ref>. The global semantic encoder utilizes the first half of the UNet, and is trained end-to-end with the conditional diffusion model.</p><p>One drawback of the global semantic encoder is that it encodes the general high-level features, but tends to pay little attention to the cardiac region. This is due to the relatively small area of LVC, LVM and RVC in the cMRI slice. However, the generation accuracy of the cardiac region is crucial for the cardiac reconstruction task. For this reason, we introduce the regional morphology encoder E mor that embeds the image into the latent space containing necessary information to produce the segmentation map of the target cardiac tissues. With this extra morphology information, we are able to guide the generative model to focus on the boundary of the ventricular cavity and myocardium region, which will produce increased image accuracy in the cardiac region and the downstream segmentation task. Here, we do not assume any particular architecture for the segmentation network. However, in our experiments, we utilize the segmentation network MedFormer proposed by Gao et al. <ref type="bibr" target="#b3">[4]</ref> for its excellent performance.</p><p>The training of DMCVR contains the training of the segmentation network and the training of the generative model. We first train the segmentation model with summation of focal loss and dice loss <ref type="bibr" target="#b3">[4]</ref>. We utilize the simple loss introduced in <ref type="bibr" target="#b6">[7]</ref> for training the conditional diffusion implicit model, where</p><formula xml:id="formula_3">L gen (x) = E tâˆ¼Unif(1,T ), âˆ¼N (0,I) || Î¸ (x t , t, E sem (x 0 ), E mor (x 0 )) -|| 2 2 . (4)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">3D Volume Reconstruction and Latent-Space-Based Interpolation</head><p>Due to various limitations, the gap between consecutive cardiac slices in cMRI is large, which results in an under-sampled 3D model. In order to output a smooth super-resolution cine image volume, we generate the missing slices by using the interpolated global semantic, regional morphology and stochastic latent codes.</p><p>For global semantic and regional morphology latent code , since it is similar to the idea of latent code in StyleGAN, we utilize the same interpolation strategies as in the original paper between adjacent slices. Assume that k &lt; j -i, i &lt; j,</p><formula xml:id="formula_4">i+k = (1 - k j -i ) i + k j -i j . (<label>5</label></formula><formula xml:id="formula_5">)</formula><p>For interpolating the stochastic latent variable, it is important to consider that the distribution of stochastic noise is high-dimensional Gaussian, as shown in Eq. ( <ref type="formula">4</ref>). Thus, our stochastic embedding is positioned on a sphere shown in Fig. <ref type="figure" target="#fig_1">2</ref>. Using linear interpolation on the stochastic noise deviates from the underlying distribution assumption and causes the diffusion model to generate unrealistic images. Hence, to preserve the Gaussian property of the stochastic latent space, we interpolate the stochastic latent codes over a unit sphere, which can be written as follows: Let k &lt; j -i, i &lt; j and x i T â€¢ x j T = cos Î¸, </p><formula xml:id="formula_6">x i+k T = sin((1 -k j-i )Î¸) sin(Î¸) x i T + sin( k j-i Î¸) sin(Î¸) x j T . (<label>6</label></formula><formula xml:id="formula_7">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Settings</head><p>In this study we use data from the publicly available UK Biobank cardiac MRI data <ref type="bibr" target="#b17">[18]</ref>, which contains SAX and LAX cine CMR images of normal subjects.</p><p>LVC, LVM and RVC are manually annotated on SAX images at the end-diastolic (ED) and end-systolic (ES) cardiac phases. We use 808 cases containing 484,800 2D SAX MR slices for training and 200 cases containing 120,000 2D images for testing. To evaluate the 3D volume reconstruction performance, we randomly choose 50 testing 2D LAX cases to evaluate the 3D volume reconstruction task. All models are implemented on PyTorch 1.13 and trained with 4Ã—RTX8000.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation of the 2D Slice Generation Quality</head><p>We provide peak signal-to-noise ratio (PSNR) and structural similarity index measure (SSIM) <ref type="bibr" target="#b7">[8]</ref> to evaluate the similarity between the generated images and the original images. In addition to image quality assessment, we want to consider the segmentation performance on the generated images by using a segmentation network trained on the real training data as the evaluator and segment the testing images generated by DeepRecon 1k , DiffAE which only uses the global semantic latent code as the condition on the DDIM model, and our DMCVR methods. The segmentation accuracy of the evaluator on the generated images can be viewed as a quantitative metric to represent the generation quality of the generated data compared to the cMRI data. We compare segmentation obtained based on three methods against ground truth on the SAX images in Table <ref type="table" target="#tab_0">1</ref>. The Dice coefficient (DICE), volumetric overlap error (VOE), average surface distance (ASD), Hausdorff distance (HD) and average symmetric surface distance (ASSD) <ref type="bibr" target="#b21">[22]</ref> are reported for comparison. Our method achieves a PSNR score of 30.504 and SSIM score of 0.982, which is a significant improvement (35% increase in SSIM) compared to Deep-Recon (PSNR: 27.684, SSIM: 0.724) with 1k optimization steps. This indicates that our method generates more realistic image compared to DeepRecon. The segmentation results on the original images in Table <ref type="table" target="#tab_0">1</ref> provide an upper bound for other results. DMCVR outperforms all other methods in every metric with an 8% increase in LVM segmentation compared to DiffRecon 1k Moreover, by comparing the DiffAE and DMCVR, the introduction of the regional morphology latent code drastically improves the generation results due to the extra information on the shape of LVC, LVM, and RVC. Figure <ref type="figure" target="#fig_2">3</ref> demonstrates the original image and corresponding synthetic images. The white arrow points towards the presence of cardiac papillary muscles. As indicated in the images, DeepRecon 1k (b) cannot effectively recover the information of the papillary muscles from the latent space. However, both diffusion-based (c, d) methods accurately synthesize the information. Our method (d) generates a cleaner image with less artifacts than (c), especially around the LV and RV regions. By comparing the yellow circled area, our method produces image closer to the ground truth compared to DeepRecon 1k . Also, the white circle in Fig. <ref type="figure" target="#fig_2">3</ref> demonstrates the benefits of incorporating regional morphology information. Besides, the generative model used in DeepRecon 1k needs to be trained for 14 days with additional time to iteratively optimize the latent code for each slice. Our method uses 4.8 days for training. Since DDIM inversion does not have test-time optimization as DeepRecon does, DMCVR generates images faster than DeepRecon.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Evaluation of the 3D Volume Reconstruction Quality Through Latent Space Interpolation</head><p>In this section, we exploit the relationship between SAX and LAX images and leverage the LAX label to evaluate the volume reconstruction quality. In cardiac MRI, long axis (LAX) slices typically comprise 2-chamber (2ch), 3-chamber (3ch), and 4-chamber (4ch) views. To evaluate the performance of different interpolation methods on LAX slices, we conducted the following experiments: 1) Nearest Neighbor resampling of short-axis (SAX) volume to each LAX view, 2) Image-based Linear Interpolation, 3) DeepRecon 1k , and 4) our DMCVR. Table <ref type="table">2</ref> shows the computed 2D DICE score between the annotation of different LAX views and the intersection between the corresponding LAX plane and 3D reconstructed volume. Our method outperforms other methods in three categories and has only less than 1% performance degradation compared to DeepRecon 1k but with more stable performance. Figure <ref type="figure">4</ref> presents three examples for each LAX view, showing better reconstructed LAX results compared to the original images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>Integrating analysis of cMRI holds significant clinical importance in understanding and evaluating cardiac function. We propose a diffusion-model-based volume reconstruction method. Our finding shows that through an interpolatable latent space, we are able to improve the spatial resolution and produce meaningful MR images. In the future, we will consider incorporating LAX slices as part of the generation process to help refine the latent space.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. (a) demonstrates the limitations of cardiac cMRI. The white line in the short axis (SAX) image is the location of 2 chamber (2ch) long axis (LAX) image slice and vice versa. The grey images indicate the missing slices which are not captured during the MRI scan. (b) is an overview of our DMCVR architecture. The SAX images x0 are first encoded to global semantic sem, regional morphology mor and stochastic latent codes xT , followed by interpolation in their respective latent space. The reconstructed images are sampled from a forward denoising diffusion implicit model (DDIM) process conditioned on the three latent codes. Finally, the 3D cardiac model is reconstructed via stacking the labels. The red, green, and blue regions represent the left ventricle cavity (LVC), left ventricle myocardium (LVM), and right ventricle cavity (RVC), respectively. (Color figure online)</figDesc><graphic coords="2,61,98,279,89,328,36,206,68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2.On the left side, we demonstrates the network structure of the DMCVR, which consists of an global semantic encoder, a regional morphology encoder/decoder and a conditional DDIM. The right side shows the visualization of the stochastic latent space sampled from a high-dimensional Gaussian distribution N (0, I).</figDesc><graphic coords="4,87,96,53,69,276,40,148,00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. 2D and 3D visualization results of the generated images and segmentation. (a, e) original image, (b, f) DeepRecon 1k , (c, g) DiffAE [19], (d, h) our proposed DMCVR. (Color figure online)</figDesc><graphic coords="7,73,80,353,99,276,28,139,84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Table 2 .Fig. 4 .</head><label>24</label><figDesc>Fig. 4. Visual comparison of 3D volumetric reconstruction from SAX images to LAX. Each row from top to bottom are 2ch, 3ch and 4ch images. The column from left to right represents: resampled original images using nearest neighbour (NN), resampled original labels using NN, resampled DMCVR images, resampled DMCVR labels and the corresponding LAX images.</figDesc><graphic coords="8,102,93,368,84,261,10,154,45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Quantitative comparison among the segmentation results of the original image (Original), DeepRecon with 1k optimization steps (DeepRecon 1k ), Diffusion AutoEncoder<ref type="bibr" target="#b18">[19]</ref> (DiffAE) and our DMCVR. We use a pretrained segmentation model on images generated by different methods. All metrics are evaluated against the ground truth based on 3D SAX images.</figDesc><table><row><cell cols="2">Cardiac Region Method</cell><cell cols="2">DICE â†‘ VOEâ†“ ASDâ†“ HDâ†“ ASSDâ†“</cell></row><row><cell>All labels</cell><cell>Original</cell><cell>0.943</cell><cell>10.730 0.229 4.056 0.229</cell></row><row><cell></cell><cell cols="2">DeepRecon 1k 0.914</cell><cell>15.179 0.367 5.879 0.397</cell></row><row><cell></cell><cell>DiffAE</cell><cell>0.919</cell><cell>14.913 0.322 4.654 0.326</cell></row><row><cell></cell><cell>DMCVR</cell><cell cols="2">0.935 12.153 0.261 4.093 0.266</cell></row><row><cell>LVC</cell><cell>Original</cell><cell>0.937</cell><cell>11.579 0.221 3.156 0.224</cell></row><row><cell></cell><cell cols="2">DeepRecon 1k 0.928</cell><cell>12.955 0.336 4.299 0.328</cell></row><row><cell></cell><cell>DiffAE</cell><cell>0.910</cell><cell>16.049 0.330 3.710 0.320</cell></row><row><cell></cell><cell>DMCVR</cell><cell>0.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>929 12.940 0.250 3.236 0.254</head><label></label><figDesc></figDesc><table><row><cell>LVM</cell><cell>Original</cell><cell>0.875</cell><cell>22.082 0.226 3.140 0.237</cell></row><row><cell></cell><cell cols="2">DeepRecon 1k 0.796</cell><cell>33.382 0.390 5.730 0.389</cell></row><row><cell></cell><cell>DiffAE</cell><cell>0.825</cell><cell>29.333 0.351 4.032 0.338</cell></row><row><cell></cell><cell>DMCVR</cell><cell>0.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>865 23.636 0.282 3.519 0.267</head><label></label><figDesc></figDesc><table><row><cell>RVC</cell><cell>Original</cell><cell>0.898</cell><cell>18.187 0.273 4.458 0.267</cell></row><row><cell></cell><cell cols="2">DeepRecon 1k 0.858</cell><cell>23.662 0.381 6.304 0.473</cell></row><row><cell></cell><cell>DiffAE</cell><cell>0.857</cell><cell>24.518 0.346 5.217 0.382</cell></row><row><cell></cell><cell>DMCVR</cell><cell cols="2">0.884 20.467 0.273 4.460 0.308</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement. This research has been partially funded by research grants to <rs type="person">D. Metaxas</rs> through <rs type="grantNumber">NSF: IUCRC CARTA 1747778</rs>, <rs type="grantNumber">2235405</rs>, <rs type="grantNumber">2212301</rs>, 1951890, 2003874, and <rs type="grantNumber">NIH-5R01HL127661</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_PEApgG2">
					<idno type="grant-number">NSF: IUCRC CARTA 1747778</idno>
				</org>
				<org type="funding" xml:id="_3ZgXF4e">
					<idno type="grant-number">2235405</idno>
				</org>
				<org type="funding" xml:id="_nBpbhay">
					<idno type="grant-number">2212301</idno>
				</org>
				<org type="funding" xml:id="_5EtcDEw">
					<idno type="grant-number">NIH-5R01HL127661</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Image2StyleGAN: how to embed images into the StyleGAN latent space?</title>
		<author>
			<persName><forename type="first">R</forename><surname>Abdal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wonka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4432" to="4441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">DeepRecon: joint 2D cardiac segmentation and 3D volume reconstruction via a structure-specific generative method</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Chang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16440-8_54</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16440-8" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022, Part IV</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13434</biblScope>
			<biblScope unit="page">54</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Tweedie&apos;s formula and selection bias</title>
		<author>
			<persName><forename type="first">B</forename><surname>Efron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">496</biblScope>
			<biblScope unit="page" from="1602" to="1614" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.00131</idno>
		<title level="m">A data-scalable transformer for medical image segmentation: architecture, model efficiency, and benchmark</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Quantification in cardiac MRI</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Van Der Geest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Reiber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Magn. Reson. Imaging Off. J. Int. Soc. Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="602" to="608" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Effective 3D humerus and scapula extraction using low-contrast and high-shape-variability MR data</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Metaxas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomedical Applications in Molecular, Structural, and Functional Imaging</title>
		<imprint>
			<biblScope unit="volume">10953</biblScope>
			<biblScope unit="page" from="118" to="124" />
			<date type="published" when="2019">2019. 2019</date>
			<publisher>SPIE</publisher>
		</imprint>
	</monogr>
	<note>Medical Imaging</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Denoising diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6840" to="6851" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Image quality metrics: PSNR vs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ziou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SSIM. In: 2010 20th International Conference on Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="2366" to="2369" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Automatic cardiac disease assessment on cine-MRI via time-series segmentation and domain specific features</title>
		<author>
			<persName><forename type="first">F</forename><surname>Isensee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Full</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Engelhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Maier-Hein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-75541-0_13</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-75541-013" />
	</analytic>
	<monogr>
		<title level="m">STACOM 2017</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Pop</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">10663</biblScope>
			<biblScope unit="page" from="120" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A style-based generator architecture for generative adversarial networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4401" to="4410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">TransFusion: multi-view divergent fusion for medical image segmentation with transformers</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16443-9_47</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16443-947" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022, Part V</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13435</biblScope>
			<biblScope unit="page" from="485" to="495" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Three-dimensional cardiac computational modelling: methods, features and applications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lopez-Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sebastian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Ferrero</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12938-015-0033-5</idno>
		<ptr target="https://doi.org/10.1186/s12938-015-0033-5" />
	</analytic>
	<monogr>
		<title level="j">Biomed. Eng. Online</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1" to="31" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Point set registration: coherent point drift</title>
		<author>
			<persName><forename type="first">A</forename><surname>Myronenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2262" to="2275" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Diagnostic performance of cardiac magnetic resonance imaging and echocardiography in evaluation of cardiac and paracardiac masses</title>
		<author>
			<persName><forename type="first">R</forename><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Cardiol</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="135" to="140" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Evaluation of cardiac function with magnetic resonance imaging</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Pattynama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>De Roos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">E</forename><surname>Van Der Wall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Van Voorthuisen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. Heart J</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="595" to="607" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Phase contrast cine magnetic resonance imaging</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Pelc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Herfkens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shimakawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Enzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Q</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="229" to="254" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A review of heart chamber segmentation for structural and functional analysis using cardiac magnetic resonance imaging</title>
		<author>
			<persName><forename type="first">P</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lekadir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gooya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10334-015-0521-4</idno>
		<ptr target="https://doi.org/10.1007/s10334-015-0521-4" />
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Mater. Phys., Biol. Med</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="155" to="195" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">UK biobank&apos;s cardiovascular magnetic resonance protocol</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Petersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cardiovasc. Magn. Reson</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Diffusion autoencoders: toward a meaningful and decodable representation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Preechakul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chatthee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wizadwongsa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Suwajanakorn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="10619" to="10629" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Quantification of cardiac function by conventional and cine magnetic resonance imaging</title>
		<author>
			<persName><forename type="first">U</forename><surname>Sechtem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pflugfelder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Higgins</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02577347</idno>
		<ptr target="https://doi.org/10.1007/BF02577347" />
	</analytic>
	<monogr>
		<title level="j">Cardiovasc. Intervent. Radiol</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="365" to="373" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Denoising diffusion implicit models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=St1giarCHLP" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Metrics for evaluating 3D medical image segmentation: analysis, selection, and tool</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Taha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Region proposal rectification towards robust instance segmentation of biological images</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhangli</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16440-8_13</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16440-813" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022, Part IV</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13434</biblScope>
			<biblScope unit="page" from="129" to="139" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
