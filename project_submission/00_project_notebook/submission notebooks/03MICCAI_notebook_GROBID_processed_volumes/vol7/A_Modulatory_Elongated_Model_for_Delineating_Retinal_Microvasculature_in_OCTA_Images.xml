<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Modulatory Elongated Model for Delineating Retinal Microvasculature in OCTA Images</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mohsin</forename><surname>Challoob</surname></persName>
							<email>mohsin.challoob@griffithuni.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Integrated and Intelligent Systems</orgName>
								<orgName type="institution">Griffith University</orgName>
								<address>
									<settlement>Brisbane</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yongsheng</forename><surname>Gao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Integrated and Intelligent Systems</orgName>
								<orgName type="institution">Griffith University</orgName>
								<address>
									<settlement>Brisbane</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andrew</forename><surname>Busch</surname></persName>
							<email>a.busch@griffith.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Integrated and Intelligent Systems</orgName>
								<orgName type="institution">Griffith University</orgName>
								<address>
									<settlement>Brisbane</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Weichuan</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Integrated and Intelligent Systems</orgName>
								<orgName type="institution">Griffith University</orgName>
								<address>
									<settlement>Brisbane</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Modulatory Elongated Model for Delineating Retinal Microvasculature in OCTA Images</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="714" to="723"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">046FCC857892807BA1F04BBEE4CC61CE</idno>
					<idno type="DOI">10.1007/978-3-031-43990-2_67</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-01T10:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Retinal vasculature</term>
					<term>OCTA</term>
					<term>Elongated responses</term>
					<term>Contextual information</term>
					<term>Modulatory influences</term>
					<term>Vessel features</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Robust delineation of retinal microvasculature in optical coherence tomography angiography (OCTA) images remains a challenging task, particularly in handling the weak continuity of vessels, low visibility of capillaries, and significant noise interferences. This paper introduces a modulatory elongated model to overcome these difficulties by exploiting the facilitatory and inhibitory interactions exhibited by the contextual influences for neurons in the primary visual cortex. We construct the receptive field of the neurons by an elongated representation, which encodes the underlying profile of vasculature structures, elongated-like patterns, in an anisotropic neighborhood. An annular function is formed to capture the contextual influences presented in the surrounding region outside the neuron support and provide an automatic tuning of contextual information. The proposed modulatory method incorporates the elongated responses with the contextual influences to produce spatial coherent responses for delineating microvasculature features more distinctively from their background regions. Experimental evaluation on clinical retinal OCTA images shows the effectiveness of the proposed model in attaining a promising performance, outperforming the state-of-the-art vessel delineation methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Optical coherence tomography angiography (OCTA) is a noninvasive ophthalmic imaging modality that captures the thin vessels and capillaries, named as microvasculature, present around the fovea and parafovea regions at various retinal depths. The 2D en face OCTA images have been increasingly used in clinical investigations for inspecting retinal eye diseases and systemic conditions at the capillary level resolution. More specifically, the morphological changes of retinal vasculature distributed within parafovea regions are associated with diseases such as diabetic retinopathy, early-stage glaucomatous optic neuropathy, macular telangiectasia type 2, uveitis, and age-related macular degeneration <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref>. In addition, analyzing retinal microvasculature at different depth layers can offer new pathological features that have not been reported before for clinically related findings. For instance, recent studies <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref> have manifested that the variations in the vascular morphology exhibited in OCTA images are associated with Alzheimer's disease, mild cognitive impairment, and chronic kidney disease. Therefore, the extraction of microvasculature from OCTA image is of a great interest. The reliability of phenotypes calculated for diagnosing retinal vascular-related diseases depend on the quality of segmented vascular trees. Since retinal vascular structures appear as a wire meshlike network that is associated with numerous branching and fusing, and considerable variations in contrast, the manual annotation of vasculature network is a labor-intensive, time-consuming, and error-prone procedure.</p><p>The automated delineation of retinal vasculature from OCTA images encounters several problems such as low signal-to-noise ratio (SNR), projection and motion artifacts, and inhomogeneous image background. A few methodologies have been used in the literature for detecting vessel trees in OCTA images. The majority of the vessel delineation approaches have been presented for color fundus images. Generally, the existing methods for vessel extraction from OCTA images can be categorized into supervised <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7]</ref> and unsupervised approaches <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9]</ref>. Li et al. <ref type="bibr" target="#b5">[6]</ref> proposed an image projection network that takes 3D OCTA data as input and produces 2D vessel segmentation results. A channel and spatial attention network was introduced by Mou et al. <ref type="bibr" target="#b6">[7]</ref> for extracting fine vessels from OCTA images. Recently, an OCTA-Net model by Ma et al. <ref type="bibr" target="#b1">[2]</ref> was presented to segment fine and coarse vessels separately. In spite of the popularity of deep learning models in the vessel detection task, these algorithms typically need a large amount of annotated samples used in intensive training processes to achieve vessel extraction task. Apart from supervised learning, Yousefi et al. <ref type="bibr" target="#b7">[8]</ref> developed a filtering approach based on multi-scale Hessian filter and morphological operations for the detection of microvascular structures in OCTA images. Zhang et al. <ref type="bibr" target="#b2">[3]</ref> combined curvelet denoising and optimally oriented flux algorithms to effectively enhance OCTA microvasculature. Gao et al. <ref type="bibr" target="#b8">[9]</ref> introduced a reflectance-adjusted thresholding method for binarizing superficial vascular complexes of en face retinal OCTA images. Further, the delineation methods <ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref> have attained encouraging results for vessel delineation in fundus color images. An operator inspired by the push-pull inhibition in the visual cortex was introduced by Strisciuglio et al. <ref type="bibr" target="#b9">[10]</ref> to increase the robustness of vessel detection against noise. Regularized volumed ratio <ref type="bibr" target="#b12">[13]</ref> considered vessels as rounded structures to produce strong responses for vessels with low contrast and preserve various vessel features. A bowler-hat transform <ref type="bibr" target="#b14">[15]</ref> was proposed to detect the inherent features of vessel-like structures. The existing algorithms have achieved a great progress for vessel enhancement and extraction. However, the following problems remain unsolved and need to be overcome for a reliable vasculature delineation in OCTA images. (i) Some vessels and capillaries suffer from the problem of weak continuity, which leads to a disjoint detection in segmented vascular trees. (ii) Due to the poor SNR of OCTA images, some capillaries are presented with an inadequate contrast, causing difficulty in differentiating them from inhomogeneous background. (iii) OCTA images are associated with high noise level, which significantly interferes with vessel structures and makes their boundary irregular.</p><p>This paper introduces a new modulatory elongated model to advance the delineation methodology of retinal microvasculature in OCTA images via addressing the above problems. The contributions of this work are summarized as follows. (1) A modulatory function is proposed to include two simultaneous facilitatory and inhibitory delineation processes that distinguish vascular trees more conspicuously from background. (2) The responses of the elongated representation encode the intrinsic profile of the vessels and capillaries, elongated-like shape, which retains the subtle intensity changes of vessels and capillaries for solving the continuity issue. (3) The proposed method disambiguates the region surrounding vessel structures for addressing the disturbance of noise at vascular regions. (4) Our method achieves the best quantitative and qualitative results over the state-of-the-art vessel delineation benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>The primary visual cortex (V1) has an essential role in the perception of objects in the visual system. The physiological studies revealed that the response of a V1 neuron to a stimulus in its receptive field can be either increased or decreased when more stimuli are added in the region surrounding the receptive field. The stimuli falling outside the classical receptive field (CRF) can exert modulatory effects on the activities of neurons in V1. The surrounding area beyond the CRF is named as a non-classical receptive filed (nCRF) modulation region, which captures long-range contextual information for modulating the neuron responses <ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref>. The modulatory effects resulted from the interaction between the CRF and nCRF extend the cortical area and allow visual cortex neurons to incorporate a broader range of visual field information to identify complex scenes. Based on the above neurophysiological evidences, we propose our modulatory elongated model as follows:</p><p>Responses of V1 Neurons. We propose to describe the responses of orientationselectivity V1 neurons to the stimuli placed within the classical receptive field (CRF) by an elongated representation. The elongated kernels <ref type="bibr" target="#b18">[19]</ref> can effectively simulate neuron responses at various characteristics such as preferred orientation, spatial scale and profile shape. The elongated responses are defined as:</p><formula xml:id="formula_0">θ σ,ρ (x, y) = ρ 2 σ 2 ρ 2 σ 2 (xcosθ + ysinθ ) 2 -1 g θ σ,ρ (x, y) (1)</formula><formula xml:id="formula_1">g θ σ,ρ (x, y) = 1 2πσ 2 exp - 1 2σ 2 x, y R -θ ρ 2 0 0 ρ -2 R θ x, y T (2)</formula><p>where σ &gt; 0 is the scaling factor that determines the width of the kernel and ρ &gt; 1 represents the anisotropic index that controls the elongation of kernel profiles. T is the matrix transpose and R θ denotes the rotation matrix with angle θ while (x, y) is a point location. In our implementation, we set σ ∈ [1 : 0.5 : 2.5], ρ ∈ (1 : 0.1 : 1.5] and θ ∈ π 16 , 2π 16 , 3π 16 , . . . , 15π 16 , π . θ σ,ρ (x, y) forms a pool of neuron responses for processing the local stimuli within the CRF. For an input OCTA image I(x, y), the final CRF response of a V1 neuron is obtained as:</p><formula xml:id="formula_2">ψ(x, y) = max σ,ρ,θ θ σ,ρ I (x, y) (3)</formula><p>where the notation represents the convolution operation in the spatial domain.</p><p>Contextual Influences for V1 Neurons. Physiological findings <ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref> illustrated that the region outside the CRF, which is termed as nCRF, of V1 neurons is alone unresponsive to visual stimuli, but it can manifest contextual influences on the neural responses to stimuli within the CRF. The contextual influences perform as a modulatory process that allows neurons in V1 to accumulate information from relatively large parts of visual space for participating in complex perceptual tasks. Also, the majority of modulatory influences are inhibitory while the reminders are facilitatory. Statistical data <ref type="bibr" target="#b19">[20]</ref> exhibited that around 80% of the orientation-selectivity neurons in V1 manifest the inhibitory effect. About 40% of these neurons show the inhibition regardless of the relative orientation between the surrounding stimuli and the optimal stimulus. Further, it has been indicated that the modulatory strength from the nCRF decays exponentially with increasing the distance from the center of the CRF <ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref>. Therefore, the intrinsic connections between the neurons and the region around them are distance related influences. Accordingly, we consider an isotropic modulatory behavior, in which contextual influences are independent of the orientation of surrounding patterns, but they take into account the distance to the surroundings. Then, an annular function (H i ) that captures contextual influences (H i ) for modulating V1 neurons is expressed as:</p><formula xml:id="formula_3">H i (x, y) = F -1 ((F(W) * F(ψ))(x, y)) 2 (4) W(x, y) = DoG(x, y) DoG(x, y) 1 (5) DoG(x, y) = 1 2π (kσ w ) 2 exp - x 2 + y 2 2(kσ w ) 2 - 1 2πσ 2 w exp - x 2 + y 2 2σ 2 w (<label>6</label></formula><formula xml:id="formula_4">)</formula><p>where F and F -1 represent forward and inverse discrete Fourier transforms, respectively while . 1 and . 2 indicate L 1 norm and L 2 norm, respectively. . denotes a truncated function that replaces negative values with zero. W(x, y) is a distance weighting function that is calculated by a 2D non-negative difference of Gaussian function DoG(x, y) <ref type="bibr" target="#b19">[20]</ref> with a standard deviation σ w = 7, which is utilized to simulate the strengths of neuron connection in distance. The factor k calculates the size of the nCRF region, and we set k = 4 to be consistent with the neurophysiological evidence <ref type="bibr" target="#b20">[21]</ref> that the extent of the nCRF is 2 to 5 times larger than that of CRF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contrast Influence on Contextual Information.</head><p>Physiological experiments <ref type="bibr" target="#b21">[22]</ref> have shown that contextual influences can vary with contrast attributes. For example, the inhibitory strength is decreased by lowering the contrast of stimulus within CRF, but when increasing the contrast, the inhibition grows relatively stronger. Thus, we introduce a contrastive operator (S i ), as defined below, to control the modulatory strength of the nCRF so that the contextual influences are adaptively varied with contrast at each location.</p><formula xml:id="formula_5">S i (x, y) = C l 2 (x, y) C l 2 + S d 2 (x, y) 1 -1/N 2 (7)</formula><p>where C l is a local range measure that returns the range value (maximum value-minimum value) using a patch of N × N neighborhood around the pixel (x, y) in the response of ψ.</p><p>S d computes the local standard deviation of the N × N patch around the corresponding input pixel of ψ response. We use N = 5 in our implementation.</p><p>Modulatory Function. The essence of the proposed modulatory model is that the response of the elongated representation at a specific point is modulated by the response of the representation presented in the area outside the region of the representation interest. We integrate the elongated responses with the contextual influences at each pixel to produce spatial coherent responses that enhance vessel structures more conspicuously from their background while reducing noise disturbances with vascular regions. The proposed modulatory model (M) is defined as:</p><formula xml:id="formula_6">M(x, y) = (ψ -S i .H i )(x, y) (S i + H i )(x, y) +<label>(8)</label></formula><p>where is a small value to avoid division by zero. When there are no spurious signals in the region surrounding the elongated responses, the modulatory influence from (H i and S i ) produces a weak response and the numerator (ψ -S i .H i ) of M becomes almost equal to the ψ. As a result, the term (H i + S i ) in the denominator together performs a faciliatory process for improving the responses of ψ. However, the influence of (H i and S i ) has a strong response when containing spurious signals in the surroundings. Then, the (H i and S i ) behave as an inhibitory process in both the numerator and denominator, which drops off the contribution of ψ to almost zero response.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Results</head><p>Datasets and Metrics. The proposed method is assessed on the ROSE-1 database <ref type="bibr" target="#b1">[2]</ref>, which is captured from 39 participants that consist of 26 subjects with Alzheimer disease and 13 healthy controls. We perform the experiments on the superficial vascular complexes (SVC) dataset and the inner retinal vascular plexus that includes both SVC and deep vascular complexes (DVC)-termed as (SVC + DVC) dataset. Vessel delineation results are only obtained on test set images of the ROSE-1 datasets. Also, we examine our method on OCTA500_6mm dataset (300 images) <ref type="bibr" target="#b5">[6]</ref> using the maximum projection between the internal limiting membrane (ILM) layer and the outer plexiform layer (OPL), named as an ILM_ OPL projection map. Most of OCTA500_6mm subjects (69.7%) were taken from a population with various retinal diseases such as age-related macular degeneration, choroidal neovascularization, central serous chorioretinopathy, diabetic retinopathy and retinal vein occlusion. For the used datasets, the pixel-level annotations of human experts are employed as the ground truths in our calculations. The following metrics are used to measure the quality of the delineation results in comparison with human annotations: precision-recall curve, accuracy (ACC), false discovery rate (FDR), geometric mean value (P VR ) of the positive predictive rate and the negative predictive rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Comparisons</head><p>. Figure <ref type="figure" target="#fig_0">1</ref> illustrates some examples of vascular delineation results produced by the proposed method and their corresponding manual annotations on OCTA images from the ROSE-1 (SVC and SVC + DVC) and OCTA500_6mm datasets. The performance of the proposed method on the used datasets is quantified using the precision-recall curve and compared with seven state-of-the-art vessel delineation benchmarks, as exhibited in Fig. <ref type="figure" target="#fig_1">2</ref>. The benchmark approaches are robust inhibitionaugmented curvilinear operator (RUSTICO) <ref type="bibr" target="#b9">[10]</ref>, morphological bowler-hat transform (MBT) <ref type="bibr" target="#b14">[15]</ref>, regularized volume ratio (RVR) <ref type="bibr" target="#b12">[13]</ref>, probabilistic fractional tensor (PFT) <ref type="bibr" target="#b13">[14]</ref>, scale and curvature invariant ridge detector (SCIRD) <ref type="bibr" target="#b11">[12]</ref>, phase congruency tensor (PCT) <ref type="bibr" target="#b10">[11]</ref>, and the second order generalized Gaussian directional derivative (SOGGDD) filter <ref type="bibr" target="#b18">[19]</ref>. Table <ref type="table" target="#tab_0">1</ref> reports the delineation results of all methods from the precisionrecall curve by selecting the best threshold that returns the highest average ACC on each dataset. As shown in Fig. <ref type="figure" target="#fig_1">2</ref>, the proposed method yields encouraging delineation results on the ROSE-1 and OCTA500_6mm images, validating its ability in extracting vascular structures from background interferences more effectively than the benchmark   <ref type="table" target="#tab_0">1</ref>, by achieving the best results of ACC, FDR, and P VR on the used datasets. Our delineation scores show large margins of improvement compared with benchmarks. For example, the proposed method attains the best scores of ACC = 0.910, P VR = 0.883, and FDR = 0.149 on ROSE-1 (SVC) dataset whilst the second-best scores obtained by benchmarks are ACC = 0.890 <ref type="bibr" target="#b11">[12]</ref>, P VR = 0.851 <ref type="bibr" target="#b14">[15]</ref>, and FDR = 0.188 <ref type="bibr" target="#b14">[15]</ref>. However, the proposed method consumes in average a computational time T s of 2.80 s and 3.86 s for processing an image of ROSE-1 and OCTA500_6mm datasets, respectively, which is longer than the benchmarks.</p><p>Performance on Challenging Cases. In Fig. <ref type="figure" target="#fig_2">3</ref>, we investigate the delineation performance of the proposed method and comparative benchmarks on some OCTA patch images that have the challenging cases of vessels and capillaries with weak continuity (first row), noise interferences with vessel structures (second row), and inadequate contrast of capillaries in a foveal avascular zone (third row). As illustrated in Fig. <ref type="figure" target="#fig_2">3</ref>-first row, the proposed method attains a superior delineation performance over the benchmarks for sustaining the spatial continuity of capillaries and vessels (red arrows) in resolving the disconnections in extracted vessel trees. Also, our method produces better results over the benchmarks in overcoming the interferences of noise that damage the spatial intensity of vessel structures, as shown in Fig. <ref type="figure" target="#fig_2">3</ref>-second row (yellow arrows). Figure <ref type="figure" target="#fig_2">3</ref>-third row shows the encouraging ability of the proposed method in addressing the challenge of the capillaries with low visibility, which are much better extracted than the benchmark approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>This paper presents a modulatory elongated model that exploits contextual modulatory effects presented for tuning the responses of neurons in V1. The proposed method incorporates the elongated responses, neuron responses, at a certain location with either a facilitatory or inhibitory process, contextual information, to reliably enable the delineation of vasculatures in OCTA images and the suppression of background inhomogeneities simultaneously. The validation phase on clinically relevant OCTA images illustrates the effectiveness of our method in producing promising vessel delineation results. The proposed method not only obtains the better quantitative results over the state-of-the-art benchmarks, but also produces an encouraging performance for retaining the continuity of vessels and capillaries, detecting the low-visibility capillaries, and handling spurious signals of noise and artifacts that interfere with vessel structures. Encouraging experimental results demonstrate the effectiveness of the proposed modulatory elongated model in improving the vessel delineation performance. Further, the proposed model is a non-learning approach that does not require any annotated samples or training procedures for performing vasculature detection. As the proposed method is not only responsive to the intrinsic profile of vessels, but also is sensitive to the region surrounding vessel structures, it can be a better alternative to the existing vessel delineation approaches that depend on surroundings-unaware operators.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Illustrative results obtained by the proposed method on example images from ROSE1-SVC (first row), ROSE1-(SVC + DVC) (second row), and OCTA500_6mm (ILM_ OPL) (last row) datasets. From left to right: original images, manual annotation results (red), and detection results by the proposed method (orange) respectively.</figDesc><graphic coords="6,63,96,57,20,324,67,324,19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Precision-Recall curves for the performance comparison of the proposed method and the state-of-the-art vessel delineation benchmarks on ROSE-1 (SVC and SVC + DVC) and OCTA500_6mm (ILM_ OPL) datasets.</figDesc><graphic coords="7,41,79,57,23,340,18,106,18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Delineation results in some difficult cases. From left to right: input image, the responses of the proposed method, SCIRD, PFT, MBT, RUSTICO, and RVR benchmarks, respectively. Red arrows (first row) indicate the vessels and capillaries presented with weak continuity while yellow arrows (second row) refer to where noise signals damage vessel features. The third row includes a foveal avascular zone, in which the majority of capillaries have low contrast.</figDesc><graphic coords="8,55,98,56,72,340,30,131,68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Delineation results of the proposed method compared to the state-of-the-art benchmarks on ROSE-1 and OCTA500_6mm (ILM_ OPL) datasets. Bold values indicate the best results.P VR ↑ FDR ↓ T s ↓ ACC ↑ P VR ↑ FDR ↓ T s ↓ ACC ↑ P VR ↑ FDR ↓ T s ↓</figDesc><table><row><cell>Dataset</cell><cell cols="2">ROSE-1 (SVC)</cell><cell cols="2">ROSE-1 (SVC + DVC)</cell><cell cols="2">OCTA500_6 mm</cell><cell></cell></row><row><cell cols="2">Method ACC ↑ Proposed 0.910</cell><cell>0.883 0.149</cell><cell>2.80 0.893</cell><cell>0.868 0.163</cell><cell>2.80 0.966</cell><cell>0.915 0.141</cell><cell>3.86</cell></row><row><cell>SOGGDD</cell><cell>0.888</cell><cell>0.844 0.209</cell><cell>2.68 0.876</cell><cell>0.834 0.215</cell><cell>2.68 0.949</cell><cell>0.857 0.238</cell><cell>3.75</cell></row><row><cell>[19]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>RUSTICO</cell><cell>0.874</cell><cell>0.810 0.265</cell><cell>1.50 0.868</cell><cell>0.810 0.256</cell><cell>1.50 0.941</cell><cell>0.835 0.270</cell><cell>2.08</cell></row><row><cell>[10]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">PCT [11] 0.873</cell><cell>0.817 0.248</cell><cell>1.12 0.861</cell><cell>0.808 0.251</cell><cell>1.12 0.949</cell><cell>0.862 0.226</cell><cell>1.50</cell></row><row><cell>SCIRD</cell><cell>0.890</cell><cell>0.849 0.202</cell><cell>1.40 0.878</cell><cell>0.839 0.208</cell><cell>1.40 0.952</cell><cell>0.876 0.203</cell><cell>1.85</cell></row><row><cell>[12]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>PFT [14]</cell><cell>0.880</cell><cell>0.815 0.263</cell><cell>0.90 0.857</cell><cell>0.789 0.288</cell><cell>0.90 0.950</cell><cell>0.870 0.212</cell><cell>1.32</cell></row><row><cell cols="2">MBT [15] 0.884</cell><cell>0.851 0.188</cell><cell>0.32 0.874</cell><cell>0.839 0.201</cell><cell>0.32 0.957</cell><cell>0.898 0.165</cell><cell>0.40</cell></row><row><cell cols="2">RVR [13] 0.889</cell><cell>0.836 0.230</cell><cell>0.33 0.867</cell><cell>0.808 0.259</cell><cell>0.33 0.954</cell><cell>0.884 0.188</cell><cell>0.42</cell></row><row><cell cols="7">approaches. Our method outperforms all benchmarks, as reported in Table</cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Optical coherence tomography angiography: a comprehensive review of current methods and clinical applications</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Kashani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Prog. Retin. Eye Res</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="66" to="100" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">ROSE: a retinal OCT-angiography vessel segmentation dataset and new model</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="928" to="939" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">3D shape modeling and analysis of retinal microvasculature in OCTangiography images</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1335" to="1346" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Retinal microvascular and neurodegenerative changes in Alzheimer&apos;s disease and mild cognitive impairment compared with control participants</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ophthalmol. Retina</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="489" to="499" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Retinal and choroidal vasculature changes associated with chronic kidney disease. Graefe&apos;s Arch</title>
		<author>
			<persName><forename type="first">M</forename><surname>Vadalà</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Castellucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Guarrasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clin. Exp. Ophthalmol</title>
		<imprint>
			<biblScope unit="volume">257</biblScope>
			<biblScope unit="page" from="1687" to="1698" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Image projection network: 3D to 2D image segmentation in OCTA images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3343" to="3354" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">CS-Net: channel and spatial attention network for curvilinear structure segmentation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Mou</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-32239-780</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-32239-780" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2019</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11764</biblScope>
			<biblScope unit="page" from="721" to="730" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Segmentation and quantification of blood vessels for OCTbased micro-angiograms using hybrid shape/intensity compounding</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yousefi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Microvasc. Res</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="37" to="46" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Compensation for reflectance variation in vessel density quantification by optical coherence tomography angiography</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Invest. Ophthalmol. Vis. Sci</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="4485" to="4492" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Robust inhibition-augmented operator for delineation of curvilinear structures</title>
		<author>
			<persName><forename type="first">N</forename><surname>Strisciuglio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Azzopardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Petkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="5852" to="5866" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Contrast-independent curvilinear structure detection in biomedical images</title>
		<author>
			<persName><forename type="first">B</forename><surname>Obara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fricker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gavaghan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Grau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2572" to="2581" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Scale and curvature invariant ridge detector for tortuous and fragmented structures</title>
		<author>
			<persName><forename type="first">R</forename><surname>Annunziata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kheirkhah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hamrah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Trucco</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-24574-4_70</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-24574-4_70" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2015</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hornegger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">9351</biblScope>
			<biblScope unit="page" from="588" to="595" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Ž: Enhancement of vascular structures in 3D and 2D angiographic images</title>
		<author>
			<persName><forename type="first">T</forename><surname>Jerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pernuš</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Likar</surname></persName>
		</author>
		<author>
			<persName><surname>Špiclin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2107" to="2118" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">2D and 3D vascular structures enhancement via multiscale fractional anisotropy tensor</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">F</forename><surname>Alhasson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Alharbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Obara</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-11024-6_26</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-11024-6_26" />
	</analytic>
	<monogr>
		<title level="m">ECCV 2018</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Leal-Taixé</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Roth</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11134</biblScope>
			<biblScope unit="page" from="365" to="374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The multiscale bowler-hat transform for blood vessel enhancement in retinal images</title>
		<author>
			<persName><forename type="first">Ç</forename><surname>Sazak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Obara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="739" to="750" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Contextual modulation in primary visual cortex</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zipser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lamme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Schiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="7376" to="7389" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Extensive integration field beyond the classical receptive field of cat&apos;s striate cortical neurons -classification and tuning properties</title>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vis. Res</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page" from="2337" to="2355" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Contextual modulation in primary visual cortex of macaques</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Desimone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ungerleider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1698" to="1709" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Corner detection using second-order generalized Gaussian directional derivative representations</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1213" to="1224" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Contour and boundary detection improved by surround suppression of texture edges</title>
		<author>
			<persName><forename type="first">C</forename><surname>Grigorescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Petkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Westenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Vis. Comput</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="609" to="622" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Spatial distribution of contextual interactions in primary visual cortex and in visual perception</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kapadia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Westheimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gilbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurophysiol</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2048" to="2062" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Contrast dependence of center and surround integration in primary visual cortex of the cat</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bardy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fitzgibbon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dreher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Vis</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
