<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Skin Lesion Correspondence Localization in Total Body Photography</title>
				<funder ref="#_Q4Yyuqj">
					<orgName type="full">Phase I NIH/NIBIB STTR</orgName>
				</funder>
				<funder ref="#_Nu2CBXA">
					<orgName type="full">NIH/NICHD, Phase I of NSF</orgName>
				</funder>
				<funder>
					<orgName type="full">Intramural Research Program</orgName>
					<orgName type="abbreviated">IRP</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Wei-Lun</forename><surname>Huang</surname></persName>
							<email>whuang44@jh.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Johns Hopkins University</orgName>
								<address>
									<settlement>Baltimore</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Davood</forename><surname>Tashayyod</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Lumo Imaging</orgName>
								<address>
									<settlement>Rockville</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jun</forename><surname>Kang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Dermatology</orgName>
								<orgName type="institution">Johns Hopkins School of Medicine</orgName>
								<address>
									<settlement>Baltimore</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Amir</forename><surname>Gandjbakhche</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Eunice Kennedy Shriver National Institute of Child Health and Human Development</orgName>
								<address>
									<settlement>Bethesda</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><surname>Kazhdan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Johns Hopkins University</orgName>
								<address>
									<settlement>Baltimore</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mehran</forename><surname>Armand</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Johns Hopkins University</orgName>
								<address>
									<settlement>Baltimore</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Orthopaedic Surgery</orgName>
								<orgName type="institution">Johns Hopkins University</orgName>
								<address>
									<settlement>Baltimore</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Skin Lesion Correspondence Localization in Total Body Photography</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="260" to="269"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">1526FB61DF0EF0E468EAB7568071D4FB</idno>
					<idno type="DOI">10.1007/978-3-031-43990-2_25</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-01T10:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Total body photography</term>
					<term>Skin lesion longitudinal tracking</term>
					<term>3D correspondence</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Longitudinal tracking of skin lesions -finding correspondence, changes in morphology, and texture -is beneficial to the early detection of melanoma. However, it has not been well investigated in the context of full-body imaging. We propose a novel framework combining geometric and texture information to localize skin lesion correspondence from a source scan to a target scan in total body photography (TBP). Body landmarks or sparse correspondence are first created on the source and target 3D textured meshes. Every vertex on each of the meshes is then mapped to a feature vector characterizing the geodesic distances to the landmarks on that mesh. Then, for each lesion of interest (LOI) on the source, its corresponding location on the target is first coarsely estimated using the geometric information encoded in the feature vectors and then refined using the texture information. We evaluated the framework quantitatively on both a public and a private dataset, for which our success rates (at 10 mm criterion) are comparable to the only reported longitudinal study. As full-body 3D capture becomes more prevalent and has higher quality, we expect the proposed method to constitute a valuable step in the longitudinal tracking of skin lesions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Evolution, the change of pigmented skin lesions, is a risk factor for melanoma <ref type="bibr" target="#b0">[1]</ref>. Therefore, longitudinal tracking of skin lesions over the whole body is beneficial for early detection of melanoma <ref type="bibr" target="#b4">[5]</ref>. However, establishing skin lesion correspondences across multiple scans from different patient visits has not been well investigated in the context of full-body imaging.</p><p>Several techniques have been proposed to match skin lesions across pairs of 2D images <ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b24">25]</ref>. Early work used geometric constraints imposed by initial matches of skin lesions (manual selection or automatic detection) to align images and further match other skin lesions <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b24">25]</ref>. Mirzaalian and colleagues published a series of works for establishing lesion correspondence in image space <ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref>. Li et al. <ref type="bibr" target="#b8">[9]</ref> used a CNN to output a 2D vector field for pixel-wise correspondences between the two input images. Though effective at matching skin lesions across pairs of images, the extension of these methods to the context of total body photography (TBP) for longitudinal tracking remains a challenge.</p><p>Several works have been proposed for tackling the skin lesion tracking problem over the full body <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22]</ref>. However, they are either only applicable in well-controlled environments or do not extend to the tracking of lesions across scans at different visits. Recently, the concept of finding lesion correspondence using a 3D representation of the human body has been explored in <ref type="bibr" target="#b25">[26]</ref> and <ref type="bibr" target="#b1">[2]</ref> by using a template mesh. However, accurately deforming a template mesh to fit varying body shapes is challenging when the scanned shape deviates from the template, leading to large errors in downstream tasks such as establishing shape correspondence. Additionally, <ref type="bibr" target="#b25">[26]</ref> does not take advantage of texture, while <ref type="bibr" target="#b1">[2]</ref> uses texture in a common UV map that may lead to failures when geodesically close locations on the surface are mapped to distant sites in the texture map (e.g. when the two locations are on opposite sides of a texture seam).</p><p>We propose a novel framework for finding skin lesion correspondence iteratively using geometric and texture information (Fig. <ref type="figure" target="#fig_0">1</ref>). We demonstrate the effectiveness of the proposed method in localizing lesion correspondence across scans in a manner that is robust to changes in body pose and camera viewing directions. Our code is available at https://github.com/weilunhuang-jhu/ LesionCorrespondenceTBP3D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>Given a set of lesions of interest (LOIs) X in the source mesh, we would like to find their corresponding positions Y in the target mesh. Formally, we assume we are given source and target meshes, M 0 and M 1 , with vertex sets</p><formula xml:id="formula_0">V k ⊂ M k and corresponding landmark sets L k ⊂ V k with |L 0 | = |L 1 | = S.</formula><p>We achieve this by computing a dense correspondence map Φ L, : V 0 → V 1 , initially defined using geometric information and refined using textural information. Then we use that to define a map taking lesions of interest on the source to positions on the target Φ : X → V 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Landmark-Based Correspondences</head><p>We define an initial dense correspondence between source and target vertices by leveraging the sparse landmark correspondences <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b5">6]</ref>. We do this by mapping source and target vertices into a high-dimensional space, based on their proximity to the landmarks, and then comparing positions in the high-dimensional space.</p><p>Concretely, we define maps k : V k → R S , associating a vertex v ∈ V k with an S-dimensional feature descriptor that describes the position of v relative to the landmarks:</p><formula xml:id="formula_1">k (v) = 1 D k (v, l 1 ) , • • • , 1 D k (v, l S )<label>(1)</label></formula><p>where</p><formula xml:id="formula_2">D k : M k × M k → R ≥0</formula><p>is the geodesic distance function on M k . We use the reciprocal of geodesic distance so that landmarks closer to v contribute more significantly to the feature vector. Given this mapping, we create an initial dense correspondence between the source and target vertices, Φ L, : V 0 → V 1 by mapping a source vertex v ∈ V 0 to the target vertex with the most similar feature descriptor (with similarity measured in terms of the normalized cross-correlation):</p><formula xml:id="formula_3">Φ L, (v) = arg max v ∈V1 C L, (v, v ) = 0 (v), 1 (v ) || 0 (v)|| • || 1 (v )|| . (<label>2</label></formula><formula xml:id="formula_4">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Texture-Based Refinement</head><p>While feature descriptors of corresponding vertices on the source and target mesh are identical when 1) the landmarks are in perfect correspondence, and 2) the source and target differ by an isometry, neither of these assumptions holds in realworld data. To address this, we use local texture to assign an additional feature descriptor to each vertex and use these texture-based descriptors to refine the coarse correspondence given by Φ L, : V 0 → V 1 . Various texture descriptors have been proposed, e.g. SHOT <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24]</ref>, RoPS <ref type="bibr" target="#b3">[4]</ref>, and ECHO <ref type="bibr" target="#b14">[15]</ref>. We selected the ECHO descriptor for its better descriptiveness and robustness to noise. Letting k (v) ∈ R N denote the ECHO descriptor of vertex v ∈ V k , our goal is to refine the dense correspondence so that corresponding source and target vertices also have similar descriptors. However, to avoid problems with repeating (local) textures, we would also like the correspondence to stay close to the correspondence defined by the landmarks.</p><p>We achieve this as follows: To every source vertex v ∈ V 0 we associate a region R v ⊂ V 1 of target vertices that are either close to Φ L, (v) (the corresponding vertex on V 1 as predicted by the landmarks) or have similar geometric feature descriptors:</p><formula xml:id="formula_5">R v = v ∈ V 1 D 1 (v , Φ L, (v)) &lt; ε 1 or C L, (v , Φ L, (v)) &gt; ε 2 .</formula><p>(</p><formula xml:id="formula_6">)<label>3</label></formula><p>Given this region, we define the target vertex corresponding to a source as the vertex within the region that has the most similar ECHO descriptor (using the normalized cross-correlation as before).</p><p>In practice, we compute the ECHO descriptor over three different radii, obtaining three descriptors for each vertex,</p><formula xml:id="formula_7">1 k (v), 2 k (v), 3 k (v) ∈ R N .</formula><p>The selection of three different radii in ECHO descriptors is done to accommodate different sizes of lesions and their surrounding texture, and the values are empirically determined. This gives a mapping Φ L, : V 0 → V 1 defined in terms of the weighted sum of cross-correlations:</p><formula xml:id="formula_8">Φ L, (v) = arg max v ∈Rv C L, (v, v ) = 3 i=1 w i i 0 (v), i 1 (v ) i 0 (v) • i 1 (v ) , (<label>4</label></formula><formula xml:id="formula_9">)</formula><p>where</p><formula xml:id="formula_10">C L, (v, v ) ∈ [0, 1]</formula><p>is the texture score of the target vertex v and w i is the weight of the cross-correlation between the ECHO descriptors computed at each radius.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Iterative Skin Lesion Correspondence Localization Framework</head><p>While each source LOI has a corresponding position on the target mesh as given by Φ L, :</p><formula xml:id="formula_11">V 0 → V 1</formula><p>, not all correspondences are localized with high confidence when 1) the local texture is not well-preserved across scans and 2) the local region R v does not include the true correspondence. To address this, we adapt our algorithm for computing the correspondence map Φ : X → V 1 by iteratively growing the set of landmarks to include LOI correspondences about which we are confident, similar to the way in which a human annotator would label lesion correspondence (Fig. <ref type="figure" target="#fig_1">2</ref>). Iteratively Anchor Confident Correspondences. We iteratively compute correspondence maps Φ k L, :</p><formula xml:id="formula_12">V 0 → V 1 and Φ k L, : V 0 → V 1</formula><p>, with the superscript denoting the k th iteration. For each map Φ k L, and every LOI x ∈ X, we determine if we are confident in the correspondence {x, Φ k L, (x)} by evaluating a binary function χ k L : X → {0, 1}. Denoting by X the subset of LOIs about which we are confident, we add the pairs {x , Φ k L, (x )} to the landmark set L and remove the LOI x ∈ X from X. We iterate this process until all the correspondences of LOIs are confidently found or a maximum number of iterations (K) have been performed.</p><p>Lesion correspondence confidence is measured using three criteria: i) texture similarity, ii) agreement between geometric and textural correspondences, and iii) the unique existence of a similar lesion within a region. To quantify uniqueness, we compute the set of target vertices whose textural descriptor is similar to that of the LOI:</p><formula xml:id="formula_13">S δ x = v ∈ R x C L, (x, v ) &gt; δ ,<label>(5)</label></formula><p>and consider the diameter of the set (defined in terms of the mean of the distances of vertices in S δ x from the centroid of S δ x ). Putting this together, we define confidence as</p><formula xml:id="formula_14">χ k L (x) = CL, x, Φ k L, (x) &gt; ε3 ∨ D1 Φ k L, (x), Φ k L, (x) &lt; ε4 ∨ ∅(S δ</formula><p>x ) &lt; ε5, <ref type="bibr" target="#b5">(6)</ref> where the initial values of thresholds ε i are empirically chosen. To further support establishing correspondences, we relax the thresholds ε i in subsequent iterations, allowing us to consider correspondences that are further away and about which we are less confident.</p><p>Final Correspondence Map. Having mapped every high-confidence LOI to a corresponding target vertex, we must complete the correspondence for the remaining low-confidence LOIs. We note that for a low-confidence LOI x ∈ X, the texture in the source mesh is not well-matched to the texture in the target, for any v ∈ R x . (Otherwise the first term in χ k L would be large.) To address this, we would like to focus on landmark-based similarity. However, by definition of R x , for all v ∈ R x , we know that the landmark descriptors of x and v will all be similar, so that C L, will not be discriminating. Instead, we use a standard transformation to turn distances into similarities. Specifically, we define geometric score between a source LOI x and a target vertex v ∈ R x in terms of the geodesic distance between v and the corresponding position of x in V 1 , as predicted by the landmark descriptors:</p><formula xml:id="formula_15">C L (x, v ) = e -1 2σ 2 D 2 1 (v , Φ K L, (x)) ∈ [0, 1] , (<label>7</label></formula><formula xml:id="formula_16">)</formula><p>where σ is the maximum geodesic distance from a vertex within R x to Φ K L, (x). Therefore, for a remaining LOI, we define its corresponding target vertex as the vertex with the highest weighted sum of the geometric and texture scores:</p><formula xml:id="formula_17">Φ(x) = arg max v ∈Rx w 1 • C L (x, v ) + w 2 • C L,ε (x, v ) , (<label>8</label></formula><formula xml:id="formula_18">)</formula><p>where w 1 and w 2 are the weights for combining the scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation and Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset</head><p>We evaluated our methods on two datasets. The first dataset is from Skin3D <ref type="bibr" target="#b25">[26]</ref> (annotated 3DBodyTex <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref>). The second dataset comes from a 2D Imaging-Rich Total Body Photography system (IRTBP), from which the 3D textured meshes are derived from photogrammetry 3D reconstruction. The number of vertices is on average 300K and 600K for Skin3D and IRTBP datasets respectively. The runtime using 10 iterations is several minutes (on average) on an Intel i7-11857G7 processor. Example data of the two datasets can be found in the supplement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Correspondence Localization Error and Success Rate</head><p>Average correspondence localization error (CLE) for individual subjects, defined as the geodesic distance between the ground-truth and the estimated lesion correspondence, is shown in Fig. <ref type="figure" target="#fig_2">3</ref>. To interpret CLE in a clinical application, the localized correspondence is successful if its CLE is less than a threshold criterion.</p><p>We measured the success rate as the percentage of the correctly localized skin lesions over the total number of skin lesion pairs in the dataset.</p><p>To compare our result to the existing method <ref type="bibr" target="#b25">[26]</ref>, we compute our success rates with the threshold criterion at 10 mm. As shown in Table <ref type="table">1</ref>, the performance of our method is comparable to the previously reported longitudinal accuracy. The qualitative result of the localized correspondence in the Skin3D dataset is shown in Fig. <ref type="figure" target="#fig_3">4</ref>. A table of parameters used in the experiments can be found in the supplement. Table <ref type="table">1</ref>. Comparison of the success rate on Skin3D dataset. Each metric is computed on a pair of meshes (for one subject) and averaged across paired meshes with the standard deviation shown in brackets. The method Texture radius 50 and Combined radius 50 are defined in Fig. <ref type="figure" target="#fig_4">5</ref>.</p><p>Skin3D <ref type="bibr" target="#b25">[26]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Usage of Texture on 3D Surface</head><p>We believe that the geometric descriptor only provides a coarse correspondence while the local texture is more discriminating. Figure <ref type="figure" target="#fig_4">5</ref> shows the success rate under different threshold criteria for the proposed methods. Since we have two combinations of defining source and target for two scans, we measured the result in both to ensure consistency (Fig. <ref type="figure" target="#fig_4">5</ref>(a) and (b)). As expected, we observed that using geometric information with body landmarks and geodesic distances is insufficient for localizing lesion correspondence accurately. However, the correspondence map Φ L, refined with local texture may lead to correspondences with large CLE when using a large region R x . The figure shows the discriminating power and the large-error-prone property of using Φ L, to localize lesion correspondence with one iteration (relatively high success rates under strict criteria and relatively low success rates under loose criteria, compared to the correspondence map combining geometric and texture scores in Eq. 8). The figure also shows the effectiveness of the proposed algorithm when the iterative anchor mechanism is used to localize lesion correspondence, having consistently higher success rates with the criteria within 20 mm.  Iterative algorithm is the proposed algorithm with the anchor mechanism. Shape is the method using Φ 1 L, . Texture radius 25 and texture radius 50 are the methods using Φ 1 L, with ε1 (Eq. 3) selected at 25 mm and 50 mm. Combined radius 25 and combined radius 50 are the methods using Eq. 8 with one iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions and Limitations</head><p>The evolution of a skin lesion is an important sign of a potentially cancerous growth and total body photography is useful to keep track of skin lesions longitudinally. We proposed a novel framework that leverages geometric and texture information to effectively find lesion correspondence across TBP scans. The framework is evaluated on a private dataset and a public dataset with success rates that are comparable to those of the state-of-the-art method.</p><p>The proposed method assumes that the local texture enclosing the lesion and its surroundings should be similar from scan to scan. This may not hold when the appearance of the lesion changes dramatically (e.g. if the person acquires a tattoo). Also, the resolution of the mesh affects the precision of the positions of landmarks and lesions. In addition, the method may not work well with longitudinal data that has non-isometric deformation due to huge variations in body shape, inconsistent 3D reconstruction, or a dramatic change in pose and, therefore, topology, such as an open armpit versus a closed one.</p><p>In the future, the method needs to be evaluated on longitudinal data with longer duration and new lesions absent in the target. In addition, an automatic method to determine accurate landmarks is desirable. Note that although we rely on the manual selection of landmarks, the framework is still preferable over manually annotating lesion correspondences when a subject has hundreds of lesions. As the 3D capture of the full body becomes more prevalent with better quality in TBP, we expect that the proposed method will serve as a valuable step for the longitudinal tracking of skin lesions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Visualization of the correspondence localization workflow with geometric and texture information. (a) and (c) show a source and a target textured mesh with landmarks (black dots) and labeled lesions of interest (color dots). (b) shows the geodesic paths from a lesion x in (a) to all the landmarks. (d) shows the correspondence of the lesion Φ L, (x) derived from the geometric feature descriptors. (e) shows the local region Rx for refining the position of the correspondence. (f) shows the correspondence of the lesion ΦL, (x) from the local texture descriptors. (g) shows the lesion correspondences with confidence and anchored as new landmarks after one iteration.</figDesc><graphic coords="3,45,30,53,78,333,28,140,92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Block diagram of the iterative lesion correspondence localization algorithm.</figDesc><graphic coords="5,50,31,54,44,323,56,99,28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Mean and standard deviation of correspondence localization error (CLE) for individual subjects in (a) Skin3D and (b) IRTBP datasets evaluated with the proposed methods. There are 10 and 3 subjects in the Skin3D and IRTBP datasets respectively. The number of LOIs for individual subjects is included in the parentheses.</figDesc><graphic coords="7,44,79,54,26,334,33,93,43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. The qualitative result on Skin3D dataset. (a) shows a source scan (left) and the scan with annotated LOIs (right). (b) shows a target scan (left) and the scan with annotated LOIs (transparent sphere) and the estimated correspondence of LOIs (solid dot) (right). The lesion correspondence pairs are shown in the same color. Large CLE occurs when the local texture is not well-preserved across scans.</figDesc><graphic coords="8,73,47,262,70,305,14,110,95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Success rate under different criteria for the proposed algorithm on the Skin3D dataset. (a) and (b) show the results of two combinations of source and target meshes.Iterative algorithm is the proposed algorithm with the anchor mechanism. Shape is the method using Φ 1 L, . Texture radius 25 and texture radius 50 are the methods using Φ 1 L, with ε1 (Eq. 3) selected at 25 mm and 50 mm. Combined radius 25 and combined radius 50 are the methods using Eq. 8 with one iteration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Texture radius 50 Combined radius 50 Iterative algorithm</figDesc><table><row><cell>Success rate 0.5 (0.38)</cell><cell>0.48 (0.17)</cell><cell>0.45 (0.14)</cell><cell>0.57 (0.14)</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. The research was in part supported by the <rs type="funder">Intramural Research Program (IRP)</rs> of the <rs type="funder">NIH/NICHD, Phase I of NSF</rs> <rs type="grantName">STTR grant</rs> <rs type="grantNumber">2127051</rs>, and <rs type="funder">Phase I NIH/NIBIB STTR</rs> grant <rs type="grantNumber">R41EB032304</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Nu2CBXA">
					<idno type="grant-number">2127051</idno>
					<orgName type="grant-name">STTR grant</orgName>
				</org>
				<org type="funding" xml:id="_Q4Yyuqj">
					<idno type="grant-number">R41EB032304</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43990-2_25.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Early diagnosis of cutaneous melanoma: revisiting the ABCD criteria</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Abbasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMA</title>
		<imprint>
			<biblScope unit="volume">292</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="2771" to="2776" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Automated detection of new or evolving melanocytic lesions using a 3D body model</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bogo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Peserico</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-10404-1_74</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-10404-1_74" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2014</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Golland</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Hata</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Barillot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hornegger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Howe</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">8673</biblScope>
			<biblScope unit="page" from="593" to="600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Geodesic distances to landmarks for dense correspondence on ensembles of complex shapes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Datar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Styner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Whitaker</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-40763-5_3</idno>
		<ptr target="https://doi.org/10.1007/978-3-642-40763-5_3" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2013</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Mori</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Sakuma</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Sato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Barillot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">8150</biblScope>
			<biblScope unit="page" from="19" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Rotational projection statistics for 3D local surface description and object recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sohel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bennamoun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vision</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="63" to="86" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Total body skin imaging as an aid to melanoma detection</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Halpern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Seminars in Cutaneous Medicine and Surgery</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="2" to="8" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep virtual markers for articulated 3D shapes</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="11615" to="11625" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An improved skin lesion matching scheme in total body photography</title>
		<author>
			<persName><forename type="first">K</forename><surname>Korotkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Biomed. Health Inform</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="586" to="598" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A new total body scanning system for automatic change detection in multiple pigmented skin lesions</title>
		<author>
			<persName><forename type="first">K</forename><surname>Korotkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Quintana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Puig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malvehy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garcia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="317" to="338" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Skin cancer detection and tracking using data synthesis and deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Esteva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kuprel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Novoa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.01074</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Automatic registration of images of pigmented skin lesions</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mcgregor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="805" to="817" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A graph-based approach to skin mole matching incorporating template-normalized coordinates</title>
		<author>
			<persName><forename type="first">H</forename><surname>Mirzaalian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hamarneh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="2152" to="2159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Uncertainty-based feature learning for skin lesion matching using a high order MRF optimization framework</title>
		<author>
			<persName><forename type="first">H</forename><surname>Mirzaalian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hamarneh</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-33418-4_13</idno>
		<ptr target="https://doi.org/10.1007/978-3-642-33418-4_13" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2012</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ayache</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Delingette</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Golland</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Mori</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">7511</biblScope>
			<biblScope unit="page" from="98" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Spatial normalization of human back images for dermatological studies</title>
		<author>
			<persName><forename type="first">H</forename><surname>Mirzaalian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hamarneh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Biomed. Health Inform</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1494" to="1501" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Skin lesion tracking using structured graphical models</title>
		<author>
			<persName><forename type="first">H</forename><surname>Mirzaalian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hamarneh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="84" to="92" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Echo: extended convolution histogram of orientations for local surface description</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Mitchel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rusinkiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Chirikjian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kazhdan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="180" to="194" />
			<date type="published" when="2021">2021</date>
			<publisher>Wiley Online Library</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Automatic registration of multiple skin lesions by use of point pattern matching</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Perednia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Med. Imaging Graph</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="205" to="216" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Registration of nevi in successive skin images for early detection of melanoma</title>
		<author>
			<persName><forename type="first">J</forename><surname>Roning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Riech</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. Fourteenth International Conference on Pattern Recognition (Cat. No. 98EX170)</title>
		<meeting>Fourteenth International Conference on Pattern Recognition (Cat. No. 98EX170)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="352" to="357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">3DBodyTex: textured 3D body dataset</title>
		<author>
			<persName><forename type="first">A</forename><surname>Saint</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cherenkova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gusev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Aouada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ottersten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 International Conference on 3D Vision (3DV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="495" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Saint</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cherenkova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gusev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Aouada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ottersten</surname></persName>
		</author>
		<title level="m">2019 IEEE International Conference on Image Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="484" to="488" />
		</imprint>
	</monogr>
	<note>Bodyfitr: robust automatic 3D human body fitting</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Shot: unique signatures of histograms for surface and texture description</title>
		<author>
			<persName><forename type="first">S</forename><surname>Salti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tombari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Di Stefano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Image Underst</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="page" from="251" to="264" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Skin lesion matching algorithm for application in full body imaging systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Strakowska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kociołek</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-09135-3_19</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-09135-3_19" />
	</analytic>
	<monogr>
		<title level="m">ITIB 2022. Advances in Intelligent Systems and Computing</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Pietka</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Badura</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Kawa</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Wieclawek</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1429</biblScope>
			<biblScope unit="page" from="222" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Skin lesion detection algorithms in whole body images</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Strzelecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Strąkowska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kozłowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Urbańczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wielowieyska-Szybińska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kociołek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">19</biblScope>
			<biblScope unit="page">6639</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Unique signatures of histograms for local surface description</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tombari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Salti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Di Stefano</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-15558-1_26</idno>
		<ptr target="https://doi.org/10.1007/978-3-642-15558-1_26" />
	</analytic>
	<monogr>
		<title level="m">ECCV 2010</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Daniilidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Maragos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Paragios</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6313</biblScope>
			<biblScope unit="page" from="356" to="369" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A combined texture-shape descriptor for enhanced 3D feature matching</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tombari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Salti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Di Stefano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 18th IEEE International Conference on Image Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="809" to="812" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Automatic derivation of initial match points for paired digital images of skin</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Perednia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Med. Imaging Graph</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="217" to="225" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Skin3D: detection and longitudinal tracking of pigmented skin lesions in 3D total-body textured meshes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Abhishek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shamanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hamarneh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page">102329</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
