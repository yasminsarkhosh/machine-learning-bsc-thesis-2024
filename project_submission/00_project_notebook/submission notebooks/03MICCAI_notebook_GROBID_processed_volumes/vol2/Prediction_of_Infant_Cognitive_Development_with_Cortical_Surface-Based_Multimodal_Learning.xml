<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Prediction of Infant Cognitive Development with Cortical Surface-Based Multimodal Learning</title>
				<funder ref="#_7c2MYQK #_zjHcE23 #_htjVMf6 #_rFHp97u #_ckJjmKw #_28cnN3h">
					<orgName type="full">National Institutes of Health</orgName>
					<orgName type="abbreviated">NIH</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jiale</forename><surname>Cheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic and Information Engineering</orgName>
								<orgName type="institution">South China University of Technology</orgName>
								<address>
									<settlement>Guangzhou, Guangdong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Radiology and Biomedical Research Imaging Center</orgName>
								<orgName type="institution">University of North Carolina at Chapel Hill</orgName>
								<address>
									<addrLine>Chapel Hill</addrLine>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xin</forename><surname>Zhang</surname></persName>
							<email>eexinzhang@scut.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Electronic and Information Engineering</orgName>
								<orgName type="institution">South China University of Technology</orgName>
								<address>
									<settlement>Guangzhou, Guangdong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">Pazhou Laboratory</orgName>
								<address>
									<settlement>Guangzhou, Guangdong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fenqiang</forename><surname>Zhao</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Radiology and Biomedical Research Imaging Center</orgName>
								<orgName type="institution">University of North Carolina at Chapel Hill</orgName>
								<address>
									<addrLine>Chapel Hill</addrLine>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhengwang</forename><surname>Wu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Radiology and Biomedical Research Imaging Center</orgName>
								<orgName type="institution">University of North Carolina at Chapel Hill</orgName>
								<address>
									<addrLine>Chapel Hill</addrLine>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xinrui</forename><surname>Yuan</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Radiology and Biomedical Research Imaging Center</orgName>
								<orgName type="institution">University of North Carolina at Chapel Hill</orgName>
								<address>
									<addrLine>Chapel Hill</addrLine>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Li</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Radiology and Biomedical Research Imaging Center</orgName>
								<orgName type="institution">University of North Carolina at Chapel Hill</orgName>
								<address>
									<addrLine>Chapel Hill</addrLine>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Weili</forename><surname>Lin</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Radiology and Biomedical Research Imaging Center</orgName>
								<orgName type="institution">University of North Carolina at Chapel Hill</orgName>
								<address>
									<addrLine>Chapel Hill</addrLine>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gang</forename><surname>Li</surname></persName>
							<email>gang_li@med.unc.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Radiology and Biomedical Research Imaging Center</orgName>
								<orgName type="institution">University of North Carolina at Chapel Hill</orgName>
								<address>
									<addrLine>Chapel Hill</addrLine>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Prediction of Infant Cognitive Development with Cortical Surface-Based Multimodal Learning</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="618" to="627"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">99BF4D60C292DC103B882D0C61A0B091</idno>
					<idno type="DOI">10.1007/978-3-031-43895-0_58</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-01T10:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Cognition Prediction</term>
					<term>Multimodality</term>
					<term>rs-fMRI</term>
					<term>sMRI</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Exploring the relationship between the cognitive ability and infant cortical structural and functional development is critically important to advance our understanding of early brain development, which, however, is very challenging due to the complex and dynamic brain development in early postnatal stages. Conventional approaches typically use either the structural MRI or resting-state functional MRI and rely on the region-level features or inter-region connectivity features after cortical parcellation for predicting cognitive scores. However, these methods have two major issues: 1) spatial information loss, which discards the critical fine-grained spatial patterns containing rich information related to cognitive development; 2) modality information loss, which ignores the complementary information and the interaction between the structural and functional images. To address these issues, we unprecedentedly invent a novel framework, namely cortical surface-based multimodal learning framework (CSML), to leverage fine-grained multimodal features for cognition development prediction. First, we introduce the fine-grained surface-based data representation to capture spatially detailed structural and functional information. Then, a dual-branch network is proposed to extract the discriminative features for each modality respectively and further captures the modality-shared and complementary information with a disentanglement strategy. Finally, an age-guided cognition prediction module is developed based on the prior that the cognition develops along with age. We validate our method on an infant multimodal MRI dataset with 318 scans. Compared to state-of-the-art methods, our method consistently achieves superior performances, and for the first time suggests crucial regions and features for cognition development hidden in the fine-grained spatial details of cortical structure and function.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Predictive modeling of the individual-level cognitive development during infancy is of great importance in advancing our understanding of the subject-specific relationship between the cognitive ability and early brain structural and functional development and their underlying neural mechanisms. It is also critical for early identifying cognitive delays and developing more effectively and timely personalized therapeutic interventions for at-risk infants. However, this is a very challenging task due to the complex and rapid development of brain structure, function and cognition during the first years of life <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>.</p><p>Recently, a few methods have been explored for predicting infant cognition using either resting-state functional MRI (rs-fMRI) <ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref> or structural MRI (sMRI) <ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref>. Although encouraging preliminary results have been achieved, two unaddressed major issues hinder the precise prediction of the individual-level cognitive development during infancy. 1) Spatial information loss: Previous works <ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref> typically rely on region-level features or inter-region connectivity features after parcellation of the brain cortex into a set of regions. Consequently, these features largely ignore fine-grained spatial patterns on cortical surfaces, which encode subject-specific rich information critical for cognitive prediction. 2) Modality-information loss: Previous methods use either functional features or structural features, and thus the complementary information between them and their underlying relationship are not leveraged for cognition development. Indeed, it is believed that the spontaneous neuronal activity is related to the intrinsic human brain functional organizations supported by the underlying structural substrates <ref type="bibr" target="#b1">[2]</ref>, which gives emphasis to understanding the underlying individual structure-functional profile during infancy. Therefore, an effective unified framework that can automatically learn the complementary and spatially fine-grained information from structural and functional data for cognition development prediction is critically desired.</p><p>To address the above issues, we propose a novel cortical surface-based multimodal learning framework (CSML), to enable learning of the fine-grained spatial patterns and complementary information from structural and functional MRI data for precise prediction of the individual-level cognitive development. Specifically, 1) to learn detailed spatial patterns of both functional connectivity and structural information, we propose to leverage the strong feature learning and representation ability of spherical surface networks <ref type="bibr" target="#b8">[9]</ref> to automatically extract task-related features on cortical surfaces. 2) To effectively fuse structural and functional information, we propose a dual-branch surface network to simultaneously extract structural morphologic features and functional connectivity features on cortical surfaces, and further fuse their complementary information in a feature disentanglement module. 3) To enable precise prediction of cognitive outcome, we leverage the prior knowledge that the cognition function develops with age growing by jointly predicting age and cognition scales. To our best knowledge, this is the first work to leverage the multimodal, fine-grained spatial information on cortical surface explicitly for cognition development prediction. The experimental results based on a longitudinal infant dataset not only validate the superiority of our proposed model but also imply the tight association between the individual cognition development and the fine-grained cortical information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>In this section, we present the details of CSML (Fig. <ref type="figure">1</ref>), including three steps: 1) surface-based fine-grained information representation (Fig. <ref type="figure">1(a)</ref>); 2) modality-specific information learning (Fig. <ref type="figure">1(b</ref>)); and 3) multi-modality information fusion (Fig. <ref type="figure">1(c)</ref>). Fig. <ref type="figure">1</ref>. Overview of our framework for cortical surface-based multimodal fine-grained information learning. Given the sMRI and fMRI of an infant, its structural and functional feature representations z s and z f are first extracted. Then, the modality shared (Com(z)) and specific (Spe(z)) information are disentangled and further fused by a modality fusion block F. After that, we constrain the fused latent variable m s,f to be age-irrelevant by the age predictor P a , and finally obtain the predicted cognitive scores from the predictor P c .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Surface-Based Fine-Grained Information Representation</head><p>The input of the network framework consists of two branches for encoding cortical structural information and functional connectivity information, respectively. To integrate multi-modal MRI data together for cognition development prediction, we map all modality data to a common space, i.e., the cortical surface registered to UNC 4D infant surface atlas <ref type="bibr" target="#b9">[10]</ref> and further resampled with 40,962 vertices, following the well-established pipelines <ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref>. To capture the spatially fine-grained information in structural MRI, the structural branch contains a set of surface maps of biologically meaningful cortical properties, including cortical thickness, surface area, cortical volume, sulcal depth, mean curvature, and average convexity. To preserve the fine-grained spatial patterns of functional connectivity, we leverage an infant-dedicated cortical functional parcellation map <ref type="bibr" target="#b14">[15]</ref>. Specifically, for each parcel, we first calculate the Pearson's correlation coefficient between the averaged functional time series of all vertices within this parcel and the functional time series of each cortical vertex to build the parcel-specific cortical functional connectivity (FC) map and then perform Fisher's r-to-z transformation. Finally, we use these cortical FC maps from all parcels, which characterize rich spatially detailed FC information, as the input of the functional branch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Modality-Specific Encoder</head><p>For the multi-modality input, we employ two modality-specific encoders E s and E f to describe its feature representation, respectively. To be specific, we regard each modality comprised of multiple feature channels, while each channel could be interpreted as an observation of the data from a certain view. Therefore, we process each view separately as</p><formula xml:id="formula_0">x i s = E s v i s , x j f = E f v j f , where i [1, I ],</formula><p>I is the number of morphological features we used; j [1, J ], J is the number of parcels we used in building FC maps. We implement E s and E f as the Spherical Res-Net <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17]</ref>, which is composed of stacks of spherical convolutional layers and spherical pooling layers to extract the fine-grained spatial patterns and generates the view-related feature representations of v i s and v j f . Considering the different number of views in each modality, two Transformer layers <ref type="bibr" target="#b17">[18]</ref> T s and T f are then adopted to fuse the multi-view feature representations for each modality separately. Herein, following the previous work <ref type="bibr" target="#b18">[19]</ref>, we prepend two learnable embeddings x s and x f as the first token for the sequences of view-related feature representations {v i s |i [1, I ]} and {v j f |j [1, J ]}, respectively. Within the Transformer layers, for the structural-related features, x s interact with and fuse the view-related feature representation {v i s |i [1, I ]} through the self-attention mechanism as follows,</p><formula xml:id="formula_1">A i s = Q s (x s )K s v i s T /const,<label>(1)</label></formula><p>∼</p><formula xml:id="formula_2">x s = x s + I i=1 softmax A i s U s (v i s ), (<label>2</label></formula><formula xml:id="formula_3">)</formula><formula xml:id="formula_4">z s = ∼ x s + W s ( ∼ x s ), (<label>3</label></formula><formula xml:id="formula_5">)</formula><p>where z s is the aggregated representation for the structural data, Q s (•), K s (•), U s (•), and W s (•) are four multi-layer perceptrons (MLP), const is a constant for normalization. Similarly, we can obtain the functional-related variable z f by feeding x f and the functional view-related representations {v</p><formula xml:id="formula_6">j f |j [1, J ]} into T f .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Modality-Fusion Block</head><p>To better learn the complementary information between the two modalities, we further decompose the modality-specific latent variables z s and z f into two parts: Com(z n ) and Spe(z n ), where n {s, f }, standing for the structure (s) and function (f ) related variables, respectively. Com(z n ) is the common code representing the shared information among modalities, while Spe(z n ) is the specific code representing the complementary information that differentiates one modality from the other. The basic requirements of this disentanglement are: (1) The concatenation of Com(z n ) and Spe(z n ) equals z n ; (2) Com(z s ) and Com(z f ) should be as similar as possible; (3) Spe(z s ) differs from Spe(z f ) as much as possible. Accordingly, L 1 Disen is defined as:</p><formula xml:id="formula_7">L 1 Disen = L Com Disen /L Spe Disen , (<label>4</label></formula><formula xml:id="formula_8">)</formula><formula xml:id="formula_9">L Com Disen = ||Com(z s ) -Com(z f )|| 2 , (<label>5</label></formula><formula xml:id="formula_10">)</formula><formula xml:id="formula_11">L Spe Disen = ||Spe(z s ) -Spe(z f )|| 2 . (<label>6</label></formula><formula xml:id="formula_12">)</formula><p>Since the latent variable of each modality has been disentangled into Com(z n ) and Spe(z n ), the combined information is formed as the concatenation of the common code and specific codes as follows: z s,f = Spe(z s ), Common, Spe(z f ) , where Common = 0.5(Com(z s ) + Com(z f )).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Cognitive Scores Prediction</head><p>Given the combined multimodal information z s,f , it is intuitive to regress the cognitive scores directly. However, considering that cognitive functions develop rapidly during the first years of life <ref type="bibr" target="#b0">[1]</ref>, the regressor would be prone to learn the age-related information instead and thus cannot differentiate the individualized development discrepancy between subjects within the same age group. Therefore, we fuse the combined multimodal information through a MLP F as follows, m s,f = F(z s,f ), and further disentangle the age-related variance Age(m s,f ) and the individual-related invariance Ind (m s,f ) from m s,f to precisely evaluate the cognition development level. The basic requirements of this disentanglement are: <ref type="bibr" target="#b0">(1)</ref> The concatenation of Age(m s,f ) and Ind (m s,f ) equals m s,f ;</p><p>(2) Age(m s,f ) is capable of age estimation through an age predictor P a ; (3) Ind (m s,f ) is incapable of age estimation through P a . Accordingly, L 2  Disen is defined as:</p><formula xml:id="formula_13">L 2 Disen = L Age Disen -L Ind Disen ,<label>(7)</label></formula><formula xml:id="formula_14">L Age Disen = |t -P a (Age(m s,f ))|, (<label>8</label></formula><formula xml:id="formula_15">)</formula><formula xml:id="formula_16">L Ind Disen = |t -P a (Ind (m s,f ))|, (<label>9</label></formula><formula xml:id="formula_17">)</formula><p>where t is the ground truth of age. Then, we can use the identity-related features Ind (m s,f ) containing subject-specific structure-function profile to predict the cognitive scores through a cognitive score predictor P c under the guidance of the corresponding age feature Age(m s,f ). The loss function to train P c is defined as:</p><formula xml:id="formula_18">L Cog = |y -P c (Ind m s,f , Age(m s,f ))|, (<label>10</label></formula><formula xml:id="formula_19">)</formula><p>where y is the ground truth of cognitive scores. Specifically, we implement P a and P c as two sets of MLP. Finally, the overall objective function to optimize the neural network is written as:</p><formula xml:id="formula_20">L = λ 1 L 1 Disen + λ 2 L 2 Disen + L Cog , (<label>11</label></formula><formula xml:id="formula_21">)</formula><p>where λ 1 and λ 2 are trade-off parameters to balance the multiple losses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset</head><p>We verified the effectiveness of the proposed CSML model for infant cognition development prediction on a public high-resolution dataset including 318 pairs of sMRI and rs-fMRI scans acquired at different ages ranging from 88 to 1040 days in the UNC/UMN Baby Connectome Project <ref type="bibr" target="#b19">[20]</ref>. All structural and functional MR images were preprocessed following state-of-the-art infant-tailored pipelines <ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref>. Cortical surfaces were reconstructed and aligned onto the public UNC 4D infant surface atlas <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>. For each cortical vertex on the middle cortical surface, its representative fMRI time-series was extracted <ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref>. An infant-dedicated fine-grained functional parcellation map <ref type="bibr" target="#b14">[15]</ref> with 432 cortical ROIs per hemisphere in UNC 4D infant surface atlas was warped onto each individual cortical surface.</p><p>To quantify the cognition development level of each participant, four Mullen cognitive scores <ref type="bibr" target="#b20">[21]</ref> were collected at their corresponding scan ages, i.e., Visual Receptive Scale (VRS), Fine Motor Scale (FMS), Receptive Language Scale (RLS), and Expressive Language Scale (ELS). These four cognitive scales were respectively normalized into the [0, 1] range using the minimum and maximum values for the training efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experimental Settings</head><p>In order to validate our methods, a 5-fold cross-validation strategy is employed, and each fold consists of 190 training samples, 64 validating samples, and 64 testing samples. To quantitatively evaluate the performance, the Pearson's correlation coefficient (PCC) and root mean square error (RMSE) between the ground truth and predicted values were calculated. In the testing phase, the mean and standard deviation of the 5-fold results were reported.</p><p>The encoders E s and E f in CSML constitutes 5 Res-blocks with the dimensions of {32, 32, 64, 64, 128}, respectively. The modality fusion block F, age predictor P a , and cognitive score predictor P c were designed as two-layer MLP with the ReLU activation function and the dimension of {192, 128}, {64, 1}, and {128, 1}, respectively. We implemented the model with PyTorch and used Adam as optimizer with the weight decay of 10 -4 and the learning rate cyclically tuned within [10 -6 , 10 -3 ]. The batch size was set to 1. The maximum training epoch is 500. After comparison, we empirically set the hyperparameters as λ 1 =0.05 and λ 2 =0.01.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results</head><p>We first show the results of some ablated models of our method in Table <ref type="table" target="#tab_0">1</ref>, where w/o Structure and w/o Function denote for the variants using functional and structural features only. w/o Age denotes the variant with single task of cognition prediction. It can be observed that, the overall performance on four cognitive tasks has been extensively improved by jointly leveraging the structural and functional information. The disentanglement mechanism successfully separates the shared and complementary information amongst modalities and further removes the redundancy with the loss L 1  Disen . Moreover, the joint age prediction and cognitive estimation also brings further improvement by differentiating the age-related and identity-related variables with L 2 Disen . The scatter plots of predicted cognitive scores in five testing folds are depicted in Fig. <ref type="figure" target="#fig_0">2(a)</ref>, demonstrating that the scores are well predicted.</p><p>We also comprehensively compared with various traditional and state-of-the-art functional connectivity-based methods, including KNN, random forest (RF), SVR, gaussian process regression (GPR), GCN <ref type="bibr" target="#b21">[22]</ref>, GAT <ref type="bibr" target="#b22">[23]</ref>, and UniMP <ref type="bibr" target="#b23">[24]</ref>. As shown in Table <ref type="table" target="#tab_1">2</ref>, our algorithm outperforms the previous methods by a large margin. Of note, the proposed method demonstrates better performance even with the functional information only, which highlights the importance to preserve the fined-grained FC information. Additionally, based on our proposed model CSML, the prediction accuracy of infant cognition development is over 0.85 on average, suggesting that the model may observe plausible biomarkers for cognition development during infancy. Based on the welltrained models, we explored the explainability and interpretability of the proposed method by investigating the weights of the Transformers. Since the Transformer layers T s and T f fuse the multi-view representations v i s and v j f into z s and z f for further cognitive prediction, by analyzing the attention value A i n of each view v i n in the Transformer, we can infer which regions for functional data and which morphological features for structural data are more important for cognition prediction. The results are shown in Fig. <ref type="figure" target="#fig_0">2</ref> (b) and Fig. <ref type="figure" target="#fig_0">2</ref> (c), in line with the reports in related studies to some extent <ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref>, demonstrating the scientific value of our method. For example, the left lateral prefrontal cortex involved in higher executive functions <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref> demonstrates high importance in functional data. Moreover, previous researchers <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28]</ref> have observed the close relevance between the visual cortex and the early cognitive process, which also confirms the result of our method. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this work, we develop an innovative cortical surface-based multimodal learning framework (CSML) to address the infant cognition prediction problem. Specifically, we unprecedentedly propose to explicitly leverage the surface-based feature representations to preserve the fine-grained, spatially detailed multimodal information for cognition prediction. In addition, by disentangling the modality-shared and complementary information, our model successfully captures the individualized cognition development patterns underlying the dramatic brain development. With its superior performance compared to state-of-the-art methods, our proposed CSML suggests that the informative clues for brain-cognitive relationship are hidden in the multimodal fine-grained details and validates itself as a potentially powerful framework for simultaneously learning effective representations from sMRI and rs-fMRI data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The illustrations of (a) the predicted values distribution for four cognitive tasks, and the importance distribution of (b) each cortical regions and (c) each morphological feature on both hemispheres.</figDesc><graphic coords="8,55,98,210,38,340,18,190,72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="3,41,79,132,71,340,21,158,80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>The impact of each component of CSML on the prediction performance (in terms of PCC). * indicates statistically significantly better results than other methods with p-value &lt; 0.05.</figDesc><table><row><cell cols="2">Components VRS</cell><cell>FMS</cell><cell>RLS</cell><cell>ELS</cell><cell>Average</cell></row><row><cell>w/o Age</cell><cell cols="5">0.768 ± 0.034 0.819 ± 0.023 0.789 ± 0.032 0.745 ± 0.034 0.780</cell></row><row><cell cols="6">w/o Structure 0.748 ± 0.050 0.814 ± 0.037 0.790 ± 0.042 0.711 ± 0.039 0.757</cell></row><row><cell cols="6">w/o Function 0.771 ± 0.038 0.831 ± 0.013 0.793 ± 0.028 0.737 ± 0.052 0.782</cell></row><row><cell>w/o L 1 Disen</cell><cell cols="5">0.791 ± 0.015 0.837 ± 0.018 0.814 ± 0.018 0.789 ± 0.021 0.808</cell></row><row><cell>w/o L 2 Disen</cell><cell cols="5">0.820 ± 0.045 0.858 ± 0.016 0.848 ± 0.016 0.824 ± 0.019 0.838</cell></row><row><cell>Proposed</cell><cell cols="5">0.855 ± 0.026* 0.874 ± 0.030* 0.873 ± 0.008* 0.852 ± 0.009* 0.864*</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Performance comparison of different methods (in terms of RMSE and PCC). The averaged values among four tasks were provided. * indicates statistically significantly better results than other methods with p-value &lt; 0.05.</figDesc><table><row><cell>Methods</cell><cell></cell><cell>RMSE</cell><cell>PCC</cell></row><row><cell>Machine Learning-based Methods</cell><cell>KNN</cell><cell>0.1421 ± 0.0144</cell><cell>0.5698 ± 0.0751</cell></row><row><cell></cell><cell>RF</cell><cell>0.1353 ± 0.0060</cell><cell>0.6705 ± 0.1354</cell></row><row><cell></cell><cell>GPR</cell><cell>0.1175 ± 0.0127</cell><cell>0.7320 ± 0.0596</cell></row><row><cell></cell><cell>SVR</cell><cell>0.1284 ± 0.0069</cell><cell>0.7355 ± 0.0192</cell></row><row><cell>Graph Convolution-based Methods</cell><cell>GCN</cell><cell>0.1382 ± 0.0175</cell><cell>0.6234 ± 0.0581</cell></row><row><cell></cell><cell>GAT</cell><cell>0.1208 ± 0.0228</cell><cell>0.7001 ± 0.1327</cell></row><row><cell></cell><cell>UniMP</cell><cell>0.1246 ± 0.0149</cell><cell>0.7073 ± 0.0249</cell></row><row><cell>Proposed</cell><cell></cell><cell>0.0915 ± 0.0091*</cell><cell>0.8635 ± 0.0066*</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. The work of <rs type="person">Gang Li</rs> was supported in part by <rs type="funder">NIH</rs> grants (<rs type="grantNumber">MH116225</rs>, <rs type="grantNumber">MH117943</rs>, <rs type="grantNumber">MH127544</rs>, and <rs type="grantNumber">MH123202</rs>). The work of <rs type="person">Li Wang</rs> was supported by <rs type="funder">NIH</rs> grant (<rs type="grantNumber">MH117943</rs>). This work also utilizes approaches developed by an <rs type="funder">NIH</rs> grant (<rs type="grantNumber">1U01MH110274</rs>) and the efforts of the <rs type="institution">UNC/UMN Baby Connectome Project Consortium</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_7c2MYQK">
					<idno type="grant-number">MH116225</idno>
				</org>
				<org type="funding" xml:id="_zjHcE23">
					<idno type="grant-number">MH117943</idno>
				</org>
				<org type="funding" xml:id="_htjVMf6">
					<idno type="grant-number">MH127544</idno>
				</org>
				<org type="funding" xml:id="_rFHp97u">
					<idno type="grant-number">MH123202</idno>
				</org>
				<org type="funding" xml:id="_ckJjmKw">
					<idno type="grant-number">MH117943</idno>
				</org>
				<org type="funding" xml:id="_28cnN3h">
					<idno type="grant-number">1U01MH110274</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Functional network development during the first year: relative sequence and socioeconomic correlations</title>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cereb. Cortex</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2919" to="2928" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Resting-state functional MRI studies on infant brains: a decade of gap-filling efforts</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="page" from="664" to="684" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The emergence of functional architecture during early brain development</title>
		<author>
			<persName><forename type="first">K</forename><surname>Keunen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Counsell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Benders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">160</biblScope>
			<biblScope unit="page" from="2" to="14" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Functional connectivity MRI in infants: exploration of the functional organization of the developing brain</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Smyser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Z</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Neil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1437" to="1452" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Path signature neural network of cortical features for prediction of infant cognitive scores</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1665" to="1676" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multi-task prediction of infant cognitive scores from longitudinal incomplete neuroimaging data</title>
		<author>
			<persName><forename type="first">E</forename><surname>Adeli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="page" from="783" to="792" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Infant brain development prediction with latent partial multi-view representation learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="909" to="918" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Existence of functional connectome fingerprint during infancy and its stability over months</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="377" to="389" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Spherical deformable u-net: application to cortical surface parcellation and development prediction</title>
		<author>
			<persName><forename type="first">F</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1217" to="1228" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Construction of 4D infant cortical surface atlases with sharp folding patterns via spherical patch-based group-wise sparse representation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hum. Brain Mapp</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="3860" to="3880" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Construction of 4D high-definition cortical surface atlases of infants: Methods and applications</title>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="22" to="36" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Computational neuroanatomy of baby brains: a review</title>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="page" from="906" to="925" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Measuring the dynamic longitudinal cortex development in infants by reconstruction of temporally consistent cortical surfaces</title>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="266" to="279" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">iBEAT V2. 0: a multisite-applicable, deep learning-based pipeline for infant cerebral cortical surface reconstruction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Protoc</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1488" to="1509" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Fine-grained functional parcellation maps of the infant cerebral cortex</title>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Harmonization of infant cortical thickness using surface-to-surface cycleconsistent adversarial networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-32251-9_52</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-32251-9_52" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2019</title>
		<editor>
			<persName><forename type="first">Dinggang</forename><surname>Shen</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11767</biblScope>
			<biblScope unit="page" from="475" to="483" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="6000" to="6010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An image is worth 16x16 words: transformers for image recognition at scale</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representation</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The UNC/UMN baby connectome project (BCP): an overview of the study design and protocol development</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Howell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="page" from="891" to="905" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Mullen scales of early learning</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Mullen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>AGS Circle Pines</publisher>
			<pubPlace>MN</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Graph attention networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Veličković</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10903</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Masked label prediction: Unified message passing model for semi-supervised classification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.03509</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Frontal lobe and cognitive development</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Fuster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurocytol</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="373" to="385" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Development of prefrontal cortex</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Kolk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rakic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuropsychopharmacology</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="57" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Early visual cortex as a multiscale cognitive blackboard</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Roelfsema</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>De Lange</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Rev. Vis. Sci</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="131" to="151" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Shared representations for working memory and mental imagery in early visual cortex</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Albers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Biol</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="1427" to="1431" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
