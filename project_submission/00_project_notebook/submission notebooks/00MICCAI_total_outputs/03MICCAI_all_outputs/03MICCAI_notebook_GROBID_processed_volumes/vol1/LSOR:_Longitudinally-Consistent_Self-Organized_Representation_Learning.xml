<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">LSOR: Longitudinally-Consistent Self-Organized Representation Learning</title>
				<funder ref="#_SATTaMm #_pTDMJT2 #_dpsN3K5 #_rqCrUvu #_ZSSMfCa #_AqrUytT">
					<orgName type="full">National Institute of Health</orgName>
				</funder>
				<funder>
					<orgName type="full">Stanford HAI Google Cloud Credit</orgName>
				</funder>
				<funder ref="#_VyrurgU">
					<orgName type="full">Ministry of Science and ICT of KOREA</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jiahong</forename><surname>Ouyang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
								<address>
									<postCode>94305</postCode>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qingyu</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
								<address>
									<postCode>94305</postCode>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ehsan</forename><surname>Adeli</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
								<address>
									<postCode>94305</postCode>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wei</forename><surname>Peng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
								<address>
									<postCode>94305</postCode>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Greg</forename><surname>Zaharchuk</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
								<address>
									<postCode>94305</postCode>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Kilian</forename><forename type="middle">M</forename><surname>Pohl</surname></persName>
							<email>kilian.pohl@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
								<address>
									<postCode>94305</postCode>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">LSOR: Longitudinally-Consistent Self-Organized Representation Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CBDF6E9EE29F156D5A913E86DD582CA3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-01T10:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Interpretability is a key issue when applying deep learning models to longitudinal brain MRIs. One way to address this issue is by visualizing the high-dimensional latent spaces generated by deep learning via self-organizing maps (SOM). SOM separates the latent space into clusters and then maps the cluster centers to a discrete (typically 2D) grid preserving the high-dimensional relationship between clusters. However, learning SOM in a high-dimensional latent space tends to be unstable, especially in a self-supervision setting. Furthermore, the learned SOM grid does not necessarily capture clinically interesting information, such as brain age. To resolve these issues, we propose the first self-supervised SOM approach that derives a high-dimensional, interpretable representation stratified by brain age solely based on longitudinal brain MRIs (i.e., without demographic or cognitive information). Called Longitudinallyconsistent Self-Organized Representation learning (LSOR), the method is stable during training as it relies on soft clustering (vs. the hard cluster assignments used by existing SOM). Furthermore, our approach generates a latent space stratified according to brain age by aligning trajectories inferred from longitudinal MRIs to the reference vector associated with the corresponding SOM cluster. When applied to longitudinal MRIs of the Alzheimer's Disease Neuroimaging Initiative (ADNI, N = 632), LSOR generates an interpretable latent space and achieves comparable or higher accuracy than the state-of-the-art representations with respect to the downstream tasks of classification (static vs. progressive mild cognitive impairment) and regression (determining ADAS-Cog score of all subjects). The code is available at https://github.com/ouyangjiahong/ longitudinal-som-single-modality.</p><p>G. Zaharchuk-Co-founder, equity Subtle Medical.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The interpretability of deep learning models is especially a concern for applications related to human health, such as analyzing longitudinal brain MRIs. To avoid interpretation during post-hoc analysis <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b13">14]</ref>, some methods strive for an interpretable latent representation <ref type="bibr" target="#b8">[9]</ref>. One example is self-organizing maps (SOM) <ref type="bibr" target="#b4">[5]</ref>, which cluster the latent space so that the SOM representations (i.e., the 'representatives of the clusters) can be arranged in a discrete (typically 2D) grid while preserving high-dimensional relationships between clusters. Embedded in unsupervised deep learning models, SOMs have been used to generate interpretable representations of low-resolution natural images <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b7">8]</ref>.</p><p>Intriguing as it sounds, we found their application to (longitudinal) 3D brain MRIs unstable during training and resulted in uninformative SOMs. These models get stuck in local minima so that only a few SOM representations are updated during backpropagation. The issue has been less severe in prior applications <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b7">8]</ref> as their corresponding latent space is of much lower dimension than the task at hand, which requires a high dimension latent space so that it can accurately encode the fine-grained anatomical details in brain MRIs <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b16">17]</ref>. To ensure all SOM representations can be updated during backpropagation, we propose a soft weighing scheme that not only updates the closest SOM representation for a given MRI but also updates all other SOM representations based on their distance to the closest SOM representation <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b7">8]</ref>. Moreover, our model relies on a stop-gradient operator <ref type="bibr" target="#b15">[16]</ref>, which sets the gradient of the latent representation to zero so that it only focuses on updating the SOM representations. It is especially crucial at the beginning of the training when the (randomly initialized) SOM representations are not good representatives of their clusters. Finally, the latent representations of the MRIs are updated via a commitment loss, which encourages the latent representation of an MRI sample to be close to its nearest SOM representation. In practice, these three components ensure stability during the self-supervised training of the SOM on high-dimensional latent spaces.</p><p>To generate SOMs informative to neuroscientists, we extend SOMs to the longitudinal setting such that the latent space and corresponding SOM grid encode brain aging. Inspired by <ref type="bibr" target="#b11">[12]</ref>, we encode pairs of MRIs from the same longitudinal sequence (i.e., same subject) as a trajectory and encourage the latent space to be a smooth trajectory (vector) field. We enforce smoothness by computing for each SOM cluster a reference trajectory, which represents the average aging of that cluster with respect to the training set. The reference trajectories are updated by the exponential moving average (EMA) such that, in each iteration, it aggregates the average trajectory of a cluster with respect to the corresponding training batch (i.e., batch-wise average trajectory). In doing so, the model ensures longitudinal consistency as the (subject-specific) trajectories of a cluster are maximally aligned with the reference trajectory of that cluster.</p><p>Named Longitudinally-consistent Self-Organized Representation learning (LSOR), we evaluate our method on a longitudinal T1-weighted MRI dataset of 632 subjects from ADNI to encode the brain aging of Normal Controls (NC) and patients diagnosed with static Mild Cognitive Impairment (sMCI  on longitudinal MRIs, i.e., without using any tabular data such as age, cognitive measure, or diagnosis. To visualize aging effects on the grid, we compute (post-hoc) a 2D similarity grid for each MRI that stores the similarity scores between the latent representation of that MRI and all SOM representations. As the SOM grid is an encoding of brain aging, the similarity grid indicates the likelihood of placing the MRI within the "spectrum" of aging. Given all MRIs of a longitudinal scan, the change across the corresponding similarity grids over time represents the brain aging process of that individual. Furthermore, we infer brain aging on a group-level by first computing the average similarity grid for an age group and then visualizing the difference of those average similarity grids across age groups. With respect to the downstream tasks of classification (sMCI vs. pMCI) and regression (i.e., estimating the Alzheimer's Disease Assessment Scale-Cognitive Subscale (ADAS-Cog) on all subjects), our latent representations of the MRIs is associated with comparable or higher accuracy scores than representations learned by other state-of-the-art self-supervised methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>As shown in Fig. <ref type="figure" target="#fig_0">1</ref>, the longitudinal 3D MRIs of a subject are encoded as a series of trajectories (blue vectors) in the latent space. Following <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b16">17]</ref>, we consider a pair of longitudinal MRIs (that corresponds to a blue vector) as a training sample. Specifically, let S denote the set of image pairs of the training cohort, where the MRIs x u and x v of a longitudinal pair (x u , x v ) are from the same subject and x v was acquired Δt years after x u . For simplicity, × refers to u or v when a function is separately applied to both time points. The MRIs are then mapped to the latent space by an encoder F , i.e., z × := F (x × ). On the latent space, the trajectory of the pair is denoted as Δz := (z v -z u )/Δt, which represents morphological changes. Finally, decoder H reconstructs the input MRI x × from the latent representation z × , i.e., x× := H(z × ). Next, we describe LSOR, which generates interpretable SOM representations, and the post-hoc analysis for deriving similarity grids.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">LSOR</head><p>Following <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b7">8]</ref>, SOM representations are organized in a N r by N c grid (denoted as SOM grid) G = {g i,j } Nr,Nc i=1,j=1 , where g i,j denotes the SOM representation on the i-th row and j-th column. This easy-to-visualize grid preserves the highdimensional relationships between the clusters as shown in by the orange lines in Fig. <ref type="figure" target="#fig_0">1</ref>. Given the latent representation z × , its closest SOM representation is denoted as g × , where × := argmin (i,j) z × -g i,j 2 is its 2D grid index in G and • 2 is the Euclidean norm. This SOM representation is also used to reconstruct the input MRI by the decoder, i.e., x× g = H(g × ). To do so, the reconstruction loss encourages both the latent representation z × and its closet SOM representation g × to be descriptive of the input MRI x × , i.e.,</p><formula xml:id="formula_0">L recon := E (x u ,x v )∼S ⎛ ⎝ ×∈{x,v} x × -x× 2 2 + x × -x× g 2 2 ⎞ ⎠ , (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where E defines the expected value. The remainder describes the three novel components of our SOM representation.</p><p>Explicitly Regularizing Closeness. Though L recon implicitly encourages close proximity between z × and g × , it does not inherently optimize g × as z × is not differentiable with respect to g × . Therefore, we introduce an additional 'commitment' loss explicitly promoting closeness between them:</p><formula xml:id="formula_2">L commit := E (x u ,x v )∼S z u -g u 2 2 + z v -g v 2 2 .</formula><p>Soft Weighting Scheme. In addition to update z × 's closest SOM representation g × , we also update all SOM representations g i,j by introducing a soft weighting scheme as proposed in <ref type="bibr" target="#b9">[10]</ref>. Specifically, we design a weight w × i,j to regularize how much g i,j should be updated with respect to z × based on its proximity to the grid location × of g × , i.e.,</p><formula xml:id="formula_3">w × i,j := δ e - × -(i,j) 2 1 2τ , (<label>2</label></formula><formula xml:id="formula_4">)</formula><p>where δ(w) := w i,j wi,j ensures that the scale of weights is constant during training and τ &gt; 0 is a scaling hyperparameter. Now, we design the following loss L som so that SOM representations close to × on the grid are also close to z × in the latent space (measured by the Euclidean distance z × -g i,j 2 ):</p><formula xml:id="formula_5">L som := E (x u ,x v )∼S ⎛ ⎝ gi,j ∼G w u i,j • z u -g i,j 2 2 + w v i,j • z v -g i,j 2 2 ⎞ ⎠ . (<label>3</label></formula><formula xml:id="formula_6">)</formula><p>To improve robustness, we make two more changes to Eq. 3. First, we account for SOM representations transitioning from random initialization to becoming meaningful cluster centers that preserve the high-dimensional relationships within the 2D SOM grid. We do so by decreasing τ in Eq. 2 with each iteration so that the weights gradually concentrate on SOM representations closer to g × as training proceeds:</p><formula xml:id="formula_7">τ (t) := N r • N c • τ max τmin τmax t/T</formula><p>with τ min being the minimum and τ max the maximum standard deviation in the Gaussian kernel, and t represents the current and T the maximum iteration.</p><p>The second change to Eq. 3 is to apply the stop-gradient operator sg[•] <ref type="bibr" target="#b15">[16]</ref> to z × , which sets the gradients of z × to 0 during the backward pass. The stopgradient operator prevents the undesirable scenario where z × is pulled towards a naive solution, i.e., different MRI samples are mapped to the same weighted average of all SOM representations. This risk of deriving the naive solution is especially high in the early stages of the training when the SOM representations are randomly initialized and may not accurately represent the clusters.</p><p>Longitudinal Consistency Regularization. We derive a SOM grid related to brain aging by generating an age-stratified latent space. Specifically, the latent space is defined by a smooth trajectory field (Fig. <ref type="figure" target="#fig_0">1</ref>, blue box) characterizing the morphological changes associated with brain aging. The smoothness is based on the assumption that MRIs with similar appearances (close latent representations on the latent space) should have similar trajectories. It is enforced by modeling the similarity between each subject-specific trajectory Δz with a reference trajectory that represents the average trajectory of the cluster. Specifically, Δg i,j is the reference trajectory (Fig. <ref type="figure" target="#fig_0">1</ref>, green arrow) associated with g i,j then the reference trajectories of all clusters G Δ = {Δg i,j } Nr,Nc i=1,j=1 represent the average aging of SOM clusters with respect to the training set. As all subject-specific trajectories are iteratively updated during the training, it is computationally infeasible to keep track of G Δ on the whole training set. We instead propose to compute the exponential moving average (EMA) (Fig. <ref type="figure" target="#fig_0">1</ref>, black box), which iteratively aggregates the average trajectory with respect to a training batch to G Δ :</p><formula xml:id="formula_8">Δg i,j ← ⎧ ⎪ ⎨ ⎪ ⎩ Δh i,j t = 0 Δg i,j t &gt; 0 and |Ω i,j | = 0 α • Δg i,j + (1 -α) • Δh i,j t &gt; 0 and |Ω i,j | &gt; 0 with Δh i,j := 1 |Ω i,j | N bs k=1 1[ u k = (i, j)] • Δz k and |Ω i,j | := N bs k=1 1[ u k = (i, j)].</formula><p>α is the EMA keep rate, k denotes the index of the sample pair, N bs symbolizes the batch size, 1[•] is the indicator function, and |Ω i,j | denotes the number of sample pairs with u = (i, j) within a batch. Then in each iteration, Δh i,j (Fig. <ref type="figure" target="#fig_0">1</ref>, purple arrow) represents the batch-wise average of subject-specific trajectories for sample pairs with u = (i, j). By iteratively updating G Δ , G Δ then approximate the average trajectories derived from the entire training set. Lastly, inspired by <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>, the longitudinal consistency regularization is formulated as</p><formula xml:id="formula_9">L dir := E (x u ,x v )∼S (1 -cos(θ[Δz, sg[Δg u ]])) ,</formula><p>where θ[•, •] denotes the angle between two vectors. Since Δg is optimized by EMA, the stop-gradient operator is again incorporated to only compute the gradient with respect to Δz in L dir .</p><p>Objective Function. The complete objective function is the weighted combination of the prior losses with weighing parameters λ commit , λ som , and λ dir :</p><formula xml:id="formula_10">L := L recon + λ commit • L commit + λ som • L som + λ dir • L dir</formula><p>The objective function encourages a smooth trajectory field of aging on the latent space while maintaining interpretable SOM representations for analyzing brain age in a pure self-supervised fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">SOM Similarity Grid</head><p>During inference, a (2D) similarity grid ρ is computed by the closeness between the latent representation z of an MRI sample and the SOM representations:</p><formula xml:id="formula_11">ρ := sof tmax(-z -G 2 2 /γ) with γ := std( z -G 2 2 )</formula><p>std denotes the standard deviation of the distance between z to all SOM representations. As the SOM grid is learned to be associated with brain age (e.g., represents aging from left to right), the similarity grid essentially encodes a "likelihood function" of the brain age in z. Given all MRIs of a longitudinal scan, the change across the corresponding similarity grids over time represents the brain aging process of that individual. Furthermore, brain aging on the group-level is captured by first computing the average similarity grid for an age group and then visualizing the difference of those average similarity grids across age groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Setting</head><p>Dataset. We evaluated the proposed method on all 632 longitudinal T1weighted MRIs (at least two visits per subject, 2389 MRIs in total) from ADNI-1 <ref type="bibr" target="#b12">[13]</ref>.  Evaluation. We performed five-fold cross-validation (folds split based on subjects) using 10% of the training subjects for validation. The training data was augmented by flipping brain hemispheres and random rotation and translation.</p><p>To quantify the interpretability of the SOM grid, we correlated the coordinates of the SOM grid with quantitative measures related to brain age, e.g., chronological age, the percentage of subjects with severe cognitive decline, and Alzheimer's Disease Assessment Scale-Cognitive Subscale (ADAS-Cog). We illustrated the interpretability with respect to brain aging by visualizing the changes in the SOM similarity maps over time. We further visualized the trajectory vector field along with SOM representations by projecting the 1024-dimensional representations to the first two principal components of SOM representations. Lastly, we quantitatively evaluated the quality of the representations by applying them to the downstream tasks of classifying sMCI vs. pMCI and ADAS-Cog prediction. We measured the classification accuracy via Balanced accuracy (BACC) and Area Under Curve (AUC) and the prediction accuracy via R2 and rootmean-square error (RMSE). The classifier and predictor were multi-layer per- ceptrons containing two fully connected layers of dimensions 1024 and 64 with a LeakyReLU activation. We compared the accuracy metrics to models using the same architecture with encoders pre-trained by other representation learning methods, including unsupervised methods (AE, VAE <ref type="bibr" target="#b3">[4]</ref>), self-supervised method (SimCLR <ref type="bibr" target="#b0">[1]</ref>), longitudinal self-supervised method (LSSL <ref type="bibr" target="#b16">[17]</ref>), and longitudinal neighborhood embedding (LNE <ref type="bibr" target="#b11">[12]</ref>). All comparing methods used the same experimental setup (e.g., encoder-decoder, learning rate, batch size, epochs, etc.), and the method-specific hyperparameters followed <ref type="bibr" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head><p>Interpretability of SOM Embeddings. Fig. <ref type="figure" target="#fig_1">2</ref> shows the stratification of brain age over the SOM grid G. For each grid entry, we show the average value of chronological age (Fig. <ref type="figure" target="#fig_1">2</ref> Interpretability of Similarity Grid. Visualizing the average similarity grid ρ of the NC and AD at each age range in Fig. <ref type="figure" target="#fig_2">3</ref>, we observed that higher similarity (yellow) gradually shifts towards the right with age in both NC and AD (see Supplemental Fig. <ref type="figure" target="#fig_1">S2</ref> for sMCI and pMCI cohorts). However, the shift is faster for AD, which aligns with AD literature reporting that AD is linked to accelerated brain aging <ref type="bibr" target="#b14">[15]</ref>. Furthermore, the subject-level aging effects shown in Supplemental Fig. <ref type="figure" target="#fig_2">S3</ref> reveal that the proposed visualization could capture subtle morphological changes caused by brain aging.</p><p>Interpretability of Trajectory Vector Field. Fig. <ref type="figure" target="#fig_4">4</ref> plots the PCA projections of the latent space in 2D, which shows a smooth trajectory field (gray arrows) and reference trajectories G Δ (blue arrows) representing brain aging.  This projection also preserved the 2D grid structure (orange) of the SOM representations suggesting that aging was the most important variation in the latent space.</p><p>Downstream Tasks. To evaluate the quality of the learned representations, we froze encoders trained by each method without fine-tuning and utilized their representations for the downstream tasks (Table <ref type="table" target="#tab_2">1</ref>). On the task of sMCI vs. pMCI classification (Table <ref type="table" target="#tab_2">1</ref> (left)), the proposed method achieved a BACC of 69.8 and an AUC of 72.4, a comparable accuracy (p &gt; 0.05, DeLong's test) with LSSL <ref type="bibr" target="#b16">[17]</ref> and LNE <ref type="bibr" target="#b11">[12]</ref>, two state-of-the-art self-supervised methods on this task. On the ADAS-Cog score regression task, the proposed method obtained the best accuracy with an R2 of 0.32 and an RMSE of 6.31. It is worth mentioning that an accurate prediction of the ADAS-Cog score is very challenging due to its large range (between 0 and 70) and its subjectiveness resulting in large variability across exams <ref type="bibr" target="#b1">[2]</ref> so that even larger RMSEs have been reported for this task <ref type="bibr" target="#b6">[7]</ref>. Furthermore, our representations were learned in an unsupervised manner so that further fine-tuning of the encoder would improve the prediction accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this work, we proposed LSOR, the first SOM-based learning framework for longitudinal MRIs that is self-supervised and interpretable. By incorporating a soft SOM regularization, the training of the SOM was stable in the highdimensional latent space of MRIs. By regularizing the latent space based on longitudinal consistency as defined by longitudinal MRIs, the latent space formed a smooth trajectory field capturing brain aging as shown by the resulting SOM grid. The interpretability of the representations was confirmed by the correlation between the SOM grid and cognitive measures, and the SOM similarity map.</p><p>When evaluated on downstream tasks sMCI vs. pMCI classification and ADAS-Cog prediction, LSOR was comparable to or better than representations learned from other state-of-the-art self-and un-supervised methods. In conclusion, LSOR is able to generate a latent space with high interpretability regarding brain age purely based on MRIs, and valuable representations for downstream tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Overview of the latent space derived from LSOR. All trajectories (Δz) form a trajectory field (blue box) modeling brain aging. SOM representations in G (orange star) are organized as a 2D grid (orange grid). As shown in the black box, reference trajectories ΔG (collection of all Δg, green arrow) are iteratively updated by EMA using the aggregated trajectory Δh (purple arrow) across all trajectories of the corresponding SOM cluster within a training batch. (Color figure online)</figDesc><graphic coords="3,105,21,68,90,245,92,98,20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The color at each SOM representation encodes the average value of (a) chronological age, (b) % of AD and pMCI, and (c) ADAS-Cog score across the training samples of that cluster; (d) Confined to the last row of the grid, the average MRI of 20 latent representations closest to the corresponding SOM representation. (Color figure online)</figDesc><graphic coords="7,89,46,54,11,273,76,88,60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The average similarity grid ρ over subjects of a specific age and diagnosis (NC vs AD). Each grid encodes the likelihood of the average brain age of the corresponding sub-cohort. Cog denotes the average ADAS-Cog score.</figDesc><graphic coords="8,59,31,53,66,305,56,57,04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(a)), % of AD &amp; pMCI (Fig.2(b)), and ADAS-Cog score (Fig.2(c)) over samples of that cluster. We observed a trend of older brain age (yellow) from the upper left towards the lower right, corresponding to older chronological age and worse cognitive status. The SOM grid index strongly correlated with these three factors (distance correlation of 0.92, 0.94, and 0.91 respectively). Figure2(d)shows the average brain over 20 input images with representations that are closest to each SOM representation of the last row of the grid (see Supplement Fig.S1for all rows). From left to right the ventricles are enlarging and the brain is atrophying, which is a hallmark for brain aging effects.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. 2D PCA of the LSOR's latent space. Light gray arrows represent Δz. The orange grid represents the relationships between SOM representations and associated reference trajectory ΔG (blue arrow). (Color figure online)</figDesc><graphic coords="9,57,12,53,75,141,76,111,94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>), progressive Mild Cognitive Impairment (pMCI), and Alzheimer's Disease (AD). LSOR clusters the latent representations of all MRIs into 32 SOM representations. The resulting 4-by-8 SOM grid is organized by both chronological age and cognitive measures that are indicators of brain age. Note, such an organization solely relies</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .</head><label>1</label><figDesc>Supervised downstream tasks using the learned representations z (without finetuning the encoder). LSOR achieved comparable or higher accuracy scores than other stateof-the-art self-and un-supervised methods.</figDesc><table><row><cell>Methods</cell><cell cols="3">sMCI/pMCI ADAS-Cog</cell></row><row><cell></cell><cell cols="2">BACC AUC R2</cell><cell>RMSE</cell></row><row><cell>AE</cell><cell>62.6</cell><cell cols="2">65.4 0.26 6.98</cell></row><row><cell>VAE [4]</cell><cell>61.3</cell><cell cols="2">64.8 0.23 7.17</cell></row><row><cell cols="2">SimCLR [1] 63.3</cell><cell cols="2">66.3 0.26 6.79</cell></row><row><cell>LSSL [17]</cell><cell>69.4</cell><cell cols="2">71.8 0.29 6.49</cell></row><row><cell>LNE [12]</cell><cell>70.6</cell><cell cols="2">72.1 0.30 6.46</cell></row><row><cell>LSOR</cell><cell>69.8</cell><cell cols="2">72.4 0.32 6.31</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>c The Author(s), under exclusive license to Springer Nature Switzerland AG 2023 H. Greenspan et al. (Eds.): MICCAI 2023, LNCS 14220, pp. 279-289, 2023. https://doi.org/10.1007/978-3-031-43907-0_27</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement. This work was partly supported by funding from the <rs type="funder">National Institute of Health</rs> (<rs type="grantNumber">MH113406</rs>, <rs type="grantNumber">DA057567</rs>, <rs type="grantNumber">AA017347</rs>, <rs type="grantNumber">AA010723</rs>, <rs type="grantNumber">AA005965</rs>, and <rs type="grantNumber">AA028840</rs>), the <rs type="programName">DGIST R&amp;D program</rs> of the <rs type="funder">Ministry of Science and ICT of KOREA</rs> (<rs type="grantNumber">22-KUJoint-02</rs>), <rs type="institution">Stanford</rs>'s <rs type="institution">Department of Psychiatry &amp; Behavioral Sciences Faculty Development &amp; Leadership Award</rs>, and by <rs type="funder">Stanford HAI Google Cloud Credit</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_SATTaMm">
					<idno type="grant-number">MH113406</idno>
				</org>
				<org type="funding" xml:id="_pTDMJT2">
					<idno type="grant-number">DA057567</idno>
				</org>
				<org type="funding" xml:id="_dpsN3K5">
					<idno type="grant-number">AA017347</idno>
				</org>
				<org type="funding" xml:id="_rqCrUvu">
					<idno type="grant-number">AA010723</idno>
				</org>
				<org type="funding" xml:id="_ZSSMfCa">
					<idno type="grant-number">AA005965</idno>
				</org>
				<org type="funding" xml:id="_AqrUytT">
					<idno type="grant-number">AA028840</idno>
					<orgName type="program" subtype="full">DGIST R&amp;D program</orgName>
				</org>
				<org type="funding" xml:id="_VyrurgU">
					<idno type="grant-number">22-KUJoint-02</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43907-0 27.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Administration and scoring variance on the ADAS-Cog</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Sabbagh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Alzheimers Dis</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="461" to="464" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">SOM-VAE: interpretable discrete representation learning on time series</title>
		<author>
			<persName><forename type="first">V</forename><surname>Fortuin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hüser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Locatello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Strathmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rätsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<title level="m">Auto-encoding variational bayes</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The self-organizing map</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kohonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="1464" to="1480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep learning for case-based reasoning through prototypes: a neural network that explains its predictions</title>
		<author>
			<persName><forename type="first">O</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rudin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Multi-task learning and ensemble approach to predict cognitive scores for patients with Alzheimer&apos;s disease. bioRxiv</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pabalan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Interian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raj</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2021" to="2033" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">DPSOM: deep probabilistic clustering with self-organizing maps</title>
		<author>
			<persName><forename type="first">L</forename><surname>Manduchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hüser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vogt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rätsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Fortuin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems Workshop on Machine Learning for Health</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Molnar</surname></persName>
		</author>
		<title level="m">Interpretable machine learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Estimating explainable Alzheimer&apos;s disease likelihood map via clinically-guided prototype learning</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Mulyadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">I</forename><surname>Suk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">273</biblScope>
			<biblScope unit="page">120073</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Self-supervised learning of neighborhood embedding for longitudinal MRI</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Adeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zaharchuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Pohl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page">102571</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Self-supervised longitudinal neighbourhood embedding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ouyang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87196-3_8</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87196-38" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12902</biblScope>
			<biblScope unit="page" from="80" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Alzheimer&apos;s disease neuroimaging initiative (ADNI): clinical characterization</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Petersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurology</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="201" to="209" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead</title>
		<author>
			<persName><forename type="first">C</forename><surname>Rudin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="206" to="215" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dissociating normal aging from Alzheimer&apos;s disease: a view from cognitive neuroscience</title>
		<author>
			<persName><forename type="first">M</forename><surname>Toepper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Alzheimers Dis</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="331" to="352" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Neural discrete representation learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Longitudinal self-supervised learning</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Adeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Pohl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page">102051</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
