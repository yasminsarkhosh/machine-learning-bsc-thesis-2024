<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">FedContrast-GPA: Heterogeneous Federated Optimization via Local Contrastive Learning and Global Process-Aware Aggregation</title>
				<funder ref="#_s6NBnjw">
					<orgName type="full">Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_vWVz2kv">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Qin</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute of Medical Robotics</orgName>
								<orgName type="department" key="dep2">School of Biomedical Engineering</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<addrLine>No. 800, Dongchuan Road</addrLine>
									<postCode>200240</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Guoyan</forename><surname>Zheng</surname></persName>
							<email>guoyan.zheng@sjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute of Medical Robotics</orgName>
								<orgName type="department" key="dep2">School of Biomedical Engineering</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<addrLine>No. 800, Dongchuan Road</addrLine>
									<postCode>200240</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">FedContrast-GPA: Heterogeneous Federated Optimization via Local Contrastive Learning and Global Process-Aware Aggregation</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="660" to="670"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">343981348B3F19CD9761AB1483B33DCC</idno>
					<idno type="DOI">10.1007/978-3-031-43895-0_62</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-01T10:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Heterogeneous federated learning</term>
					<term>Process-aware aggregation</term>
					<term>Local prototype learning</term>
					<term>Contrastive learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Federated learning is a promising strategy for performing privacy-preserving, distributed learning for medical image segmentation. However, the data-level heterogeneity as well as system-level heterogeneity makes it challenging to optimize. In this paper, we propose to improve Federated optimization via local Contrastive learning and Global Process-aware Aggregation (referred as FedContrast-GPA), aiming to jointly address both data-level and system-level heterogeneity issues. In specific, To address data-level heterogeneity, we propose to learn a unified latent feature space via an intra-client and inter-client local prototype based contrastive learning scheme. Among which, intra-client contrastive learning is adopted to improve the discriminative ability of learned feature embedding at each client, while inter-client contrastive learning is introduced to achieve cross-client distribution perception and alignment in a privacy preserving manner. To address system-level heterogeneity, we further propose a simple yet effective process-aware aggregation scheme to achieve effective straggler mitigation. Experimental results on six prostate segmentation datasets demonstrate large performance boost over existing state-of-the-art methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recently, federated learning has emerged as a promising strategy for performing privacy-preserving, distributed learning for medical image segmentation. Among various methods, FedAvg <ref type="bibr" target="#b0">[1]</ref> has been the de facto approach for federated learning, where the server maintains a global model which is dispatched to each client for updating locally on their own private data. After that, the updated local models are collected and averaged to produce a global model for the training of the next round. For FedAvg and its variants, a well-known issue is "client drift" caused by non-IID data distribution across different clients (i.e., data-level heterogeneity). To address this issue, a group of methods resort to designing proximal terms or reparametrization strategies <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref> to restrain the client drift from the global model. However, these regularization terms inherently limit the local convergence potential, Other methods try to improve the local models' generalization ability without strict proximal restrictions on model parameters <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>. In <ref type="bibr" target="#b26">[27]</ref>, the authors proposed to learn compact local representations on each device and a global model across all devices, reducing both the intra-client and inter-client data variance. However, these methods perform local updates blindly, totally ignoring the feature distributions of other clients. In medical image segmentation, FedDG <ref type="bibr" target="#b5">[6]</ref> was proposed to improve the local models' generalization ability via exchanging amplitude spectrum to transmit the distribution information across clients. However, the distribution perception step was processed offline, which was fixed upon finished, limiting its potential adaptability to various subsequent tasks.</p><p>Different from the above-mentioned methods, in this paper, we aim to tackle the "client drift" problem by exploring a unified latent feature space for different clients in a privacy-preserving manner and by enhancing the feature discriminability of each client. Concretely, we propose to extract local prototypes to represent the feature distribution at each client. Since local prototypes are statistical characteristics, we can share them among different clients without the concern of privacy issues. Then performing cross-client pixel to local prototype matching can help not only to perceive the global feature distribution but also to explicitly align the cross-client features, leading to a more unified latent feature space. Besides, by performing pixel to local prototype matching at each client, we can directly shape and enhance the discriminability of the learned feature space at each client.</p><p>Another well-acknowledged concern of federated networks is the "straggler" problem caused by system-level heterogeneity. FedAvg and some of its variants <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref> directly average the local models weighted by their data amount ratio, which may lead to unexpected deterioration due to asynchronous learning process of local models. Based on the intuition that well-trained local models should contribute more to the global model, in this paper, we propose a simple yet effective process-aware model aggregation scheme, which is demonstrated to effectively suppress the influence of "stragglers".</p><p>The contributions of our method can be summarized as follows:</p><p>-We propose a novel FedContrast-GPA framework to simultaneously alleviate both data-level and system-level heterogeneity issues in federated optimization. -We propose an intra-client and inter-client local prototype based contrastive learning scheme, which not only enhances the feature discriminability of each client, but also explicitly performs cross-client feature distribution perception and alignment in a privacy-preserving manner. -We introduce a simple yet effective process-aware weighting scheme to suppress the influence of "stragglers" in global model aggregation. 2 Method</p><p>A typical federated learning process consists of two stages: local update at each client and global aggregation at the server side. In this paper, we propose the FedContrast-GPA framework (as shown in Fig. <ref type="figure" target="#fig_0">1</ref>), which consists of the intraand inter-client local prototype based contrastive learning scheme (during local update) and the process-aware aggregation scheme (during global aggregation).</p><p>Assuming there exist K clients in the federated network, we denote client k as S k . Then private data set on the k-th client can be denoted as </p><formula xml:id="formula_0">{I n k , Y n k }, n ∈ {1, • • • , N k },</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Intra-and Inter-client Local-Prototype based Contrastive Learning</head><p>Local Prototype Learning. Denote the bottleneck features of class c on S k as</p><formula xml:id="formula_1">F c k = {f c,i k , i ∈ {1, • • • , N c k }},</formula><p>where N c k represents the number of pixels belonging to class c in the intermediate feature maps. In order to model the feature distribution of S k from a statistical view, we propose to generate the class-specific local prototypes to capture semantic-aware feature distribution. Considering that the spatial coverage and visual changes may vary dramatically across different classes, we extend the method introduced in <ref type="bibr" target="#b7">[8]</ref> to allow learning different number of sub-clusters for different semantic classes. For detailed derivation of local prototype learning, please refer to <ref type="bibr" target="#b7">[8]</ref>. Denote the learned local prototypes for class c as</p><formula xml:id="formula_2">P c k = {p c,t k , t ∈ {1, • • • , T c }} (</formula><p>where T c refers to the number of sub-clusters for class c), and the pixel-to-local-prototype mapping as </p><formula xml:id="formula_3">M c k = {m c,i k , i = {1, • • • , N c k }}, where m c,i k ∈ {1, • • • , T c }</formula><formula xml:id="formula_4">{P c k = {p c,t k , t ∈ {1, • • • , T c }}, c ∈ {1, • • • , C}}</formula><p>from all the semantic classes, where C is the total class number. Then contrastive learning is introduced to enforce compactness within a subcluster and separation among different sub-clusters. Specifically, the intra-client pixel-to-local-prototype contrastive loss is calculated as,</p><formula xml:id="formula_5">L c k = 1 Z C c=1 N c k i=1 -log e s c,m c,i k k C c =1 T c t=1 e s c ,t k ,<label>(1)</label></formula><p>where s  <ref type="figure"></ref>and<ref type="figure">s c ,t</ref> k represents the similarity score between f c,i k and the local prototype from the t-th sub-cluster of class c , where T c denotes the number of sub-clusters for class c , and Z is the normalization factor to average over all the pixels within a mini-batch. In our method, we adopt cosine similarity to get the similarity score,</p><formula xml:id="formula_6">s c ,t k =&lt; f c,i k , p c ,t k &gt;,<label>(2)</label></formula><p>where &lt;, &gt; denotes the cosine similarity function. Please note, visual compactness is only imposed at the sub-cluster granularity, which means the local features should distribute faraway from not only sub-clusters of the other semantic classes, but also other sub-clusters of the same semantic class. Apart from the contrastive loss term, in Intra-LPCL, we also explicitly maximize the feature similarities between local features and their assigned local prototypes as,</p><formula xml:id="formula_7">L d k = 1 Z C c=1 N c k i=1 1.0-&lt; f c,i k , p c,m c,i k k &gt;,<label>(3)</label></formula><p>Then the final Intra-LPCL loss is calculated as,</p><formula xml:id="formula_8">L intra k = L c k + L d k ,<label>(4)</label></formula><p>Inter-client Local-Prototype Based Contrastive Learning (Inter-LPCL) for Feature Alignment. The aim of Inter-LPCL is to perform distributed feature alignment across different clients in a privacy-preserving manner, such that the aggregated global model can generalize well across clients.</p><p>Given the i-th local feature of class c from S k (i.e., f c,i k ), and the prototypes pool</p><formula xml:id="formula_9">{P c k = {p c ,t k , t ∈ {1, • • • , T c }}, c ∈ {1, • • • , C}} from S k (k = k),</formula><p>we don't know the cross-client pixel-to-prototype assignments. Thus, instead of imposing strict restrictions on sub-cluster compactness as done in Intra-LPCL, we loosen the alignment restrictions to category level. Specifically, the local features from S k are supposed to distribute closer to one of the sub-clusters belonging to the same class in S k , and faraway from sub-clusters of the other semantic classes. Mathematically, the inter-LPCL loss is calcualted as,</p><formula xml:id="formula_10">L inter k,k = 1 Z C c=1 N c k i=1 -log e max({s c,t k,k t∈{1,••• ,Tc}}) C c =1 e max({s c ,t k,k ,t∈{1,••• ,T c }}) , (<label>5</label></formula><formula xml:id="formula_11">)</formula><p>where max(•) returns the maximum value in the set, {s c ,t k,k , t ∈ {1, • • • , T c }} denotes the similarity set calculated between f c,i k and all the local prototypes from class c in S k , which is formulated as,</p><formula xml:id="formula_12">s c ,t k,k =&lt; f c,i k , p c ,t k &gt;,<label>(6)</label></formula><p>The final Inter-LPCL loss of S k is then calculated by averaging over k in L inter k,k , which is formally defined as,</p><formula xml:id="formula_13">L inter k = 1 K -1 k =k L inter k,k ,<label>(7)</label></formula><p>Overall Objective for Local Update. The overall loss function for updating local model from S k is formulated as,</p><formula xml:id="formula_14">L k = L seg k + λ 1 L intra k + λ 2 L inter k , (<label>8</label></formula><formula xml:id="formula_15">)</formula><p>where λ 1 , λ 2 are the hyper-parameters, L seg k is the segmentation loss,</p><formula xml:id="formula_16">L seg k = 1 Z n CE(ϕ k (I n k ), Y n k ),<label>(9)</label></formula><p>where CE(•) denotes the cross entropy loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Process-Aware Global Model Aggregation</head><p>During each federated communication, FedAvg updates the global model as weighted average over local models, where α k is the aggregation weight for S k , which is commonly set as N k k N k (N k is the number of images in S k ). Instead of weighting the local models by its data amount ratio, in this paper, we argue that the aggregation weights should reflect the training process of each local model (i.e., well-trained model that generates good segmentation results should contribute more during aggregation). Specifically, denote the mean Dice Similarity Coefficient obtained on the training and validation data of S k as DSC k , then the normalized weights in our method are calculated as,</p><formula xml:id="formula_17">w = α k w k , k ∈ {1, • • • , K},<label>(10)</label></formula><formula xml:id="formula_18">α k = DSC k k DSC k . (<label>11</label></formula><formula xml:id="formula_19">)</formula><p>By introducing the process-aware aggregation scheme, we can effectively detect the straggler, improving the robustness of aggregated global model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head><p>Datasets and Implementation Details. We validate our method on the challenging task of prostate segmentation from 3D MR images. T2-weighted MRI images used in our study are collected from 6 different data sources <ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref>,</p><p>where each source is treated as a client in our study. We follow <ref type="bibr" target="#b27">[28]</ref> to preprocess the data. For data augmentation, both geometric transformations (including elastic deformation, translation, rotation and scaling) and intensity augmentations (including contrast and gaussian noise) are employed in our method. The local model is trained using Adam optimizer with a batch size of 64 and Adam momentum of 0.9 and 0.999. The learning rate is initialzed as 0.001 and multiplied by 0.9 after each round of federated communication. The local epoch in each federated round is empirically set as 1. The hyper-parameters λ 1 , λ 2 are empirically set as 0.03 and 0.001 respectively. The number of local prototypes for prostate and background are chosen by grid search, and empirically set as 3 and 6, respectively.</p><p>Ablation Study on the Effectiveness of Each Component: We denote the process-aware global aggregation as GA p , then the detailed analysis on component effectiveness is presented in Table <ref type="table" target="#tab_0">1</ref>. One can see from this table that incorporating the "Intra-LPCL" and "Inter-LPCL" terms can bring +1.3% and +1.4% overall DSC performance gains respectively, validating the effectiveness of intra-client discriminability enhancement and inter-client feature perception and alignment. Albeit its simplicity, our process-aware global aggregation scheme can also boost the DSC segmentation performance by a large margin (i.e., a 1.7% increase over the baseline). Combined together, the proposed FedContrast-GPA framework can witness a gain of 3.4% on the overall DSC performance.</p><p>To further demonstrate the advantage of our federated learning strategy, we conduct experiments to analyze the performance of centralized training and separate training, where centralized training is trained by updating the global model sequentially using private data from each client, while separate training is trained by updating each local client with only private data and no global communication. The average Dice performance for each client in centralized training is 73%, 77%, 84%, 72%, 86%, and 76%, respectively, while the average Dice performance for each client in separate training is 85%, 79%, 86%, 73%, 91%, and 27%, respectively. We can see that directly putting data together in centralized training does not bring performance gain due to data heterogeneity. Besides, in separate training, we can see a severe performance drop in some clients without enough learning data and knowledge from others.</p><p>Analysis on the Straggler Mitigation Effect. To demonstrate the effectiveness of our method in straggler mitigation, we compare the client-specific DSC and HD95 performance between the baseline (FedAvg) and Ours. For clarity, we first define the "stragglers" in a federated learning network as follows: the clients whose performance from the baseline (FedAvg) rank among the worst half of all the clients. Note that the "stragglers" are recognized according to the performance of FedAvg, since our method aims to address the "straggler" problem in FedAvg.</p><p>As shown in Fig. <ref type="figure" target="#fig_4">2</ref>, for the prostate segmentation task, "Client 2", "Client 4" and "Client 6" are the "stragglers". Compared to the "non-stragglers", we can observe large performance gains on the "stragglers". In specific, the DSC performance gains on "Client 2", "Client 4" and "Client 6" are 2.0%, 3.3% and +11.0% (on average a 5.4% DSC gain), respectively. The HD95 performance  gains are -0.33 mm, -0.47 mm, and -1.3 mm, respectively (on average -0.7 mm gain in terms of HD95). Meanwhile, for the "non-stragglers", the improvements are respectively 2.2%, 0.6% and 1.5% (on average 1.4%) in terms of DSC and -0.0 mm, -0.0 mm, and -0.11 mm (on average -0.04 mm) in terms of HD95.</p><p>From above analysis, we can see that the proposed method can achieve effective straggler mitigation by bringing larger performance gains over stragglers, and slightly boost the performance over the 'non-stragglers".</p><p>Comparison with State-of-the-Art Methods. We compare the performance of our method with five state-of-the-art (SOTA) methods, including FedAvg <ref type="bibr" target="#b0">[1]</ref>, FedAvg-LG <ref type="bibr" target="#b26">[27]</ref>, FedDG <ref type="bibr" target="#b5">[6]</ref>, FedProx <ref type="bibr" target="#b1">[2]</ref> and MOON <ref type="bibr" target="#b3">[4]</ref>. For fair comparison, all the SOTA methods were trained/tested on our own dataset splits. The base parameter settings are kept the same as ours, other hyperparameters are chosen by grid-search (In FedAvg-LG, the number of layers for global aggregation is set as 13, the hyper-parameters in FedDG are the same as the original paper, the weight for proxy term in FedProx is 2.5e-4, and the model contrastive coefficient in MOON is 0.01). In the following, we conduct both quantitative and qualitative comparisons with SOTA methods.</p><p>To analyse the performance of our proposed FedContrast-GPA framework, we report the DSCs for all the distributed clients (i.e., S 1 -S 6 in Table <ref type="table" target="#tab_1">2</ref>). For a straightforward comparison with the SOTA methods, we also record the average DSC across all the clients. Detailed comparison results are illustrated in Table <ref type="table" target="#tab_1">2</ref>. As shown, overall, our proposed FedContrast-GPA framework achieves superior performance than the listed SOTA methods. Specifically, FedContrast-GPA outperforms the second best method by 1.8% in terms of average DSC, and generates the best DSC performance at each client, demonstrating favorable generalization ability of our method. Figure <ref type="figure" target="#fig_5">3</ref> demonstrates some sampled visualization results from different clients. As shown, listed SOTA methods may fail to obtain good segmentation results on some samples from different clients, while our approach can consistently generate reasonably good results, demonstrating the robustness and generalizability of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>In this paper, we proposed a novel FedContrast-GPA framework to simultaneously address both the data-level heterogeneity and the system-level heterogeneity issues in federated networks. Extensive ablation studies and comparisons with the SOTA methods demonstrated the effectiveness of the proposed method.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The workflow of the proposed FedContrast-GPA framework. Please note in local update, same shapes mean the features belong to the same semantic class while same shapes of the same color figure online form a sub-cluster of the related semantic class. The local prototypes are marked with border lines. In global aggregation, the numbers indicate the training process. (Color figure online)</figDesc><graphic coords="4,41,79,53,96,340,21,105,73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>where I n k , Y n k are the image and the corresponding segmentation map for the n-th instance in S k , and N k is the number of instances in S k . In this paper, we adopt U-Net as the backbone architecture for segmentation. Denote ϕ k = f e k • f d k as the mapping function for S k , where f e k and f d k are the encoder and decoder, and • means sequentially executing f e k and f d k . Denote w k as the parameters of local model on S k , then the goal of federated learning is to find the optimal global model w = GA({w k }, k ∈ {1, • • • , K}) that generalizes well across different clients, where GA(•) refers to a certain strategy for model aggregation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>represents the assigned sub-cluster index of pixel i in class c. Then the learned local prototypes are utilized to perform intra-client feature enhancement and inter-client feature alignment. Please note, T c may vary for different semantic class to flexibly adapt to its visual characteristics. Intra-client Local-Prototype Based Contrastive Learning (Intra-LPCL) for Feature Enhancement. The motivation of Intra-LPCL is to enhance the discriminability of local features. Specifically, given the bottleneck features F c k , and the learned local prototypes</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>c,m c,i k k denotes the similarity between the i-th local feature of class c (i.e., f c,i k ) and the local prototype from the sub-cluster that it belongs to (i.e., p c,m c,i k k),</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Analysis on the straggler mitigation effect in terms of both DSC and 95% Hausdorff Distance (HD95) metrics.</figDesc><graphic coords="8,42,30,54,32,339,40,85,39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Qualitative comparison results between our method and other state-of-the-arts on prostate segmentation.</figDesc><graphic coords="9,88,47,196,79,275,80,158,44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Dice similarity coefficients (DSC) of different settings to demonstrate effectiveness of each component in our method.</figDesc><table><row><cell>Intra-LPCL Inter-LPCL GAp S1</cell><cell>S2</cell><cell>S3</cell><cell>S4</cell><cell>S5</cell><cell>S6</cell><cell>Average</cell></row><row><cell cols="7">87.5 83.0 88.9 80.1 90.0 76.3 84.3</cell></row><row><cell cols="7">86.3 85.5 87.1 81.3 90.8 82.5 85.6</cell></row><row><cell cols="7">88.8 86.0 87.8 80.0 91.4 80.2 85.7</cell></row><row><cell cols="7">88.2 86.3 86.9 82.8 91.1 80.5 86.0</cell></row><row><cell cols="7">89.7 85.0 89.5 83.4 91.5 87.3 87.7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Comparison with state-of-the-art methods in terms of DSC. Please note that larger DSC numbers indicate better performance. Best results are marked in bold.</figDesc><table><row><cell>Methods</cell><cell>S1</cell><cell>S2</cell><cell>S3</cell><cell>S4</cell><cell>S5</cell><cell>S6</cell><cell>Average</cell></row><row><cell>FedAvg</cell><cell cols="7">87.5 83.0 88.9 80.1 90.0 76.3 84.3</cell></row><row><cell cols="8">FedAvg-LG 83.8 82.4 85.3 75.9 89.9 56.3 78.9</cell></row><row><cell>FedDG</cell><cell cols="7">85.7 83.4 84.2 80.6 89.4 81.4 84.1</cell></row><row><cell>FedProx</cell><cell cols="7">88.1 84.3 86.2 83.1 90.6 83.1 85.9</cell></row><row><cell>MOON</cell><cell cols="7">87.0 84.9 87.7 82.7 90.3 83.0 85.9</cell></row><row><cell>Ours</cell><cell cols="7">89.7 85.0 89.5 83.4 91.5 87.3 87.7</cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div><p>This study was partially supported by the <rs type="funder">Natural Science Foundation of China</rs> via project <rs type="grantNumber">U20A20199</rs> and <rs type="grantNumber">62201341</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_s6NBnjw">
					<idno type="grant-number">U20A20199</idno>
				</org>
				<org type="funding" xml:id="_vWVz2kv">
					<idno type="grant-number">62201341</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Communication-efficient learning of deep networks from decentralized data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hampson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Arcas</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Statistics</title>
		<imprint>
			<biblScope unit="page" from="1273" to="1282" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Federated optimization in heterogeneous networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Sahu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sanjabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Talwalkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Mach. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="429" to="450" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">SCAF-FOLD: stochastic controlled averaging for federated learning</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Karimireddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Reddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Stich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Suresh</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5132" to="5143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Model-contrastive federated learning</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="10713" to="10722" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Local learning matters: rethinking data-level heterogeneity in federated learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mendieta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="8397" to="8406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">FedDG: federated domain generalization on medical image segmentation via episodic learning in continuous frequency space</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1013" to="1023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Self-supervision with Superpixels: training few-shot medical image segmentation without annotation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Biffi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-58526-6_45</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-58526-6_45" />
	</analytic>
	<monogr>
		<title level="m">ECCV 2020</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Bischof</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J.-M</forename><surname>Frahm</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12374</biblScope>
			<biblScope unit="page" from="762" to="780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Rethinking semantic segmentation: a prototype view</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Konukoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2582" to="2593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yurochkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Papailiopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Khazaeni</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.06440</idno>
		<title level="m">Federated learning with matched averaging</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Measuring the effects of non-identical data distribution for federated visual classification</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M H</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.06335</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Tackling the objective inconsistency problem in heterogeneous federated optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Poor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="7611" to="7623" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Federated contrastive learning for volumetric medical image segmentation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87199-4_35</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87199-4_35" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12903</biblScope>
			<biblScope unit="page" from="367" to="377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Few-shot semantic segmentation with prototype learning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference (BMVC)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Prototype refinement network for few-shot segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.03579</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Part-aware prototype network for few-shot semantic segmentation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-58545-7_9</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-58545-7_9" />
	</analytic>
	<monogr>
		<title level="m">ECCV 2020</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Bischof</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J.-M</forename><surname>Frahm</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12354</biblScope>
			<biblScope unit="page" from="142" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A location-sensitive local prototype network for few-shot medical image segmentation</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tajbakhsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Terzopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 18th International Symposium on Biomedical Imaging (ISBI)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="262" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A survey on contrastive self-supervised learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jaiswal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Babu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Z</forename><surname>Zadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Makedon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technologies</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Few-shot segmentation with global and local contrastive learning</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.05293</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Contrastive learning of global and local features for medical image segmentation with limited annotations</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chaitanya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Erdil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Karani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Konukoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="12546" to="12558" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Positional contrastive learning for volumetric medical image segmentation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="221" to="230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Distributed contrastive learning for medical image segmentation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page">102564</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">U-Net: convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-24574-4_28</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-24574-4_28" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2015</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hornegger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">9351</biblScope>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Bloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Madabhushi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huisman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Freymann</surname></persName>
		</author>
		<title level="m">NCI-ISBI 2013 Challenge: Automated Segmentation of Prostate Structures</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Computer-aided detection and diagnosis for prostate cancer based on mono and multi-parametric MRI: a review</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lemaitre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Marti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Freixenet</surname></persName>
		</author>
		<author>
			<persName><forename type="middle">J C</forename><surname>Vilanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers in Biology and Medicine</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="8" to="31" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Evaluation of prostate segmentation algorithms for MRI: the promise12 challenge</title>
		<author>
			<persName><forename type="first">G</forename><surname>Litjens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Toth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hoeks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Analysis</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="359" to="373" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Think locally, act globally: federated learning with local and global representations</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Federated Learning at Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">MS-Net: multi-site network for improving prostate segmentation with heterogeneous MRI data</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2713" to="2724" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Patro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Sahu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.06462</idno>
		<title level="m">Normalization: A preprocessing stage</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
