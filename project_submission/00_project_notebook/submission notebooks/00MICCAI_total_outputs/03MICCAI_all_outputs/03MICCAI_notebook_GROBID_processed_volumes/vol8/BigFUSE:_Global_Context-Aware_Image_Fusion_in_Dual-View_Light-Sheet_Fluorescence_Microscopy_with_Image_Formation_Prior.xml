<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">BigFUSE: Global Context-Aware Image Fusion in Dual-View Light-Sheet Fluorescence Microscopy with Image Formation Prior</title>
				<funder ref="#_cnj97tx">
					<orgName type="full">China Scholarship Council</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yu</forename><surname>Liu</surname></persName>
							<idno type="ORCID">0000-0003-2281-6791</idno>
							<affiliation key="aff0">
								<orgName type="institution">Technical University of Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gesine</forename><surname>Müller</surname></persName>
							<idno type="ORCID">0009-0007-9720-3099</idno>
							<affiliation key="aff1">
								<orgName type="institution">Georg-August-University Goettingen</orgName>
								<address>
									<settlement>Goettingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nassir</forename><surname>Navab</surname></persName>
							<idno type="ORCID">0000-0002-6032-5611</idno>
							<affiliation key="aff0">
								<orgName type="institution">Technical University of Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Johns Hopkins University</orgName>
								<address>
									<settlement>Baltimore</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Carsten</forename><surname>Marr</surname></persName>
							<idno type="ORCID">0000-0003-2154-4552</idno>
							<affiliation key="aff3">
								<orgName type="department">Institute of AI for Health</orgName>
								<orgName type="institution">Helmholtz Munich -German Research Center for Environmental Health</orgName>
								<address>
									<settlement>Neuherberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jan</forename><surname>Huisken</surname></persName>
							<idno type="ORCID">0000-0001-7250-3756</idno>
							<affiliation key="aff1">
								<orgName type="institution">Georg-August-University Goettingen</orgName>
								<address>
									<settlement>Goettingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Tingying</forename><surname>Peng</surname></persName>
							<email>tingying.peng@helmholtz-muenchen.de</email>
							<idno type="ORCID">0000-0002-7881-1749</idno>
							<affiliation key="aff4">
								<orgName type="department">Helmholtz AI</orgName>
								<orgName type="institution">Helmholtz Munich -German Research Center for Environmental Health</orgName>
								<address>
									<settlement>Neuherberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">BigFUSE: Global Context-Aware Image Fusion in Dual-View Light-Sheet Fluorescence Microscopy with Image Formation Prior</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="646" to="655"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">74DE4E1500A82FA4A4572FAF1AB768AF</idno>
					<idno type="DOI">10.1007/978-3-031-43993-3_62</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-01T10:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Light-sheet Fluorescence Microscopy (LSFM)</term>
					<term>Multi-View Image Fusion</term>
					<term>Bayesian</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Light-sheet fluorescence microscopy (LSFM), a planar illumination technique that enables high-resolution imaging of samples, experiences "defocused" image quality caused by light scattering when photons propagate through thick tissues. To circumvent this issue, dualview imaging is helpful. It allows various sections of the specimen to be scanned ideally by viewing the sample from opposing orientations. Recent image fusion approaches can then be applied to determine infocus pixels by comparing image qualities of two views locally and thus yield spatially inconsistent focus measures due to their limited field-ofview. Here, we propose BigFUSE, a global context-aware image fuser that stabilizes image fusion in LSFM by considering the global impact of photon propagation in the specimen while determining focus-defocus based on local image qualities. Inspired by the image formation prior in dual-view LSFM, image fusion is considered as estimating a focusdefocus boundary using Bayes' Theorem, where (i) the effect of light scattering onto focus measures is included within Likelihood ; and (ii) the spatial consistency regarding focus-defocus is imposed in Prior. The expectation-maximum algorithm is then adopted to estimate the focusdefocus boundary. Competitive experimental results show that BigFUSE is the first dual-view LSFM fuser that is able to exclude structured artifacts when fusing information, highlighting its abilities of automatic image fusion.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Light-sheet fluorescence microscopy (LSFM), characterized by orthogonal illumination with respect to detection, provides higher imaging speeds than other light microscopies, e.g., confocal microscopy, via gentle optical sectioning <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15]</ref>, which makes it well-suited for whole-organism studies <ref type="bibr" target="#b10">[11]</ref>. At macroscopic scales, however, light scattering degrade image quality. It leads to images from deeper layers of the sample being of worse quality than from tissues close to the illumination source <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b16">17]</ref>. To overcome the negative effect of photon propagation, dual-view LSFM is introduced, in which the sample is sequentially illuminated from opposing directions, and thus portions of the specimen with inferior quality in one view will be better in the other <ref type="bibr" target="#b15">[16]</ref> (Fig. <ref type="figure" target="#fig_0">1a</ref>). Thus, image fusion methods that combine information from opposite views into one volume are needed.</p><p>To realize dual-view LSFM fusion, recent pipelines adapt image fusers for natural image fusion to weigh between views by comparing the local clarity of images <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>. For example, one line of research estimates focus measures in a transformed domain, e.g., wavelet <ref type="bibr" target="#b6">[7]</ref> or contourlet <ref type="bibr" target="#b17">[18]</ref>, such that details with various scales can be considered independently <ref type="bibr" target="#b9">[10]</ref>. However, the composite result often exhibits global artifacts <ref type="bibr" target="#b7">[8]</ref>. Another line of studies conducts fusion in the image space, with pixel-level focus measures decided via local block-based representational engineering such as multi-scale weighted multi-scale weighted gradient <ref type="bibr" target="#b19">[20]</ref> and SIFT <ref type="bibr" target="#b8">[9]</ref>. Unfortunately, spatially inconsistent focus measures are commonly derived for LSFM, considering the sparse structures of the biological sample involved by the limited field-of-view (FOV).</p><p>Apart from limited FOV, another obstacle that hinders the adoption of natural image fusion methods into dual-view LSFM is the inability to distinguish sample structures from structural artifacts <ref type="bibr" target="#b0">[1]</ref>. For example, ghost artifacts, surrounding the sample as a result of scattered illumination light <ref type="bibr" target="#b2">[3]</ref>, can be observed, as it only appears in regions far from the light source after light travels through scattering tissues. Yet, when ghosts appear in one view, the same region in the opposite view would be background, i.e., no signal. Thus, ghosts will be erroneously transferred to the result by conventional fusion studies, as they are considered as owning richer information than its counterpart in the other view.</p><p>Here, we propose BigFUSE to realize spatially consistent image fusion and exclude ghost artifacts. Main contributions are summarized as follows:</p><p>• BigFUSE is the first effort to think of dual-view LSFM fusion using Bayes, which maximizes the conditional probability of fused volume regarding image clarity, given the image formation prior of opposing illumination directions. • The overall focus measure along illumination is modeled as a joint consideration of both global light scattering and local neighboring image qualities in the contourlet domain, which, together with the smoothness of focus-defocus, can be maximized as Likelihood and Prior in Bayesian. • Aided by a reliable initialization, BigFUSE can be efficiently optimized by utilizing expectation-maximum (EM) algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>An illustration of BigFUSE for dual-view LSFM fusion is given in Fig. <ref type="figure" target="#fig_0">1</ref>. First, pixel-level focus measures are derived for two opposing views separately, using nonsubsampled contourlet transform (NSCT) (Fig. <ref type="figure" target="#fig_0">1b</ref>). Pixel-wise photon propagation maps in tissue are then determined along light sheet via segmentation (Fig. <ref type="figure" target="#fig_0">1c</ref>). The overall focus measures are thus modeled as the inverse of integrated photon scattering along illumination conditioned on the focus-defocus change, i.e., Likelihood, whereas the smoothness of focus-defocus is ensured via Prior. Finally, the focus-defocus boundary is optimized via EM (Fig. <ref type="figure" target="#fig_0">1d</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Revisiting Dual-View LSFM Fusion Using Bayes</head><p>BigFUSE first rethinks dual-view LSFM fusion from a Bayesian perspective, that is, the conditional probability of fused volume in terms of "in-focusness", is given on not only a pair of image inputs, but also prior knowledge that these two images are illiminated from opposing orientations respectively:</p><formula xml:id="formula_0">Y = argmax Y p(Y|(X a , X b ), P) = argmax Y {p(Y|P)p((X a , X b )|Y, P)} (1)</formula><p>where Y ∈ R M ×N is our predicted fusion with minimal light scattering effect. X a and X b are two image views illuminated by light source a and b, respectively. We choose Y ∈ {X a , X b } depending on their competitive image clarity at each pixel. Priors P denote our empirical favor of X a against X b at each pixel if photons travel through fewer scattering tissues from source a than b, and vice versa. Due to the non-positive light scattering effect along illumination path, there is only one focus-defocus change per column for dual-view LSFM in Fig. <ref type="figure" target="#fig_0">1a</ref>. Thus, fusion is equivalent to estimating a focus-defocus boundary ω defined as a function associating focus-defocus changes to column indexes:</p><formula xml:id="formula_1">ω = argmax ω p(ω)p((X a , X b )|ω)<label>(2)</label></formula><p>which can be further reformulated by logarithm:</p><formula xml:id="formula_2">ω = argmax ω p(ω)p((X a , X b )|ω) = argmax ω∈{1,2,...,N } log(p(ω) N i=1 p((X a :,i , X b :,i )|ω i )) = argmax ω∈{1,2,...,N } log(p(ω)) + N i=1 log(p((X a :,i , X b :,i )|ω i ))<label>(3)</label></formula><p>where ω i denotes the focus-defocus changeover at i -th column, X :,i is the i -th column of X. Next, estimating ω is decomposed into: (i ) define the column-wise image clarity, i.e., log-likelihood log(p((X a :,i , X b :,i )|ω i )); (ii ) consider the belief on a spatially smooth focus-defocus boundary, namely log-prior log(p(ω)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Image Clarity Characterization with Image Formation Prior</head><p>In LSFM, log-likelihood log(p((X a :,i , X b :,i )|ω i )) can be interpreted as the probability of observing (X a :,i , X b :,i ) given the hypothesis that the focus-defocus change is determined as ω i in the i -th column:</p><formula xml:id="formula_3">argmax ωi log(p((X a :,i , X b :,i )|ω i )) = argmax ωi c(X a 1:ωi,i ⊕ X b ωi+1:M,i ) (<label>4</label></formula><formula xml:id="formula_4">)</formula><p>where ⊕ is a concatenation, c(•) is the column-wise image clarity to be defined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Estimating Pixel-Level Image Clarity in NSCT.</head><p>To define c(•), BigFUSE first uses NSCT, a shift-invariant image representation technique, to estimate pixel-level focus measures by characterizing salient image structures <ref type="bibr" target="#b17">[18]</ref>. Specifically, NSCT coefficients S a and S b are derived for two opposing LSFM views, where S = {S i0 , S i,l |(1 ≤ i ≤ i 0 , 1 ≤ l ≤ 2 li )}, S i0 is the lowpass coefficient at the coarsest scale, S i,l is the bandpass directional coefficient at i -th scale and l -th direction. Local image clarity is then projected from S a and S b <ref type="bibr" target="#b17">[18]</ref>:</p><formula xml:id="formula_5">F i,l = R i,l × Dσ i = |S i,l | Si0 × 1 2 li 2 l i r=1 [|S i,r | -Si ] 2 , Si = 1 2 li 2 l i r=1 |S i,r |(5)</formula><p>where R i,l is local directional band-limited image contrast and Si0 is the smoothed image baseline, whereas Dσ i highlights image features that are distributed only on a few directions, which is helpful to exclude noise <ref type="bibr" target="#b17">[18]</ref>. As a result, pixel-level image clarity F = j0 j=1 2ˆlj l=1 F j,l is quantified for respective LSFM view.</p><p>Reweighting Image Clarity Measures by Photon Traveling Path. Pixelindependent focus measures may be adversely sensitive to noise, due to the limited receptive field when characterizing local image clarities. Thus, BigFUSE proposes to integrate pixel-independent image clarity measures along columns by taking into consideration the photon propagation in depth. Specifically, given a pair of pixels (X a m,n , X b m,n ), X a m,n is empirically more in-focus than X a m,n , if photons travel through fewer light-scattering tissues from illumination objective a than from b to get to position (m, n), and vice versa. Therefore, BigFUSE defines column-level image clarity measures as:</p><formula xml:id="formula_6">c(X a 1:ωi,i ⊕ X b ωi+1:M,i ) = ωi j=1 A j,i F a j,i + M j=ωi+1 A j,i F b j,i<label>(6)</label></formula><p>where A :,i is to model the image deterioration due to light scattering. To visualize photon traveling path, BigFUSE uses OTSU thresholding for foreground segmentation (followed by AlphaShape to generalize bounding polygons), and thus obtains sample boundary, i.e., incident points of light sheet, which we refer to as p u and p l for opposing views a and b respectively. Since the derivative of A :,i implicitly refers to the spatially varying index of refraction within the sample, which is nearly impossible to accurately measure from the physics perspective, we model it using a piecewise linear model, without loss of generality:</p><formula xml:id="formula_7">A j,i = ⎧ ⎨ ⎩ 1 -0.5 × |j -p u | /ω i , j&lt;ω i 0.5 + 0.5 × j -p l /(M -ω i ), j ≥ ω i 0, otherwise<label>(7)</label></formula><p>As a result, log(p((X a :,i , X b :,i )|ω i )) is obtained as summed pixel-level image clarity measures with integral factors conditioned on photon propagation in depth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Least Squares Smoothness of Focus-Defocus Boundary</head><p>With log-likelihood log(p((X a :,i , X b :,i )|ω i )) considering the focus-defocus consistency along illuminations using image formation prior in LSFM, BigFUSE then ensures consistency across columns in p(ω). Specifically, the smoothness of ω is characterized as a window-based polynomial fitness using linear least squares:</p><formula xml:id="formula_8">log(p(ω)) = N i=1 log(p(ω i )) = N i=1 ω i-s:i+s -υi 2 (8) where υi = c i Ω i = [c i,0 , c i,1 , . . . , c i,Q ][ω T i-s , ω T i-s+1 , . . . , ω T i+s ], ω i = [ω Q i , ω Q-1 i , . . . , 1]</formula><p>, c i is the parameters to be estimated, the sliding window is with a size of 2s + 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Focus-Defocus Boundary Inference via EM</head><p>Finally, in order to estimate the ω together with the fitting parameter c, Big-FUSE reformulates the posterior distribution in Eq. ( <ref type="formula" target="#formula_1">2</ref>) as follows:</p><formula xml:id="formula_9">{ω, ĉ} = argmax ω,c N j=1 ωj i=1 A i,j F a i,j + M i=ωj +1 A i,j F b i,j +λ{ N i=1 ω i-s:i+s -υi 2 } (<label>9</label></formula><formula xml:id="formula_10">)</formula><p>where λ is the trade-off parameter. Here, BigFUSE alternates the estimations of ω, and c, and iterates until the method converges. Specifically, given c (n) for the n-th iteration, ω (n+1) i is estimated by maximizing (E-step):</p><formula xml:id="formula_11">ω (n+1) i = argmax ωi ωi j=1 A j,i F a j,i + M j=ωi+1 A j,i F b j,i + λ ω i-s:i+s -υi 2<label>(10)</label></formula><p>which can be solved by iterating over {i|1 ≤ i ≤ M }. BigFUSE then updates c (n+1) i based on least squares estimation: Additionally, A n+1 is updated based on Eq. ( <ref type="formula" target="#formula_7">7</ref>) subject to ω (n+1) (M-step). BigFUSE proposes to initialize ω based on F a and F b :</p><formula xml:id="formula_12">c (n+1) i = (Ω T Ω) -1 Ω T ω i-s:i+s (11)</formula><formula xml:id="formula_13">ω (0) i = p u + |Φ|, Φ = {j|F a j,i &gt; F b j,i , p u ≤ j ≤ p l } (<label>12</label></formula><formula xml:id="formula_14">)</formula><p>where |Φ| denotes the total number of elements in Φ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Competitive Methods</head><p>We compare BigFUSE to four baseline methods: (i ) DWT <ref type="bibr" target="#b15">[16]</ref>: a multi-resolution image fusion method using discrete wavelet transform (DWT); (ii ) NSCT <ref type="bibr" target="#b17">[18]</ref>: another multi-scale image fuser but in the NSCT domain; (iii ) dSIFT <ref type="bibr" target="#b8">[9]</ref>: a dense SIFT-based focus estimator in the image space; (iv ) BF <ref type="bibr" target="#b18">[19]</ref>: a focusdefocus boundary detection method that considers region consistency in focus; and two BigFUSE variations: (v ) S(•): built by disabling smooth constraint;</p><p>(vi ) P(•): formulated by replacing the weighted summation of pixel-level clarity measures for overall characterization, by a simple average. To access the blind image fusion performance, we adopt three fusion quality metrics, Q mi <ref type="bibr" target="#b3">[4]</ref>, Q g <ref type="bibr" target="#b11">[12]</ref> and Q s <ref type="bibr" target="#b12">[13]</ref>. Specifically, Q mi , Q g and Q s use mutual information, gradient or image quality index to quantify how well the information or features of the inputs are transferred to the result, respectively. In the simulation studies where ground truth is available, mean square error (EMSE) and structural similarity index (SSIM) are used for quantification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results and Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Evaluation on LSFM Images with Synthetic Blur</head><p>We first evaluate BigFUSE in fusing dual-view LSFM blurred by simulation. Here, we blur a mouse brain sample collected in <ref type="bibr" target="#b1">[2]</ref> with spatially varying Gaussian filter for thirty times, which is chemically well-cleared and thus provides an almost optimal ground truth for simulation, perform image fusion, and compare the results to the ground truth. BigFUSE achieves the best EMSE and SSIM, statistically surpassing other approaches (Table <ref type="table" target="#tab_0">1</ref>, p &lt; 0.05 using Wilcoxon signed-rank test). Only BigFUSE and BF realize information fusing without damaging original images with top two EMSE. In comparison, DWT, NSCT and dSIFT could distort the original signal when fusing (green box in Fig. <ref type="figure">2</ref>).   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation on LSFM Images with Real Blur</head><p>BigFUSE is then evaluated against baseline methods on real dual-view LSFM. A large sample volume, zebrafish embryo (282 × 2048 × 2048 for each view), is imaged using a Flamingo Light Sheet Microscope. BigFUSE takes roughly nine minutes to process this zebrafish embryo, using a T4 GPU with 25 GB system RAM and 15 GB GPU RAM. In Fig. <ref type="figure" target="#fig_2">4</ref>, inconsistent boundary is detected by BF, while methods like DWT and NSCT generate structures that do not exist in either input. Moreover, only BigFUSE can exclude ghost artifact from the result (red box), as BigFUSE is the only pipeline that considers image formation prior. Additionally, we demonstrate the impact of bigFUSE on a specific downstream task in Fig. <ref type="figure" target="#fig_3">5</ref>, i.e., segmentation by Cellpose. Only the fusion result provided by bigFUSE allows reasonable predicted cell pose, given that ghosting artifacts are excluded dramatically. This explains why the Q s in Fig. <ref type="figure">3</ref> is suboptimal, since BigFUSE do not allow for the transmission of structural ghosts to the output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we propose BigFUSE, a image fusion pipline with image formation prior. Specifically, image fusion in dual-view LSFM is revisited as inferring a focus-defocus boundary using Bayes, which is essential to exclude ghost artifacts. Furthermore, focus measures are determined based on not only pure image representational engineering in NSCT domain, but also the empirical effects of photon propagation in depth embeded in the opposite illumination directions in dualview LSFM. BigFUSE can be efficiently optimized using EM. Both qualitative and quantitative evaluations show that BigFUSE surpasses other state-of-the-art LSFM fusers by a large margin. BigFUSE will be made accessible.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. An overview of BigFUSE (see text for explanation)</figDesc><graphic coords="3,60,81,196,43,302,56,89,80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .Fig. 3 .</head><label>23</label><figDesc>Fig. 2. Visualization of fusion quality with respect to ground-truth. Focus-defocus boundary is given in blue curve, if applicable. (Color figure online)</figDesc><graphic coords="7,59,31,232,52,305,20,116,80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Visualization of fusing a zebrafish embryo.</figDesc><graphic coords="7,43,80,486,59,336,76,64,84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Visualization of Cellpose result.</figDesc><graphic coords="8,64,17,58,46,329,44,85,24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>BigFUSE achieves best quantitative results on synthetic blur.</figDesc><table><row><cell></cell><cell cols="5">DWT [16] NSCT [18] dSIFT [9] BF [19] S(•)</cell><cell>P(•)</cell><cell>BigFUSE</cell></row><row><cell>EMSE</cell><cell>6.81</cell><cell>4.66</cell><cell>5.17</cell><cell>1.55</cell><cell>1.43</cell><cell>0.96</cell><cell>0.94</cell></row><row><cell>(×10 -5 )</cell><cell>±0.72</cell><cell>±0.56</cell><cell>±0.72</cell><cell>±0.25</cell><cell>±0.34</cell><cell>±0.08</cell><cell>±0.09</cell></row><row><cell>SSIM</cell><cell>0.974</cell><cell>0.996</cell><cell>0.93</cell><cell>0.994</cell><cell>0.993</cell><cell>0.993</cell><cell>0.998</cell></row><row><cell></cell><cell>±0.02</cell><cell>±0.03</cell><cell>±0.01</cell><cell>±0.03</cell><cell>±0.02</cell><cell>±0.02</cell><cell>±0.01</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. Y.L. is supported by the <rs type="funder">China Scholarship Council</rs> (No.<rs type="grantNumber">20210 6020050</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_cnj97tx">
					<idno type="grant-number">20210 6020050</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A review on multimodal medical image fusion: compendious analysis of medical modalities, multimodal databases, fusion techniques and quality metrics</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Azam</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.compbiomed.2022.105253</idno>
		<ptr target="https://doi.org/10.1016/j.compbiomed.2022.105253" />
	</analytic>
	<monogr>
		<title level="j">Comput. Biol. Med</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="page">105253</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Isotropic imaging across spatial scales with axially swept lightsheet microscopy</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Dean</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41596-022-00706-6</idno>
		<idno>41596-022-00706-6</idno>
		<ptr target="https://doi.org/10.1038/s" />
	</analytic>
	<monogr>
		<title level="j">Nat. Protoc</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2025" to="2053" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Microscopy with self-reconstructing beams</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">O</forename><surname>Fahrbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rohrbach</surname></persName>
		</author>
		<idno type="DOI">10.1038/nphoton.2010.204</idno>
		<ptr target="https://doi.org/10.1038/nphoton.2010.204" />
	</analytic>
	<monogr>
		<title level="j">Nat. Photonics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="780" to="785" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Comments on &apos;information measure for performance of image fusion</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hossny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nahavandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Creighton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Quantitative in vivo imaging of entire embryos with digital scanned laser light sheet fluorescence microscopy</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Stelzer</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.conb.2009.03.008</idno>
		<ptr target="https://doi.org/10.1016/j.conb.2009.03.008" />
	</analytic>
	<monogr>
		<title level="j">Curr. Opin. Neurobiol</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="624" to="632" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multiview light-sheet microscope for rapid in toto imaging</title>
		<author>
			<persName><forename type="first">U</forename><surname>Krzic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gunther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Streichan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hufnagel</surname></persName>
		</author>
		<idno type="DOI">10.1038/nmeth.2064</idno>
		<ptr target="https://doi.org/10.1038/nmeth.2064" />
	</analytic>
	<monogr>
		<title level="j">Nat. Meth</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="730" to="733" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Pixeland region-based image fusion with complex wavelets</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>O'callaghan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Bull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Canagarajah</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.inffus.2005.09.006</idno>
		<ptr target="https://doi.org/10.1016/j.inffus.2005.09.006" />
	</analytic>
	<monogr>
		<title level="j">Inf. Fusion</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="119" to="130" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Image fusion with guided filtering</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<idno type="DOI">10.1109/TIP.2013.2244222</idno>
		<ptr target="https://doi.org/10.1109/TIP.2013.2244222" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2864" to="2875" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multi-focus image fusion with dense sift</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.inffus.2014.05.004</idno>
		<ptr target="https://doi.org/10.1016/j.inffus.2014.05.004" />
	</analytic>
	<monogr>
		<title level="j">Inf. Fusion</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="139" to="155" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multi-focus image fusion: a survey of the state of the art</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.inffus.2020.06.013</idno>
		<ptr target="https://doi.org/10.1016/j.inffus.2020.06.013" />
	</analytic>
	<monogr>
		<title level="j">Inf. Fusion</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="71" to="91" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Confocal multiview light-sheet microscopy</title>
		<author>
			<persName><forename type="first">G</forename><surname>Medeiros</surname></persName>
		</author>
		<idno type="DOI">10.1038/ncomms9881</idno>
		<ptr target="https://doi.org/10.1038/ncomms9881" />
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">8881</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Objective image fusion performance characterisation</title>
		<author>
			<persName><forename type="first">V</forename><surname>Petrovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xydeas</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICCV.2005.175</idno>
		<ptr target="https://doi.org/10.1109/ICCV.2005.175" />
	</analytic>
	<monogr>
		<title level="m">Tenth IEEE International Conference on Computer Vision (ICCV 2005)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1866" to="1871" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A new quality metric for image fusion</title>
		<author>
			<persName><forename type="first">G</forename><surname>Piella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Heijmans</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICIP.2003.1247209</idno>
		<ptr target="https://doi.org/10.1109/ICIP.2003.1247209" />
	</analytic>
	<monogr>
		<title level="m">Proceedings 2003 International Conference on Image Processing</title>
		<meeting>2003 International Conference on Image Processing</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">173</biblScope>
		</imprint>
	</monogr>
	<note>Cat. No. 03CH37429</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A guide to light-sheet fluorescence microscopy for multiscale imaging</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Power</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huisken</surname></persName>
		</author>
		<idno type="DOI">10.1038/nmeth.4224</idno>
		<ptr target="https://doi.org/10.1038/nmeth.4224" />
	</analytic>
	<monogr>
		<title level="j">Nat. Meth</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="360" to="373" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Guide to light-sheet microscopy for adventurous biologists</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Reynaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peychl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huisken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tomancak</surname></persName>
		</author>
		<idno type="DOI">10.1038/nmeth.3222</idno>
		<ptr target="https://doi.org/10.1038/nmeth.3222" />
	</analytic>
	<monogr>
		<title level="j">Nat. Meth</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="30" to="34" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Wavelet-based image fusion in multi-view threedimensional microscopy</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Rubio-Guivernau</surname></persName>
		</author>
		<idno type="DOI">10.1093/bioinformatics/btr609</idno>
		<ptr target="https://doi.org/10.1093/bioinformatics/btr609" />
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="238" to="245" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Restoration of light sheet multi-view data with the Huygens fusion and deconvolution wizard</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Verveer</surname></persName>
		</author>
		<idno type="DOI">10.1017/S1551929518000846</idno>
		<ptr target="https://doi.org/10.1017/S1551929518000846" />
	</analytic>
	<monogr>
		<title level="j">Microscopy today</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="12" to="19" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Multifocus image fusion using the nonsubsampled contourlet transform. Signal Process</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Guo</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.sigpro.2009.01.012</idno>
		<ptr target="https://doi.org/10.1016/j.sigpro.2009.01.012" />
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="1334" to="1346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Boundary finding based multi-focus image fusion through multi-scale morphological focus-measure</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.inffus.2016.09.006</idno>
		<ptr target="https://doi.org/10.1016/j.inffus.2016.09.006" />
	</analytic>
	<monogr>
		<title level="j">Inf. Fusion</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="81" to="101" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Multi-scale weighted gradient-based fusion for multifocus images</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.inffus.2013.11.005</idno>
		<idno>11.005</idno>
		<ptr target="https://doi.org/10.1016/j.inffus.2013" />
	</analytic>
	<monogr>
		<title level="j">Inf. Fusion</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="60" to="72" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
