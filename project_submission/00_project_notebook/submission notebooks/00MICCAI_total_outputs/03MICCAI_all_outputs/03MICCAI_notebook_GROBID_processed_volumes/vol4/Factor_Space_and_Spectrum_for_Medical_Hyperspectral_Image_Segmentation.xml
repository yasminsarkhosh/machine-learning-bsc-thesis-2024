<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Factor Space and Spectrum for Medical Hyperspectral Image Segmentation</title>
				<funder ref="#_YNp6fRh">
					<orgName type="full">Science and Technology Commission of Shanghai Municipality</orgName>
				</funder>
				<funder ref="#_M57bfqT">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_XgPvTEy">
					<orgName type="full">Shanghai Natural Science Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Boxiang</forename><surname>Yun</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Shanghai Key Laboratory of Multidimensional Information Processing</orgName>
								<orgName type="institution">Normal University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country>East China, China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qingli</forename><surname>Li</surname></persName>
							<email>qlli@cs.ecnu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Shanghai Key Laboratory of Multidimensional Information Processing</orgName>
								<orgName type="institution">Normal University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country>East China, China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lubov</forename><surname>Mitrofanova</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Chunhua</forename><surname>Zhou</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Medicine</orgName>
								<orgName type="institution" key="instit1">Rui Jin Hospital</orgName>
								<orgName type="institution" key="instit2">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yan</forename><surname>Wang</surname></persName>
							<email>ywang@cee.ecnu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Shanghai Key Laboratory of Multidimensional Information Processing</orgName>
								<orgName type="institution">Normal University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country>East China, China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Factor Space and Spectrum for Medical Hyperspectral Image Segmentation</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="152" to="162"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">F6D12BFAAF713B9DA0B8045C19CEEF63</idno>
					<idno type="DOI">10.1007/978-3-031-43901-8_15</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-01T10:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Medical hyperspectral images • MHSI segmentation</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Medical Hyperspectral Imaging (MHSI) brings opportunities for computational pathology and precision medicine. Since MHSI is a 3D hypercube, building a 3D segmentation network is the most intuitive way for MHSI segmentation. But, high spatiospectral dimensions make it difficult to perform efficient and effective segmentation. In this study, in light of information correlation in MHSIs, we present a computationally efficient, plug-and-play space and spectrum factorization strategy based on 2D architectures. Drawing inspiration from the low-rank prior of MHSIs, we propose spectral matrix decomposition and low-rank decomposition modules for removing redundant spatiospectral information. By plugging our dual-stream strategy into 2D backbones, we can achieve state-of-the-art MHSI segmentation performances with 3-13 times faster compared with existing 3D networks in terms of inference speed. Experiments show our strategy leads to remarkable performance gains in different 2D architectures, reporting an improvement up to 7.7% compared with its 2D counterpart in terms of DSC on a public Multi-Dimensional Choledoch dataset. Code is publicly available at https:// github.com/boxiangyun/Dual-Stream-MHSI.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Medical Hyperspectral Imaging (MHSI) is an emerging imaging modality which acquires two-dimensional medical images across a wide range of electromagnetic spectrum. It brings opportunities for disease diagnosis, and computational pathology <ref type="bibr" target="#b18">[16]</ref>. Typically, an MHSI is presented as a hypercube, with hundreds of narrow and contiguous spectral bands in spectral dimension, and thousands of pixels in spatial dimension (Fig. <ref type="figure" target="#fig_0">1(a)</ref>). Due to the success of 2-Dimensional (2D) deep neural network in natural images, the simplest way to classify/segment an MHSI is to treat its two spatial dimensions as input spatial dimension, and treat its spectral dimension as input channel dimension <ref type="bibr" target="#b27">[25]</ref> (Fig. <ref type="figure" target="#fig_0">1(c)</ref>). Dimensionality reduction <ref type="bibr" target="#b14">[12]</ref> and recurrent approaches <ref type="bibr" target="#b3">[1]</ref> are usually adopted to aggregate spectral information before feeding the HSI into 2D networks (Fig. <ref type="figure" target="#fig_0">1(d)</ref>). These methods are not suitable for high spatial resolution MHSI, and they may bring noises in spatial features while reducing spectral dimension. The 2D networks are computationally efficient, usually much faster than 3D networks. But, they mix spectral information after the first convolutional layer, making the interband correlations of MHSIs underutilized. Building a 3D network usually suffers from high computational complexity, but it is the most straightforward way to learn interpixel and interband correlations of MHSIs <ref type="bibr" target="#b25">[23]</ref> (Fig. <ref type="figure" target="#fig_0">1</ref>(e)). Since spatiospectral orientations are not equally likely, there is no need to treat space and spectrum symmetrically, as is implicit in 3D networks. We might instead design a dual-stream strategy to "factor" the architecture. A few HSI classification backbones try to design dual-stream architectures that treat spatial structures and spectral intensities separately <ref type="bibr" target="#b4">[2,</ref><ref type="bibr" target="#b22">20,</ref><ref type="bibr" target="#b32">30]</ref> (Fig. <ref type="figure" target="#fig_0">1</ref>(f)). But, these methods simply adopt convolutional or MLP layers to extract spectral features. SpecTr <ref type="bibr" target="#b30">[28]</ref>, learning spectral and spatial features alternatively, utilizes Transformer to capture the global spectral feature. They overlook the low rankness in the spectral domain, which contains discriminative information for differentiating targets from the background.</p><p>High spatiospectral dimensions make it difficult to perform a thorough analysis of MHSI. In MHSIs, there exist two types of correlation. One is a spectral correlation in adjacent pixels. As shown in Fig. <ref type="figure" target="#fig_0">1</ref>(b), the intensity values vs. spectral bands for the local positive (cancer) area and negative (normal) area are highly correlated. The other is spatial correlation between adjacent bands. Figure <ref type="figure" target="#fig_0">1</ref>(b) plots the spatial similarity among all bands, and shows large cosine similarity scores among nearby bands (error band of line chart in the light color area) and small scores between bands in a long distance. The correlation implies spectral redundancy when representing spatial features, and spatial redundancy when learning spectral features. The low-rank structure in MHSIs holds significant discriminatory and characterizing information <ref type="bibr" target="#b13">[11]</ref>. Exploring MHSI's low-rank prior can promote the segmentation performance.</p><p>In this paper, we consider treating spatiospectral dimensions separately and propose an effective and efficient dual-stream strategy to "factor" the architecture, by exploiting the correlation information of MHSIs. Our dual-stream strategy is designed based on 2D CNNs with U-shaped <ref type="bibr" target="#b18">[16]</ref> architecture. For the spatial feature extraction stream, inspired from spatial redundancy between adjacent bands, we group adjacent bands into a spectral agent. Different spectral agents are fed into a 2D CNN backbone as a batch. For the spectral feature extraction stream, inspired by the low-rank prior on the spectral space, we propose a matrix factorization-based method to capture global spectral information. To remove the redundancy in the spatiospectral features and promote the capability of representing the low-rank prior of MHSI, we further design Lowrank Decomposition modules, and employ the Canonical-Polyadic decomposition method <ref type="bibr" target="#b11">[9,</ref><ref type="bibr" target="#b34">32]</ref>. Our space and spectrum factorization strategy is plug-and-play. The effectiveness of the proposed strategy is compared and verified by plugging in different 2D architectures. We also show that with our proposed strategy, U-Net model using ResNet-34 can achieve state-of-the-art MHSI segmentation with 3-13 faster than other 3D architectures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>Mathematically, let Z ∈ R S×H×W denote the 3D volume of a pathology MHSI, where H × W is the spatial resolution, and S is the number of spectral bands. The goal of MHSI segmentation is to predict the per-pixel annotation mask</p><formula xml:id="formula_0">Ŷ ∈ {0, 1} H×W . Our training set is D = {(Z i , Y i )} N i=1</formula><p>, where Y i denotes the per-pixel groundtruth for MHSI Z i .</p><p>The overall architecture of our proposed method is shown in Fig. <ref type="figure" target="#fig_1">2</ref>, where the 2D CNN in the figure is a proxy which may represent all widely-used 2D architectures. It represents a spatial stream, which focuses on extracting spatial features from spectral agents (Sect. 2.1). The lightweight spectral stream learns multi-granular spectral features, and it consists of three key modules: Depthwise Convolution (DwConv), Spectral Matrix Decomposition (SMD) and Feed Forward Network, where SMD module effectively leverages low-rank prior from spectral features (Sect. 2.1). Besides, the Low-rank Decomposition module (LD) represents high-level low-rank spatiospectral features (Sect. 2.2). The input MHSI Z is decomposed into a spatial input Z spa ∈ R G×(S/G)×H×W and a spectral input Z spe ∈ R S×C spe 0 ×H×W , where G indicates evenly dividing spectral bands into G groups, i.e., spectral agents. S/G and C spe 0 = 1 are the input feature dimensions for two streams respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Dual-Stream Architecture with SpatioSpectral Representation</head><p>As mentioned above, for the spatial stream, we first reshape MHSI Z ∈ R S×H×W into Z spa ∈ R G×(S/G)×H×W , which has G spectral agents. Each spectral agent is treated as one sample. One sample contains highly correlated spectral bands, so that the spatial stream can focus on spatial feature extraction. For the spectral stream, to deal with problems of spatiospectral redundancy and the inefficiency of global spectral feature representation, we propose a novel and concise hierarchical structure shown in Fig. <ref type="figure" target="#fig_1">2</ref>. We employ a basic transformer paradigm <ref type="bibr" target="#b23">[21]</ref> but design it tailored for capturing global low-rank spectral features. Our spectral encoder block can be formulated by:</p><formula xml:id="formula_1">X = DwConv(Z in ), X = SM D(Norm(X))+ X, Z out = F F N(Norm(X ))+X ,<label>(1)</label></formula><p>where Z in ∈ R S×Cspe×H×W indicates the input spectral token tensor, and C spe is the spectral feature dimension. We introduce Depth-wise Conv (DwConv) for dynamically integrating redundant spatial information into spectral features to reduce spatial redundant noises, achieved by setting different strides of the convolutional kernel. Then, we represent long-distance dependencies among spectral inter-bands as a low-rank completion problem. SM D(•) indicates the spectral matrix decomposition operation. Concretely, we flatten feature map X to spectral sequence tokens X spe ∈ R H•W ×S×Cspe , which has S spectral tokens. We map X spe to a feature space using a linear transform W l ∈ R Cspe×C spe . We then apply a matrix decomposition method NMF (Non-negative Matrix Factorization) <ref type="bibr" target="#b12">[10]</ref>, denoted by M(•), to identify and solve for a low-rank signal subspace and use iterative optimization algorithms backpropagate gradients <ref type="bibr" target="#b6">[4]</ref>: SM D(X spe ) = M(W l X spe ). Finally, to enhance the individual component of spectral tokens, we utilize a Feedforward Neural Network (FFN) in Transformer consisting of two linear layers and an activation layer.</p><p>In the framework shown in Fig. <ref type="figure" target="#fig_1">2</ref>, spectral information is integrated from channel dimensions by performing concatenation, after the second and fourth encoder blocks, to aggregate the spatiospectral features. The reason for this design is that spectral features are simpler and lack hierarchical structures compared to spatial features, we will discuss more in the experimental section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Low-Rank Decomposition and Skip Connection Ensemble</head><p>The MHSI has low-rank priority due to redundancy, so we propose a lowrank decomposition module using Canonical-Polyadic (CP) decomposition <ref type="bibr" target="#b11">[9]</ref> to set constraints on the latent representation. For a three-order tensor U ∈ R C ×H ×W , where H × W is the spatial resolution and C is the channel number. It can be decomposed into a linear combination of N rank-1 tensors. The mathematical formulation of CP decomposition can be expressed as</p><formula xml:id="formula_2">U = r i=1 λ i a ci ⊗a hi ⊗a wi . Where ⊗ denote Kronecker Product, a ci ∈ R C ×1×1 , a hi ∈ R C ×1×1 , a wi ∈ R C ×1×1 ,</formula><p>r is the tensor rank and λ i is a scaling factor. Recent research <ref type="bibr" target="#b5">[3,</ref><ref type="bibr" target="#b34">32]</ref> has proposed new methods based on DNNs to address this problem of representing MHSIs as low-rank tensors. As shown in Fig. <ref type="figure" target="#fig_1">2</ref>, rank-1 generators are used to create rank-1 tensors in different directions, which are then aggregated by Kronecker Product to synthesize a sub-attention map A 1 . The residual part between the input of features and the generated rank-1 tensor is used to generate second rank-1 tensors A 2 . It can obtain r rank-1 tensors by repeating r times. Mathematically, this process can be expressed as:</p><formula xml:id="formula_3">A 1 = G c (U ) ⊗ G h (U ) ⊗ G w (U ), A 2 = G c (U -A 1 ) ⊗ G h (U -A 1 ) ⊗ G w (U -A 1 ), A r = G c (U - r-1 i=1 A i ) ⊗ G h (U - r-1 i=1 A i ) ⊗ G w (U - r-1 i=1 A i ),<label>(2)</label></formula><p>where G c (•), G h (•) and G w (•) are the channel, height and width generators. Finally, we aggregate all rank-1 tensors (from A 1 to A r ) into the attention map along the channel dimension, followed by a linear layer used to reduce the feature dimension to obtain the low-rank feature U low :</p><formula xml:id="formula_4">U low = U Linear(Concate(A 1 , A 2 , ..., A r )),<label>(3)</label></formula><p>where is the element-wise product, and U low ∈ R C ×H ×W . We employ a straightforward non-parametric ensemble approach for grouping spectral agents. This approach involves multiple agents combining their features by averaging the vote. The encoders in the spatial stream produce 2D feature maps with G spectral agents, defined as F i ∈ R G×Ci×H/2 i ×W/2 i for the ith encoder, where G, C i , H/2 i , and W/2 i represent the spectral, channel, and two spatial dimensions, respectively. The ensemble is computed by</p><formula xml:id="formula_5">F out i = Mean(F 1 i , F 2 i , ..., F G i ), where F G i ∈ R Ci×H/2 i ×W/2 i</formula><p>represents the 2D feature map of the Gth agent. The ensemble operation aggregates spectral agents to produce a 2D feature map Table <ref type="table">1</ref>. Ablation study (in "mean (std)") on MDC dataset using RegNetX40 <ref type="bibr" target="#b28">[26]</ref> as the backbone. SA denote the spectral agent. L1 to L4 represent the locations where output spectral features from the spectral flow module are inserted into the spatial flow. Tr and Conv mean we replace the SMD module in the spectral stream with self-attention and convolutional blocks. Best results are highlighted. with enhanced information interactions learned from the multi-spectral agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SA Spectral</head><p>The feature maps obtained from the ensemble can be decoded using lightweight 2D decoders to generate segmentation masks.</p><p>3 Experimental Results</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Setup</head><p>We conducted experiments on the public Multi-Dimensional Choledoch (MDC) Dataset <ref type="bibr" target="#b33">[31]</ref> with 538 scenes and Hyperspectral Gastric Carcinoma (HGC) Dataset <ref type="bibr" target="#b35">[33]</ref> (data provided by the author) with 414 scenes, both with highquality labels for binary MHSI segmentation tasks. These MHSIs are collected by hyperspectral system with an objective lens of 20x, and wavelengths from 550 nm to 1000 nm for MDC and 450 nm to 750 nm for HGC, resulting in 60 and 40 spectral bands for each scene. The size of a single band image in MDC and HGC are both resized to 256 × 320. Following <ref type="bibr" target="#b25">[23,</ref><ref type="bibr" target="#b29">27]</ref>, we partition the datasets into training, validation, and test sets using a patient-centric hard split approach with a ratio of 3:1:1. Specifically, each patient's data is allocated entirely to one of the three sets, ensuring that the same patient's data do not appear in multiple sets.</p><p>We use data augmentation techniques such as rotation and flipping, and train with an Adam optimizer using a combination of dice loss and cross-entropy loss for 8 batch size and 100 epochs. The segmentation performance is evaluated using Dice-Sørensen coefficient (DSC), Intersection of Union (IoU), and Hausdorff Distance (HD) metrics, and Throughput (images/s) is reported for comparison. Pytorch framework and four NVIDIA GeForce RTX 3090 are used for implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation of the Proposed Dual-Stream Strategy</head><p>Ablation Study. Our dual-stream strategy is plug-and-play. We first conduct an ablation study to show the effectiveness of each component. We use a dualstream strategy with RegNetX40 and U-Net architecture. As shown in Table <ref type="table">1</ref>, Our ablation study shows that spectral agent strategy improves segmentation performance by more than 2.5% (63.11 vs. 66.05). If we utilize spectral information from the spectral stream to assist in the spatial stream, we find that inserting spectral information at L2 and L4 yields a significant improvement of 3.7% (69.73 vs. 66.05), while inserting at L4 alone also results in a significant increase of 1.9% in DSC (67.95 vs. 66.05). A slight improvement is observed when inserting at L2, possibly due to the coarse features of shallow spectral information. Inserting spectral information at all spatial layers (i.e., L1 to L4) and only at L2 and L4 produce similar results, indicating that spectral features do not possess complex multilevel characteristics relative to spatial features. Therefore, we adopt a simple and efficient two-layer spectral flow design. Replacing the spectral stream with transformer layers results in a 0.96% (70.88 vs. 69.89) lower DSC, possibly because transformers are difficult to optimize on small datasets. Our proposed LD module is crucial, resulting in a 1.12% performance drop in terms of DSC without it.</p><p>It is known that high feature redundancy limits the generalization of neural networks <ref type="bibr" target="#b31">[29]</ref>. Here we show our low-rank representation effectively reduces the redundancy of features. Our quantitative and qualitative analysis demonstrated that the proposed MDC and LD modules effectively reduces the redundancy of output features. Following <ref type="bibr" target="#b10">[8]</ref>, we define the dominant features for the feature embedding of i-th MHSI h i ∈ R C d as L i = j : h ij &gt; μ + σ, where μ is mean of h i and σ is stand deviation of h i . As shown in the left part of Fig. <ref type="figure" target="#fig_2">3</ref>, our designed modules effectively reduce the number of dominant features and maintain sparsity in the entire spatiospectral feature space. Inspired by <ref type="bibr" target="#b26">[24]</ref>, we evaluate the degree of feature redundancy by computing the Pearson correlation coefficient between different feature channels. As shown in the right part of Fig. <ref type="figure" target="#fig_2">3</ref>, the  Comparisons with State-of-the-Art MHSI Segmentation Methods. Table <ref type="table" target="#tab_2">3</ref> shows comparisons on MDC and HGC datasets. We use a lightweight and efficient ResNet34 as the backbone of our dual-stream method. Experimental results show that 2D methods are generally faster than 3D methods in inference speed, but 3D methods have an advantage in segmentation performance (DSC &amp; HD). However, our approach outperforms other methods in both inference speed and segmentation accuracy. It is also plug-and-play, with the potential to achieve better segmentation performance by selecting more powerful backbones. The complete table (including IoU and variance) and qualitative results are shown in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we present to factor space and spectrum for accurate and fast medical hyperspectral image segmentation. Our dual-stream strategy, leveraging low-rank prior of MHSIs, is computationally efficient and plug-and-play, which can be easily plugged into any 2D architecture. We evaluate our approach on two MHSI datasets. Experiments show significant performance improvements on different evaluation metrics, e.g., with our proposed strategy, we can obtain over 7.7% improvement in DSC compared with its 2D counterpart. After plugging our strategy into ResNet-34 backbone, we can achieve state-of-the-art MHSI segmentation accuracy with 3-13 times faster in terms of inference speed than existing 3D networks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. (a): An example of MHSI. (b): Illustration of two types of correlation in MHSI. (c)-(f): HSI classification and segmentation backbones. 2D decoder can be changed into classification head for classification tasks.</figDesc><graphic coords="2,55,98,55,25,340,30,100,36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig.2. The proposed dual-stream architecture. An MHSI goes through a spectral stream with the proposed spectral encoder block which consists of three key modules, i.e, DwConv, Spectral Matrix Decomposition (SMD) and Feed Forward Network (FFN), and it goes through a spatial stream after dividing into G spectral agents. Low-rank Decomposition (LD) is designed to characterize the low-rank prior.</figDesc><graphic coords="4,55,98,54,53,340,30,151,18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Feature redundancy of three methods on MDC dataset. Left figures plot each feature embedding in ascending order of the number of times they are dominant in the population (y-axis) and feature dimension (x-axis) on the statistical results of the test set. Right table shows the influence of SMD and LD modules in reducing redundancy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Performance comparison in "mean (std)" in MDC and HCG dataset. The best results of each comparison are highlighted.</figDesc><table><row><cell>Backbone</cell><cell cols="2">Method MDC</cell><cell></cell><cell>HGC</cell><cell></cell></row><row><cell></cell><cell></cell><cell>DSC ↑</cell><cell>HD ↓</cell><cell>DSC ↑</cell><cell>HD ↓</cell></row><row><cell>ResNet50</cell><cell cols="2">U-Net 72.10 (14.17)</cell><cell>82.62 (29.70)</cell><cell>81.72 (15.79)</cell><cell>77.02 (44.22)</cell></row><row><cell>+Ours</cell><cell cols="5">U-Net 74.12 (13.76) 78.32 (29.80) 85.08 (13.40) 69.78 (43.41)</cell></row><row><cell>Convnext</cell><cell cols="2">U-Net 71.29 (13.68)</cell><cell>84.28 (30.50)</cell><cell>76.21 (15.15)</cell><cell>87.18 (43.85)</cell></row><row><cell>+Ours</cell><cell cols="5">U-Net 72.82 (15.39) 82.12 (30.97) 77.51 (15.59) 79.73 (45.40)</cell></row><row><cell cols="3">Swin-Transformer U-Net 70.61 (14.42)</cell><cell>85.77 (31.76)</cell><cell>73.89 (18.05)</cell><cell>70.99 (36.10)</cell></row><row><cell>+Ours</cell><cell cols="5">U-Net 72.10 (13.60) 82.94 (30.67) 78.07 (15.76) 63.35 (35.49)</cell></row><row><cell>Efficinet-b2</cell><cell cols="2">U-Net 62.54 (19.28)</cell><cell>87.34 (32.72)</cell><cell>70.60 (17.41)</cell><cell>94.28 (46.95)</cell></row><row><cell>+Ours</cell><cell cols="5">U-Net 68.72 (15.16) 84.91 (33.62) 77.44 (14.40) 81.24 (40.36)</cell></row><row><cell>RegNetX40</cell><cell cols="2">U-Net 63.11 (19.13)</cell><cell>92.04 (34.14)</cell><cell>74.32 (18.39)</cell><cell>88.54 (45.34)</cell></row><row><cell>+Ours</cell><cell cols="5">U-Net 70.88 (15.05) 82.72 (31.77) 79.86 (15.18) 80.35 (43.16)</cell></row><row><cell>ResNet50</cell><cell>FPN</cell><cell>71.23 (16.01)</cell><cell>83.17 (36.84)</cell><cell>79.98 (15.30)</cell><cell>68.52 (43.32)</cell></row><row><cell>+Ours</cell><cell>FPN</cell><cell cols="4">73.01 (13.84) 78.37 (30.26) 81.88 (14.75) 68.60 (45.63)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Performance comparison with SOTA methods with Throughput(images/s) on MDC dataset and HGC dataset. The best results are highlighted. HD ↓ Throughput ↑ DSC ↑ HD ↓ Throughput ↑</figDesc><table><row><cell>Method</cell><cell>MDC</cell><cell>HGC</cell></row><row><cell></cell><cell>DSC ↑</cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This work was supported by the <rs type="funder">National Natural Science Foundation of China</rs> (Grant No. <rs type="grantNumber">62101191</rs>), <rs type="funder">Shanghai Natural Science Foundation</rs> (Grant No. <rs type="grantNumber">21ZR1420800</rs>), and the <rs type="funder">Science and Technology Commission of Shanghai Municipality</rs> (Grant No. <rs type="grantNumber">22DZ2229004</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_M57bfqT">
					<idno type="grant-number">62101191</idno>
				</org>
				<org type="funding" xml:id="_XgPvTEy">
					<idno type="grant-number">21ZR1420800</idno>
				</org>
				<org type="funding" xml:id="_YNp6fRh">
					<idno type="grant-number">22DZ2229004</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43901-8_15.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>Ours</surname></persName>
		</author>
		<idno>75.44 77.70 13.84 85.80 64.04 14.82</idno>
		<imprint/>
	</monogr>
	<note>Resnet34</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">SMD and LD modules can reduce feature redundancy and lead to an increase in segmentation performance</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Dual-Stream Strategy on Different Backbones. To show the effectiveness of our dual-stream strategy in improving MHSI segmentation performance in various architectures, we plug it into different segmentation methods</title>
	</analytic>
	<monogr>
		<title level="j">References</title>
		<editor>
			<persName><forename type="first">I</forename><forename type="middle">E</forename></persName>
		</editor>
		<editor>
			<persName><forename type="first">U-Net</forename></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">13</biblScope>
		</imprint>
	</monogr>
	<note>FPN</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Spectral-spatial recurrent-convolutional networks for in-vivo hyperspectral tumor type classification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bengs</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59716-0_66</idno>
		<idno>978-3-030-59716-0_66</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12263</biblScope>
			<biblScope unit="page" from="690" to="699" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Spectral-spatial feature fusion via dual-stream deep architecture for hyperspectral image classification</title>
		<author>
			<persName><forename type="first">R</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Infrared Phys. Technol</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page">103935</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Tensor low-rank reconstruction for semantic segmentation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-58520-4_4</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-58520-4_4" />
	</analytic>
	<monogr>
		<title level="m">ECCV 2020</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Bischof</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J.-M</forename><surname>Frahm</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12362</biblScope>
			<biblScope unit="page" from="52" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Is attention better than matrix decomposition?</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">3D U-Net: learning dense volumetric segmentation from sparse annotation</title>
		<author>
			<persName><forename type="first">Ö</forename><surname>Çiçek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abdulkadir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Lienkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-46723-8_49</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-46723-8_49" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2016</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Ourselin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Joskowicz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Sabuncu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Unal</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Wells</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">9901</biblScope>
			<biblScope unit="page" from="424" to="432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">nnU-Net: self-adapting framework for u-net-based medical image segmentation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Isensee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Towards better understanding of self-supervised representations</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Kalibhat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Firooz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sanjabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Feizi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Spurious Correlations, Invariance and Stability</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Tensor decompositions and applications</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Kolda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Bader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Rev</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="455" to="500" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning the parts of objects by non-negative matrix factorization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Seung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">401</biblScope>
			<biblScope unit="issue">6755</biblScope>
			<biblScope unit="page" from="788" to="791" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Low-rank and sparse decomposition with mixture of gaussian for hyperspectral anomaly detection</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4363" to="4372" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Cell classification using convolutional neural networks in medical hyperspectral imagery</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Image, Vision and Computing</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Feature pyramid networks for object detection</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<title level="m">Swin transformer: hierarchical vision transformer using shifted windows. arXiv, Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A convnet for the 2020s</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Feichtenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR52688.2022.01167</idno>
		<ptr target="https://doi.org/10.1109/CVPR52688.2022.01167" />
	</analytic>
	<monogr>
		<title level="m">2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="11966" to="11976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Medical hyperspectral imaging: a review</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomed. Opt</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">10901</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">U-Net: convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-24574-4_28</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-24574-4_28" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2015</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hornegger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">9351</biblScope>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">EfficientNet: rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Self-supervised pre-training of swin transformers for 3D medical image analysis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="20730" to="20740" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Tongue tumor detection in hyperspectral images using deep learning semantic segmentation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Trajanovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Weijtmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G B</forename><surname>De Koning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Ruers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1330" to="1340" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">PCA-U-Net based breast cancer nest segmentation from microarray hyperspectral images</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fundam. Res</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="631" to="640" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Identification of melanoma from hyperspectral pathology image using 3D convolutional networks</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="218" to="227" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Revisiting the transferability of supervised pretraining: an MLP perspective</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR52688.2022.00897</idno>
		<ptr target="https://doi.org/10.1109/CVPR52688.2022.00897" />
	</analytic>
	<monogr>
		<title level="m">2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="9173" to="9183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Medical hyperspectral image classification based on end-to-end fusion deep neural network</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Instrum. Measur</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="4481" to="4492" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">S 3 r: self-supervised spectral regression for hyperspectral histopathology image classification</title>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16434-7_5</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16434-7_5" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13432</biblScope>
			<biblScope unit="page" from="46" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<title level="m">Spectr: spectral transformer for hyperspectral pathology image segmentation. arXiv, Image and Video Processing</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Barlow twins: self-supervised learning via redundancy reduction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zbontar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Deny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Spectral-spatial classification of hyperspectral imagery using a dual-channel convolutional neural network</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sens. Lett</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="438" to="447" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A multidimensional choledoch database and benchmarks for cholangiocarcinoma diagnosis</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="149414" to="149421" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning tensor low-rank prior for hyperspectral image reconstruction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="12006" to="12015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A hyperspectral dataset of precancerous lesions in gastric cancer and benchmarks for pathological diagnosis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biophotonics e</title>
		<imprint>
			<biblScope unit="page">202200163</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
