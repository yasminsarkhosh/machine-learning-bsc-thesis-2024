<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer</title>
				<funder ref="#_MgcZ9ds #_WS4ESwy">
					<orgName type="full">NSFC</orgName>
				</funder>
				<funder ref="#_MQ9CtUt">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder>
					<orgName type="full">Alibaba Group through Alibaba Research Intern Program</orgName>
				</funder>
				<funder ref="#_U72Asya">
					<orgName type="full">Clinical Medicine Plus X-Young Scholars Project of Peking University</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hexin</forename><surname>Dong</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">DAMO Academy</orgName>
								<orgName type="institution" key="instit2">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">Hupan Lab</orgName>
								<address>
									<postCode>310023</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiawen</forename><surname>Yao</surname></persName>
							<email>yaojiawen.yjw@alibaba-inc.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">DAMO Academy</orgName>
								<orgName type="institution" key="instit2">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">Hupan Lab</orgName>
								<address>
									<postCode>310023</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuxing</forename><surname>Tang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">DAMO Academy</orgName>
								<orgName type="institution" key="instit2">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mingze</forename><surname>Yuan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">DAMO Academy</orgName>
								<orgName type="institution" key="instit2">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">Hupan Lab</orgName>
								<address>
									<postCode>310023</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yingda</forename><surname>Xia</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">DAMO Academy</orgName>
								<orgName type="institution" key="instit2">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jian</forename><surname>Zhou</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Sun Yat-sen University Cancer Center</orgName>
								<address>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution" key="instit1">South China Hospital</orgName>
								<orgName type="institution" key="instit2">Shenzhen University</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hong</forename><surname>Lu</surname></persName>
							<affiliation key="aff5">
								<orgName type="institution">Tianjin Medical University Cancer Institute and Hospital</orgName>
								<address>
									<settlement>Tianjin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jingren</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">DAMO Academy</orgName>
								<orgName type="institution" key="instit2">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">Hupan Lab</orgName>
								<address>
									<postCode>310023</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bin</forename><surname>Dong</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff6">
								<orgName type="institution">Peking University Changsha Institute for Computing and Digital Economy</orgName>
								<address>
									<settlement>Changsha</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Le</forename><surname>Lu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">DAMO Academy</orgName>
								<orgName type="institution" key="instit2">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zaiyi</forename><surname>Liu</surname></persName>
							<affiliation key="aff7">
								<orgName type="institution">Guangdong Provincial People&apos;s Hospital</orgName>
								<address>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Li</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yu</forename><surname>Shi</surname></persName>
							<affiliation key="aff8">
								<orgName type="institution">Shengjing Hospital</orgName>
								<address>
									<settlement>Shenyang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ling</forename><surname>Zhang</surname></persName>
							<email>zhanglipku@pku.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">DAMO Academy</orgName>
								<orgName type="institution" key="instit2">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="241" to="251"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">83C36D3350A3AC9A36779CDE8B6E406D</idno>
					<idno type="DOI">10.1007/978-3-031-43904-9_24</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-05-01T10:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Pancreatic ductal adenocarcinoma (PDAC)</term>
					<term>Survival prediction</term>
					<term>Texture-aware Transformer</term>
					<term>Cross-attention</term>
					<term>Nerual distance</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Pancreatic ductal adenocarcinoma (PDAC) is a highly lethal cancer in which the tumor-vascular involvement greatly affects the resectability and, thus, overall survival of patients. However, current prognostic prediction methods fail to explicitly and accurately investigate relationships between the tumor and nearby important vessels. This paper proposes a novel learnable neural distance that describes the precise relationship between the tumor and vessels in CT images of different patients, adopting it as a major feature for prognosis prediction. Besides, different from existing models that used CNNs or LSTMs to exploit tumor enhancement patterns on dynamic contrast-enhanced CT imaging, we improved the extraction of dynamic tumor-related texture features in multi-phase contrast-enhanced CT by fusing local and global features using CNN and transformer modules, further enhancing the features extracted across multi-phase CT images. We extensively evaluated and compared the proposed method with existing methods in the multicenter (n = 4) dataset with 1,070 patients with PDAC, and statistical H. Dong-Work was done during an internship at Alibaba DAMO Academy.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Pancreatic ductal adenocarcinoma (PDAC) is one of the deadliest forms of human cancer, with a 5-year survival rate of only 9% <ref type="bibr" target="#b15">[16]</ref>. Neoadjuvant chemotherapy can increase the likelihood of achieving a margin-negative resection and avoid unnecessary surgery in patients with aggressive tumor types <ref type="bibr" target="#b22">[23]</ref>. Providing accurate and objective preoperative biomarkers is crucial for triaging patients who are most likely to benefit from neoadjuvant chemotherapy. However, current clinical markers such as larger tumor size and high carbohydrate antigen (CA) 19-9 level may not be sufficient to accurately tailor neoadjuvant treatment for patients <ref type="bibr" target="#b18">[19]</ref>. Therefore, multi-phase contrast-enhanced CT has a great potential to enable personalized prognostic prediction for PDAC, leveraging its ability to provide a wealth of texture information that can aid in the development of accurate and effective prognostic models <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b9">10]</ref>.</p><p>Previous studies have utilized image texture analysis with hand-crafted features to predict the survival of patients with PDACs <ref type="bibr" target="#b0">[1]</ref>, but the representational Fig. <ref type="figure">1</ref>. Two examples of spatial information between vessel (orange region) and tumor (green region). The minimum distance, which refers to the closest distance between the Superior Mesenteric Artery (SMA) and the PDAC tumor region, is almost identical in these two cases. We define the surface-to-surface distance based on point-to-surface distance (weighted-average of red lines from ♦ to ) instead of point-to-point distance (blue lines) to better capture the relationship between the tumor and the perivascular tissue.</p><p>Here ♦ and are points sampled from subset Vc and Pc defined in Eq. power of these features may be limited. In recent years, deep learning-based methods have shown promising results in prognosis models <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b11">12]</ref>. However, PDACs differ significantly from the tumors in these studies. A clinical investigation based on contrast-enhanced CT has revealed a dynamic correlation between the internal stromal fractions of PDACs and their surrounding vasculature <ref type="bibr" target="#b13">[14]</ref>. Therefore, focusing solely on the texture information of the tumor itself may not be effective for the prognostic prediction of PDAC. It is necessary to incorporate tumor-vascular involvement into the feature extraction process of the prognostic model. Although some studies have investigated tumor-vascular relationships <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>, these methods may not be sufficiently capable of capturing the complex dynamics between the tumor and its environment.</p><p>We propose a novel approach for measuring the relative position relationship between the tumor and the vessel by explicitly using the distance between them. Typically, Chamfer distance <ref type="bibr" target="#b6">[7]</ref>, Hausdorff distance <ref type="bibr" target="#b7">[8]</ref>, or other surfaceawareness metrics are used. However, as shown in Fig. <ref type="figure">1</ref>, these point-to-point distances cannot differentiate the degree of tumor-vascular invasion <ref type="bibr" target="#b17">[18]</ref>. To address this limitation, we propose a learnable neural distance that considers all relevant points on different surfaces and uses an attention mechanism to compute a combined distance that is more suitable for determining the degree of invasion. Furthermore, to capture the tumor enhancement patterns across multi-phase CT images, we are the first to combine convolutional neural networks (CNN) and transformer <ref type="bibr" target="#b3">[4]</ref> modules for extracting the dynamic texture patterns of PDAC and its surroundings. This approach takes advantage of the visual transformer's adeptness in capturing long-distance information compared to the CNN-onlybased framework in the original approach. By incorporating texture information between PDAC, pancreas, and peripancreatic vessels, as well as the local tumor information captured by CNN, we aim to improve the accuracy of our prognostic prediction model.</p><p>In this study, we make the following contributions: <ref type="bibr" target="#b0">(1)</ref> We propose a novel approach for aiding survival prediction in PDAC by introducing a learnable neural distance that explicitly evaluates the degree of vascular invasion between the tumor and its surrounding vessels. <ref type="bibr" target="#b1">(2)</ref> We introduce a texture-aware transformer block to enhance the feature extraction approach, combining local and global information for comprehensive texture information. We validate that the cross-attention is utilized to capture cross-modality information and integrate it with in-modality information, resulting in a more accurate and robust prognostic prediction model for PDAC. (3) Through extensive evaluation and statistical analysis, we demonstrate the effectiveness of our proposed method. The signature built from our model remains statistically significant in multivariable analysis after adjusting for established clinical predictors. Our proposed model has the potential to be used in combination with clinical factors for risk stratification and treatment decisions for patients with PDAC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>As shown in Fig. <ref type="figure" target="#fig_1">2</ref>, the proposed method consists of two main components. The first component combines the CNN and transformer to enhance the extraction of tumor dynamic texture features. The second component proposes a neural distance metric between PDAC and important vessels to assess their involvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Texture-Aware Vision Transformer: Combination of CNN and Transformer</head><p>Recently, self-attention models, specifically vision transformers (ViTs <ref type="bibr" target="#b3">[4]</ref>), have emerged as an alternative to CNNs in survival prediction <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b24">25]</ref>. Our proposed texture-aware transformer, inspired by MobileViT <ref type="bibr" target="#b12">[13]</ref>, aims to combine both local information (such as PDAC texture) and global information (such as the relationship between PDAC and the pancreas). This approach is different from previous methods that rely solely on either CNN-based or transformer-based backbones, focusing only on local or global information, respectively. The texture-aware transformer (Fig. <ref type="figure" target="#fig_1">2</ref>) comprises three blocks, each consisting of a texture-aware CNN block and a texture-aware self-attention block. These blocks encode the input feature of an image F i ∈ R H×W ×D×C to the hidden feature F c ∈ R H×W ×D×C l using a 3 × 3 × 3 convolutional layer, followed by a We first select related points set from the closest sub-surface on PDAC and vessels respectively. Then we use a cross-attention block to obtain the neural distance. Finally, we concatenate features from three branches to obtain the survival outcome OOS.</p><p>1 × 1 × 1 convolutional layer. The 3 × 3 × 3 convolution captures local spatial information, while the 1 × 1 × 1 convolution maps the input tensor to a higherdimensional space (i.e., C l &gt; C). The texture-aware CNN block downsamples the input, and the texture-aware self-attention block captures long-range nonlocal dependencies through a patch-wise self-attention mechanism.</p><p>In the texture-aware self-attention block, the input feature F c is divided into N non-overlapping 3D patches F u ∈ R V ×N ×Cu , where V = hwd and N = HW D/V is the number of patches, and h, w, d are the height, width, and depth of a patch, respectively. For each voxel position within a patch, we apply a multi-head self-attention block and a feed-forward block following <ref type="bibr" target="#b19">[20]</ref> to obtain the output feature F o . In this study, preoperative multi-phase CE-CT pancreatic imaging includes the non-contrast phase, the pancreatic phase and venous phase. Therefore, we obtain three outputs from the transformer block with the input of these phases, denoted as</p><formula xml:id="formula_0">F 1 o , F 2 o , F 3 o ∈ R D×C , resulting in the concatenated output F o ∈ R D×3C .</formula><p>Instead of directly fusing the outputs as in previous work, we employ a 3-way cross-attention block to extract cross-modality information from these phases. The cross-attention is performed on the concatenated self-attention matrix with an extra mask M ∈ {0, -∞} 3C×3C , defined as:</p><formula xml:id="formula_1">F cross = Softmax(QK T + M)V, M(i, j) = -∞ kC &lt; i, j ≤ (k + 1)C, k = 0, 1<label>, 2, 0 otherwise, (1)</label></formula><p>Here, Q, K, V are the query, key, and value matrices, respectively, obtained by linearly projecting the input F T o ∈ R 3C×D . The cross-modality output F cross and in-modality output F T o are then concatenated and passed through an average pooling layer to obtain the final output feature of the texture branch, denoted as F t ∈ R Ct .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Neural Distance: Positional and Structural Information</head><p>Between PDAC and Vessels</p><p>The vascular involvement in patients with PDAC affects the resectability and treatment planning <ref type="bibr" target="#b4">[5]</ref>. In this study, we investigate four important vessels: portal vein and splenic vein (PVSV), superior mesenteric artery (SMA), superior mesenteric vein (SMV), and truncus coeliacus (TC). We used a semi-supervised nnUnet model to segment PDAC and the surrounding vessels, following recent work <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b20">21]</ref>. We define a general distance between the surface boundaries of PDAC (P) and the aforementioned four types of vessels (V) as D(V, P), which can be derived as follows:</p><formula xml:id="formula_2">D(V, P) = d ss (V, P) + d ss (P, V) = 1 V V d ps (v, P)dv + 1 P P d ps (p, V)dp,<label>(2)</label></formula><p>where v ∈ V and p ∈ P are points on the surfaces of blood vessels and PDAC, respectively. The point-to-surface distance d ps (v, P) is the distance from a point v on V to P, defined as d ps (v, P) = min p∈P v -p 2 2 , and vice versa. To numerically calculate the integrals in the previous equation, we uniformly sample from the surfaces V and P to obtain the sets V and P consisting of N v points and N p points, respectively. The distance is then calculated between the two sets using the following equation:</p><formula xml:id="formula_3">D( V, P) = 1 N v v∈ V d ps (v, P) + 1 N p p∈ P d ps (p, V).<label>(3)</label></formula><p>However, the above distance treats all points equally and may not be flexible enough to adapt to individualized prognostic predictions. Therefore, we improve the above equation in two ways. Firstly, we focus on the sub-sets Vc and Pc of V and P, respectively, which only contain the K closest points to the opposite surfaces P and V, respectively. The sub-sets are defined as:</p><formula xml:id="formula_4">Vc = argmin {v1,v2,••• ,vK }⊂ V K i=1 d ps (v i , P), Pc = argmin {p1,p2,••• ,pK }⊂ P K i=1 d ps (p i , V).<label>(4)</label></formula><p>Secondly, we regard the entire sets Vc and Pc as sequences and calculate the distance using a 2-way cross-attention block (similar to Eq. 1) to build a neural distance based on the 3D spatial coordinates of each point:</p><formula xml:id="formula_5">D θ ( V, P) = CrossAttention( Vc , Pc ), Vc , Pc ∈ R K×3 . (<label>5</label></formula><formula xml:id="formula_6">)</formula><p>Neural distance allows for the flexible assignment of weights to different points and is able to find positional information that is more suitable for PDAC prognosis prediction. In addition to neural distance, we use the 3D-CNN model introduced in <ref type="bibr" target="#b21">[22]</ref> to extract the structural relationship between PDAC and the vessels. Specifically, we concatenate each PDAC-vessel pair X v s ∈ R 2×H×W ×D , where v ∈{PVSV, SMV, SMA, TC} and obtain the structure feature F s ∈ R Cs .</p><p>Finally, we concatenate the features extracted from the two components and apply a fully-connected layer to predict the survival outcome, denoted as O OS , which is a value between 0 and 1. To optimize the proposed model, we use the negative log partial likelihood as the survival loss <ref type="bibr" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>Dataset. In this study, we used data from Shengjing Hospital to train our method with 892 patients, and data from three other centers, including Guangdong Provincial People's Hospital, Tianjin Medical University and Sun Yatsen University Cancer Center for independent testing with 178 patients. The contrast-enhanced CT protocol included non-contrast, pancreatic, and portal venous phases. PDAC masks for 340 patients were manually labeled by a radiologist from Shengjing Hospital with 18 years of experience in pancreatic cancer, while the rest were predicted using self-learning models <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b23">24]</ref> and checked by the same annotator. Other vessel masks were generated using the same semisupervised segmentation models. C-index was used as our primary evaluation metric for survival prediction. We also reported the survival AUC, which estimates the cumulative area under the ROC curve for the first 36 months.</p><p>Implementation Details: We used nested 5-fold cross-validation and augmented the training data by rotating volumetric tumors in the axial direction and randomly selecting cropped regions with random shifts. We also set the output feature dimensions to C t = 64 for the texture-aware transformer, C s = 64 for the structure extraction and K = 32 for the neural distance. The batch size was 16 and the maximum iteration was set to 1000 epochs, and we selected the model with the best performance on the validation set during training for testing. We implemented our experiments using PyTorch 1.11 and trained the models on a single NVIDIA 32G-V100 GPU.</p><p>Ablation Study. We first evaluated the performance of our proposed textureaware transformer (TAT) by comparing it with the ResNet18 CNN backbone and ViT transformer backbone, as shown in Table <ref type="table" target="#tab_0">1</ref>. Our model leverages the strengths of both local and global information in the pancreas and achieved the best result. Next, we compared different methods for multi-phase stages, including LSTM, early fusion (Fusion), and cross-attention (Cross) in our method. Cross-attention is more effective and lightweight than LSTM. Moreover, we separated texture features into in-phase features and cross-phase features, which is more reasonable than early fusion.</p><p>Secondly, we evaluated each component in our proposed method, as shown in Fig. <ref type="figure" target="#fig_1">2</ref>, and presented the results in Table <ref type="table" target="#tab_0">1</ref>. Combining the texture-aware transformer and regular structure information improved the results from 0.630 to 0.648, as tumor invasion strongly affects the survival of PDAC patients. We also employed a simple 4-variable regression model that used only the Chamfer distance of the tumor and the four vessels for prognostic prediction. The resulting C-index of 0.611 confirmed the correlation of the distance with the survival, which is consistent with clinical findings <ref type="bibr" target="#b17">[18]</ref>. Explicitly adding the distance measure further improved the results. Our proposed neural distance metric outperformed traditional surface distance metrics like Chamfer distance, indicating its suitability for distinguishing the severity of PDAC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparisons.</head><p>To further evaluate the performance of our proposed model, we compared it with recent deep prediction methods <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b20">21]</ref> and report the results in Table <ref type="table" target="#tab_1">2</ref>. We modified baseline deep learning models <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b16">17]</ref> and used their network architectures to take a single pancreatic phase or all three phases as inputs. DeepCT-PDAC <ref type="bibr" target="#b20">[21]</ref> is the most recent method that considers both tumor-related and tumor-vascular relationships using 3D CNNs. Our proposed method, which uses the transformer and structure-aware blocks to capture tumor enhancement patterns and tumor-vascular involvement, demonstrated its effectiveness with better performance in both nested 5-fold cross-validation and the multi-center independent test set.</p><p>In Table <ref type="table" target="#tab_2">3</ref>, we used univariate and multivariate Cox proportional-hazards models to evaluate our signature and other clinicopathologic factors in the independent test set. The proposed risk stratification was a significant prognostic factor, along with other factors like pathological TNM stages. After selecting significant variables (p &lt; 0.05) in univariate analysis, our proposed staging remained strong in multivariable analysis after adjusting for important prognostic markers like pT and resection margins. Notably, our proposed marker remained the strongest among all pre-operative markers, such as tumor size and CA 19-9.</p><p>Neoadjuvant Therapy Selection. To demonstrate the added value of our signature as a tool to select patients for neoadjuvant treatment before surgery, we plotted Kaplan-Meier survival curves in Fig. <ref type="figure" target="#fig_2">3</ref>. We further stratify patients by our signature after grouping them by tumor size and CA19-9, two clinically used preoperative criteria for selection, and also age. Our signature could significantly stratify patients in all cases and those in the high-risk group had worse outcomes and might be considered as potential neoadjuvant treatment candidates (e.g. 33 high-risk patients with larger tumor size and high CA19-9).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In our paper, we propose a multi-branch transformer-based framework for predicting cancer survival. Our framework includes a texture-aware transformer that captures both local and global information about the PDAC and pancreas. We also introduce a neural distance to calculate a more reasonable distance between PDAC and vessels, which is highly correlated with PDAC survival. We have extensively evaluated and statistically analyzed our proposed method, demonstrating its effectiveness. Furthermore, our model can be combined with established high-risk features to aid in the patient selections who might benefit from neoadjuvant therapy before surgery.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Fig. 1. Two examples of spatial information between vessel (orange region) and tumor (green region). The minimum distance, which refers to the closest distance between the Superior Mesenteric Artery (SMA) and the PDAC tumor region, is almost identical in these two cases. We define the surface-to-surface distance based on point-to-surface distance (weighted-average of red lines from ♦ to ) instead of point-to-point distance (blue lines) to better capture the relationship between the tumor and the perivascular tissue. Here ♦ and are points sampled from subset Vc and Pc defined in Eq. 4. The distances and weights shown in the figure is for illustration purposes only. (Color figure online)</figDesc><graphic coords="2,100,65,383,75,228,40,117,16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. An overview of the proposed method. The texture-aware transformer captures texture information among PDAC, Pancreas and vessels around Pancreas with our proposed texture-aware transformer block and a cross-attention block to fusion cross-modality features. The structure-aware block extracts the structure relationship between PDAC and four related vessels. The neural distance calculates the distances between the PDAC surface and the vessel surface with our proposed neural distance.We first select related points set from the closest sub-surface on PDAC and vessels respectively. Then we use a cross-attention block to obtain the neural distance. Finally, we concatenate features from three branches to obtain the survival outcome OOS.</figDesc><graphic coords="4,49,80,335,15,324,64,153,88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. Kaplan-Meier analyses of overall survival according to the proposed signature in all patients in the independent test set (n = 178) and subgroups defined by preoperative factors. High risk group indicated by the proposed method is the potential patient group that could benefit from neoadjuvant treatment before surgery.</figDesc><graphic coords="9,78,96,213,41,294,28,146,32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Ablation tests with different network backbones including ResNet18 (Res), ViT and texture-aware transformer (TAT) and methods for multi-phases including LSTM, early fusion (Fusion) and cross-attention (Cross).</figDesc><table><row><cell cols="3">Network Backbone Structural Info Distance</cell><cell cols="2">Model Size (M) C-index</cell></row><row><cell>Res-LSTM</cell><cell>-</cell><cell>-</cell><cell>65.06</cell><cell>0.618 ± 0.017</cell></row><row><cell>Res-Cross</cell><cell>-</cell><cell>-</cell><cell>43.54</cell><cell>0.625 ± 0.016</cell></row><row><cell>ViT-Cross</cell><cell>-</cell><cell>-</cell><cell>23.18</cell><cell>0.628 ± 0.018</cell></row><row><cell>TAT-Fusion</cell><cell>-</cell><cell>-</cell><cell>3.64</cell><cell>0.626 ± 0.022</cell></row><row><cell>TAT-Cross</cell><cell>-</cell><cell>-</cell><cell>15.13</cell><cell>0.630 ± 0.019</cell></row><row><cell>TAT-Cross</cell><cell></cell><cell>-</cell><cell>15.90</cell><cell>0.648 ± 0.021</cell></row><row><cell>-</cell><cell>-</cell><cell cols="2">Chamfer distance -</cell><cell>0.611 ± 0.029</cell></row><row><cell>TAT-Cross</cell><cell></cell><cell cols="2">Chamfer distance 15.93</cell><cell>0.652 ± 0.019</cell></row><row><cell>TAT-Cross</cell><cell></cell><cell>Nerual distance</cell><cell>16.28</cell><cell>0.656 ± 0.017</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Results of different methods on nested 5-fold CV and independent set.</figDesc><table><row><cell></cell><cell cols="2">Nested 5-fold CV (n = 892)</cell><cell>Independent test (n = 178)</cell></row><row><cell></cell><cell>C-index</cell><cell>AUC</cell><cell>C-index AUC</cell></row><row><cell>3DCNN-P [12]</cell><cell cols="3">0.630 ± 0.009 0.668 ± 0.019 0.674</cell><cell>0.740</cell></row><row><cell>Early Fusion [17]</cell><cell cols="3">0.635 ± 0.011 0.670 ± 0.024 0.696</cell><cell>0.779</cell></row><row><cell cols="4">DeepCT-PDAC [21] 0.640 ± 0.018 0.680 ± 0.036 0.697</cell><cell>0.773</cell></row><row><cell>Ours</cell><cell cols="3">0.656 ± 0.017 0.695 ± 0.023 0.710</cell><cell>0.792</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Univariate and Multivariate Cox regression analysis. HR: hazard ratio. High vs low risk) 2.42(1.64-3.58) &lt;0.0001 1.85(1.08-3.17</figDesc><table><row><cell>Independent test set (n = 178)</cell><cell cols="2">Univariate Analysis</cell><cell>Multivariate Analysis</cell></row><row><cell></cell><cell>HR (95% CI)</cell><cell cols="2">p-value HR (95% CI)</cell><cell>p-value</cell></row><row><cell>Proposed (</cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement. This work was supported by <rs type="funder">Alibaba Group through Alibaba Research Intern Program</rs>. <rs type="person">Bin Dong</rs> and <rs type="person">Li Zhang</rs> was partly supported by <rs type="funder">NSFC</rs> <rs type="grantNumber">12090022</rs> and <rs type="grantNumber">11831002</rs>, and <rs type="funder">Clinical Medicine Plus X-Young Scholars Project of Peking University</rs> <rs type="grantNumber">PKU2023LCXQ041</rs>. <rs type="person">Yu Shi</rs> was supported by the <rs type="funder">National Natural Science Foundation of China</rs> (No. <rs type="grantNumber">82071885</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_MgcZ9ds">
					<idno type="grant-number">12090022</idno>
				</org>
				<org type="funding" xml:id="_WS4ESwy">
					<idno type="grant-number">11831002</idno>
				</org>
				<org type="funding" xml:id="_U72Asya">
					<idno type="grant-number">PKU2023LCXQ041</idno>
				</org>
				<org type="funding" xml:id="_MQ9CtUt">
					<idno type="grant-number">82071885</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43904-9 24.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Survival prediction in pancreatic ductal adenocarcinoma by quantitative computed tomography image analysis</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Attiyeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Surg. Oncol</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1034" to="1042" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Artificial intelligence to predict lymph node metastasis at CT in pancreatic ductal adenocarcinoma</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">306</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="160" to="169" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deep learning for fully automated prediction of overall survival in patients with oropharyngeal cancer using FDG-PET imaging</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clin. Cancer Res</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="3948" to="3959" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An image is worth 16x16 words: transformers for image recognition at scale</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Cancer of the pancreas: ESMO clinical practice guidelines for diagnosis, treatment and follow-up</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ducreux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Oncol</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="56" to="68" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">End-to-end evidentialefficient net for radiomics analysis of brain MRI to predict oncogene expression and overall survival</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16437-8_27</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16437-827" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13433</biblScope>
			<biblScope unit="page" from="282" to="291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A point set generation network for 3D object reconstruction from a single image</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Haoqiang Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Comparing images using the hausdorff distance under translation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Huttenlocher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Rucklidge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Klanderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<meeting>1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deepsurv: personalized treatment recommender system using a cox proportional hazards deep neural network</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Katzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Shaham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cloninger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kluger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Med. Res. Methodol</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">24</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Computed tomography-based biomarker outcomes in a prospective trial of preoperative folfirinox and chemoradiation for borderline resectable pancreatic cancer</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Koay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JCO Precis. Oncol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A noisy nnU-Net student for semisupervised abdominal organ segmentation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Koehler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Isensee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Maier-Hein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-23911-3_12</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-23911-312" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">13816</biblScope>
			<biblScope unit="page" from="128" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An image-based deep learning framework for individualising radiotherapy dose: a retrospective analysis of outcome prediction</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lancet Digit. Health</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="136" to="e147" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Mobilevit: light-weight, general-purpose, and mobilefriendly vision transformer</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rastegari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Isoattenuating pancreatic adenocarcinoma at multi-detector row CT: secondary signs</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Prokesch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Beaulieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bammer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Jeffrey</surname></persName>
		</author>
		<author>
			<persName><surname>Jr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">224</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="764" to="768" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">TMSS: an end-to-end transformer-based multimodal network for segmentation and survival prediction</title>
		<author>
			<persName><forename type="first">N</forename><surname>Saeed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sobirov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Al Majzoub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yaqub</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16449-1_31</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16449-1" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13437</biblScope>
			<biblScope unit="page">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Cancer statistics</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jemal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CA Cancer J. Clin</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="34" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep learning of imaging phenotype and genotype for predicting overall survival time of glioblastoma patients</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2100" to="2109" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Pancreatic adenocarcinoma, version 2.2021, NCCN clinical practice guidelines in oncology</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Tempero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Natl. Compr. Cancer Netw</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="439" to="457" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Importance of normalization of ca19-9 levels following neoadjuvant therapy in patients with localized pancreatic cancer</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tsai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Surg</title>
		<imprint>
			<biblScope unit="volume">271</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="740" to="747" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
			<publisher>Curran Associates, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep learning for fully automated prediction of overall survival in patients undergoing resection for pancreatic cancer: a retrospective multicenter study</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Surg</title>
		<imprint>
			<biblScope unit="volume">278</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="68" to="e79" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deepprognosis: Preoperative prediction of pancreatic cancer survival and surgical margin via comprehensive understanding of dynamic contrastenhanced CT imaging and tumor-vascular contact parsing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page">102150</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Devil is in the queries: advancing mask transformers for realworld medical image segmentation and out-of-distribution localization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yuan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="23879" to="23889" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Robust pancreatic ductal adenocarcinoma segmentation with multi-institutional multi-phase partially-annotated CT scans</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59719-1_48</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-59719-148" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12264</biblScope>
			<biblScope unit="page" from="491" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Multi-transSP: multimodal transformer for survival prediction of nasopharyngeal carcinoma patients</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16449-1_23</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16449-123" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="234" to="243" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
