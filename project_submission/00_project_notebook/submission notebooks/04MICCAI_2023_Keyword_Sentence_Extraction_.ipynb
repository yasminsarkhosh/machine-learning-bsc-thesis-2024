{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective of the Notebook\n",
    "The notebook aims to extract sentences from already preprocessed MICCAI 2023 research papers based on a list of relevant keywords. The sentences are organized by paper titles and focus on extracting text that might contain specific information related to demographics and other significant categories.\n",
    "\n",
    "### Input Data Expected\n",
    "- **CSV File**: The input for this notebook is a CSV file containing preprocessed text from research papers. This data is expected to be structured with columns for paper titles and text content, which were processed in a previous step (as indicated by a linked notebook).\n",
    "\n",
    "### Output Data/Files Generated\n",
    "- **CSV Files**: For each category of interest (like age, gender, ethnicity, dataset info), the notebook will generate CSV files containing extracted sentences or keywords. These files will help in further analysis or machine learning tasks focused on these categories.\n",
    "- **Directories**: The extracted data will be saved into directories specified for cancer-related content, patient-related content, etc., facilitating organized access to this information for further use.\n",
    "\n",
    "### Assumptions or Important Notes\n",
    "- **Preprocessing Required**: It assumes that the data has been preprocessed for extraction, meaning any necessary cleaning, formatting, or preliminary analysis has been completed beforehand.\n",
    "- **Keyword Relevance**: The effectiveness of the extraction process heavily depends on the relevance and comprehensiveness of the keyword list used for extraction. Misclassification or omission of relevant keywords might lead to incomplete or skewed data analysis.\n",
    "- **Text Structure**: The notebook assumes that the text in the input CSV is well-structured and correctly segmented into sentences. Any irregularities in text structuring might affect the accuracy of sentence extraction.\n",
    "- **Error Handling**: There seems to be minimal error handling regarding file reading and writing, which could lead to issues if files are not found or directories do not exist. It's crucial to ensure that the input paths are correct and accessible.\n",
    "- **Scalability**: Depending on the volume of data (number of papers and the length of text in them), the process might be computationally intensive, requiring optimization for handling large datasets efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword-Based Sentence Extraction from Selected MICCAI 2023 Research Articles\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Setup and Imports: Import necessary libraries (e.g., os, pandas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. File and Data Loading: Load data from CSV files.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"\n",
    "    Load the dataset from a CSV file.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. A utility function (wrap_text) to wrap sentences at a given width, making the dataframe more readable.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_text(text, width=80):\n",
    "    \"\"\"\n",
    "    A simple function to wrap text at a given width.\n",
    "    \"\"\"\n",
    "    if pd.isnull(text):\n",
    "        return text\n",
    "    \n",
    "    wrapped_lines = []\n",
    "    for paragraph in text.split('\\n'):\n",
    "        line = ''\n",
    "        for word in paragraph.split():\n",
    "            if len(line) + len(word) + 1 > width:\n",
    "                wrapped_lines.append(line)\n",
    "                line = word\n",
    "            else:\n",
    "                line += (' ' + word if line else word)\n",
    "        wrapped_lines.append(line)\n",
    "    return '\\n'.join(wrapped_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Keyword Extraction: Logic to extract keywords and sentences containing those keywords.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(df, keywords):\n",
    "    \"\"\"\n",
    "    Extract rows from a DataFrame based on matching keywords.\n",
    "    \"\"\"\n",
    "    pattern = r'\\b(' + '|'.join(re.escape(keyword) for keyword in keywords) + r')\\b'\n",
    "    sentences_by_paper = {}\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        sentences = re.findall(pattern, row['text'], flags=re.IGNORECASE | re.DOTALL)\n",
    "        if sentences:\n",
    "            paper_title = row['title']\n",
    "            if paper_title not in sentences_by_paper:\n",
    "                sentences_by_paper[paper_title] = []\n",
    "            sentences_by_paper[paper_title].extend(sentences)\n",
    "\n",
    "    keywords_data = [(title, keyword_sentence) for title, related_group in sentences_by_paper.items() for keyword_sentence in related_group]\n",
    "    return pd.DataFrame(keywords_data, columns=['title', 'keyword'])\n",
    "\n",
    "\n",
    "def extract_keyword_sentences(df, keywords):\n",
    "    \"\"\"\n",
    "    Extract sentences containing specified keywords from DataFrame and organize by paper title.\n",
    "    \"\"\"\n",
    "    keyword_pattern = re.compile(r'\\b(?:' + '|'.join(keywords) + r')\\b', flags=re.IGNORECASE)\n",
    "    sentences_by_paper = {}\n",
    "\n",
    "    for title in df['title'].unique():\n",
    "        text = ' '.join(df[df['title'] == title]['text'])\n",
    "        sentences = re.split(r'(?<=[.?!])\\s+', text)\n",
    "        keyword_sentences_buffer = []\n",
    "\n",
    "        for sentence in sentences:\n",
    "            if keyword_pattern.search(sentence):\n",
    "                keyword_sentences_buffer.append(sentence)\n",
    "\n",
    "        sentences_by_paper[title] = keyword_sentences_buffer if keyword_sentences_buffer else ['none']\n",
    "    \n",
    "    extracted_data = [(title, keyword_sentence) for title, related_group in sentences_by_paper.items() for keyword_sentence in related_group]\n",
    "    extracted_df = pd.DataFrame(extracted_data, columns=['title', 'extracted_keyword_sent'])\n",
    "    extracted_df['extracted_keyword_sent'] = extracted_df['extracted_keyword_sent'].apply(lambda x: wrap_text(x, width=80))\n",
    "\n",
    "    return extracted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Functions for keyword and sentence extraction (extract_keywords, extract_keyword_sentences).\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords_by_category(df, categories):\n",
    "    \"\"\"\n",
    "    Extract keywords from DataFrame based on multiple categories of keywords.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing the text to search through.\n",
    "    - categories: A dictionary with category names as keys and lists of keywords as values.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with category names as keys and DataFrames of extracted keywords as values.\n",
    "    \"\"\"\n",
    "    extracted_data = {}\n",
    "    for category, keywords in categories.items():\n",
    "        extracted_data[category] = extract_keywords(df, keywords)\n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_extracted_data_by_category(data_by_category, output_dir):\n",
    "    \"\"\"\n",
    "    Save each DataFrame in the data_by_category dictionary to a CSV file.\n",
    "    Each category has a list of corresponding keywords\n",
    "    \n",
    "    Parameters:\n",
    "    - data_by_category (dict): A dictionary with category names as keys and DataFrames as values.\n",
    "    - output_dir (str): The directory where the CSV files will be saved.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Iterate through the dictionary\n",
    "    for category, df in data_by_category.items():\n",
    "        # Define the output file path\n",
    "        output_file_path = os.path.join(output_dir, f\"{category}_related_keywords.csv\")\n",
    "        # Save the DataFrame to a CSV file\n",
    "        df.to_csv(output_file_path, index=False)\n",
    "        print(f\"Saved {category} data to {output_file_path}\")\n",
    "\n",
    "\n",
    "# Cancer related papers\n",
    "# keyword counts\n",
    "\n",
    "#output_directory = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/outputs/extracted_data_cancer'\n",
    "#save_extracted_data_by_category(extracted_data_by_category, output_directory)\n",
    "\n",
    "# Cancer patient related papers\n",
    "# keyword counts\n",
    "output_directory = '.../extracted_data_patients'\n",
    "#save_extracted_data_by_category(extracted_data_by_category, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save_sentences_by_category(df, categories, output_dir):\n",
    "    \"\"\"\n",
    "    Extract sentences by keywords for each category and save them to CSV files.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing the text to search through.\n",
    "    - categories: A dictionary with category names as keys and lists of keywords as values.\n",
    "    - output_dir (str): The directory where the CSV files will be saved.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Iterate through the categories and keywords\n",
    "    for category, keywords in categories.items():\n",
    "        # Extract sentences containing the keywords\n",
    "        extracted_df = extract_keyword_sentences(df, keywords)\n",
    "        \n",
    "        # Define the output file path\n",
    "        output_file_path = os.path.join(output_dir, f\"{category}_related_sentences.csv\")\n",
    "        \n",
    "        # Save the DataFrame to a CSV file\n",
    "        extracted_df.to_csv(output_file_path, index=False)\n",
    "        print(f\"Saved {category} sentences to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories and their corresponding keywords\n",
    "categories = {\n",
    "    'age': ['age', 'age', 'young', 'old', 'gender'],\n",
    "    'gender': ['gender', 'sex', 'women', 'woman', 'female', 'male'],\n",
    "    'ethnicity': ['ethnicity', 'ethnicities', 'race', 'white patients', 'black patients'],\n",
    "    'location_info': ['geolocation', 'geographical', 'geographic', 'country', 'countries', \n",
    "                    'city', 'cities', 'hospital', 'hospitals', 'clinic', 'clinics', 'continent',\n",
    "                    'province', 'state', 'region', 'town', 'village', 'area', 'district'],\n",
    "    'dataset_info': ['dataset', 'datasets', 'data set', 'data sets', 'publicly', 'public', 'private', 'open access', 'open-access'],\n",
    "    'bias_info': ['bias', 'biases', 'fairness']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Papers with cancer-related content only\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with cancer-related papers and extract text\n",
    "filename = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/outputs/databases/cancer_related_papers_w_text.csv'\n",
    "df_cancer_related = pd.read_csv(filename)\n",
    "unique_titles_count = len(df_cancer_related['title'].unique())\n",
    "print(f\"Number of unique titles: {unique_titles_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancer-related papers\n",
    "output_directory = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/outputs/extracted_sentences_cancer'\n",
    "extract_and_save_sentences_by_category(df_cancer_related, categories, output_directory)\n",
    "\n",
    "# Cancer related papers\n",
    "output_directory = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/outputs/extracted_data_cancer'\n",
    "save_extracted_data_by_category(extracted_data_by_category, output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Papers with cancer AND patient content only\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique titles: 155\n"
     ]
    }
   ],
   "source": [
    "# Dataset with cancer-patient-related papers and extract text\n",
    "filename = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/outputs/databases/papers_with_patients.csv'\n",
    "df_cancer_patient_related = pd.read_csv(filename)\n",
    "unique_titles_count = len(df_cancer_patient_related['title'].unique())\n",
    "print(f\"Number of unique titles: {unique_titles_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Output directory where the extracted data will be saved\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Cancer patient related papers\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# keyword counts\u001b[39;00m\n\u001b[1;32m      5\u001b[0m output_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/outputs/extracted_data_patients\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[43msave_extracted_data_by_category\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_directory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# keyword-sentence extractions\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#output_directory = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/outputs/extracted_sentences_patients'\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#extract_and_save_sentences_by_category(df_cancer_patient_related, categories, output_directory)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 21\u001b[0m, in \u001b[0;36msave_extracted_data_by_category\u001b[0;34m(data_by_category, output_dir)\u001b[0m\n\u001b[1;32m     19\u001b[0m output_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_related_keywords.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Save the DataFrame to a CSV file\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m(output_file_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m data to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "# Output directory where the extracted data will be saved\n",
    "# Cancer patient related papers\n",
    "\n",
    "# keyword counts\n",
    "output_directory = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/outputs/extracted_data_patients'\n",
    "save_extracted_data_by_category(extracted_data_by_category, output_directory)\n",
    "\n",
    "# keyword-sentence extractions\n",
    "output_directory = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/outputs/extracted_sentences_patients'\n",
    "extract_and_save_sentences_by_category(df_cancer_patient_related, categories, output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_cancer_related_patients' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Check if the number of unique titles is at least 50\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m unique_titles \u001b[38;5;241m=\u001b[39m \u001b[43mdf_cancer_related_patients\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unique_titles \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m100\u001b[39m:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: Only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munique_titles\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m unique papers found, less than 100.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_cancer_related_patients' is not defined"
     ]
    }
   ],
   "source": [
    "# Check if the number of unique titles is at least 50\n",
    "unique_titles = df_cancer_related_patients['title'].nunique()\n",
    "if unique_titles < 100:\n",
    "    print(f\"Warning: Only {unique_titles} unique papers found, less than 100.\")\n",
    "\n",
    "# Randomly select 50 unique titles\n",
    "selected_titles = df_cancer_related_patients['title'].drop_duplicates().sample(n=min(100, unique_titles), random_state=32)\n",
    "\n",
    "# Filter the original DataFrame to include only the selected titles\n",
    "selected_papers_df = df_cancer_related_patients[df_cancer_related_patients['title'].isin(selected_titles)]\n",
    "\n",
    "# You now have the selected_papers_df DataFrame with 50 randomly selected papers and their related rows\n",
    "#selected_papers_df.to_csv('/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/outputs/databases/50_selected_papers_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
