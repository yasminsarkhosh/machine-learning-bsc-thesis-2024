{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf webscrapping and text extraction\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# get the pdf files or url from the web\n",
    "import requests\n",
    "\n",
    "# input output operations\n",
    "import io\n",
    "\n",
    "#!pip install xhtml2pdf requests\n",
    "#!pip install lxml\n",
    "\n",
    "# for converting html to pdf\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "from urllib import request as urllib2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function for extracting PDFS into a Pandas Dataframe\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to find lines in html document with DOI and titles of articles\n",
    "def has_doi(href):\n",
    "    return href and re.compile(\"chapter/\").search(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main mining function returning the initial dataframe \n",
    "def mining(html_doc, year, current_page, all_pages, part):\n",
    "    #opening the html document (copy pasted and saved as a .doc file)\n",
    "    doc = open(html_doc, \"r\", encoding = \"ISO-8859-1\") \n",
    "    soup = BeautifulSoup(doc, 'html.parser' )\n",
    "\n",
    "    list_of_doi = soup.find_all(href=has_doi)\n",
    "        \n",
    "    #getting the titles and the doi's from list generated helper function\n",
    "\n",
    "    titles = []\n",
    "    doi_str = []\n",
    "\n",
    "    for element in list_of_doi:\n",
    "        titles.append(element.get_text()) #returns the titles as the only text in the list\n",
    "        string = str(element)\n",
    "        first_substring = '/chapter'\n",
    "        second_substring ='\">'\n",
    "        #separates out the DOIS (added the +9 to remove /chapter/ from the beginning of all DOIS)\n",
    "        doi_str.append(string[(string.find(first_substring)+9):string.find(second_substring)]) \n",
    "                \n",
    "    ## now the lines containing author are found\n",
    "    authors = soup.find_all(\"li\", class_=\"c-author-list__item\")\n",
    "        \n",
    "    #keeping only the author names\n",
    "    authors_str = []\n",
    "    for element in authors:\n",
    "        string = str(element)\n",
    "        first_substring = 'item\">'\n",
    "        second_substring ='</li>'\n",
    "        authors_str.append(string[(string.find(first_substring)+6):string.find(second_substring)])\n",
    "\n",
    "    #now the lines containing page numbers are found\n",
    "    page_numbers= soup.find_all('div', class_ = \"c-meta\")\n",
    "\n",
    "    #keeping only the page numbers\n",
    "    page_numbers_str = []\n",
    "\n",
    "    # an element in page_numbers_str looks like this:\n",
    "    '''' <div class=\"c-meta\"><span class=\"c-meta__item u-display-inline-block\" \n",
    "    data-test=\"page-number\"> Pages 618-627</span> </div> '''  \n",
    "\n",
    "    for element in page_numbers:            \n",
    "        #removes white spaces, and everything within the div tag that is not the page numbers\n",
    "        string = element.get_text()[6:-1]                       #618-627\n",
    "        #splits the string into two numbers\n",
    "        both = string.split(\"-\")                                #['618', '627']\n",
    "        #filtering out front matters and back matters                                                   \n",
    "        if 'x' and '1-1' and '463-463' and '135-135' and '649-649' and '247-247' and '281-281' and '369-369' and '433-433' and '509-509' and '583-583' and '757-757' and '535-535' not in string:             \n",
    "            try: \n",
    "                if int(both[1])-int(both[0]) > 1: \n",
    "                    page_numbers_str.append(string)              #if True adds the string to the list\n",
    "\n",
    "            except:\n",
    "                if \"C1\" in string or \"C\" in string:              #page numbers that are in the form of C<some number> \n",
    "                    page_numbers_str.append(string)\n",
    "        \n",
    "        #filtering out back matters\n",
    "        if int(current_page) == int(all_pages) and '781-785' in string: \n",
    "            page_numbers_str = page_numbers_str[:-1]\n",
    "            #print('1')         \n",
    "        elif int(current_page) == int(all_pages) and '787-791' in string:\n",
    "            page_numbers_str = page_numbers_str[:-1]\n",
    "            #print('2')\n",
    "        elif int(current_page) == int(all_pages) and '767-771' in string:\n",
    "            page_numbers_str = page_numbers_str[:-1]\n",
    "            #print('3')\n",
    "        elif int(current_page) == int(all_pages) and '797-801' in string:  \n",
    "            page_numbers_str = page_numbers_str[:-1]\n",
    "            #print('4')\n",
    "        elif int(current_page) == int(all_pages) and '801-806' in string:\n",
    "            page_numbers_str = page_numbers_str[:-1]\n",
    "            #print('5')\n",
    "        elif int(current_page) == int(all_pages) and '813-818' in string:\n",
    "            page_numbers_str = page_numbers_str[:-1]\n",
    "            #print('6')\n",
    "        elif int(current_page) == int(all_pages) and '687-690' in string:\n",
    "            page_numbers_str = page_numbers_str[:-1]\n",
    "            #print('7')\n",
    "        elif int(current_page) == int(all_pages) and '739-743' in string:\n",
    "            page_numbers_str = page_numbers_str[:-1]\n",
    "            #print('8')\n",
    "        elif int(current_page) == int(all_pages) and '791-795' in string:\n",
    "            page_numbers_str = page_numbers_str[:-1]\n",
    "            #print('9')\n",
    "\n",
    "\n",
    "    #need to create a list of the year of publication to add to dataframe \n",
    "    year_of_pub = []\n",
    "    for element in titles:\n",
    "        year_of_pub.append(year)\n",
    "    \n",
    "    #will add the part of the publication to the dataframe as well\n",
    "    part_of_pub = []\n",
    "    for element in titles:\n",
    "        part_of_pub.append(part)\n",
    "        \n",
    "\n",
    "    #creating the column names and content for the dataframe        \n",
    "    data = {'Title': titles,\n",
    "        'Authors': authors_str,\n",
    "        'Page numbers' : page_numbers_str,\n",
    "        'DOI': doi_str,\n",
    "        'Year of publication' : year_of_pub,\n",
    "        'Part of publication' : part_of_pub       }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to combine all df together\n",
    "def data_together(data, year):\n",
    "    combined_frame = pd.concat(data, ignore_index = True, sort = False)\n",
    "    combined_frame.to_csv('database_miccai_'+ str(year) +'.csv')\n",
    "   \n",
    "    return combined_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#miccai 2023 papers: 10 volumes in total \n",
    " \n",
    "miccai =[\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 01 page 1 of 4.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 01 page 2 of 4.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 01 page 3 of 4.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 01 page 4 of 4.doc',\n",
    "\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 02 page 1 of 4.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 02 page 2 of 4.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 02 page 3 of 4.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 02 page 4 of 4.doc',\n",
    "\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 03 page 1 of 4.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 03 page 2 of 4.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 03 page 3 of 4.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 03 page 4 of 4.doc',\n",
    "\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 04 page 1 of 4.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 04 page 2 of 4.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 04 page 3 of 4.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 04 page 4 of 4.doc',\n",
    "\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 05 page 1 of 4.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 05 page 2 of 4.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 05 page 3 of 4.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 05 page 4 of 4.doc',\n",
    "\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 06 page 1 of 4.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 06 page 2 of 4.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 06 page 3 of 4.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 06 page 4 of 4.doc',\n",
    "\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 07 page 1 of 5.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 07 page 2 of 5.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 07 page 3 of 5.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 07 page 4 of 5.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 07 page 5 of 5.doc',\n",
    "\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 08 page 1 of 4.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 08 page 2 of 4.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 08 page 3 of 4.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 08 page 4 of 4.doc',\n",
    "\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 09 page 1 of 4.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 09 page 2 of 4.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 09 page 3 of 4.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 09 page 4 of 4.doc',\n",
    "\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 10 page 1 of 4.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 10 page 2 of 4.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 10 page 3 of 4.doc',\n",
    "    '/Users/yasminsarkhosh/Documents/miccai2023 papers/miccai2023 vol 10 page 4 of 4.doc',     \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for element in miccai:\n",
    "    data.append(mining(element, 2023, element[-10], element[-5],  element[-18:-16]))\n",
    "\n",
    "data_together(data, 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
