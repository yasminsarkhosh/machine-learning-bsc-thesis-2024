<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Smooth Attention for Deep Multiple Instance Learning: Application to CT Intracranial Hemorrhage Detection</title>
				<funder>
					<orgName type="full">Ministerio de Universidades</orgName>
				</funder>
				<funder ref="#_Kx4AQxz">
					<orgName type="full">FEDER/Junta de Andalucía and Universidad de Granada</orgName>
				</funder>
				<funder ref="#_GPgZhnF">
					<orgName type="full">Ministerio de Ciencia e Innovación</orgName>
				</funder>
				<funder ref="#_7Pgmrmu">
					<orgName type="full">FPU</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yunan</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="laboratory">Image and Video Processing Laboratory</orgName>
								<orgName type="institution">Northwestern University</orgName>
								<address>
									<settlement>Evanston</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Francisco</forename><forename type="middle">M</forename><surname>Castro-Macías</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science and Artificial Intelligence</orgName>
								<orgName type="institution">University of Granada</orgName>
								<address>
									<settlement>Granada</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory">Research Centre for Information and Communication Technologies (CITIC-UGR)</orgName>
								<orgName type="institution">University of Granada</orgName>
								<address>
									<settlement>Granada</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pablo</forename><surname>Morales-Álvarez</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Statistics and Operations Research</orgName>
								<orgName type="institution">University of Granada</orgName>
								<address>
									<settlement>Granada</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory">Research Centre for Information and Communication Technologies (CITIC-UGR)</orgName>
								<orgName type="institution">University of Granada</orgName>
								<address>
									<settlement>Granada</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rafael</forename><surname>Molina</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science and Artificial Intelligence</orgName>
								<orgName type="institution">University of Granada</orgName>
								<address>
									<settlement>Granada</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aggelos</forename><forename type="middle">K</forename><surname>Katsaggelos</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="laboratory">Image and Video Processing Laboratory</orgName>
								<orgName type="institution">Northwestern University</orgName>
								<address>
									<settlement>Evanston</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Smooth Attention for Deep Multiple Instance Learning: Application to CT Intracranial Hemorrhage Detection</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="327" to="337"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">A83134F938A99C2C667D62964F9AF70A</idno>
					<idno type="DOI">10.1007/978-3-031-43904-9_32</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-23T22:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Smooth attention</term>
					<term>Multiple instance learning</term>
					<term>CT hemorrhage diagnosis</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Multiple Instance Learning (MIL) has been widely applied to medical imaging diagnosis, where bag labels are known and instance labels inside bags are unknown. Traditional MIL assumes that instances in each bag are independent samples from a given distribution. However, instances are often spatially or sequentially ordered, and one would expect similar diagnostic importance for neighboring instances. To address this, in this study, we propose a smooth attention deep MIL (SA-DMIL) model. Smoothness is achieved by the introduction of first and second order constraints on the latent function encoding the attention paid to each instance in a bag. The method is applied to the detection of intracranial hemorrhage (ICH) on head CT scans. The results show that this novel SA-DMIL: (a) achieves better performance than the nonsmooth attention MIL at both scan (bag) and slice (instance) levels; (b) learns spatial dependencies between slices; and (c) outperforms current state-of-the-art MIL methods on the same ICH test set.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Multiple Instance Learning (MIL) <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b20">21]</ref> is a type of weakly supervised learning that has become very popular in biomedical imaging diagnostics due to the reduced annotation effort it requires <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b12">13]</ref>. In the case of MIL binary classification, the training set is partitioned into bags of instances. Both bags and instances have labels, but only bag labels are observed while instance labels remain unknown. It is assumed that a bag label is positive if and only if the bag contains at least one positive instance <ref type="bibr" target="#b9">[10]</ref>. The goal is to produce a method that, trained on bag labels only, is capable of predicting both bag and instance labels.</p><p>Among the proposed approaches for learning in the MIL scenario <ref type="bibr" target="#b20">[21]</ref>, deep learning (DL) methods stand out when dealing with highly structured data (such as medical images and videos) <ref type="bibr" target="#b16">[17]</ref>. The most successful deep MIL approaches combine an instance-level processing mechanism (i.e., a feature extractor) with a pooling mechanism to aggregate information from instances in a bag <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b12">13]</ref>. Among the pooling operators, the attention-based weight pooling proposed in <ref type="bibr" target="#b14">[15]</ref> is frequently used as a way to discover key instances, i.e., those responsible for the label of a bag. However, this pooling operator was formulated under strong assumptions of independence between the instances in a bag. This is a drawback in biomedical imaging problems, where instances in a bag are often spatially or sequentially ordered and their diagnostic importance is expected to be similar for neighboring instances <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b23">24]</ref>.</p><p>In this work, we are particularly interested in the detection of intracranial hemorrhage (ICH), a serious life-threatening emergency caused by blood leakage inside the brain <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b21">22]</ref>. Radiologists confirm the presence of ICH by using computed tomography (CT) scans <ref type="bibr" target="#b8">[9]</ref>, which consist of a significant number of slices, each representing a section of the head at a given height. Unfortunately, the shortage of specialized radiologists and their increasing workload sometimes lead to delayed and erroneous diagnoses <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b24">25]</ref>, which may result in potentially preventable cerebral injury or morbidity <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b10">11]</ref>. For this reason, there is a growing interest in the development of automated systems to assist radiologists in making rapid and reliable diagnoses.</p><p>State-of-the-art ICH detection methods rely on DL models, specifically convolutional neural networks (CNNs), to extract meaningful ICH features <ref type="bibr" target="#b30">[31]</ref>. However, 2D CNNs need to be coupled with other mechanisms such as recurrent neural networks (RNNs) <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b29">30]</ref> or 3D CNNs <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b26">27]</ref> to account for interslice dependencies. Although these approaches are quite successful in terms of performance, their use is limited by the large amount of labeled data they require <ref type="bibr" target="#b30">[31]</ref>. To address this issue, the ICH detection task has been formulated as an MIL problem, achieving comparable performance to fully supervised models while reducing the workload of radiologists <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b28">29]</ref>. Note that the MIL framework is naturally suited for the ICH detection problem since a CT scan (i.e., a bag) is considered positive if it contains at least one slice (i.e., an instance) with evidence of hemorrhage (i.e., positive instance).</p><p>In this work, we improve upon the state-of-the-art deep MIL methods by introducing dependencies between instances in a sound probabilistic manner. These dependencies are formulated over a neighborhood graph to impose smoothness on the latent function that encodes the attention given to each instance. Smoothness is achieved by introducing specific first-and second-order constraints on the latent function. Our model, called SA-DMIL, is applied to the ICH detection problem, obtaining (a) significant improvements upon the performance of non-smooth models at both scan and slice levels, (b) smoother attention weights across slices by benefiting from the inter-slice dependencies, and (c) a superior performance against other popular MIL methods on the same test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem Formulation</head><p>We start by formulating ICH detection as a Multiple Instance Learning (MIL) problem. To do so, we map slices to instances and CT scans to bags. The slices (instances) will be denoted by</p><formula xml:id="formula_0">x b i ∈ R 3HW</formula><p>, where H and W are the height and width of the image, 3 is the number of color channels, b is the index of the scan to which the slice belongs to and i is the index of the slice inside the bag. We will denote the label of a slice by y b i ∈ {0, 1}. If the slice contains hemorrhage, then y b i = 1, otherwise y b i = 0. Note that the slice labels remain unknown since only scan labels are given. As we know, slices are grouped to form the CT scans. Each scan (bag) will be denoted by</p><formula xml:id="formula_1">X b = x b 1 , . . . , x b N b ∈ R N b ×3HW .</formula><p>Here, N b is the number of slices in bag b. We will assume that B CT scans are given, so b ∈ {1, . . . , B}. Given a CT scan b, we will denote its label by T b ∈ {0, 1}. Notice that T b = 1 if and only if some of y i b = 1, i.e., the following relationship between scan and slice labels holds,</p><formula xml:id="formula_2">T b = max y b 1 , . . . , y b N b . (<label>1</label></formula><formula xml:id="formula_3">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Attention-Based Multiple Instance Learning Pooling</head><p>The attention-based MIL pooling was proposed in <ref type="bibr" target="#b14">[15]</ref> as a way to discover key instances, i.e., those responsible for the diagnosis of a scan. It consists of a weighted average of instances (low-dimensional embeddings) where the weights are parameterized by a neural network. Formally, given a bag of N b embeddings</p><formula xml:id="formula_4">Z b = z b 1 , . . . , z b N b</formula><p>, where z b i ∈ R D , the attention-based MIL pooling computes</p><formula xml:id="formula_5">Φ Att Z b = N b i=1 s(z b i )z b i ,<label>(2)</label></formula><p>where</p><formula xml:id="formula_6">s z b i = exp f z b i N b j exp f z b j , f z b i = w tanh Vz b i . (<label>3</label></formula><formula xml:id="formula_7">)</formula><p>Notice that w ∈ R L and V ∈ R L×D are trainable parameters, where D denotes the size of feature vectors. We refer to s z b i as attention weights and to f z b i as attention values. This operator was proposed under the assumption that the instances in a bag show neither dependency nor order among each other. Although this may be the case in simple problems, it does not occur in problems such as ICH detection. Note that the attention weights of slices in a bag are correlated: given a slice containing ICH, we expect that the adjacent slices will also contain ICH with high probabilities. This is essential in finding slices with ICH. In the next subsection, we show how to introduce this correlation between attention weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Modeling Correlation Through the Attention Mechanism</head><p>Ideally, in the case of a positive scan (T b = 1), high attention weights should be assigned to slices that are likely to have a positive label (y b i = 1). Given the dependency between slices, contiguous slices should have similar attention values. In other words, the differences between the attention values of contiguous slices should be small. Thus, for each bag b, these quantities should be small</p><formula xml:id="formula_8">L b S1 = 2 -1 i,j∈Bag(b) A b ij f z b i -f z b j 2 , (<label>4</label></formula><formula xml:id="formula_9">)</formula><formula xml:id="formula_10">L b S2 = 4 -1 i∈Bag(b) j∈Bag(b) A b ij f z b i -f z b j 2 , (<label>5</label></formula><formula xml:id="formula_11">)</formula><p>where A b ij = 1 if the slices i, j are related in bag b, and 0 otherwise. We smooth f z b i instead of s z b i because a non-constrained parameter f ensures consistent smoothing while s requires a normalization across instances in a bag.</p><p>Equations ( <ref type="formula" target="#formula_8">4</ref>) and ( <ref type="formula" target="#formula_10">5</ref>) correspond, respectively, to the energies of the, so called, conditional and simultaneous autoregressive models in the statistics literature <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b22">23]</ref>. For our problem, they model the value of f at a given location (instance) given the values at neighboring instances. From the regularization viewpoint, these terms constrain the first and second derivatives of the function f , respectively, which favors smoother functions (examine the zero of the derivative of f ). That is, a priori all attention weights are expected to be the same because f is expected to be constant. As observations arrive, they change to reflect the importance of each instance. Note that (4) and ( <ref type="formula" target="#formula_10">5</ref>) impose smoothness but they can be modified to model, for example, competition between the attention weights by simply replacing the minus sign with a plus sign.</p><p>To compute L b S1 and L b S2 efficiently we consider the simple graph defined by the dependency between slices. For a bag b, its adjacency matrix is</p><formula xml:id="formula_12">A b = A b ij . The degree matrix D b = D b</formula><p>ij is a diagonal matrix that contains the degree of each slice (the degree of the slice i is the number of slices j such that A b ij = 1). This is, D b ii = degree(i) and D b ij = 0 if i = j. Using these, one can compute the graph Laplacian matrix of a bag as</p><formula xml:id="formula_13">L b = D b -A b . It is easy to show that L b S1 = f b L b f b , L b S2 = f b L b L b f b , (<label>6</label></formula><formula xml:id="formula_14">)</formula><p>where</p><formula xml:id="formula_15">f b = f (z b 1 ), . . . , f(z b N b ) . The sum of L b Sk over bags,</formula><p>where k ∈ {1, 2}, can be added to the loss function of a network to be minimized along the taskspecific loss. Note that these two terms provide two different approaches to exploiting the correlations between instances through the loss function. We will refer to this approach as smooth attention (SA) loss. In the following subsection, we propose a model that can use either L S1 or L S2 . The effect of each term will be discussed in Sect. 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">SA-DMIL Model Description</head><p>We propose to couple the attention-based MIL pooling with the SA loss terms introduced in Subsect. 2.3. The proposed model, named Smooth Attention Deep Multiple Instance Learning (SA-DMIL), is depicted in Fig. <ref type="figure" target="#fig_0">1</ref>. We use a Convolutional Neural Network (CNN), denoted by Φ CNN , as a feature extractor to obtain a vector of low dimensional embeddings for each instance. That is, given a bag</p><formula xml:id="formula_16">X b = x b 1 , . . . , x b N b , where x b n ∈ R 3×HW , we compute z b n = Φ CNN x b n ∈ R D , Z b = z b 1 , . . . , z b N b . (<label>7</label></formula><formula xml:id="formula_17">)</formula><p>The CNN module in Fig. <ref type="figure" target="#fig_0">1</ref> is implemented with six convolutional blocks, followed by a flatten layer. Z b is then fed into the attention layer Φ Att described in Subsect. 2.3 to obtain a scan representation. After that, the scan representation passes through a classifier Φ c (i.e., one fully connected layer with a sigmoid activation) to predict the scan labels,</p><formula xml:id="formula_18">p T b | X b ≈ Φ X b = Φ c Φ Att Φ CNN X b , (<label>8</label></formula><formula xml:id="formula_19">)</formula><p>where we have written</p><formula xml:id="formula_20">Φ CNN X b = Φ CNN x b 1 , . . . , Φ CNN x b N b . Our model, that corresponds to the composition Φ = Φ c • Φ Att • Φ CNN , is trained using the following loss function until convergence, L = (1 -α) L CE + αL Sk , (<label>9</label></formula><formula xml:id="formula_21">)</formula><p>where α ∈ [0, 1] is an hyperparameter and L CE the common cross-entropy loss,</p><formula xml:id="formula_22">L CE = b T b log Φ X b + 1 -T b log 1 -Φ X b , (<label>10</label></formula><formula xml:id="formula_23">)</formula><p>where k ∈ {1, 2}, and L Sk = b L b Sk (see Eqs. ( <ref type="formula" target="#formula_8">4</ref>) and ( <ref type="formula" target="#formula_10">5</ref>)). Depending on the value of k, we obtain two variations of SA-DMIL, which will be referred to as SA-DMIL-S1 and SA-DMIL-S2. The baseline model, Att-MIL (non-smooth attention), is recovered when α = 0.0 <ref type="bibr" target="#b14">[15]</ref>. Following the approach of previous studies <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b28">29]</ref>, attention weights will be used to obtain predictions at the slice level (although they are not specifically designed for it). If a scan is predicted to be negative, all slices are also predicted to be negative, while if a scan is predicted to correspond to an ICH, slices whose attention weight is above a threshold (i.e., 1/N b , with N b being the number of slices in that scan) are predicted as ICH.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Design</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data and Data Preprocessing</head><p>The dataset used in this work was obtained from the 2019 Radiological Society of North America (RSNA) challenge <ref type="bibr" target="#b0">[1]</ref>, which included 39650 CT slices from 1150 subjects. The data were split among subjects, with 1000 scans (ICH: Normal scans = 411: 589; ICH: Normal slices = 4976: 29520) used for training and validation, and the remaining 150 scans (ICH: Normal scans = 72: 78; ICH: Normal slices = 806: 4448) used for held-out testing. The number of slices in the scans varied from 24 to 57. All CT slices underwent the same preprocessing procedure as described in <ref type="bibr" target="#b28">[29]</ref>. Each CT slice had three windows applied to its original Hounsfield Units by changing the window Width (W) and Center (C) to manipulate the display of specific tissues, as radiologists typically do when diagnosing brain CTs. Here, we selected the brain (W: 80, C:40), subdural (W:200, C:80) and soft tissue (W:380, C: 40) windows. All images were then resized to the same size of 512 × 512 and normalized to the range [0, 1]. CTs were annotated at both the scan and slice levels, but slice labels were used for evaluation only, while scan labels were used for training and evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experimental Settings</head><p>We fix D = 128 and L = 50 in Eq. ( <ref type="formula" target="#formula_6">3</ref>). We use the Adam optimizer with the learning rate starting at 10 -4 . The batch size is set to 4, the maximum number of epochs is set to 200 and the patience for early stopping is set to 8. We test different values of the α hyperparameter, between 0 and 1 with a jump of 0.1. All experiments were run 5 independent times and the mean and standard deviation were reported in the held-old testing set at both scan and slice levels. The average training time is 10.3 h for SA-DMIL-S1 and 10.5 h for SA-DMIL-S2. The prediction time is approximately 15.8 s for each scan. All experiments were conducted using Tensorflow 2.11 in Python 3.8 on a single GPU (NVIDIA Quadro RTX 8000). The code will be available via GitHub.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Hyperparameters Tuning</head><p>In this subsection, we study the effect of SA loss in terms of performance. Table <ref type="table" target="#tab_0">1</ref> compares the performance of models for different values of α. The standard deviation and other values of α can be found in the appendix, Tables <ref type="table" target="#tab_0">S1</ref> and<ref type="table">S2</ref>. The results show that at both scan and slice levels, adding a smoothness term to the loss function (α &gt; 0.0) achieves better performance than Att-MIL (α = 0.0). These improvements are significant, with increases in accuracy, F1 and AUC scores of approximately 7%, 9% and 5% respectively, at scan level, and increases in accuracy and F1 score of 8% and 11% respectively, at slice level. The recall is the only metric in which our model does not excel, where the baseline Att-MIL obtains the best value. However, this is associated with very low precision values. Note that, as α increases, the performance of the model first improves and then drops, which is consistent with the role played by the SA loss as a regularization term. The difference between L S1 and L S2 is not significant although L S1 performs slightly better. In fact, when using L S1 , α = 0.5 gives the best diagnostic performance with an AUC of 0.879 (± 0.003) at scan level and an accuracy of 0.834 (± 0.010) at slice level. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Smooth Attention MIL vs. Other MIL Methods</head><p>The performance of other popular MIL methods is also included in Table <ref type="table" target="#tab_0">1</ref>. All method share the same CNN architecture to extract slice features, but they differ in the pooling operator they use: Max <ref type="bibr" target="#b27">[28]</ref>, Mean <ref type="bibr" target="#b27">[28]</ref>, Attention <ref type="bibr" target="#b14">[15]</ref> or Gaussian Process (GP) <ref type="bibr" target="#b28">[29]</ref>. These results show that the performance of SA-DMIL is consistently better than other methods across different metrics and at both scan and slice levels. Only the precision of MIL+Max agg. and the recall of AttCNN+VGPMIL at scan level are higher than those obtained by SA-DMIL. However, considering the trade-off between precision and recall given by F1, our method achieves a superior performance. In tasks like ICH detection, where neighbouring instances are expected to have similar diagnostic importance. Unlike other MIL methods that assume each instance to be independently distributed, SA-DMIL stands out by considering the spatial correlation between instances, which compels it to learn more meaningful features for making accurate bag predictions. Notably, this is achieved by simply adding a smoothing term to the loss function without increasing the number of model parameters. This can potentially be applied to existing architectures to further improve performance without adding complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Visualizing Smooth Regularizing Effects at Slice Level</head><p>So far we have observed enhanced performance through the SA term. In this subsection, we visually illustrate how this novel term imposes smoothness between attention scores of consecutive slices, leading to more accurate predictions.</p><p>Figure <ref type="figure">2</ref> shows plots of the attention scores assigned by SA-DMIL-S1 and Att-MIL to the slices of three different scans (Fig. <ref type="figure" target="#fig_0">S1</ref> in the appendix contains an analogous plot for SA-DMIL-S2). As expected, introducing the SA loss results in smoother attention weights. Note that the smoothness constraint of SA-DMIL effectively penalizes the appearance of isolated non-smooth attention weights that incorrectly jump over or below the threshold. We also include visual examples of consecutive CT slices in Fig. <ref type="figure">3</ref>. In Scan 1, the baseline Att-MIL produces a wrong prediction at scan level. When using SA, the prediction is correct since dependencies between adjacent slices have been learned. In Scan 2, both models produce correct predictions at scan level, but SA-DMIL is more accurate at slice level. This occurs thanks to the SA loss, that turns the attention scores into smoother values and, therefore, avoids random jumps up and down the decision threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this study we have proposed SA-DMIL, a new model that obtains significant improvements in ICH classification compared to state-of-the-art MIL methods. This is done by adding a smoothing regularizing term to the loss function. This term imposes a smoothness constraint on the latent function that encodes the attention weights, which forces our model to learn dependencies between instances rather than training each instance independently in a bag. This flexible approach does not introduce any additional complexity, so similar ideas can be applied to other methods to model dependencies between neighboring instances.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. SA-DMIL architecture. It consists of CNNs that extract slice level features and an attention block to aggregate slice features. The loss function is a weighted average of the binary cross entropy and a novel smooth attention loss.</figDesc><graphic coords="4,51,30,53,84,321,88,144,88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .Fig. 3 .</head><label>23</label><figDesc>Fig. 2. Attention weights of SA-DMIL-S1 (blue lines, α = 0.5) and Att-MIL [15] (orange lines, α = 0.0). Slices with values above the threshold (1/N b ) are predicted as ICH, while those below are predicted as Normal. The green area highlights those slices whose ground truth label is ICH. (Color figure online)</figDesc><graphic coords="8,50,31,401,57,324,04,104,92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Performance of SA-DMIL and other MIL methods at slice and scan levels on the RSNA dataset. The average of 5 independent runs is reported. For space constraints, the standard deviation is reported in the appendix.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Scan level</cell><cell></cell><cell cols="2">Slice level</cell><cell></cell></row><row><cell>Model</cell><cell>Acc</cell><cell>Pre</cell><cell>Rec</cell><cell>F1</cell><cell>AUC Acc</cell><cell>Pre</cell><cell>Rec</cell><cell>F1</cell></row><row><cell>SA-DMIL-S1 α = 0.9</cell><cell cols="8">0.753 0.803 0.681 0.735 0.839 0.789 0.670 0.541 0.598</cell></row><row><cell>α = 0.7</cell><cell cols="8">0.806 0.763 0.784 0.775 0.860 0.828 0.679 0.576 0.639</cell></row><row><cell>α = 0.5</cell><cell cols="8">0.813 0.805 0.806 0.806 0.879 0.834 0.732 0.608 0.686</cell></row><row><cell>α = 0.3</cell><cell cols="8">0.767 0.734 0.806 0.768 0.859 0.775 0.702 0.551 0.624</cell></row><row><cell>α = 0.1</cell><cell cols="8">0.747 0.783 0.652 0.712 0.841 0.766 0.649 0.540 0.584</cell></row><row><cell>SA-DMIL-S2 α = 0.9</cell><cell cols="8">0.753 0.817 0.613 0.714 0.816 0.768 0.733 0.551 0.598</cell></row><row><cell>α = 0.7</cell><cell cols="8">0.767 0.776 0.722 0.748 0.843 0.807 0.734 0.591 0.638</cell></row><row><cell>α = 0.5</cell><cell cols="8">0.800 0.828 0.736 0.780 0.867 0.823 0.748 0.596 0.659</cell></row><row><cell>α = 0.3</cell><cell cols="8">0.763 0.797 0.686 0.721 0.853 0.790 0.738 0.561 0.622</cell></row><row><cell>α = 0.1</cell><cell cols="8">0.747 0.736 0.740 0.736 0.833 0.767 0.683 0.547 0.593</cell></row><row><cell>Att-MIL (α = 0.0) [15]</cell><cell cols="8">0.740 0.674 0.832 0.719 0.829 0.751 0.623 0.543 0.579</cell></row><row><cell>MIL + Max agg. [28]</cell><cell cols="8">0.617 0.856 0.447 0.575 0.743 0.732 0.441 0.373 0.406</cell></row><row><cell>MIL + Mean agg. [28]</cell><cell cols="8">0.677 0.670 0.734 0.693 0.801 0.741 0.502 0.386 0.447</cell></row><row><cell cols="9">Att-CNN + VGPMIL [29] 0.765 0.724 0.851 0.773 0.868 0.807 0.714 0.538 0.597</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement. This work was supported by project <rs type="grantNumber">PID2019-105142RB-C22</rs> funded by <rs type="funder">Ministerio de Ciencia e Innovación</rs> and by project <rs type="grantNumber">B-TIC-324-UGR20</rs> funded by <rs type="funder">FEDER/Junta de Andalucía and Universidad de Granada</rs>. The work by <rs type="person">Francisco M. Castro-Macías</rs> was supported by <rs type="funder">Ministerio de Universidades</rs> under <rs type="funder">FPU</rs> contract <rs type="grantNumber">FPU21/01874</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_GPgZhnF">
					<idno type="grant-number">PID2019-105142RB-C22</idno>
				</org>
				<org type="funding" xml:id="_Kx4AQxz">
					<idno type="grant-number">B-TIC-324-UGR20</idno>
				</org>
				<org type="funding" xml:id="_7Pgmrmu">
					<idno type="grant-number">FPU21/01874</idno>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Use Declaration</head><p>The dataset used in this study is from the 2019 RSNA Intracranial Hemorrhage Detection Challenge and is publicly available in this link.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43904-9 32.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="https://kaggle.com/c/rsna-intracranial-hemorrhage-detection" />
		<title level="m">RSNA intracranial hemorrhage detection</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Advanced machine learning in action: identification of intracranial hemorrhage on computed tomography scans of the head with clinical workflow integration</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Arbabshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NPJ Digit.Med</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Cranial CT interpretation by senior emergency department staff</title>
		<author>
			<persName><forename type="first">G</forename><surname>Arendts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Manovel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Australas. Radiol</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="368" to="374" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Manifold regularization: a geometric framework for learning from labeled and unlabeled examples</title>
		<author>
			<persName><forename type="first">M</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sindhwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2399" to="2434" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Intracranial hemorrhage</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Caceres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Emerg. Med. Clin. North Am</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="771" to="794" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Multiple instance learning: a survey of problem characteristics and applications. Pattern Recogn</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Carbonneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Cheplygina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Granger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gagnon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="329" to="353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Hybrid 3d/2d convolutional neural network for hemorrhage evaluation on head CT</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Neuroradiol</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1609" to="1616" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Not-so-supervised: a survey of semisupervised, multi-instance, and transfer learning in medical image analysis</title>
		<author>
			<persName><forename type="first">V</forename><surname>Cheplygina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Pluim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="280" to="296" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Intracerebral hemorrhage: current approaches to acute management</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cordonnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Demchuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ziai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lancet</title>
		<imprint>
			<biblScope unit="volume">392</biblScope>
			<biblScope unit="page" from="1257" to="1268" />
			<date type="published" when="2018">10154. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Solving the multiple instance problem with axis-parallel rectangles</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Dietterich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Lathrop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lozano-Pérez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="31" to="71" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The acute management of intracerebral hemorrhage: a clinical review</title>
		<author>
			<persName><forename type="first">J</forename><surname>Elliott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Anesth. Analg</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1419" to="1427" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Radiology resident evaluation of head CT scan orders in the emergency department</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Erly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">G</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Krupinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Seeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Guisto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Neuroradiol</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="103" to="107" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Multiple instance learning for digital pathology: a review on the state-of-the-art, limitations &amp; future potential</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gadermayr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tschuchnig</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.04425</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">RadNet: radiologist level accuracy using deep learning for hemorrhage detection in CT scans</title>
		<author>
			<persName><forename type="first">M</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Varadarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018. 2018</date>
			<biblScope unit="page" from="281" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Attention-based deep multiple instance learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ilse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tomczak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2127" to="2136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Image thresholding improves 3-dimensional convolutional neural network diagnosis of different acute brain hemorrhages on computed tomography scans</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">2167</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multi-modal multi-instance learning using weakly correlated histopathological images and tabular clinical information</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87237-3_51</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87237-351" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12908</biblScope>
			<biblScope unit="page" from="529" to="539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep gaussian processes for multiple instance learning: application to CT intracranial hemorrhage detection</title>
		<author>
			<persName><forename type="first">M</forename><surname>López-Pérez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Katsaggelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Methods Program. Biomed</title>
		<imprint>
			<biblScope unit="volume">219</biblScope>
			<biblScope unit="page">106783</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The effects of changes in utilization and technological advancements of cross-sectional imaging on radiologist workload</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acad. Radiol</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1191" to="1198" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Multiple-instance learning for medical image and video analysis</title>
		<author>
			<persName><forename type="first">G</forename><surname>Quellec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cazuguel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cochener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lamard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Rev. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="213" to="234" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Spontaneous intracerebral hemorrhage</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Qureshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tuhrim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Broderick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Batjer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hondo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Hanley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New England J. Med</title>
		<imprint>
			<biblScope unit="volume">344</biblScope>
			<biblScope unit="issue">19</biblScope>
			<biblScope unit="page" from="1450" to="1460" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">B</forename><surname>Ripley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981">1981</date>
			<publisher>Spatial Statistics. Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Transmil: transformer based correlated multiple instance learning for whole slide image classification</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="2136" to="2147" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Overnight preliminary head CT interpretations provided by residents: locations of misidentified intracranial hemorrhage</title>
		<author>
			<persName><forename type="first">W</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tomsick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vagal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Neuroradiol</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1679" to="1682" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Weakly supervised learning significantly reduces the number of labels required for intracranial hemorrhage detection on head ct</title>
		<author>
			<persName><forename type="first">J</forename><surname>Teneggi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sulam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.15924</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Automated deep-neural-network surveillance of cranial images for acute neurologic events</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Titano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1337" to="1341" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A comparison of five multiple instance learning pooling functions for sound event detection with weak labeling</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Metze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="31" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Combining attention-based multiple instance learning and gaussian processes for CT hemorrhage detection</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hernández-Sánchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Katsaggelos</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87196-3_54</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87196-3" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12902</biblScope>
			<biblScope unit="page">54</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Precise diagnosis of intracranial hemorrhage and subtypes using a three-dimensional joint convolutional and recurrent neural network</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ye</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00330-019-06163-2</idno>
		<ptr target="https://doi.org/10.1007/s00330-019-06163-2" />
	</analytic>
	<monogr>
		<title level="j">Eur. Radiol</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="6191" to="6201" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Review of deep learning algorithms for the automatic detection of intracranial hemorrhages on computed tomography head imaging</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yeo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurointerventional Surg</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="369" to="378" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
