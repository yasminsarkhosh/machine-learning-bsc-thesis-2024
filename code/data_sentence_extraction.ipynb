{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence extraction for analysis purposes \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The main purpose of this notebook is to extract sentences from the preprocessed and already extracted data (made by the previous notebook: https://github.com/yasminsarkhosh/machine-learning-bsc-thesis-2024/blob/main/code/data_processing_w_GROBID.ipynb) from MICCAI 2023 research papers. The extracted sentences are based on a list of relevant keywords, organized by paper title. \n",
    "\n",
    "\n",
    "**It includes:**\n",
    "1. Setup and Imports: Import necessary libraries (e.g., os, pandas).\n",
    "2. File and Data Loading: Load data from CSV files.\n",
    "    - The dataframe with the selected papers with cancer-relevant content containing extracted text from Abstract til Conclusion\n",
    "3. A utility function (wrap_text) to wrap sentences at a given width, making the dataframe more readable.\n",
    "4. Keyword Extraction: Logic to extract keywords and sentences containing those keywords.\n",
    "    - For demographics a list of keywords has been created and tested to find the optimal list of words, that extracts just about the most neccessary sentences however without excluding too much valuable information or including too much information that is irrelevant and too overwhelming for analysis\n",
    "5. Functions for keyword and sentence extraction (extract_keywords, extract_keyword_sentences).\n",
    "6. Dataframe Manipulations: Operations on dataframes like filling NaN values, type casting, and saving to CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Setup and Imports: Import necessary libraries (e.g., os, pandas).\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. File and Data Loading: Load data from CSV files.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"\n",
    "    Load the dataset from a CSV file.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique titles: 263\n"
     ]
    }
   ],
   "source": [
    "# Dataset with cancer-related papers and extract text\n",
    "filename = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/outputs/databases/cancer_related_papers_w_text.csv'\n",
    "df_cancer_related = pd.read_csv(filename)\n",
    "unique_titles_count = len(df_cancer_related['title'].unique())\n",
    "print(f\"Number of unique titles: {unique_titles_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. A utility function (wrap_text) to wrap sentences at a given width, making the dataframe more readable.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_text(text, width=100):\n",
    "    \"\"\"\n",
    "    A simple function to wrap text at a given width.\n",
    "    \"\"\"\n",
    "    if pd.isnull(text):\n",
    "        return text\n",
    "    \n",
    "    wrapped_lines = []\n",
    "    for paragraph in text.split('\\n'):\n",
    "        line = ''\n",
    "        for word in paragraph.split():\n",
    "            if len(line) + len(word) + 1 > width:\n",
    "                wrapped_lines.append(line)\n",
    "                line = word\n",
    "            else:\n",
    "                line += (' ' + word if line else word)\n",
    "        wrapped_lines.append(line)\n",
    "    return '\\n'.join(wrapped_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Keyword Extraction: Logic to extract keywords and sentences containing those keywords.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(df, keywords):\n",
    "    \"\"\"\n",
    "    Extract rows from a DataFrame based on matching keywords.\n",
    "    \"\"\"\n",
    "    pattern = r'\\b(' + '|'.join(re.escape(keyword) for keyword in keywords) + r')\\b'\n",
    "    sentences_by_paper = {}\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        sentences = re.findall(pattern, row['text'], flags=re.IGNORECASE | re.DOTALL)\n",
    "        if sentences:\n",
    "            paper_title = row['title']\n",
    "            if paper_title not in sentences_by_paper:\n",
    "                sentences_by_paper[paper_title] = []\n",
    "            sentences_by_paper[paper_title].extend(sentences)\n",
    "\n",
    "    keywords_data = [(title, keyword_sentence) for title, related_group in sentences_by_paper.items() for keyword_sentence in related_group]\n",
    "    return pd.DataFrame(keywords_data, columns=['title', 'keyword'])\n",
    "\n",
    "\n",
    "def extract_keyword_sentences(df, keywords):\n",
    "    \"\"\"\n",
    "    Extract sentences containing specified keywords from DataFrame and organize by paper title.\n",
    "    \"\"\"\n",
    "    keyword_pattern = re.compile(r'\\b(?:' + '|'.join(keywords) + r')\\b', flags=re.IGNORECASE)\n",
    "    sentences_by_paper = {}\n",
    "\n",
    "    for title in df['title'].unique():\n",
    "        text = ' '.join(df[df['title'] == title]['text'])\n",
    "        sentences = re.split(r'(?<=[.?!])\\s+', text)\n",
    "        keyword_sentences_buffer = []\n",
    "\n",
    "        for sentence in sentences:\n",
    "            if keyword_pattern.search(sentence):\n",
    "                keyword_sentences_buffer.append(sentence)\n",
    "\n",
    "        sentences_by_paper[title] = keyword_sentences_buffer if keyword_sentences_buffer else ['none']\n",
    "    \n",
    "    extracted_data = [(title, keyword_sentence) for title, related_group in sentences_by_paper.items() for keyword_sentence in related_group]\n",
    "    extracted_df = pd.DataFrame(extracted_data, columns=['title', 'extracted_keyword_sent'])\n",
    "    extracted_df['extracted_keyword_sent'] = extracted_df['extracted_keyword_sent'].apply(lambda x: wrap_text(x, width=80))\n",
    "\n",
    "    return extracted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Functions for keyword and sentence extraction (extract_keywords, extract_keyword_sentences).\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: age, Rows: 28\n",
      "Category: gender, Rows: 36\n",
      "Category: ethnicity, Rows: 29\n",
      "Category: geolocation, Rows: 98\n",
      "Category: patients, Rows: 950\n",
      "Category: bias, Rows: 154\n"
     ]
    }
   ],
   "source": [
    "def extract_keywords_by_category(df, categories):\n",
    "    \"\"\"\n",
    "    Extract keywords from DataFrame based on multiple categories of keywords.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing the text to search through.\n",
    "    - categories: A dictionary with category names as keys and lists of keywords as values.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with category names as keys and DataFrames of extracted keywords as values.\n",
    "    \"\"\"\n",
    "    extracted_data = {}\n",
    "    for category, keywords in categories.items():\n",
    "        extracted_data[category] = extract_keywords(df, keywords)\n",
    "    return extracted_data\n",
    "\n",
    "# Categories and their corresponding keywords\n",
    "categories = {\n",
    "    'age': ['age'],\n",
    "    'gender': ['gender', 'sex', 'women', 'woman', 'female', 'male'],\n",
    "    'ethnicity': ['ethnicity', 'ethnicities', 'race', 'white patients', 'black patients'],\n",
    "    'geolocation': ['geolocation', 'geographical', 'geographic', 'country', 'countries', 'city', 'cities', \n",
    "                    'hospital', 'hospitals', 'clinic', 'clinics'],\n",
    "    'patients': ['patient', 'patients'],\n",
    "    'bias': ['bias', 'biases'],\n",
    "}\n",
    "\n",
    "# Call the function to extract keywords by category\n",
    "extracted_data_by_category = extract_keywords_by_category(df_cancer_related, categories)\n",
    "\n",
    "# Now, extracted_data_by_category will hold a dictionary where each key is a category\n",
    "# and the value is the DataFrame containing the extracted keywords for that category.\n",
    "\n",
    "# To process or save the extracted data for each category:\n",
    "for category, data in extracted_data_by_category.items():\n",
    "    # Process or save data\n",
    "    print(f\"Category: {category}, Rows: {len(data)}\")\n",
    "    # For example, to save:\n",
    "    #data.to_csv(f\"{category}_related_keywords.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved age data to /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/extracted_data/age_related_keywords.csv\n",
      "Saved gender data to /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/extracted_data/gender_related_keywords.csv\n",
      "Saved ethnicity data to /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/extracted_data/ethnicity_related_keywords.csv\n",
      "Saved geolocation data to /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/extracted_data/geolocation_related_keywords.csv\n",
      "Saved patients data to /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/extracted_data/patients_related_keywords.csv\n",
      "Saved bias data to /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/extracted_data/bias_related_keywords.csv\n"
     ]
    }
   ],
   "source": [
    "def save_extracted_data_by_category(data_by_category, output_dir):\n",
    "    \"\"\"\n",
    "    Save each DataFrame in the data_by_category dictionary to a CSV file.\n",
    "    Each category has a list of corresponding keywords\n",
    "    \n",
    "    Parameters:\n",
    "    - data_by_category (dict): A dictionary with category names as keys and DataFrames as values.\n",
    "    - output_dir (str): The directory where the CSV files will be saved.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Iterate through the dictionary\n",
    "    for category, df in data_by_category.items():\n",
    "        # Define the output file path\n",
    "        output_file_path = os.path.join(output_dir, f\"{category}_related_keywords.csv\")\n",
    "        # Save the DataFrame to a CSV file\n",
    "        df.to_csv(output_file_path, index=False)\n",
    "        print(f\"Saved {category} data to {output_file_path}\")\n",
    "\n",
    "# Example usage:\n",
    "output_directory = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/extracted_data'\n",
    "save_extracted_data_by_category(extracted_data_by_category, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved age sentences to /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/sentences/age_related_sentences.csv\n",
      "Saved gender sentences to /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/sentences/gender_related_sentences.csv\n",
      "Saved ethnicity sentences to /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/sentences/ethnicity_related_sentences.csv\n",
      "Saved geolocation sentences to /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/sentences/geolocation_related_sentences.csv\n",
      "Saved patients sentences to /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/sentences/patients_related_sentences.csv\n",
      "Saved bias sentences to /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/sentences/bias_related_sentences.csv\n"
     ]
    }
   ],
   "source": [
    "def extract_and_save_sentences_by_category(df, categories, output_dir):\n",
    "    \"\"\"\n",
    "    Extract sentences by keywords for each category and save them to CSV files.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing the text to search through.\n",
    "    - categories: A dictionary with category names as keys and lists of keywords as values.\n",
    "    - output_dir (str): The directory where the CSV files will be saved.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Iterate through the categories and keywords\n",
    "    for category, keywords in categories.items():\n",
    "        # Extract sentences containing the keywords\n",
    "        extracted_df = extract_keyword_sentences(df, keywords)\n",
    "        \n",
    "        # Define the output file path\n",
    "        output_file_path = os.path.join(output_dir, f\"{category}_related_sentences.csv\")\n",
    "        \n",
    "        # Save the DataFrame to a CSV file\n",
    "        extracted_df.to_csv(output_file_path, index=False)\n",
    "        print(f\"Saved {category} sentences to {output_file_path}\")\n",
    "\n",
    "# Example usage:\n",
    "categories = {\n",
    "    'age': ['age'],\n",
    "    'gender': ['gender', 'sex', 'women', 'woman', 'female', 'male'],\n",
    "    'ethnicity': ['ethnicity', 'ethnicities', 'race', 'white patients', 'black patients'],\n",
    "    'geolocation': ['geolocation', 'geographical', 'geographic', 'country', 'countries', 'city', 'cities', \n",
    "                    'hospital', 'hospitals', 'clinic', 'clinics'],\n",
    "    'patients': ['patient', 'patients'],\n",
    "    'bias': ['bias', 'biases'],\n",
    "}\n",
    "\n",
    "output_directory = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/extracted_sentences'\n",
    "extract_and_save_sentences_by_category(df_cancer_related, categories, output_directory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
