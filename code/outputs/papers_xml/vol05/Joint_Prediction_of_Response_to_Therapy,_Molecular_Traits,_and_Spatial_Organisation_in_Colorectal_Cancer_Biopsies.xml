<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies</title>
				<funder>
					<orgName type="full">Cancer Research UK</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ruby</forename><surname>Wood</surname></persName>
							<email>ruby.wood@eng.ox.ac.uk</email>
							<idno type="ORCID">0000-0001-9916-888X</idno>
							<affiliation key="aff0">
								<orgName type="department">Department of Engineering Science</orgName>
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<settlement>Oxford</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Big Data Institute</orgName>
								<orgName type="laboratory">Li Ka Shing Centre for Health Information and Discovery</orgName>
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<settlement>Oxford</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Enric</forename><surname>Domingo</surname></persName>
							<idno type="ORCID">0000-0003-4390-8767</idno>
							<affiliation key="aff3">
								<orgName type="department">Department of Oncology</orgName>
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<settlement>Oxford</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Korsuk</forename><surname>Sirinukunwattana</surname></persName>
							<idno type="ORCID">0000-0002-3603-4435</idno>
							<affiliation key="aff0">
								<orgName type="department">Department of Engineering Science</orgName>
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<settlement>Oxford</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Big Data Institute</orgName>
								<orgName type="laboratory">Li Ka Shing Centre for Health Information and Discovery</orgName>
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<settlement>Oxford</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Maxime</forename><forename type="middle">W</forename><surname>Lafarge</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Department of Pathology and Molecular Pathology</orgName>
								<orgName type="laboratory">Computational and Translational Pathology Group</orgName>
								<orgName type="institution">University Hospital and University of Zürich</orgName>
								<address>
									<postCode>8091</postCode>
									<settlement>Zürich</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Viktor</forename><forename type="middle">H</forename><surname>Koelzer</surname></persName>
							<idno type="ORCID">0000-0001-9206-4885</idno>
							<affiliation key="aff4">
								<orgName type="department">Department of Pathology and Molecular Pathology</orgName>
								<orgName type="laboratory">Computational and Translational Pathology Group</orgName>
								<orgName type="institution">University Hospital and University of Zürich</orgName>
								<address>
									<postCode>8091</postCode>
									<settlement>Zürich</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Timothy</forename><forename type="middle">S</forename><surname>Maughan</surname></persName>
							<idno type="ORCID">0000-0002-0580-5065</idno>
							<affiliation key="aff3">
								<orgName type="department">Department of Oncology</orgName>
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<settlement>Oxford</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jens</forename><surname>Rittscher</surname></persName>
							<email>jens.rittscher@eng.ox.ac.uk</email>
							<idno type="ORCID">0000-0002-8528-8298</idno>
							<affiliation key="aff0">
								<orgName type="department">Department of Engineering Science</orgName>
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<settlement>Oxford</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Nuffield Department of Medicine</orgName>
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<settlement>Oxford</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Big Data Institute</orgName>
								<orgName type="laboratory">Li Ka Shing Centre for Health Information and Discovery</orgName>
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<settlement>Oxford</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="758" to="767"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">43A60444C71D8C0E59E1CAA56298C5BC</idno>
					<idno type="DOI">10.1007/978-3-031-43904-9_73</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-25T18:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Histology</term>
					<term>Graphs</term>
					<term>Colorectal Cancer</term>
					<term>Response to Therapy</term>
					<term>Interpretability</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Existing methods for interpretability of model predictions are largely based on technical insights and are not linked to clinical context. We use the question of predicting response to radiotherapy in colorectal cancer patients as an exemplar for developing prediction models that do provide such contextual information and therefore can effectively support clinical decision making. There is a growing body of evidence that about 30% of colorectal cancer patients do not respond to radiotherapy and will need alternative treatment. The consensus molecular subtypes for colorectal cancer (CMS) provide one such approach to categorising patients based on their disease biology. Here we select the CMS4 subtype as a proxy for stromal infiltration. By jointly predicting a patient's response to radiotherapy, the presence of CMS4, and the epithelial tissue map from morphological features extracted from standard H&amp;E slides we provide a comprehensive clinically relevant assessment of a biopsy. A graph neural network is trained to achieve this joint prediction task, which subsequently provides novel interpretability maps to aid clinicians in their cancer treatment decision making process. Our model is trained and validated on two private rectal cancer datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In the UK, approximately 11,500 patients are diagnosed with rectal cancer each year <ref type="bibr" target="#b19">[19]</ref>. A common form of treatment for such patients is neoadjuvant therapy, including chemotherapy and radiotherapy, which can be given to patients with locally advanced rectal cancer to shrink the tumour prior to surgery. Recent evidence suggests that 10-20% of patients will have a complete pathological response to neoadjuvant therapy and can therefore avoid surgery altogether <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5]</ref>. However, one third of patients do not benefit from radiotherapy treatment prior to surgery <ref type="bibr" target="#b8">[8]</ref>, hence it is important to determine how a patient will respond to radiotherapy with a personalized approach in order to avoid overtreatment.</p><p>Histology-based digital biomarkers enable the possibility to predict a patient's response to therapy. The consensus molecular subtypes (CMS) classification system derived from gene expressions <ref type="bibr" target="#b9">[9]</ref> has been developed to provide biological insight into metastatic colorectal cancer. It has been shown that these four CMS classes can be predicted directly from the standard haematoxylin and eosin (H&amp;E) stained slide images using deep learning <ref type="bibr" target="#b18">[18]</ref>. Various studies have investigated the link between CMS and patient outcomes, suggesting that patients with tumour classified as CMS4, which features stromal invasion <ref type="bibr" target="#b9">[9]</ref> and shows significantly higher stroma content <ref type="bibr" target="#b15">[15]</ref>, have worse survival rates compared to the other CMS classes <ref type="bibr" target="#b4">[5]</ref>. Increased stromal content has independently been shown to be a predictor for increased risk of recurrence in early rectal cancer <ref type="bibr" target="#b10">[10]</ref>, and tumour immune infiltrate evaluated with Immunoscore is a useful prognostic marker <ref type="bibr" target="#b2">[3]</ref>. The spatial organisation of the cancerous tissue has been identified as a biomarker for aggressiveness or recurrence <ref type="bibr" target="#b12">[12]</ref>, and Qi et al. <ref type="bibr" target="#b15">[15]</ref> found that the features they developed representing spatial organisation reflected characteristics of the four CMS classes. Interactions between the epithelial tissue (cellular tissue lining) and other prevalent tissue types in the tumour microenvironment are also indicators of prognosis <ref type="bibr" target="#b15">[15]</ref>, since progression of colorectal cancer is dependent on both the epithelial and stromal tissues <ref type="bibr" target="#b20">[20]</ref>. Other work has looked at predicting chemoradiotherapy response in rectal cancer patients from H&amp;E images using different approaches, but without providing contextual interpretations <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b22">22]</ref>.</p><p>As opposed to predicting response to radiotherapy alone, we aim to analyse this prediction in the context of the overall tissue architecture and the tumour biology as captured by CMS. Input to our model is a standard H&amp;E Whole Slide Image (WSI) which is split into smaller patches to overcome the memory limitations of existing GPUs. To achieve our goal we need to capture the heterogeneity at the slide level, which is why applying full or semi-supervised approaches on individual tiles followed by a slide aggregation method is not suitable. Instead, we build on recent graph neural network (GNN) approaches that allow us to model the entire WSI as a graph. As local cell communities form the nodes of such a graph it can effectively model the micro-anatomy of the tissue. At the same time it is possible to make predictions at the node-, graph-, and slide-level. Related Work. To predict the grading of colorectal cancer (CRC), both cellbased and patch-based graphs have been used in separate works <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b23">23]</ref>, setting the nodes of the graph as either cell nuclei or square patches, defining the node features as either handcrafted or learned features, and then applying a GNN for outcome prediction. Another patch-based GNN approach to predicting genetic mutations in CRC from H&amp;E slides found their model trained on colon cancer generalised well to rectal cancer. For other cancers, the SlideGraph pipeline clusters nuclei for the graph nodes, and provides node-level predictions to make their model more interpretable <ref type="bibr" target="#b13">[13]</ref>. Other approaches to setting the graph nodes include using subgraphs to represent regions <ref type="bibr" target="#b14">[14]</ref>, and creating superpatches by combining patches <ref type="bibr" target="#b11">[11]</ref>. Edges between the nodes are usually defined by a spatial distance metric, which helps model the spatial organisation of the tissue. Common choices for GNNs include a Graph Isomorphism Network (GIN) with jumping connectivity <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b13">13,</ref><ref type="bibr" target="#b14">14]</ref>, as we use in this research.</p><p>Our methodology proposes a novel and disease relevant approach to a more interpretable model that effectively supports a diagnostic task. Pathologists and oncologists can use this information to inspect the validity of the prediction result and interrogate key aspects of the spatial biology that is critical for patient management. Ultimately, this type of information that is not available today will help to characterise interactions between the tumour and the host tissue and therefore help to support choice of therapy. The developed framework combines self-supervised training of a Vision Transformer (ViT) to extract morphological features, a superpixel algorithm for determining nodes of a graph, and a GNN for predictions. We achieve 0.82 AUC predicting complete response to radiotherapy using deep learning on WSIs for CRC patients, whilst providing novel interpretability of the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>In this section we present the patch-level feature extraction, provide the detail of the superpixel segmentation of the WSI, and illustrate the resulting graph presentation. A GNN with three branches for our output predictions is used to simultaneously make the three different predictions as shown in Fig. <ref type="figure" target="#fig_0">1</ref>.</p><p>Pipeline. For computational reasons, all images are split into patches of size 256 × 256 pixels. In order to have a common feature set all the way up to the last layer of the GNN, individual patches should be represented by morphological features that are label-agnostic. This last layer of the GNN then splits into three branches to predict response to radiotherapy, the CMS4 subtype classification for CRC, and epithelial tissue regions. This way we can guarantee the common latent features and derivation across branches, maintaining the contextual importance of each branch. The DINO framework <ref type="bibr" target="#b3">[4]</ref> uses a self-distillation training approach, using data augmentation to locally crop the patches and train with a local-global student-teacher approach. We use the DINO framework to train a ViT in a self-supervised manner on our H&amp;E slides <ref type="bibr" target="#b5">[6]</ref>, representing each patch with 384 features. We use only the training set to train this model, and use the image patches at 20x magnification. We extract patch-level features from each WSI using selfsupervised DINO training with a ViT model <ref type="bibr" target="#b3">[4]</ref>. The SLIC superpixel algorithm segments the entire slide into smaller regions <ref type="bibr" target="#b0">[1]</ref>. We calculate the mean patch features for these superpixel regions, and use the superpixel features and centers as our graph nodes, applying Delaunay triangulation to generate the edges of the graph. A GNN consisting of GINConv layers is trained on these fixed graphs, and the final layer splits into three separate MLP branches to provide predictions of three different outcomes, complete response (CR) to radiotherapy (RT), CMS4 classification, and epithelial tissue. An example output is visualized in Fig. <ref type="figure" target="#fig_1">2</ref>.</p><p>To find the nodes of the WSI graphs, we apply the SLIC superpixel algorithm <ref type="bibr" target="#b0">[1]</ref> on the WSIs at 5x magnification to segment the tissue to capture cellular neighbourhoods that are roughly between 80-100 µm 2 /pixels in size. It can be seen that the superpixel boundaries consistently align with the boundaries of tissue compartments.</p><p>The superpixels centers are used as the nodes of the graph, and the node features are the weighted mean of the corresponding patch features which overlap with the superpixel region. The edges of the graph are determined by nearest neighbours from Delaunay triangulation, as in SlideGraph <ref type="bibr" target="#b13">[13]</ref>.</p><p>Building on the ideas introduced by SlideGraph <ref type="bibr" target="#b13">[13]</ref> we use GINConv layers <ref type="bibr" target="#b21">[21]</ref>, adding tempering to avoid overfitting, and replace their logistic regression scaler with a simple sigmoid function. We add three branches to the final layer of the GNN, in the form of three separate multilayer perceptrons (MLPs). Two of these MLPs return a graph-level prediction, for the response to RT and CMS4 predictions, and the final branch returns node-level predictions, predicting whether each node is epithelial tissue or not. Our loss function is defined as</p><formula xml:id="formula_0">L = BCE(ŷ RT , y RT ) + BCE(ŷ CMS4 , y CMS4 ) + BCE(ŷ epi , y epi ),</formula><p>where BCE is the binary cross entropy loss, ŷRT ∈ R is the slide-level prediction of response to radiotherapy, ŷCMS4 ∈ R is the slide-level prediction of CMS4, ŷepi ∈ R ni are the node-level predictions of epithelial tissue and n i is the number of nodes in the i th WSI graph.</p><p>For each prediction branch, we can visualize the individual node predictions from the WSI graph, overlaid on the WSI itself, to get an idea of how the node predictions vary across the different tissue regions. Each graph-level prediction is derived from the corresponding branch node predictions, by applying pooling and dropout.</p><p>Data. We train and validate our methods on two retrospective rectal cancer datasets, Grampian and Aristotle. Both cohorts received standard chemoradiotherapy of pelvic irradiation (45-50.4Gy in 25 fractions over 5 weeks) with capecitabine 900mg/m 2 . The pre-treatment biopsy slides were all sectioned and stained in the same laboratory, and scanned at 20x magnification (0.5 µm 2 /pixel) on an Aperio scanner. Pathological complete response, which we use as a target outcome here, was derived from histopathological assessment from posttreatment resections.</p><p>The CMS labels for this data are derived from three different transcriptomic versions (single cohort, combined cohort correcting batch effects and combined cohort including 2036 cases run with the same platform), in order to generate robust classifications. In all cases the CMS call was calculated using the CMSclassifier random forest and single sample predictor <ref type="bibr" target="#b9">[9]</ref>. Final CMS calls are based on matching calls between the three transcriptomic versions. Despite our efforts to minimise the noise from RNA sequencing, we still expect a certain level of noise in our ground truth data, which we discuss in the Results section.</p><p>The epithelial labels for each graph node are calculated from epithelial masks for each WSI. These epithelial segmentation masks were generated at 10x magnification (1 µm 2 /pixel) with a U-Net <ref type="bibr" target="#b17">[17]</ref> which was trained and validated on 666 full tissue sections belonging to 362 patients from the FOCUS cohort <ref type="bibr" target="#b18">[18]</ref>. The ground truth annotations for the training of this model were generated by VK.</p><p>For consistency the tumour regions were marked up by an expert pathologist. We use these masks in our analysis to filter out background and irrelevant tissue from the images. Grampian and Aristotle are used in both training and validation, with a 70/30% training-validation split, keeping any WSIs from a single patient in the same dataset. We predict complete response to radiotherapy against all other responses, such as partial response and no response. The datasets are unbalanced, since in Grampian only 61/244 slides have complete response, and in Aristotle only 24/121 slides have complete response. They are even more unbalanced for CMS4, since only 28/244 slides in Grampian and 17/121 slides in Aristotle are labelled with CMS4. We address this imbalance in the Supplementary Materials. There are 365 slides total in our dataset, from 249 patients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>Implementation. We use the default DINO parameters, but train for 20 epochs with 5 warmup epochs. We apply the SLIC algorithm <ref type="bibr" target="#b0">[1]</ref> with compactness of 20, setting the number of segments for each WSI as half the mean size of the WSI. Prior to fitting the graph model we normalize the node features relative to the whole dataset. We train our graph model for 30 epochs using Adam optimizer with learning rate 0.001 and weight decay 0.0001. Our graph model has three GINConv layers <ref type="bibr" target="#b21">[21]</ref> with dimensions 64, 32 and 16 respectively. We apply dropout of 0.5 in-between graph layers, use minimum aggregation for message passing between nodes and use maximum pooling for concatenating the node activations. We apply tempering to the outcome of the graph model, dividing the output by 1.5. We evaluate the best validation epoch by finding the best mean AUC across the three prediction branches. We run the whole pipeline on four folds with different random data splits for training and validation. The code for this research will be made available upon request.</p><p>Table <ref type="table">1</ref>. For each fold, we take the mean metrics for the three branch predictions from the best model on our validation data, with the best epoch chosen based on mean AUC for the three predictions. The standard deviation of the metrics across the four folds is provided in brackets. Each prediction uses an optimised threshold value determined from the validation set in order to round the output probabilities to a binary prediction. We use weighted metrics due to the class imbalance in our dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Response branch</head><p>Response Results. Despite the noise in our reference data used for training, our model achieves good performance in terms of mean AUC scores on all three prediction branches of our model, predicting complete response to radiotherapy (RT) with 0.819 AUC, CMS4 with 0.819 AUC and epithelial tissue at the node level with 0.760 AUC across folds. Further metrics are provided in Table <ref type="table">1</ref>. The prediction performance of the model could be improved by utilising a larger training dataset and performing more exhaustive parameter searches, however the current performance of the model is sufficient to demonstrate the impact of this approach.</p><p>The predicted response to radiotherapy can now be viewed in the context of disease biology as captured by CMS4. For example, the model demonstrates that CMS4 patients are less likely to respond to radiotherapy. In addition, it is now possible to view the spatial distribution of CMS4 active regions in the tissue architecture context as shown in Fig. <ref type="figure" target="#fig_1">2</ref>. Additional samples are presented in the Supplementary Materials. An example of our proposed prediction maps on two slides can be seen in Fig. <ref type="figure" target="#fig_1">2</ref>, with further slides in the Supplementary Materials. A pathologist reviewing these maps assesses that the observed patterns fit the known interplay of response to therapy, CMS4 activation, and the spatial localisation of these signals. In the top slide, we observe high CMS4 activation in stromal rich regions, and interestingly also high CMS4 activation in the bottom center, dissociating from the response to RT activation map. This could be explained by the lymphocyte content, supported by the higher epithelial map activations in the same location. Expert pathologists highlight a similar pattern in certain regions of the maps for the bottom slide. Different from the slide above, the CMS4 and response to RT maps have some overlap with moderate activations here, encouraging discovery into tumour-host interactions. Ultimately, a pathologist confirmed that these maps support an interpretable and trustworthy prediction in the context of response to radiotherapy. While we cannot present a more extensive interpretation of these results due to space limitations, these examples already indicate that the proposed approach enables a level of analysis that has not been possible before. We find that predicting these outcomes individually in a single branch model, particularly with response to radiotherapy, can result in slightly higher AUC scores, but we consciously make this trade-off in order to provide better interpretability of the model predictions. The focus of this research is not to achieve the best possible metrics, but to develop robust methods which can add context and explanation to clinical black box deep learning model predictions, with the view to ease clinical translation of such models.</p><p>To explore the effects of the noisy CMS4 ground truth labels, we remove from our dataset any WSIs classified as 'Unmatched' for the CMS call, which for the main results of this paper we defined as 'Not CMS4'. Removing this data and rerunning our analysis improved our predictions for CMS4 by +0.06 AUC, and reduced our response to radiotherapy and epithelial predictions by -0.02 and -0.01 respectively. The results can be found in the Supplementary Materials. These small changes indicate that the noise in our data does not degrade the performance of our classifier, reinforcing it as a robust and accurate model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>By setting the prediction of response to therapy in context with disease biology and spatial organisation of the tissue we are providing a novel approach for enhancing the interpretablity of complex prediction tasks. These results do not only enhance the interpretability, they also provide new ways to utilise large retrospective clinical trial cohorts for which no additional molecular data is available. Extending the amount of training data and improving model training will improve model performance, which is already impressive.</p><p>We argue that this work also advances the state of the art in feature representation and analysis. Our prediction maps derive from the same graph model, and hence they share underlying graph features. The prediction branches only diverge at the final stage of translating these graph features into outcome predictions for our three clinically relevant outcomes. Importantly, this level of visualisation is not only accessible to pathologists, this joint prediction model also enhances the communication between pathologists and oncologists which is critical for patient management. By cross-referencing these prediction maps with our prior understanding of cancer biology, this approach can help to establish trust in the prediction model and also help to identify potential failure cases.</p><p>This work relies on access to well annotated clinical trial samples which will limit our ability to include more data for training and testing. In future, we plan to use these methods to help better characterise tumour-stromal interactions of the tissue. We also plan to use a denser graph with less connectivity to be able to better predict the heterogeneous epithelial tissue.</p><p>The Aristotle trial was funded by Cancer Research UK (CRUK/08/032). The funders played no role in the analyses performed or the results presented. Financial support: RW -EPSRC Center for Doctoral Training in Health Data Science (EP/S02428X/1), Oxford CRUK Cancer Centre; VHK -Promedica Foundation (F-87701-41-01) and Swiss National Science Foundation (P2SKP3_168322/1, P2SKP3_168322/2); TSM -S:CORT (see above); JR, KS -Oxford NIHR National Oxford Biomedical Research Centre and the PathLAKE consortium (InnovateUK). The computational aspects of this research were funded from the NIHR Oxford BRC with additional support from the Wellcome Trust Core Award Grant Number 203141/Z/16/Z. The views expressed are those of the author(s) and not necessarily those of the NHS, the NIHR or the Department of Health.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. Approach. We extract patch-level features from each WSI using selfsupervised DINO training with a ViT model<ref type="bibr" target="#b3">[4]</ref>. The SLIC superpixel algorithm segments the entire slide into smaller regions<ref type="bibr" target="#b0">[1]</ref>. We calculate the mean patch features for these superpixel regions, and use the superpixel features and centers as our graph nodes, applying Delaunay triangulation to generate the edges of the graph. A GNN consisting of GINConv layers is trained on these fixed graphs, and the final layer splits into three separate MLP branches to provide predictions of three different outcomes, complete response (CR) to radiotherapy (RT), CMS4 classification, and epithelial tissue. An example output is visualized in Fig.2.</figDesc><graphic coords="4,56,46,53,66,339,64,123,04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Node activation maps from the three prediction branches on two different slides, top and bottom. The nodes are coloured by their predictions. Both slides are classified as CMS4 and the patients did not have a complete response to radiotherapy.</figDesc><graphic coords="7,42,30,217,88,339,40,220,96" type="bitmap" /></figure>
		</body>
		<back>

			<div type="funding">
<div><p>Supported by <rs type="funder">Cancer Research UK</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Data Use Declaration and Acknowledgements. The Grampian, Aristotle and FOCUS datasets used in this study were available through the S:CORT consortium. Grampian and Aristotle will be made publicly available shortly. Additional data is available on request to the S:CORT consortium. The S:CORT consortium was reviewed and approved by the South Cambs Research Ethics committee (REC ref 15/EE/0241; IRAS reference 169363). The Stratification in Colorectal Cancer Consortium (S:CORT) was funded by the Medical Research Council and Cancer Research UK (MR/M016587/1).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43904-9_73.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Slic superpixels compared to state-of-the-art superpixel methods</title>
		<author>
			<persName><forename type="first">R</forename><surname>Achanta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shaji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lucchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Süsstrunk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2274" to="2282" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Biomarkers and cell-based models to predict the outcome of neoadjuvant therapy for rectal cancer patients</title>
		<author>
			<persName><forename type="first">A</forename><surname>Alkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hofving</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Angenete</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Yrlid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomark. Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Prognostic and predictive values of the immunoscore in patients with rectal cancer</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Anitei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clin. Cancer Res</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1891" to="1899" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Emerging properties in self-supervised vision transformers</title>
		<author>
			<persName><forename type="first">M</forename><surname>Caron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Computer Vision (ICCV</title>
		<meeting>the International Conference on Computer Vision (ICCV</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Genomic and transcriptomic determinants of response to neoadjuvant therapy in rectal cancer</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chatila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Walch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1646" to="1655" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Self-supervised vision transformers learn visual concepts in histopathology</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Krishnan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Feature-enhanced graph networks for genetic mutational prediction using histopathological images in colon cancer</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">12262</biblScope>
			<biblScope unit="page" from="294" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Cham</forename><surname>Springer</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59713-9_29</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-59713-9_29" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Neoadjuvant rectal (NAR) score: a new surrogate endpoint in rectal cancer clinical trials</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J J</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Allegra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yothers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Colorect. Cancer Rep</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="275" to="280" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The consensus molecular subtypes of colorectal cancer</title>
		<author>
			<persName><forename type="first">J</forename><surname>Guinney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1350" to="1356" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Stromal composition predicts recurrence of early rectal cancer after local excision</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J S</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Histopathology</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="947" to="956" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Derivation of prognostic contextual histopathological features from whole-slide images of tumours via graph deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biomed. Eng</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Artificial intelligence for multimodal data integration in oncology</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lipkova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer Cell</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1095" to="1110" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Slidegraph+: whole slide image level graphs to predict her2 status in breast cancer</title>
		<author>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Toss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dawood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rakha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Rajpoot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Minhas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page">102486</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Self-supervised graph representations of WSIS</title>
		<author>
			<persName><forename type="first">O</forename><surname>Pina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vilaplana</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First International Workshop on Geometric Deep Learning in Medical Image Analysis. Proceedings of Machine Learning Research</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Bekkers</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Wolterink</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Aviles-Rivero</surname></persName>
		</editor>
		<meeting>the First International Workshop on Geometric Deep Learning in Medical Image Analysis. Machine Learning Research</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">194</biblScope>
			<biblScope unit="page" from="107" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Identification of prognostic spatial organization features in colorectal cancer microenvironment using deep learning on histopathology images</title>
		<author>
			<persName><forename type="first">L</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Omics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">100008</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Graph attention multi-instance learning for accurate colorectal cancer staging</title>
		<author>
			<persName><forename type="first">A</forename><surname>Raju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M H</forename><surname>Haq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jonnagaddala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59722-1_51</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-59722-1_51" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12265</biblScope>
			<biblScope unit="page" from="529" to="539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">U-net: convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Image-based consensus molecular subtype (imcms) classification of colorectal cancer using deep learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sirinukunwattana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Gut</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="544" to="554" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Enhancing local context of histology features in vision transformers</title>
		<author>
			<persName><forename type="first">R</forename><surname>Wood</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-19660-7_15</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-19660-7_15" />
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence over Infrared Images for Medical Applications and Medical Image Assisted Biomarker Discovery</title>
		<imprint>
			<biblScope unit="page" from="154" to="163" />
			<date type="published" when="2022">2022</date>
			<publisher>Springer</publisher>
			<pubPlace>Cham</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A deep convolutional neural network for segmenting and classifying epithelial and stromal regions in histopathological images</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gilmore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Madabhushi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">191</biblScope>
			<biblScope unit="page" from="214" to="223" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">How powerful are graph neural networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Predicting treatment response to neoadjuvant chemoradiotherapy in local advanced rectal cancer by biopsy digital pathology image features</title>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clin. Transl. Med</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">110</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">CGC-net: cell graph convolutional network for grading of colorectal cancer histology images</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Koohbanani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shaban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Rajpoot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF International Conference on Computer Vision Workshops</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="388" to="398" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
