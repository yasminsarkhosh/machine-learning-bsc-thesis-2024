<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Amoon</forename><surname>Jamzad</surname></persName>
							<email>a.jamzad@queensu.ca</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">Queen&apos;s University</orgName>
								<address>
									<settlement>Kingston</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fahimeh</forename><surname>Fooladgar</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of British Columbia</orgName>
								<address>
									<settlement>Vancouver</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Laura</forename><surname>Connolly</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">Queen&apos;s University</orgName>
								<address>
									<settlement>Kingston</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dilakshan</forename><surname>Srikanthan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">Queen&apos;s University</orgName>
								<address>
									<settlement>Kingston</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ayesha</forename><surname>Syeda</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">Queen&apos;s University</orgName>
								<address>
									<settlement>Kingston</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Martin</forename><surname>Kaufmann</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Surgery</orgName>
								<orgName type="institution">Queen&apos;s University</orgName>
								<address>
									<settlement>Kingston</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kevin</forename><forename type="middle">Y M</forename><surname>Ren</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Pathology and Molecular Medicine</orgName>
								<orgName type="institution">Queen&apos;s University</orgName>
								<address>
									<settlement>Kingston</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shaila</forename><surname>Merchant</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Surgery</orgName>
								<orgName type="institution">Queen&apos;s University</orgName>
								<address>
									<settlement>Kingston</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jay</forename><surname>Engel</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Surgery</orgName>
								<orgName type="institution">Queen&apos;s University</orgName>
								<address>
									<settlement>Kingston</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sonal</forename><surname>Varma</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Pathology and Molecular Medicine</orgName>
								<orgName type="institution">Queen&apos;s University</orgName>
								<address>
									<settlement>Kingston</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gabor</forename><surname>Fichtinger</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">Queen&apos;s University</orgName>
								<address>
									<settlement>Kingston</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">John</forename><forename type="middle">F</forename><surname>Rudan</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Surgery</orgName>
								<orgName type="institution">Queen&apos;s University</orgName>
								<address>
									<settlement>Kingston</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Parvin</forename><surname>Mousavi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">Queen&apos;s University</orgName>
								<address>
									<settlement>Kingston</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="562" to="571"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">6CEACBEC6979F4F8FAF5263695CD0676</idno>
					<idno type="DOI">10.1007/978-3-031-43990-2_53</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-24T11:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Intra-operative deployment</term>
					<term>Uncertainty estimation</term>
					<term>Interpretation</term>
					<term>Graph transformer network</term>
					<term>Breast cancer margin</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>PURPOSE: The use of intra-operative mass spectrometry along with Graph Transformer models showed promising results for margin detection on ex-vivo data. Although highly interpretable, these methods lack the ability to handle the uncertainty associated with intraoperative decision making. In this paper for the first time, we propose Evidential Graph Transformer network, a combination of attention mapping and uncertainty estimation to increase the performance and interpretability of surgical margin assessment. METHODS: The Evidential Graph Transformer was formulated to output the uncertainty estimation along with intermediate attentions. The performance of the model was compared with different baselines in an ex-vivo cross-validation scheme, with extensive ablation study. The association of the model with clinical features were explored. The model was further validated for a prospective ex-vivo data, as well as a breast conserving surgery intra-operative data. RESULTS: The purposed model outperformed all baselines, statistically significantly, with average balanced accuracy of 91.6%. When applied to intra-operative data, the purposed model improved the false positive rate of the baselines. The estimated attention distribution for status of different hormone receptors agreed with reported metabolic findings in the literature. CONCLUSION: Deployment of ex-vivo models is challenging due to the tissue heterogeneity of intra-operative data. The proposed Evidential Graph Transformer is a powerful tool that while providing the attention distribution of biochemical subbands, improve the surgical deployment power by providing decision confidence.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Achieving complete tumor resection in surgical oncology like breast conserving surgery (BCS) is challenging as boundaries of tumors are not always visible/ palpable <ref type="bibr" target="#b9">[10]</ref>. In BCS the surgeon removes breast cancer while attempting to preserve as much healthy tissue as possible to prevent permanent deformation and to enhance cosmesis. The current standard of care for evaluating surgical success is to investigate the resection margins, which refers to the area surrounding the excised tumor. Up to 30% of surgeries result in incomplete tumor resection and require a revision operation <ref type="bibr" target="#b9">[10]</ref>. The intelligent knife (iKnife) is a mass spectrometry device that can address this challenge by analyzing the biochemical signatures of resected tissue using the smoke that is released during tissue incineration <ref type="bibr" target="#b2">[3]</ref>. Each spectrum contains the distribution of sampled ions with respect to their mass to charge ratio (m/z). Previously, learning models have been used in combination with iKnife data for ex-vivo tissue characterization and real-time margin detection <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>.</p><p>The success of clinical deployment of learning models heavily relies on approaches that are not only accurate but also interpretable. Therefore, it should be clear how models reach their decisions and the confidence they have in such decision. Studies suggest that one way to improve these factors is through data centric approaches i.e. to focus on appropriate representation of data. Specifically, representation of data as graphs has been shown to be effective for medical diagnosis and analysis <ref type="bibr" target="#b0">[1]</ref>. It has also been shown that graph neural networks can accurately capture the biochemical signatures of iKnife and determine the tissue type. Particularly, Graph Transformer Networks (GTN) has have shown to further enhance the transparency of underlying relation between the graph nodes and decision making via attention mechanism <ref type="bibr" target="#b10">[11]</ref>.</p><p>Biological data, specially those acquired intra-opertively, are heterogeneous by nature. While the use of ex-vivo data collected under specific protocols are beneficial to develop baseline models, intra-operative deployment of these models is challenging. For iKnife, the ex-vivo data is usually collected from homogeneous regions of resected specimens under the guidance of a trained pathologist, versus the intra-operative data is recorded continuously while the surgeon cutting through tissues with different heterogeneity and pathology. Therefore, beyond predictive power and explainable decision making, intra-operative models must be able to handle mixed and unseen pathology labels.</p><p>Uncertainty-aware models in computer-assisted interventions can provide clinicians with feedback on prediction confidence to increase their reliability during deployment. Deep ensembles <ref type="bibr" target="#b14">[15]</ref> and Bayesian networks <ref type="bibr" target="#b8">[9]</ref> incur high runtime and computational cost both at training and inference time and thus, less practical for real-time computer-assisted interventions. Evidential Deep Learning <ref type="bibr" target="#b17">[18]</ref> is another approach that has been proposed based on the evidence framework of Dempster-Shafer Theory <ref type="bibr" target="#b11">[12]</ref>. Since the evidential approach jointly generates the network prediction and uncertainty estimation, it seems more suitable for computationally efficient intra-operative deployment. In this paper, we propose Evidential Graph Transformer (EGT), a combination of graph-based feature-level attention mechanism with sample-level uncertainty estimation, to increase the performance and interpretability of surgical margin assessment. This is done by implementing the evidential loss and prediction functions within a graph transformer model to output the uncertainty, intermediate attention, and model prediction. To demonstrate the state-of-theart performance of the proposed approach on mass spectrometry data, the model is compared with different baselines in both cross-validation and prospective schemes on ex-vivo data. Furthermore, the performance of model is also investigated intraoperatively. In addition to the proposed model, we present a new visualization approach to better correlate the graph nodes with the spectral content of the data, which improves interpretability. In addition to the ablation study on the network and graph strictures, we also investigate the metabolic association of breast cancer hormone receptor status.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Materials and Methods</head><p>Figure <ref type="figure" target="#fig_0">1</ref> presents the overview of the proposed approach. Following data collection and curation, each burn (spectrum) is converted to a single graph structure. The proposed graph model learns from the biochemical signatures of the tissue to classify cancer versus normal tissue. The uncertainty and intermediate attentions generated by the model are visualized and explored for their association with the biochemical mechanisms of cancer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data Curation</head><p>Ex-vivo: Data is collected from fresh breast tissue samples from the patients referred to BCS at Kingston Health Sciences Center over two years. The study is approved by the institutional research ethics board and patients consent to be included. Peri-operatively, a pathologist guides and annotates the ex-vivo pointburns, referred to as spectra, from normal or cancerous breast tissue immediately after excision. In addition to spectral data, clinicopathological details such as the status of hormone receptors is also provided post-surgically. In total 51 cancer and 149 normal spectra are collected and stratified into five folds (4 for cross validation and 1 prospectively) with each patient restricted to one fold only.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Intra-operative:</head><p>A stream of iKnife data is collected during a BCS case (27 min) at Kingston Health Sciences Center. At the sampling rate of 1 Hz, a total of 1616 spectra are recorded. Each spectrum is then labeled based both on surgeons comments during the operation and post-operative pathology report.</p><p>Preprocessing: Each spectrum is converted to a hierarchical graph as illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>. The nodes are generated from a specific subband in each spectrum. Different subband widths (50, 100, 300, and 900 m/z) are used to create different levels of hierarchy (Fig. <ref type="figure" target="#fig_1">2</ref>). The edges connect nodes with overlapping subbands within and between levels. As a result, each graph (spectrum) consists of 58 nodes and 135 edges. For details on graph conversion please refer to <ref type="bibr" target="#b1">[2]</ref> and <ref type="bibr" target="#b10">[11]</ref>. For easier interpretation of nodes with respect to their corresponding subbands, we visualize the graph as a Piano-key plot in Fig. <ref type="figure" target="#fig_1">2</ref>, where each key represents a node with m/z range equal to the angular extent of the key. The dark keys show the subband overlaps between adjacent nodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Network Architecture and Training</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph Transformer Network:</head><p>The GTN consists of a node embedding layer, L Graph Transformer Layers (GTL), a node aggregation layer, multiple dense layers, and a prediction layer <ref type="bibr" target="#b7">[8]</ref>. Assume a graph G with N nodes and h i ∈ R d×1 as node features of node i. In each GTL, the H headed attention mechanism updates the features of node i based on all neighboring node features h j that are directly connected to node i via e ij edges. The attention mechanism for node update at layer l + 1 is formulated as:</p><formula xml:id="formula_0">w k,l ij = sof tmax j Q k,l h l i • K k,l h l j √ d , ĥl+1 i = O l H k=1 ⎛ ⎝ j∈Ni w k,l ij V k,l h l j ⎞ ⎠<label>(1)</label></formula><p>where Q k,l , K k,l , and V k,l are trainable linear weights. The weights w kl ij defines the k-th attention that is paid by node j to update node i at layer l. The concatenation of all H attention heads multiplied by trainable parameters O l generates final attention ĥl+1 i , which is passed through batch normalization and residual layers to update the node features for the next layer. After the last GTL, features from all nodes are aggregated, then passed to the dense layers to construct a final prediction output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evidential Graph Transformer:</head><p>Evidential deep learning provides a welldefined theoretical framework to jointly quantify classification prediction and uncertainty modeling by assuming the class probability follows a Dirichlet distribution <ref type="bibr" target="#b17">[18]</ref>. We propose to modify the loss and prediction layer of GTN, considering the same assumption, to formulate the Evidential Graph Transformer model. Therefore, there are two mechanisms embedded in EGT: i) node-level attention calculation -via aggregation of neighboring nodes according to their relevance to the predictions, and ii) graph-level uncertainty estimation -via fitting the Dirichlet distribution to the predictions.</p><p>In the context of surgical margin assessment, the attentions reveal the relevant metabolic ranges to cancerous tissue, while uncertainty helps identify and filter data with unseen pathology. Specifically, the attentions affect the predictions by selectively emphasizing the contributions of relevant nodes, enabling the model to make more accurate predictions. On the other hand, the spread of the outcome probabilities as modeled by the Dirichlet distribution represents the confidence in the final predictions. Combining the two provides interpretable predictions along with the uncertainty estimation.</p><p>Mathematically, the Dirichlet distribution is characterized by α = [α 1 , ..., α C ] where C is the number of classes in the classification task. The parameters can be estimates as α = f (x i |Θ) + 1 where f (x i |Θ) is the output of the Evidential Graph Transformer parameterized by Θ for each sample(x i ). Then, the expected probability for the c-th class p c and the total uncertainty u for each sample (x i ) can be calculated as p c = αc S , and u = C S , respectively, where S = C c=1 α c . To fit the Dirichlet distribution to the output layer of our network, we use a loss function consisting of the prediction error L p i and the evidence adjustment</p><formula xml:id="formula_1">L e i L i (Θ) = L p i (Θ) + λL e i (Θ) (<label>2</label></formula><formula xml:id="formula_2">)</formula><p>where λ is the annealing coefficient to balance the two terms. L p i can be crossentropy, negative log-likelihood, or mean square error , while L e i (Θ) is KL divergence to the uniform Dirichlet distribution <ref type="bibr" target="#b17">[18]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Network/Graph Ablation:</head><p>We explore the hyper-parameters of the proposed model in an extensive ablation study. The attention parameters include the number of attention heads ( 1-15 with step size of 2) and the number of hidden features <ref type="bibr" target="#b6">(7)</ref><ref type="bibr" target="#b7">(8)</ref><ref type="bibr" target="#b8">(9)</ref><ref type="bibr" target="#b9">(10)</ref><ref type="bibr" target="#b10">(11)</ref><ref type="bibr" target="#b11">(12)</ref><ref type="bibr" target="#b12">(13)</ref><ref type="bibr" target="#b13">(14)</ref>. For the evidential loss, we evaluate the choice of loss function (the 3 previously mentioned), and the annealing coefficient (5-50 with step size of 5). The number of GTLs and dense layers are both fixed at 3. Additionally, we run ablation studies on the graph structure themselves to show the importance of presenting the data as graphs. We try randomizing the edge connections and dropping the nodes with overlapping m/z subbands.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ex-vivo Evaluation:</head><p>The performance of the proposed network is compared with 3 baseline models including GTN, graph convolution network <ref type="bibr" target="#b13">[14]</ref>, and non-graph convolution network. Four-fold cross validation is used for comparison of the different approaches, to increase the generalizability (3 folds for train/validation, test on remaining unseen fold, report average test performance). Separate ablation studies are performed for the baseline models to fine tune their structural parameters. All experiments are implemented using PyTorch with Adam optimizer, learning rate of 10 -4 , batch size of 32, and early stopping based on validation loss. To demonstrate the robustness of the model and ensure it is not overfitting, we also report the performance of the ensemble model from the 4-fold cross validation study on the 5th unseen prospective test fold.</p><p>Clinical Relevance: Hormone receptor status plays an important role in determining breast cancer prognosis and tailoring treatment plans for patients <ref type="bibr" target="#b5">[6]</ref>. Here, we explore the correlation of the attention maps generated by EGT with the status of HER2 and PR hormones associated with each spectrum. These hormones are involved in different types of signaling that the cell depends on <ref type="bibr" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Intra-operative Deployment:</head><p>To explore the intra-operative capability of the models, we deploy the ensemble models of the proposed method as well as the baselines from the cross-validation study to the BCS iKnife stream.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results and Discussion</head><p>Ablation Study and Ex-vivo Evaluation: According to our ablation study, hyper parameters of 11 attention heads, 11 hidden features per attention head, the cross entropy loss function, and annealing coefficient of 30, result in higher performances when compared to other configurations (370k learnable parameters). The performance of EGT in comparison with the mentioned baselines are summarized in Table <ref type="table">1</ref>. As can be seen, the proposed EGT model with average accuracy of 94.1% outperformed all the baselines statistically significantly (maximum p-values of 0.02 in one-tail paired Wilcoxon Signed-Rank test). The lower standard deviation of parameters shows the robustness of EGT compared to other baselines. The regularization term in EGT loss prevents overconfident estimation of incorrect predictions <ref type="bibr" target="#b17">[18]</ref> that could lead to superior results, compared to GTN, without overfitting. Lastly, when compared to other state-ofthe-art baselines with uncertainty estimation mechanisms, the proposed Evidential Graph Transformer network (average balanced accuracy of 91.6 ± 4.3% in Table <ref type="table">1</ref>) outperforms MC Dropout <ref type="bibr" target="#b8">[9]</ref>, Deep Ensembles <ref type="bibr" target="#b14">[15]</ref>, and Masksembles <ref type="bibr" target="#b6">[7]</ref> (86.1 ± 5.7%, 88.5 ± 6.8%, and 89.2 ± 5.4% respectively <ref type="bibr" target="#b18">[19]</ref>).</p><p>The estimated probabilities in evidence based models are directly correlated with model confidence and therefore more interpretable. To demonstrate this, Table <ref type="table">1</ref>. Average(standard deviation) of accuracy (ACC), balanced accuracy (BAC) Sensitivity (SEN), Specificity (SPC), and the area under the curve (AUC) for the proposed Evidential Graph Transformer in comparison with graph transformer (GTN), graph convolution (GCN), and non-graph convolution (CNN) baselines. the probability of cancer predictions and uncertainty scores for all test samples are visualized in the left plot of Fig. <ref type="figure" target="#fig_2">3</ref>. As seen, the higher the uncertainty score (bottom bar plot), the closer the estimated cancer probability is to 0.5 (top bar plot). This information can be provided during deployment to further augment surgical decision making for uncertain data instances. This is demonstrated in the right plot of Fig. <ref type="figure" target="#fig_2">3</ref>, where the samples with high uncertainties are gradually disregarded. It can be seen that by not using the network prediction for up to 10% of most uncertain test data, the AUC increases to 1. Providing surgeons with not only the model decision but also a measure of model confidence will improve their intervention decisions. For example, if the model has low confidence in a prediction they can reinforce their decision by other means. The result of our graph structure ablation shows the drop of average ACC to 85.6% by randomizing the edges in the graph (p-value 0.004). Dropping overlapping nodes further decreased the ACC to 82.3% (p-value 0.001). Although the model still trained due to node aggregation, random graph structure acts as noise and affects the performance. Multi-level graphs were shown to outperform other structures for masspect data <ref type="bibr" target="#b1">[Akbarifar 2021</ref>] as they preserve the receptive field in the neighborhood of subbands (metabolites).  Clinical Relevance: An appropriate visualization of the attention map for samples can be used to help with this exploration. Accumulating the attentions maps from the cancerous burns based on their hormone receptor status results in the representative maps demonstrated in Fig. <ref type="figure" target="#fig_3">4</ref>. The polar bars in this figure show the attention level paid to the nodes in the associated m/z subband. It can be seen that more attention is paid to the amino acids range (100-350 m/z) in HER2 positive breast cancer in comparison to HER2 negative breast cancer, which is in accordance with previous literature that has found evidence for higher glutamine metabolism activity in HER2+ <ref type="bibr" target="#b12">[13]</ref>. we have also found that there's more attention in this range for PR negative breast cancer in comparison PR positive, which is in concordance with previous literature demonstrating that these subtypes have higher glutamine metabolic activity <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Intra-operative Deployment:</head><p>The raw intra-operative iKnife data (y-axis is m/z spectral range and x-axis is the surgery timeline) along with the temporal reference labels extracted from surgeon's call-outs and pathology report are shown in Fig. <ref type="figure" target="#fig_4">5</ref>, top. As seen, the iKnife stream contains spectra from skin cuts, which is considered as an unseen label for the ex-vivo models. The results of deploying the proposed models and baselines are presented in Fig. <ref type="figure" target="#fig_4">5</ref>, bottom. When a spectrum is classified as cancer, a red line is overlaid on the timeline. Previous studies showed the similarity between skin and breast cancer mass spectrum that can confuse the binary models. Since our proposed EGT is equipped with uncertainty estimation, this information can be used to eliminate skin spectra from being wrongly detected as cancer. By integrating uncertainty, predictions for such burns are flagged as uncertain so clinicians can compensate for surgical decision making with other sources of information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>Intra-operative deployment of deep learning solutions requires a measure of interpretability as well as predictive confidence. These two factors are particularly importance to deal with heterogeneity of tissues which represented as mixed or unseen labels for the retrospective models. In this paper, we propose an Evidential Graph Transformer for margin detection in breast cancer surgery using mass spectrometry with these benefits in mind. This structure combines the attention mechanisms of graph transformer with predictive uncertainty. We demonstrate the significance of this model in different experiments. It has been shown that the proposed architecture can provide additional insight and consequently clearer interpretation of surgical margin characterization and clinical features like status of hormone receptors. In the future, we plan to work on other uncertainty estimation approaches and further investigate the graph conversion technique to be more targeted on the metabolic pathways, rather than regular conversion.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. An overview of the proposed approach including data collection and preprocessing, graph conversion, and interpretation of uncertainty and attentions.</figDesc><graphic coords="3,44,79,53,81,334,51,104,89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Graph conversion: each spectrum is converted to a multi-level hierarchical graph. For intuitive interpretation of the process, Piano-key visualization is introduced. Each key represent a node with m/z range equal to the angular extent of the key.</figDesc><graphic coords="4,58,98,53,87,334,51,100,84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Left Estimated probabilities and uncertainty scores for data samples in test set. Right Effect of uncertain data exclusion on accuracy and AUC during model deployment.</figDesc><graphic coords="7,44,79,202,52,334,51,102,67" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Visualization of attention distribution for HER2 (left) and PR (right) hormone receptors in cancerous spectra.</figDesc><graphic coords="8,58,47,53,78,335,95,77,92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Intra-operative data and label from a BCS case (top) and the temporal prediction of different ex-vivo models (bottom).</figDesc><graphic coords="8,58,98,178,10,334,63,150,19" type="bitmap" /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Graph-based deep learning for medical diagnosis and analysis: past, present and future</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ahmedt-Aristizabal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Armin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Denman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fookes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Petersson</surname></persName>
		</author>
		<idno type="DOI">10.3390/S21144758</idno>
		<ptr target="https://doi.org/10.3390/S21144758" />
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page">4758</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Graph-based analysis of mass spectrometry data for tissue characterization with application in basal cell carcinoma surgery</title>
		<author>
			<persName><forename type="first">F</forename><surname>Akbarifar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE Medical Imaging: Image-Guided Procedures, Robotic Interventions, and Modeling</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">11598</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">In vivo endoscopic tissue identification by rapid evaporative ionization mass spectrometry (REIMS)</title>
		<author>
			<persName><forename type="first">J</forename><surname>Balog</surname></persName>
		</author>
		<idno type="DOI">10.1002/anie.201502770</idno>
		<ptr target="https://doi.org/10.1002/anie.201502770" />
	</analytic>
	<monogr>
		<title level="j">Angewandte Chemie Int. Ed</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">38</biblScope>
			<biblScope unit="page" from="11059" to="11062" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Glutamate enrichment as new diagnostic opportunity in breast cancer</title>
		<author>
			<persName><forename type="first">J</forename><surname>Budczies</surname></persName>
		</author>
		<idno type="DOI">10.1002/ijc.29152</idno>
		<ptr target="https://doi.org/10.1002/ijc.29152" />
	</analytic>
	<monogr>
		<title level="j">Int. J. Cancer</title>
		<imprint>
			<biblScope unit="volume">136</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1619" to="1628" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Glutamine metabolism drives growth in advanced hormone receptor positive breast cancer</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Demas</surname></persName>
		</author>
		<idno type="DOI">10.3389/fonc.2019.00686</idno>
		<ptr target="https://doi.org/10.3389/fonc.2019.00686" />
	</analytic>
	<monogr>
		<title level="j">Front. Oncol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hormone receptor status, tumor characteristics, and prognosis: a prospective cohort of breast cancer patients</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Dunnwald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Rossing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">I</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1186/bcr1639</idno>
		<ptr target="https://doi.org/10.1186/bcr1639" />
	</analytic>
	<monogr>
		<title level="j">Breast Cancer Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Masksembles for uncertainty estimation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Durasov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bagautdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Baque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="13539" to="13548" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A generalization of transformer networks to graphs</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">P</forename><surname>Dwivedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Methods and Applications, AAAI Workshop on Deep Learning on Graphs</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Dropout as a Bayesian approximation: Representing model uncertainty in deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 33rd International Conference on Machine Learning. Proceedings of Machine Learning Research</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Balcan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<meeting>The 33rd International Conference on Machine Learning. Machine Learning Research<address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2016-06">June 2016</date>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="20" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Intra-operative guidance: methods for achieving negative margins in breast conserving surgery</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Hargreaves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Audisio</surname></persName>
		</author>
		<idno type="DOI">10.1002/JSO.23645</idno>
		<ptr target="https://doi.org/10.1002/JSO.23645" />
	</analytic>
	<monogr>
		<title level="j">J. Surg. Oncol</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="25" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Graph transformers for characterization and interpretation of surgical margins</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jamzad</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87234-2_9</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87234-29" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12907</biblScope>
			<biblScope unit="page" from="88" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Jsang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-42337-1</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-42337-1" />
		<title level="m">Subjective Logic: A Formalism for Reasoning Under Uncertainty</title>
		<imprint>
			<publisher>Cham Verlag</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Expression of glutamine metabolismrelated proteins according to molecular subtype of breast cancer</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Koo</surname></persName>
		</author>
		<idno type="DOI">10.1530/ERC-12-0398</idno>
		<ptr target="https://doi.org/10.1530/ERC-12-0398" />
	</analytic>
	<monogr>
		<title level="j">Endocrine-Related Cancer</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="339" to="348" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Simple and scalable predictive uncertainty estimation using deep ensembles</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Domain adaptation and self-supervised learning for surgical margin detection</title>
		<author>
			<persName><forename type="first">A</forename><surname>Santilli</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11548-021-02381-6</idno>
		<idno>11548-021-02381-6</idno>
		<ptr target="https://doi.org/10.1007/s" />
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Assist. Radiol. Surg</title>
		<imprint>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Self-supervised learning for detection of breast cancer in surgical margins with limited data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Santilli</surname></persName>
		</author>
		<idno type="DOI">10.1109/ISBI48211.2021.9433829</idno>
		<ptr target="https://doi.org/10.1109/ISBI48211.2021.9433829" />
	</analytic>
	<monogr>
		<title level="m">Proceedings -International Symposium on Biomedical Imaging</title>
		<meeting>-International Symposium on Biomedical Imaging</meeting>
		<imprint>
			<date type="published" when="2021-04">April 2021. April 2021</date>
			<biblScope unit="page" from="980" to="984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Evidential deep learning to quantify classification uncertainty</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sensoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kandemir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Self-supervision and uncertainty estimation in surgical margin detection</title>
		<author>
			<persName><forename type="first">A</forename><surname>Syeda</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
