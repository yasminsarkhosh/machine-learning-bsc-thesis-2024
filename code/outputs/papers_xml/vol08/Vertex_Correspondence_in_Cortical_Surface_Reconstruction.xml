<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Vertex Correspondence in Cortical Surface Reconstruction</title>
				<funder>
					<orgName type="full">German Research Foundation</orgName>
				</funder>
				<funder>
					<orgName type="full">Leibniz Supercomputing Centre</orgName>
				</funder>
				<funder ref="#_JfyR69q">
					<orgName type="full">Federal Ministry of Education and Research in the call for Computational Life Sciences</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Anne-Marie</forename><surname>Rickmann</surname></persName>
							<email>arickman@med.lmu.de</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Lab for Artificial Intelligence in Medical Imaging</orgName>
								<orgName type="institution">Ludwig Maximilians University</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Radiology</orgName>
								<orgName type="institution">Technical University Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><surname>Fabian Bongratz</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Radiology</orgName>
								<orgName type="institution">Technical University Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Christian</forename><surname>Wachinger</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Lab for Artificial Intelligence in Medical Imaging</orgName>
								<orgName type="institution">Ludwig Maximilians University</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Radiology</orgName>
								<orgName type="institution">Technical University Munich</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Vertex Correspondence in Cortical Surface Reconstruction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">ADA1C387240AD72DECC0FFB3168F3349</idno>
					<idno type="DOI">10.1007/978-3-031-43993-3_31</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-24T11:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Mesh-based cortical surface reconstruction is a fundamental task in neuroimaging that enables highly accurate measurements of brain morphology. Vertex correspondence between a patient's cortical mesh and a group template is necessary for comparing cortical thickness and other measures at the vertex level. However, post-processing methods for generating vertex correspondence are time-consuming and involve registering and remeshing a patient's surfaces to an atlas. Recent deep learning methods for cortex reconstruction have neither been optimized for generating vertex correspondence nor have they analyzed the quality of such correspondence. In this work, we propose to learn vertex correspondence by optimizing an L1 loss on registered surfaces instead of the commonly used Chamfer loss. This results in improved inter-and intra-subject correspondence suitable for direct group comparison and atlas-based parcellation. We demonstrate that state-of-the-art methods provide insufficient correspondence for mapping parcellations, highlighting the importance of optimizing for accurate vertex correspondence.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The reconstruction of cortical surfaces from brain MRI scans, a fundamental process in neuroimaging, involves extracting the pial surface (outer cerebral cortex layer) and the white matter surface (white-gray matter boundary). Various methods, including FreeSurfer <ref type="bibr" target="#b7">[8]</ref> and CAT12 <ref type="bibr" target="#b4">[5]</ref>, have been widely employed for cortical surface reconstruction. While a single patient's surface can be used for computing metrics such as cortical thickness, curvature, and gyrification, one of the main objectives of reconstructing cortical surfaces is to perform group comparisons, which are essential for detecting differences in brain structures between patients and healthy control groups. To enable such comparisons, it is necessary to establish point-to-point correspondence between the vertices of a patient's cortical mesh and a group template. This allows for measures such as cortical thickness to be compared at the vertex level. In addition, vertex correspondence enables the mapping of an atlas parcellation from the template onto individual surfaces, which is useful for comparing measures at a regional level. This includes computing cortical thickness for specific parcels, which has wide applications for studying cortex maturation, as well as, aging-and disease-related cortical atrophy <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21]</ref>. Currently, vertex correspondence is generated in a post-processing step, which is a time-consuming process that typically involves registering and remeshing a patient's surfaces to an atlas <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9]</ref>. Therefore, directly generating surfaces with vertex correspondence would be valuable for fast, reliable, and accurate cortical surface comparison. Recently, several deep learning methods for cortex reconstruction have emerged, including DeepCSR <ref type="bibr" target="#b3">[4]</ref>, Vox2Cortex <ref type="bibr" target="#b2">[3]</ref>, CorticalFlow <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b18">19]</ref>, CortexODE <ref type="bibr" target="#b14">[15]</ref>, and Topofit <ref type="bibr" target="#b10">[11]</ref>. These methods can be divided into two categories: (i) implicit surface reconstruction methods, and (ii) explicit template deformation methods. Implicit surface reconstruction methods represent a 2D surface as a signed distance function and rely on mesh extraction and topology correction, which can be computationally demanding and result in geometric artifacts <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b12">13]</ref>. Explicit deformation approaches for cortical surface reconstruction take a template mesh as input to the deep learning model, where a vertex-wise deformation field is learned conditioned on 3D MRI scans. One advantage of mesh-based methods in cortical surface reconstruction is that the sphere-like topology of neural tissue boundaries can already be incorporated into the template mesh. As a result, there is no need for topology correction during the reconstruction process. The main challenge with these methods is generating smooth and watertight output meshes, i.e., ensuring a diffeomorphic mapping from the input to the output mesh. Researchers have addressed this issue through regularization losses <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b10">11]</ref> or numerical integration of a deformation-describing ODE <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b18">19]</ref>. The connectivity of the output mesh is mostly determined by the template mesh, with potential up-or down-sampling of the mesh resolution. Keeping the mesh resolution constant facilitates comparisons between reconstructed surfaces as the output mesh has the same number of vertices and vertex connectivity as the input mesh. Despite maintaining constant mesh resolution, Vox2Cortex <ref type="bibr" target="#b2">[3]</ref> (V2C), Cor-ticalFlow++ <ref type="bibr" target="#b18">[19]</ref> (CFPP), and Topofit <ref type="bibr" target="#b10">[11]</ref> have not focused on optimizing or evaluating the accuracy of vertex correspondence. In this work, we propose a novel surface reconstruction approach that natively provides correspondence to a template without the need for spherical registration, see Fig. <ref type="figure" target="#fig_0">1</ref>. We achieve this by training on meshes with vertex correspondence instead of meshes that vary in the number of vertices and vertex connectivity. For the network to learn these correspondences, we replace the commonly used Chamfer loss with the L1 loss, which has not yet been used for cortical surface reconstruction. We use V2C as our backbone network as it is fast to train and provides white and pial surfaces for both hemispheres with one network, but our approach is generic and can also be integrated in other surface reconstruction methods. We term our method Vox2Cortex with Correspondence (V2CC). We demonstrate that template deformation methods trained with the Chamfer loss, such as V2C, Topofit, and CFPP, provide vertex correspondences that are insufficient for mapping parcellations. Instead, our approach results in improved interand intra-subject vertex correspondence, making it suitable for direct group comparison and atlas-based parcellation. Top: Overview of existing cortical surface reconstruction approaches, that are dependent on a cumbersome spherical registration as post-processing to obtain vertex correspondence to a template. Bottom: Our approach directly yields surface predictions with correspondence to the input template and does not require any registration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>Fig. <ref type="figure">2</ref>. Overview of our V2CC method. The ground truth mesh is registered to the template mesh in a pre-processing step, allowing to compute the L1 loss on the vertex locations. We use V2C <ref type="bibr" target="#b2">[3]</ref> as the surface reconstruction network. Vertex correspondence to the template enables direct mapping of an atlas parcellation at inference.</p><p>In cortical surface reconstruction, template deformation methods transform a mesh template to match the neuroanatomy of the given patient. Let M x be the triangular mesh template, where</p><formula xml:id="formula_0">M x = {V x , F x , E x }, contains n vertices, repre- sented as V x ∈ R n×3 , o faces F x ∈ R o×3</formula><p>, storing the indices of the respective vertices that make up the triangles, and r edges E ∈ R r×2 , storing the indices of two adjacent faces that share a common edge. The surface reconstruction algorithm computes the displacement f : R n×3 → R n×3 for the set of vertices V x . In V2C, this displacement is computed by a graph convolutional network, which is conditioned on image features from a convolutional neural network that takes the MRI scan as input. The two sub-networks are connected via feature-sampling modules that map features extracted by the CNN to vertex locations of the meshes. V2C addresses the issue of self-intersections in explicit surface reconstruction methods by incorporating multiple regularization terms into the loss function. Let M y = {V y , F y , E y } be the ground truth mesh, and M ŷ = {V ŷ , F ŷ , E ŷ } the predicted deformed mesh, where Vy ∈ R n×3 , and V y ∈ R m×3 . Note that n = m and therefore there exists no one-to-one mapping for vertex correspondence. The full loss function of V2C consists of a loss term for the CNN and a loss term for the mesh reconstruction, with further details in <ref type="bibr" target="#b2">[3]</ref>. Here, we focus on the mesh reconstruction loss, which contains a geometric consistency loss and several regularization terms. The geometric consistency loss L C is a curvature weighted Chamfer loss, and is defined as:</p><formula xml:id="formula_1">L C (M y , M ŷ ) = 1 |P y | u∈Py min v∈P ŷ u -v 2 + 1 |P ŷ | v∈P ŷ min u∈Py v -u 2 , (<label>1</label></formula><formula xml:id="formula_2">)</formula><p>where P y ∈ R q×3 , and P ŷ ∈ R q×3 are point clouds sampled from the surfaces of M y and M ŷ respectively. For simplicity, we have omitted the curvature weights. In order to optimize for vertex correspondence, we propose to use a preprocessing step that registers the Mesh M y to the template mesh M x , resulting in a resampled ground truth mesh M y = {V y , F y , E y }, with V y ∈ R n×3 and F y ∈ R o×3 , where each index i ∈ 1, . . . , n represents the same anatomical location in both V x and V y . Instead of the Chamfer loss in Eq. ( <ref type="formula" target="#formula_1">1</ref>), we propose the loss function of V2CC as L(M y , M y ) = L1(M y , M y ) + λL reg (M ŷ ), where L 1 is the mean absolute distance between corresponding vertices in M y and My , and L reg is the normal consistency regularization to avoid self-intersections in M ŷ . L 1 and L reg are defined as:</p><formula xml:id="formula_3">L 1 (M y , M y ) = 1 n n i |v i -u i |, (<label>2</label></formula><formula xml:id="formula_4">)</formula><formula xml:id="formula_5">L reg (M ŷ ) = 1 |E ŷ | a,b∈E ŷ (1 -(n a • nb )) 2 , (<label>3</label></formula><formula xml:id="formula_6">)</formula><p>where ni is the unit normal of the i-th face of M ŷ . Our method relies on only one regularization term, compared to three in V2C. The regularization factor λ needs to be tuned as a hyperparameter. Our proposed V2CC method and the pre-processing step are presented in Fig. <ref type="figure">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head><p>Evaluation Metrics: To assess the quality of reconstructed cortical surfaces, we employ four metrics. With the average symmetric Chamfer distance (cdist ) and the percentage of self-intersecting faces (%SIF ), we evaluate the reconstructed surfaces' quality. For evaluating vertex correspondence, we use two different approaches for intra-and inter-subject cases. In intra-subject cases, we measure whether the same template vertex moves to the same location when provided with different scans of the same subject. In this case, we use scans that were acquired within a brief period of time to avoid structural changes. We calculate the consistency of vertex locations using the root-mean-square deviation (RMSD) of vertex positions. In inter-subject cases, we assess the ability of our method to map pre-defined parcellation atlases, such as the Desikan-Killany-Tourville (DKT) atlas <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b11">12]</ref>, onto cortical surfaces. This mapping allows for the assessment of morphological measurements, such as cortical thickness in cortical regions. To evaluate inter-subject vertex correspondence, we directly map vertex classes from the template atlas onto the predicted mesh and calculate the Dice overlap (Dice) to FreeSurfer's silver standard parcellation.</p><p>Data: For evaluation, we used the ADNI dataset (available at http://adni.loni. usc.edu), which provides MRI T1 scans for subjects with Alzheimer's disease, mild cognitive impairment, and cognitively normal. After removing scans with processing artifacts, we split the data into training, validation, and testing sets, balanced according to diagnosis, age, and sex. As ADNI is a longitudinal study, only the initial (baseline) scan for each subject was used. Our ADNI subset contains 1,155 subjects for training, 169 for validation, and 323 for testing. We used the TRT dataset <ref type="bibr" target="#b15">[16]</ref> to evaluate intra-subject correspondence, which contains 120 MRI T1 scans from 3 subjects, where each subject was scanned twice in 20 days. We further tested generalization to the Mindboggle-101 dataset <ref type="bibr" target="#b11">[12]</ref> (101 scans) and the Japanese ADNI (J-ADNI, https://www.j-adni.org) (502 baseline scans). All three datasets contain scans from various scanner vendors, with different field strengths (1.5 and 3T).</p><p>Implementation Details: To prepare for training, we pre-processed the data using FreeSurfer v7.2 <ref type="bibr" target="#b7">[8]</ref>, generating orig.mgz files and white and pial surfaces to use as silver standard ground truth surfaces. We use FreeSurfer's mri surf2surf tool to register surfaces to fsaverage6 (40,962 vertices) and fsaverage (163,842 vertices) template surfaces. We further followed the pipeline of <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>, registering MRI scans to the MNI152 space. We used public implementations of baseline methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b17">18]</ref> and made adaptations so that all methods use the same template for training and testing. All models were trained on NVIDIA Titan-RTX or A100 GPUs. The hyperparameter λ was set to 0.003 for white matter surfaces and 0.007 for pial surfaces after grid search. Our code is publicly available<ref type="foot" target="#foot_0">1</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Discussion:</head><p>We compare the proposed V2CC method to state-ofthe-art models V2C, CFPP, and Topofit on the ADNI dataset with FreeSurfer's fsaverage6 right hemisphere templates as an input mesh. All methods were trained using the resampled ground truth meshes. For baseline models we used hyperparameters proposed by the original method. We show the results in the top part of Table <ref type="table" target="#tab_0">1</ref>. Topofit achieves the highest surface reconstruction accuracy on the white matter surface, and CFPP has the lowest number of self-intersecting faces pial surfaces. V2C achieves lower surface accuracy compared to CFPP and Topofit and has a higher number of self-intersections. We believe this could be due to longer training time for Topofit and CFPP, 2600 and 1000 epochs, compared to 100 epochs for V2C. When replacing the loss function in V2C with L 1 , we interestingly observe an immense boost in surface accuracy, as well as improved inter-and intra-subject correspondence. The disadvantage of using the L 1 alone, is seen in an increase of self-intersecting faces, especially on pial surfaces. Self-intersections of pial surfaces can be reduced by introducing the normal consistency regularizer in Eq. ( <ref type="formula" target="#formula_3">2</ref>). Next, we trained the baseline V2C model, Topofit, and our V2CC model on higher resolution templates (fsaverage) and images. We present the results on the right hemisphere in the lower section of Table <ref type="table" target="#tab_0">1</ref>. Results for the left hemisphere can be found in the supplementary material. We did not train CFPP on high resolution because of the long training process (about four weeks). We can observe that all models achieve lower surface reconstruction error (cdist) when trained with higher resolution, but also more self-intersections. We believe this is partly due to already existing self-intersections in the fsaverage templates and the resampled ground truth meshes. For the vertex correspondence metrics, we can observe that both baselines, V2C and Topofit, achieve higher parcellation scores than in the low-resolution experiment, but are still outperformed by V2CC. We have further trained a state-of-the-art parcellation model (Fast-Surfer <ref type="bibr" target="#b9">[10]</ref>) on the same dataset, which yields a Dice score of 0.88 ± 0.022, so we can conclude that our atlas-based parcellation can even outperform dedicated parcellation models. We visualize the quality of intra-subject correspondence of V2CC and FreeSurfer in the top box of Fig. <ref type="figure" target="#fig_1">3</ref>, where we display the per-vertex RMSD on each subject's white matter surface of the right hemisphere. We can observe that for all three subjects, our method leads to less variance of vertex positions than FreeSurfer. This is interesting, as FreeSurfer results were registered and resampled to obtain vertex correspondence and our predictions were not. Further, this shows that even though FreeSurfer surfaces have been used as ground truth to train our model, V2CC generalizes well and is more robust to subtle changes in the images. The bottom box in Fig. <ref type="figure" target="#fig_1">3</ref> visualizes the parcellation result of one example subject and the average parcellation error over the whole test set. We observe that parcellation errors occur mainly in boundary regions for all methods, but these boundary regions are much finer in V2CC. To test the generalization ability of our method, we tested V2CC and V2C on two unseen datasets J-ADNI and Mindboggle. We observe, that V2CC achieves better parcellation Dice scores, while the surface reconstruction accuracy is similar for both methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Downstream Applications:</head><p>We hypothesize that our meshes with vertex correspondence to the template can be directly used for downstream applications such as group comparisons or disease classification, without the need for postprocessing steps. We performed a group comparison of subjects with Alzheimer's disease (AD) and healthy controls of the ADNI test set, where we compare cortical thickness measures on a per-vertex level. We present a visualization of p-values in Fig. <ref type="figure" target="#fig_2">4</ref>. We observe that meshes generated with V2CC highlight similar regions to FreeSurfer meshes. The visualization shows significant atrophy throughout the cortex, with stronger amount of thinning in the left hemisphere which matches findings from studies on cortical thinning in Alzheimer's disease <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b20">21]</ref>.We further performed an AD classification study based on thickness measures on the ADNI test set. We computed mean thickness values per parcel (DKT atlas parcellation) for V2CC, FreeSurfer, and the V2C <ref type="bibr" target="#b2">[3]</ref> baseline. We show the classification results for AD and controls using a gradient-boosted regression tree, trained on thickness measurements from the ADNI training set. The classifiers achieved 0.810 balanced accuracy (bacc) for Freesurfer, 0.804 bacc for V2CC, and 0.776 bacc, for V2C on the ADNI test set. Demonstrating that V2CC achieves comparable results to FS and outperforms V2C. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this work, we proposed V2CC, a novel approach for cortical surface reconstruction that directly provides vertx correspondence. V2CC utilizes a pre-processing step, where ground truth meshes are registered to a template, and directly learns the correspondences by optimizing an L1 loss instead of the commonly used Chamfer loss. We evaluated V2CC on several datasets, including ADNI, TRT, Mindboggle-101, and J-ADNI, and compared it to state-of-the-art methods. Our experimental results show that V2CC achieves comparable performance to previous methods in terms of surface reconstruction accuracy. However, V2CC improves intra-and inter-subject correspondence and disease classification based on cortical thickness. We have evaluated our proposed pre-processing step and loss function with V2C as the backbone network, but the underlying concepts are generic and could also be integrated in other methods like Topofit or CFPP.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. Top: Overview of existing cortical surface reconstruction approaches, that are dependent on a cumbersome spherical registration as post-processing to obtain vertex correspondence to a template. Bottom: Our approach directly yields surface predictions with correspondence to the input template and does not require any registration.</figDesc><graphic coords="3,41,79,54,56,340,18,127,15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Top box: vertex RMSD on the TRT dataset. Bottom box: Top: Parcellation examples on a white matter surface of the right hemisphere of an example subject from the ADNI test set. Bottom: Fraction of misclassified vertices over the test set, displayed on the smoothed fsaverage template.</figDesc><graphic coords="7,41,79,53,81,340,18,274,90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Group study of per-vertex cortical thickness measures in patients withAlzheimer's disease and healthy controls on the ADNI test set. Colors indicate regions with significantly lower cortical thickness in AD subjects (t-test, one-sided). Note that our predicted meshes can be directly compared on a per-vertex basis while FreeSurfer meshes need to be inflated to a sphere and registered.</figDesc><graphic coords="8,55,98,320,42,340,15,91,93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Comparison of mesh quality of right hemisphere surfaces by average symmetric chamfer distance (cdist) in mm ±std and mean of percentage of self-intersecting faces (% SIF), and vertex correspondences by mean RMSD ±std of vertex positions and Dice overlap of mapped atlas parcellation. All models were trained on the ADNI data. RMSD values were computed on the TRT dataset, all other metrics on the data specified by the data column. Bold numbers indicate best performing methods.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">fsaverage6 template</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Right Pial</cell><cell></cell><cell cols="2">Right WM</cell><cell>Average</cell></row><row><cell>Method</cell><cell>data</cell><cell>RMSD↓</cell><cell>cdist↓</cell><cell cols="2">% SIF↓ RMSD↓</cell><cell>cdist↓</cell><cell>% SIF↓ Dice↑</cell></row><row><cell>V2C [3]</cell><cell>ADNI</cell><cell cols="3">1.015 ±0.496 0.437 ±0.0311 1.123</cell><cell cols="3">0.961 ±0.447 0.372 ± 0.030 0.185</cell><cell>0.762</cell></row><row><cell>CFPP [19]</cell><cell>ADNI</cell><cell cols="3">0.884 ±0.353 0.3314 ±0.029 0.052</cell><cell cols="3">0.778 ±0.294 0.337 ±0.031 0.013</cell><cell>0.813</cell></row><row><cell>Topofit [11]</cell><cell>ADNI</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="3">1.271 ±0.410 0.180 ±0.030 0.022</cell><cell>0.838</cell></row><row><cell cols="2">V2CC only L1 ADNI</cell><cell cols="2">0.816 ±0.337 0.268 ±0.036</cell><cell>2.880</cell><cell cols="3">0.739 ±0.268 0.228 ±0.036 0.073</cell><cell>0.921</cell></row><row><cell>V2CC</cell><cell>ADNI</cell><cell cols="3">0.825 ±0.360 0.285 ±0.040 1.335</cell><cell cols="3">0.748 ±0.285 0.231 ±0.036 0.073</cell><cell>0.921</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">fsaverage template</cell><cell></cell></row><row><cell>V2C [3]</cell><cell>ADNI</cell><cell cols="3">1.139 ±0.569 0.210 ±0.030 3.174</cell><cell cols="3">1.010 ±0.485 0.185 ±0.032 0.727</cell><cell>0.823</cell></row><row><cell>Topofit [11]</cell><cell>ADNI</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="3">1.326 ±0.406 0.137 ±0.033 0.020</cell><cell>0.871</cell></row><row><cell>V2CC</cell><cell>ADNI</cell><cell cols="2">0.911 ±0.404 0.192 ±0.029</cell><cell>2.981</cell><cell cols="3">0.821 ±0.326 0.186 ±0.035 0.110</cell><cell>0.920</cell></row><row><cell>V2C [3]</cell><cell cols="2">Mindb -</cell><cell cols="2">0.305 ±0.045 5.372</cell><cell>-</cell><cell cols="2">0.196 ±0.023 1.272</cell><cell>0.780</cell></row><row><cell>V2CC</cell><cell cols="2">Mindb -</cell><cell cols="2">0.305 ±0.048 4.453</cell><cell>-</cell><cell cols="2">0.204 ±0.030 0.157</cell><cell>0.865</cell></row><row><cell>V2C [3]</cell><cell cols="2">J-ADNI -</cell><cell cols="2">0.262 ±0.046 3.578</cell><cell>-</cell><cell cols="2">0.222 ±0.078 1.063</cell><cell>0.803</cell></row><row><cell>V2CC</cell><cell cols="2">J-ADNI -</cell><cell cols="2">0.262 ±0.048 3.614</cell><cell>-</cell><cell cols="2">0.230 ±0.079 0.140</cell><cell>0.913</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://github.com/ai-med/V2CC.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. This research was supported by the <rs type="funder">German Research Foundation</rs> and the <rs type="funder">Federal Ministry of Education and Research in the call for Computational Life Sciences</rs> (DeepMentia, <rs type="grantNumber">031L0200A</rs>). We gratefully acknowledge the computational resources provided by the <rs type="funder">Leibniz Supercomputing Centre</rs> (www.lrz.de).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_JfyR69q">
					<idno type="grant-number">031L0200A</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43993-3 31.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An automated labeling system for subdividing the human cerebral cortex on MRI scans into gyral based regions of interest</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Desikan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="968" to="980" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Hoopes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Greve</surname></persName>
		</author>
		<ptr target="https://github.com/ahoopes/topofit" />
		<title level="m">TopoFit GitHub repository</title>
		<imprint>
			<date type="published" when="2023-03-04">04 Mar 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Vox2Cortex: fast explicit reconstruction of cortical surfaces from 3D MRI scans with geometric deep neural networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bongratz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rickmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pölsterl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wachinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="20773" to="20783" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">DeepCSR: a 3D deep learning approach for cortical surface reconstruction</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Cruz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lebrat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bourgeat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fookes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fripp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Salvado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="806" to="815" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Cortical thickness and central surface estimation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dahnke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Yotter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gaser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="336" to="348" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Bongratz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bongratz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rickmann</surname></persName>
		</author>
		<ptr target="https://github.com/ai-med/Vox2Cortex" />
		<title level="m">Vox2Cortex github repository</title>
		<imprint>
			<date type="published" when="2023-03-04">04 Mar 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">High-resolution inter-subject averaging and a coordinate system for the cortical surface</title>
		<author>
			<persName><forename type="first">B</forename><surname>Fischl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sereno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tootell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dale</surname></persName>
		</author>
		<ptr target="https://surfer.nmr.mgh.harvard.edu/ftp/articles/fischl99-morphing.pdf" />
	</analytic>
	<monogr>
		<title level="j">Hum. Brain Mapp</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="272" to="284" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">FreeSurfer</title>
		<author>
			<persName><forename type="first">B</forename><surname>Fischl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="774" to="781" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Cortical surface-based analysis: II: inflation, flattening, and a surface-based coordinate system</title>
		<author>
			<persName><forename type="first">B</forename><surname>Fischl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Sereno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Dale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="195" to="207" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">FastSurfer -a fast and accurate deep learning based neuroimaging pipeline</title>
		<author>
			<persName><forename type="first">L</forename><surname>Henschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Conjeti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Estrada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Diers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fischl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Reuter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">219</biblScope>
			<biblScope unit="page">117012</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">TopoFit: rapid reconstruction of topologically-correct cortical surfaces</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hoopes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Iglesias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fischl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Greve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Dalca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Imaging with Deep Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">101 labeled brain images and a consistent human cortical labeling protocol</title>
		<author>
			<persName><forename type="first">A</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tourville</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnins.2012.00171</idno>
		<ptr target="https://doi.org/10.3389/fnins.2012.00171" />
	</analytic>
	<monogr>
		<title level="j">Front. Neurosci</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">171</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">CorticalFlow: a diffeomorphic mesh transformer network for cortical surface reconstruction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lebrat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Focal decline of cortical thickness in Alzheimer&apos;s disease identified by computational neuroanatomy</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Lerch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Pruessner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Zijdenbos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hampel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Teipel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cereb. Cortex</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="995" to="1001" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">CortexODE: learning cortical surface reconstruction by neural odes</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kainz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alansary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="430" to="443" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Maclaren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Vos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Fischbein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bammer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">a test-retest dataset. Sci. Data</title>
		<imprint>
			<biblScope unit="volume">measurements</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>Reliability of brain</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Asymmetric thinning of the cerebral cortex across the adult lifespan is accelerated in Alzheimer&apos;s disease</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Roe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">721</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Santa</forename><surname>Cruz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
		<ptr target="https://bitbucket.csiro.au/projects/CRCPMAX/repos/corticalflow/browse" />
	</analytic>
	<monogr>
		<title level="j">CorticalFlow++</title>
		<imprint>
			<date type="published" when="2023-03-04">04 Mar 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">CorticalFlow++: boosting cortical surface reconstruction accuracy, regularity, and interoperability</title>
		<author>
			<persName><forename type="first">Santa</forename><surname>Cruz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16443-9_48</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16443-948" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13435</biblScope>
			<biblScope unit="page" from="496" to="505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Age-related cortical thinning in cognitively healthy individuals in their 60s: the path through life study</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Sachdev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Anstey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cherbuin</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neurobiolaging.2015.12.009</idno>
		<ptr target="https://doi.org/10.1016/j.neurobiolaging.2015.12.009" />
	</analytic>
	<monogr>
		<title level="j">Neurobiol. Aging</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="202" to="209" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Spatial patterns of cortical thinning in mild cognitive impairment and Alzheimer&apos;s disease</title>
		<author>
			<persName><forename type="first">V</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chertkow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Lerch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Kabani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brain</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2885" to="2893" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
