,title,extracted_keyword_sent,selected
0,Anatomy-Driven Pathology Detection on Chest X-rays,"additionally, manually annotating
pathology bounding boxes is a time-consuming task, further exacerbating the
issue.",
1,Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET,"despite the advantages of kpis in diagnosis,
the generation of accurate micro-parametric images is not yet possible in
clinical practice.to address the problem of the generation of micro-parametric
images, we propose a custom 3d unet [3] to estimate kinetic micro-parameters in
an unsupervised setting drawing inspiration from physics-informed neural
networks (pinn).",
2,Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET,"the main contributions of this work are:-a self-supervised
formulation of the problem of kinetic micro-parameters estimation -a
spatio-temporal deep neural network for parametric images estimation -a
quantitative and qualitative comparison with conventional methods for pbpk
modelingthe code is available at:
https://github.com/francescadb/self_supervised_pbpk_modelling.",
3,Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET,"finding the parameters of a km is a classical optimization problem [2,19,21]
solved by fitting the km equation to a measured tac in a least squares sense
[1,14,17].",
4,AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor,"to address this
issue, recent research has focused on developing segmentation frameworks that
require little or no segmentation labels.to meet this need, many researchers
have devoted their efforts to weakly-supervised semantic segmentation (wsss)
[21], which utilizes weak supervision, such as image-level classification
labels.",
5,AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor,"recent wsss methods can be broadly categorized into two types [4]:
class-activation-mapping-based (cam-based) [9,13,16,19,20,22], and
multiple-instance-learning-based (mil-based) [15] methods.the literature has not
adequately addressed the issue of low-resolution class-activation maps (cams),
especially for medical images.",
6,AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor,"some existing methods, such as dilated residual
networks [24] and u-net segmentation architecture [3,7,17], have attempted to
tackle this issue, but still require many upsampling operations, which the
results become blurry.",
7,AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor,"the model
learns the pixel-wise weighted sum of the activation maps by a novel contrastive
learning method.our proposed method has the following contributions:-to tackle
the issues in existing cams, we propose to use multiple-exit classification
networks to accurately capture all the internal activation maps of different
resolutions.",
8,AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor,"-we demonstrate the
superiority of ame-cam over state-of-the-art cam methods in extracting
segmentation results from classification networks on the 2021 brain tumor
segmentation challenge (brats 2021) [1,2,14].",
9,AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor,"-for reproducibility, we have
released our code at https://github.com/windstormer/ame-cam overall, our
proposed method can help overcome the challenges of expensive and time-consuming
segmentation labeling in medical imaging, and has the potential to improve the
accuracy of disease diagnosis and assessment.",
10,AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor,"we evaluate our method on the brain tumor segmentation challenge (brats) dataset
[1,2,14], which contains 2,000 cases, each of which includes four 3d volumes
from four different mri modalities: t1, post-contrast enhanced t1 (t1-ce), t2,
and t2 fluid attenuated inversion recovery (t2-flair), as well as a
corresponding segmentation ground-truth mask.",x
11,AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor,"quantitatively,
grad-cam and scorecam result in low dice scores, demonstrating that they have
difficulty extracting the activation of medical images.",
12,Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"in this work, we focus on the scenario where
radiological meta-data (thus, low-confidence labels) are available for a large
amount of images, whereas high-confidence labels, obtained by histological
analysis, are scarce.naive extensions of contrastive learning methods, such as
[5,10,11], from 2d to 3d images may be difficult due to limited gpu memory and
therefore small batch size.",
13,Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"however, these methods pose two difficulties: they reduce the
spatial context (limited by the size of the patch), and they require similar
spatial resolution across images.",
14,Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"these works implicitly assume a certain threshold on depth to define
positive and negative samples, which may be difficult to define and may be
different among applications and datasets.",
15,Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"as commonly
done in cl [3], this condition can be transformed into an optimization problem
using the max operator and its smooth approximation logsumexp:arg min(3) by
defining p (t) = {i : y i = y t } as the set of indices of images x i in the
batch with the same discrete label y i as the anchor x t , we can rewrite our
final loss function as:wherein practice, it is rather easy to find a good value
of σ, as the proposed kernel method is quite robust to its variation.",
16,Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"we first sample n patients, where n is the batch size, in a
balanced way with respect to the radiological/histological classes; namely, we
roughly have the same number of subjects per class.",
17,Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"for d 2 histo , which has fewer patients than the batch size, we use
a balanced sampling strategy with respect to the radiological/histological
classes with no obligation of one slice per patient in the batch.",
18,Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"the method depth-aware manages to correctly encode the
depth position but not the diagnostic class label.to assess the clinical
performance of the pretraining methods, we also compute the balanced accuracy
scores (bacc) of the trained classifiers, which is compared in table 2 to the
bacc achieved by radiologists who were asked to visually assess the presence or
absence of cirrhosis for the n=106 cases of d 1 histo .",
19,Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"in terms of application, our method could be easily
translated to other medical problems, such as pancreas cancer prediction using
the presence of intrapancreatic fat, diabetes mellitus or obesity as discrete
meta-labels.",
20,Unsupervised Discovery of 3D Hierarchical Structure with Generative Diffusion Features,"mri, ct, electron tomography) and different tasks associated with them
precludes image annotations for all existing problems in practice.",
21,Unsupervised Discovery of 3D Hierarchical Structure with Generative Diffusion Features,"to alleviate this problem, we use a voxel visual consistency loss:where i(x 0 )
is the identity feature extractor, i.e.",
22,Unsupervised Discovery of 3D Hierarchical Structure with Generative Diffusion Features,"the evaluation
metric, as in the brats'19 challenge [21], is dice score and the 95th percentile
of the symmetric hausdorff distance, which quantifies the surface distance of
the predicted segmentation from the manual tumor segmentation in millimeters.",x
23,S 2 ME: Spatial-Spectral Mutual Teaching and Ensemble Learning for Scribble-Supervised Polyp Segmentation,"1 that the pixels of the polyp boundary
exhibit greater difficulties in accurate segmentation, presenting with higher
entropy values (the white contours).",
24,S 2 ME: Spatial-Spectral Mutual Teaching and Ensemble Learning for Scribble-Supervised Polyp Segmentation,"varying data shifts and corruption like motion blur
and specular reflections2 pose significant challenges to model generalization
and robustness.implementation details.",
25,S 2 ME: Spatial-Spectral Mutual Teaching and Ensemble Learning for Scribble-Supervised Polyp Segmentation,"for a fair comparison, the output from the spatial
branch is taken as the final prediction and utilized in evaluation without
post-processing.",
26,S 2 ME: Spatial-Spectral Mutual Teaching and Ensemble Learning for Scribble-Supervised Polyp Segmentation,"to ensure the reliability of the mixed pseudo labels for
ensemble learning, we present the pixel-level adaptive fusion strategy according
to entropy maps of dual predictions to balance the strengths and weaknesses of
spatial and spectral branches.",
27,S 2 ME: Spatial-Spectral Mutual Teaching and Ensemble Learning for Scribble-Supervised Polyp Segmentation,"with extensive in-domain and
out-ofdomain evaluation on four public datasets, our method shows superior
accuracy, generalization, and robustness, indicating its clinical significance
in alleviating data-related issues such as data shift and corruption which are
commonly encountered in the medical field.",
28,Tracking Adaptation to Improve SuperPoint for 3D Reconstruction in Endoscopy,"endoscopic images are a challenging case for feature
detection and matching, due to several well known challenges for these tasks,
such as lack of texture, or the presence of frequent artifacts, like specular
reflections.",
29,Tracking Adaptation to Improve SuperPoint for 3D Reconstruction in Endoscopy,"these problems are accentuated when all the elements in the scene
are deformable, as it is the case in most endoscopy scenarios, and in particular
in the real use case studied in our work, the lower gastrointestinal tract
explored with colonoscopies.",
30,Tracking Adaptation to Improve SuperPoint for 3D Reconstruction in Endoscopy,"3d reconstruction is an open problem for laparoscopic and endoscopic settings
[14] of high interest for the community.",
31,Tracking Adaptation to Improve SuperPoint for 3D Reconstruction in Endoscopy,"more recent approaches
attempt to tackle specific endoscopy challenges, such as the deformation [18] or
the artifacts due to specular reflections in the feature extraction step
[2].well known sfm and slam pipelines rely on accurate and robust feature
extraction methods.",
32,Tracking Adaptation to Improve SuperPoint for 3D Reconstruction in Endoscopy,"however, transferring that
performance to endoscopy settings remains a difficult task due to several
challenges.",
33,Tracking Adaptation to Improve SuperPoint for 3D Reconstruction in Endoscopy,"exporting this progress to the matching stage, disk [24] proposes
a formulation of the problem to optimize in an end-to-end manner.",
34,Tracking Adaptation to Improve SuperPoint for 3D Reconstruction in Endoscopy,"we chose
superpoint because it is a seminal work that has inspired many follow up works,
and it is still among the top performers on current feature matching challenges
[10].",
35,Tracking Adaptation to Improve SuperPoint for 3D Reconstruction in Endoscopy,"simulated data lacks some of the biggest challenges of endoscopy
images (e.g.",
36,Black-box Domain Adaptative Cell Segmentation via Multi-source Distillation,"however, data acquisition for medical
images poses unique challenges due to privacy concerns and the high cost of
manual annotation.",
37,Black-box Domain Adaptative Cell Segmentation via Multi-source Distillation,"due to the
abovementioned challenges, some researchers have proposed various white-box
domain adaptation methods to address these issues.recently, [8,16] propose to
use generative adversarial networks to align the distributions of source and
target domains and generate source-domain lookalike outputs for target images.",
38,Black-box Domain Adaptative Cell Segmentation via Multi-source Distillation,"such privacy breaches may detrimental to the privacy protection policies of
hospitals.",
39,Black-box Domain Adaptative Cell Segmentation via Multi-source Distillation,"moreover, the target domain uses the same neural network as the
source domain, which is not desirable for low-resource target users like
hospitals [15].",
40,Black-box Domain Adaptative Cell Segmentation via Multi-source Distillation,"therefore, how to leverage the existing knowledge of black-box
models to effectively train new models for the target domain without accessing
the source domain data remains a critical challenge.in this paper, we present a
novel source-free domain adaptation framework for cross-tissue cell segmentation
without accessing both source domain data and model parameters, which can
seamlessly integrate heterogeneous models from different source domains into any
cell segmentation network with high generality.",
41,Black-box Domain Adaptative Cell Segmentation via Multi-source Distillation,"therefore, we develop two strategies within this new
framework to address this issue.",
42,Black-box Domain Adaptative Cell Segmentation via Multi-source Distillation,"this method effectively addresses two significant challenges
encountered in the analysis of cellular images, namely, the uncertainty in
source domain output and the ambiguity in cell boundary semantics.",
43,Black-box Domain Adaptative Cell Segmentation via Multi-source Distillation,"accordingly, direct knowledge transfer
using the output of the source domain predictor may lead to feature bias in the
student model due to the unavoidable covariance [20] between the target and
source domains.",
44,Black-box Domain Adaptative Cell Segmentation via Multi-source Distillation,"for single-source domain
adaptation approach, cellsegssda and sfda-dpl, we employ two strategies to
ensure the fairness of the experiments: (1) single-source, i.e.",x
45,Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning,"yet, acquiring large training datasets and
their corresponding labels, especially from a cohort of patients, can be costly
or even infeasible, which poses a significant challenge in developing a dl model
with high performance [7].",
46,Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning,"nonetheless, unlike natural images, generating labels
can be a challenging task, making it difficult to apply general da methods; thus
bridging domain gaps by da methods remains limited [26,33].",
47,Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning,"this is due to
sensitive privacy issues in patients' data, particularly in collaborative
research, which restricts access to labels from different domains.",
48,Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning,"more recently,
unsupervised domain adaptation (uda) has been introduced to address this issue
[16,33], aiming to generate semi-predictions (pseudo-labels) in target domains
first, followed by producing accurate predictions using the pseudo-labels.",
49,Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning,"this can lead to significant
degradation of the performance of dl models, as errors can compound and become
more pronounced over time [17,25].to alleviate the problem of pseudo-label-based
uda, in this work, we propose an advanced uda framework based on self-supervised
da with a test-time finetuning network.",
50,Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning,"to address this
issue, we introduced a novel self-supervised da network for breast cancer
segmentation in ultrasound images.",
51,PET-Diffusion: Unsupervised PET Enhancement Based on the Latent Diffusion Model,"however, acquiring high-quality pet images requires
injecting a sufficient dose (standard dose) of radionuclides into the human
body, which poses unacceptable radiation hazards for pregnant women and infants
even following the as low as reasonably achievable (alara) principle [19].",
52,PET-Diffusion: Unsupervised PET Enhancement Based on the Latent Diffusion Model,"but these supervised methods
relied heavily on the paired lpet and spet data that are rare in actual clinic
due to radiation exposure and involuntary motions (e.g., respiratory and muscle
relaxation).",
53,PET-Diffusion: Unsupervised PET Enhancement Based on the Latent Diffusion Model,"however, these methods still require lpet to train
models, which contradicts with the fact that only spet scans are conducted in
clinic.fortunately, the recent glowing diffusion model [6] provides us with the
idea for proposing a clinically-applicable pet enhancement approach, whose
training only relies on spet data.",
54,PET-Diffusion: Unsupervised PET Enhancement Based on the Latent Diffusion Model,"however, extending
the diffusion model developed for 2d photographic images to pet enhancement
still faces two problems: a) three-dimensionsal (3d) pet images will
dramatically increase the computational cost of diffusion model; b) pet is the
detail-sensitive images and may be introduced/lost some details during the
procedure of adding/removing noise, which will affect the downstream
diagnosis.taking all into consideration, we propose the spet-only unsupervised
pet enhancement (upete) framework based on the latent diffusion model.",
55,PET-Diffusion: Unsupervised PET Enhancement Based on the Latent Diffusion Model,"denoting the output of previous layer as z p et ,
the ct-guided cross-attention can be formulated as follows:where d is the number
of channels, b is the position bias, and conv(•) denotes the 1 × 1 × 1
convolution with stride of 1.",
56,3D Arterial Segmentation via Single 2D Projections and Depth Supervision in Contrast-Enhanced CT Images,"compared to centerline segmentation,
where the vessel diameter is disregarded, training a 3d vessel segmentation
model from 2d annotations poses additional segmentationspecific challenges, as
2d projections only capture the outline of the vessels, providing no information
about their interior.",
57,3D Arterial Segmentation via Single 2D Projections and Depth Supervision in Contrast-Enhanced CT Images,"the cohort consists of 141 patients with pancreatic ductal
adenocarcinoma, of an equal ratio of male to female patients.",x
58,3D Arterial Segmentation via Single 2D Projections and Depth Supervision in Contrast-Enhanced CT Images,"we distinguish between models selected according to the
2d performance on the validation set (2d) which is a fair baseline, and models
selected according to the 3d performance on the validation set (3d), which is an
unfair baseline as it requires 3d annotations on the validation set.with the
exception of the single fixed viewpoint baselines where the models have the
tendency to diverge towards over-or segmentation, we perform binary holefilling
on the output of all of our other models, as producing hollow objects is a
common under-segmentation issue.in table 1 we compare our method against the 3d
baseline, as well as baselines trained on multiple viewpoints.",
59,Mesh2SSM: From Surface Meshes to Statistical Shape Models of Anatomy,"mesh2ssm also includes an analysis
network that operates on the learned correspondences to obtain a data-driven
template point cloud (i.e., template point cloud), which can replace the initial
template, and hence reducing the bias that could arise from template selection.",x
60,Mesh2SSM: From Surface Meshes to Statistical Shape Models of Anatomy,"incorporating template feedback loop via vae [13,21] analysis module helps in
mitigating bias and capturing non-linear characteristics of the data.",x
61,Cross-Adversarial Local Distribution Regularization for Semi-supervised Medical Image Segmentation,"in this section, we begin by reviewing the minimax optimization problem of
virtual adversarial training (vat) [14].",
62,Cross-Adversarial Local Distribution Regularization for Semi-supervised Medical Image Segmentation,"given an input, we then formulate a
novel adversarial local distribution (ald) with dice loss, which benefits the
medical semi-supervised image segmentation problem specifically.",
63,Cross-Adversarial Local Distribution Regularization for Semi-supervised Medical Image Segmentation,"given that f θ is our model
parameterized by θ, vat [14] trains the model with the loss of vat that a
minimax optimization problem:where d kl is the kullback-leibler divergence.",
64,Cross-Adversarial Local Distribution Regularization for Semi-supervised Medical Image Segmentation,"the
inner maximization problem is to find an adversarial example near decision
boundaries, while the minimization problem enforces the local smoothness of the
model.",
65,Cross-Adversarial Local Distribution Regularization for Semi-supervised Medical Image Segmentation,"moreover, the works [15,20] show that even solving the
maximization problem with random initialization, its solutions can also lie
together and lose diversity, which significantly reduces the quality of
adversarial examples.",
66,Cross-Adversarial Local Distribution Regularization for Semi-supervised Medical Image Segmentation,"svgdf is used to solve the optimization problem of
finding a target distribution p θ (•|x)).",
67,Cross-Adversarial Local Distribution Regularization for Semi-supervised Medical Image Segmentation,"while vanilla svgd [10]
is difficult to capture semantic meaning of high-resolution data because of
calculating rbf kernel (k) directly on the data-level, we use the feature
extractor φ as a semantic transformation to further enhance the svgd algorithm
performance for medical imaging.",
68,Cross-Adversarial Local Distribution Regularization for Semi-supervised Medical Image Segmentation,"the problem (5) can then be relaxed towhere γ ∼
beta(α, α) for α ∈ (0, ∞).",
69,Cross-Adversarial Local Distribution Regularization for Semi-supervised Medical Image Segmentation,"the
third term is our cross-ald regularization, which is an enhancement of vat to
significantly improve the model performance.where λ cs and λ cross-ald are the
corresponding weights to balance the losses.",
70,Cross-Adversarial Local Distribution Regularization for Semi-supervised Medical Image Segmentation,"for fair comparisons, all experiments are conducted using the
identical setting, following [21].",x
71,Cross-Adversarial Local Distribution Regularization for Semi-supervised Medical Image Segmentation,"moreover, vanilla svgd
is difficult to capture semantic meaning of high-resolution medical imaging
because it calculates kernel k on image-level.",
72,Cross-Adversarial Local Distribution Regularization for Semi-supervised Medical Image Segmentation,"all experiments are conducted using the identical settings in the github
repository 6 [21] for fair comparisons.results.",x
73,Infusing Physically Inspired Known Operators in Deep Models of Ultrasound Elastography,"the known operator can be viewed as the prior knowledge related to the
physics of the problem.",
74,Infusing Physically Inspired Known Operators in Deep Models of Ultrasound Elastography,"it should be noted in contrast to [5] in which
only out-of-range samples were contributing to the loss, in this work, all
samples contribute to l vd to reduce the estimation bias.3-smoothness of epr is
considered by:4-picture loss is defined as l v = l vd + λ vs × l vs , where λ vs
is the weight of the smoothness loss.",
75,Infusing Physically Inspired Known Operators in Deep Models of Ultrasound Elastography,"this data is available online at http://code.sonography.ai
in [16].in vivo data was collected at johns hopkins hospital from patients with
liver cancer during open-surgical rf thermal ablation by a research antares
siemens system using a vf 10-5 linear array with the sampling frequency of 40
mhz and the center frequency of 6.67 mhz.",x
76,Infusing Physically Inspired Known Operators in Deep Models of Ultrasound Elastography,"the network is trained by physically inspired constraints specifically
designed to tackle the long-standing illusive problem of lateral strain imaging.",
77,SLPD: Slide-Level Prototypical Distillation for WSIs,"in computational histopathology, visual representation extraction is a
fundamental problem [14], serving as a cornerstone of the (downstream)
task-specific learning on whole slide pathological images (wsis).",
78,SLPD: Slide-Level Prototypical Distillation for WSIs,"however, the
obtained clustering centers, i.e., the prototypes, are inclined to represent the
visual bias related to staining or scanning procedure rather than medically
relevant features [33].",x
79,SLPD: Slide-Level Prototypical Distillation for WSIs,"we
rethink this problem from the perspective how to measure the similarity between
two slides accurately.",
80,SLPD: Slide-Level Prototypical Distillation for WSIs,"for a fair comparison, the total
number of prototypes of the two clustering methods is approximately the same.",
81,PROnet: Point Refinement Using Shape-Guided Offset Map for Nuclei Instance Segmentation,"in
real-world scenarios, point annotation locations may shift from nuclei centers
as a result of the expert labeling process, leading to a lower performance after
model training.to overcome these challenges, we propose a novel weakly
supervised instance segmentation method that effectively distinguishes adjacent
nuclei and is robust to point shifts.",
82,PROnet: Point Refinement Using Shape-Guided Offset Map for Nuclei Instance Segmentation,"to train the module we employ a focal loss, commonly used in
point detection problems.",
83,PROnet: Point Refinement Using Shape-Guided Offset Map for Nuclei Instance Segmentation,"for a fair
comparison, images were pre-processed before training/testing i.e., normalized
and cropped to 250×250 patches following the setting used in [17].to make point
labels, we use the center point of full mask annotations.",
84,Many Tasks Make Light Work: Learning to Localise Medical Anomalies from Multiple Synthetic Tasks,"their success is most evident at the miccai medical
outof-distribution analysis (mood) challenge [31], where all winning methods
have followed this paradigm so far (2020-2022).",
85,Many Tasks Make Light Work: Learning to Localise Medical Anomalies from Multiple Synthetic Tasks,"also, all tasks share a common recipe: the target anomaly mask m h is always a
randomly sized and rotated ellipse or rectangle (ellipsoids/cuboids in 3d); all
anomalies are positioned such that at least 50% of the mask intersects with the
foreground of the image; and after one augmentation is applied, the process is
randomly repeated (based on a fair coin toss, p = 0.5), for up to a maximum of 4
anomalies per image.the intra-dataset blending task.",
86,Many Tasks Make Light Work: Learning to Localise Medical Anomalies from Multiple Synthetic Tasks,"it does this
by combining the target gradient with dirichlet boundary conditions to define a
minimisation problem min fin h |∇f in -v| also, by defining h as the
axis-aligned bounding box of m h , we can ensure the boundaries coincide with
coordinate lines.",
87,Many Tasks Make Light Work: Learning to Localise Medical Anomalies from Multiple Synthetic Tasks,"to evaluate, we use the brain tumor segmentation
challenge 2017 (brats) dataset [1], containing 285 cases with either high or low
grade glioma, and the ischemic stroke lesion segmentation challenge 2015 (isles)
dataset [13], containing 28 cases with ischemic stroke lesions.",x
88,Many Tasks Make Light Work: Learning to Localise Medical Anomalies from Multiple Synthetic Tasks,"clinical scans) adds further
difficulty to this task.",
89,TPRO: Text-Prompting-Based Weakly Supervised Histopathology Tissue Segmentation,"nonetheless, weakly supervised histopathological image
segmentation presents a challenge due to the low contrast between different
tissues, intra-class variations, and inter-class similarities [4,11].",
90,TPRO: Text-Prompting-Based Weakly Supervised Histopathology Tissue Segmentation,"additionally, the tissue structures in histopathology images can be randomly
arranged and dispersed, which makes it difficult to identify complete tissues or
regions of interest [7].ours cam under the microscope, tumor epithelial ɵssue
may appear as solid nests, acinar structures, or papillary formaɵons.",
91,TPRO: Text-Prompting-Based Weakly Supervised Histopathology Tissue Segmentation,"however, these improved variants still face difficulties in capturing
the complete tissues.",
92,TPRO: Text-Prompting-Based Weakly Supervised Histopathology Tissue Segmentation,"this could be due to the design of transws [18] for single-label
image segmentation, with the segmentation branch simplified to binary
segmentation to reduce the difficulty, while our dataset consists of multilabel
images.",
93,VesselVAE: Recursive Variational Autoencoders for 3D Blood Vessel Synthesis,"this decision reflects a
balance between the computational demands of depth-first tree traversal in each
training step and the complexity of the training meshes.",
94,VesselVAE: Recursive Variational Autoencoders for 3D Blood Vessel Synthesis,"given the differences with the baselines generated
topologies, for a fair comparison, we limited our evaluation to a visual
inspection of the meshes.the qualitative analyses consisted of a visual
evaluation of the reconstructed outputs provided by the decoder network.",
95,VesselVAE: Recursive Variational Autoencoders for 3D Blood Vessel Synthesis,"since the presented framework would require significant
adaptations to accommodate such complex topologies, exploring this problem would
certainly be an interesting direction for future research.",
96,MetaLR: Meta-tuning of Learning Rates for Transfer Learning in Medical Imaging,"given the two issues,
transferability for medical tasks becomes more complicated [24,25].",
97,MetaLR: Meta-tuning of Learning Rates for Transfer Learning in Medical Imaging,"in
order to address this issue and improve the flexibility of fine-tuning
strategies, we propose controlling the fine-tuning process with layer-wise
learning rates (lrs), rather than simply manually fixing or updating the layers
(see fig.",
98,MetaLR: Meta-tuning of Learning Rates for Transfer Learning in Medical Imaging,"this problem can be formulated as the following bi-level
optimization problem:metalr aims to use the validation set to optimize α through
an automatic process rather than a manual one.",
99,MetaLR: Meta-tuning of Learning Rates for Transfer Learning in Medical Imaging,"to address this issue, we propose
using a proportional hyper-lr η = β × α t j , where β is a pre-defined
hyper-parameter.",
100,MetaLR: Meta-tuning of Learning Rates for Transfer Learning in Medical Imaging,"moreover, although the generalization validation on the training data batch may
introduce bias, providing sufficient training data ultimately benefits the
performance.",x
101,MetaLR: Meta-tuning of Learning Rates for Transfer Learning in Medical Imaging,"2 (b)), the middle layers of the encoder ""down-128"" and ""down-256"" are the
most transferable and have the lowest lrs, which is difficult for previous
fine-tuning schemes to discover.",
102,DAS-MIL: Distilling Across Scales for MIL Classification of Histological WSIs,"furthermore, a knowledge
distillation mechanism encourages the agreement between the predictions
delivered by different scales.retrieval, but also introducing multiple
challenges.",
103,DAS-MIL: Distilling Across Scales for MIL Classification of Histological WSIs,"through
knowledge distillation, we encour-age agreement across the predictions delivered
at different resolutions, while individual scale features are learned in
isolation to preserve the diversity in terms of information content.",
104,DAS-MIL: Distilling Across Scales for MIL Classification of Histological WSIs,"to sum up, the overall optimization problem is formulated as a
mixture of two objectives: the one requiring higher conditional likelihood
w.r.t.",
105,Pick the Best Pre-trained Model: Towards Transferability Estimation for Medical Image Segmentation,"to address this problem, the common paradigm of
transfer learning, which first pre-trains a model on upstream image datasets and
then fine-tunes it on various target tasks, has been widely investigated in
recent years [10,21,30].",
106,Pick the Best Pre-trained Model: Towards Transferability Estimation for Medical Image Segmentation,"compared with the distributed training across multiple
centers, there are no specific ethical issues or computational design of
distributed/federated learning frameworks with the ""pre-train-then-fine-tune""
workflow.previous works mainly focused on the fine-tuning strategy to
effectively adapt the knowledge from the pre-trained models to target tasks
[4,12,19,26].",
107,Pick the Best Pre-trained Model: Towards Transferability Estimation for Medical Image Segmentation,"however,
most of these works require source information available while medical images
have more privacy and ethical issues and fewer datasets are publicly available
than natural images.considering the issues mentioned above, this work focused on
source-free pre-trained model selection for segmentation tasks in the medical
image.",x
108,Pick the Best Pre-trained Model: Towards Transferability Estimation for Medical Image Segmentation,"first, unlike classification and regression problems that can use
a single n-dimensional feature vector to represent each image, segmentation
problems lack a global semantic representation, which poses difficulties for
direct transferability estimation.",
109,Pick the Best Pre-trained Model: Towards Transferability Estimation for Medical Image Segmentation,"third, medical images face severe class imbalance problems, with
excessive differences between foreground and background.",x
110,Pick the Best Pre-trained Model: Towards Transferability Estimation for Medical Image Segmentation,"however, existing
algorithms rarely give additional attention to the class imbalance problem.",x
111,Pick the Best Pre-trained Model: Towards Transferability Estimation for Medical Image Segmentation,"we calculate the
wasserstein distance of the distribution with voxels of the same class in a
sample pair comprised of every two samples in the dataset, and obtained the
following definition of class consistency c consgiven that 3d medical images are
computationally intensive, and prone to causing out-of-memory problems, in the
sliding window inference process for each case, we do not concatenate the output
of each patch into the final prediction result, but directly sample from the
patched output and concatenate them into the final sampled feature matrix.",
112,Pick the Best Pre-trained Model: Towards Transferability Estimation for Medical Image Segmentation,"in
the calculation of class consistency, we only sample the foreground voxels with
a pre-defined sampling number which is proportional to the voxel number of each
class in the image because of the severe class imbalance problem.feature
variety.",
113,Pick the Best Pre-trained Model: Towards Transferability Estimation for Medical Image Segmentation,"as a result of learning some trivial solutions, some overfitted
models have limited generalization capacity and are difficult to apply to new
tasks.",
114,Pick the Best Pre-trained Model: Towards Transferability Estimation for Medical Image Segmentation,"as for semantic segmentation problems, the
feature pyramid structure is critical for segmentation results [14,29].",
115,Pick the Best Pre-trained Model: Towards Transferability Estimation for Medical Image Segmentation,"for fair comparisons, the baseline methods including
transrate [9], logme [27], gbc [17] and leep [15] are also implemented.",
116,Pick the Best Pre-trained Model: Towards Transferability Estimation for Medical Image Segmentation,"most of the existing methods are inferior to ours because
they are not designed for segmentation tasks with a serious class imbalance
problem.",
117,Pick the Best Pre-trained Model: Towards Transferability Estimation for Medical Image Segmentation,"in our work, we raise the problem of model selection for upstream and downstream
transfer processes in the medical image segmentation task and analyze the
practical implications of this problem.",
118,Pick the Best Pre-trained Model: Towards Transferability Estimation for Medical Image Segmentation,"in addition, due to the ethical and
privacy issues inherent in medical care and the computational load of 3d image
segmentation tasks, we design a generic framework for the task and propose a
transferability estimation method based on class consistency with feature
variety constraint, which outperforms existing model transferability estimation
methods as demonstrated by extensive experiments.",
119,vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images,"meanwhile, to be suitable for many
downstream tasks, representations should have a dimensionality of about 1000, as
in [8].to address this issue, we utilize a 3d fpn architecture instead of a
standard 3d unet.",
120,vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images,"we demonstrate an example of the
excellent performance of vox2vec-fpn in both linear and non-linear probing
regimes in supplementary materials.we reproduce the key results on msd challenge
ct datasets, which contain tumor and organ segmentation tasks.",x
121,vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images,"another interesting research direction is exploring the
effectiveness of vox2vec with regard to domain adaptation to address the
challenges of domain shift between different medical imaging datasets obtained
from different sources.",x
122,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"domain shift is typically caused by various factors, including
differences in acquisition protocols (e.g., parameters, imaging methods,
modalities) and characteristics of data (e.g., age, gender, the severity of the
disease and so on).domain adaptation (da) has been proposed and investigated to
combat distribution shift in medical image segmentation.",x
123,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"many researchers
proposed using adversarial learning to tackle distribution shift problems
[3][4][5][6][7].",
124,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"however, they
easily suffer from the balance between feature alignment and discrimination
ability of the model.",x
125,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"while it is very difficult to ensure
the quality of pseudo labels in the 'other' domain and is also hard to build
capable models with noise labels.",
126,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"also, the domain information itself is well utilized
in the da algorithms.to tackle the aforementioned issues, we propose utilizing
prompt learning to take full advantage of domain information.",
127,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"the infant brain
mri dataset for cross-age segmentation; 2).",x
128,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"to optimize the segmentation backbone network, we use a combined loss function,
l seg , that incorporates both dice loss [19] and cross-entropy loss with a
balance factor.by summing the above-introduced losses, the total loss to train
the segmentation network can be defined by eq.",
129,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"7.where λ is the scaling factor
to balance the losses.",
130,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"the first dataset, i.e., cross-age infant segmentation [20], was used
for cross-age infant brain image segmentation, while the second dataset, i.e.,
brats2018 [21], was used for hgg to lgg domain adaptation.the first dataset is
for infant brain segmentation (white matter, gray matter and cerebrospinal
fluid).",x
131,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"to build the cross-age dataset, we take advantage 10 brain mris of
6-month-old from iseg2019 [20], and also build 3-month-old and 12-month-old
in-house datasets.",x
132,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"we directly use the code from the corresponding papers.for fair
comparison, we have replaced the backbone of these models with the same we used
in our approach.",
133,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"the quantitative comparison results of cross-age infant brain
segmentation is presented in table 1, and due to space limitations, we put the
experimental results of the brain tumor segmentation task in table 1 of
supplementary material, sec.3.",
134,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"experiments on two da datasets with two different segmentation backbones
demonstrate that our proposed method works well on da problems.",x
135,Spectral Adversarial MixUp for Few-Shot Unsupervised Domain Adaptation,"a common challenge for deploying deep learning to clinical problems is the
discrepancy between data distributions across different clinical sites
[6,15,20,28,29].",x
136,Spectral Adversarial MixUp for Few-Shot Unsupervised Domain Adaptation,"to solve this problem, many unsupervised domain
adaptation (uda) methods [6] have been developed for adapting a model to a new
site with only unlabeled data (target domain) by transferring the knowledge
learned from the original dataset (source domain).",
137,Spectral Adversarial MixUp for Few-Shot Unsupervised Domain Adaptation,"this motivates a new problem of
few-shot unsupervised domain adaptation (fsuda), where only a few unlabeled
target samples are available for training.few approaches [11,22] have been
proposed to tackle the problem of fsuda.",
138,Spectral Adversarial MixUp for Few-Shot Unsupervised Domain Adaptation,"to
tackle the overfitting issue of existing uda methods, we propose a novel
approach called sensitivityguided spectral adversarial mixup (samix) to augment
training samples.",
139,Spectral Adversarial MixUp for Few-Shot Unsupervised Domain Adaptation,"samix enables
high-performance uda methods to adapt easily to fsuda problems.",
140,Spectral Adversarial MixUp for Few-Shot Unsupervised Domain Adaptation,"thus, we introduce dodiss,
extending the previous method by incorporating domain distance to tackle domain
adaptation problems.",
141,Spectral Adversarial MixUp for Few-Shot Unsupervised Domain Adaptation,"camelyon [1] is a
tumor tissue binary classification task across 5 hospitals.",x
142,Spectral Adversarial MixUp for Few-Shot Unsupervised Domain Adaptation,"we use the training
set of camelyon as the source domain (302, 436 images from hospitals 1 -3) and
consider the validation set (34, 904 images from hospital 4) and test set (85,
054 images from the hospital 5) as the target domains 1 and 2, respectively.",x
143,Spectral Adversarial MixUp for Few-Shot Unsupervised Domain Adaptation,"for a fair
comparison, we adopted the same network architecture for all the methods on each
task.",
144,Gall Bladder Cancer Detection from US Images with only Image Level Labels,"gbc is a deadly disease that is difficult to detect at an early stage [12,15].",
145,Gall Bladder Cancer Detection from US Images with only Image Level Labels,"many of these works formulate the problem as an object
detection, since training a image classification model for gbc detection seems
challenging due to the reasons outlined in the abstract (also see fig.",
146,Gall Bladder Cancer Detection from US Images with only Image Level Labels,"on the
other hand, the image-level malignancy label is usually available at a low cost,
as it can be obtained readily from the diagnostic report of a patient without
additional effort from clinicians.instead of training a classification pipeline,
we propose to solve an object detection problem, which involves predicting a
bounding box for the malignancy.",
147,Gall Bladder Cancer Detection from US Images with only Image Level Labels,"however, since we
only have image-level labels available, we formulate the problem as a weakly
supervised object detection (wsod) problem.",
148,Gall Bladder Cancer Detection from US Images with only Image Level Labels,"our experiments validate the utility
of this approach in circumventing the challenges in us images and detecting gbc
accurately from us images using only image-level labels.",x
149,Gall Bladder Cancer Detection from US Images with only Image Level Labels,"-we formulate the gbc
classification problem as a weakly supervised object detection problem to
mitigate the effect of low inter-class and large intra-class variances, and
solve the difficult gbc detection problem on us images without using the costly
and difficult to obtain additional annotation (bounding box) or video data.",
150,Gall Bladder Cancer Detection from US Images with only Image Level Labels,gbc is a difficult-to-detect disease that benefits greatly from early diagnosis.,
151,Gall Bladder Cancer Detection from US Images with only Image Level Labels,"we proposed to formulate gbc detection as
a weakly supervised object detection/ localization problem using a detr with
selfsupervised instance learning in a mil framework.",
152,Gall Bladder Cancer Detection from US Images with only Image Level Labels,"we hope that our technique will simplify the model training
at the hospitals with easily available data locally, enhancing the applicability
and impact of automated gbc detection.",
153,Structured State Space Models for Multiple Instance Learning in Digital Pathology,"to deal with this issue, multiple instance
learning (mil) schemes based on weakly supervised training are used for wsi
classification tasks.",
154,Structured State Space Models for Multiple Instance Learning in Digital Pathology,"in particular, lstm networks have been shown to work well in
different mil settings including both visual cognition [22] and computational
pathology [1].the state space model is a linear differential equation,that is
widely studied in control theory, and describes a continuous time process for
input and output signals u(t) ∈ r p and y(t) ∈ r q , and state signal x(t) ∈ r n
, and where the process is governed by matricesin hippo [9] (high-order
polynomial projection operator), continuous time memorisation is posed as a
problem of function approximation in a hilbert space defined by a probability
measure μ.",
155,Structured State Space Models for Multiple Instance Learning in Digital Pathology,"both in terms of auroc and accuracy, our method outperforms the other
methods on long sequences, while the performances are comparable to table 1,
albeit slightly lower, illustrating the challenge of processing large wsis.",
156,Structured State Space Models for Multiple Instance Learning in Digital Pathology,"these models have been developed for their ability to memorise long
sequences, and they have proven competitive with state of the art mil models
across a range of pathology problems.",
157,Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision,"this information can be leveraged to assess treatment response, e.g., by
analyzing the evolution of size and morphology for a given tumor [1], but also
for adaptation of (re-)treatment radiotherapy plans that take into account new
tumors.in practice, the development of automatic and reliable lesion tracking
solutions is hindered by the complexity of the data (over different modalities),
the absence of large, annotated datasets, and the difficulties associated with
lesion identification (i.e., varying sizes, poses, shapes, and sparsely
distributed locations).",
158,Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision,"the problem of lesion tracking in longitudinal data is typically divided into
two steps: (1) detection of lesions and (2) tracking the same lesion over
multiple time points.",
159,Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision,"classical methods to solve this problem rely on image
registration, where tracking is performed via image alignment and rule-based
correspondence matching [15,16,21].",
160,Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision,"these approaches are difficult to optimize,
especially when scaling across different body regions and fields of view.",x
161,Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision,"the problem of lesion tracking can be formulated as
finding the optimal transformation that maps p 1 to its corresponding location,
p 2 , in i 2 .",
162,Geometry-Invariant Abnormality Detection,"however, novel unsupervised anomaly detectors based on
autoregressive transformers coupled with vector-quantized variational
autoencoders (vq-vae) have overcome issues associated with autoencoder-only
methods [21,22].",
163,Geometry-Invariant Abnormality Detection,"this transforms the problem to learning the codebook
distribution at position i as p(s i ) = p(s i |s <i , c) where c is the entire
ct latent sequence.",
164,Geometry-Invariant Abnormality Detection,"in this work,
we take inspiration from coordconv [19] as a mechanism to account for some level
of spatial awareness, an approach which has been applied to various tasks in
medical imaging scenarios with ranging levels of success [1,18].a coordconv
layer is a concatenation of channels to the input image referencing a predefined
coordinate system.",
165,Geometry-Invariant Abnormality Detection,"we found when
training the vq-vae model on data with varying resolutions and dimensions that
reconstructions showcased unwanted and significant artifacts, while by adding
the coordconv channels this issue was not present (see appendix c for examples).",
166,Geometry-Invariant Abnormality Detection,"in addition, we calculate the area under the precision-recall curve
(auprc) as a suitable measure for segmentation performance under class
imbalance.",
167,Interpretable Medical Image Classification Using Prototype Learning and Privileged Information,"nodules
were also scored according to their characteristics with respect to predefined
attributes, namely subtlety (difficulty of detection, 1-extremely subtle,
5-obvious), internal structure (1-soft tissue, 4-air ), pattern of calcification
(1popcorn, 6-absent), sphericity (1-linear, 5-round ), margin (1-poorly defined,
5sharp), lobulation (1-no lobulation, 5-marked lobulation), spiculation (1-no
spiculation, 5-marked spiculation), and texture (1-non-solid, 5-solid ).",
168,Incremental Learning for Heterogeneous Structure Segmentation in Brain Tumor MRI,"to explicitly avoid the overwriting of previously
learned parameters, our d 3 f follows a ""divide-and-conquer"" strategy to balance
the old and new tasks with a fixed rigidity branch and a compensated learnable
plasticity branch, which is guided by our novel divergence-aware continuous
batch renormalization (cbrn).",
169,Incremental Learning for Heterogeneous Structure Segmentation in Brain Tumor MRI,"simply enforcing the same statistics across domains
as [5,30,33] can weaken the model expressiveness [36].the recent brn [10]
proposes to rectify the data shift between each batch and the dataset by using
the moving average μ and σ along with the training:where η ∈ [0, 1] is applied
to balance the global statistics and the current batch.in addition, γ = σb σ and
β = μb -μ σ are used in both training and testing.",
170,Incremental Learning for Heterogeneous Structure Segmentation in Brain Tumor MRI,"specifically, we have the slice-level
segmentation se, which is the averaged entropy of the pixel-wise softmax
prediction asin training, the overall optimization loss is formulated as
follows:where α is used to balance our hsi distillation and se minimization
terms, and i max is the scheduled iteration.",
171,Incremental Learning for Heterogeneous Structure Segmentation in Brain Tumor MRI,"for a fair comparison, we adopted the resnet-based 2d nnu-net
backbone with bn as in [12] for all of the methods and all stages used in this
work.",
172,Incremental Learning for Heterogeneous Structure Segmentation in Brain Tumor MRI,"in doing so, we were able to achieve divergence awareness with our
cbrn-guided model adaptation for all the data involved.",x
173,ArSDM: Colonoscopy Images Synthesis with Adaptive Refinement Semantic Diffusion Models,"recently, diffusion
models [6,15] have emerged as promising solutions to this problem, demonstrating
remarkable progress in generating multiple modalities of medical data
[4,10,12,21].",
174,ArSDM: Colonoscopy Images Synthesis with Adaptive Refinement Semantic Diffusion Models,"2.despite recent progress in these methods for
medical image analysis, existing models face two major challenges when applied
to colonoscopy image analysis.",
175,ArSDM: Colonoscopy Images Synthesis with Adaptive Refinement Semantic Diffusion Models,"in addition, in order to generate
high-quality annotated samples, it is crucial to maintain the consistency
between the polyp morphologies in synthesized images and the original masks,
which current generative models struggle to achieve.to tackle these issues and
inspired by the remarkable success achieved by diffusion models in generating
high-quality ct or mri data [8,11,23], we creatively propose an effective
adaptive refinement semantic diffusion model (arsdm) to generate polyp-contained
colonoscopy images while preserving the original annotations.",
176,ArSDM: Colonoscopy Images Synthesis with Adaptive Refinement Semantic Diffusion Models,"moreover, during diffusion model training, we
employ an adaptive loss re-weighting method to assign loss weights for each
input according to the size ratio of polyps and background, which addresses the
overfitting problem for the large background.",
177,ArSDM: Colonoscopy Images Synthesis with Adaptive Refinement Semantic Diffusion Models,"(2) large-scale colonoscopy
generation: the proposed approach can be used to generate large-scale datasets
with no/arbitrary annotations, which significantly benefits the medical image
society, laying the foundation for large-scale pre-training models in automatic
colonoscopy analysis.",
178,ArSDM: Colonoscopy Images Synthesis with Adaptive Refinement Semantic Diffusion Models,"a simple
way to alleviate this problem is to apply a weighted loss function that assigns
the polyp and background regions with different weights.",
179,ArSDM: Colonoscopy Images Synthesis with Adaptive Refinement Semantic Diffusion Models,"thus assigning constant weights for all polyps
exacerbated the imbalance problem.",
180,ArSDM: Colonoscopy Images Synthesis with Adaptive Refinement Semantic Diffusion Models,"in this case, to tackle this problem, we
propose an adaptive loss function that vests different weights according to the
size ratio of the polyp over the background.",
181,ArSDM: Colonoscopy Images Synthesis with Adaptive Refinement Semantic Diffusion Models,"through extensive
experiments, we found inaccurate sample images with coarse polyp boundary that
is not aligned properly with the original masks may introduce large biases and
noises to the datasets.",x
182,Synthetic Augmentation with Large-Scale Unconditional Pre-training,"to overcome this challenge, a
natural choice is to employ data augmentation to increase the number of training
samples.",
183,Synthetic Augmentation with Large-Scale Unconditional Pre-training,"to mitigate the issue existed in current cgan-based synthetic augmentation
methods [8,[36][37][38], in this work, we propose to leverage the diffusion
model with unlabeled pre-training to reduce the dependency on the amount of
labeled data (see comparisons in fig.",
184,Synthetic Augmentation with Large-Scale Unconditional Pre-training,"by ensuring that the fine-tuning
process is representative of the entire dataset through even sampling from each
tissue type, we can eliminate bias towards any particular tissue type.",x
185,Synthetic Augmentation with Large-Scale Unconditional Pre-training,"for downstream
evaluation, we implement the classifier using the vit-b/16 architecture [5] in
all experiments to ensure fair comparisons.",
186,Synthetic Augmentation with Large-Scale Unconditional Pre-training,"to ensure a fair comparison,
all images synthesized by stylegan2 and histodiffusion model are further
selected based on feature centroid distances [36].",
187,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation,"this challenge of data annotation becomes even worse for medical image
segmentation tasks that require pixel-level annotation by experts.",
188,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation,"data
augmentation (da) is a recognized approach to tackle this challenge.",
189,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation,"this assumption is
restrictive and associated with several challenges.",
190,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation,"it thus will be challenging to transfer the
learned shape variations to even the same objects across different locations,
orientations, or sizes in the image, let alone transferring across dataset
(e.g., to transfer the learned shape variations of an organ from one image
modality to another).intuitively, object-centric transformations and
augmentations have the potential to overcome the challenges associated with
global image-level transformations.",
191,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation,"to overcome this issue, we
focus on a specific finitedimensional subset of the lie group that is large
enough to capture the relevant variations in the tumours.",
192,Longitudinal Multimodal Transformer Integrating Imaging and Latent Clinical Signatures from Routine EHRs for Pulmonary Nodule Classification,"previous studies overcome these
challenges by aggregating over visits and binning time series within a
bidirectional encoder representations from transformers (bert) architecture
[2,14,20,25], limiting their scope to data collected on similar time scales,
such as icu measurements, [11,29], or leveraging graph guided transformers to
handle asynchrony [33].",x
193,Longitudinal Multimodal Transformer Integrating Imaging and Latent Clinical Signatures from Routine EHRs for Pulmonary Nodule Classification,"on qualitative inspection of a control subject, clinical
signatures likely added clarity to benign imaging findings that were difficult
for baseline approaches to classify (fig.",
194,Longitudinal Multimodal Transformer Integrating Imaging and Latent Clinical Signatures from Routine EHRs for Pulmonary Nodule Classification,"we evaluated on clinically-billed spns,
meaning that clinicians likely found these lesions difficult enough to conduct a
clinical workup.",
195,Partially Supervised Multi-organ Segmentation via Affinity-Aware Consistency Learning and Cross Site Feature Alignment,"another
method was introduced in [9] where the non-overlapping characteristics between
different organs were exploited to design the exclusion loss.although witnessed
great progress in psmos, existing methods are faced with the following
challenges: 1) shortage in sufficiently labeled samples for supervised learning,
since voxel-level labels are only available for a subset of organs in plds; 2)
significant cross-site appearance variations caused by different imaging
protocols or subject cohorts.",x
196,Partially Supervised Multi-organ Segmentation via Affinity-Aware Consistency Learning and Cross Site Feature Alignment,"different from existing methods, we propose a
novel framework to explicitly tackle the above-mentioned challenges.to handle
the label-scarcity problem in plds, we propose a novel affinityaware consistency
learning (acl) scheme to incorporate voxel-to-organ affinity in the embedding
space into consistency learning.",
197,Partially Supervised Multi-organ Segmentation via Affinity-Aware Consistency Learning and Cross Site Feature Alignment,"by incorporating voxel-to-organ affinity in the
embedding space into consistency learning, our acl scheme is plug-and-play and
can capture rich context information in the embedding space.to tackle the data
discrepancy problem [17], based on the assumption that a well trained joint
model should generate consistent feature distributions across different sites,
we propose a novel cross-site feature alignment (csfa) module, where two terms
are introduced to attend to both the organ-specific and interorgan statistics in
the latent feature space.",x
198,Partially Supervised Multi-organ Segmentation via Affinity-Aware Consistency Learning and Cross Site Feature Alignment,"to further reduce the
data discrepancy problem, we constrain the affinity relationships across
different organ-specific prototypes to be consistent among different sites.",x
199,Partially Supervised Multi-organ Segmentation via Affinity-Aware Consistency Learning and Cross Site Feature Alignment,"to learn a unified model from a small-sized fld and a number of plds, we propose
a novel framework to address the issues of label-scarcity and cross-site data
discrepancy.",
200,Partially Supervised Multi-organ Segmentation via Affinity-Aware Consistency Learning and Cross Site Feature Alignment,"since
foreground organ in one pld may be labeled as background in another dataset,
such a background ambiguity brings challenges to joint training on multiple
plds.",
201,Partially Supervised Multi-organ Segmentation via Affinity-Aware Consistency Learning and Cross Site Feature Alignment,"to address this issue, we follow [7,9] to calculate the marginal cross
entropy and marginal dice loss as the baseline segmentation loss l seg .",
202,Partially Supervised Multi-organ Segmentation via Affinity-Aware Consistency Learning and Cross Site Feature Alignment,"for fair comparison, all the sota methods
were trained/tested on our own dataset splits.",
203,Partially Supervised Multi-organ Segmentation via Affinity-Aware Consistency Learning and Cross Site Feature Alignment,"therefore, we pay more attention to the performance on those hard organs (in our
datasets, pancreas and kidneys are deemed to be more difficult due to their
relatively small sizes).",x
204,Centroid-Aware Feature Recalibration for Cancer Grading in Pathology Images,"for example,
[7] proposed to incorporate both local and global contexts through the
aggregation learning of multiple context blocks for colorectal cancer
classification; [8] extracted and utilized multi-scale patterns for cancer
grading in prostate and colorectal tissues; [9] proposed to re-formulate cancer
classification in pathology images as both categorical and ordinal
classification problems.",
205,Explaining Massive-Training Artificial Neural Networks in Medical Image Analysis Task Through Visualizing Functions Within the Models,"the complexity of dl models
reduces interpretability and transparency substantially; therefore, the current
dl models are ""black-box"" [2].",
206,Explaining Massive-Training Artificial Neural Networks in Medical Image Analysis Task Through Visualizing Functions Within the Models,"it is difficult to find how the model works in a
way that humans can understand.",
207,Explaining Massive-Training Artificial Neural Networks in Medical Image Analysis Task Through Visualizing Functions Within the Models,"this makes the analysis of the functions
of neurons very difficult [15].to address this issue, we applied our
sensitivity-based structure optimization algorithm [16] to a trained large mtann
model to ""consolidate"" the diluted functions of neurons in the mtann model.",
208,Explaining Massive-Training Artificial Neural Networks in Medical Image Analysis Task Through Visualizing Functions Within the Models,"our
structure optimization algorithm refined the structure and made every hidden
unit in the model have a clear, meaningful function by removing redundant hidden
units and ""condensing"" the functions into fewer hidden units, which solved the
issue of unstable xai results with conventional xai methods.",
209,FeSViBS: Federated Split Learning of Vision Transformer with Block Sampling,"however, training vit models typically requires
significantly more data than traditional convolutional neural network (cnn)
models [16], which limits their application in domains such as healthcare, where
data scarcity is a challenge.",x
210,FeSViBS: Federated Split Learning of Vision Transformer with Block Sampling,"one way to overcome this challenge is to train
such models in a collaborative and distributed manner, where large amounts of
data can be leveraged from different sites without the need for sharing private
data [9,11].",x
211,FeSViBS: Federated Split Learning of Vision Transformer with Block Sampling,"in the absence of pretraining, limited training
data availability (a common problem in medical imaging) leads to severe
overfitting and poor generalization.",x
212,FeSViBS: Federated Split Learning of Vision Transformer with Block Sampling,"hence, the client's optimization problem is:in the fesvibs framework, the heads
and tails of all the clients are assumed to have the same network architecture.",
213,FeSViBS: Federated Split Learning of Vision Transformer with Block Sampling,"the second dataset [2] termed ""bloodmnist""
is a multi-class dataset consisting of 17, 092 blood cell images for 8 different
imbalanced cell types.",x
214,FeSViBS: Federated Split Learning of Vision Transformer with Block Sampling,"following [25], we used balanced accuracy in all experiments to evaluate the
performance of the classification task across all datasets.",
215,TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"in
hospitals, collected multi-phase cts are normally grouped by patients rather
than lesions, which makes single-phase lesion annotation insufficient for
feature fusion learning.",x
216,TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"first,
pure vit has several limitations itself [6], including ignoring local
information within each patch, extracting only single-scale features, and
lacking inductive bias.",x
217,TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"while most
multi-phase liver lesion classification studies use datasets with no more than
three phases (without dl phase for its difficulty of collection) or no more than
six lesion classes, we validate the whole framework on an in-house dataset with
four phases of abdominal ct and seven classes of liver lesions.",x
218,TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"the single-phase annotated lesion has the position and class labels in all
phases but they are not aligned, so we could have difficulty finding out which
lesions in different phases are the same with 2 or more lesions in one patient.",x
219,TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"vision transformers can get excellent performance on large-scale datasets such
as imagenet [4], but they are also prone to overfit on small datasets such as
private hospital datasets.",x
220,TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"the employed single-phase annotated dataset is collected from sir run
run shaw hospital (srrsh), affiliated with the zhejiang university school of
medicine, and has received the ethics approval of irb.",x
221,TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"to
handle the imbalance of dataset, we randomly select 586 lesions as the training
and validation set with no more than 700 axial slices in each lesion type, and
the rest 175 lesions constitute the test set.",x
222,TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"considering the fairness, all the models below are
initialized with pre-trained weights and adopt 2-d structures using the same
slice-level classification strategy.",x
223,TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"most of lesions in our dataset having few slices weakens the
redundancy between slices in 2-d pipeline, while the number of slices is still
obviously larger than the number of lesions, alleviating the overfitting issue.",
224,TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"then, we fuse the
features from different phases through cross phase tokens to enhance their
information exchange.to handle the issues in realistic cases, we design a
pre-processing unit to acquire multi-phase annotated lesions from single-phase
annotated ones.",
225,Adaptive Region Selection for Active Learning in Whole Slide Image Semantic Segmentation,"100, 000 × 100, 000 pixels) for
training a segmentation model are difficult to acquire.",
226,Adaptive Region Selection for Active Learning in Whole Slide Image Semantic Segmentation,"the challenge is to effectively select annotation regions
in order to achieve full annotation performance with the least annotated area,
resulting in high sampling efficiency.we use region-based active learning (al)
[13] to progressively identify annotation regions, based on iteratively updated
segmentation models.",
227,Adaptive Region Selection for Active Learning in Whole Slide Image Semantic Segmentation,"we used the publicly available camelyon16 challenge dataset [10] training
schedules.",x
228,Adaptive Region Selection for Active Learning in Whole Slide Image Semantic Segmentation,"we use the camelyon16 challenge metric free response operating
characteristic (froc) score [1] to validate the segmentation framework.to
evaluate the wsi segmentation performance directly, we use mean intersection
over union (miou).",
229,Adaptive Region Selection for Active Learning in Whole Slide Image Semantic Segmentation,"with a patch extraction stride s = 256 pixels, our framework yields
an froc score of 0.760 that is equivalent to the challenge top 2, and an miou
(tumor) of 0.749, which is higher than the most comparable method in [3] that
achieved 0.741 with s = 128 pixels.",
230,Adaptive Region Selection for Active Learning in Whole Slide Image Semantic Segmentation,"this is advantageous because extensive al step size tuning to balance
the annotation and computation costs can be avoided.",
231,Adaptive Region Selection for Active Learning in Whole Slide Image Semantic Segmentation,"s1 in the supplementary
materials we show that allowing for oversampling of previously selected regions
can be a solution to this problem.",
232,Adaptive Region Selection for Active Learning in Whole Slide Image Semantic Segmentation,"5 and show that adaptive avoids two region selection
issues of standard : small, isolated informative areas are missed, and
irrelevant pixels are selected due to the region shape and size restrictions.",
233,COLosSAL: A Benchmark for Cold-Start Active Learning for 3D Medical Image Segmentation,"second, medical images typically need to be
annotated by medical experts whose time is limited and expensive, making the
annotations even more difficult and costly to obtain.",
234,COLosSAL: A Benchmark for Cold-Start Active Learning for 3D Medical Image Segmentation,"this problem is
known as cold-start active learning , a low-budget paradigm of al that permits
only one chance to request annotations from experts without access to any
previously annotated data.cold-start al is highly relevant to many practical
scenarios.",
235,COLosSAL: A Benchmark for Cold-Start Active Learning for 3D Medical Image Segmentation,"this can lead to an appealing 'less
is more' outcome by optimizing the available budget and also alleviating the
issue of having human experts on standby for traditional iterative al.despite
its importance, very little effort has been made to address the coldstart
problem, especially in medical imaging settings.",
236,COLosSAL: A Benchmark for Cold-Start Active Learning for 3D Medical Image Segmentation,"consequently, no comprehensive cold-start al baselines currently
exist for 3d medical image segmentation, creating additional challenges for this
promising research direction.in this paper, we introduce the colossal benchmark,
the first cold-start active learning benchmark for 3d medical image segmentation
by evaluating on six popular cold-start al strategies.",
237,COLosSAL: A Benchmark for Cold-Start Active Learning for 3D Medical Image Segmentation,"the major challenge of benchmarking the diversity-based methods
for 3d tasks is to have a feature extraction network for 3d volumes.",
238,COLosSAL: A Benchmark for Cold-Start Active Learning for 3D Medical Image Segmentation,"to address
this issue, we train a 3d auto-encoder on the unlabeled training data using a
self-supervised task, i.e., image reconstruction.",
239,COLosSAL: A Benchmark for Cold-Start Active Learning for 3D Medical Image Segmentation,"the uncertainty-based
methods heavily rely on the uncertainty estimated by the network trained on the
proxy tasks, which likely makes the uncertainty of tumors difficult to capture.",
240,COLosSAL: A Benchmark for Cold-Start Active Learning for 3D Medical Image Segmentation,"while cold-start al remains an unsolved problem for 3d
segmentation, important trends emerge from our results; for example,
diversitybased strategies tend to benefit more from a larger budget.",
241,Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation,"at test
time, we set t = 100 to create a fair distribution of pa maps.",
242,Continual Learning for Abdominal Multi-organ and Tumor Segmentation,"in this context, the class-incremental continual
learning problem was formalized by rebuffi et al.",
243,Continual Learning for Abdominal Multi-organ and Tumor Segmentation,"[23], where new classes are
observed in different stages, restricting the model from accessing previous
data.the medical domain faces a similar problem: the ability to dynamically
extend a model to new classes is critical for multiple organ and tumor
segmentation, wherein the key obstacle lies in mitigating 'forgetting.' a
typical strategy involves retaining some previous data.",x
244,Continual Learning for Abdominal Multi-organ and Tumor Segmentation,"however, such methods, reliant on an account of data
and annotations, may face practical constraints as privacy regulations could
make accessing prior data and annotations difficult [9].",x
245,Continual Learning for Abdominal Multi-organ and Tumor Segmentation,"a concurrent study of ours [7] mainly focused on architectural
extension, addressing the forgetting problem by freezing the encoder and decoder
and adding additional decoders when learning new classes.",
246,Continual Learning for Abdominal Multi-organ and Tumor Segmentation,"while these strategies
have been alleviating the forgetting problem, they led to tremendous memory
costs for model parameters.therefore, we identify two main open questions that
must be addressed when designing a multi-organ and tumor segmentation framework.",
247,Continual Learning for Abdominal Multi-organ and Tumor Segmentation,"q1: can we relieve the forgetting problem without needing previous data and
annotations?",
248,Continual Learning for Abdominal Multi-organ and Tumor Segmentation,"q2: can we design a new model architecture that allows us to share
more parameters among different continual learning steps?to tackle the above
questions, in this paper, we propose a novel continual multi-organ and tumor
segmentation method that overcomes the forgetting problem with little memory and
computation overhead.",
249,Continual Learning for Abdominal Multi-organ and Tumor Segmentation,"we
evaluate our continual learning method using three datasets: btcv [8], lits [1]
and jhh [25] (a private dataset at johns hopkins hospital) 1 .",x
250,Continual Learning for Abdominal Multi-organ and Tumor Segmentation,"in the context of continual organ segmentation, the model's inability to access
the previous dataset presents a challenge as it often results in the model
forgetting the previously learned classes.",x
251,Continual Learning for Abdominal Multi-organ and Tumor Segmentation,"we found the use of
pseudo-labeling can largely mitigate this issue and preserve the existing
knowledge.",x
252,Continual Learning for Abdominal Multi-organ and Tumor Segmentation,"for a fair comparison, all the compared methods use the same swin unetr [4] as
the backbone, which is the state-of-the-art model in a bunch of medical image
segmentation tasks.",
253,Efficient Subclass Segmentation in Medical Images,"in such
cases, re-annotating an entire dataset may not be as cost-effective as
annotating only a small amount of data with subclass labels.here, the primary
challenge is to effectively leverage superclass annotations to facilitate the
learning of fine-grained subclasses.",
254,Efficient Subclass Segmentation in Medical Images,"to solve this problem, several works have
proposed approaches for recognizing new subclasses with limited subclass
annotations while utilizing the abundant superclass annotations in
classification tasks [6,8,18,25].",
255,Efficient Subclass Segmentation in Medical Images,"however, they do not take into account the existence
of superclasses annotations, making them less competitive in our setting.in this
study, we focus on the problem of efficient subclass segmentation in medical
images, whose goal is to segment subclasses under the supervision of limited
subclass and sufficient superclass annotations.",
256,Efficient Subclass Segmentation in Medical Images,problem definition.,
257,Efficient Subclass Segmentation in Medical Images,"to alleviate this issue, we aim to enhance the internal
diversity of the distribution within the same superclass while preserving the
discriminative features among superclasses.to achieve this, we propose separate
normalization(sn) to separately process feature maps belonging to hierarchical
foreground and background divided by superclass labels.",
258,Efficient Subclass Segmentation in Medical Images,"while mixing up only the semantic foreground provides a way of exchanging
knowledge between similar foreground objects while lifting the confirmation bias
in pseudo labeling [1].",x
259,Efficient Subclass Segmentation in Medical Images,"in fact, these
methods sometimes performed worse than the simple modified u-net, indicating the
difficulty of utilizing superclass information effectively.",
260,Efficient Subclass Segmentation in Medical Images,"in this work, we proposed an innovative approach to address the problem of
efficient subclass segmentation in medical images, where limited subclass
annotations and sufficient superclass annotations are available.",
261,Efficient Subclass Segmentation in Medical Images,"to the best of
our knowledge, this is the first work specifically focusing on this problem.",
262,Towards AI-Driven Radiology Education: A Self-supervised Segmentation-Based Framework for High-Precision Medical Image Editing,"however, designing educational materials solely
based on real-world data poses several challenges.",
263,Towards AI-Driven Radiology Education: A Self-supervised Segmentation-Based Framework for High-Precision Medical Image Editing,"another major challenge is longitudinal tracking
of pathological progression over time (e.g., from the early stage of cancer to
the advanced stage), which is difficult to understand because medical images are
often snapshots.",
264,Towards AI-Driven Radiology Education: A Self-supervised Segmentation-Based Framework for High-Precision Medical Image Editing,"nevertheless, editing specific anatomical elements remains a challenge [1,11].",
265,Towards AI-Driven Radiology Education: A Self-supervised Segmentation-Based Framework for High-Precision Medical Image Editing,"future challenges
include improving scalability with fewer manual operations, validating
segmentation maps from a more objective perspective, and comparing our proposed
algorithm with existing methods, such as those based on superpixels [10].data
use declaration and acknowledgment: the pelvic mri and chest ct datasets were
collected from the national cancer center hospital.",x
266,Towards AI-Driven Radiology Education: A Self-supervised Segmentation-Based Framework for High-Precision Medical Image Editing,"both were in-house datasets collected
from a single hospital.",x
267,Towards AI-Driven Radiology Education: A Self-supervised Segmentation-Based Framework for High-Precision Medical Image Editing,"because anatomical elements,
including the substructures of organs and diseases, are too detailed for human
annotators to segment, it was difficult to create ground-truth labels.",x
268,Localized Region Contrast for Enhancing Self-supervised Learning in Medical Image Segmentation,"to address this issue, in this paper, we propose a novel contrastive learning
framework that integrates localized region contrast (lrc) to enhance existing
self-supervised pre-training methods for medical image segmentation.our proposed
framework leverages felzenszwalb's algorithm [8] to formulate local regions and
defines a novel contrastive sampling loss to perform localized contrastive
learning.",
269,Localized Region Contrast for Enhancing Self-supervised Learning in Medical Image Segmentation,"in
the opposite, when the number of samples n is large, the sampling bias can be
high, since the number of pixels can be smaller than n .",x
270,FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation,"to solve the
non-iid challenges of fl in the medical image field, feddg [11] and fedmrcm [12]
were proposed to address the domain shift issue between the source domain and
the target domain, but the sharing of latent features may cause privacy
concerns.",
271,FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation,"auto-fedrl [13] and auto-fedavg [14] were proposed to deal with the
non-iid problem by using an optimization algorithm to learn super parameters and
aggregate weights.",
272,FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation,"[25] proposed fedcostwavg get a
notable improvement compared to fedavg by including the cost function decreased
during the last round and won the challenge.",
273,FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation,"(3) we propose an aggregation algorithm that introduces the concept of
affinity and graph into federated learning, and the aggregation weights can be
adjusted adaptively; (4) the superior performance is achieved by the proposed
method, on the public cifar-10 and fets challenge datasets.",x
274,FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation,"suppose k clients with private data cooperate to train a global model and share
the same neural network structure, 3d-unet [26], which is provided by the fets
challenge and kept unchanged.",
275,FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation,"the real-world dataset used in experiments is provided by the
fets challenge organizer, which is the training set of the whole dataset about
brain tumor segmentation.",x
276,FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation,"as
is shown in table 2, we list the average results of fedavg,
fedcostwavg(shortened to fcw), the champion method of fets challenge 2021, and
the proposed fed-grav.",
277,FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation,"different from the original fedcostwavg which changed the
activation function of networks, our re-implemented version made the network
unchanged to ensure a fair comparison.",
278,FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation,"we evaluated our
method on cifar-10 and real-world miccai federated tumor segmentation challenge
(fets) datasets, and the superior results demonstrated the effectiveness and
robustness of our fedgrav.",x
279,Faithful Synthesis of Low-Dose Contrast-Enhanced Brain MRI Scans Using Noise-Preserving Conditional GANs,"thus, the wasserstein distance generalizes this
distributional loss to any distribution within paired patches.to efficiently
solve problem (2), we use the inexact proximal point algorithm [34].",
280,A Spatial-Temporal Deformable Attention Based Framework for Breast Lesion Detection in Videos,"automatically detecting breast lesions is a
challenging problem with a potential to aid in improving the efficiency of
radiologists in ultrasound-based breast cancer diagnosis [18,21].",
281,A Spatial-Temporal Deformable Attention Based Framework for Breast Lesion Detection in Videos,"some of the
challenges associated with automatic breast lesion detection include blurry
boundaries and changeable sizes of breast lesions.most existing breast lesion
detection methods can be categorized into imagebased [10,11,16,17,19] and
video-based [1,9] breast lesion detection approaches.",
282,A Spatial-Temporal Deformable Attention Based Framework for Breast Lesion Detection in Videos,"although the recent cva-net aggregates clip and video level features, we
distinguish two key issues that hamper its performance.",
283,A Spatial-Temporal Deformable Attention Based Framework for Breast Lesion Detection in Videos,"second,
cva-net only performs one-frame prediction based on multiple frame inputs, which
is very time-consuming.to address the aforementioned issues, we propose a
spatial-temporal deformable attention based network, named stnet, for detecting
the breast lesions in ultrasound videos.",
284,A Spatial-Temporal Deformable Attention Based Framework for Breast Lesion Detection in Videos,"the previous work cva-net [9], to guarantee a fair
comparison.",
285,DeDA: Deep Directed Accumulator,"despite the effectiveness of general inductive
biases like translation equivariance [15] and locality [16], the diverse nature
of the gradient field map of the qsm images presents normalized gradient vectors
(the darker the blue, the larger the gradient vector's magnitude).",x
286,DeDA: Deep Directed Accumulator,"consequently, the question of how
to incorporate domain-specific inductive biases, or priors, beyond general ones
into neural networks for medical image processing remains an open challenge.in
this study, we strive to answer this question by addressing the identification
problem associated with a specific type of multiple sclerosis (ms) lesion,
referred to as a chronic active lesion, or rim+ lesion.",x
287,DeDA: Deep Directed Accumulator,"despite
several efforts to tackle the issue [4,18,24], a clinically reliable solution
remains elusive.given the limited amount of data and high class imbalance, it's
more advantageous to explicitly incorporate domain knowledge into the network as
priors.",x
288,DeDA: Deep Directed Accumulator,"for fair and consistent comparison, the dataset applied in the previous work
[24] was asked for and used to demonstrate the performance of the proposed
dedabased rim parameterization da-tr.",
289,DeDA: Deep Directed Accumulator,"transformer-based networks with fewer inductive biases rely heavily on the
use of a large training dataset or depends strongly on the feature reuse [19],
as a result, these networks as well as cnns with deeper structures are prone to
overfit small datasets.implementation details: a stratified five-fold
cross-validation procedure was applied to train and validate the performance,
and all experiments including ablation study were carried out within this
setting.",x
290,DeDA: Deep Directed Accumulator,"capturing these characteristics
poses a challenge for modern neural networks, especially given limited and
imbalanced training data.",x
291,DeDA: Deep Directed Accumulator,"while differentiable grid sampling [12] can tackle
some of these issues within a certain scope, another major class involving
transformations (e.g.",
292,OpenAL: An Efficient Deep Active Learning Framework for Open-Set Pathology Image Classification,"therefore, a very important
issue is how to obtain the highest model performance with a limited annotation
budget.",
293,OpenAL: An Efficient Deep Active Learning Framework for Open-Set Pathology Image Classification,"(color figure online)active learning (al) is an effective approach
to address this issue from a data selection perspective, which selects the most
informative samples from an unlabeled sample pool for experts to label and
improves the performance of the trained model with reduced labeling cost
[1,2,9,10,16,17,19].",
294,OpenAL: An Efficient Deep Active Learning Framework for Open-Set Pathology Image Classification,"we call this scenario in which the unlabeled pool consists of
both target class and non-target class samples open-set al problem.",
295,OpenAL: An Efficient Deep Active Learning Framework for Open-Set Pathology Image Classification,"upon analysis, our openal is capable of effectively maintaining the
balance of sample numbers across different classes during active learning.",
296,OpenAL: An Efficient Deep Active Learning Framework for Open-Set Pathology Image Classification,"this
severe sample imbalance weakens the performance of lfosa compared to random
selection initially.",
297,OpenAL: An Efficient Deep Active Learning Framework for Open-Set Pathology Image Classification,"furthermore, we constructed a more imbalanced
setting for the target classes lym (6000 samples), norm (3000 samples), and tum
(9000 samples), yet the cumulative sampling ratios of our method for these three
target classes remain fairly balanced, as shown in fig.",
298,OpenAL: An Efficient Deep Active Learning Framework for Open-Set Pathology Image Classification,"we propose a novel al framework for this open-set scenario,
openal, which addresses the challenge of accurately querying the most
informative target class samples in an unlabeled sample pool containing a large
number of non-target samples.",
299,SFusion: Self-attention Based N-to-One Multimodal Fusion Block,"however, it is particularly challenging due to the varying
number of input modalities, which results in the n-to-one fusion
problem.currently, existing fusion strategies to tackle this challenge can be
broadly grouped into three categories: the arithmetic strategy, the selection
strategy and the convolution strategy.",
300,SFusion: Self-attention Based N-to-One Multimodal Fusion Block,"therefore, it has to simulate
missing data by crudely zero-padding or replacing it with similar modalities,
which inevitably introduces a bias in computation and causes performance
degradation [5,18,25].transformer has achieved success in the field of computer
vision, demonstrating that self-attention mechanism has the ability to capture
the latent correlation of image tokens.",x
301,SFusion: Self-attention Based N-to-One Multimodal Fusion Block,"therefore, we propose a
self-attention based fusion block (sfusion) to tackle the problems of the above
fusion strategies.",
302,SFusion: Self-attention Based N-to-One Multimodal Fusion Block,"the shl (sussex-huawei locomotion) challenge 2019 [22] dataset provides
data from seven sensors of a smartphone to recognize eight modes of locomotion
and transportation (activities), including still, walking, run, bike, car, bus,
train, and subway.",x
303,SFusion: Self-attention Based N-to-One Multimodal Fusion Block,"for a
fair comparison, as shown in fig.",
304,SFusion: Self-attention Based N-to-One Multimodal Fusion Block,"for a fair comparison,
we adopt the same encoders (e c i and e a i ) and decoders (d s and d r i ) as
used in [5].",
305,SFusion: Self-attention Based N-to-One Multimodal Fusion Block,"for a fair comparison, we conduct
experiments on brats2018, adopt the same data partition as [24], and cite the
results in [24].",x
306,SFusion: Self-attention Based N-to-One Multimodal Fusion Block,"in this paper, we propose a self-attention based n-to-one fusion block sfusion
to tackle the problem of multimodal missing modalities fusion.",
307,VISA-FSS: A Volume-Informed Self Supervised Approach for Few-Shot 3D Segmentation,"in this way, the (s, q s ) pair is taken as the input data of the few-shot
segmenter, presenting a 1-way 1-shot segmentation problem.",
308,VISA-FSS: A Volume-Informed Self Supervised Approach for Few-Shot 3D Segmentation,"importantly,
pseudo-label generation for consecutive slices is the main challenge.",
309,VISA-FSS: A Volume-Informed Self Supervised Approach for Few-Shot 3D Segmentation,"to solve
this problem, we introduce a novel strategy called spps that propagates the
pseudo-label of the support image into query ones.",
310,VISA-FSS: A Volume-Informed Self Supervised Approach for Few-Shot 3D Segmentation,"following [8,19], we perform experiments on two common
medical benchmarks, including abdominal ct image scans from miccai 2015
multi-atlas abdomen labeling challenge [15] and abdominal mri image scans from
isbi 2019 combined healthy abdominal organ segmentation challenge [14].",x
311,VISA-FSS: A Volume-Informed Self Supervised Approach for Few-Shot 3D Segmentation,"to intuitively illustrate this issue, visual comparison of some
pseudo-labels generated by slic and spps is depicted in the supplementary
materials.",
312,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"however, as data-hungry
approaches, deep learning models require large balanced and high-quality
datasets to meet the in scl, head classes are overtreated leading to
optimization concentrating on head classes.",x
313,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"by contrast, ecl utilizes the
proxies to enhance the learning of tail classes and treats all classes equally
according to balanced contrastive theory [24].",x
314,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"long-tailed problem is
usually caused by differences in incidence rate and difficulties in data
collection.",x
315,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"some diseases are common while others are rare, making it difficult
to collect balanced data [13].",x
316,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"thus,
existing public skin datasets usually suffer from imbalanced problems which then
results in class bias of classifier, for example, poor model performance
especially on tail lesion types.to tackle the challenge of learning unbiased
classifiers with imbalanced data, many previous works focus on three main ideas,
including re-sampling data [1,18], re-weighting loss [2,15,22] and re-balancing
training strategies [10,23].",x
317,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"despite the
great results achieved, these methods either manually interfere with the
original data distribution or improve the accuracy of minority classes at the
cost of reducing that of majority classes [12,13].recently, contrastive learning
(cl) methods pose great potential for representation learning when trained on
imbalanced data [4,14].",x
318,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"(3) most methods only
consider the impact of sample size (""imbalanced data"") on the classification
accuracy of skin diseases, while ignoring the diagnostic difficulty of the
diseases themselves (""imbalanced diagnosis difficulty"").to address the above
issues, we propose a class-enhancement contrastive learning (ecl) method for
skin lesion classification, differences between scl and ecl are illustrated in
fig.",x
319,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"we propose a
novel hybrid-proxy model to generate proxies for enhancing different classes
with a reversed imbalanced strategy, i.e., the fewer samples in a class, the
more proxies the class has.",
320,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"furthermore,
we propose a balanced-hybrid-proxy loss, besides introducing balanced
contrastive learning (bcl) [24].",
321,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"moreover, we design a balanced-weighted
crossentropy loss which follows a curriculum learning schedule by considering
both imbalanced data and diagnosis difficulty.our contributions can be
summarized as follows: (1) we propose an ecl framework for long-tailed skin
lesion classification.",
322,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"(2) we present a
balanced-hybrid-proxy loss to balance the optimization of each class and
leverage relations among samples and proxies.",
323,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"(3) a new balancedweighted
cross-entropy loss is designed for an unbiased classifier, which considers both
""imbalanced data"" and ""imbalanced diagnosis difficulty"".",x
324,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"(4) experimental
results demonstrate that the proposed framework outperforms other
state-of-theart methods on two imbalanced dermoscopic image datasets and the
ablation study shows the effectiveness of each element.",x
325,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"both the class-dependent proxies generated by
hybrid-proxy model and the embeddings of samples are used to calculate
balanced-weighted cross-entropy loss, thus capturing the rich relations of
samples and proxies.",
326,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"since samples in a mini-batch follow
imbalanced data distribution, these proxies are designed to be generated in a
reversed imbalanced way by giving more representative proxies of tail classes
for enhancing the information of minority samples.",
327,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"the proxy
number n p c can be obtained by calculating the imbalanced factor nmax nc of
each class:in this way, the tail classes have more proxies while head classes
have less, thus alleviating the imbalanced problem in a mini-batch.as we know, a
gradient descent algorithm will generally be executed to update the parameters
after training a mini-batch of samples.",
328,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"however, when dealing with an imbalanced
dataset, tail samples in a batch contribute little to the update of their
corresponding proxies due to the low probability of being sampled.",
329,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"to tackle the problem that scl loss pays more attention on head classes, we
introduce bcl and propose balanced-hybrid-proxy loss to treat classes equally.",
330,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"the proposed
balanced-hybrid-proxy loss pulls points (both samples and proxies) in the same
class together, while pushes apart samples from different classes in embedding
space by using dot product as a similarity measure, which can be formulated as
follows:where b c means the sample number of class c in a batch, τ is the
temperature parameter.",
331,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"taking both ""imbalanced data"" and ""imbalanced diagnosis difficulty"" into
consideration, we design a curriculum schedule and propose balanced-weighted
cross-entropy loss to train an unbiased classifier.",x
332,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"we first train a general classifier, then in the
second stage we assign larger weight to tail classes for ""imbalanced data"".",
333,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"in
the last stage, we utilize the results on the validation set as the diagnosis
difficulty indicator of skin disease types to update the weights for ""imbalanced
diagnosis difficulty"".",
334,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"to ensure fairness, we re-train all methods by rerun their released codes
on our divided datasets with the same experimental settings.",
335,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"noticeably, our ecl
outperforms other imbalanced methods by great gains, e.g., 2.56% in pre on
isic2018 compared with scl and 4.33% in f1 on isic2019 dataset compared with
tsc.",x
336,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"first, we directly move the contrastive learning
(cl) branch and replaced the balanced-weighted cross-entropy (bwce) loss with
cross-entropy (ce) loss.",
337,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"however, the result of using proxies generated by reversed
balanced way in hybrid-proxy model (hpm) outperforms equal proxies in nearly all
metrics, which proves that giving more proxies to tail classes can effectively
enhance and enrich the information.",
338,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"hybrid-proxy model and
balanced-hybrid-proxy loss are proposed to tackle the problem that scl-based
methods pay less attention to the learning of tail classes.",
339,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"furthermore, balanced-weighted
cross-entropy loss is designed to help train an unbiased classifier by
considering both ""imbalanced data"" and ""imbalanced diagnosis difficulty"".",x
340,SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation,"specifically, expert annotations are required for medical data, which
can be costly and time-consuming, especially in tasks such as 3d image
segmentation.transferring pre-trained models to downstream tasks is an effective
solution for addressing the label-limited problem [8], but fine-tuning the full
network with small downstream data is prone to overfitting [16].",
341,SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation,"nevertheless, directly combining
prompt tuning with al presents several problems.",
342,SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation,"to overcome this issue, we draw inspiration from nlp
[18] and explore prompt tuning on visual models.",
343,SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation,"to address these challenges, we propose a diversified
visual prompt tuning approach.",
344,SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation,"previous studies overlook the critical issue of data selection for downstream
tasks, especially when available labels are limited.",x
345,SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation,"to address this challenge,
we propose a novel strategy called tesla.",
346,SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation,"although there are publicly available liver
tumor datasets [1,24], they only contain major tumor types and differ in image
characteristics and label distribution from our hospital's data.",x
347,SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation,"deploying a
model trained from public data to our hospital directly will be
problematic.collecting large-scale data from our hospital and training a new
model will be expensive.",
348,SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation,"therefore, we can use the model trained from them as a
starting point and use slpt to adapt it to our hospital with minimum cost.",
349,SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation,"we
collected a dataset from our in-house hospital comprising 941 ct scans with
eight categories: hepatocellular carcinoma, cholangioma, metastasis,
hepatoblastoma, hemangioma, focal nodular hyperplasia, cyst, and others.",x
350,SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation,"to ensure fairness and eliminate model ensemble effects,
we only used the model's prediction with k = 1 during testing.",
351,SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation,"specifically, we calculate
the class probability distribution vector for each sample based on the pixel
class in the mask and use coreset with these vectors to select 40 class-balanced
samples.",
352,SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation,"mc dropout and entropy underperformed in our
prompt tuning, likely due to the difficulty of learning such uncertain data with
only a few prompt parameters.",
353,UniSeg: A Prompt-Driven Universal Segmentation Model as Well as A Strong Representation Learner,"however, although the performance of deep learning models
even surpasses the accuracy of human exports on some segmentation tasks, two
challenges still persist.",
354,UniSeg: A Prompt-Driven Universal Segmentation Model as Well as A Strong Representation Learner,"(2) most segmentation tasks face the limitation of a small
labeled dataset, especially for 3d segmentation tasks, since pixel-wise 3d image
annotation is labor-intensive, time-consuming, and susceptible to operator bias.",x
355,UniSeg: A Prompt-Driven Universal Segmentation Model as Well as A Strong Representation Learner,"we use purple to
highlight where to add the task-related information.several strategies have been
attempted to address both challenges.",
356,UniSeg: A Prompt-Driven Universal Segmentation Model as Well as A Strong Representation Learner,"the
second strategy is the multi-class model, which formulates multiple segmentation
tasks into a multi-class problem and performs it simultaneously.",
357,UniSeg: A Prompt-Driven Universal Segmentation Model as Well as A Strong Representation Learner,"it is
concluded that the discriminative ability of text prompts is weak in different
tasks, and it is difficult to help learn task-specific semantic information.",
358,UniSeg: A Prompt-Driven Universal Segmentation Model as Well as A Strong Representation Learner,"it may be too
late for the model to be 'aware' of the ongoing task, making it difficult to
decode complex targets.in this paper, we propose a prompt-driven universal
segmentation model (uniseg) to segment multiple organs, tumors, and vertebrae on
3d medical images with diverse modalities and domains.",
359,UniSeg: A Prompt-Driven Universal Segmentation Model as Well as A Strong Representation Learner,"this solution
faces the issues of ( 1) designing an architecture for each task, (2)
distributing research effort, and (3) dropping the benefit of rich information
from other tasks.",
360,UniSeg: A Prompt-Driven Universal Segmentation Model as Well as A Strong Representation Learner,"for a fair comparison, the maximum training iterations of
single-task models on each task are 50,000, and the patch size is 64 × 192 ×
192, except for swin unetr, whose patch size is 64 × 160 × 160 due to the
limitation of gpu memory.",
361,Cross-Modulated Few-Shot Image Generation for Colorectal Tissue Classification,"in this work, we investigate the problem of diagnosing colorectal
cancer, which is one of the most common reason for cancer deaths around the
world and particularly in europe and america [23].existing deep learning-based
colorectal tissue classification methods [18,21,22] typically require large
amounts of annotated histopathological training data for all tissue types to be
categorized.",x
362,Cross-Modulated Few-Shot Image Generation for Colorectal Tissue Classification,"moreover, we demonstrate the
applicability of these generated images for the challenging problem of fs
colorectal tissue classification.",
363,Cross-Modulated Few-Shot Image Generation for Colorectal Tissue Classification,"in this work, we look into multi-class
colorectal tissue analysis problem, with low and high-grade tumors included in
the set.",
364,Cross-Modulated Few-Shot Image Generation for Colorectal Tissue Classification,"problem formulation: in our few-shot colorectal tissue image generation
framework, the goal is to generate diverse set of images from k input examples x
of a unseen (novel) tissue classes.",
365,Cross-Modulated Few-Shot Image Generation for Colorectal Tissue Classification,"however, given the
deterministic nature of the cross-attention and the limited set of reference
images, simultaneously generating diverse and high-quality images in the
few-shot setting is still a challenge.",
366,Cross-Modulated Few-Shot Image Generation for Colorectal Tissue Classification,"the study shows that pathologists could differentiate between the
ai-generated and real images only 55% time, which is comparable with a random
prediction in a binary classification problem, indicating the ability of our
proposed generative framework to generate realistic colorectal images.",
367,Unpaired Cross-Modal Interaction Learning for COVID-19 Segmentation on Limited CT Images,"to address the challenge of information interaction
between unpaired cross-modal data, we introduce a momentum-updated prototype
learning strategy to condense modality-specific knowledge.",
368,Unpaired Cross-Modal Interaction Learning for COVID-19 Segmentation on Limited CT Images,"it is difficult to directly learn cross-modal
dependencies using the features obtained by the encoder because ct and x-ray
data were collected from different patients.",x
369,Unpaired Cross-Modal Interaction Learning for COVID-19 Segmentation on Limited CT Images,"to address the challenge of
information interaction between unpaired cross-modal data, uci further develops
a kc and ki module to condense modality-specific knowledge and facilitates
cross-modal interaction, thereby enhancing segmentation training.",
370,Structure-Preserving Instance Segmentation via Skeleton-Aware Distance Transform,"1a), posing significant challenges for existing
segmentation methods.in the biomedical domain, most methods [3,4,13,14,22] first
learns intermediate representations and then convert them into masks with
standard segmentation algorithms like connected-component labeling and watershed
transform.",
371,Structure-Preserving Instance Segmentation via Skeleton-Aware Distance Transform,"there is an inconsistency problem in object skeleton generation: part of the
complete instance skeleton can be different from the skeleton of the instance
part (fig.",
372,Structure-Preserving Instance Segmentation via Skeleton-Aware Distance Transform,"we use the gland segmentation challenge dataset [17] that
contains colored light microscopy images of tissues with a wide range of
histological levels from benign to malignant.",x
373,Structure-Preserving Instance Segmentation via Skeleton-Aware Distance Transform,"according to the challenge protocol, the test set is further
divided into two splits with 60 images of normal and 20 images of abnormal
tissues for evaluation.",x
374,Structure-Preserving Instance Segmentation via Skeleton-Aware Distance Transform,"three evaluation criteria used in the challenge include
instance-level f1 score, dice index, and hausdorff distance, which measure the
performance of object detection, segmentation, and shape similarity,
respectively.",
375,Structure-Preserving Instance Segmentation via Skeleton-Aware Distance Transform,"since the training
data is relatively limited due to the challenges in collecting medical images,
we apply pixel-level and spatial-level augmentations, including random
brightness, contrast, rotation, crop, and elastic transformation, to alleviate
overfitting.",x
376,Structure-Preserving Instance Segmentation via Skeleton-Aware Distance Transform,2.2 we show the inconsistency problem of global and local skeletons.,
377,Structure-Preserving Instance Segmentation via Skeleton-Aware Distance Transform,"for multi-class problems, we can use class-aware semantic
segmentation to mask the sdt energy trained for all objects that is agnostic to
their classes.",
378,DAST: Differentiable Architecture Search with Transformer for 3D Medical Image Segmentation,"the transformer block is crafted with
longrange dependency inside sequences with marginal inductive bias.",x
379,DAST: Differentiable Architecture Search with Transformer for 3D Medical Image Segmentation,"intrinsically, it
shall benefit from inductive biases of these two popular deep learning
ingredients.",x
380,DAST: Differentiable Architecture Search with Transformer for 3D Medical Image Segmentation,"however, from a network design's perspective, it is not trivial to find the
right balance between convolutions and transformers inside the architecture.",
381,DAST: Differentiable Architecture Search with Transformer for 3D Medical Image Segmentation,"kits'19
challenge test-set performance evaluation for kidney and tumor segmentation in
terms of the average dice score per case.",x
382,DAST: Differentiable Architecture Search with Transformer for 3D Medical Image Segmentation,"1, our single-fold model and ensemble of five
models achieve excellent performance compared to all other entries in the
challenge shown in the table .",
383,DAST: Differentiable Architecture Search with Transformer for 3D Medical Image Segmentation,"the nnu-net [16] is the best among all other
entries, but the method utilized 20 u-net models with training strategies to
achieve the ensemble result for the challenge.",
384,DAST: Differentiable Architecture Search with Transformer for 3D Medical Image Segmentation,"on the
other hand, more convolutions are chosen than transformers, which implicitly
suggests that this balance between convolutions and transformers is better for
feature learning in segmentation.",
385,DAST: Differentiable Architecture Search with Transformer for 3D Medical Image Segmentation,"such models benefit from the different
inductive biases introduced by these two operations.",x
386,MultiTalent: A Multi-dataset Approach to Medical Image Segmentation,"the annotation of 3d medical images is a
difficult and laborious task.",
387,MultiTalent: A Multi-dataset Approach to Medical Image Segmentation,"interestingly, the benefits of
multitalent are particularly notable for more difficult classes and pathologies.",
388,MultiTalent: A Multi-dataset Approach to Medical Image Segmentation,"to solve the label contradiction problem we decouple the
segmentation outputs for each class by applying a sigmoid activation function
instead of the commonly used softmax activation function across the dataset.",
389,MultiTalent: A Multi-dataset Approach to Medical Image Segmentation,"we employed a 3d u-net [24], an
extension with additional residual blocks in the encoder (resenc u-net), that
demonstrated highly competitive results in previous medical image segmentation
challenges [14,15] and a recently proposed transformer based architecture
(swinunetr [29]).",
390,MultiTalent: A Multi-dataset Approach to Medical Image Segmentation,"to ensure fair
comparability, we did not scale up any models.",
391,MultiTalent: A Multi-dataset Approach to Medical Image Segmentation,"the first group includes all ""difficult""
classes for which the default nnu-net has a dice smaller than 75 (labeled by a
""d"" in table 4 in the appendix).",
392,Co-assistant Networks for Label Correction,"however, either of them is very difficult
to be obtained for conducting medical image analysis with dnns.",
393,Co-assistant Networks for Label Correction,"hence, correcting corrupted labels might be one of effective
solutions to solve the issues of high-quality labels.numerous works have been
proposed to tackle the issue of corrupted labels.",
394,Co-assistant Networks for Label Correction,"second, existing label correction methods often ignore to take into
account the relationship among the samples so that influencing the effectiveness
of label correction.to address the aforementioned issues, in this paper, we
propose a new co-assistant framework, namely co-assistant networks for label
correction (cnlc) (shown in fig.",x
395,Co-assistant Networks for Label Correction,"moreover, we design a robust loss (i.e., a resistance loss)
into the cnn framework to avoid model overfitting on corrupted labels and thus
exploring the first issue in previous label correction methods.",x
396,Co-assistant Networks for Label Correction,"during the process of noise cleaner, we
consider the relationship among samples (i.e., the local topology structure
preservation by gcn) to touch the second issue in previous methods.",x
397,Co-assistant Networks for Label Correction,"in
particular, our proposed cnlc iteratively updates the noise detector and the
noise cleaner, which results in a bi-level optimization problem [4,10] compared
to previous methods, the contributions of our method is two-fold.",
398,Co-assistant Networks for Label Correction,"second, two sequential modules in our framework
results in a bi-level optimization problem.",
399,Co-assistant Networks for Label Correction,"in this paper, we address the above issues by
employing semi-supervised learning, i.e., a gcn for each class, which keeps the
local topology structure of samples on both labeled samples and unlabeled
samples.",
400,Co-assistant Networks for Label Correction,"as the optimizations of two modules are nested, the objective
function of our proposed method is the following bi-level optimization problem:
in this paper, we construct a bi-level optimization algorithm to search optimal
network parameters of the above objective function.",
401,Co-assistant Networks for Label Correction,"for fairness, in our
experiments, we adopt the same neural network for all comparison methods based
on their public codes and default parameter settings.",
402,Co-assistant Networks for Label Correction,"the reason is that
the cross-entropy loss easily results in the overfitting issue on corrupted
labels.",
403,Co-assistant Networks for Label Correction,"in this paper, we proposed a novel co-assistant framework, to solve the problem
of dnns with corrupted labels for medical image analysis.",
404,Pre-trained Diffusion Models for Plug-and-Play Medical Image Enhancement,"the main
objective is to recover x by solving the minimization problem:x * = arg minwhere
the first data-fidelity term keeps the data consistency and the second
dataregularization term r(x) imposes prior knowledge constraints on the
solution.",
405,Pre-trained Diffusion Models for Plug-and-Play Medical Image Enhancement,"this problem can be solved by the iterative denoising and backward
projections (idbp) algorithm [26], which optimizes the revised equivalent
problem:whereis the pseudo inverse of the degradation matrix h and f h t h := f
t h t hf.",
406,Pre-trained Diffusion Models for Plug-and-Play Medical Image Enhancement,"estimating x * is essentially
a denoising problem that can be solved by a denoising operator and ŷ * has a
closed-form solution:intuitively, idbp iteratively estimates the original image
from the current degraded image and makes a projection by constraining it with
prior knowledge.although idbp offers a flexible way to solve image enhancement
problems, it still requires paired images to train the denoising operator [26].",
407,Pre-trained Diffusion Models for Plug-and-Play Medical Image Enhancement,"specifically, the denoising task is based on
the aapm low dose ct grand challenge abdominal dataset [19], which can be also
used for sr [33].",x
408,Pre-trained Diffusion Models for Plug-and-Play Medical Image Enhancement,"specifically, we used the identity matrix i as the degradation operator for the
denoising task and scaled the projection difference h † (hx 0|t -y) with
coefficient σ to balance the information from measurement y and denoising output
x 0|t .",
409,Robust T-Loss for Medical Image Segmentation,"in addition, medical image
annotations can be affected by human bias and poor inter-annotator agreement
[23], further complicating the process.",x
410,Robust T-Loss for Medical Image Segmentation,"noisy labels are and will continue to be, a problem
in medical datasets.",x
411,Robust T-Loss for Medical Image Segmentation,"this is a concern as label noise has been shown to decrease
the accuracy of supervised models [20,22,35], making it a key area of focus for
both research and practical applications.previous literature has explored many
methods to mitigate the problem of noisy labels in deep learning.",x
412,Robust T-Loss for Medical Image Segmentation,"to overcome this problem, we introduce a novel robust
loss function, the t-loss, which is inspired by the negative loglikelihood of
the student-t distribution.",
413,Robust T-Loss for Medical Image Segmentation,"this simulates the real risk of
errors due to factors like annotator fatigue and difficulty in annotating
certain images.",
414,Multi-Head Multi-Loss Model Calibration,"briefly speaking, epistemic
uncertainty arises from imperfect knowledge of the model about the problem it is
trained to solve, whereas aleatoric uncertainty describes ignorance regarding
the data used for learning and making predictions.",
415,Multi-Head Multi-Loss Model Calibration,"for example, if a classifier
has learned to predict the presence of cancerous tissue on a colon
histopathology, and it is tasked with making a prediction on a breast biopsy it
may display epistemic uncertainty, as it was never trained for this problem
[21].",
416,Multi-Head Multi-Loss Model Calibration,"a hard-todiagnose image, then it could express aleatoric
uncertainty, as it may not know how to solve the problem, but the ambiguity
comes from the data.",x
417,Multi-Head Multi-Loss Model Calibration,"consider a k-class classification problem, and a neural network u θ taking an
image x and mapping it onto a representation u θ (x) ∈ r n , which is linearly
transformed by f into a logits vector z = f (u θ (x)) ∈ r k .",
418,Multi-Head Multi-Loss Model Calibration,"we
first assume that the multi-head model has less branches than the number of
classes in our problem, i.e.",
419,Multi-Head Multi-Loss Model Calibration,"for example, in a
problem with 4 categories and 2 branches, we could haveif n is not divisible by
k, the reminder categories are assigned for specialization to random branches.",
420,Multi-Head Multi-Loss Model Calibration,"a binary classifier in a
balanced dataset, randomly predicting always one class with c = 0.5 +
confidence, has a perfect calibration and 50% accuracy.",
421,Multi-Head Multi-Loss Model Calibration,"the annotated part of this dataset contains 10,662 images,
and it represents a challenging classification problem due a high amount of
classes (23) and highly imbalanced class frequencies [2].",x
422,Multi-Head Multi-Loss Model Calibration,"we attribute this to class imbalance and the large number of
categories: smoothing labels might be ineffective in this scenario.",
423,Guiding the Guidance: A Comparative Analysis of User Guidance Signals for Interactive Segmentation of Volumetric Images,"interactive
segmentation models address this issue by utilizing weak labels, such as clicks,
instead of voxelwise annotations [5][6][7].",
424,Guiding the Guidance: A Comparative Analysis of User Guidance Signals for Interactive Segmentation of Volumetric Images,"we address these challenges with the following
contributions:1.",
425,Laplacian-Former: Overcoming the Limitations of Vision Transformers in Local Texture Detection,"then, a parametric frequency
attention fusion strategy to balance the importance of shape and texture
features by recalibrating the frequency features.",
426,Laplacian-Former: Overcoming the Limitations of Vision Transformers in Local Texture Detection,"➌ our method not only
alleviates the problem of the traditional self-attention mechanism mentioned
above, but also it surpasses all its counterparts in terms of different
evaluation metrics for the tasks of medical image segmentation.",
427,Laplacian-Former: Overcoming the Limitations of Vision Transformers in Local Texture Detection,"then it applies the ef-att mechanism to capture contextual
information and selectively include various types of frequency information while
using the laplacian pyramid to balance the importance of shape and texture
features.",
428,Laplacian-Former: Overcoming the Limitations of Vision Transformers in Local Texture Detection,"to address this issue, we have implemented an augmented
short- cut method from [9], a diversity-enhanced shortcut (des), employing a
kronecker decomposition-based projection.",
429,Laplacian-Former: Overcoming the Limitations of Vision Transformers in Local Texture Detection,"by adopting this approach, we can alleviate the
issues of feature redundancy and computational complexity associated with
self-attention.wang et al.",
430,Laplacian-Former: Overcoming the Limitations of Vision Transformers in Local Texture Detection,"to ensure a balanced distribution of low and
high-frequency information in the model, it is necessary to efficiently
aggregate the features from all levels of the frequency domain.",
431,Understanding Silent Failures in Medical Image Classification,"we emulate two acquisition shifts by defining either images from
the memorial sloan kettering cancer center (mskcc) or hospital clinic barcelona
(hcb) as the target domain and the remaining images as the source domain.",x
432,Understanding Silent Failures in Medical Image Classification,"while this reveals an increased blurriness in the
target domain, it is difficult to derive further insights involving specific
pathologies without a clinical expert.",
433,Evidence Reconciled Neural Network for Out-of-Distribution Detection in Medical Images,"these approaches overlook the inherent near
ood problem in medical images, in which instances belong to categories or
classes that are not present in the training set [21] due to the differences in
morbidities.",x
434,Evidence Reconciled Neural Network for Out-of-Distribution Detection in Medical Images,"to address this problem, edl utilizes the
dirichlet distribution as the conjugate prior of the categorical distribution
and replaces the softmax layer with an evidential head which produces a
non-negative output as evidence and formalizes an opinion based on evidence
theory to explicitly express the uncertainty of generated evidence.",
435,Evidence Reconciled Neural Network for Out-of-Distribution Detection in Medical Images,"moreover, the higher the similarity between samples, the greater impact of
evidence accumulation, which results in a dramatic performance degradation in
medical near ood detection.to tackle the problem mentioned above, we propose an
evidence reconcile block (erb) that reformulates the representation of original
evidence and minimizes the deviation of uncertainty in evidence generation.",
436,Evidence Reconciled Neural Network for Out-of-Distribution Detection in Medical Images,"based on proposition 1,
the reconciled evidence can generate a larger loss, which helps the model focus
more on the difficult-to-distinguish samples.",
437,Evidence Reconciled Neural Network for Out-of-Distribution Detection in Medical Images,"the in-house pancreas
tumor dataset collected from a cooperative hospital is composed of eight
classes: pdac (302), ipmn (71), net (43), scn (37), asc (33), cp (6), mcn (3),
and panin (1).",x
438,Evidence Reconciled Neural Network for Out-of-Distribution Detection in Medical Images,"to ensure fairness, we used pretrained resnet34 [9] as
backbone for all methods.",
439,Evidence Reconciled Neural Network for Out-of-Distribution Detection in Medical Images,"the experimental results validate the effectiveness and
robustness of our method in the medical near ood detection problem.",x
440,Scale-Aware Test-Time Click Adaptation for Pulmonary Nodule and Mass Segmentation,"this makes the pulmonary nodule and mass
segmentation task resemble a long-tail problem rather than a mere large scale
span problem.",
441,Scale-Aware Test-Time Click Adaptation for Pulmonary Nodule and Mass Segmentation,"this leads to unsatisfactory results when segmenting large lesions
that require more accurate delineation [26].several studies have proposed
solutions to tackle the large scale span challenges at both the input and
feature level.",
442,Scale-Aware Test-Time Click Adaptation for Pulmonary Nodule and Mass Segmentation,"though these
methods have achieved impressive performance, they still struggle to accurately
segment the extremely imbalanced multi-scale lesions.recently, some click-based
lesion segmentation methods [19][20][21] introduce the click at the input or
feature level and modify the network accordingly, resulting in higher accuracy
results.",
443,Scale-Aware Test-Time Click Adaptation for Pulmonary Nodule and Mass Segmentation,"additionally, we
also propose a multi-scale input encoder to further address the problem of
imbalanced lesion scales.",
444,Scale-Aware Test-Time Click Adaptation for Pulmonary Nodule and Mass Segmentation,"however,
incorporating clicks in this way does not focus on addressing the extremely
imbalanced lesion scales.",
445,Scale-Aware Test-Time Click Adaptation for Pulmonary Nodule and Mass Segmentation,"2, is enhanced
with a multi-scale (ms) input encoder to address the issue of multi-scale
lesions.",
446,Scale-Aware Test-Time Click Adaptation for Pulmonary Nodule and Mass Segmentation,"the multi-scale input encoder allows the network to capture more
scale information of the nodules and masses, thus mitigating the problem of
large lesion scale span.",
447,Scale-Aware Test-Time Click Adaptation for Pulmonary Nodule and Mass Segmentation,"in datasets such as lidc and in-house, where the number imbalance of
multi-scale lesion phenomena is more notable, the multi-input method
consistently outperforms the other two baselines.",x
448,Scale-Aware Test-Time Click Adaptation for Pulmonary Nodule and Mass Segmentation,"the difference between the two scatter diagrams indicates that the
proposed sattca effectively alleviates the issue of extremely imbalanced lesion
scales, and improves the segmentation performance for large lesions.",
449,Scale-Aware Test-Time Click Adaptation for Pulmonary Nodule and Mass Segmentation,"this paper introduces a novel approach called the scale-aware test-time click
adaptation for nodule and mass segmentation, which aims to address the issue of
extremely imbalanced lesion scale and poor segmentation performance on
largescale nodules and masses.",
450,WeakPolyp: You only Look Bounding Box for Polyp Segmentation,"this indirect supervision avoids the misleading of box-shape bias of
annotations.",x
451,WeakPolyp: You only Look Bounding Box for Polyp Segmentation,"because
there is a strong box-shape bias in b.",x
452,WeakPolyp: You only Look Bounding Box for Polyp Segmentation,"training with this bias, the model is
forced to predict the box-shape mask, unable to maintain the polyp's contours.",
453,WeakPolyp: You only Look Bounding Box for Polyp Segmentation,"this indirect supervision
separates p 1 /p 2 from b so that p 1 /p 2 is not affected by the shape bias of
b while obtaining the position and extent of polyps.",
454,WeakPolyp: You only Look Bounding Box for Polyp Segmentation,"because both t 1 /t 2 and b are
box-like masks, we directly calculate the supervision loss between them without
worrying about the misguidance of box-shape bias.",
455,Shifting More Attention to Breast Lesion Segmentation in Ultrasound Videos,"instead of formulating it as a
regression problem, we adopt a likelihood heatmap-based approach to encode the
location of breast lesions, since it is more robust to occlusion and motion
blur.",
456,Shifting More Attention to Breast Lesion Segmentation in Ultrasound Videos,"to ensure a fair and equitable comparison, we acquire the
segmentation results of all nine compared methods by utilizing either their
publicly available implementations or by implementing them ourselves.",
457,ACC-UNet: A Completely Convolutional UNet Model for the 2020s,"smeswin-unet fell behind
in all the cases, despite having such a large number of parameters, which in
turn probably makes it difficult to be trained on small-scale datasets.however,
our model combining the design principles of transformers with the inductive
bias of cnns seemed to perform best in all the different categories with much
lower parameters.",
458,ACC-UNet: A Completely Convolutional UNet Model for the 2020s,"the
resultant acc-unet possesses the inductive bias of cnns infused with long-range
and multi-level feature accumulation of transformers.",x
459,FocalUNETR: A Focal Transformer for Boundary-Aware Prostate Segmentation Using CT Images,"several automated segmentation
methods have been proposed to alleviate these issues, especially the fully
convolutional networks (fcn) based u-net [19] (an encoder-decoder architecture
with skip connections to preserve details and extract local visual features) and
its variants [14,23,26].",
460,FocalUNETR: A Focal Transformer for Boundary-Aware Prostate Segmentation Using CT Images,"despite good progress, these methods often have
limitations in capturing long-range relationships and global context information
[2] due to the inherent bias of convolutional operations.",x
461,FocalUNETR: A Focal Transformer for Boundary-Aware Prostate Segmentation Using CT Images,"and
the auxiliary task enhances the model's generalizability by addressing the
challenge of unclear boundaries in low-contrast ct images.",
462,FocalUNETR: A Focal Transformer for Boundary-Aware Prostate Segmentation Using CT Images,"second, we also
address the challenge of unclear boundaries specific to ct images by
incorporating an auxiliary task of contour regression.",
463,FocalUNETR: A Focal Transformer for Boundary-Aware Prostate Segmentation Using CT Images,"after obtaining the pooled feature mapsx l l 1 , we calculate the
query at the first level and key and value for all levels using three linear
projection layers f q , f k , and f v :for the queries inside the i-th window q
i ∈ r d×sw×sw , we extract the s l r × s l r keys and values from k l and v l
around the window where the query lies in and then gather the keys and values
from all l to obtainfinally, a relative position bias is added to compute the
focal sa forwhere b = {b l } l 1 is the learnable relative position bias [24].",x
464,FocalUNETR: A Focal Transformer for Boundary-Aware Prostate Segmentation Using CT Images,"the
predicted probabilities, pi , are derived from the main task through the
application of the focalunetr model to the input ct image.to address the
challenge of unclear boundaries in ct-based prostate segmentation, an auxiliary
task is introduced for the purpose of predicting boundaryaware contours to
assist the main prostate segmentation task.",
465,FocalUNETR: A Focal Transformer for Boundary-Aware Prostate Segmentation Using CT Images,"we
predict this heatmap with a regression task trained by minimizing mean-squared
error instead of treating it as a single-pixel boundary segmentation problem.",
466,FocalUNETR: A Focal Transformer for Boundary-Aware Prostate Segmentation Using CT Images,"thus, the overall performance of focalunetr is overshadowed by this
challenge, resulting in only moderate improvement over the baselines on the amos
dataset.",x
467,FocalUNETR: A Focal Transformer for Boundary-Aware Prostate Segmentation Using CT Images,"the auxiliary contour regression
task has also been shown to improve the segmentation performance for unclear
boundary issues in low-contrast ct images.",
468,Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,"the japanese society of radiological technology (jsrt) dataset
consists of 247 chest x-rays [26].",x
469,Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,"for a fair comparison, we made sure the segmentation models achieve similar
segmentation performance, with the average dice being .90 ± .02 for camus, .86 ±
.02 for private us., and .94 ± .02 for jsrt.for the pixel-wise segmentations, we
report results of a classical aleatoric uncertainty segmentation method [16] as
well as a test time augmentation (tta) method [29].",
470,Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,"the results reported before reveal that approaching the problem of segmentation
uncertainty prediction via a regression task, where the uncertainty is expressed
in terms of landmark location, is globally better than via pixel-based
segmentation methods.",
471,Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,"this is why on very noisy and
poorly contrasted data, the univariate or the bivariate model might be
preferable to using the asymmetric model.while our method works well on the
tasks presented, it is worth noting that it may not be applicable to all
segmentation problems like tumour segmentation.",x
472,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"the shortage of labeled data is a significant challenge in medical image
segmentation, as acquiring large amounts of labeled data is expensive and
requires specialized knowledge.",
473,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"to address this issue, researchers have proposed various
semi-supervised learning (ssl) techniques that incorporate both labeled and
unlabeled data to train models for both natural [2,4,12,13,15,16] and medical
images [10,11,14,[18][19][20][21].",
474,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"however, most of these methods do not
consider the class imbalance issue, which is common in medical image datasets.",x
475,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"for example, multi-organ segmentation from ct scans requires to segment
esophagus, right adrenal gland, left adrenal gland, etc., where the class ratio
is quite imbalanced; see fig 1(a).",x
476,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"as for liver tumor segmentation from ct
scans, usually the ratio for liver and tumor is larger than 16:1.recently, some
researchers proposed class-imbalanced semi-supervised methods [1,10] and
demonstrated substantial advances in medical image segmentation tasks.",x
477,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"[1] introduced a robust class-wise sampling strategy to
address the learning bias by maintaining performance indicators on the fly and
using fuzzy fusion to dynamically obtain the class-wise sampling rates.",x
478,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"however,
the proposed indicators can not model the difficulty well, and the benefits may
be overestimated due to the non-representative datasets used (fig.",x
479,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"[10] proposed cld to address the data bias by weighting the overall loss
function based on the voxel number of each class.",x
480,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"however, this method fails due
to the easily over-fitted cps (cross pseudo supervision) [4] baseline, ignoring
unlabeled data in weight estimation and the fixed class-aware weights.in this
work, we explore the importance of heterogeneity in solving the over-fitting
problem of cps (fig.",x
481,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"2) and propose a novel dhc (dual-debiased heterogeneous
co-training) framework with two distinct dynamic weighting strategies leveraging
both labeled and unlabeled data, to tackle the class imbalance issues and
drawbacks of the cps baseline model.",
482,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"the key idea of heterogeneous co-training
is that individual learners in an ensemble model should be both accurate and
diverse, as stated in the error-ambiguity decomposition [8].to achieve this, we
propose distdw (distribution-aware debiased weighting) and diffdw (diff
iculty-aware debiased weighting) strategies to guide the two sub-models to
tackle different biases, leading to heterogeneous learning directions.",x
483,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"specifically, distdw solves the data bias by calculating the imbalance ratio
with the unlabeled data and forcing the model to focus on extreme minority
classes through careful function design.",x
484,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"then, after observing the inconsistency
between the imbalance degrees and the performances (see fig.",
485,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"1(b)), diffdw is
designed to solve the learning bias.",x
486,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"we use the labeled samples and the
corresponding labels to measure the learning difficulty from learning speed and
dice value aspects and slow down the speeds of the easier classes by setting
smaller weights.",
487,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"1(c)), which satisfies the design ethos of a heterogeneous framework.the
key contributions of our work can be summarized as follows: 1) we first state
the homogeneity issue of cps and improve it with a novel dual-debiased
heterogeneous co-training framework targeting the class imbalance issue; 2) we
propose two novel weighting strategies, distdw and diffdw, which effectively
solve two critical issues of ssl: data and learning biases; 3) we introduce two
public datasets, synapse [9] and amos [7], as new benchmarks for
class-imbalanced semi-supervised medical image segmentation.",x
488,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"these datasets
include sufficient classes and significant imbalance ratios (> 500 : 1), making
them ideal for evaluating the effectiveness of class-imbalance-targeted
algorithm designs.",
489,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"dhc
leverages the benefits of combining two diverse and accurate sub-models with two
distinct learning objectives: alleviating data bias and learning bias.",x
490,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"to
achieve this, we propose two dynamic loss weighting strategies, distdw
(distributionaware debiased weighting) and diffdw (difficulty-aware debiased
weighting), to guide the training of the two sub-models.",
491,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"to mitigate the data distribution bias, we propose a simple yet efficient
reweighing strategy, distdw.",x
492,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"after analyzing the proposed distdw, we found that some classes with many
samples present significant learning difficulties.",x
493,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"blindly forcing the model to prioritize minority classes may
further exacerbate the learning bias, as some challenging classes may not be
learned to an adequate extent.",x
494,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"to alleviate this problem, we design diffdw to
force the model to focus on the most difficult classes (i.e.",
495,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"the
difficulty is modeled in two ways: learning speed and performance.",
496,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"then, we define the
difficulty of k th class after t th iteration as, where is a smoothing item with
minimal value.",
497,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"after
several iterations, the training process will be stable, and the difficulties of
all classes defined above will be similar.",
498,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"the
overall difficulty-aware weight of k th class is defined as:α is empirically set
to 1 5 in the experiments to alleviate outliers.",
499,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"the difficulty-aware weights
for all classes are dataset and implementation details.",
500,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"we introduce two new benchmarks on the
synapse [9] and amos [7] datasets for class-imbalanced semi-supervised medical
image segmentation.",x
501,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"moreover, simply extending the
state-of-the-art semi-supervised classification methods [2,3,5,15,17], including
class-imbalanced designs [3,5,17] to segmentation, is a straightforward solution
to our task.",
502,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"as shown in table 1 and2, the general semi-supervised methods which do
not consider the class imbalance problem fail to capture effective features of
the minority classes and lead to terrible performances (colored with red).",x
503,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"the
methods considered the class imbalance problem have better results on some
smaller minority classes such as gallbladder, portal & splenic veins and etc.",x
504,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"however, they still fail in some minority classes (es, rag, and lag) since this
task is highly imbalanced.",x
505,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"distdw
('distdw-distdw') alleviates the bias of baseline on majority classes and thus
segments the minority classes (ra, la, es, etc.) very well.",x
506,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"however, it has
unsatisfactory results on the spleen and stomach, which are difficult classes
but down-weighted due to the larger voxel numbers.",x
507,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"diffdw ('diffdw-diffdw')
shows complementary results with distdw, it has better results on difficult
classes (e.g.",
508,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"this work proposes a novel dual-debiased heterogeneous co-training framework for
class-imbalanced semi-supervised segmentation.",
509,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"we are the first to state the
homogeneity issue of cps and solve it intuitively in a heterogeneous way.",
510,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"to
achieve it, we propose two diverse and accurate weighting strategies: distdw for
eliminating the data bias of majority classes and diffdw for eliminating the
learning bias of well-performed classes.",x
511,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"by combining the complementary
properties of distdw and diffdw, the overall framework can learn both the
minority classes and the difficult classes well in a balanced way.",
512,Anatomical-Aware Point-Voxel Network for Couinaud Segmentation in Liver CT,"in clinics, couinaud segments obtained from manual
annotation are tedious and time-consuming, based on the vasculature used as
rough guide (fig.",
513,Anatomical-Aware Point-Voxel Network for Couinaud Segmentation in Liver CT,"it can supplement the
cnn-based method and improve the segmentation performance in regions without
intensity contrast.in this paper, to tackle the aforementioned challenges, we
propose a pointvoxel fusion framework that represents the liver ct in continuous
points to better learn the spatial structure, while performing the convolutions
in voxels to obtain the complementary semantic information of the couinaud
segments.",
514,Anatomical-Aware Point-Voxel Network for Couinaud Segmentation in Liver CT,"intuitively, due to the image
intensity between different couinaud segments being similar, the voxel-based cnn
model is difficult to achieve good segmentation performance.",
515,HENet: Hierarchical Enhancement Network for Pulmonary Vessel Segmentation in Non-contrast CT Images,"in recent years, deep learning-based methods have
emerged as promising approaches to solving challenging medical image analysis
problems and have demonstrated exciting performance in segmenting various
biological structures [10,11,15,17].",x
516,HENet: Hierarchical Enhancement Network for Pulmonary Vessel Segmentation in Non-contrast CT Images,"also, some recent methods combine convolutional neural
networks (cnns) with transformer or non-local block to address this issue
[3,6,13,18].",
517,HENet: Hierarchical Enhancement Network for Pulmonary Vessel Segmentation in Non-contrast CT Images,"however, all these methods ignored the
significant variability in hu values of pulmonary vessels at different
regions.to summarize, there exist several challenges for pulmonary vessel
segmentation in non-contrast ct images: (1) the contrast between pulmonary
vessels and background voxels is extremely low (fig.",
518,HENet: Hierarchical Enhancement Network for Pulmonary Vessel Segmentation in Non-contrast CT Images,"1(d) and(e).to address the above
challenges, we propose a h ierarchical e nhancement n etwork (henet) for
pulmonary vessel segmentation in non-contrast ct images by enhancing the
representation of vessels at both image-and feature-level.",
519,HENet: Hierarchical Enhancement Network for Pulmonary Vessel Segmentation in Non-contrast CT Images,"this study is approved by the ethical committee of west china
hospital of sichuan university, china.",x
520,HENet: Hierarchical Enhancement Network for Pulmonary Vessel Segmentation in Non-contrast CT Images,"for a fair comparison, we
use the same hyper-parameter settings and dice similarity coefficient loss
across all experiments.",
521,Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels,"take for example y = 0.5; it is straightforward
to verify that sdl achieves its minimum at x = 1, which is clearly
erroneous.loss functions that utilize l 2 relaxations [9,30] do not exhibit this
problem [47], but they are less commonly employed in practice and are shown to
be inferior to their l 1 counterparts [9,47].",
522,Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels,"qubiq is a recent challenge held at miccai 2020 and 2021, specifically designed
to evaluate the inter-rater variability in medical imaging.",x
523,Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels,"for
qubiq experiments, we additionally present the binarized dice score (bdice),
which is the official evaluation metrics used in the qubiq challenge.",x
524,Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels,"that is, the bias of the estimation is bounded above by the
calibration error and this explains why the calibration of the teacher would be
important for the student.",x
525,Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels,"for a fair comparison, we disable kde in all kd experiments.we find models
trained with sdl can still benefit from soft labels to a certain extent because
(i) models are trained with a mixture of ce and sdl, and ce is compatible with
soft labels; (ii) although sdl pushes predictions towards vertices, it can still
add some regularization effects in a binary segmentation setting.",
526,Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels,"our extensive experiments on the
public qubiq, lits and kits benchmarks validate that incorporating soft labels
leads to higher dice score and lower calibration error, indicating that these
losses can find wide application in diverse medical image segmentation problems.",
527,Semi-supervised Domain Adaptive Medical Image Segmentation Through Consistency Regularized Disentangled Contrastive Learning,"despite their remarkable success in numerous tasks, deep learning models trained
on a source domain face the challenges to generalize to a new target domain,
especially for segmentation which requires dense pixel-level prediction.",
528,Semi-supervised Domain Adaptive Medical Image Segmentation Through Consistency Regularized Disentangled Contrastive Learning,"fourier domain adaptation (fda) [26] was proposed to address these
challenges by an effective spectral transfer method.",
529,Semi-supervised Domain Adaptive Medical Image Segmentation Through Consistency Regularized Disentangled Contrastive Learning,"[15] proposed a margin-preserving
constraint along with a self-paced cl framework, gradually increasing the
training data difficulty.",
530,Semi-supervised Domain Adaptive Medical Image Segmentation Through Consistency Regularized Disentangled Contrastive Learning,"the
margins are even higher for less labeled data (1l) on the brats dataset, which
is promising considering the difficulty of the task.",x
531,BerDiff: Conditional Bernoulli Diffusion Model for Medical Image Segmentation,"the inherent ambiguity and high
uncertainty of medical images pose significant challenges [5] for accurate
segmentation, attributed to factors such as unclear tumor boundaries in brain
magnetic resonance imaging (mri) images and multiple plausible annotations of
lung nodule in computed tomography (ct) images.",
532,BerDiff: Conditional Bernoulli Diffusion Model for Medical Image Segmentation,"in this section, we first describe the problem definitions, and then demonstrate
the bernoulli forward and diverse reverse processes of our berdiff, as shown in
fig.",
533,BerDiff: Conditional Bernoulli Diffusion Model for Medical Image Segmentation,"note
that we treat the original four types of brain tumors as one type following
previous work [25], converting the multi-target segmentation problem into
binary.",
534,BerDiff: Conditional Bernoulli Diffusion Model for Medical Image Segmentation,"we have the following
three observations: 1) diffusion-based methods demonstrate significant
superiority over traditional approaches based on vae, gan, and autoregression
models for discrete segmentation tasks; 2) our berdiff outperforms other
diffusion-based models that use gaussian noise as the diffusion kernel; and 3)
our berdiff also outperforms the methods that explicitly model the annotator,
striking a good balance between diversity and accuracy.",
535,BerDiff: Conditional Bernoulli Diffusion Model for Medical Image Segmentation,"3, we find that our berdiff segments more accurately on parts that are
difficult to recognize by the human eye, such as the tumor in the 3rd row.",
536,BerDiff: Conditional Bernoulli Diffusion Model for Medical Image Segmentation,"in the future, we will extend our berdiff to the multi-target
segmentation problem and implement additional strategies for speeding up the
segmentation process.",
537,Annotator Consensus Prediction for Medical Image Segmentation with Diffusion Models,"multiple expert annotators are often employed to address this challenge, to
provide binary segmentation annotations for the same image.",
538,Annotator Consensus Prediction for Medical Image Segmentation with Diffusion Models,"research attention has recently been directed
towards the issues of multi-annotator labels [7,12].",
539,Annotator Consensus Prediction for Medical Image Segmentation with Diffusion Models,"in our work, we use
diffusion models to solve the image segmentation problem as conditional
generation, given the image.",
540,Annotator Consensus Prediction for Medical Image Segmentation with Diffusion Models,"the quantification of
uncertainties in biomedical image quantification challenge (qubiq), is a
recently available challenge dataset specifically for the evaluation of
inter-rater variability.",x
541,Anti-adversarial Consistency Regularization for Data Augmentation: Applications to Robust Medical Image Segmentation,"furthermore, semantic
segmentation in medical imaging suffers from privacy and data sharing issues
[13,35] and a lack of experts to secure accurate and clinically meaningful
regions of interest (rois).",x
542,Anti-adversarial Consistency Regularization for Data Augmentation: Applications to Robust Medical Image Segmentation,"this data shortage problem causes overfitting for
training dnns, resulting in the networks being biased by outliers and ignorant
of unseen data.to alleviate the sample size and overfitting issues, diverse data
augmentations have been recently developed.",x
543,Anti-adversarial Consistency Regularization for Data Augmentation: Applications to Robust Medical Image Segmentation,"considering the rois are
usually small and underrepresented compared to the backgrounds, the loss of
information may cause a fatal class imbalance problem in semantic segmentation
tasks.in these regards, we tackle these issues with a novel augmentation method
without distorting the semantics of objects in image space.",
544,Anti-adversarial Consistency Regularization for Data Augmentation: Applications to Robust Medical Image Segmentation,"with this regularization, the easier samples provide
adaptive guidance to the misclassified data such that the difficult (but
object-relevant) pixels can be gradually integrated into the correct prediction.",
545,Anti-adversarial Consistency Regularization for Data Augmentation: Applications to Robust Medical Image Segmentation,"for the training, we used k augmented images with the
given images for all baselines as in ours for a fair comparison.",
546,Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk,"however, other studies have shown that the best fusion strategy depends on the
specific nature of the problem, e.g.",
547,Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk,"consequently, our primary focus is the
paired multimodal segmentation problem, including the missing modality
scenario.motivation.",
548,Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk,"to address these challenges, we propose
an upgraded nnu-net network with two separate encoders, one for each modality,
and a common decoder that fuses fms using the proposed mfm that learns to infer
affine transformation parameters in a single forward pass.",
549,Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk,"on the other hand, to evaluate the generalization ability of our
method, we also conducted experiments on the ct-only pddca dataset (for details,
please refer to [15]), from which we collected 15 images from the offand on-site
test sets of the corresponding challenge for our evaluation.",x
550,Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk,"to ensure a fair model comparison, we set the number of filters in
the encoder of the single modality baseline model to match the number of filters
of the entry-level concatenation encoder.",
551,Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk,"to address the challenge of a relatively small dataset, we adopted a
4-fold cross-validation strategy without using any external training images.",
552,Learning Reliability of Multi modality Medical Images for Tumor Segmentation via Evidence Identified Denoising Diffusion Probabilistic Models,"in the clinic, the consistent
information and complementary information in multi-modality medical images
provide the basis for tumor diagnosis.",
553,Learning Reliability of Multi modality Medical Images for Tumor Segmentation via Evidence Identified Denoising Diffusion Probabilistic Models,"but it is still tricky to integrate
multi-modality medical images due to the complexity of medical images.existing
methods for multi-modality medical image integration can be categorized into
three groups: (1) input-based integration methods that concatenate
multi-modality images at the beginning of the framework to fuse them directly [
19,21], (2) feature-based fusion methods that incorporate a fusion module to
merge feature maps [16,23], and (3) decision-based fusion methods that use
weighted averaging to balance the weights of different modalities [11,15].",
554,Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network,breast cancer is the leading cause of cancer-related fatalities among women.,
555,Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network,"currently, it holds the highest incidence rate of cancer among women in the
u.s., and in 2022 it accounted for 31% of all newly diagnosed cancer cases [1].",
556,Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network,"this is primarily because the
architectural design of vits does not rely on the same inductive biases in
feature extraction which allow cnns to learn spatially invariant
features.accordingly, numerous prior studies introduced modifications to the
original vit network specifically designed for bus image classification
[13,14,23].",
557,Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network,"moreover,
multitask learning acts as a regularizer by introducing inductive bias and
prevents overfitting [25] (particularly with vits), and with that, can mitigate
the challenges posed by small bus dataset sizes.",x
558,Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network,"because malignant tumors are more
challenging to detect due to greater differences in margin, shape, and
appearance in bus images, focal loss forces the model to focus more on difficult
predictions.",
559,Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network,"to avoid data
leakage and bias, we selected the train, test, and validation sets based on the
cases, i.e., the images from one case (patient) were assigned to only one of the
training, validation, and test sets.",x
560,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"nn-unet [12], which is based on unet [21], has achieved top performances on over
20 medical segmentation challenges.",x
561,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"parallel to manually created networks such
as nn-unet, dints [10], a cnn designed by automated neural network search, also
achieved top performances in medical segmentation decathlon (msd) [1]
challenges.",x
562,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"the convolution operation in cnn provides a strong inductive bias
which is translational equivalent and efficient in capturing local features like
boundary and texture.",x
563,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"however, this inductive bias limits the representation
power of cnn models which means a potentially lower performance ceiling on more
challenging tasks [7].",
564,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"among them, swinunetr [23] has
achieved the new top performance in the msd challenge and beyond the cranial
vault (btcv) segmentation challenge by pretraining on large datasets.",
565,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"it has a
u-shaped structure where the encoder is a swin-transformer [16].although
transformers have achieved certain success in medical imaging, the lack of
inductive bias makes them harder to be trained and requires much more training
data to avoid overfitting.",x
566,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"ade20k [34], where the challenge is in learning complex
relationships and scene understanding from a large amount of labeled training
images, many medical image segmentation networks need to be extremely focused on
local boundary details while less in need of highlevel relationships.",
567,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"hence in real clinical studies and
challenges, cnns can still achieve better results than transformers.",
568,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"for
example, the top solutions in the last year miccai challenges hector [19], flare
[11], instance [15,22] and amos [13] are all cnn based.",x
569,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"besides lacking
inductive bias and enough training data, one extra reason could be that
transformers are computationally much expensive and harder to tune.",
570,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"swinunetr reaches top performances
on several large benchmarks, making itself the current sota, but without
effective pretraining and excessive tuning, its performance on new datasets and
challenges is not as high-performing as expected.a straightforward direction to
improve transformers is to combine the merits of both convolutions and
self-attentions.",
571,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"coatnet [5] unifies convolution and
self-attention with relative attention, while convit [7] uses gated positional
self-attention which is equipped with a soft convolutional inductive bias.",
572,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"although swin-transformer uses local window attention to introduce
inductive bias like convolutions, self-attentions can still mess up with the
local details.",
573,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"to make fair comparisons with baselines, we
did not use any pre-trained weights.datasets.",
574,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"the network is validated on five
datasets of different sizes, targets and modalities:1) the word dataset [17] the
challenge comes from segmenting small tumors from large full 3d ct images.",x
575,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"the challenge is from the large label imbalances between the background,
pancreas, and tumor structures.",
576,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"to make a fair
comparison, we didn't use any test-time augmentation or model ensemble.",
577,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"we didn't compare
with leaderboard results because the purpose of the experiments is to make fair
comparisons, while not resorting to additional training data/pretraining,
postprocessing, or model ensembling.",
578,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"although existing
window-based attention already has a convolution-like inductive bias, it is
still not good enough for learning local details as convolutions.",
579,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"by only adding one resconv block at the beginning of each resolution
level, the features can be well-regularized while not too constrained by the
convolution inductive bias, and the computation cost will not increase by a lot.",
580,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"we will apply the
network to active challenges for more evaluation.",
581,SimPLe: Similarity-Aware Propagation Learning for Weakly-Supervised Breast Cancer Segmentation in DCE-MRI,"breast cancer is the most common cause of cancer-related deaths among women all
around the world [8].",
582,SimPLe: Similarity-Aware Propagation Learning for Weakly-Supervised Breast Cancer Segmentation in DCE-MRI,"these
methods may encounter the issue of high computational complexity when analyzing
volumetric data, and most of them require manual interactions.",
583,SimPLe: Similarity-Aware Propagation Learning for Weakly-Supervised Breast Cancer Segmentation in DCE-MRI,"such setting can help alleviate class
imbalance issue.",x
584,Uncertainty-Informed Mutual Learning for Joint Medical Image Classification and Segmentation,"for the k classification problems, we
utilize subjective logic [7] to produce the belief mass of each class and the
uncertainty mass of the whole image based on evidence.",
585,Conditional Diffusion Models for Weakly Supervised Medical Image Segmentation,"brats (brain tumor segmentation challenge) [1]
contains 2,000 cases of 3d brain scans, each of which includes four different
mri modalities as well as tumor segmentation ground truth.",x
586,Conditional Diffusion Models for Weakly Supervised Medical Image Segmentation,"this task is conducted on
dataset from isbi 2019 chaos challenge [12], which contains 20 volumes of
t2-spir mr abdominal scans.",x
587,DBTrans: A Dual-Branch Vision Transformer for Multi-Modal Brain Tumor Segmentation,"therefore, it is
necessary to design an efficient and accurate glioma lesion segmentation
algorithm to effectively alleviate this problem and relieve doctors' workload
and improve radiotherapy quality.with the rise of deep learning, researchers
have begun to study deep learning-based image analysis methods [2,37].",
588,DBTrans: A Dual-Branch Vision Transformer for Multi-Modal Brain Tumor Segmentation,"first, modeling
relationships between 3d voxel sequences is much more difficult than 2d pixel
sequences.",
589,DBTrans: A Dual-Branch Vision Transformer for Multi-Modal Brain Tumor Segmentation,"second, most existing mri segmentation methods
still have difficulty capturing global interaction information while effectively
encoding local information.",
590,DBTrans: A Dual-Branch Vision Transformer for Multi-Modal Brain Tumor Segmentation,"here we use parameter γ to balance the
two loss parts.",
591,DBTrans: A Dual-Branch Vision Transformer for Multi-Modal Brain Tumor Segmentation,"we use the multimodal brain tumor segmentation challenge (brats 2021
[33,34,38]) as the benchmark training set, validation set, and testing set.",x
592,HartleyMHA: Self-attention in Frequency Domain for Resolution-Robust and Parameter-Efficient 3D Image Segmentation,"to balance
between computational complexity and network capability, input size reductions
by image downsampling and patch-wise training are common approaches.",
593,HartleyMHA: Self-attention in Frequency Domain for Resolution-Robust and Parameter-Efficient 3D Image Segmentation,"although only the results of a dataset are shown because of
the page limit, the characteristics of the proposed models can be demonstrated
through this challenging multi-modal brain tumor segmentation problem.",
594,MDViT: Multi-domain Vision Transformer for Small Medical Image Segmentation Datasets,"however, due to the lack of inductive biases, such as
weight sharing and locality, vits are more data-hungry than cnns, i.e., require
more data to train [31].",x
595,MDViT: Multi-domain Vision Transformer for Small Medical Image Segmentation Datasets,"as each
dataset alone is too small to properly train a vit, the challenge becomes how to
effectively leverage the different datasets.",
596,MDViT: Multi-domain Vision Transformer for Small Medical Image Segmentation Datasets,"various strategies have been
proposed to address vits' data-hunger (table 1), mainly: adding inductive bias
by constructing a hybrid network that fuses a cnn with a vit [39], imitating
cnns' shifted filters and convolutional operations [7], or enhancing spatial
information learning [22]; sharing knowledge by transferring knowledge from a
cnn [31] or pertaining vits on multiple related tasks and then fine-tuning on a
down-stream task [37]; increasing data via augmentation [34]; and non-supervised
pre-training [8].",
597,MDViT: Multi-domain Vision Transformer for Small Medical Image Segmentation Datasets,"we
implement resnet-34 as the backbone of bat for fair comparison (similar model
size).",
598,MDViT: Multi-domain Vision Transformer for Small Medical Image Segmentation Datasets,"previous mis
vits mitigated the data-hunger in one dataset by adding inductive bias, e.g.,
swinunet the online version contains supplementary material available at
https://doi.org/10.1007/978-3-031-43901-8 43.",x
599,M-GenSeg: Domain Adaptation for Target Modality Tumor Segmentation with Annotation-Efficient Supervision,"however, the success of most existing
architectures relies on the availability of pixel-level annotations, which are
difficult to produce [1].",
600,M-GenSeg: Domain Adaptation for Target Modality Tumor Segmentation with Annotation-Efficient Supervision,"this challenge could also be addressed through
unsupervised domain-adaptive approaches, which transfer the knowledge available
in the ""source"" modality s from pixel-level labels to the ""target"" imaging
modality t lacking annotations [4].several generative models attempt to
generalize to a target modality by performing unsupervised domain adaptation
through image-to-image translation and image reconstruction.",
601,M-GenSeg: Domain Adaptation for Target Modality Tumor Segmentation with Annotation-Efficient Supervision,"experiments were performed on the brats 2020 challenge dataset [23][24][25],
adapted for the cross-modality tumor segmentation problem where images are known
to be diseased or healthy.",x
602,Edge-Aware Multi-task Network for Integrating Quantification Segmentation and Uncertainty Prediction of Liver Tumor on Multi-modality Non-contrast MRI,"no attempt has been
made to automatically liver tumor multi-task via integrating multi-modality
ncmri due to the following challenges: (1) the lack of an effective
multi-modality mri fusion mechanism.",
603,Edge-Aware Multi-task Network for Integrating Quantification Segmentation and Uncertainty Prediction of Liver Tumor on Multi-modality Non-contrast MRI,"at the same time, eamt-net utilizes the boundary information
extracted by the sobel filter [19] as prior knowledge to enhance the weight of
tumor edge information to increase the awareness of the boundary.",
604,Edge-Aware Multi-task Network for Integrating Quantification Segmentation and Uncertainty Prediction of Liver Tumor on Multi-modality Non-contrast MRI,"on the basis
of the 1d sequence, to make the feature fusion with edge awareness, the
operation of position encoding is performed not only on feature maps but also on
edge maps.",
605,Edge-Aware Multi-task Network for Integrating Quantification Segmentation and Uncertainty Prediction of Liver Tumor on Multi-modality Non-contrast MRI,"the new eafa
enhances edge awareness by utilizing boundary information as prior knowledge
while capturing the long-range dependency of features to improve feature
selection and fusion.",
606,RCS-YOLO: A Fast and High-Accuracy Object Detector for Brain Tumor Detection,"though many advanced cnns deliver higher accuracy, the
complicated multi-branch designs (e.g., residual-addition in resnet and
branch-concatenation in inception) make the models difficult to implement and
customize, slowing down the inference and reducing memory utilization.",
607,Certification of Deep Learning Models for Medical Image Segmentation,"in this paper, we propose to leverage randomized smoothing and
diffusion models for certified segmentation on medical datasets, setting the
first baseline for this challenging problem and certifying popular segmentation
architectures.",
608,Certification of Deep Learning Models for Medical Image Segmentation,"to address this issue,
cohen et al.",
609,Certification of Deep Learning Models for Medical Image Segmentation,"montgomery consists of 138 and shenzen of 662 annotated images.skin lesion: skin
images with their annotations provided by the isic 2018 boundary segmentation
challenge [10] were used.",x
610,Category-Level Regularized Unlabeled-to-Labeled Learning for Semi-supervised Prostate Segmentation with Multi-site Unlabeled Data,"yet, due to differences
in imaging protocols and variations in patient demographics, this solution
usually introduces data heterogeneity, lead-ing to a quality problem.",x
611,Category-Level Regularized Unlabeled-to-Labeled Learning for Semi-supervised Prostate Segmentation with Multi-site Unlabeled Data,"yet, their
adversarial min-max optimization often leads to instability and it is difficult
to align multiple external sources with the local source using a single image
mapping network.in this work, we propose a more generalized framework called
categorylevel regularized unlabeled-to-labeled (cu2l) learning, as depicted in
fig.",
612,Category-Level Regularized Unlabeled-to-Labeled Learning for Semi-supervised Prostate Segmentation with Multi-site Unlabeled Data,"the key challenge of ms-ssl is the proper design of l u for
robustly exploiting multi-site unlabeled data {d u local , d u e } to support
the local center.",
613,Category-Level Regularized Unlabeled-to-Labeled Learning for Semi-supervised Prostate Segmentation with Multi-site Unlabeled Data,"yet, with limited local labeled data for
training, it is difficult to generate high-quality pseudo labels.",
614,Category-Level Regularized Unlabeled-to-Labeled Learning for Semi-supervised Prostate Segmentation with Multi-site Unlabeled Data,"inherently, the challenge of ms-ssl stems from
intra-class variation, which results from different imaging protocols, disease
progress and patient demographics.",x
615,Category-Level Regularized Unlabeled-to-Labeled Learning for Semi-supervised Prostate Segmentation with Multi-site Unlabeled Data,"specifically, we introduce category-level regularization, which advocates class
prototype alignment between local and external data, to regularize the
distribution of intra-class features from arbitrary external data to be closer
to the local one, thus reducing the difficulty of u2l learning.",
616,Category-Level Regularized Unlabeled-to-Labeled Learning for Semi-supervised Prostate Segmentation with Multi-site Unlabeled Data,"all methods are implemented
with the same backbone and training protocols to ensure fairness.",x
617,Category-Level Regularized Unlabeled-to-Labeled Learning for Semi-supervised Prostate Segmentation with Multi-site Unlabeled Data,"meanwhile, the most relevant ahdc [2] is mediocre in ms-ssl, mainly due to the
instability of adversarial training and the difficulty of aligning multiple
distributions to the local distribution via a single image-mapping network.",
618,Category-Level Regularized Unlabeled-to-Labeled Learning for Semi-supervised Prostate Segmentation with Multi-site Unlabeled Data,"if we remove l cr which accompanies with l u2l (cu2l-3), the performance
degrades, which justifies the necessity of this regularization to reduce the
difficulty of unlabeled-to-labeled learning process.",
619,A Sheaf Theoretic Perspective for Robust Prostate Segmentation,"however, this increases training
time and we propose to tackle the problem head on by learning shape only
embedding features to build a shape dictionary using vector quantisation [31]
which can be sampled to compose the segmentation output.",
620,A Sheaf Theoretic Perspective for Robust Prostate Segmentation,"recent methods have utilized adversarial techniques,
such as advbias [11], which trains the model to generate bias field deformations
and enhance its robustness.randconv [33] incorporates a randomized convolution
layer to learn textural invariant features.",
621,MedNeXt: Transformer-Driven Scaling of ConvNets for Medical Image Segmentation,"however, transformers are plagued by
the necessity of large annotated datasets to maximize performance benefits owing
to their limited inductive bias.",
622,MedNeXt: Transformer-Driven Scaling of ConvNets for Medical Image Segmentation,"to retain the
inherent inductive bias of convolutions while taking advantage of architectural
improvements of transformers, the convnext [22] was recently introduced to
re-establish the competitive performance of convolutional networks for natural
images.",
623,MedNeXt: Transformer-Driven Scaling of ConvNets for Medical Image Segmentation,"out-of-the-box
data-efficient solutions such as nnunet [13], using variants of a standard unet
[5], have still remained effective across a wide range of tasks.the convnext
architecture marries the scalability and long-range spatial representation
learning capabilities of vision [7] and swin transformers [21] with the inherent
inductive bias of convnets.",
624,MedNeXt: Transformer-Driven Scaling of ConvNets for Medical Image Segmentation,"however, 3d-ux-net only uses these blocks partially in a
standard convolutional encoder, limiting their possible benefits.in this work,
we maximize the potential of a convnext design while uniquely addressing
challenges of limited datasets in medical image segmentation.",
625,MedNeXt: Transformer-Driven Scaling of ConvNets for Medical Image Segmentation,"compression layer: convolution
layer with 1 × 1 × 1 kernel and c output channels performing channel-wise
compression of the feature maps.mednext is convolutional and retains the
inductive bias inherent to conv-nets that allows easier training on sparse
medical datasets.",
626,MedNeXt: Transformer-Driven Scaling of ConvNets for Medical Image Segmentation,"medical image segmentation tasks have significantly less data and
performance saturation can be a problem in large kernel networks.",
627,MedNeXt: Transformer-Driven Scaling of ConvNets for Medical Image Segmentation,"specifically, swin transformers use a bias matrix b ∈
r (2m -1)×(2m -1) to store learnt relative positional embeddings, where m is the
number of patches in an attention window.",
628,MedNeXt: Transformer-Driven Scaling of ConvNets for Medical Image Segmentation,"the authors proposed spatially
interpolating an existing bias matrix to the larger size as a pretraining step,
instead of training from scratch, which demonstrated improved performance.",
629,MedNeXt: Transformer-Driven Scaling of ConvNets for Medical Image Segmentation,"we use 4 popular tasks, encompassing organ as well as tumor segmentation tasks,
to comprehensively demonstrate the benefits of the mednext architecture -1)
beyond-the-cranial-vault (btcv) abdominal ct organ segmentation [16], 2) amos22
abdominal ct organ segmentation [14] 3) kidney tumor segmentation challenge 2019
dataset (kits19) [11], 4) brain tumor segmentation challenge 2021 (brats21) [1].",
630,MedNeXt: Transformer-Driven Scaling of ConvNets for Medical Image Segmentation,"in comparison to natural image analysis, medical image segmentation lacks
architectures that benefit from scaling networks due to inherent domain
challenges such as limited training data.",
631,Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,"however, as
illustrated in [9,23], it is rather difficult for cnns to recognize the object
boundary precisely due to the information loss in the successive downsampling
layers.",
632,Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,"our
previously proposed kspc provides a clear framework to calculate the probability
contours of the suv values and can readily be used to define an objective
strategy for segmenting tumours into subregions based on metabolic activities,
which in turn can be used to design the imrt dp strategy.to address both tumour
delineation and corresponding dose painting challenges, we propose to combine
the expressiveness of deep cnns with the versa-tility of kspc in a unified
framework, which we call kspc-net.",
633,Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,"more
specifically, we use the classic unet [17] as the cnn backbone and evaluate our
kspc-net on the publicly available miccai hecktor (head and neck tumor
segmentation) challenge 2021 dataset.",
634,Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,"the dataset is from the hecktor challenge in miccai 2021 (head and neck tumor
segmentation challenge).",
635,Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,"additionally, we compare our
performance against newly developed approaches msa-net [7] and ccut-net [21]
which were reported in the hecktor 2021 challenges [1].",
636,Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,"promising performance was achieved by
our proposed kspc-net compared to the state-of-the-art approaches on the miccai
2021 challenge dataset (hecktor).",
637,A2FSeg: Adaptive Multi-modal Fusion Network for Medical Image Segmentation,"however, in practice, we face the challenge of collecting all modalities at the
same time, with often one or more missing.",
638,A2FSeg: Adaptive Multi-modal Fusion Network for Medical Image Segmentation,"therefore, in this paper, we consider
the problem of segmenting brain tumors with missing image modalities.current
image segmentation methods for handling missing modalities can be divided into
three categories, including: 1) brute-force methods: designing individual
segmentation networks for each possible modality combination [18], 2) completion
methods: synthesizing the missing modalities to complete all modalities required
for conventional image segmentation methods [16], and 3) fusionbased methods:
mapping images from different modalities into the same feature space for fusion
and then segmenting brain tumors based on the fused features [10].",
639,A2FSeg: Adaptive Multi-modal Fusion Network for Medical Image Segmentation,"to address this issue, we normalize the
different attention weights by using a softmax function:that is, we only
consider feature maps from those available modalities but normalize their
contribution to the final fusion result, so that, the fused one has a consistent
value range, no matter how many modalities are missing.",
640,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"concerning the inherent issue of imbalanced tumor types in the training data
collected in clinic, a novel ordinal manifold mixup based feature augmentation
is presented and applied in the training stage of the tumor subtyping network.",
641,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"in this way, inconsistency between the augmented features and the corresponding
labels can be effectively reduced.our method is evaluated using pre-operative
multimodal mr brain images of 1726 diffuse glioma patients collected from
cooperation hospitals and a public dataset brats2019 [12] containing multimodal
mr brain images of 210 patients.",
642,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"to solve the inherent issue of
imbalanced tumor type in the training data collected in clinic, a novel ordinal
manifold mixup based feature augmentation is applied in the training of the
tumor subtyping network.",
643,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"in addition, information of patient age and tumor
position is also used.",
644,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"to solve the imbalance issue
of tumor types in the training of the tumor subtyping network, a novel ordinal
manifold mixup based feature augmentation is presented.",
645,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"for
binary classification, the original manifold mixup can effectively enhance the
network performance, however, for the classification of more than two classes,
e.g., tumor types, there exists a big issue.as shown in fig.",
646,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"specifically, the in-house dataset collected in cooperation hospitals
contains pre-operative multimodal mr images, including t1, t1 contrast enhanced
(t1c), t2, and flair, of 1726 patients (age 49.7 ± 13.1) with confirmed diffuse
glioma types.",
647,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"besides the inhouse
dataset, a public dataset brats2019, including pre-operative multimodal mr
images of 210 non-censored patients (age 61.4 ± 12.2), is adopted as the
external independent testing dataset.",
648,Medical Boundary Diffusion Model for Skin Lesion Segmentation,"despite these advances, the segmentation
of skin lesions with ambiguous boundaries, particularly at extremely challenging
scales, remains a bottleneck issue that needs to be addressed.",
649,Medical Boundary Diffusion Model for Skin Lesion Segmentation,"as studied prior,
solving the segmentation problems of such two types of lesions have different
strategies.",
650,Medical Boundary Diffusion Model for Skin Lesion Segmentation,"besides the challenge of how to
yield stable representations for various scales, multi-scale lesions will cause
training fluctuation, that is, small lesions usually lead to large dice loss.",
651,Medical Boundary Diffusion Model for Skin Lesion Segmentation,"the latest transformer, xbound-former, comprehensively
addresses the multi-scale boundary problem through cross-scale boundary learning
and exactly reaches higher performance on whatever small or large
lesions.however, current models for skin lesion segmentation are still
struggling with extremely challenging cases, which are often encountered in
clinical practice.",
652,Medical Boundary Diffusion Model for Skin Lesion Segmentation,"these metrics include the dice score, the iou score,
average symmetric surface distance (assd), and hausdorff distance of boundaries
(95-th percentile; hd95).to ensure fair comparison, all labels and predictions
are resized to (512×512) before computing these scores, following the approach
of a previous study [18].",
653,Medical Boundary Diffusion Model for Skin Lesion Segmentation,"additionally, we evaluate our method against medsegdiff
[22], a recently released diffusion-based model, which we re-trained for 200,000
steps to ensure a fair comparison.",
654,Medical Boundary Diffusion Model for Skin Lesion Segmentation,"to ensure a fair comparison, we average the
scores of multiple evolutions to represent the performance of ""w/o fusion"".",
655,H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation,"other works like [9] and [33], which combine
the transformer with the multimodal feature fusion approaches mentioned above,
further demonstrate the potential of this idea for multimodal tumor
segmentation.although remarkable performance has been accomplished with these
efforts, there still exist several challenges to be resolved.",
656,H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation,"to address this problem, we propose the densely connected
transformer (dct) module inspired by densenet [17] to balance computational cost
and representation capability.",
657,H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation,"to mitigate the
pixel imbalance problem, we use a combined loss of focal loss [23] and dice loss
as the optimization target, defined as follows:where n refers to the total
number of pixels, p t and q t denote the predicted probability and ground truth
of the t-th pixel, respectively, and r = 2 is the modulation factor.",
658,H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation,"for a fair
comparison, all models are trained from scratch using two nvidia a100 gpus and
all comparison methods are implemented with open-source codes, following their
original configurations.",
659,H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation,"online data augmentation,
including random rotation and flipping, is performed to alleviate the
overfitting problem.",
660,H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation,"overall, h-denseformer reaches an
effective balance of performance and computational cost compared to existing
cnns and hybrid structures.",
661,H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation,"concretely, a
multi-path parallel embedding module and a densely connected transformer block
were developed and integrated to balance accuracy and computational complexity.",
662,TransNuSeg: A Lightweight Multi-task Transformer for Nuclei Segmentation,none,
663,Learnable Cross-modal Knowledge Distillation for Multi-modal Learning with Missing Modality,"however, most existing multi-modal methods require
complete modalities during training and testing, which limits their
applicability in real-world scenarios, where subsets of modalities may be
missing during training and testing.the missing modality issue is a significant
challenge in the multi-modal domain, and it has motivated the community to
develop approaches that attempt to address this problem.",
664,Learnable Cross-modal Knowledge Distillation for Multi-modal Learning with Missing Modality,"[5]
proposed an rfm module to fuse the modal features based on the sensitivity of
each modality to different tumor regions and a segmentation-based regularizer to
address the imbalanced training problem.",
665,Learnable Cross-modal Knowledge Distillation for Multi-modal Learning with Missing Modality,"an
interesting fact about multi-modal problems is that there is always one modality
that contributes much more than other modalities for a certain task.",
666,Learnable Cross-modal Knowledge Distillation for Multi-modal Learning with Missing Modality,"however, the aforementioned methods neglect the contribution biases
of different modalities and failed to consider keeping that knowledge.aiming at
this issue, we propose the non-dedicated training model1 learnable cross-modal
knowledge distillation (lckd) for tackling the missing modality issue.",
667,Learnable Cross-modal Knowledge Distillation for Multi-modal Learning with Missing Modality,"our main contributions are:-we propose the learnable cross-modal
knowledge distillation (lckd) model to address missing modality problem in
multi-modal learning.",
668,Learnable Cross-modal Knowledge Distillation for Multi-modal Learning with Missing Modality,"our model and competing methods are evaluated on the brats2018 segmentation
challenge dataset [1,14].",
669,Learnable Cross-modal Knowledge Distillation for Multi-modal Learning with Missing Modality,"the lckd-m model can overcome this issue since it attempts to find a point in
the parameter space that is beneficial for all tasks.",
670,Learnable Cross-modal Knowledge Distillation for Multi-modal Learning with Missing Modality,"experiments on brats2018 [1,14] show that lckd reaches state-of-the-art
performance in missing modality segmentation problems.",
671,Learnable Cross-modal Knowledge Distillation for Multi-modal Learning with Missing Modality,"we plan to improve this point by transforming
this problem into a meta-learning strategy, where the meta parameter is the
weight for each modality, which will be optimised per task.",
672,QCResUNet: Joint Subject-Level and Voxel-Level Prediction of Segmentation Quality,"to address these challenges, we
propose a novel framework for joint subject-level and voxel-level prediction of
segmentation quality from multimodal mri.",
673,QCResUNet: Joint Subject-Level and Voxel-Level Prediction of Segmentation Quality,"the
two parts are combined using a weight parameter λ to balance the different loss
components:3 experimentsfor this study, pre-operative multimodal mri scans of
varying grades of glioma were obtained from the 2021 brain tumor segmentation
(brats) challenge [1] training dataset (n = 1251).",
674,QCResUNet: Joint Subject-Level and Voxel-Level Prediction of Segmentation Quality,"however, this generated dataset suffered from
imbalance (fig.",
675,QCResUNet: Joint Subject-Level and Voxel-Level Prediction of Segmentation Quality,"training using such an imbalanced dataset is prone to
producing biased models that do not generalize well.",
676,QCResUNet: Joint Subject-Level and Voxel-Level Prediction of Segmentation Quality,"to mitigate this issue, we
proposed a resampling strategy during the training to make the dsc more
uniformly distributed.",
677,QCResUNet: Joint Subject-Level and Voxel-Level Prediction of Segmentation Quality,"for a fair comparison,
the residual blocks in the resnet-34 and resnet-50 were the same as that in the
qcresunet.",
678,QCResUNet: Joint Subject-Level and Voxel-Level Prediction of Segmentation Quality,"we performed a random search [2]
to determine the optimal hyperparameters (i.e., initial learning rate and loss
weight balance parameter λ) on the training and validation set.",
679,EGE-UNet: An Efficient Group Enhanced UNet for Skin Lesion Segmentation,"as
estimated by the american cancer society, there were approximately 100,350 new
cases and over 6,500 deaths in 2020 [14].",
680,EGE-UNet: An Efficient Group Enhanced UNet for Skin Lesion Segmentation,"to overcome the quadratic complexity issue posed by mhsa, we propose hpa
with linear complexity.",
681,Diffusion Kinetic Model for Breast Cancer Segmentation in Incomplete DCE-MRI,"however, the
aforementioned methods require the complete dce-mri sequences and overlook the
difficulty in assessing complete temporal sequences and the missing time point
problem, especially post-contrast phase, due to the privacy protection and
patient conditions.",
682,Diffusion Kinetic Model for Breast Cancer Segmentation in Incomplete DCE-MRI,"considering the varying
sizes, shapes and appearances of tumors that results from intratumor
heterogeneity and results in difficulties of accurate cancer annotation, we
design the segmentation loss as follows:where l ssim is used to evaluate tumor
structural characteristics, s and g represents segmentation map and ground
truth, respectively; μ s is the mean of s and μ g is the mean of g; ϕ s
represents the variance of s and ϕ g represents the variance of g; c 1 and c 2
denote the constant to hold training stable [15], and ϕ sg is the covariance
between s and g.",
683,Diffusion Kinetic Model for Breast Cancer Segmentation in Incomplete DCE-MRI,no data augmentation techniques are used to ensure fairness.,
684,Diffusion Kinetic Model for Breast Cancer Segmentation in Incomplete DCE-MRI,"no data augmentation techniques are used to ensure
fairness.comparison with sota methods: the quantitative comparison of the
proposed method to recent state-of-the-art methdos is reported in table 1.",
685,Diffusion Kinetic Model for Breast Cancer Segmentation in Incomplete DCE-MRI,"it probably due to two aspects: 1) the hemodynamic
knowledge is implicitly exploited by diffusion module from pre-contrast images,
which is useful for cancer segmentation.2) the intermediate activations from
diffusion models effectively capture the semantic information and are excellent
pixel-level representations for the segmentation problem [9].",
686,Morphology-Inspired Unsupervised Gland Segmentation via Selective Semantic Grouping,"to
address this issue, previous works have exploited conventional clustering
[8,22,23] and metric learning [10,29] to design annotation-free methods for
gland segmentation.",
687,Morphology-Inspired Unsupervised Gland Segmentation via Selective Semantic Grouping,"this is because these methods are usually designed to be extremely
sensitive to color [2], while gland images present a unique challenge due to
their highly dense and complex tissues with intricate color distribution [18].",
688,Morphology-Inspired Unsupervised Gland Segmentation via Selective Semantic Grouping,"as such, the e2e clustering methods tend to blindly cluster pixels
with similar properties and confuse many gland regions with the background,
leading to under-segment results.to tackle the above challenges, our solution is
to incorporate an empirical cue about gland morphology as additional knowledge
to guide gland segmentation.",
689,Morphology-Inspired Unsupervised Gland Segmentation via Selective Semantic Grouping,"1(b).our contributions are as follows: (1) we identify the major challenge
encountered by prior unsupervised semantic segmentation (uss) methods when
dealing with gland images, and propose a novel mssg for unsupervised gland
segmentation.",
690,Morphology-Inspired Unsupervised Gland Segmentation via Selective Semantic Grouping,"as such, we propose two types of
morphology-aware semantic grouping (msg) modules (i.e., msg for variation and
msg for omission) to respectively reduce the confusion caused by the two
challenges mentioned above and improve the overall accuracy and
comprehensiveness of the segmentation results.",
691,Morphology-Inspired Unsupervised Gland Segmentation via Selective Semantic Grouping,"then, we use the average of the pixel embeddings in
gland border set g as the alignment anchor and pull all pixels of i towards the
anchor:(msg for omission is designed to overcome the problem of partial omission
in the proposals.",
692,Morphology-Inspired Unsupervised Gland Segmentation via Selective Semantic Grouping,"we evaluate our mssg on the gland segmentation challenge (glas) dataset [27] and
the colorectal adenocarcinoma gland (crag) dataset [13].",
693,Morphology-Inspired Unsupervised Gland Segmentation via Selective Semantic Grouping,"the
crag dataset has more irregular malignant glands, which makes it more difficult
than glas, and we would like to emphasize that the results on crag are from the
model trained on glas without retraining.",
694,Morphology-Inspired Unsupervised Gland Segmentation via Selective Semantic Grouping,"for a fair comparison, the results of all
unsupervised methods in table 1 are obtained using the same backbone trained
with the corresponding pseudo-labels.",
695,Morphology-Inspired Unsupervised Gland Segmentation via Selective Semantic Grouping,"this paper explores a dl method for unsupervised gland segmentation, which aims
to address the issues of over/under segmentation commonly observed in previous
uss methods.",
696,EoFormer: Edge-Oriented Transformer for Brain Tumor Segmentation,"our approach combines the strengths of cnn
and transformer to create a more powerful encoder that can extract both local
and global information from input data.we address the computational and memory
complexity issues that arise from 3d input by replacing the vanilla attention
with our extended 3d efficient attention.",
697,EoFormer: Edge-Oriented Transformer for Brain Tumor Segmentation,"specifically, we explain the re-parameterization of the eol
module as follows:where ' * ' represents the convolution operation, w conv means
the weights of the convolution and b conv denotes the bias, and up(•) is the
spatial broadcasting operation ,which upgrades the bias b ∈ r 1×c×1×1×1 into
up(b) ∈ r 1×c×3×3×3 .",
698,EoFormer: Edge-Oriented Transformer for Brain Tumor Segmentation,"the encoder effectively extracts features from
images by striking a balance between cnn and transformer architectures.",
699,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"medical image analysis has greatly benefited from advances in ai [1] yet some
improvements still remain to be addressed, importantly in areas that allow both
algorithmic performance and fairness [2], and in certain medical applications
that promise to significantly lessen morbidity and mortality.",
700,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"on one hand, some datasets-such as
ham10000 [10] and isbi challenges [11]-have manual annotated segmentations for
diseases like melanoma, but they do not have lyme disease lesions.",
701,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"furthermore, clinical data collected for training is
usually imbalanced in some properties, e.g., more samples with light skins
compared with dark skins.",
702,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"therefore, existing skin disease segmentation [13] as
well as existing general segmentation works, such as u-net [14], polar training
[15], vit-adapter [16], and mfsnet [17], usually suffer from relatively low
performance and reduced fairness [2,18,19].in this paper, we present the first
lyme disease dataset that contains labeled segmentation and skin tones.",
703,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"our
dataset with manual labels is available at this url [20].secondly, we design a
simple yet novel data preprocessing and alternation method, called edgemixup, to
improve lyme disease segmentation and diagnosis fairness on samples with
different skin-tones.",
704,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"such an
improvement is an iterative process that gradually improves lesion edge
detection and segmentation fairness until convergence.",
705,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"then, the detected,
converged edge in the first step also helps classification of lyme diseases via
mixup with improved fairness.",
706,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"our
results show that edgemixup is able to increase segmentation utility and improve
fairness.",
707,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"we also show that the improved segmentation further improves
classification fairness as well as joint fairness-utility metrics compared to
existing debiasing methods, e.g., ad [21] and st-debias [22].",
708,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"in this section, we first give the definition for model fairness, and we then
describe the design of edgemixup for the purpose of de-biasing in fig.",
709,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"2
edgemixup improves model fairness on light and dark skin samples in both
segmentation and classification tasks, and it has two major components: (i) edge
detection using mixup, and (ii) data preprocessing and alteration for downstream
tasks.",
710,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"note that the
initial edge detection is irrelevant to the sample size of a particular
subpopulation, thus improving the fairness.",
711,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"that is, even if the original
dataset is imbalanced, as long as one sample from a subpopulation exists, the
color range of the sample's lesion is considered in the initial detection.",
712,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"our evaluation metrics include (i) jaccard index (iou score), which
measures the similarity between a predicted mask and the manually annotated
ground truth, and (ii) the gap between jaccard values (j gap ) to measure
fairness.",
713,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"table 2 shows the performance and fairness of edgemixup and different
baselines.",
714,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"our evaluation metrics include accuracy gap, the (rawlsian) minimum
accuracy across subpopulations, area under the receiver operating characteristic
curve (auc), and joint metrics (cai α and cauci α ).table 3 shows utility
performance (acc and auc) and fairness results (gaps of acc and auc between ls
and ds subpopulations).",
715,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"international skin imaging collaboration (isic) hosts challenges of
international symposium on biomedical imaging (isbi) [11] to encourage
researches studying lesion segmentation, feature detection, and image
classification.",
716,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"however, official datasets released, e.g., ham10000 [10] only
contains melanoma samples and all of the samples are with light skins according
to our inspection using ita scores.bias mitigation: researchers have addressed
bias and heterogeneity in deep learning models [18,29].",
717,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"first, masking sensitive
factors in imagery is shown to improve fairness in object detection and action
recognition [30].",
718,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"the key insight is a novel data
preprocessing method that utilizes edge detection and mixup to isolate and
highlight skin lesions and reduce bias.",
719,Factor Space and Spectrum for Medical Hyperspectral Image Segmentation,"they overlook the
low rankness in the spectral domain, which contains discriminative information
for differentiating targets from the background.high spatiospectral dimensions
make it difficult to perform a thorough analysis of mhsi.",
720,Factor Space and Spectrum for Medical Hyperspectral Image Segmentation,"for the
spectral stream, to deal with problems of spatiospectral redundancy and the
inefficiency of global spectral feature representation, we propose a novel and
concise hierarchical structure shown in fig.",
721,Factor Space and Spectrum for Medical Hyperspectral Image Segmentation,"then, we represent long-distance dependencies among
spectral inter-bands as a low-rank completion problem.",
722,Factor Space and Spectrum for Medical Hyperspectral Image Segmentation,"recent research [3,32] has proposed new methods based on
dnns to address this problem of representing mhsis as low-rank tensors.",
723,Factor Space and Spectrum for Medical Hyperspectral Image Segmentation,"69.89) lower dsc, possibly because transformers are difficult
to optimize on small datasets.",
724,Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,the tasks are formalized as graph-theoretic problems (fig.,
725,Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"however, the high overlap of clinical symptoms with other
psychiatric disorders and the absence of early non-invasive biomarkers make
accurate diagnosis difficult and time-consuming [3].although conventional
magnetic resonance imaging (mri) tools are widely used to detect brain injuries
and neuronal lesions, around 50% of patients with npsle present no brain
abnormalities in structural mri [17].",
726,Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"meanwhile, the individual differences
in metabolism and the interaction between metabolites under low sample size make
it difficult for traditional learning methods to distinguish npsle.",
727,Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"therefore, applying the same
sparsity constraint to the metabolic features of all brain regions may not
contribute to the improvement of the diagnostic performance of npsle.in light of
this, we propose a robust exclusive adaptive sparse feature selection (reasfs)
algorithm to jointly address the aforementioned problems in biomarker discovery
and early diagnosis of npsle.",
728,Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"dataset and preprocessing: the t2-weighted mr images of 39 participants
including 23 patients with npsle and 16 hcs were gathered from our affiliated
hospital.",
729,Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"all images were acquired at an average age of 30.6 years on a signa
3.0t scanner with an eight-channel standard head coil.",
730,Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"the frobenius norm offor sparse codingbased methods, the
general problem can be formulated aswhere l(w), r(w), and λ are the loss
function, the regularization term, and the hyperparameter, respectively.",
731,Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"the generalized correntropic loss function between a and b can be defined
asto analyze the adaptive weighting mechanism of generalized correntropy, we
consider an alternative problem of (1), wherethe optimal projection matrix w
should satisfy (∂j(w)/∂w) = 0, and we havewhere λ is a diagonal matrix with
error-based diagonal elementsfor adaptive sample weight.",
732,Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"we apply
generalized correntropy to the row vector w i of w to achieve the adaptive
weighted sparse constraint, and the problem (6) can be rewritten aswheresince
minimizing w i 2 is equivalent to maximizing exp(-s w i 2 ), we add a negative
sign to this term.",
733,Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"through the gcie 2,1 regularization term in (7), each feature
is expected to be enforced with a sparsity constraint of a different weight
according to its sparsity level of metabolic information in different brain
regions.optimization: since the gcie 2,1 is a non-smooth regularization term,
the final problem (7) can be optimized by the stochastic gradient method with
appropriate initialization of w.",
734,Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"once we obtained the solution
to the problem (7), the importance of feature i is proportional to w i 2 .",
735,CARL: Cross-Aligned Representation Learning for Multi-view Lung Cancer Histology Classification,"multi-view
deep learning, a 2.5d method, represents a promising solution to this issue, as
it focuses on obtaining a unified joint representation from different views of
lung nodules to capture abundant spatial information [16,20].",
736,CARL: Cross-Aligned Representation Learning for Multi-view Lung Cancer Histology Classification,"by integrating multi-view representations,
these methods efficiently preserve the spatial information of ct volumes while
significantly reducing the required computational resource compared to 3d cnns
[9,20,23].despite the promising results of previous multi-view methods, they
still confront a severe challenge for accurate nsclc histological subtype
prediction.",
737,CARL: Cross-Aligned Representation Learning for Multi-view Lung Cancer Histology Classification,"consequently, the
discrepancies of distinct views will hamper the fusion of multi-view
information, limiting further improvements in the classification performance.to
overcome the challenge mentioned above, we propose a novel cross-aligned
representation learning (carl) method for the multi-view histologic subtype
classification of nsclc.",
738,CARL: Cross-Aligned Representation Learning for Multi-view Lung Cancer Histology Classification,"however, the distributions of h c
av , h c cv and h c sv are very complex due to the significant variations
between different views, which puts a burden on obtaining well-aligned
view-invariant representations with merely an encoder.to address this issue, we
design a discriminability-enforcing similarity loss l dsim to further enhance
the alignment of cross-view representations in the common subspace.",
739,CARL: Cross-Aligned Representation Learning for Multi-view Lung Cancer Histology Classification,"despite the fact that minimizing the l sim can
efficiently mitigate the issue of distributional disparities, it may not
guarantee that the alignment network will learn informative and discriminative
representations.",
740,CARL: Cross-Aligned Representation Learning for Multi-view Lung Cancer Histology Classification,"we
observed that l ce is hundred times smaller than l sim , so this study uses an
empirical value of λ = 110 to balance the magnitude of two terms.",
741,Self- and Semi-supervised Learning for Gastroscopic Lesion Detection,"generic self-supervised
backbone pre-training or semi-supervised detector training methods can solve the
first challenge for natural images but its effectiveness is undermined for
gastroscopic images due to the second challenge.self-supervised backbone
pre-training methods enhance object detection performance by learning
high-quality feature representations from massive unlabelled data for the
backbone.",
742,Self- and Semi-supervised Learning for Gastroscopic Lesion Detection,"current pseudolabel
generation methods rely on the objectiveness score threshold to generate
pseudo-labels, which makes them perform below expectations on gld, because the
characteristic of gastroscopic lesions makes it difficult to set a suitable
threshold to discover potential lesions meanwhile avoiding introducing much
noise.the motivation of this paper is to explore how to enhance gld performance
using massive unlabeled gastroscopic images to overcome the labeled data
shortage problem.",
743,Self- and Semi-supervised Learning for Gastroscopic Lesion Detection,"the main challenge for this goal is the characteristic of
gastroscopic lesions.",
744,Self- and Semi-supervised Learning for Gastroscopic Lesion Detection,"intuitively, such a challenge requires local feature
representations to contain enough detailed information, meanwhile preserving
discriminability.",
745,Self- and Semi-supervised Learning for Gastroscopic Lesion Detection,"enlightened by this, we propose the self-and semi-supervised
learning (ssl) framework tailored to address challenges in daily clinical
practice and use massive unlabeled data to enhance gld performance.",
746,Self- and Semi-supervised Learning for Gastroscopic Lesion Detection,"ssl
overcomes the challenges of gld by leveraging a large volume of unlabeled
gastroscopic images using self-supervised learning for improved feature
representations and semi-supervised learning to discover and utilize potential
lesions to enhance performance.",
747,Self- and Semi-supervised Learning for Gastroscopic Lesion Detection,"in semi-supervised
learning, ppg generates pseudo-labels for unlabeled data relying on the
similarity to the prototype feature vectors, which achieves a better balance
between lesion discovery and noise avoidance.memory module.",
748,Self- and Semi-supervised Learning for Gastroscopic Lesion Detection,"collection : lgmdd collects about 1m+ gastroscopic
images from 2 hospitals of about 500 patients and their diagnosis reports.",
749,Self- and Semi-supervised Learning for Gastroscopic Lesion Detection,"4) endo21: to further evaluate the effectiveness of
ssl, we conduct experiments on endo21 [2] sub-task 2 (endo21 challenge consists
of 4 sub-tasks and only the sub-task 2 train/test split is available according
to the [2]).",
750,Revisiting Feature Propagation and Aggregation in Polyp Segmentation,"to further address the issue of
high-level semantics being overwhelmed in the progressive feature fusion
process, we also integrate a feature aggregation enhancement (fae) module that
aggregates the outputs of fpe from previous stages at decoder.",
751,"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","we address this imbalance in
the supplementary materials.",
752,"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","we use
weighted metrics due to the class imbalance in our dataset.",
753,Automatic Bleeding Risk Rating System of Gastric Varices,"this may cause inconsistency or even
misdiagnosis due to the variant experience of endoscopists in different
hospitals.",
754,Automatic Bleeding Risk Rating System of Gastric Varices,"in the public dataset of
endocv challenge [2], the majority are colonoscopies while only few are
gastroscopy images.",
755,Automatic Bleeding Risk Rating System of Gastric Varices,"to solve this issue, we first embed a
segmentation network into the classification framework.",
756,Automatic Bleeding Risk Rating System of Gastric Varices,"all of these cases are collected
from 411 patients in a grade-iii class-a hospital during the period from 2017 to
2022.",
757,Automatic Bleeding Risk Rating System of Gastric Varices,"2) moderate: moderate risk
of bleeding, and endoscopic treatment is necessary, with relatively low
endoscopic treatment difficulty (usually with a diameter between 5 mm and 10
mm).",
758,Automatic Bleeding Risk Rating System of Gastric Varices,"3) severe: high risk of bleeding and endoscopic treatment is necessary,
with high endoscopic treatment difficulty.",
759,Automatic Bleeding Risk Rating System of Gastric Varices,"to solve this
issue, we constructively introduce segmentation to enhance the robustness of
representation learning.",
760,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"bias in medicine has demonstrated a notable challenge for providing
comprehensive and equitable care.",
761,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"implicit biases can negatively affect patient
care, particularly for marginalized populations with lower socioeconomic status
[30].",
762,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"evidence has demonstrated that implicit biases in healthcare providers
could contribute to exacerbating these healthcare inequalities and create a more
unfair system for people of lower socioeconomic status [30].",
763,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"based on the data
with racial bias, the unfairness presents in developing evaluative algorithms.",
764,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"along these advancements, bias in
healthcare and ai are exposing poignant gaps in the field's understanding of
model implementation and their utility [25,26].",
765,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"ai model quality relies on input
data and addressing bias is a crucial research area.",
766,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"systemic bias poses a
greater threat to ai model's applications, as these biases can be baked right
into the model's decision process [22].pulmonary embolism (pe) is an example of
health disparities related to race.",
767,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"black patients exhibit a 50% higher
age-standardized pe fatality rate and a twofold risk for pe hospitalization than
white patients [18,24].",
768,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"survival
analysis is often used in pe to assess how survival is affected by different
variables, using a statistical method like kaplan-meier method and cox
proportional-hazards regression model [7,12,14].however, one issue with
traditional survival analysis is bias from single modal data that gets
compounded when curating multimodal datasets, as different combinations of modes
and datasets create with a unified structure.",
769,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"multimodal data sets are useful
for fair ai model development as the bias complementary from different sources
can make de-biased decisions and assessments.",
770,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"in that process, the biases of
each individual data set will get pooled together, creating a multimodal data
set that inherits multiple biases, such as racial bias [1,15,23].",
771,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"in addition,
it has been found that creating multimodal datasets without any debiasing
techniques does not improve performance significantly and does increase bias and
reduce fairness [5].",
772,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"overall, a holistic approach to model development would be
beneficial in reducing bias aggregation in multimodal datasets.",
773,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"in recent years,
disentangled representation learning (drl) [4] for bias disentanglement improves
model generalization for fairness [3,6,27].we developed a pe outcome model that
predicted mortality and detected bias in the output.",
774,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"we then implemented methods
to remove racial bias in our dataset and model and output unbiased pe outcomes
as a result.",
775,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"our contributions are as follows: (1) we identified bias diversity
in multimodal information using a survival prediction fusion framework.",
776,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"(2) we
proposed a de-biased survival prediction framework with demographic bias
disentanglement.",
777,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"(3) the multimodal cph learning models improve fairness with
unbiased features.",
778,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"this section describes the detail of how we identify the varying degrees of bias
in multimodal information and illustrates bias using the relative difference in
survival outcomes.",
779,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"we will first introduce our pulmonary embolism multimodal
datasets, including survival and race labels.",
780,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the pulmonary embolism dataset used in this study from 918
patients (163 deceased, median age 64 years, range 13-99 years, 52% female),
including 3978 ctpa images and 918 clinical reports, which were identified via
retrospective review across three institutions.",
781,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"for each patient, the race labels, survival time-to-event labels and
pesi variables are collected from clinical data, and the 11 pesi variables are
used to calculate the pesi scores, which include age, sex, comorbid illnesses
(cancer, heart failure, chronic lung disease), pulse, systolic blood pressure,
respiratory rate, temperature, altered mental status, and arterial oxygen
saturation at the time of diagnosis [2].diverse bias of multimodal survival
prediction model.",
782,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"this
redundancy leads to model overfitting on race, compromising the fairness of risk
prediction across different races.",
783,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"besides, clinical data in the form of text
reports and pesi variables objectively reflect the patient's physiological
information and the physician's diagnosis, exhibiting smaller race biases in
correlation with survival across different races.",
784,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"2, we
present a feature-level de-biased sp module that enhances fairness in survival
outcomes by decoupling race attributes, as shown in the lower right of fig.",
785,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"in the de-biased sp module, firstly, two separate encoders e m i and e m c are
formulated to embed features f m into disentangled latent vectors for
race-intrinsic attributes z id or race-conflicting attributes z sur implied
survival information [16].",
786,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"then, the linear classifiers c m i and c m c
constructed to predict the race label y id with concatenated vector z = [z id ;
z sur ].",
787,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"to disentangle survival features from the race identification, we use
the generalized cross-entropy (gce) loss [31] to train e m c and c m c to
overfit to race label while training e m i and c m i with crossentropy (ce)
loss.",
788,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,the relative difficulty scores w as defined in eq.,
789,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"1 reweight and enhance
the learning of the race-intrinsic attributes [20].",
790,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"2, but the parameters of id or survival branch are
only updated by their respective losses:to promote race-intrinsic learning in e
m i and c m i , we apply diversify with latent vectors swapping.",
791,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"as the random combination are generated from different samples, the
swapping decreases the correlation of these feature vectors, thereby enhancing
the race-intrinsic attributes.",
792,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the weights λ sw
and λ sur are assigned as 0.5 and 0.8, respectively, to balance the feature
disentanglement and survival prediction.",
793,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"in
general, our framework including de-biased sp modules shows significantly better
predictions in testing set than the pesi-based outcome estimation with c-indexes
of 0.669, 0.654, 0.697, 0.043 for the overall testset, white testset, color
testset and race bias.",
794,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the de-biased results outperform the baseline in overall
survival c-index and show a lower race bias, especially in imaging-and
fusion-based predictions.",
795,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the results indicate the effectiveness of the proposed
de-biasing in mitigating race inequity.",
796,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the results also prove the observations
for the different biases present in different modalities, especially in the ctpa
images containing more abundant race-related information.",
797,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the disentangled
representations, transformed from latent space to a 2d plane via tsne and
color-coded by race [9], are shown in fig.",
798,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"we observe the disentanglement in
the visualization of the id features z id , while the survival features z sur
eliminate the race bias.",
799,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the lack of apparent race bias observed in both the
original features and those encoded in the baseline can be attributed to the
subordinate role that id features play in the multimodal information.",
800,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"in addition, the predictions of
the de-biased framework show favorable performance, and our multimodal fusion
demonstrates a more pronounced discriminative ability in the k-m survival
analysis compared to the single-modal results.we conducted ablation studies to
examine the effect of the two key components, including swapping feature
augmentation and race-balance resampling.",
801,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the swapping augmentation provides a strong bias
correction effect for image data with obvious bias.",
802,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"in this work, we developed a de-biased survival prediction framework based on
the race-disentangled representation.",
803,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"we detected indications of racial bias in our dataset and
conducted an analysis of the multimodal diversity.",
804,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"experimental results
illustrate that our approach is effective for eliminating racial bias while
resulting in an overall improved model performance.",
805,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the proposed technique is
clinically relevant as it can address the pervasive presence of racial bias in
healthcare systems and offer a solution for minimizing or eliminating bias
without pausing to evaluate their affection for the models and tools.",
806,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"our study
is significant as it highlights and evaluates the negative impact of racial bias
on deep learning models.",
807,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the research in our paper demonstrates and proves that eliminating
racial biases from data improves performance, and yields a more precise and
robust survival prediction tool.",
808,Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"breast cancer impacts women globally [15] and mammographic screening for women
over a certain age has been shown to reduce mortality [7,10,23].",
809,Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"recently,
several studies [8,32,33] revealed the potential of artificial intelligence (ai)
to develop a better risk assessment model to identify women who may benefit from
supplemental screening or a personalized screening interval and these may lead
to improved screening outcomes.in clinical practice, breast density and
traditional statistical methods for predicting breast cancer risks such as the
gail [14] and the tyrer-cuzick models [27] have been used to estimate an
individual's risk of developing breast cancer.",
810,Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"for medical applications, x typically
represents patient information like age, family history, genetic makeup, and
diagnostic test results (e.g., a mammogram).",
811,Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"women with dense breasts have a four-to six-fold higher
risk of breast cancer [2].",
812,Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"in pare, a nodule is diagnosed from two levels: first parsing the contextual
information contained in the nodule itself, and then recalling the previously
learned nodules to look for related clues.one of the major challenges of lung
nodule malignancy prediction is the quality of datasets [6].",
813,Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"another issue is most of the studies focus on ldct for malignancy
prediction [10].",
814,Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"for the ncct, we annotate over 4,029 nodules from
over 2,565 patients from our collaborating hospital.",
815,Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"the in-house cohort was retrospectively collected from 2,565 patients
at our collaborating hospital between 2019 and 2022.",
816,Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"we additionally evaluate our method on the lungx [2] challenge
dataset, which is usually used for external validation in previous work
[6,11,24].",
817,M&M: Tackling False Positives in Mammography with a Multi-view and Multi-instance Learning Sparse Detector,"to
tackle the high rate of false positives in mammography, we identify three
challenges: (1) a malignant mammogram typically contains only one malignant
finding.",
818,M&M: Tackling False Positives in Mammography with a Multi-view and Multi-instance Learning Sparse Detector,"1b.in this
work, we tackle these challenges and propose a multi-view and multiinstance
learning system, m&m.",
819,M&M: Tackling False Positives in Mammography with a Multi-view and Multi-instance Learning Sparse Detector,"academic
hospital (see [18], sec.",
820,Reversing the Abnormal: Pseudo-Healthy Generative Networks for Anomaly Detection,"nevertheless,
latent methods still face difficulties in accurately reconstructing data from
their low-dimensional representations, causing false positive detections on
healthy tissues.several techniques have been proposed that make use of the
inherent spatial information in the data rather than relying on constrained
latent representations [12,25,30].",
821,Reversing the Abnormal: Pseudo-Healthy Generative Networks for Anomaly Detection,"adapting the noise distribution to the diversity
and heterogeneity of pathology is inherently difficult, and even if achieved,
the noising process disrupts the structure of both healthy and anomalous regions
throughout the entire image.in related computer vision areas, such as industrial
inspection [3], the topperforming methods do not focus on reversing anomalies,
but rather on detecting them by using large nominal banks [7,20], or pre-trained
features from large natural imaging datasets like imagenet [4,22].",
822,Reversing the Abnormal: Pseudo-Healthy Generative Networks for Anomaly Detection,"however, the application of these networks in
medical anomaly segmentation, particularly in brain mri, is limited by various
challenges specific to the medical imaging domain.",
823,SHISRCNet: Super-Resolution and Classification Network for Low-Resolution Breast Cancer Histopathology Image,"breast cancer is one of the high-mortality cancers among women in the 21st
century.",
824,SHISRCNet: Super-Resolution and Classification Network for Low-Resolution Breast Cancer Histopathology Image,"every year, 1.2 million women around the world suffer from breast
cancer and about 0.5 million die of it [3].",
825,SHISRCNet: Super-Resolution and Classification Network for Low-Resolution Breast Cancer Histopathology Image,"these
models cannot capture multi-scale features and do not solve the problems caused
by lr in various magnification factors well.",
826,SHISRCNet: Super-Resolution and Classification Network for Low-Resolution Breast Cancer Histopathology Image,"it considered the problem of multi-scale, but only
fused two scales features.",
827,SHISRCNet: Super-Resolution and Classification Network for Low-Resolution Breast Cancer Histopathology Image,"therefore, designing an appropriate feature
extraction block for sr of the histopathological images is still a challenging
task.in recent years, a series of deep learning methods have been proposed to
solve the breast cancer histopathological image classification issue by the
highresolution (hr) histopathological images.",
828,SHISRCNet: Super-Resolution and Classification Network for Low-Resolution Breast Cancer Histopathology Image,"ssca [24] considered the problem of multi-scale feature extraction which
utilized feature pyramid network (fpn) [15] and attention mechanism to extract
discriminative features from complex backgrounds.",
829,SHISRCNet: Super-Resolution and Classification Network for Low-Resolution Breast Cancer Histopathology Image,"however, it only concatenates
multi-scale features and does not consider the problem of feature fusion.",
830,SHISRCNet: Super-Resolution and Classification Network for Low-Resolution Breast Cancer Histopathology Image,"so it
is still worth to explore the potential of extraction and fusion of multi-scale
features for breast images classification.to tackle the problem of lr breast
cancer histopathological images reconstruction and diagnosis, we propose the
single histopathological image super-resolution classification network
(shisrcnet) integrating super-resolution (sr) and classification (cf) modules.",
831,SHISRCNet: Super-Resolution and Classification Network for Low-Resolution Breast Cancer Histopathology Image,"we use f ocal loss [16] to alleviate the class imbalanced data problem
of the hr and sr images' classification.",
832,Text-Guided Foundation Model Adaptation for Pathological Image Classification,"those approaches are
often designed to address disease-specific problems with limitations in their
generalizability.",
833,Text-Guided Foundation Model Adaptation for Pathological Image Classification,"to tackle this issue,
we emphasize the adaptation of foundation models in a data-efficient
manner.vision-language pre-training.",
834,Text-Guided Foundation Model Adaptation for Pathological Image Classification,"to address
this challenge, we leverage large language models pre-trained with biomedical
text to inject medical domain knowledge.biomedical language model utilization.",
835,Text-Guided Foundation Model Adaptation for Pathological Image Classification,"a class-balanced sampling strategy is adopted by choosing one
image from each class in turn.",
836,Text-Guided Foundation Model Adaptation for Pathological Image Classification,"adapting powerful foundation models into medical imaging constantly faces
data-limited challenges.",
837,Distributionally Robust Image Classifiers for Stroke Diagnosis in Accelerated MRI,"nevertheless, the long acquisition time for a
brain mri (20 to 30 min) imposes challenges, especially in cases of acute stroke
where rapid diagnosis is essential and patient movement during this distressing
period of time commonly limits evaluation.",
838,Distributionally Robust Image Classifiers for Stroke Diagnosis in Accelerated MRI,"logistic regression solves this problem by
minimizing the following expected true riskwhereis the coefficient matrix, p *
is the true distribution of the data (x, y), h b (x, y) log 1 e b x -y b x is
the loss function to be minimized, and e p * denotes the expectation under the
distribution p * .",
839,Distributionally Robust Image Classifiers for Stroke Diagnosis in Accelerated MRI,"since p * is usually unknown, problem (1) cannot be solved
directly.",
840,Distributionally Robust Image Classifiers for Stroke Diagnosis in Accelerated MRI,"to account for the non-linear
transformation of the raw image resulted from all layers before l, we solve the
following linear matrix inequality (lmi) problem [4] to estimate a weight matrix
w:where xi is the perturbed version of an mr image slice x i , d the training
set, s {(i, j)|x i , x j ∈ d, y i = y j }, |s| denotes the cardinality of the
set s, φ l is the input to l and φ (t) l is the t-th hidden state (i.e., the
vector representation for each instance in the sequence, output by and fed into
different layers in vit) in the sequence φ l of length t , and c is a fixed
parameter.",
841,Distributionally Robust Image Classifiers for Stroke Diagnosis in Accelerated MRI,"to solve the lmi problem in (5), we used sdpt3 v4.0
[17] as the solver.",
842,Distributionally Robust Image Classifiers for Stroke Diagnosis in Accelerated MRI,"for both erm-and drlbased vit models, we maximized the f1
score of the stroke class on the training set to calculate the optimal decision
threshold for stroke prediction, in order to balance the precision and recall.",
843,Contrastive Feature Decoupling for Weakly-Supervised Disease Detection,"as a result, the difficulty of data collection restricts the
development of the supervised cad.due to the difficulty of acquiring the
abundant annotated training data, the current sota method, i.e., csm [14],
proposes a mil-based wvad manner to specifically tackle one specific disease
detection task, i.e., colorectal cancer diagnosis via colonoscopy.",
844,Contrastive Feature Decoupling for Weakly-Supervised Disease Detection,"we employ the same evaluation
criteria as the previous work for a fair comparison.",
845,Contrastive Feature Decoupling for Weakly-Supervised Disease Detection,"the prostate cancer grade assessment (panda) challenge [2] comprises over 10k
whole-slide images (wsis) of digitized hematoxylin and eosin-stained biopsies
originating from radboud university medical center and karolinska institute.",
846,Contrastive Feature Decoupling for Weakly-Supervised Disease Detection,"we
follow the previous methods [4,13,14] to employ the instant-level area under
curve (auc) and the average precision (ap) for a fair comparison.",
847,Contrastive Feature Decoupling for Weakly-Supervised Disease Detection,"all the evaluated methods in the experiment used the same feature encoder, i.e.,
i3d [3] pre-trained on kinetics-400 [5], for a fair comparison.",
848,Multiple Prompt Fusion for Zero-Shot Lesion Detection Using Vision-Language Models,"this problem motivates us to study alternative
approaches with multiple prompt fusion.in this work, instead of striving to
design a single satisfying prompt, we aim to take advantage of pre-trained vlms
in a more flexible way with the form of multiple prompts, where each prompt can
elicit respective knowledge from the model which can then be fused for better
lesion detection performance.",
849,Multiple Prompt Fusion for Zero-Shot Lesion Detection Using Vision-Language Models,"as mentioned above, it is difficult for a single prompt input structure such as
glip to cover all necessary descriptions even through careful designation of the
prompt.",
850,Multiple Prompt Fusion for Zero-Shot Lesion Detection Using Vision-Language Models,"the misclassification problem in some of the single prompts is
corrected (i.e., malignant to benign) on the first dataset.",
851,Fast Non-Markovian Diffusion Model for Weakly Supervised Anomaly Detection in Brain MR Images,"moreover, all these methods still face challenges including the lack of
fine-grained guidance and gradual loss of anatomical information in markovian
chains.",
852,Fast Non-Markovian Diffusion Model for Weakly Supervised Anomaly Detection in Brain MR Images,"a memory bank [21] is applied to store representative features of
healthy samples, which enables quick generation of coarse segmentation maps x
seg during the testing phase, addressing the issue of knowledge forgetting in
original diffusion models.",
853,MUVF-YOLOX: A Multi-modal Ultrasound Video Fusion Network for Renal Tumor Diagnosis,"we further collect 36 cases from
the two medical centers mentioned above (14 benign cases) and another center
(fujian provincial hospital, 22 malignant cases) to form the test set.",
854,MUVF-YOLOX: A Multi-modal Ultrasound Video Fusion Network for Renal Tumor Diagnosis,"there is an obvious visual difference between
the images from the fujian provincial hospital (last column in fig.",
855,MUVF-YOLOX: A Multi-modal Ultrasound Video Fusion Network for Renal Tumor Diagnosis,"for a fair comparison with other fusion
methods, we embed their fusion modules into our framework so that different
approaches can be validated in the same environment.",
856,Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"despite this, the clinical
pathological analysis presents certain challenges and complexities, with the
ultimate diagnosis relying on patients rather than slides.specifically, in
clinical problems of pathological image analysis, doctors usually summarize
patient-level labels based on slide labels as the diagnostic results [1,6].",
857,Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"1, actual pathological image analysis involves the
relationships of patches, slides, and patients, which is called a multi-level
multi-instance learning (ml-mil) problem.",
858,Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"among them, for patients and slides,
patients are bags while slides are instances, and for slides and patches, slides
are bags while patches are instances.there are generally two methods to solve
the ml-mil problem.",
859,Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"the second method is
to treat slide-patient as a new mil problem according to the traditional mil
thinking, where slides are regarded as instances and patient labels as bags.",
860,Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"therefore, the insufficient number of samples at the
slide-patient level may make it difficult for the model to learn enough
information.to address the multi-level multi-instance learning (ml-mil) problem
in medical field, we propose a novel framework called patients and slides are
equal (p&sre).",
861,Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"our method can effectively
solve the problem of difficult training due to the scarcity of samples at the
highest level in ml-mil, and can be integrated into two state-of-the-art methods
to further improve performance.",
862,Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"our contributions
include:1) proposing a novel general framework to address the unique
""patch-slidepatient"" ml-mil problem in the medical field.",
863,Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"before this, no other
framework had directly tackled this specific problem, making our proposal a
ground-breaking step in the application of ml-mil in healthcare; 2) proposing a
simple yet highly effective method that leverages self-attention mechanisms and
transformer models to enhance the interaction between slide and patient
information.",
864,Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"b
1 and b 2 are bias vectors.",
865,Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"due to the
issue of class imbalance in both slide level and patient level, we use the lade
[7] loss function.",
866,Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"the primary reason is that the vast number of patches required for
analysis is significantly larger than that of slides and patients, which
presents a computational challenge for training.",
867,Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"this study proposes a highly scalable and versatile framework to address m-mil
problems.",
868,Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"we first classify the process from patch to slide to the patient in
medical pathology diagnosis as a multi-level mil problem.",
869,Learning with Synthesized Data for Generalizable Lesion Detection in Real PET Images,"this is difficult or even infeasible for some applications such as
lesion identification in neuroendocrine tumor (net) images, because nets are
rare tumors and lesion annotation in low-resolution, noisy pet images is
expensive.",
870,Learning with Synthesized Data for Generalizable Lesion Detection in Real PET Images,"to address the data shortage issue, we propose to train a deep model
for lesion detection with synthesized pet images generated from list mode pet
data, which is low-cost and does not require human effort for manual data
annotation.synthesized pet images may exhibit a different data distribution from
real clinical images (see fig.",
871,Learning with Synthesized Data for Generalizable Lesion Detection in Real PET Images,"1), i.e., a domain shift, which can pose
significant challenges to model generalization.",
872,Learning with Synthesized Data for Generalizable Lesion Detection in Real PET Images,"most of
current dg methods rely on multiple sources of data to learn a generalizable
model, i.e., multisource dg (mdg); however, multi-source data collection is
often difficult in real practice due to privacy concerns or budget deficits.",
873,Learning with Synthesized Data for Generalizable Lesion Detection in Real PET Images,"to address this issue, we propose to use a
pretext task as an additional information resource for the encoder e and to
further promote domain-agnostic representation learning.",
874,Learning with Synthesized Data for Generalizable Lesion Detection in Real PET Images,"the combo loss l det can further help address the data
imbalance issue [22], i.e., lesions have significantly fewer voxels than the
non-lesion regions including the background.",
875,What Do AEs Learn? Challenging Common Assumptions in Unsupervised Anomaly Detection,"therefore, it is difficult and expensive to collect
large amounts of annotated samples that cover the full abnormality spectrum,
with supervised [7,15] fig.",
876,What Do AEs Learn? Challenging Common Assumptions in Unsupervised Anomaly Detection,"this section aims to discuss the common assumptions of
unsupervised anomaly detection, specifically for aes, while also outlining the
challenges and desired properties associated with these techniques.",
877,What Do AEs Learn? Challenging Common Assumptions in Unsupervised Anomaly Detection,"in contrast, the detection of pathology on chest
radiographs is much more difficult due to the high variability and complexity of
nominal features and the diversity and irregularity of abnormalities.datasets.",
878,Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"in this study, we used data from shengjing hospital to train our method
with 892 patients, and data from three other centers, including guangdong
provincial people's hospital, tianjin medical university and sun yatsen
university cancer center for independent testing with 178 patients.",
879,Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"pdac masks for 340 patients were manually labeled by a
radiologist from shengjing hospital with 18 years of experience in pancreatic
cancer, while the rest were predicted using self-learning models [11,24] and
checked by the same annotator.",
880,Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"we further stratify patients by our signature after
grouping them by tumor size and ca19-9, two clinically used preoperative
criteria for selection, and also age.",
881,DCAug: Domain-Aware and Content-Consistent Cross-Cycle Framework for Tumor Augmentation,"existing tumor augmentation methods, including ""copy-paste"" strategy based
methods [15][16][17]19] and style-transfer based methods [5], only considered
content or style information when synthesizing new samples, which leads to a
distortion gap in content or domain space between the true image and synthetic
image, and further causes a distortion problem [14] as shown in fig.",
882,DCAug: Domain-Aware and Content-Consistent Cross-Cycle Framework for Tumor Augmentation,"the
distortion problem damages the effectiveness of dcnns in feature representation
learning as proven in many studies [1,5,18].",
883,DCAug: Domain-Aware and Content-Consistent Cross-Cycle Framework for Tumor Augmentation,"therefore, a domain and content
simultaneously aware data augmentation method is urgently needed to eliminate
and avoid the distortion challenges during tumor generation.",
884,DCAug: Domain-Aware and Content-Consistent Cross-Cycle Framework for Tumor Augmentation,"therefore, it's necessary to reduce the influence of the domain on content and
keep the content consistent during image generation.to overcome the above
challenges, a domain-aware and content-consistent tumor augmentation method,
named dcaug, is developed (fig.",
885,DCAug: Domain-Aware and Content-Consistent Cross-Cycle Framework for Tumor Augmentation,"it has the advantage of alleviating the challenge of distortion in
synthetic tumor images.",
886,DCAug: Domain-Aware and Content-Consistent Cross-Cycle Framework for Tumor Augmentation,"there are two challenges need to be solved: 1) x b→a a , x a→b b ,
by adjusting the domain information of the copied tumor, making the copied tumor
have the same domain space as the target image to avoid domain distortion; 2)b ,
maintaining the domain-invariant content information consistency during tumor
copy to avoid content distortion.to achieve the above goals, a novel cross-cycle
framework (fig.",
887,DCAug: Domain-Aware and Content-Consistent Cross-Cycle Framework for Tumor Augmentation,"specifically, the dcaug assists the mixup,
cutmix, and stylemix to obtain a 3.15%, 8.53%, and 0.60% improvement in
segmentation performance, respectively, which demonstrates that 1) it is
necessary to consider both content and domain information during samples
generation; 2) avoiding the content and domain distortion challenge can further
improve the quality of generated samples; 3) dcaug can alleviate the challenge
of distortion problem present in existing tumor augmentation methods.",
888,Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"this is
because early-stage gastric tumors may only invade the mucosal and muscularis
layers, which are difficult to identify without the help of stomach preparation
and contrast injection.",
889,Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"additionally, the poor contrast between the tumor and
normal stomach wall/tissues on non-contrast ct scans and various shape
alterations of gastric cancer, further exacerbates this challenge.in this paper,
we propose a novel approach for detecting gastric cancer on non-contrast ct
scans.",
890,Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"while
previous studies have successfully detected pancreatic [25] and esophageal [26]
cancers on non-contrast ct, identifying gastric cancer presents a unique
challenge due to its subtle texture changes, various shape alterations, and
complex background, e.g., irregular gastric wall; liquid and contents in the
stomach.",
891,Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"their cluster representations demonstrate a remarkable balance
of intra-cluster similarity and inter-class discrepancy.",
892,Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,problem formulation.,
893,Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"to address difficulties with tumor annotation on non-contrast cts, the
radiologists start by annotating a voxel-wise tumor mask on the
contrast-enhanced ct, referring to clinical and endoscopy reports as needed.",
894,Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"however, local textures are inadequate
for accurate gastric tumor detection on non-contrast cts, so we need a network
of both local sensitivity to textures and global awareness of the organ-tumor
morphology.",
895,Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"our study analyzed a dataset of ct scans collected
from guangdong province people's hospital between years 2018 and 2020, with
2,139 patients consisting of 787 gastric cancer and 1,352 normal cases.",
896,Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"to further evaluate specificity in
a larger population, we collected an external test set of 903 normal cases from
shengjing hospital.",
897,Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"a reader study was conducted with two
experienced radiologists, one from guangdong province people's hospital with 20
years of experience and the other from the first affiliated hospital of zhejiang
university with 9 years of experience in gastric imaging.",
898,Self-supervised Polyp Re-identification in Colonoscopy,"to deal with this
problem, computer-aided polyp detector (cade) was introduced [13][14][15][16]
and recently became commercially available [3].",
899,Self-supervised Polyp Re-identification in Colonoscopy,"clustering polyp detections into polyp entities is a
prerequisite for computing such quality metrics as polyp detection rate (pdr)
and polyps per colonoscopy (ppc), and for listing detected polyps in a
report.one may notice that the described task generally falls into the category
of the well known multiple object tracking (mot) problem [26,27].",
900,Self-supervised Polyp Re-identification in Colonoscopy,"we use a tracking by detection method [27]), in this paper we focus on the
second step.to avoid manual data annotation, which is extremely ineffective in
our case, we turn to self-supervision and adapt the widely used contrastive
learning approach [5] to video input and object tracking scenario.as tracklet
re-identification is a sequence-to-sequence matching problem, the standard
solution is comparing sequences element-wise and then aggregating the
per-element comparisons, e.g.",
901,Self-supervised Polyp Re-identification in Colonoscopy,"combined with the temperature mechanism this allows for
hard negative mining by prioritizing hard-to-distinguish pairs, resulting in a
more effective loss weighting scheme.one caveat of simclr is the difficulty to
generate augmentations beneficial for the learning process [5].",
902,YONA: You Only Need One Adjacent Reference-Frame for Accurate and Fast Video Polyp Detection,"thus, we
rethink the video polyp detection task and conclude three core challenges in
colonoscopy videos.",
903,YONA: You Only Need One Adjacent Reference-Frame for Accurate and Fast Video Polyp Detection,"the model will be confused by such frames in inference and
result in high false-positive or false-negative predictions.to address the above
issues, we propose the yona framework, which fully exploits the reference frame
information and only needs one adjacent reference frame for accurate video polyp
detection.",
904,YONA: You Only Need One Adjacent Reference-Frame for Accurate and Fast Video Polyp Detection,"for the fairness of the experiments, we
keep the same dataset settings for yona and all other methods.",
905,YONA: You Only Need One Adjacent Reference-Frame for Accurate and Fast Video Polyp Detection,"to address the problem of fast-moving polyps, we introduced the
foreground temporal alignment module, which explicitly aligns the channel
patterns of two frames according to their foreground similarity.",
906,Boosting Breast Ultrasound Video Classification by the Guidance of Keyframe Feature Centers,"breast cancer is a life-threatening disease that has surpassed lung cancer as
leading cancer in some countries and regions [20].",
907,Boosting Breast Ultrasound Video Classification by the Guidance of Keyframe Feature Centers,"obtaining ultrasound video data with pathology gold standard results
poses a major challenge.",
908,Boosting Breast Ultrasound Video Classification by the Guidance of Keyframe Feature Centers,"consequently, while there are many breast ultrasound image datasets [1,28],
breast ultrasound video datasets remain scarce, with only one relatively small
dataset [15] containing 188 videos available currently.given the difficulties in
collecting ultrasound video data, we investigate the feasibility of enhancing
the performance of ultrasound video classification using a static image dataset.",
909,Boosting Breast Ultrasound Video Classification by the Guidance of Keyframe Feature Centers,"for fairness comparison, we train these models
using both video and image data, treating images as static videos.",
910,Boosting Breast Ultrasound Video Classification by the Guidance of Keyframe Feature Centers,"it is worth
noting that these two models without coherence loss obtain very low sensitivity
and high specificity, which means the model predictions are imbalanced and
intend to make benign predictions.",
911,Boosting Breast Ultrasound Video Classification by the Guidance of Keyframe Feature Centers,"without
our coherence loss or frame attention, it is difficult for the model to focus on
typical frames that possess malignant features.",
912,Text-Guided Cross-Position Attention for Segmentation: Case of Medical Image,"for instance, clip [12] used
contrastive learning based on image-text pairs to learn the similarity between
the image of an object and the text describing it, achieving significant
performance gains in a variety of computer vision problems.the trend of
text-image multi-modality-based research on image processing has extended to the
medical field.",
913,Text-Guided Cross-Position Attention for Segmentation: Case of Medical Image,"this makes finding an accurate roi a
challenge.we segmented the pelvic bones in mri slices using the proposed method
to construct a fully automatic deep learning-based active sacroiliitis diagnosis
system, including roi settings from mri input images.",
914,Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fréchet Domain Distance,"to address this problem previous
work either use domain adaptation when data from the target domain is available
[32], or domain generalisation when the target data is unavailable [34].",
915,Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fréchet Domain Distance,"however, it may
not be feasible to perform an explicit domain adaptation, and an already adapted
model could still experience problems with domain shifts.",
916,Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fréchet Domain Distance,"hence, it is not clear how well
they will work in such a scenario.in this work, we evaluate an attention-based
mil model on unseen data from a new hospital and propose a way to quantify the
domain shift severity.",
917,Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fréchet Domain Distance,"we split the data from the new
hospital into several subsets to investigate clinically realistic scenarios
triggering different levels of domain shift.",
918,Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fréchet Domain Distance,"grand challenge camelyon data [16] potentially large shift as some patients have
already started neoadjuvant treatment as well as the tissue may be affected from
the procedure of sentinel lymph node removal.",
919,Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fréchet Domain Distance,"68 wsis with lobular carcinoma
(28 wsis with metastases): potentially large shift as it is a rare type of
carcinoma and relatively difficult to diagnose.the datasets of lobular and
ductal carcinomas each contain 50 % of wsis from sentinel and axillary lymph
node procedures.",
920,Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fréchet Domain Distance,"our results show that domain
shift is present between the wsis from the same hospital (camelyon data) and
another medical centre (brln data).",
921,Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fréchet Domain Distance,"in
practical applications, it may be a problem when the domain shift quantification
cannot separate between shifts having positive or negative effect on
performance.",
922,Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fréchet Domain Distance,"the results show that domain shift
may raise challenges in mil algorithms.",
923,Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"such metrics cannot reflect the
lesion-level accuracy (how many lesion instances are correctly detected and
classified) and may bias to large lesions when a patient has multiple tumors.",
924,Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"we propose a simple approach
to remedy this issue by sampling an extra n foreground pixels for each
lesion.patient branch.",
925,Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"since one patient can have multiple liver tumors of different types,
in our problem, we give each image several hierarchical binary labels.",
926,Self-supervised Learning for Endoscopic Video Analysis,"over 250 million endoscopic
procedures are performed each year globally and 80 million in the united states,
signifying the crucial role of endoscopy in clinical research and care.a
cardinal challenge in performing endoscopy is the limited field of view which
hinders navigation and proper visual assessment, potentially leading to high
detection miss-rate, incorrect diagnosis or insufficient treatment.",
927,Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"for instance, head and neck tumor
segmentation and outcome prediction challenges (hecktor) have been held for the
last three years to facilitate the development of new algorithms for survival
prediction from pet-ct images in h&n cancer [5][6][7].traditional survival
prediction methods are usually based on radiomics [8], where handcrafted
radiomics features are extracted from pre-segmented tumor regions and then are
modeled by statistical survival models, such as the cox proportional hazard
(coxph) model [9].",
928,Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"however, early fusion has difficulties in extracting intra-modality information
due to entangled (concatenated) images for feature extraction, while late fusion
has difficulties in extracting inter-modality information due to fully
independent feature extraction.",
929,Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"however, the performance of this method heavily relies on using tumor
segmentation masks as inputs, which limits its generalizability.secondly,
although deep survival models have advantages in performing end-to-end survival
prediction without requiring tumor masks, this also incurs difficulties in
extracting region-specific information, such as the prognostic information in
primary tumor (pt) and metastatic lymph node (mln) regions.",
930,Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"however, this method extracted entangled features related to both
pt and mln regions, which incurs difficulties in discovering the prognostic
information in pt-/mln-only regions.in this study, we design an x-shape
merging-diverging hybrid transformer network (named xsurv, fig.",
931,Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"following existing multi-task deep survival models [11,16,[24][25][26], our
xsurv is endto-end trained for survival prediction and pt-mln segmentation using
a combined loss: l = l surv +λ(l pt +l mln ), where the λ is a parameter to
balance the survival prediction term l surv and the pt/mln segmentation terms l
pt /mln .",
932,Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"in addition,
clinical indicators (e.g., age, gender) also can be integrated by the coxph
model.",
933,Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"for a fair
comparison, all methods took the same preprocessed images and clinical
indicators as inputs.",
934,Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"survival prediction and segmentation were evaluated using
concordance index (c-index) and dice similarity coefficient (dsc), which are the
standard evaluation metrics in the challenges [6,7,35].we also performed two
ablation studies on the encoder and decoder separately: (i) we replaced
hpca/hpsa blocks with conv blocks and compared different strategies to combine
pet-ct images.",
935,Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"as we have mentioned, early and late fusion have difficulties
in extracting intra-and inter-modality information, respectively.",
936,Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"to relieve this
problem, in tang et al.'s study [22], tumor segmentation masks were fed into the
model as explicit guidance to tumor regions.",
937,ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"while prognostication and survival analysis offer invaluable
insights for patient management, biological studies and drug development
efforts, they require careful tracking of patients for a lengthy period of time;
rendering this as a task that requires a significant amount of effort and
funding.in the machine learning domain, patient prognostication can be treated
as a weakly supervised problem, which a model would predict the outcome (e.g.,
time to cancer recurrence) based on the histopathology images.",
938,ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"this is perhaps due to the fact that
mil-based technique do not incorporate patch locations and interactions as well
as tissue heterogeneity which can potentially have a vital role in defining
clinical outcomes [4,26].to address this issue, graph neural networks (gnn) have
recently received more attention in histology.",
939,ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"the code and graph
embeddings are publicly available at https://github.com/pazadimo/all-in 2
related works utilizing weakly supervised learning for modeling histopathology
problems has
been getting popular due to the high resolution of slides and substantial time
and financial costs associated with annotating them as well as the development
of powerful deep discriminative models in the recent years [24].such models are
used to perform nuclei segmentation [18], identify novel subtypes [12], or later
descendants are even able to pinpoint sub-areas with a high diagnostic value
[19].",
940,ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"inspired by the relaxation form of the known k-way mincut problem, we create a
continuous cluster matrix c n ∈ r m ×k using mlp layers and can finally estimate
the super-nodes features (s n ∈ r m ×d ) as:where w 1 , w 2 are mlps' weights.",
941,ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"this term is motivated by
the original mincut problem and intends to solve it for the the patients' graph.",
942,ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"here, we take a balanced policy
between the independence and knowledge mixture of the two routes by only sharing
the weights without using any guidance.",
943,ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"we also utilized the prostate
cancer grade assessment (panda) challenge dataset [7] that includes more than
10,000 pca needle biopsy slides (no outcome data) as an external dataset for
training the encoder of our model.",
944,ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"superior performance of our mca policy implies that balanced
exploitation of fine and coarse features with shared weights may provide more
robust contextual information compared to using mixed guided information or
utilizing them independently.patient stratification.",
945,ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"this
group should be managed differently from the rest of the low-risk prostate
cancer patients in the clinic.",
946,DARC: Distribution-Aware Re-Coloring Model for Generalizable Nucleus Segmentation,"to handle this problem, we compensate i r with
the original semantic information contained in i.",
947,DARC: Distribution-Aware Re-Coloring Model for Generalizable Nucleus Segmentation,"however, for
dense-prediction tasks like semantic segmentation or contour detection, adopting
in alone cannot fully address the feature statistics variation problem.",
948,DARC: Distribution-Aware Re-Coloring Model for Generalizable Nucleus Segmentation,"it is shown that the value of b affects the model
performance significantly.the above problem is common in nucleus segmentation
because pathological images from different organs or tissues tend to have
significantly different foreground-background ratios.",
949,DARC: Distribution-Aware Re-Coloring Model for Generalizable Nucleus Segmentation,"to handle this problem, we propose the
distribution-aware instance normalization (dain) method to re-estimate feature
statistics that account for different ratios of foreground and background
pixels.",
950,DARC: Distribution-Aware Re-Coloring Model for Generalizable Nucleus Segmentation,"the images are extracted from 16
colorectal adenocarcinoma wsis, each of which belongs to an individual patient,
and scanned with an omnyx vl120 scanner within the department of pathology at
university hospitals coventry and warwickshire, uk.",
951,DARC: Distribution-Aware Re-Coloring Model for Generalizable Nucleus Segmentation,this problem is well addressed by our proposed dain.,
952,An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"multiplex staining
resolves this issue by allowing different tumor and immune cell markers to be
stained on the same tissue section, avoiding any phenotyping guesswork from
pathologists.",
953,An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"we randomly extracted tiles from
the lyon19 challenge dataset [14] to use as style ihc images.",
954,An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"this work was
supported by msk cancer center support grant/core grant (p30 ca008748) and by
james and esther king biomedical research grant (7jk02) and moffitt merit
society award to c.",
955,Detection of Basal Cell Carcinoma in Whole Slide Images,"neural architecture search (nas)
addresses this issue by auto-designing superior models [10][11][12][13],
exploring a vast architecture space.",
956,Detection of Basal Cell Carcinoma in Whole Slide Images,"however, current nas methods often overlook
fairness in architecture ranking, impeding the discovery of top-performing
models.in this study, we utilized the nas approach to identify the optimal
network for skin cancer detection.",
957,Detection of Basal Cell Carcinoma in Whole Slide Images,"we observed that conventional nas methods often
overlook fairness ranking during the search, hindering the search for optimal
solutions.",
958,Detection of Basal Cell Carcinoma in Whole Slide Images,"our sc-net framework addresses this by ensuring fair training and
precise ranking.",
959,Detection of Basal Cell Carcinoma in Whole Slide Images,"a balanced evolutionary algorithm
is then used to select the optimal structure from the search space, with the
candidate structures' performance evaluated using mini-batch patch data.",
960,Detection of Basal Cell Carcinoma in Whole Slide Images,"current approaches for neural architecture search [19][20][21] often employ a
unilaterally augmented (ua) principle to evaluate each width, resulting in
unfair training of channels in the supernet.",
961,Detection of Basal Cell Carcinoma in Whole Slide Images,"however, the ua principle leads to channel
training imbalance in the supernet due to its constraints, as illustrated in
fig.",
962,Detection of Basal Cell Carcinoma in Whole Slide Images,"this
introduces evaluation bias and leads to sub-optimal results.to mitigate
evaluation bias on width, we propose a new sc-net that promotes the fairness of
channels during training.",
963,Detection of Basal Cell Carcinoma in Whole Slide Images,"therefore, the training degree t
(d) of the d-th channel in our proposed method istherefore, the training degree
t for each channel will always be equal to the same constant value of the width,
independent of the channel index, ensuring fairness in terms of channel (filter)
levels.",
964,Detection of Basal Cell Carcinoma in Whole Slide Images,"to
ensure a fair comparison on our dataset, we selected several papers in the field
of pathological image analysis, such as [9,22,23], as well as others using the
ua principle, such as [18,24].evaluation metrics.",
965,Detection of Basal Cell Carcinoma in Whole Slide Images,"by formulating sc-net as a balanced supernet, we
ensure fair ranking and treatment of all potential architectures.",
966,IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis,"to address this issue,
multiple instance learning (mil) [1] is usually applied to formulate
pathological image analysis tasks into weakly supervised learning problems.",
967,IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis,"the primary challenge of mil arises from its weakly supervised
nature, i.e.",
968,IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis,"bag-level mil incorporates instance embeddings to create a bag
representation, converting the mil into a supervised learning problem.",
969,IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis,"the
instance-level mil, however, faces the problem of noisy labels, which is caused
by the common strategy of assigning the wsi labels to patches and the fact that
there are lots of patches irrelevant to the wsi labels [3,6].considering these
conventional mil methods usually utilize either bag-level or instance-level
supervision, leading to suboptimal performance.",
970,Multi-scale Prototypical Transformer for Whole Slide Image Classification,"however, wsis are extremely large in the size and lack of pixel-level
annotations, making it difficult to adopt the traditional supervised learning
methods for wsi classification [4].to address this issue, multiple instance
learning (mil) has been successfully applied to the wsi classification task as a
weakly supervised learning problem [5][6][7].",
971,Multi-scale Prototypical Transformer for Whole Slide Image Classification,"when the
positive and negative instances in the bag are highly imbalanced, the mil models
are prone to incorrectly discriminate these positive instances when using simple
aggregation operations.",
972,Multi-scale Prototypical Transformer for Whole Slide Image Classification,"however, the wsi dataset generally has
a long sequence of instances, which makes the clustering algorithms
computationally expensive and slow down as the size of the bag increases.to
solve the issue above, we propose to apply the self-attention (sa) mechanism in
transformer to re-calibrate these cluster prototypes.",
973,Thyroid Nodule Diagnosis in Dynamic Contrast-Enhanced Ultrasound via Microvessel Infiltration Awareness,"whether the awareness of infiltrative
area information can be helpful in the improvement of diagnostic accuracy is
still unexplored.here, we propose an explanatory framework for the diagnosis of
thyroid nodules based on dynamic ceus video, which considers the dynamic
perfusion characteristics and the amplification of the lesion region caused by
microvessel infiltration.",
974,Thyroid Nodule Diagnosis in Dynamic Contrast-Enhanced Ultrasound via Microvessel Infiltration Awareness,"the great challenge of automatic recognition of lesion area from ceus video is
that the semantic information of the lesion area is different in the ceus video
of the different microvessel perfusion periods.",
975,Thyroid Nodule Diagnosis in Dynamic Contrast-Enhanced Ultrasound via Microvessel Infiltration Awareness,"based on the fact that inceptext [15] has
experimentally demonstrated that asymmetric convolution can effectively solve
the problem of highly variable size and aspect ratio, we use asymmetric
convolution in the ipo unit.",
976,Thyroid Nodule Diagnosis in Dynamic Contrast-Enhanced Ultrasound via Microvessel Infiltration Awareness,"the l total is denoted as follows:where λ 1 , λ 2 , λ 3 are
the hyper-parameters to balance the corresponding loss.",
977,Thyroid Nodule Diagnosis in Dynamic Contrast-Enhanced Ultrasound via Microvessel Infiltration Awareness,"our dataset contained 282 consecutive patients who underwent thyroid
nodule examination at nanjing drum tower hospital.",
978,Thyroid Nodule Diagnosis in Dynamic Contrast-Enhanced Ultrasound via Microvessel Infiltration Awareness,"all data were approved by the institutional review board of
nanjing drum tower hospital, and all patients signed the informed consent before
enrollment into the study.implementation details.",
979,Thyroid Nodule Diagnosis in Dynamic Contrast-Enhanced Ultrasound via Microvessel Infiltration Awareness,"for fair
comparison, all methods used the manually annotated lesion mask to assist the
diagnosis.",
980,Thyroid Nodule Diagnosis in Dynamic Contrast-Enhanced Ultrasound via Microvessel Infiltration Awareness,"the awareness of microvascular infiltration
using saf and ipo unit was helpful for ceus-based diagnosis, as it could improve
the diagnosis accuracy by 7.69% (as in table 2).",
981,Label-Free Nuclei Segmentation Using Intra-Image Self Similarity,"methods to relieve
the high dependency on the accurate annotations of nuclei are highly
needed.unsupervised learning (ul) methods achieved great success in the data
dependency problem for nuclei segmentation, which learns from the structural
properties in the data without any manual annotations.",
982,Label-Free Nuclei Segmentation Using Intra-Image Self Similarity,"while reasonable results are obtained, these deep clustering-based
methods still suffer difficulties: (i) poor segmentation of the regions between
adjacent nuclei.",
983,Label-Free Nuclei Segmentation Using Intra-Image Self Similarity,"deep clustering-based methods experience difficulties in dealing with
these regions due to the lack of supervision.",
984,Label-Free Nuclei Segmentation Using Intra-Image Self Similarity,"this phenomenon offers valuable
information for networks to use but the current clustering models do not take
this into account.to address the above issues and motivated by the iiss
property, we hereby propose a novel self-similarity-driven segmentation network
(ssimnet) for unsupervised nuclei segmentation.",
985,Label-Free Nuclei Segmentation Using Intra-Image Self Similarity,"to evaluate the effectiveness of ssimnet, we compare it with several deep
learning based and conventional unsupervised segmentation methods on the
mentioned datasets, including minibatch k-means (termed as mkmeans), gaussian
mixture model [9] (termed as gmm), invariant information clustering [12] (termed
as iic), double dip [18], deep clustering via adaptive gmm model [19] (termed as
dcagmm), deep image clustering [13] (termed as dic), kim's work [20], kanezaki's
work [11], deep conditional gmm [14] (termed as dcgmm), and deep constrained
gaussian network [15] (termed as dcgn).for the methods without public codes, we
report the results from the original publications for a fair comparison.",
986,Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"in this study, we
introduce a novel approach called triangular analysis of geographical interplay
of lymphocytes (triangil), representing a unique and interpretable way to
characterize the distribution, and higher-order interaction of various cell
families (e.g., cancerous cells, stromal cells, lymphocyte subtypes) across
digital histopathology slides.",
987,Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"instead of measuring only simple two-by-two relations between
cells, it seeks to identify triadic spatial relations (hyperedges [18,20] have
shown great capabilities in solving complex problems in the biomedical field,
these tend to be black-box in nature.",
988,Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"by
focusing on every set, triangil allows for capturing higher-order and balanced
spatial triadic relationships [4] between cell families, while keeping the
computational complexity relatively low.",
989,Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"we presented a new approach, triangular analysis of geographical interplay of
lymphocytes (triangil), to quantitatively chartacterize the spatial arrangement
and relative geographical interplay of multiple cell families across
pathological images.",
990,NASDM: Nuclei-Aware Semantic Histopathology Image Generation Using Diffusion Models,"this presents a challenge,
as some disease variants are extremely rare, making visual identification
difficult.",
991,NASDM: Nuclei-Aware Semantic Histopathology Image Generation Using Diffusion Models,"in recent years, deep learning methods have aimed to alleviate this
problem by designing discriminative frameworks that aid diagnosis [15,28].",
992,NASDM: Nuclei-Aware Semantic Histopathology Image Generation Using Diffusion Models,"as such, generative models can be sampled to emphasize each
disease subtype equally and generate more balanced datasets, thus preventing
dataset biases getting amplified by the models [7].",
993,NASDM: Nuclei-Aware Semantic Histopathology Image Generation Using Diffusion Models,"however,
gans suffer from problems of frequent mode collapse and overfitting their
discriminator [29].",
994,NASDM: Nuclei-Aware Semantic Histopathology Image Generation Using Diffusion Models,"it is also challenging to capture long-tailed distributions
and synthesize rare samples from imbalanced datasets using gans.",
995,NASDM: Nuclei-Aware Semantic Histopathology Image Generation Using Diffusion Models,"a common issue in deep learning with h&e stained histopathology slides is the
visual bias introduced by variations in the staining protocol and the raw
materials of chemicals leading to different colors across slides prepared at
different labs [1].",
996,NASDM: Nuclei-Aware Semantic Histopathology Image Generation Using Diffusion Models,"as such, several stain-normalization methods have been
proposed to tackle this issue by normalizing all the tissue samples to mimic the
stain distribution of a given target slide [17,23,26].",
997,NASDM: Nuclei-Aware Semantic Histopathology Image Generation Using Diffusion Models,"epithelial cells are most difficult to generate in a
convincing manner, however, we can see that model is able to capture the nuances
well and generates accurate chromatin distributions.",
998,DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"[17] constructed an additional segmentation task to provide the
dose prediction task with essential anatomical knowledge.although the above
methods have achieved good performance in predicting dose distribution, they
suffer from the over-smoothing problem.",
999,DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"unlike other dl models, the
diffusion model is trained without any extra assumption about target data
distribution, thus evading the average effect and alleviating the over-smoothing
problem [24].",
1000,DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"by
incorporating the anatomical information, the noise predictor can be aware of
the dose constraints among ptv and oars, thus distributing more appropriate dose
to them and generating more accurate dose distribution maps.overall, the
contributions of this paper can be concluded as follows: (1) we propose a novel
diffusion-based model for dose prediction in cancer radiotherapy to address the
over-smoothing issue commonly encountered in existing dl-based dose prediction
methods.",
1001,DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"vanilla diffusion model has difficulty preserving essential structural
information and produce unstable results when predicting dose distribution maps
directly from noise with a simple condition mechanism.",
1002,DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"we measure the performance of our model on an in-house
rectum cancer dataset which contains 130 patients who underwent volumetric
modulated arc therapy (vmat) treatment at west china hospital.",
1003,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning,"however, due to the limitation of hardware resources, it is
difficult to directly process gigapixel wsis in an end-to-end framework.",
1004,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning,"mil methods regard wsi recognition as a weakly supervised learning
problem and focus on how to effectively and efficiently aggregate
histopathological local features into a global representation.",
1005,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning,"[5] explored and posed a new
challenge referred to as slide-level self-learning and proposed hipt, which
leveraged the hierarchical structure inherent in wsis and constructed multiple
levels of the self-supervised learning framework to learn high-resolution image
representations.",
1006,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning,"the bias and error generated in each level of the
representation model will accumulate in the final decision model.",
1007,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning,"to relieve
this problem, kat [19] built hierarchical masks based on local anchors to
maintain multi-scale relative distance information in the training.",
1008,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning,"embedding the orientation information with a fixed polar axis
will lead to ambiguities in various slides.to address this problem, we design a
kernel reorientation (kro) strategy to dynamically update the polar axis during
the training.",
1009,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning,"the multi-stage framework
accumulated the training bias and noise, which caused an auc gap of hipt [5] to
mae [7] and pama, especially trained with only 10% labeled wsis.",
1010,Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,"cervical cancer is a common and severe disease that affects millions of women
globally, particularly in developing countries [9].",
1011,Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,"the tendency to neglect effective integration of the overall
information across the entire wsi results in poor performance in sample-level
classification.to address the aforementioned issues, we propose a detection-free
pipeline in this paper, which does not rely on any detection model.",
1012,Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,"in this study, we have collected 5384 cervical
cytopathological wsi by 20x lens, each with 20000 × 20000 pixels, from our
collaborating hospitals.",
1013,Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,"as shown in table 1 for fair five-fold
cross-validation, our method outperforms all compared detection-based methods.",
1014,Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,"3, our method has shorter
inference time and a good balance between accuracy and inference time.",
1015,Instance-Aware Diffusion Model for Gland Segmentation in Colon Histology Images,"however, these methods
may face difficulties in capturing different cell shapes and distinguishing
tightly positioned gland boundaries.",
1016,Instance-Aware Diffusion Model for Gland Segmentation in Colon Histology Images,"our proposed
method was trained and tested on the 2015 mic-cai gland segmentation (glas)
challenge dataset [20] and colorectal adenocarcinoma gland (crag) dataset [6]
(as shown in fig.",
1017,Instance-Aware Diffusion Model for Gland Segmentation in Colon Histology Images,"we
enhance our loss function by incorporating two components, l d and l s , and
utilize the γ parameter to optimize the balance between these two losses.where
the l s in our model represents the measure of overlap between the predicted
instance mask and the ground truth s gt [14], and the l d is the loss of
diffusiondet.",
1018,Instance-Aware Diffusion Model for Gland Segmentation in Colon Histology Images,"in this work,
we chose γ = 5 to balance these two losses.",
1019,Instance-Aware Diffusion Model for Gland Segmentation in Colon Histology Images,"furthermore, to enhance the
training dataset and mitigate the risk of overfitting, we employed random
combinations of image flipping, translation, gaussian blur, brightness
variation, and other augmentation techniques.we assessed the segmentation
results using three metrics from the glas challenge: (1) object f1, which
measures the accuracy of detecting individual glands, (2) object dice, which
evaluates the volume-based accuracy of gland segmentation, and (3) object
hausdorff, which assesses the shape similarity between the segmentation result
and the ground truth.",
1020,Instance-Aware Diffusion Model for Gland Segmentation in Colon Histology Images,"although our method demonstrates excellent
performance in gland instance segmentation, challenges arise in certain
scenarios characterized by irregular shapes, flattening, and overlapping.",
1021,Instance-Aware Diffusion Model for Gland Segmentation in Colon Histology Images,"this limitation may stem from the
difficulty in accurately distinguishing fine details between instances and the
incorrect identification of boundaries.to address these limitations, future work
will focus on improving segmentation performance in challenging scenarios by
specifically targeting three identified limitations: (1) incorporate random
noise during training to reduce reliance on bounding box information for
denoising; (2) explore more efficient methods for cross-step denoising in the
diffusion model to improve processing time without compromising segmentation
accuracy; and (3) develop a more effective conditional encoding method to
provide accurate instance context for noise filtering in discriminative tasks
like nuclear segmentation.",
1022,Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs,"despite the progress, the
outstanding challenge in training such i2it frameworks is the lack of aligned
h&e-ihc image pairs, or in other words, the inconsistencies in the h&e-ihc
groundtruth pairs.",
1023,Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs,"such scheduling of the weights is done so that in the beginning of
the training, the weights are uniform in order not to wrongly bias the network
when the embeddings are still indiscriminative.",
1024,Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs,"the following datasets are used in our experiments: the breast cancer
immunohistochemical (bci) challenge dataset [7] and our own mist dataset that is
now in the public domain.",
1025,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis,"such gigapixel resolution and expensive
pixel-wise annotation efforts pose unique challenges to constructing effective
and accurate models for wsi analysis.",
1026,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis,"to overcome these challenges, multiple
instance learning (mil) has become a popular paradigm for wsi analysis.",
1027,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,image classification is a significant challenge in medical image analysis.,
1028,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"although some classification methods achieve promising performance on balanced
and clean medical datasets, balanced datasets with high-accuracy annotations are
time-consuming and expensive.",
1029,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"besides, pruning clean and balanced datasets
require a large amount of crucial clinical data, which is insufficient for
large-scale deep learning.",
1030,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"therefore, we focus on a more practical yet
unexplored setting for handling imbalanced medical data with noisy labels,
utilizing all available lowcost data with possible noisy annotations.",
1031,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"noisy
imbalanced datasets arise due to the lack of high-quality annotations [11] and
skewed data distributions [18] where the number of instances largely varies
across different classes.",
1032,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"besides, the class hardness problem where
classification difficulties vary for different categories presents another
challenge in removing label noise.",
1033,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"due to differences in disease epidemicity and
collection difficulty, rare anomalies or anatomical features render diseases
with low epidemicity easier to detect.",
1034,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"therefore, noisy-labeled, imbalanced datasets with various class
hardness remain a persistent challenge in medical classification.existing
approaches for non-ideal medical image classification can be summarized into
noisy classification, imbalanced recognition, and noisy imbalanced
identification.",
1035,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"however, imbalanced data creates different confidence distributions of clean and
noisy data in the majority class and minority class as shown in fig.",
1036,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"imbalanced recognition approaches
[9,15,21] utilize augmented embeddings and imbalance-invariant training loss to
re-balance the long-tailed medical data artificially, but the disturbance from
noisy labels leads to uncasual feature learning, impeding the recognition of
tail classes.",
1037,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"noisy longtailed identification technique [25] has achieved
promising results by addressing noise and imbalance concerns sequentially.",
1038,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"however, the class hardness problem leads to vague decision boundaries that
hinders accurate' noise identification.in this work, we propose a multi-stage
noise removal framework to address these concerns jointly.",
1039,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"in the noisy imbalanced classification setting, we denote a medical dataset as
{(x i , y i )} n i=1 where y i is the corresponding label of data x i and n is
the total amount of instances.",
1040,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"we aim to train a robust medical image classification model composed of a
representation backbone and a classifier head on label noise and imbalance
distribution, resulting in a minimized loss on the testing dataset: we decompose
the non-linear mapping p(y = c|x) as a product of two space
mappings p g (y = c|z) • p h (z|x).",
1041,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"given that backbone mapping is independent
of noisy imbalanced effects, we conduct further disentanglement by defining e as
the negative effects and p as constant for fixed probability mappings:the
induction derives from the assumption that the incorrect mapping p g (y = c|z,
e) conditions on both pure latent to logits mapping p g (y = c|z) and adverse
effects p g (y = c|e).",
1042,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"by bayes theorem, we decompose the effect into imbalance,
noise, and mode (hardness), where the noise effect depends on skew distribution
and hardness effect; and the hardness effect is noise-invariant.",
1043,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"currently,
noise removal methods only address pure noise effects (p g (e n |y = c)), while
imbalance recognition methods can only resolve imbalanced distribution, which
hinders the co-removal of adverse influences.",
1044,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"to address these
issues, we propose a mapping correction approach that combines independent noise
detection and removal techniques to identify and remove noise effectively.",
1045,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"however, they fail to consider the influence of imbalanced
distributions, which might cause a biased gradient direction on the optimization
subspace.",
1046,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"by transferring the constraints into a penalty in
the optimizing object, we solve this problem by learning the constraint scale ω
[2]:ideally, the noise removal process is distribution-invariant if data is
uniformly distributed w.r.t.",
1047,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"by the law of large numbers, all
constructed distributions should be symmetric according to the balanced
distribution to obtain a uniform expectation.",
1048,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"however, in medical image analysis, an overlooked mismatch exists
between class hardness and difficulty in noise identification.",
1049,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"to resolve the challenge, we propose a novel method called rescaling
class-aware gaussian mixture modeling (rcgm) which clusters each category data
independently by fitting confidence scores q ij from ith class into two gaussian
distributions as p n i (x n |μ n , σ n ) and p c i (x c |μ c , σ c ).",
1050,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"with a pre-defined noise selection threshold as τ
, we have the final clean score as: in contrast to two-stage noise removal and
imbalance classification techniques,
our approach applies a multi-stage protocol: warm-up phases, noise removal
phases, and fine-tuning phases as shown in fig.",
1051,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"finally, in the fine-tuning phases, we
apply mixup technique [13,25,26] to rebuild a hybrid distribution from noisy
pairs and clean pairs by:where α kl := v(x k ) v(x l ) denotes the balanced
scale; and {(x kl , ŷkl )} are the mixed clean data for classifier fine-tuning.",
1052,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"sqrt sampler is applied to re-balance the data, and cross-stage kl [12] and ce
loss are the fine-tuning loss functions.",
1053,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"we evaluated our approach on two medical image datasets with imbalanced class
distributions and noisy labels.",
1054,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"to emulate imbalanced scenarios, we prune the
class sizes of the training set into an imbalanced distribution as [5].",
1055,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"the imbalanced ratios [12] of
ham10000 and chaoyang are 59 and 20, respectively.",
1056,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"we compare our model with state-of-the-art methods which contain noisy methods
(including dividemix [13], nl [16], gce [27], co-learning [19]), imbalance
methods (including focal loss [14], sqrt-rs [17], pg-rs [10], cb-focal [5], eql
[21], eql v2 [20], cece [5], clas [28], fcd [12]), and noisy imbalanced
classification methods (including h2e [25], nl+sqrt-rs, gce+sqrt-rs, gce+focal).",
1057,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"further, our multi-stage noise removal technique outperforms single mer and
rcgm, revealing that the decomposition for noise effect and hardness effect
works on noisy imbalanced datasets.",
1058,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"we propose a multi-step framework for noisy long-imbalanced medical image
classification.",
1059,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"we address three practical adverse effects including data noise,
imbalanced distribution, and class hardness.",
1060,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"to solve these difficulties, we
conduct multi-environment risk minimization (mer) and rescaling class-aware
gaussian mixture modeling (rcgm) together for robust feature learning.extensive
results on two public medical image datasets have verified that our framework
works on the noisy imbalanced classification problem.",
1061,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"radiologists heavily rely on this data to
detect the crlm in the very early stage [15].extensive existing works have
demonstrated the power of deep learning on various spatial-temporal data, and
can potentially be applied towards the problem of crlm.",
1062,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"-no potential focal infection in the liver before the
colorectal radical surgery.-no metastases in other organs before the liver
metastases.-no other malignant tumors.our retrospective dataset includes two
cohorts from two hospitals.",
1063,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"this issue will be demonstrated and
discussed later in the ablation study.in summary, the mpbd-lstm model comprises
two planes, each of which contains three 3d-lstm stacks with two modules in each
stack.",
1064,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"to handle the imbalanced training dataset, we selected and
duplicated 60% of positive cases and 20% of negative cases by applying standard
scale jittering (ssj) [5].",
1065,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"our results suggest that lstm networks are more effective in
handling temporal features for our problem compared with cnn-based models.",
1066,Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology,"to overcome this
problem, weakly supervised and multiple instance learning (mil) based approaches
have been applied to numerous wsi classification tasks [6][7][8][9][10].",
1067,Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology,"transfer learning using backbones pretrained on natural images is a common
method that addresses the challenge of using data sets that largely lack
annotation.",
1068,Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology,"although these features may still have been predictive, they
were less interpretable, and it was more difficult to know what kind of
information they captured.",
1069,Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology,"for breast cancer human
epidermal growth factor receptor 2 (her2) prediction, we used data from the
herohe challenge data set [26].",
1070,Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology,"to enable comparison with previous results we
used the same test data set that was used in the challenge [27].",
1071,Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology,"for prediction
of estrogen receptor (er) status, we used images from the tcga-breast invasive
carcinoma (tcga-brca) data set [28] for which the er status was known.for these
two tasks we used artifact-free tiles from tumor regions detected with an
in-house tumor detection model.for breast cancer metastasis detection in lymph
node tissue, we used wsis of h&estained healthy lymph node tissue and lymph node
tissue with breast cancer metastases from the publicly available camelyon16
challenge data set [16,29].",
1072,Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology,"in fact, for the her2
classification task, combined embeddings obtained using the xformer architecture
achieved, to our knowledge, the best performance yet reported on the herohe
challenge data set (area under the receiver operating characteristic curve
[auc], 90%; f1 score, 82%).for coo classification in dlbcl, not only did the
combined embeddings achieve better performance than the tile-level only
embeddings with both the xformer and a-mil architectures (fig.",
1073,Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology,"to gain insights into cell-level
patterns that were very difficult or impossible to obtain from tile-level only
embeddings, we applied an explainability method that assigned attention weights
to the cellular average part of the embedding.",
1074,Progressive Attention Guidance for Whole Slide Vulvovaginal Candidiasis Screening,"it is the most prevalent human candidal infection,
estimated to afflict approximately 75% of all women at least once in their
lifetime [1,20], resulting in huge consumption of medical resources.",
1075,Progressive Attention Guidance for Whole Slide Vulvovaginal Candidiasis Screening,"the class
imbalance makes it difficult to conduct discriminative learning and to find
candida.",
1076,Progressive Attention Guidance for Whole Slide Vulvovaginal Candidiasis Screening,"all of the above issues make it difficult for
diagnostic models to focus on candida, thus resulting in poor classification
performance and generalization capability.in this paper, we find that the
attention for a deep network to focus on candida is the key to the high
performance of the screening task.",
1077,Progressive Attention Guidance for Whole Slide Vulvovaginal Candidiasis Screening,"however, in such a task, as candida occupies only a few pixels in
an image, it is difficult for the classifier to focus on the target.",
1078,Progressive Attention Guidance for Whole Slide Vulvovaginal Candidiasis Screening,"that, the
attention of the classifier may spread across the entire image, leading to
overfitted training quickly.therefore, we argue that the detection and
classification tasks are complementary to solve our problem.",
1079,Progressive Attention Guidance for Whole Slide Vulvovaginal Candidiasis Screening,"1, the style gap is another problem, which makes
overfitting more severe.",
1080,Progressive Attention Guidance for Whole Slide Vulvovaginal Candidiasis Screening,"in this part, we adopt the strategy of contrastive
learning to alleviate such problems and further optimize the attention of the
network.",
1081,Progressive Attention Guidance for Whole Slide Vulvovaginal Candidiasis Screening,"dataset-small is balanced with 100 positive wsis and
100 negative wsis.",
1082,Progressive Attention Guidance for Whole Slide Vulvovaginal Candidiasis Screening,"we further validate upon an
imbalanced dataset-large of 7654 wsis.",
1083,CellGAN: Conditional Cervical Cell Synthesis for Augmenting Cytopathological Image Classification,"and the
efforts in collecting reliably annotated data can hardly be negligible, which
requires high expertise due to the intrinsic difficulty of visually reading
wsis.to alleviate the shortage of sufficient data to supervise classification,
one may adopt traditional data augmentation techniques, which yet may bring
little improvement due to scarcely expanded data diversity [26].",
1084,CellGAN: Conditional Cervical Cell Synthesis for Augmenting Cytopathological Image Classification,"then, we pass c through learnable affine transformations,
such that the class embedding is specialized to the scaling and bias parameters
controlling adaptive instance normalization (adain) [13] in each upblock.",
1085,An Anti-biased TBSRTC-Category Aware Nuclei Segmentation Framework with a Multi-label Thyroid Cytology Benchmark,"for example, benign cells (i & ii) present high sparsity and
are difficult to be distinguished from background tissues, thus may account for
a relatively small proportion when equal images are involved in a training set
[3].",
1086,An Anti-biased TBSRTC-Category Aware Nuclei Segmentation Framework with a Multi-label Thyroid Cytology Benchmark,"we also noticed
that another challenge for accurate nuclei identification is the heavy reliance
on large-scale high-quality annotations [11].",
1087,An Anti-biased TBSRTC-Category Aware Nuclei Segmentation Framework with a Multi-label Thyroid Cytology Benchmark,"innovatively, our approach can
help reduce bias in the learning process of the segmentation model with the
routine unbalanced training set.",
1088,An Anti-biased TBSRTC-Category Aware Nuclei Segmentation Framework with a Multi-label Thyroid Cytology Benchmark,"in tcsegnet, we introduce a tbsrtc-category label guidance block to
address the learning issue from unbalanced routine datasets.",
1089,An Anti-biased TBSRTC-Category Aware Nuclei Segmentation Framework with a Multi-label Thyroid Cytology Benchmark,"the traditional method of
integrating gaussian noise in the mean teacher [18] may be problematic when
working with cytopathology images that have an imbalanced color distribution.",
1090,An Anti-biased TBSRTC-Category Aware Nuclei Segmentation Framework with a Multi-label Thyroid Cytology Benchmark,"to
address this issue, we generate a novel intensity-based noise, which can
adaptively behave stronger in the dark nuclei areas and weaker in bright
cytoplasm or background regions.",
1091,An Anti-biased TBSRTC-Category Aware Nuclei Segmentation Framework with a Multi-label Thyroid Cytology Benchmark,"our approach is capable to address the current
issue in the recognition and segmentation of small isolated cells graded in the
i category, which is always ignored by the unbalanced pixel-wise cell morphology
with other approaches.",
1092,An Anti-biased TBSRTC-Category Aware Nuclei Segmentation Framework with a Multi-label Thyroid Cytology Benchmark,"importantly, it addresses the challenge of
distinguishing nuclei across different cell scales in an unbalanced dataset.",
1093,An Anti-biased TBSRTC-Category Aware Nuclei Segmentation Framework with a Multi-label Thyroid Cytology Benchmark,"we
also extend the framework to a semi-supervised learning fashion to overcome the
issue of lacking annotated training samples.",
1094,Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,"breast cancer (bc) is one of the most common malignant tumors in women worldwide
and it causes nearly 0.7 million deaths in 2020 [26].",
1095,Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,"we evaluate the proposed method on two public datasets as
herohe challenge and bci challenge, which shows that our method achieves
state-of-theart performance.",
1096,Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,"the reconstruction loss is computed by the mean
squared error between the original images x, y and the generative images x , y ,
which is computed aswe use an adjustable hyperparameter θ to balance the losses
of two modalities.",
1097,Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,"we use clam-mil [19] as the
aggregator in our training process.3 experimental results acrobat challenge.",
1098,Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,"the automatic registration of breast cancer tissue (acrobat)
challenge [27] provides h&e wsis and matched ihc wsis (er, pr, her2, and ki67),
which consists of 750 training cases, 100 validation cases, and 300 testing
cases.",
1099,Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,"finally, all the chosen images
(around 0.35 million) from wsi in the same pair are saved for mmp-mae
pre-training.bci challenge.",
1100,Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,"breast cancer immunohistochemical image generation
challenge [16] consists of 3896 pairs of images for training and 977 pairs for
testing, which are used to generate her2 images based on h&e images.",
1101,Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,"so cyclegan focuses more
on style transformation, and it is difficult to match the cell-level information
in detail.",
1102,Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,"we compare our method
with the top five methods reported in herohe challenge review [9].",
1103,Semi-supervised Pathological Image Segmentation via Cross Distillation of Multiple Attentions,"since using a model's prediction to supervise itself may over-fit its bias,
chen et al.",
1104,Semi-supervised Pathological Image Segmentation via Cross Distillation of Multiple Attentions,"since the three branches have different decision boundaries, using the
predictions from one branch as pseudo labels to supervise the others would avoid
each branch over-fitting its bias.",
1105,Semi-supervised Pathological Image Segmentation via Cross Distillation of Multiple Attentions,"to address this problem, we introduce cdkd
to enhance the ability of our mtnet to leverage unlabeled images and eliminate
the negative impact of noisy pseudo labels.",
1106,Semi-supervised Pathological Image Segmentation via Cross Distillation of Multiple Attentions,"to
avoid this problem and further encourage inter-decoder consistency for
regularization, we propose an average prediction-based uncertainty
minimization:where p = (p csa + p ca + p sa )/3 is the average probability map.",
1107,Semi-supervised Pathological Image Segmentation via Cross Distillation of Multiple Attentions,"all these methods used the same backbone of deeplabv3+ [1] for a fair
comparison.quantitative evaluation of these methods is shown in table 1.",
1108,Towards Novel Class Discovery: A Study in Novel Skin Lesions Clustering,"however, since there is a correlation
between new and known diseases, a priori knowledge from known diseases is
expected to help automatically identify new diseases [9].one approach to address
the above problem is novel class discovery (ncd) [7,9,24], which aims to
transfer knowledge from known classes to discover new semantic classes.",
1109,Towards Novel Class Discovery: A Study in Novel Skin Lesions Clustering,"the overall contrastive loss can be
expressed as:, where μ denotes the balance coefficient.",
1110,Towards Novel Class Discovery: A Study in Novel Skin Lesions Clustering,"for
each sample in the current batch, we compute the similarity between its features
and the features of each sample in the memory bank:then based on this feature
similarity, we obtain the final pseudo labels as:k , where ρ is the balance
coefficient.",
1111,Towards Novel Class Discovery: A Study in Novel Skin Lesions Clustering,"to validate the effectiveness of the proposed algorithm, we conduct
experiments on the widely used public dermoscopy challenge dataset isic 2019
[4,5].",
1112,Towards Novel Class Discovery: A Study in Novel Skin Lesions Clustering,"since the dataset suffers from
severe category imbalance, we randomly sampled 500 samples from those major
categories (mel, nv, bcc, bkl) to maintain category balance.",
1113,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"meanwhile, the size of multimodal
medical datasets is not as large as natural vision-language datasets, which
necessitates the need for data-efficient analytics to address the training
difficulty.to tackle above challenges, we propose a pathology-and-genomics
multimodal framework (i.e., pathomics) for survival prediction (fig.",
1114,Robust Cervical Abnormal Cell Detection via Distillation from Local-Scale Consistency Refinement,cervical cancer is the second most common cancer among adult women.,
1115,Robust Cervical Abnormal Cell Detection via Distillation from Local-Scale Consistency Refinement,"to solve this problem, zhou et al.",
1116,Robust Cervical Abnormal Cell Detection via Distillation from Local-Scale Consistency Refinement,"[24] developed an artificial intelligence assistive diagnostic solution,
which integrated yolov3 [16] for detection, xception, and patch-based models to
boost classification.although the above-mentioned attempts can improve the
screening performance significantly, there are several issues that need to be
addressed: 1) object detection methods often require accurate annotated data to
guarantee performance with robustness and generalization.",
1117,Robust Cervical Abnormal Cell Detection via Distillation from Local-Scale Consistency Refinement,"therefore,
the visual feature correlations between the target cells and their surroundings
can provide valuable information to aid the screening process, which also needs
to be utilized when designing the cervical abnormal cell detection network.to
address these issues, we propose a novel method for cervical abnormal cell
detection using distillation from local-scale consistency refinement.",
1118,Robust Cervical Abnormal Cell Detection via Distillation from Local-Scale Consistency Refinement,"in order to solve the problem of mismatched inputs to the detection and
classification models, we add the roi align layer to the output of the fpn.",
1119,StainDiff: Transfer Stain Styles of Histology Images with Denoising Diffusion Probabilistic Models and Self-ensemble,"consequently, it is crucial to minimize
staining variations to ensure reliable, consistent, and accurate cad systems.to
address the issue of stain variations between different domains, stain style
transfer has been proposed.",
1120,StainDiff: Transfer Stain Styles of Histology Images with Denoising Diffusion Probabilistic Models and Self-ensemble,"additionally, they can avoid some of
the challenges encountered by gans and aes, such as the alignment of posterior
distributions or training extra discriminators, leading to a simpler model and
training process.",
1121,StainDiff: Transfer Stain Styles of Histology Images with Denoising Diffusion Probabilistic Models and Self-ensemble,"the model is
superior to gan-based methods as the training of additional discriminators is
free, and also spares for the difficulty in the alignment of posterior
probabilities in ae-based approaches.(2) we also propose a self-ensemble scheme
to further improve and stabilize the style transfer performance in staindiff.",
1122,StainDiff: Transfer Stain Styles of Histology Images with Denoising Diffusion Probabilistic Models and Self-ensemble,"finally, the overall loss function is l = l d + γl c , balanced by the
coefficient γ.",
1123,StainDiff: Transfer Stain Styles of Histology Images with Denoising Diffusion Probabilistic Models and Self-ensemble,"meanwhile, in some clinical settings, multiple institutions or hospitals are
involved, where stain normalization is usually employed for multiple stain
styles to one style alignment.",
1124,StainDiff: Transfer Stain Styles of Histology Images with Denoising Diffusion Probabilistic Models and Self-ensemble,"for a fair comparison,
we follow the settings in previous work [26] by using 10,000 unpaired patches
randomly cropped from the first 184 slides of both scanners as the training set.",
1125,StainDiff: Transfer Stain Styles of Histology Images with Denoising Diffusion Probabilistic Models and Self-ensemble,"in this paper, we propose staindiff, a denoising diffusion model for
histological stain style transfer, hence a model can get rid of the challenging
issues in mainstream networks, such as the mode collapses in gans or alignment
between posterior distributions in aes.",
1126,StainDiff: Transfer Stain Styles of Histology Images with Denoising Diffusion Probabilistic Models and Self-ensemble,"one future work will explore efficient sampling diffusion models,
e.g., ddim [28], to address the long sampling time issue as inherited from ddpm.",
1127,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"in spite of the large amount of data, the number of labeled samples in
mil (represented by the number of individual, globally labelled wsis) is often
small and/or imbalanced [6].",
1128,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"variations were proposed,
to be applied to latent representations [17] as well as to balance data sets
[6].",
1129,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"specifically,
we applied a resnet18 pre-trained on the image-net challenge data, due to the
high performance in previous work on similar data [5].",
1130,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"we investigated various
settings consisting of instancebased only (inst), embedding-based only (emb) and
the dual-stream approach with weightings 3/1, 2/2 (balanced) and 1/3 for the
instance and the embedding-based pathways.as comparison, several other
augmentation methods on feature level are investigated including random
sampling, selective random sampling and random noise.",
1131,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"all images were acquired during clinical
routine at the kardinal schwarzenberg hospital.",
1132,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"the mean and median
age of patients at the date of dissection was 47 and 50 years, respectively.",
1133,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"the
data set comprised 13 male and 27 female patients, corresponding to a slight
gender imbalance.",
1134,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"due to the almost balanced setting, the overall
classification accuracy (mean and standard deviation) is finally reported.",
1135,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"for feature extraction, a resnet18 network,
pretrained on the image-net challenge was deployed [10].",
1136,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"in our analysis, we focused on the embedding-based configuration and on
the balanced combined approach (referred to as 2/2).",
1137,Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"breast cancer (bc) is the most common cancer diagnosed among females and the
second leading cause of cancer death among women after lung cancer [1].",
1138,Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"however, due to the high-cost of
collecting survival information from the patients, it is still a challenge to
build effective machine learning models for specific bc subtypes with limited
annotation data.to deal with the above challenges, several researchers began to
design domain adaption algorithms, which utilize the labeled data from a related
cancer subtype to help predict the patients' survival in the target domain.",
1139,Gene-Induced Multimodal Pre-training for Image-Omic Classification,"but, none of these works considers the challenges in wsis and genes
processing.",
1140,Gene-Induced Multimodal Pre-training for Image-Omic Classification,"the transformer-based
backbones in the classification task require the cls token to be able to extract
accurate global information, which is even more important yet difficult in wsis
due to the long sequence challenge.",
1141,Gene-Induced Multimodal Pre-training for Image-Omic Classification,"to overcome
these issues, we further propose a gene-induced triplet learning module, which
uses pathological images and genomic data as input and extracts high-order and
discriminative features via cls tokens.",
1142,Gene-Induced Multimodal Pre-training for Image-Omic Classification,"training configurations are
consistent throughout the fine-tuning process to ensure fair comparisons.",
1143,Histopathology Image Classification Using Deep Manifold Contrastive Learning,"[4] employed the geodesic distance computed
using the dijkstra algorithm on the knearest neighbor graph to measure the
correlation between the original samples and then further divided each class
into sub-classes to deal with the problems of high spectral dimension and
channel redundancy in the hyperspectral images.",
1144,Histopathology Image Classification Using Deep Manifold Contrastive Learning,"the dataset for the former task was collected from 168 patients
with 332 wsis from seoul national university hospital.",
1145,Histopathology Image Classification Using Deep Manifold Contrastive Learning,"the k-nearest neighbors graph and
the geodesic distance matrix are updated once every five training epochs, which
is empirically chosen to balance running time and accuracy.",
1146,Histopathology Image Classification Using Deep Manifold Contrastive Learning,"in
the future, we plan to optimize the algorithm and apply our method to other
datasets and tasks, such as multi-class classification problems and natural
image datasets.",
1147,Histopathology Image Classification Using Deep Manifold Contrastive Learning,"this study was approved by the institutional review board of seoul national
university hospital (irb no.h-1011-046-339).",
1148,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"additionally, the presence of tumor heterogeneity and the varied distribution of
tumor foci can further complicate the labeling process.to address this issue, we
propose applying neighbor consistency regularization (ncr) [20] to prevent the
model from overfitting to incorrect labels.",
1149,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"for instance, a model
trained on whole-mount slides only may not generalize well to biopsy slides due
to systematic shifts, hindering model performance in the clinical application
scenario.to address the above issues, we propose an adversarial multi-modal
learning (aml) module to force the feature extractor to produce
multimodal-invariant representations on multiple source images.",
1150,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"the optimization process aims to achieve a
balance between these two goals, resulting in an embedding space that encodes as
much information as possible about tumor-associated stroma identification while
not encoding any information on the data source.",
1151,Multi-scope Analysis Driven Hierarchical Graph Transformer for Whole Slide Image Based Cancer Survival Prediction,"moreover, unlike cancer
diagnosis and subtyping tasks, survival prediction is a future state prediction
task with higher difficulty.",
1152,Multi-scope Analysis Driven Hierarchical Graph Transformer for Whole Slide Image Based Cancer Survival Prediction,"however, the conventional
patch-level analysis is difficult to meet this requirement.",
1153,Multi-scope Analysis Driven Hierarchical Graph Transformer for Whole Slide Image Based Cancer Survival Prediction,"for fair comparison, same cnn extractor (i.e.",
1154,Multi-scope Analysis Driven Hierarchical Graph Transformer for Whole Slide Image Based Cancer Survival Prediction,"[13] 0.580 ± 0.005 0.634 ± 0.005 0.617 ± 0.094 deepattnmisl [26] 0.570 ± 0.001
0.644 ± 0.009 0.584 ± 0.019 clam [18] 0.575 ± 0.010 0.641 ± 0.002 0.635 ± 0.006
dsmil [16] 0.550 ± 0.016 0.626 ± 0.005 0.603 ± 0.022 patchgcn [ we selected the
crc dataset for further interpretable analysis, as it is one of
the leading causes of mortality in industrialized countries, and its
prognosis-related factors have been widely studied [3,8].",
1155,Mining Negative Temporal Contexts for False Positive Suppression in Real-Time Ultrasound Lesion Detection,"4.4, the inability to utilize ntc is a key
issue leading to the fps reported by general-purpose detectors.to address this
issue, we propose a novel ultradet model to leverage ntc.",
1156,Mining Negative Temporal Contexts for False Positive Suppression in Real-Time Ultrasound Lesion Detection,"we reproduce all baselines
using our high-quality labels to ensure a fair comparison.",
1157,Mining Negative Temporal Contexts for False Positive Suppression in Real-Time Ultrasound Lesion Detection,"in this paper, we address the clinical challenge of real-time ultrasound lesion
detection.",
1158,Iteratively Coupled Multiple Instance Learning from Instance to Bag Classifier for Whole Slide Image Classification,"patchbased classification is a common solution to this problem [3,8,24].",
1159,Iteratively Coupled Multiple Instance Learning from Instance to Bag Classifier for Whole Slide Image Classification,"however, the lack of reliable supervision directly hinders the
performance of these methods, and serious class-imbalance problems could arise,
as tumor patches may only account for a small portion of the entire wsi [12].in
contrast, mil-based methods have become increasingly preferred due to their only
demand for slide-level labels [18].",
1160,Iteratively Coupled Multiple Instance Learning from Instance to Bag Classifier for Whole Slide Image Classification,"to address the challenges
mentioned above, we propose a novel mil framework called icmil, which can
iteratively couple the patch feature embedding process with the bag-level
classification process to enhance the effectiveness of mil training (as
illustrated in fig.",
1161,Iteratively Coupled Multiple Instance Learning from Instance to Bag Classifier for Whole Slide Image Classification,"after fine-tuning, the domain shift
problem is alleviated in g(•), leading to better patch representations.",
1162,Iteratively Coupled Multiple Instance Learning from Instance to Bag Classifier for Whole Slide Image Classification,"in
contrast, we are the first to consider the optimization of the entire mil
pipeline as an em alike problem, utilizing em for coupling g(•) and f (•)
together iteratively.",
1163,Iteratively Coupled Multiple Instance Learning from Instance to Bag Classifier for Whole Slide Image Classification,"although patch-level labels are officially
provided in camelyon16, they were not used in our experiments.the second dataset
is a private hepatocellular carcinoma (hcc) dataset collected from sir run run
shaw hospital, hangzhou, china.",
1164,Iteratively Coupled Multiple Instance Learning from Instance to Bag Classifier for Whole Slide Image Classification,"since the number of
instances is very large in wsi datasets, we empirically recommend to choose to
run icmil one iteration for fine-tuning g(•) to achieve the balance between
performance gain and time consumption.",
1165,Artifact Restoration in Histology Images with Diffusion Probabilistic Models,"[19] formulates the artifact restoration as an
image-to-image transfer problem.",
1166,Artifact Restoration in Histology Images with Diffusion Probabilistic Models,"(b) diffusion probabilistic model [5] (ours) formulates artifact
restoration as a regional denoising process.in real clinical practice,
rescanning the wsis that contain artifacts can partially address this issue.",
1167,Artifact Restoration in Histology Images with Diffusion Probabilistic Models,"for example, cyclegan [19] formulates the artifact
restoration as an image-to-image transfer problem by learning the transfer
between the artifact and artifact-free image domains from unpaired images, as
depicted in fig.",
1168,Artifact Restoration in Histology Images with Diffusion Probabilistic Models,"however, existing artifact restoration solutions are
confined to generative adversarial networks (gans) [2], which are difficult to
train due to the mode collapse and are prone to suffer from unexpected stain
style mistransfer.",
1169,Artifact Restoration in Histology Images with Diffusion Probabilistic Models,"to address these issues, we make the first attempt at a
diffusion probabilistic model for artifact restoration approach [5], as shown in
fig.",
1170,Artifact Restoration in Histology Images with Diffusion Probabilistic Models,"furthermore, our approach is trained solely with artifact-free images, which
reduces the difficulty in data collection.the major contributions are two-fold.",
1171,Artifact Restoration in Histology Images with Diffusion Probabilistic Models,"for a fair compaison, we train the
cyclegan with two configurations, namely (#1) using the entire dataset, and (#2)
using only half the dataset, where the latter uses the same number of the
training samples as artifusion.",
1172,Thinking Like Sonographers: A Deep CNN Model for Diagnosing Gout from Musculoskeletal Ultrasound,"there are significant
challenges in cnn based gout diagnosis.",
1173,Thinking Like Sonographers: A Deep CNN Model for Diagnosing Gout from Musculoskeletal Ultrasound,"firstly, the gout-characteristics
contain various types including double contour sign, synovial hypertrophy,
synovial effusion, synovial dislocation and bone erosion, and these
gout-characteristics are small and difficult to localize in mskus.",
1174,Thinking Like Sonographers: A Deep CNN Model for Diagnosing Gout from Musculoskeletal Ultrasound,"due to these issues, sota cnn models often fail to learn the gouty
mskus features which are key factors for sonographers' decision.in medical image
analysis, recent works have attempted to inject the recorded gaze information of
clinicians into deep cnn models for helping the models to predict correctly
based on lesion area.",
1175,Thinking Like Sonographers: A Deep CNN Model for Diagnosing Gout from Musculoskeletal Ultrasound,"although these methods have led to promising results, they can be
difficult to implement due to the need to collect doctors' eye movement data for
each image, along with certain restrictions on the network structure.different
from the existing studies, we propose a novel framework to adjust the general
cnns to ""think like sonographers"" from three different levels.",
1176,Thinking Like Sonographers: A Deep CNN Model for Diagnosing Gout from Musculoskeletal Ultrasound,"(1) where to
adjust: modeling sonographers' gaze map to emphasize the region that needs
adjust; (2) what to adjust: classify the instances to systemically detect
predictions made based on unreasonable/biased reasoning and adjust; (3) how to
adjust: developing a training mechanism to strike the balance between gout
prediction accuracy and attention reasonability.",
1177,Thinking Like Sonographers: A Deep CNN Model for Diagnosing Gout from Musculoskeletal Ultrasound,"3) how to adjust: a
training mechanism is developed to strike the balance between gout diagnosis and
attention accuracy for improving cnn.",
1178,Thinking Like Sonographers: A Deep CNN Model for Diagnosing Gout from Musculoskeletal Ultrasound,"we proposed a training mechanism (algorithm 1) which can strike the balance
between the gout diagnosis error and the reasonability error of attention region
to promote the cnns to ""think like sonographers"".",
1179,Thinking Like Sonographers: A Deep CNN Model for Diagnosing Gout from Musculoskeletal Ultrasound,"for sample in rp and uip, α
can be set 0.5 to strike the balance between accuracy and reasonability.",
1180,Scribble-Based 3D Multiple Abdominal Organ Segmentation via Triple-Branch Multi-Dilated Network with Pixel- and Class-Wise Consistency,"for a fair comparison, we used the
primary decoder's outputs as the final results during the inference stage and
did not use any post-processing methods.",
1181,Scribble-Based 3D Multiple Abdominal Organ Segmentation via Triple-Branch Multi-Dilated Network with Pixel- and Class-Wise Consistency,"it can be observed that tv [9] obtained a worse performance than
pce, which is mainly because that method classifies pixels by minimizing the
intra-class intensity variance, making it difficult to achieve good segmentation
due to the low contrast.",
1182,Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"breast cancer is the most prevalent form of cancer among women and can have
serious physical and mental health consequences if left unchecked [5].",
1183,Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"capturing these multi-view shared features can be a challenge
for models.",
1184,Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"to address this issue, we develop a novel method called
bidirectional fusion learning (bfl) to extract shared features from multi-view
mammograms.our contributions can be summarized as follows:• we emphasize the
significance of low-cost gaze to provide weakly-supervised positioning and
visual interpretability for the model.",
1185,Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"layernorm is
also employed to address the issue of imprecise gaze data.",
1186,Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"to overcome the problem of limited data, we
employed various data augmentation techniques, including translation, rotation,
and flipping.",
1187,Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"to address the problem of imbalanced classes, we utilized a
weighted loss function that assigns higher weights to malign cases in order to
balance the number of benign and malign cases.",
1188,Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"we
developed a multi-view model using this approach for a fair comparison, and
found that our method performed better.",
1189,Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"this model requires gaze input during both the
training and inference stages, which limits its practical use in hospitals
without eyetrackers.",
1190,CTFlow: Mitigating Effects of Computed Tomography Acquisition and Reconstruction with Normalizing Flows,"however, inverse problems such as
recovering full radiation dose scans from lower dose scans are inherently
ill-posed.",
1191,CTFlow: Mitigating Effects of Computed Tomography Acquisition and Reconstruction with Normalizing Flows,"(2) aapm-mayo clinic low-dose ct ""grand challenge"" dataset,
a publicly available grand challenge dataset consisting of 5,936 abdominal ct
images from 10 patient cases reconstructed at 1.0 mm slice thickness.",
1192,CTFlow: Mitigating Effects of Computed Tomography Acquisition and Reconstruction with Normalizing Flows,"using the grand challenge dataset, we assessed image
quality and compared it with other previously published low-dose ct denoising
techniques.",
1193,CTFlow: Mitigating Effects of Computed Tomography Acquisition and Reconstruction with Normalizing Flows,"on the grand challenge dataset, ctflow took 3 days to train on an nvidia rtx
8000 gpu.",
1194,Probabilistic Modeling Ensemble Vision Transformer Improves Complex Polyp Segmentation,"furthermore, transformer [3,17,19,20] models have also been proposed
for polyp segmentation, and achieve the state-of-the-art(sota)
performance.despite significant progress made by these binary mask supervised
models, challenges remain in accurately locating polyps, particularly in complex
clinical scenarios, due to their insensitivity to complex lesions and high
false-positive rates.",
1195,Probabilistic Modeling Ensemble Vision Transformer Improves Complex Polyp Segmentation,"however, this method has
limitations in accurately segmenting polyp boundaries, which are crucial for
clinical decision-making.therefore, the primary challenge lies in enhancing
polyp segmentation performance in complex scenarios by precisely preserving the
polyp segmentation boundaries, while simultaneously maximizing the decoder's
attention on the overall pattern of the polyps.in this paper, we propose a novel
transformer-based polyp segmentation framework, petnet, which addresses the
aforementioned challenges and achieves sota performance in locating polyps with
high precision.",
1196,Probabilistic Modeling Ensemble Vision Transformer Improves Complex Polyp Segmentation,"to balance the trade-off between computational speed and feature representation
capability, we utilize the pre-trained pvtv2-b2 model [18] as the backbone.mixed
transformer attention(mta) layer is composed of local-global gaussian-weighted
self-attention (lgg-sa) and external attention (ea).",
1197,Probabilistic Modeling Ensemble Vision Transformer Improves Complex Polyp Segmentation,"building on this manner, we
propose the ensemble method that integrates multiple simple decoders to enhance
the detection and discrimination of difficult polyp samples.",
1198,Probabilistic Modeling Ensemble Vision Transformer Improves Complex Polyp Segmentation,"λ is a hyperparameter used to
balance the binary and gaussian losses.",
1199,DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,"breast cancer (bc) is the most common cancer in women and incidence is
increasing [14].",
1200,DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,"however, most of these studies formulate the diagnosis as an mv
analysis problem without dedicated comparisons between the two breasts.the
question of ""what the bi-mg would look like if they were symmetric?"" is often
considered when radiologists determine the symmetry of bi-mg.",
1201,DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,"however, it is difficult to train the generator in a supervised
manner due to the lack of annotations of the location for asymmetrical pairs.",
1202,DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,"inspired by previous self-adversarial learning work [10], we introduce a frozen
discriminator ψ d to impose constraints on the generator to address this
challenge.",
1203,DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,"the tumors and symmetrical mammograms are combined by an
alpha blending-based method [17], which can be denoted by x|fake =the alpha
weights α k is a 2d gaussian distribution map, in which the co-variance is
determined by the size of k-th tumor t, representing the transparency of the
pixels of the tumor.",
1204,DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,"the in-house
dataset comprises 43,258 mammography exams from 10,670 women between 2004-2020,
collected from a hospital with irb approvals.",
1205,DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,"in this study, we randomly select
20% women of the full dataset, comprising 6,000 normal (bi-rads = 1) and 28,732
abnormal (bi-rads = 1) images.",
1206,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,"however, early-stage renal cancers are
usually asymptomatic, therefore they are often incidentally found during other
examinations [19], which includes non-contrast ct (ncct) scans.segmentation of
kidney tumors on ncct images adds challenges compared to contrast-enhanced ct
(cect) images, due to low contrast and lack of multiphase images.",
1207,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,"the release of two public ct image datasets with kidney and tumor masks from the
2019/2021 kidney and kidney tumor segmentation challenge [8] (kits19, kits21)
attracted researchers to develop various methods for segmentation.looking at the
top 3 teams from each challenge [6,11,13,17,21], all teams utilized 3d u-net [3]
or v-net [16], which bears a similar architecture.",
1208,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,"to overcome this issue, we developed a framework
that specifically incorporates protuberances in kidneys, allowing for an
effective segmentation of tumors on ncct images.in terms of focusing on
protruded regions in kidneys, our work is close to [14,15].",
1209,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,"to avoid this issue, we perform summation not
concatenation to avoid the model from ignoring all output from the protuberance
detection network.",
1210,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,"as can be seen from table 1, our model showed
comparable scores to the winner of kits19 challenge.",
1211,Skin Lesion Correspondence Localization in Total Body Photography,"though
effective at matching skin lesions across pairs of images, the extension of
these methods to the context of total body photography (tbp) for longitudinal
tracking remains a challenge.several works have been proposed for tackling the
skin lesion tracking problem over the full body [7,8,21,22].",
1212,Skin Lesion Correspondence Localization in Total Body Photography,"however, to avoid problems with
repeating (local) textures, we would also like the correspondence to stay close
to the correspondence defined by the landmarks.we achieve this as follows: to
every source vertex v ∈ v 0 we associate a region r v ⊂ v 1 of target vertices
that are either close to φ l, (v) (the corresponding vertex on v 1 as predicted
by the landmarks) or have similar geometric feature descriptors:(given this
region, we define the target vertex corresponding to a source as the vertex
within the region that has the most similar echo descriptor (using the
normalized cross-correlation as before).in practice, we compute the echo
descriptor over three different radii, obtaining three descriptors for each
vertex,the selection of three different radii in echo descriptors is done to
accommodate different sizes of lesions and their surrounding texture, and the
values are empirically determined.",
1213,Anatomy-Informed Data Augmentation for Enhanced Prostate Cancer Detection,"however, the da scheme received less attention, despite its
potential to leverage the data characteristic and address overfitting as the
root of generalization problems.state-of-the-art approaches still rely on
simplistic spatial transformations, like translation, rotation, cropping, and
scaling by globally augmenting the mri sequences [12,20].",
1214,Anatomy-Informed Data Augmentation for Enhanced Prostate Cancer Detection,"the samples were evaluated according to the
international society of urological pathology (isup) standards under the
supervision of a dedicated uropathologist.",
1215,Anatomy-Informed Data Augmentation for Enhanced Prostate Cancer Detection,"compared to the standard nnu-net settings, we implemented balanced
sampling regarding the prevalence of cspca and reduced the number of epochs to
350 to avoid overfitting.",
1216,Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,"the intelligent knife (iknife)
is a mass spectrometry device that can address this challenge by analyzing the
biochemical signatures of resected tissue using the smoke that is released
during tissue incineration [3].",
1217,Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,"particularly, graph transformer networks (gtn) has have shown to
further enhance the transparency of underlying relation between the graph nodes
and decision making via attention mechanism [11].biological data, specially
those acquired intra-opertively, are heterogeneous by nature.",
1218,Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,"to fit the dirichlet distribution to the
output layer of our network, we use a loss function consisting of the prediction
error l p i and the evidence adjustmentwhere λ is the annealing coefficient to
balance the two terms.",
1219,Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,"lastly, when compared to other state-ofthe-art
baselines with uncertainty estimation mechanisms, the proposed evidential graph
transformer network (average balanced accuracy of 91.6 ± 4.3% in table 1)
outperforms mc dropout [9], deep ensembles [15], and masksembles [7] (86.1 ±
5.7%, 88.5 ± 6.8%, and 89.2 ± 5.4% respectively [19]).the estimated
probabilities in evidence based models are directly correlated with model
confidence and therefore more interpretable.",
1220,Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,"average(standard deviation) of accuracy (acc), balanced accuracy (bac)
sensitivity (sen), specificity (spc), and the area under the curve (auc) for the
proposed evidential graph transformer in comparison with graph transformer
(gtn), graph convolution (gcn), and non-graph convolution (cnn) baselines.",
1221,Radiomics-Informed Deep Learning for Classification of Atrial Fibrillation Sub-Types from Left-Atrium CT Volumes,"we use a dataset of 172 patients containing 94 paaf and 78 peaf cases
collected from the sun yat-sen memorial hospital in china.",
1222,Radiomics-Informed Deep Learning for Classification of Atrial Fibrillation Sub-Types from Left-Atrium CT Volumes,"we use the same encoder for all
deep architectures for fair comparison, except for methods that are architecture
specific.",
1223,Radiomics-Informed Deep Learning for Classification of Atrial Fibrillation Sub-Types from Left-Atrium CT Volumes,these issues may be addressed in future works.,
1224,Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-Based Hierarchical Fusion Network with Attention Mechanism,"breast cancer is the most common cancer and the leading cause of cancer death in
women [18].",
1225,Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-Based Hierarchical Fusion Network with Attention Mechanism,"compared to existing methods, we avoid the challenges of
using full-sequence mri and aim to be selective on valuable source data dwi.",
1226,Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-Based Hierarchical Fusion Network with Attention Mechanism,"hierarchical fusion generation module, weighted difference module, and
multisequence attention module have all been shown to improve the performance of
synthesizing target images by addressing the problems of synthesis at different
scales, leveraging differentiable information within and across sequences.",
1227,Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"npc is characterized
by a distinct geographical distribution in southeast asia, north africa, and
arctic [2].",
1228,Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"rigorous
clinical evaluations can establish the safety and efficacy of ai-based
techniques, identify potential biases and limitations, and facilitate the
integration of clinical expertise to ensure accurate and meaningful results
[13].",
1229,Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"the three hospitals were labelled
as institution-1 (110 patients), institution-2 (58 patients), and institution-3
(135 patients), respectively.",
1230,Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"the use of this dataset was approved by the institutional review board
of the university of hong kong/hospital authority hong kong west cluster (hku/ha
hkw irb) with reference number uw21-412, and the research ethics committee
(kowloon central/kowloon east) with reference number kc/ke-18-0085/er-1.",
1231,Automated CT Lung Cancer Screening Workflow Using 3D Camera,none,
1232,Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"age-related macular degeneration (amd) is the leading cause of blindness in the
elderly, affecting nearly 200 million people worldwide [24].",
1233,Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"late amd is classified into either
choroidal neovascularisation (cnv), identified by subretinal fluid, or
geographic atrophy, signalled by progressive loss of photoreceptors and retinal
thinning.",
1234,Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"the one work that tackles this challenge,
and the most related to ours, categorises the time-dependent response of cancer
cells to different drugs, measured by the changing distance in contrastive
feature space from healthy controls [5].",
1235,Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"afterwards, we test our method on a
second independent unseen dataset, which was obtained from moorfields eye
hospital.",
1236,Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"we
also include a demographic baseline using age and sex.",
1237,Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"in all tasks the
standard biomarkers are only marginally more indicative of risk than the
patient's age and sex.",
1238,Multi-task Learning of Histology and Molecular Markers for Classifying Diffuse Glioma,none,
1239,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"however, the precise delineation of the gtv is laborintensive, and is restricted
to specialized hospitals with highly skilled rt experts.",
1240,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"the automatic
identification of the esophagus presents inherent challenges due to its
elongated soft structure and ambiguous boundaries between it and adjacent organs
[12].",
1241,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"moreover, the automatic delineation of the gtv in the esophagus poses a
significant difficulty, primarily attributable to the low contrast between the
esophageal gtv and the neighboring tissue, as well as the limited
datasets.recently, advances in deep learning [21] have promoted research in
automatic esophageal gtv segmentation from computed tomography (ct) [18,19].",
1242,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"meanwhile, an ideal method
for automatic esophageal gtv segmentation in the second course of rt should
consider three key aspects: 1) changes in tumor volume after the first course of
rt, 2) the proliferation of cancerous cells from a tumor to neighboring healthy
cells, and 3) the anatomical-dependent our training approach leverages
multi-center datasets containing relevant annotations, that challenges the
network to retrieve information from e1 using the features from e2.",
1243,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"our training strategy does not specific to any
tasks but challenges the network to retrieve information from another encoder
with augmented inputs, which enables the network to learn from the above three
aspects.",
1244,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"1, our strategy is to challenge the network to retrieve information from
augmented inputs in e 1 using the features from e 2 , which can incorporate a
wide range of datasets that are not tailored for second-course gtv segmentation.",
1245,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"to address this, we apply two distinct randomized
augmentations, p 1 , p 2 , to mimic the unregistered issue of the first and
second course ct.",
1246,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"( 4), s e challenges the
network to extract information from the entire esophagus, which enhances the
network's embedding space with anatomical prior knowledge of the esophagus.",
1247,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"we attribute the drawback is due to the
location-agnostic nature of the operations in mha, where the local regional
correlations are perturbed.to tackle the aforementioned problem, we propose ram
which involves the concatenation of the original features with attention
outputs, allowing for the preservation of convolution-generated regional tumor
patterns while effectively comprehending long-range prior knowledge specific to
the esophagus.",
1248,CLIP-Lung: Textual Knowledge-Guided Lung Nodule Malignancy Prediction,"indeed, the ordinal
regressionbased methods are able to learn ordered manifolds and to further
enhance the prediction accuracy.however, the aforementioned methods still face
challenges in distinguishing visually similar samples with adjacent rank labels.",
1249,CLIP-Lung: Textual Knowledge-Guided Lung Nodule Malignancy Prediction,"to address
this issue, we found that the text attributes, such as ""subtlety"", ""sphericity"",
""margin"", and ""lobulation"", annotated by radiologists, can exhibit the
differences between these hard samples.",
1250,CLIP-Lung: Textual Knowledge-Guided Lung Nodule Malignancy Prediction,"in practice, this also
aligns with the fact that the annotated text information represents the direct
justification for identifying lesion regions in the clinic.",
1251,CLIP-Lung: Textual Knowledge-Guided Lung Nodule Malignancy Prediction,"consequently, aligning these distinct feature types becomes challenging,
resulting in a bias towards the text features associated with malignant nodules.",
1252,EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"when a deep learning model overfits specific
artifacts instead of learning the correct dermoscopic patterns, it may fail to
identify skin lesions in real-world environments where the artifacts are absent
or inconsistent.to alleviate the artifact bias and enhance the model's
generalization ability, we rethink the problem from the domain generalization
(dg) perspective, where a model trained within multiple different but related
domains are expected to perform well in unseen test domains.",
1253,EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"still, two significant challenges
remain.",
1254,EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"second, previous methods such as [30]
focused on learning domain knowledge independently while overlooking the rich
cross-domain information that all domain experts can contribute collectively for
the target domain prediction.to overcome the above problems, we propose an
environment-aware prompt vision transformer (epvt) for domain generalization of
skin lesion recognition.",
1255,EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"additionally, we devise a domain
mixup strategy to resolve the problem of co-occurring artifacts in dermoscopic
images and mitigate the resulting noisy domain label assignments.our
contributions can be summarized as: (1) we resolve an artifacts-derived biasing
problem in skin cancer diagnosis using a novel environment-aware prompt
learning-based dg algorithm, epvt; (2) epvt takes advantage of a vitbased
domain-aware prompt learning and a novel domain prompt generator to improve
domain-specific and cross-domain knowledge learning simultaneously;(3) a domain
mixup strategy is devised to reduce the co-artifacts specific to dermoscopic
images; (4) extensive experiments on four out-of-distribution skin datasets and
six biased isic datasets demonstrate the outperforming generalization ability
and robustness of epvt under heterogeneous distribution shifts.",
1256,EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"however, a non-trivial issue arises due to the possible cooccurrence of
different artifacts from other domains within each domain.",
1257,EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"to address this
issue, we employ a domain mixup strategy [27,28].",
1258,EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"this strategy can overcome the challenge
of ambiguous domain labels in dermoscopic images and improve the performance of
our model.",
1259,EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"(2) trap set debiasing: we train
and test our epvt with its baseline on six trap sets [3] with increasing bias
levels, ranging from 0 (randomly split training and testing sets from the
isic2019 dataset) to 1 (the highest bias level where the correlation between
artifacts and class label is in the opposite direction in the dataset splits).",
1260,EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"more details about these datasets and splits are provided in the complementary
material.implementation details: for a fair comparison, we train all models
using vit-base/16 [8] backbone pre-trained on imagenet and report the roc-auc
with five random seeds.",
1261,EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"each point on the graph represents an algorithm that
is trained and tested on a specific bias degree split.the graph shows that the
erm baseline performs better than our epvt when the bias is low (0 and 0.3).",
1262,EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"as the
bias degree increases, the correlation between artifacts and class labels
decreases, and overfitting the train set causes the performance of erm to drop
dramatically on the test set with a significant distribution difference.",
1263,EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"in
contrast, our epvt exhibits greater robustness to different bias levels.",
1264,EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"notably, our epvt outperforms the erm baseline by 9.4% on the bias 1
dataset.prompt weights analysis: to verify whether our model has learned the
correct domain prompts for target domain prediction, we analyze and plot the
results in fig.",
1265,EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"our approach addresses the co-artifacts problem using a
domain mixup strategy and cross-domain learning problems using a domain prompt
generator.",
1266,Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"most cad studies were developed on regular and selected
datasets in the laboratory environment, which avoided the problems (data noise,
missing data, etc.) in the clinical scenarios [3,6,9,13,18].",
1267,Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"this phenomenon is especially common in rare tumors like
pancreatic neuroendocrine neoplasms (pnens).in order to overcome above
challenges, some studies [3,9,13,18] used multilabel method because of the
following advantages: 1) the input of the model is only a single modality such
as images, which is easy to apply clinically; 2) the model learns multi-label
and multi-disciplinary knowledge, which is consistent with clinical logic; 3)
multi-label simultaneous prediction, which meets the need of clinical
multi-dimensional description of patients.",
1268,Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"the former implicitly interacts with
multi-label information, making it difficult to fully utilize the correlation
among labels; and the latter requires the use of word embeddings pre-trained on
public databases, which is not friendly to many medical domain proper nouns.",
1269,Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"in addition, none of the current multi-label cad studies have
considered the problem of missing labels and noisy labels.considering these
real-world challenges, we propose a multi-label model named self-feedback
transformer (sft), and validate our method on a realworld pnens dataset.",
1270,Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"for labels with continuous values such as
age, the value normalized to 0 ∼ 1 is w p i .",
1271,Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"specifically, embedding setare
the input tokens, the attention value α and output token e are computed as
follows:where e i is from e, w q , w k and w v are weight matrices of query, key
and value, respectively, w r and w o are transformation matrices, and b 1 and b
2 are bias vectors.",
1272,Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"to overcome this problem, we propose a self-feedback strategy (sfs) inspired by
recurrent neural networks (rnn) to enhance the interaction of labels.",
1273,Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"it should be
noted that the cnn backbone of each method was replaced as 3d vgg8 to ensure
fair comparison.",
1274,Developing Large Pre-trained Model for Breast Tumor Segmentation from Ultrasound Images,"breast cancer is a serious health problem with high incidence and wide
prevalence for women throughout the world [1,2].",
1275,Developing Large Pre-trained Model for Breast Tumor Segmentation from Ultrasound Images,"however, due to speckle noise and
shadows in ultrasound images, breast tumor boundaries tend to be blurry and are
difficult to be distinguished from background.",
1276,Developing Large Pre-trained Model for Breast Tumor Segmentation from Ultrasound Images,"these issues
pose challenges and difficulties for accurate breast tumor segmentation in
ultrasound images.various approaches based on deep learning have been developed
for tumor segmentation with promising results [13][14][15][16][17][18][19].",
1277,Developing Large Pre-trained Model for Breast Tumor Segmentation from Ultrasound Images,"however, although these proposed
models have achieved satisfactory results in different medical segmentation
tasks, their performances are limited for breast tumor segmentation in
ultrasound images due to the low image contrast and blurry tissue boundary.to
address these challenges, we present, to the best of our knowledge, the first
work to adopt multi-scale features collected from large set of clinical
ultrasound images for breast tumor segmentation.",
1278,Developing Large Pre-trained Model for Breast Tumor Segmentation from Ultrasound Images,we collected 10927 cases for this research from yunnan cancer hospital.,
1279,Developing Large Pre-trained Model for Breast Tumor Segmentation from Ultrasound Images,"for external validation, we further test our model on two independent
publicly-available datasets collected by stu-hospital (dataset 1) [22] and
syu-university (dataset 2) [23].",
1280,Developing Large Pre-trained Model for Breast Tumor Segmentation from Ultrasound Images,"the probability maps
predicted by our model are more consistent with the ground truth, especially in
the tiny structures which are difficult to capture.",
1281,3D Mitochondria Instance Segmentation with Spatio-Temporal Transformers,"here, we look into the problem of accurate 3d mitochondria instance
segmentation.earlier works on mitochondria segmentation employ standard image
processing and machine learning methods [20,21,33].",
1282,3D Mitochondria Instance Segmentation with Spatio-Temporal Transformers,"recent approaches address
[4,15,26] this problem by leveraging either 2d or 3d deep convolutional neural
network (cnns) architectures.",
1283,3D Mitochondria Instance Segmentation with Spatio-Temporal Transformers,"inspired from success in natural language processing
[32], recently vision transformers (vits) [6,13,19,30,31] have been successfully
utilized in different computer vision problems due to their capabilities at
modelling long-range dependencies and enabling the model to attend to all the
elements in the input sequence.",
1284,3D Mitochondria Instance Segmentation with Spatio-Temporal Transformers,"while self-attention has been
shown to be beneficial when combined with convolutional layers for different
medical imaging tasks, to the best of our knowledge, no previous attempt to
design spatio-temporal self-attention as an exclusive building block for the
problem of 3d mitochondria instance segmentation exists in literature.",
1285,3D Mitochondria Instance Segmentation with Spatio-Temporal Transformers,"the resulting spatio-temporal features of decoder are then input to
instance segmentation block to generate final instance masks, as in
baseline.semantic fg-bg adversarial loss: as discussed earlier, a common
challenge in mitochondria instance segmentation is to accurately delineate the
region of mitochondria instances from the cluttered background.",
1286,3D Mitochondria Instance Segmentation with Spatio-Temporal Transformers,"the mitoem [36] is a dense mitochondria instance
segmentation dataset from isbi 2021 challenge.",
1287,3D Mitochondria Instance Segmentation with Spatio-Temporal Transformers,"during training of mitoem, for the fair comparison, we adopt same
data augmentation technique from [36].",
1288,3D Mitochondria Instance Segmentation with Spatio-Temporal Transformers,"for fair comparison with previous works, we use the same
evaluation metrics as in the literature for both datasets.",
1289,Physics-Informed Conditional Autoencoder Approach for Robust Metabolic CEST MRI at 7T,"we
developed a conditional autoencoder (cae) to solve the b 1 inhomogeneity
problem, which is essential for the generation of metabolic cest contrast maps
at 7t.",
1290,Diffusion-Based Data Augmentation for Nuclei Image Segmentation,"therefore, the problem of
synthesizing instance map transfers to synthesizing nuclei structures.",
1291,Deep Unsupervised Clustering for Conditional Identification of Subgroups Within a Digital Pathology Image Set,"never-theless, comprehensive reviews highlight major issues of generalizability,
robustness, and reproducibility in medical imaging ai/ml [9,15].",
1292,Deep Unsupervised Clustering for Conditional Identification of Subgroups Within a Digital Pathology Image Set,"one solution to this issue is to apply a clustering
algorithm to the data, with the goal of identifying the unannotated subgroups.",
1293,Deep Unsupervised Clustering for Conditional Identification of Subgroups Within a Digital Pathology Image Set,"however, due to the complexity and high
dimensionality of the medical imaging data and the resulting difficulty in
establishing a concrete notion of similarity, extracting low-dimensional
characteristics becomes the key to establishing the best criteria for grouping.",
1294,Deep Unsupervised Clustering for Conditional Identification of Subgroups Within a Digital Pathology Image Set,"while cdvade can be used as an exploratory tool to unveil unknown subgroups in a
given dataset, developing specialized quantitative evaluation metrics for this
unsupervised task is inherently difficult and will also be a focus in our future
work.",
1295,A Texture Neural Network to Predict the Abnormal Brachial Plexus from Routine Magnetic Resonance Imaging,"however, how to arrange these glcms to form the 3d
volume to optimize the performance is a major challenge.with the goal of
classifying normal from abnormal bp, we explored the approach of deep texture
learning.",
1296,A Texture Neural Network to Predict the Abnormal Brachial Plexus from Routine Magnetic Resonance Imaging,"following irb approval for this study, we search for patients with metastatic
breast cancer who had a breast cancer mri performed between 2010 and 2020 and
had morphologically positive bp on the mri report from our electronic medical
records (emr) in * hospital.",
1297,A Texture Neural Network to Predict the Abnormal Brachial Plexus from Routine Magnetic Resonance Imaging,"good, fair and poor.",
1298,A Texture Neural Network to Predict the Abnormal Brachial Plexus from Routine Magnetic Resonance Imaging,"since the tpp matrix is always small, there are
only 15 layers in tpp which could reduce the risk of overfitting issue met in
deeper neural networks.",
1299,A Texture Neural Network to Predict the Abnormal Brachial Plexus from Routine Magnetic Resonance Imaging,"since each channel is corresponding with one tpp, it can solve the
pattern arrangement issue occurred in glcm-cnn.",
1300,CircleFormer: Circular Nuclei Detection in Whole Slide Images with Circle Queries and Attention,"to address the problem, an anchor-free cnnbased
circular object detection method circlenet [16] is proposed for glomeruli
detection.",
1301,CircleFormer: Circular Nuclei Detection in Whole Slide Images with Circle Queries and Attention,"but it also suffers poor detection
accuracy for overlapping objects and requires additional post-processing steps
to obtain the final detection results.recently, detr [1], a transformer-based
object detection method reformulates object detection as a set-to-set prediction
problem, and it removes both the hand-crafted anchors and the non-maximum
suppression (nms) postprocessing.",
1302,CircleFormer: Circular Nuclei Detection in Whole Slide Images with Circle Queries and Attention,"to address the difficulty optimizing
non-overlapping bounding boxes, generalized iou (giou) [13] is introduced as a
loss for rectangle object detection tasks.",
1303,CircleFormer: Circular Nuclei Detection in Whole Slide Images with Circle Queries and Attention,"monuseg dataset is a public dataset from the 2018 multi-organ
nuclei segmentation challenge [6].",
1304,CircleFormer: Circular Nuclei Detection in Whole Slide Images with Circle Queries and Attention,"we assume increasing the number of heads brings too
many parameters and makes the model difficult to converge.",
1305,Self-supervised Dense Representation Learning for Live-Cell Microscopy with Time Arrow Prediction,"recently, self-supervised representation learning (ssl) has
emerged as a promising approach to alleviate this problem [1,3].",
1306,Self-supervised Dense Representation Learning for Live-Cell Microscopy with Time Arrow Prediction,"resnet [9]) that lack this symmetry, we here directly incorporate this
inductive bias via a permutation-equivariant head h that is a generalization of
the set permutation-equivariant layer proposed in [32] to dense inputs.",
1307,Self-supervised Dense Representation Learning for Live-Cell Microscopy with Time Arrow Prediction,"using the permutation-equivariant head alleviated this
problem and enabled a consistent loss decrease already from the beginning of
training.",
1308,Prompt-MIL: Boosting Multi-instance Learning Schemes via Task-Specific Prompt Tuning,"to address this issue, we utilize the
patch batching and gradient retaining techniques from [25].",
1309,Prompt-Based Grouping Transformer for Nucleus Detection and Classification,"it is a
challenge to infer the nucleus types due to the diversity and unbalanced
distribution of nuclei.",
1310,Maximum-Entropy Estimation of Joint Relaxation-Diffusion Distribution Using Multi-TE Diffusion MRI,"a standard approach for
estimating rdd functions is to represent the measurement signal using basis
functions of different diffusivity and relaxation rates which may lead to biased
estimation results because of the strong coupling between basis signals.this
work introduces the maximum entropy (me) estimation method for more accurate
estimation of rdd functions by adapting theories and techniques developed for
the classical hausdorff moment problems [10,13,15,18].",
1311,Maximum-Entropy Estimation of Joint Relaxation-Diffusion Distribution Using Multi-TE Diffusion MRI,"me estimation is also a
standard approach for high-resolution power spectral estimation of time series
data which involves a similar trigonometric moment problem [7,21].",
1312,Maximum-Entropy Estimation of Joint Relaxation-Diffusion Distribution Using Multi-TE Diffusion MRI,"to this
end, we first show that the problem of estimation rdd function is equivalent to
the multivariate hausdorff moment problem by applying a change of variables.",
1313,Maximum-Entropy Estimation of Joint Relaxation-Diffusion Distribution Using Multi-TE Diffusion MRI,"three formulations of maximum entropy (me) estimation problems are proposed to
estimate me-rdd functions in different parameter spaces.",
1314,Maximum-Entropy Estimation of Joint Relaxation-Diffusion Distribution Using Multi-TE Diffusion MRI,"next, let s k := s(x k ) which satisfies thatwhere p(θ) = e
-xmin•θ p(θ) is a scaled rdd function adjusted based on the non-zero minimum
te.the hausdorff moment problem focuses on the existence of distribution
functions that satisfy a sequence of power moments [10,15].",
1315,Maximum-Entropy Estimation of Joint Relaxation-Diffusion Distribution Using Multi-TE Diffusion MRI,"to change s k to
power moments as in the hausdorff moment problem, we define γ := [e -δ b θ1 , e
-δtθ2 ], which takes value in the interval γ := [e -δ b d0 , 1] × [e -δtr0 , 1].",
1316,Maximum-Entropy Estimation of Joint Relaxation-Diffusion Distribution Using Multi-TE Diffusion MRI,"therefore the problem of estimating rdd functions using finite rdmri
measurements is equivalent to a multivariate hausdorff moment problem.",
1317,Maximum-Entropy Estimation of Joint Relaxation-Diffusion Distribution Using Multi-TE Diffusion MRI,"we note
that the unit interval is usually considered in hausdorff moment problems.",
1318,Maximum-Entropy Estimation of Joint Relaxation-Diffusion Distribution Using Multi-TE Diffusion MRI,"in moment
problems, the maximum entropy (me) method is a standard approach to estimate
probability distributions and power spectral density functions [15].",
1319,Maximum-Entropy Estimation of Joint Relaxation-Diffusion Distribution Using Multi-TE Diffusion MRI,"(3), ( 4) and ( 5), three
optimization problems are introduced to estimate me-rdd functions below.the
first me problem is developed based on eq.",
1320,Maximum-Entropy Estimation of Joint Relaxation-Diffusion Distribution Using Multi-TE Diffusion MRI,"the solutions to me
problems have been extensively investigated in moment problems [15].",
1321,Maximum-Entropy Estimation of Joint Relaxation-Diffusion Distribution Using Multi-TE Diffusion MRI,"( 4), the second me
problem is introduced as below:where p(θ) is the pre-scaled rdd to adjust for
the nonzero t min .",
1322,Maximum-Entropy Estimation of Joint Relaxation-Diffusion Distribution Using Multi-TE Diffusion MRI,"( 5) by
solving the following problem:γby changing the variable γ back to θ, eq.",
1323,Maximum-Entropy Estimation of Joint Relaxation-Diffusion Distribution Using Multi-TE Diffusion MRI,"( 7), ( 9) and ( 12) can be obtained by
solving the dual formulation of the me problems, which can be expressed as
energy minimization problems based on the dual formulations.for the solution in
eq.",
1324,Maximum-Entropy Estimation of Joint Relaxation-Diffusion Distribution Using Multi-TE Diffusion MRI,"( 12) can be obtained by minimizing the following to convex
energy functions:in this paper, the energy minimization problem was solved using
a customized newton algorithm with the armijo line-search method [5].",
1325,Maximum-Entropy Estimation of Joint Relaxation-Diffusion Distribution Using Multi-TE Diffusion MRI,"we solved a constrained l 2
minimization problem to find the optimal non-negative coefficient c n with
minimum l 2 norm.",
1326,Maximum-Entropy Estimation of Joint Relaxation-Diffusion Distribution Using Multi-TE Diffusion MRI,"to our knowledge, this
is the first work showing that the estimation of multidimensional rdd functions
is equivalent to the classical multivariate hausdorff moment problem.",
1327,Simulation of Arbitrary Level Contrast Dose in MRI Using an Iterative Global Transformer Model,"to this effect, we introduce a vision transformer based dl model1
that can synthesize brain 2 mri images that correspond to arbitrary dose levels,
by training on a highly imbalanced dataset with only t1w pre-contrast, t1w 10%
low-dose, and t1w ce standard dose images.",
1328,Simulation of Arbitrary Level Contrast Dose in MRI Using an Iterative Global Transformer Model,"iterative learning design: dl based models tend to perform poorly when the
training data is highly imbalanced [11].",
1329,Simulation of Arbitrary Level Contrast Dose in MRI Using an Iterative Global Transformer Model,"furthermore, the problem of arbitrary
dose simulation requires the interpolation of intermediate dose-levels using a
minimum number of data points.",
1330,Simulation of Arbitrary Level Contrast Dose in MRI Using an Iterative Global Transformer Model,"we
first utilize this design paradigm for the dose simulation task and train an
end-to-end model on a highly imbalanced dataset where only t1w pre-contrast, t1w
low-dose, and t1w post-contrast are available.as shown in fig.",
1331,Simulation of Arbitrary Level Contrast Dose in MRI Using an Iterative Global Transformer Model,"to tackle the problem of
gradient explosion or vanishing, ""soft labels"" are generated using linear
scaling.",
1332,Simulation of Arbitrary Level Contrast Dose in MRI Using an Iterative Global Transformer Model,"2)
tumor segmentation using the t1ce volumes synthesized in the above step, we
perform tumor segmentation using the winning solution of brats 2018 challenge
[26].",
1333,TractCloud: Registration-Free Tractography Parcellation with a Novel Local-Global Streamline Point Cloud Representation,"however, multiple
challenges exist when using streamline data as deep network input.",
1334,TractCloud: Registration-Free Tractography Parcellation with a Novel Local-Global Streamline Point Cloud Representation,"one
well-known challenge is that streamlines can be equivalently represented in
forward or reverse order [11,39], complicating their direct representation as
vectors [7] or images [44].",
1335,TractCloud: Registration-Free Tractography Parcellation with a Novel Local-Global Streamline Point Cloud Representation,"another challenge is that the geometric
relationships between the streamlines in the brain have previously been ignored:
existing parcellation methods [7,[15][16][17]37,39,44] train and classify each
streamline independently.",
1336,TractCloud: Registration-Free Tractography Parcellation with a Novel Local-Global Streamline Point Cloud Representation,"finally, computational cost can pose a challenge for
the parcellation of large tractography datasets that can include thousands of
subjects with millions of streamlines per subject.in this work, we propose a
novel point-cloud-based strategy that leverages neighboring and whole-brain
streamline information to learn local-global streamline representations.",
1337,TractCloud: Registration-Free Tractography Parcellation with a Novel Local-Global Streamline Point Cloud Representation,"recently,
registration-free techniques have been proposed for tractography parcellation to
handle computational challenges resulting from large inter-subject variability
and to increase robustness to image registration inaccuracies [19,29].",
1338,Relaxation-Diffusion Spectrum Imaging for Probing Tissue Microarchitecture,"the problem can be
simplified by considering per-axon diffusion models [8,10,28], which typically
factor out orientation information and hence involve less parameters.",
1339,Relaxation-Diffusion Spectrum Imaging for Probing Tissue Microarchitecture,"we can solve
for x in ( 6) via an augmented problem with the osqp solver 1 :(ii) relaxation
times.",
1340,Relaxation-Diffusion Spectrum Imaging for Probing Tissue Microarchitecture,"with x solved, e and w can be determined by minimizing a constrained
non-linear multivariate problem:which can be solved using a gradient based
optimizer.",
1341,Relaxation-Diffusion Spectrum Imaging for Probing Tissue Microarchitecture,"with e
determined, (3) can be rewritten as a strictly convex quadratic programming (qp)
problem:which can be solved using the osqp solver.",
1342,Exploring Unsupervised Cell Recognition with Prior Self-activation Maps,"it is
also difficult to achieve accurate labeling because of the large variations
among different cells and the variability of reading experiences among
pathologists.work has been devoted to reducing dependency on manual annotations
recently.",
1343,Exploring Unsupervised Cell Recognition with Prior Self-activation Maps,"it combines the advantage of correlation filters
and deep learning but needs iterative training and finetuning.cnns with
inductive biases have priority over local features of the nuclei with dense
distribution and semi-regular shape.",
1344,Brain Anatomy-Guided MRI Analysis for Assessing Clinical Progression of Cognitive Impairment with Structural MRI,"to provide accurate brain anatomy, we perform image preprocessing and
brain tissue segmentation for these mris to generate ground-truth segmentation
of three tissues, i.e., white matter (wm), gray matter (gm) and cerebrospinal
fluid (csf), using an in-house toolbox ibeat [16] with manual verification.the
downstream model is trained on 1) a late-life depression (lld) study with 309
subjects from two sites [17,18], and 2) a type 2 diabetes mellitus (dm) study
with 82 subjects from the first affiliated hospital of guangzhou university of
chinese medicine.",
1345,Brain Anatomy-Guided MRI Analysis for Assessing Clinical Progression of Cognitive Impairment with Structural MRI,"all mris
are preprocessed via the following pipeline: 1) bias field correction, 2) skull
stripping, 3) affine registration to the mni space, 4) resampling to 1 × 1 × 1
mm 3 , 5) deformable registration to aal3 [19] with syn [20], and 6) warping 166
regions-of-interest (rois) of aal3 back to mri volumes.proposed method.",
1346,Brain Anatomy-Guided MRI Analysis for Assessing Clinical Progression of Cognitive Impairment with Structural MRI,"for problems without ground-truth segmentation
maps, we can resort to an mri reconstruction task to train the pretext model in
an unsupervised manner.(2) downstream model for prediction.",
1347,Brain Anatomy-Guided MRI Analysis for Assessing Clinical Progression of Cognitive Impairment with Structural MRI,"such
partition is repeated five times independently to avoid any bias introduced by
random partition, and the mean and standard deviation results are recorded.",
1348,Brain Anatomy-Guided MRI Analysis for Assessing Clinical Progression of Cognitive Impairment with Structural MRI,"second, among 10 deep models, our bar produces the lowest
standard deviation in most cases (especially on sen and spe), suggesting its
robustness to bias introduced by random data partition in the downstream task.",
1349,Brain Anatomy-Guided MRI Analysis for Assessing Clinical Progression of Cognitive Impairment with Structural MRI,"cnd classification is more
challenging, which could be due to the more imbalanced training data in this
task (as shown in table sii of supplementary materials).",
1350,Brain Anatomy-Guided MRI Analysis for Assessing Clinical Progression of Cognitive Impairment with Structural MRI,"there are a total of 42
subjects (i.e., 17 mci and 25 hc) used for training in this task, which are
fewer but more balanced than the two tasks in the lld study (see table sii).",
1351,Brain Anatomy-Guided MRI Analysis for Assessing Clinical Progression of Cognitive Impairment with Structural MRI,"these results imply that data
imbalance may be an important issue affecting the performance of deep learning
models when the number of training samples is limited.segmentation results.",
1352,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning,"however, such algorithms are commonly
trained on healthy subjects and have shown issues in processing cases with
anatomical abnormalities, e.g.",
1353,B-Cos Aligned Transformers Learn Human-Interpretable Features,"making artificial neural networks more interpretable, transparent, and
trustworthy remains one of the biggest challenges in deep learning.",
1354,B-Cos Aligned Transformers Learn Human-Interpretable Features,"to
address these issues, we propose a novel family of transformer architectures
based on the b-cos transform originally developed for cnns [7].",
1355,B-Cos Aligned Transformers Learn Human-Interpretable Features,"therefore, we
choose this problem as our target.",
1356,B-Cos Aligned Transformers Learn Human-Interpretable Features,"5: when bvt
is trained from scratch, the model faces a trade-off between learning the weight
and input alignment and finding the appropriate inductive bias to solve the
classification task.",
1357,B-Cos Aligned Transformers Learn Human-Interpretable Features,"by reintroducing many of the inductive biases of cnns
through the window attention in the case of swin or transfer learning in the
case of bvt, the model likely overcomes this initial problem.moreover, we would
like to emphasize that the modified models have no negative impact on the
model's performance.",
1358,Single-subject Multi-contrast MRI Super-resolution via Implicit Neural Representations,"moreover, unlike
conventional super-resolution models trained on a cohort, a personalized model
is of clinical relevance to avoid the danger of potential misdiagnosis caused by
cohort-learned biases.",
1359,Single-subject Multi-contrast MRI Super-resolution via Implicit Neural Representations,"key reasons behind inr's success can be attributed to
overcoming the low-frequency bias of multi-layer perceptrons (mlp) [21,24,25].",
1360,Single-subject Multi-contrast MRI Super-resolution via Implicit Neural Representations,"in this section, we first formally introduce the problem of joint
super-resolution of multi-contrast mri from only one image per contrast per
patient.",
1361,Single-subject Multi-contrast MRI Super-resolution via Implicit Neural Representations,"subsequently, we detail our model architecture and
training configuration.problem statement.",
1362,Single-subject Multi-contrast MRI Super-resolution via Implicit Neural Representations,"to enable fair evaluation between our predictions and the reference hr
ground truths, the in-plane snr between the lr input scan and corresponding
ground truth has to match.",
1363,Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"patients with gbm generally have a very poor survival rate;
the median overall survival time is about 14 months [17]; and the overall
survival time is affected by many factors, including patient characteristics
(e.g., age and physical status), tissue histopathology (e.g., cellular density
and nuclear atypia), and molecular pathology (e.g., mutations and gene
expression levels) [1,14,15].",
1364,Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"although these factors, particularly molecular
information, have usually proved to be strong predictors of survival in gbm,
there remain substantial challenges and unmet clinical needs to exploit easily
accessible, noninvasive neuroimaging data acquired preoperatively to predict
overall survival time of gbm patients, which can benefit treatment planning.to
do so, magnetic resonance imaging (mri) and its derived radiomics have been
widely used to study gbm preoperative prognosis over the last few decades.",
1365,Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"in order to circumvent these issues, in this paper we
introduce a novel neuroimaging feature family, namely functional lesion network
(fln) maps that are generated by our augmented lesion network mapping (a-lnm),
for overall survival time prediction of gbm patients.",
1366,Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"it publicly released preprocessed
restingstate fmri data of 1000 healthy right-handed subjects with an average age
21.5 ± 2.9 years and approximately equal numbers of males and females from the
brain genomics superstruct project (gsp) [5], where the concrete image
acquisition parameters and preprocessing procedures can be found as well.",
1367,Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"in all
experiments, we conducted five-fold crossvalidation ten times in order to reduce
the effect of sampling bias.",
1368,A Multi-task Network for Anatomy Identification in Endoscopic Pituitary Surgery,"a difficulty faced by surgeons performing endoscopic pituitary surgery is
identifying the areas of the bone which are safe to open.",
1369,A Multi-task Network for Anatomy Identification in Endoscopic Pituitary Surgery,"hence, the task can be split into two sub-tasks to account for these
difficulties in identification: (1) the semantic segmentation of the two larger,
visually distinct, and frequently occurring structures (sella and clival
recess); and (2) the centroid detection of the eight smaller structures (fig.",
1370,A Multi-task Network for Anatomy Identification in Endoscopic Pituitary Surgery,"to the best of the authors' knowledge, this is the
first work addressing the problem at this granularity.",
1371,A Multi-task Network for Anatomy Identification in Endoscopic Pituitary Surgery,"an extension of logits
cross-entropy, logits focal loss, was used instead as it accounts for data
imbalance between classes.centroid detection: 5-models were trialed: 3-models
consisted of encoders with a convolution layer and linear activation; and
2-models consisted of encoderdecoders with an average pooling layer and sigmoid
activation with 0.3 dropout.",
1372,A Multi-task Network for Anatomy Identification in Endoscopic Pituitary Surgery,"to account for structure data imbalance, images were randomly
split such that the number of structures in each fold is approximately even.",
1373,A Multi-task Network for Anatomy Identification in Endoscopic Pituitary Surgery,"images: images come from 64-videos of endoscopic pituitary surgery where the
sellar phase is present [9], recorded between 30 aug 2018 and 20 feb 2021 from
the national hospital of neurology and neurosurgery, london, united kingdom.",
1374,A Multi-task Network for Anatomy Identification in Endoscopic Pituitary Surgery,"this emphasizes the challenge of
identifying smaller structure in computer vision, and supports the need for
detection and multi-task solutions.",
1375,Intraoperative CT Augmentation for Needle-Based Liver Interventions,"in this work, we propose a method
for visualizing intrahepatic structures after organ motion and needle-induced
deformations, in non-injected images, by exploiting image features that are
generally not perceivable by the human eye in common clinical workflows.to
address this challenge, two main strategies could be considered: image fusion
and image processing techniques.",
1376,Intraoperative CT Augmentation for Needle-Based Liver Interventions,"this process is often described as an optimization problem [9,10] which
can be computationally expensive when dealing with non-linear deformations,
making their use in a clinical workflow limited.",
1377,Intraoperative CT Augmentation for Needle-Based Liver Interventions,"recent deep learning approaches
[11,12,14] have proved to be a successful alternative to solve image fusion
problems, even when a large non-linear mapping is required.",
1378,Intraoperative CT Augmentation for Needle-Based Liver Interventions,"however, such unsupervised methods fail
at solving our problem due to lack of similar image features between the
contrasted (cct) and non-contrasted (ncct) image in the vascular tree region
(see sect.",
1379,Intraoperative CT Augmentation for Needle-Based Liver Interventions,"3.3).on the other hand, deep learning techniques have proven to be
very efficient at solving image processing challenges [15].",
1380,Intraoperative CT Augmentation for Needle-Based Liver Interventions,"yet, segmenting vessels from non-contrasted images remains a challenge for
the medical imaging community [16].",
1381,Intraoperative CT Augmentation for Needle-Based Liver Interventions,"however,
applying such methods to generate a contrasted intraoperative ct is not a
sufficiently accurate solution for the problem that we address.",
1382,Intraoperative CT Augmentation for Needle-Based Liver Interventions,"we note that public data sets
such as deeplesion [24], 3dircadb-01 [25] and others do not fit our problem
since they do not include the ncct images.",
1383,Intraoperative CT Augmentation for Needle-Based Liver Interventions,"being a commonly used metric for
segmentation problems, dice aligns the nature of our problem as well as the
clinical impact of our solution.",
1384,Intraoperative CT Augmentation for Needle-Based Liver Interventions,the problem that we address can be seen from different angles.,
1385,Optical Coherence Elastography Needle for Biomechanical Characterization of Deep Tissue,none,
1386,Pelvic Fracture Segmentation Using a Multi-scale Distance-Weighted Neural Network,"in fracnet, rib fracture detection was formulated as a
segmentation problem, but with a resultant dice of 71.5%, it merely outlined the
fracture site coarsely without delineating the fracture surface [7].",
1387,Pelvic Fracture Segmentation Using a Multi-scale Distance-Weighted Neural Network,"learning-based methods that directly deal with fracture segmentation have rarely
been studied.fracture segmentation is still a challenging task for the
learning-based method because (1) compared to the more common organ/tumor
segmentation tasks where the model can implicitly learn the shape prior of an
object, it is difficult to learn the shape information of a bone fragment due to
the large variations in fracture types and shapes [10]; (2) the fracture surface
itself can take various forms including large space (fragments isolated and
moved), small gap (fragments isolated but not moved), crease (fragments not
completely isolated), compression (fragments collided), and their combinations,
resulting in quite different image intensity profiles around the fracture site;
and (3) the variable number of bone fragments in pelvic fracture makes it
difficult to prescribe a consistent labeling strategy that applies to every type
and case.this paper proposes a deep learning-based method to segment pelvic
fracture fragments from preoperative ct images automatically.",
1388,Pelvic Fracture Segmentation Using a Multi-scale Distance-Weighted Neural Network,"these data is collected from 100 patients (aged 18-74 years,
41 females) who were to undergo pelvic reduction surgery at beijing jishuitan
hospital between 2018 and 2022, under irb approval (202009-04).",
1389,Pelvic Fracture Segmentation Using a Multi-scale Distance-Weighted Neural Network,"the deep
supervision and smooth transition strategies stabilized the training, and
achieved the overall best results, with balanced local and global
performance.the average inference time for the fracture segmentation network was
12 s.",
1390,Towards Multi-modal Anatomical Landmark Detection for Ultrasound-Guided Brain Tumor Resection with Contrastive Learning,"to address these unique challenges, we
proposed a new contrastive learning (cl) framework to detect matching landmarks
in intra-operative us with those from mri as references.",
1391,Towards Multi-modal Anatomical Landmark Detection for Ultrasound-Guided Brain Tumor Resection with Contrastive Learning,"in contrast, our described application is more challenging due to the 3d nature,
difficulty in inter-modal feature learning, weaker anatomical contrast (i.e.,
mri vs us), and variable landmark locations.",
1392,Towards Multi-modal Anatomical Landmark Detection for Ultrasound-Guided Brain Tumor Resection with Contrastive Learning,"to date, cl has not been explored in multi-modal landmark detection, a unique
problem in clinical applications.",
1393,Towards Multi-modal Anatomical Landmark Detection for Ultrasound-Guided Brain Tumor Resection with Contrastive Learning,"this dataset is a deep-learning-ready version of the original resect database,
and was released as part of the 2020 learn2reg challenge [24].",
1394,Towards Multi-modal Anatomical Landmark Detection for Ultrasound-Guided Brain Tumor Resection with Contrastive Learning,"inter-modal anatomical landmark localization is still a difficult task,
especially for the described application, where landmarks have no consistent
spatial arrangement across different cases and image features in us are rough.",
1395,Towards Multi-modal Anatomical Landmark Detection for Ultrasound-Guided Brain Tumor Resection with Contrastive Learning,we tackled the challenge with the cl framework for the first time.,
1396,Towards Multi-modal Anatomical Landmark Detection for Ultrasound-Guided Brain Tumor Resection with Contrastive Learning,"as a baseline
comparison, we employed the sift algorithm, which has demonstrated excellent
performance in a large variety of computer vision problems for keypoint
matching.",
1397,Deep Reinforcement Learning Based System for Intraoperative Hyperspectral Video Autofocusing,"this exacerbates the focusing issues, making
current real-time handheld hsi imaging systems particularly challenging to
focus, posing significant usability issues.",
1398,Deep Reinforcement Learning Based System for Intraoperative Hyperspectral Video Autofocusing,"figure 1 highlights the limited
focal depth of our system, and shows a typical target that the surgeon must
manually bring into focus during surgery.the issue of reduced focal depth in
real-time hsi systems could be mitigated by the introduction of a video
autofocus system.",
1399,Deep Reinforcement Learning Based System for Intraoperative Hyperspectral Video Autofocusing,"we
randomise the order of the focal powers to reduce systematic bias caused by the
response of the liquid lens.",
1400,Deep Reinforcement Learning Based System for Intraoperative Hyperspectral Video Autofocusing,"while regression based approcahes may work,
reinforcement learning provides a natural framework for this problem by allowing
the policy to model the trade-off between maximisation and exploration.",
1401,Surgical Video Captioning with Mutual-Modal Concept Alignment,"due to the variability of lesions
and surgical operations, surgical videos contain complex visual contents, and
thus it is difficult to directly learn the mapping from the visual input to the
text output.",
1402,Surgical Video Captioning with Mutual-Modal Concept Alignment,"these surgical videos are recorded at the
prince of wales hospital, chinese university of hong kong, where surgeons remove
pituitary tumors through the endonasal corridor to the skull base.",
1403,Imitation Learning from Expert Video Data for Dissection Trajectory Prediction in Endoscopic Surgical Procedure,"one challenge arises from the inherent uncertainty of future
trajectories.",
1404,Imitation Learning from Expert Video Data for Dissection Trajectory Prediction in Endoscopic Surgical Procedure,"while advanced probabilistic models are employed to capture the complexity and
variability of dissection trajectories [14,19,25], how to ensure reliable
predictions across various surgical scenes still remains a great challenge.",
1405,Imitation Learning from Expert Video Data for Dissection Trajectory Prediction in Endoscopic Surgical Procedure,"to
overcome these issues, implicit models are emerging for policy learning,
inspiring us to rely on implicit behavior cloning (ibc) [5], which can learn
robust representations by capturing the shared features of both visual inputs
and trajectory predictions with a unified implicit function, yielding superior
expressivity and visual generalizability.",
1406,Imitation Learning from Expert Video Data for Dissection Trajectory Prediction in Endoscopic Surgical Procedure,"in our approach, we formulate the dissection trajectory prediction to an
imitation learning from expert demonstrations problem, which defines a markov
decision process (mdp) m = (s, a, t , d), comprising of state space s, action
set a, state transition distribution t , and expert demonstrations d.",
1407,Imitation Learning from Expert Video Data for Dissection Trajectory Prediction in Endoscopic Surgical Procedure,"the optimal
action is derived from the policy distribution conditioned on the state s, and p
θ (s, a) represents the joint state-action distribution.to learn the implicit
policy from the demonstrations, we adopt the behavior cloning objective which is
to essentially minimize the kullback-leibler (kl) divergence between the
learning policy π θ (a|s) and the demonstration distribution d, also equivalent
to maximize the expected log-likelihood of the joint state-action distribution,
as shown:(in this regard, the imitation of surgical dissection decision-making
is converted to a distribution approximation problem.",
1408,Imitation Learning from Expert Video Data for Dissection Trajectory Prediction in Endoscopic Surgical Procedure,"using the
evidence lower bound (elbo) as the proxy, the likelihood maximization can be
simplified to a noise prediction problem, more details can be referred to [10].",
1409,Imitation Learning from Expert Video Data for Dissection Trajectory Prediction in Endoscopic Surgical Procedure,"we evaluated the proposed approach on a dataset assembled from 22
videos of esd surgery cases, which are collected from the endoscopy centre of
the prince of wales hospital in hong kong.",
1410,Regularized Kelvinlet Functions to Model Linear Elasticity for Image-to-Physical Registration of the Breast,"determining
correspondences between imaging space and geometric data is required for
image-to-physical registration, but it is often an inexact and ill-posed
problem.",
1411,Regularized Kelvinlet Functions to Model Linear Elasticity for Image-to-Physical Registration of the Breast,"regularized kelvinlet functions are analytical solutions to the equations for
linear elasticity that we superpose to compute a nonrigid deformation field
nearly instantaneously [15].we utilize ""grab"" and ""twist"" regularized kelvinlet
functions with a linearized iterative reconstruction approach (adapted from
[12]) that is well-suited for sparse data registration problems.",
1412,Regularized Kelvinlet Functions to Model Linear Elasticity for Image-to-Physical Registration of the Breast,"( 3) becomes numerically problematic
in discretized problems because the displacement and displacement gradient
become indefinite as x approaches x 0 .to address numerical singularity,
regularization is incorporated with a new forcing function eq.",
1413,Regularized Kelvinlet Functions to Model Linear Elasticity for Image-to-Physical Registration of the Breast,"this approach may not be
well suited for problems where geometry has significant influence.",
1414,Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"we address the important problem of intraoperative patient-to-image registration
in a new way by relying on preoperative data to synthesize plausible
transformations and appearances that are expected to be found intraoperatively.",
1415,Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"indeed, the extent of tumor removal is highly
correlated with patients' chances of survival and complete resection must be
balanced against the risk of causing new neurological deficits [5] making
accurate intraoperative registration a critical component of
neuronavigation.most existing techniques perform patient-to-image registration
using intraoperative mri [11], cbct [19] or ultrasound [9,17,20].",
1416,Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"a model-based inverse minimization problem is solved by
estimating the model's parameters from a set of pre-computed transformations.",
1417,Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"1, we formulate the
problem as a camera pose estimation problem that finds the optimal 3d pose
minimizing the dissimilarity between the intraoperative 2d image and its
pre-generated expected appearance.",
1418,Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"assuming a set of 3d points u = {u j ∈ r 3 } ⊂ m and a set of 2d points in the
image v = {v i ∈ r 2 } ⊂ i, solving for this registration problem can be
formalized as finding the 6-dof camera pose that minimizes the reprojection
error:where r ∈ so(3) and t ∈ r 3 represent a 3d rotation and 3d translation,
respectively, and a is the camera intrinsic matrix composed of the focal length
and the principal points (center of the image) while {c i } i is a
correspondence map and is built so that if a 2d point v i corresponds to a 3d
point u j where c i = j for each point of the two sets.",
1419,Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"we alleviate these issues by
directly minimizing the dissimilarity between the image i and its expected
appearance synthesized from m.by defining a synthesize function s θ that
synthesizes a new image i given a projection of a 3d surface mesh for different
camera poses, i.e.",
1420,Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"i = s θ (a[r|t], m), the optimization problem above can be
rewritten as:argminthis new formulation is correspondence-free, meaning that it
alleviates the requirement of the explicit matching between u and v.",
1421,Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"we kept the size of the training set constant to not introduce size
biases.",
1422,Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"furthermore, from a robustness point of view, models trained with
these loss functions have been shown to be more prone to generalization issues.",
1423,Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"we employed the same u-net [20] architecture for all trained segmentation
models, with the same training parameters but two different loss functions, to
allow for a fair comparison.",
1424,Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"we
also remark that the range of hd values is in range with values reported by
models trained using much more training data (see [1]), alluding to the
possibility that the problem of robustness might not be directly solvable with
more data.",
1425,FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"one significant challenge in developing a flim-based
classifier to detect tumor in the surgical cavity is the presence of highly
imbalanced labels.surgeons aim to perform an en bloc resection, removing the
entire tumor and a margin of healthy tissue around it to ensure complete
excision.",
1426,FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"to address the technical challenge of highly imbalanced label distribution and
the need for intraoperative real-time cavity imaging, we developed an
intraoperative flim guidance model to identify residual tumors by classifying
residual cancer as anomalies.",
1427,FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"ν denote a
penalty factor on these soft constraints, and b is the biases.",
1428,FocalErrorNet: Uncertainty-Aware Focal Modulation Network for Inter-modal Registration Error Estimation in Ultrasound-Guided Neurosurgery,"however, despite these challenges, we saw an acceptable outcome from
focaler-rornet (absolute error = 1.28 mm or ∼1 voxel in clinical mris).",
1429,FocalErrorNet: Uncertainty-Aware Focal Modulation Network for Inter-modal Registration Error Estimation in Ultrasound-Guided Neurosurgery,"multi-modal registration quality evaluation poses
major challenges due to three main factors.",
1430,FocalErrorNet: Uncertainty-Aware Focal Modulation Network for Inter-modal Registration Error Estimation in Ultrasound-Guided Neurosurgery,"second, unlike segmentation or classification, the ground truths of
registration errors are difficult to obtain.",
1431,FocalErrorNet: Uncertainty-Aware Focal Modulation Network for Inter-modal Registration Error Estimation in Ultrasound-Guided Neurosurgery,"to tackle these challenges, we employed 3d focal modulation with
depth-wise convolution to encode contextual information for the image pair.",
1432,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"cancer remains a significant public health challenge worldwide, with a new
diagnosis occurring every two minutes in the uk (cancer research uk 1 ).",
1433,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"however, the use of this probe
presents a visualization challenge as the probe is non-imaging and is air-gapped
from the tissue, making it challenging for the surgeon to locate the
probe-sensing area on the tissue surface.it is crucial to accurately determine
the sensing area, with positive signal potentially indicating cancer or affected
lymph nodes.",
1434,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"similarly, it is also
challenging to acquire the probe pose during the surgery.problem redefinition.",
1435,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"with this
setup, we aim to transform the sensing area localization problem from a
geometrical issue to a high-level content inference problem in 2d.",
1436,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"laparoscopic images play an important role in computer-assisted surgery and have
been used in several problems such as object detection [9], image segmentation
[23], depth estimation [20] or 3d reconstruction [13].",
1437,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"however, acquiring per-pixel ground truth depth
data is challenging, especially for laparoscopic images, which makes it
difficult for large-scale supervised training [8].laparoscopic segmentation is
another important task in computer-assisted surgery as it allows for accurate
and efficient identification of instrument position, anatomical structures, and
pathological tissue.",
1438,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"hence, stereo image data was also adopted in this paper.if the
problem of inferring the intersection point is treated as a geometric problem,
both data collection and intra-operative registration would be difficult, which
inspired us to approach this problem differently.",
1439,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"to validate our proposed solution for the newly formulated problem, we acquired
and publicly released two new datasets.",
1440,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"since it is
important to report errors in 3d and in millimeters, we recorded another dataset
similar to jerry but also including ground truth depth map for all frames by
using structured-lighting system [8]-namely the coffbee dataset.these datasets
have multiple uses such as:-intersection point detection: detecting intersection
points is an important problem that can bring accurate surgical cancer
visualization.",
1441,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"we believe this is an under-investigated problem in surgical
vision.",
1442,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"the problem of detecting the intersection point is trivial when the laser is on
and can be solved by training a deep segmentation network.",
1443,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"however, marker-based tracking and pose
estimation methods have sterilization implications for the instrument, and the
sfm method requires the surgeon to constantly move the laparoscope, reducing the
practicality of these methods for surgery.in this work, we propose a simple, yet
effective regression approach to address this problem.",
1444,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"we utilized different deep segmentation networks as a first attempt to address
our problem [10,18].",
1445,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,problem formulation.,
1446,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"in this work, a new framework for using a laparoscopic drop-in gamma detector in
manual or robotic-assisted minimally invasive cancer surgery was presented,
where a laser module mock probe was utilized to provide training guidance and
the problem of detecting the probe axis-tissue intersection point was
transformed to laser point position inference.",
1447,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"we believe that our problem
reformulation and dataset release, together with the initial experimental
results, will establish a new benchmark for the surgical vision community.",
1448,A Novel Video-CTU Registration Method with Structural Point Similarity for FURS Navigation,"to this end, ureteroscope tracking
and navigation is increasingly developed as a promising tool to solve these
issues.many researchers have developed various methods to boost endoscopic
navigation.",
1449,A Novel Video-CTU Registration Method with Structural Point Similarity for FURS Navigation,"[14] employed
electromagnetic sensors to estimate the ureteroscope shape for
navigation.although these methods mentioned above work well, ureteroscopic
navigation is still a challenging problem.",
1450,A Novel Video-CTU Registration Method with Structural Point Similarity for FURS Navigation,"on the other hand, the complex internal structures such as calyx,
papilla, and pyramids of the kidneys are difficult to be observed in ct images.",
1451,A Novel Video-CTU Registration Method with Structural Point Similarity for FURS Navigation,"these issues introduce a difficulty in directly aligning ureteroscopic video
sequences to ct images, leading to a challenge of image-based continuous
ureteroscopic navigation.this work aims to explore an accurate and robust
vision-based navigation method for furs procedures without using any external
positional sensors.",
1452,A Novel Video-CTU Registration Method with Structural Point Similarity for FURS Navigation,"to deal with these issues, we use the segmented stones as
a mask to remove these regions with wrong depth.",
1453,Cascade Transformer Encoded Boundary-Aware Multibranch Fusion Networks for Real-Time and Accurate Colonoscopic Lesion Segmentation,"to address these issues
mentioned above, we explore a new deep learning architecture called cascade
transformer encoded boundary-aware multibranch fusion (ctbmf) networks with
cascade transformers and multibranch fusion for polyp and adenoma segmentation
in colonoscopic white-light and narrow-band video images.",
1454,Unified Brain MR-Ultrasound Synthesis Using Multi-modal Hierarchical Representations,"conversely, ius is an affordable tool but has been perceived as difficult to
read compared to imri [5].",
1455,Unified Brain MR-Ultrasound Synthesis Using Multi-modal Hierarchical Representations,"however, a key limitation of these techniques is that they must be trained
for each subset of available images.to tackle this challenge, unified approaches
have been proposed.",
1456,Unified Brain MR-Ultrasound Synthesis Using Multi-modal Hierarchical Representations,"finally, experiments
on the challenging problem of ius and mr synthesis demonstrate the effectiveness
of the proposed approach, enabling the synthesis of high-quality images while
establishing a mathematically grounded formulation for unified image synthesis
and outperforming non-unified gan-based approaches and the state-of-the-art
method for unified multi-modal medical image synthesis.",
1457,Unified Brain MR-Ultrasound Synthesis Using Multi-modal Hierarchical Representations,"mhvae's design focuses on
tackling three challenges: (i) improving expressiveness of vaes and mvaes using
a hierarchical latent representation; (ii) parametrizing the variational
posterior to handle missing modalities; (iii) synthesizing realistic images.",
1458,Unified Brain MR-Ultrasound Synthesis Using Multi-modal Hierarchical Representations,"in this section, we report experiments conducted on the challenging problem of
mr and ius image synthesis.data.",
1459,Unified Brain MR-Ultrasound Synthesis Using Multi-modal Hierarchical Representations,"we evaluated our method on a dataset of 66
consecutive adult patients with brain gliomas who were surgically treated at the
brigham and women's hospital, boston usa, where both pre-operative 3d t2-space
and pre-dural opening intraoperative us (ius) reconstructed from a tracked
handheld 2d probe were acquired.",
1460,Unified Brain MR-Ultrasound Synthesis Using Multi-modal Hierarchical Representations,"since image delineation is much more efficient on
mri than on us, annotations performed on mri could be used to train a
segmentation network on pseudo-ius data, as performed by the top-performing
teams in the crossmoda challenge [9].",
1461,Unified Brain MR-Ultrasound Synthesis Using Multi-modal Hierarchical Representations,"by approximating the true posterior using a
combination of unimodal approximates and optimizing the elbo with multi-modal
and uni-modal examples, mhvae demonstrated state-of-the-art performance on the
challenging problem of ius and mr synthesis.",
1462,StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"however, the registration process is substantially difficult
due to the visual characteristics, resolution scale, and dimensional differences
between the two modalities.",
1463,StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"on the other hand, successful dl
methods have been proposed to address the 2d/3d mapping problem for other
medical modalities [6,8,16,21].",
1464,StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"to our knowledge, no previous study proposed 2d/3d registration
combined with structure awareness.",
1465,StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"the modality transfer is a 2d image-to-image
translation problem defined as follows: given a sequence of n slices h = {h 1 ,
..., h n } and a volume considered as a full stack of m axial slices ct = {ct 1
, ..., ct m }, we build a cyclegan with two generators and two discriminators g
h→ct , g ct →h , d h and d ct .",
1466,StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"we then introduce
a sequence alignment problem, the objective being to update the slice sequence z
of sct by mapping it to a corresponding sequence j of 2d images from ct .",
1467,StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"we defined the number of iterations as a hyperparameter to reach a good
balance between computational time and similarity maximization.",
1468,StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"two expert radiation oncologists on ct delineated both the thyroid and
cricoid cartilages for structure awareness and the gross tumor volume (gtv) for
clinical validation, while two expert pathologists did the same on wsis.",
1469,StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"even for
some severe difficulties inherent to the histological process like a cut larynx,
the model successfully maps both cartilage and soft tissue without completely
tearing the ct image thanks to regularization (c-d-e).",
1470,StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"we also compared against
msv-regsynnet on its own validation dataset for generalization assessment: we
yielded comparable results for the first cohort and significantly better ones
for the second, which proves that structuregnet behaves well on other modalities
and that the structure awareness is an essential asset for better registration,
as pelvis is a location where organs are moving.",
1471,X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"this can improve image-guided therapies and preoperative planning,
especially for radiotherapy, which requires precise patient positioning with
minimal radiation exposure.however, this task is an ill-posed inverse problem:
x-ray measurements are the result of attenuation integration across the body,
which makes them very fig.",
1472,X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"with very few projections, it is very difficult to disentangle the
structures for even coarse 3d estimation.",
1473,X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"in this section, we formalize the problem, describe how we learn the
manifold, and detail how we optimize the latent vectors.",
1474,X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"this is a hard ill-posed problem, and to solve it, we need prior
knowledge about the possible volumes.",
1475,X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"then, we describe how
exactly we use this generative model for regularization term r(v) and how this
changes our optimization problem.",
1476,X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"the mapping network learns to disentangle the initial latent space
relatively to semantic features which is crucial for the inverse problem.",
1477,X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"we model a realistic x-ray attenuation as a ray tracing projection
using material and spectrum awareness:with μ(m, e) the linear attenuation
coefficient of material m at energy state e that is known [11], t m the material
thickness, i 0 the intensity of the source x-ray.for materials, we consider the
bones and tissues that we separate by threshold on electron density.",
1478,X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"by grid search on the
validation set, we selected the best weights that well balance between structure
and fine-grained details, λ 2 = 10, λ p = 0.1, λ w = 0.1, λ c = 0.05, λ n = 10.",
1479,X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"without a previous ct volume, nerp lacks the
necessary prior to accurately solve the ill-posed problem.",
1480,X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"however, relying solely on projection consistency is
inadequate for this ill-posed problem.",
1481,Structure-Preserving Synthesis: MaskGAN for Unpaired MR-CT Translation,"given these issues, there are clear
advantages for synthesizing anatomically accurate ct data from mri.most
synthesis methods adopt supervised learning paradigms and train generative
models to synthesize ct [1][2][3]6,17].",
1482,Structure-Preserving Synthesis: MaskGAN for Unpaired MR-CT Translation,"this problem is particularly relevant in brain scanning, where both the
pixel-wise correlation and noise statistics in mr and ct images are different,
as a direct consequence of the signal acquisition technique.",
1483,Structure-Preserving Synthesis: MaskGAN for Unpaired MR-CT Translation,"we targeted the age group from 6-24 months since
pediatric patients are more susceptible to ionizing radiation and experience a
greater cancer risk (up to 24% increase) from radiation exposure [7].",
1484,Structure-Preserving Synthesis: MaskGAN for Unpaired MR-CT Translation,"furthermore, surgery for craniosynostosis, a birth defect in which the skull
bones fuse too early, typically occurs during this age [5,16].",
1485,Structure-Preserving Synthesis: MaskGAN for Unpaired MR-CT Translation,"for a fair comparison, we implement shape-cyclegan using
our extracted coarse masks based on the authors' official code.",
1486,FreeSeed: Frequency-Band-Aware and Self-guided Network for Sparse-View CT Reconstruction,"lowering the
dose of ct scans has been widely adopted in clinical practice to address this
issue, following the ""as low as reasonably achievable"" (alara) principle in the
medical community [9].",
1487,FreeSeed: Frequency-Band-Aware and Self-guided Network for Sparse-View CT Reconstruction,"inspired
by this, we propose a frequency-band-aware artifact modeling network (freenet)
that learns the artifact-concentrated frequency components to remove the
artifacts efficiently using learnable band-pass attention maps in the fourier
domain.while fourier domain band-pass maps help capture the pattern of the
artifacts, restoring the image detail contaminated by strong artifacts may still
be difficult due to the entanglement of artifacts and details in the residues.",
1488,FreeSeed: Frequency-Band-Aware and Self-guided Network for Sparse-View CT Reconstruction,"we conduct experiments on the dataset of ""the 2016 nih-aapm mayo clinic low dose
ct grand challenge"" [8], which contains 5,936 ct slices in 1 mm image thickness
from 10 anonymous patients, where a total of 5,410 slices from 9 patients,
resized to 256 × 256 resolution, are randomly selected for training and the 526
slices from the remaining one patient for testing without patient overlap.",
1489,Co-learning Semantic-Aware Unsupervised Segmentation for Pathological Image Registration,"direct registration
of pathology images without taking into account the impact of focal tissue can
result in missed pixel-level correspondence and large registration errors.a
variety of approaches have been proposed to handle the noncorrespondence problem
in medical image registration.",
1490,Co-learning Semantic-Aware Unsupervised Segmentation for Pathological Image Registration,"although these approaches partially handle the issue
of non-correspondence in the registration, they still have some serious
shortcomings.",
1491,Co-learning Semantic-Aware Unsupervised Segmentation for Pathological Image Registration,"the non-correspondence
detection approach, which typically relies on a sophisticated designed loss
function, is very sensitive to the dataset [1] and difficult to find a set of
unified parameters.therefore, to effectively address the non-correspondence
problem in registering pathology images, it is necessary to incorporate both a
data-independent segmentation module and a modality-adaptive inpainting module
into the registration pipeline.",
1492,Co-learning Semantic-Aware Unsupervised Segmentation for Pathological Image Registration,"in
this paper, we address the challenge of large alignment errors due to the loss
of spatial correspondence in processing pathological images.",
1493,Co-learning Semantic-Aware Unsupervised Segmentation for Pathological Image Registration,"to overcome this
challenge, we propose girnet, a tri-net collaborative learning framework that
simultaneously updates the segmentation, inpainting, and registration networks.",
1494,Co-learning Semantic-Aware Unsupervised Segmentation for Pathological Image Registration,"the most critical problem in pathological image registration is identifying and
dealing with the lesion area.",
1495,Co-learning Semantic-Aware Unsupervised Segmentation for Pathological Image Registration,"furthermore, l sym denotes the registration loss of
symnet [14], which aims to balance the losses of orientation consistency,
regularization and magnitude.segnet.",
1496,Co-learning Semantic-Aware Unsupervised Segmentation for Pathological Image Registration,"dirac jointly
estimates regions with absent correspondence and bidirectional deformation
fields and ranked first in the bratsreg2022 challenge.atlas-based registration.",
1497,Fast Reconstruction for Deep Learning PET Head Motion Correction,"however, vicra is not routinely used in the clinic, as setup and
calibration of the tracking device can be complicated and attaching markers to
each patient increases the logistical burden of the scan.",
1498,Fast Reconstruction for Deep Learning PET Head Motion Correction,"to overcome the challenges when using low-quality, noisy pci for motion
correction, ultra-fast reconstruction techniques [14] that generate one-second
dynamic fast reconstruction images (fris), can be utilized as input for deep
learning motion correction methods.",
1499,Fast Reconstruction for Deep Learning PET Head Motion Correction,"to take this problem into account, we perform
data augmentation by simulating an additional relative motion that can be
concatenated with the true relative motion.",
1500,Revealing Anatomical Structures in PET to Generate CT for Attenuation Correction,"since pseudo ct is convenient to be integrated into conventional ac processes,
generating pseudo ct images is feasible in clinics for ac.the pseudo ct images
should satisfy two-fold requests.",
1501,Revealing Anatomical Structures in PET to Generate CT for Attenuation Correction,"for a fair
comparison, we implemented these methods by ourselves in a tensorflow platform
with an nvidia 3090 gpu.",
1502,Revealing Anatomical Structures in PET to Generate CT for Attenuation Correction,"such
inconsistent metrics suggest that the global intensity similarity may have a
competing relationship with anatomical consistency in the learning procedure,
thus it is not advisable to balance them in a single network.",
1503,An Explainable Deep Framework: Towards Task-Specific Fusion for Multi-to-One MRI Synthesis,"however, some acquired sequences are unusable or missing in clinical
settings due to incorrect machine settings, imaging artifacts, high scanning
costs, time constraints, contrast agents allergies, and different acquisition
protocols between hospitals [5].",
1504,An Explainable Deep Framework: Towards Task-Specific Fusion for Multi-to-One MRI Synthesis,"unlike these one-to-one approaches, mri
synthesis faces the challenge of fusing complementary information from multiple
input sequences.",
1505,An Explainable Deep Framework: Towards Task-Specific Fusion for Multi-to-One MRI Synthesis,"the model architectures of these methods are not
flexible and difficult to adapt to various sequence combinations.",
1506,An Explainable Deep Framework: Towards Task-Specific Fusion for Multi-to-One MRI Synthesis,"to learn the weight automatically,
we use a trainable fully connected (fc) layer to predict the initial weight ω 0
∈ r n from c.where w and b are weights and bias for the fc layer, = 10 -5 to
avoid dividing 0 in the following equation.",
1507,Geometric Ultrasound Localization Microscopy,"our work challenges the conventional assumption
that beamforming is the ideal processing step for ulm and presents an
alternative approach based on geometric reconstruction from time-of-arrival
(toa) information.the discovery of ulm has recently surpassed the
diffraction-limited spatial resolution and enabled highly detailed visualization
of the vascularity [8].",
1508,Geometric Ultrasound Localization Microscopy,"in conclusion,
we challenge the conventional wisdom that beamforming is necessary for ulm and
propose a novel approach that entirely relies on tdoa information for mb
localization.",
1509,Geometric Ultrasound Localization Microscopy,"also, the
jaccard index reflects an outperforming balance of true positive and false
negative mb detections by our approach.",
1510,Reflectance Mode Fluorescence Optical Tomography with Consumer-Grade Cameras,"the primary cause of this
impasse is the ill-posedness of the mathematical inverse problem underlying the
3d reconstruction of the target in tissue from boundary measurements.the prime
motivation of our work is to enable an efficient 3d tumor shape reconstruction
for fgs in an operating room environment, where we do not have full control of
the ambient light and we cannot rely on sophisticated time or frequency domain
imaging instrumentation and setup.",
1511,Reflectance Mode Fluorescence Optical Tomography with Consumer-Grade Cameras,"in these situations, one has to use clinical
cameras producing rapid continuous wave (cw) fluorescence boundary measurements
[19] in reflectance mode (i.e., the transmission of the light through the domain
is not measured), and with low signal-to-noise ratio which further exacerbates
the ill-posedness of fdot problem.",
1512,Reflectance Mode Fluorescence Optical Tomography with Consumer-Grade Cameras,"the standard approach for solving fdot
problem with cw measurements is based on born approximation which works well in
the case of a small compared to the computational domain target and a very large
number of reflectance-transmission type measurements made by ""slow in
acquisition"" light sources and detector arrays of highly sensitive cooled ccd
cameras or photomultiplier tube arrays collecting both reflected and transmitted
light [18].",
1513,Reflectance Mode Fluorescence Optical Tomography with Consumer-Grade Cameras,"for such provision we need to
solve the following fdot problem: estimate the spatial shape χ of the icg tagged
tumor target (the cube in green) within the tissue domain ω ∈ r 3 (the area in
grey) from measurements y.",
1514,Reflectance Mode Fluorescence Optical Tomography with Consumer-Grade Cameras,"measurements are obtained by illuminating the tissue
domain with nir light at icg peak excitation wavelength via the expanded beam
from endoscope fiber bundle, and then measuring the light emitted by the tumor
like target diffusing to the top face of the phantom surface ∂ω obs , by the
fiber bundle with suitable emission filter which is coupled to a camera at the
backend.in this section we briefly describe the mathematical formulation of the
fdot problem and introduce the iftr scheme for solving it.forward and inverse
problems.",
1515,Reflectance Mode Fluorescence Optical Tomography with Consumer-Grade Cameras,"finally, vector of
measurements y ∈ r k is related to the emission fluence φ m as followshere t ∈ r
k×n is a binary matrix that selects components of φ m corresponding to the
observed grid nodes and k is a number of observed nodes.in the following if
target indicator χ is given then the system (1) is referred to as the forward
fdot problem to compute unknown excitation and emission fluence φ x , φ m .",
1516,Reflectance Mode Fluorescence Optical Tomography with Consumer-Grade Cameras,"if
vector χ is unknown but measurements of emission fluence are present then the
system (1)-( 2) is referred to as the fdot inverse problem.",
1517,Reflectance Mode Fluorescence Optical Tomography with Consumer-Grade Cameras,solves the inverse fdot problem.,
1518,Reflectance Mode Fluorescence Optical Tomography with Consumer-Grade Cameras,"to reduce the ill-posedness of the
inverse problem ( 1)-( 2) we introduce several regularization schemes.",
1519,Reflectance Mode Fluorescence Optical Tomography with Consumer-Grade Cameras,"the third regularization
aims to reduce a null space of the inverse problem in the boundary layer of a
thickness , reflecting the assumption that the target is under the surface.",
1520,Reflectance Mode Fluorescence Optical Tomography with Consumer-Grade Cameras,"in this subsection
we present an incremental fluorescent target reconstruction (iftr) scheme
solving the inverse problem (1)- (2).",
1521,Reflectance Mode Fluorescence Optical Tomography with Consumer-Grade Cameras,"noting that the nonlinearity of the
inverse problem stems from the fact that χ φ x is a bi-linear vector function
the iftr scheme employs the following splitting method: (i) for n = 0, 1, .",
1522,Reflectance Mode Fluorescence Optical Tomography with Consumer-Grade Cameras,"fix χ n and compute φ nx as the unique solution of linear excitation
equation:then (ii) fix the obtained φ n x and compute χ n+1 as the unique
solution of one of the 3 convex optimization problems: m to find χ n+1 :variant
ii.",
1523,Reflectance Mode Fluorescence Optical Tomography with Consumer-Grade Cameras,"this variant uses the emission equation as a term of the
loss function:we note that all the three variants depend on parameter p = 1, 2
which defines the type of optimization problem that should be solved: i) if p =
1 we get conic optimization problems of the loss function in the form • 2 which
would be treated as conic constraints); ii) if p = 2 we get quadratic
optimization problems.to get a good initial guess for χ 0 we borrow from the
born approximation which suggests that excitation field φ x can be approximated
by the background excitation obtained by solving excitation equation with no
icg, i.e., χ 0 = 0.",
1524,Reflectance Mode Fluorescence Optical Tomography with Consumer-Grade Cameras,"the performed experiments reveal that it is difficult to
pick a single winning configuration of iftr scheme but there are several
considerations: i) variant i provides the lowest errors but is the slowest
variant with mosek solver has been consistently faster than osqp; ii) variant ii
is the fastest variant but it is more sensitive to the amount of measurement
compared to others; iii) variant iii is less sensitive to the amount of
measurements compared to variant ii has similar execution time but is less
accurate.we also note that iftr scheme is robust with respect to ptv
regularization parameter.",
1525,Reflectance Mode Fluorescence Optical Tomography with Consumer-Grade Cameras,in this work we proposed novel iftr scheme for solving fdot problem.,
1526,Reflectance Mode Fluorescence Optical Tomography with Consumer-Grade Cameras,"it performs
a splitting of the bi-linearity of the original non-convex problem into a
sequence of convex ones.",
1527,DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"essentially, it abstracts the
problem to the statistical concept of information theory and optimizes
image-wide alignment statistics.",
1528,DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"a prominent example is
the modality-independent neighbourhood descriptor (mind) [5], which is based on
image self-similarity and has with minor adaptations (denoted mind-ssc for
self-similarity context) also been applied to us problems [7].",
1529,DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"some of these methods involve the utilization of
convolutional neural networks (cnn) to extract segmentation volumes from the
source data, transforming the problem into the registration of label maps
[13,24].",
1530,DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"moreover, the paucity of precise and
unambiguous ground truth registration, particularly in abdominal mr-us
registration, exacerbates the overfitting problem, restricting generalization
even within the same modality and anatomy.",
1531,DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"we formulate image registration as an optimization problem of a similarity
metric s between the moving image m and the fixed image f with respect to the
parameters α of a spatial transformation t α : ω → ω.",
1532,DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"1) is
then approximated asthus converting the original problem into a registration of
pre-computed feature maps using a simple and differentiable dot product
similarity.",
1533,DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"our neural network is
trained using patches from the ""gold atlas -male pelvis -gentle radiotherapy""
[14] dataset, which is comprised of 18 patients each with a ct, mr t1, and mr t2
volumes.",
1534,DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"4.3) our method
obtains a significantly larger capture range, opening new possibilities for
tackling this challenging problem.",
1535,DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"in this experiment, we evaluate the performance of different methods for
estimating affine registration of the retrospective evaluation of cerebral
tumors (resect) miccai challenge dataset [23].",
1536,DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"our second application is the abdomen mr-ct task of the learn2reg challenge 2021
[8].",
1537,DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"furthermore, the evaluation speed of our objective function allows us to
exhaustively search the solution space, escaping local minima and converging to
the correct solution with pose and deformation parameters at once, in less than
two seconds.note that this registration problem is much more challenging than
the prior two due to difficult ultrasonic visibility in the abdomen, strong
deformations, and ambiguous matches of liver vasculature.",
1538,Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"however, when the dose is
low together with the issues like sparse-view or limited angles, it becomes
quite challenging to reconstruct high-quality ct images.",
1539,Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"the high-quality ct
images are important to improve the performance of diagnosis in clinic [27].",
1540,Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"the problem of ct reconstruction is to recover x r
from the received y.solving the inverse problem of ( 1) is often very
challenging if there is no any additional information.",
1541,Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"however, t is often ill-posed,
which means the inverse function t -1 does not exist and the inverse problem of
(1) may have multiple solutions.",
1542,Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"so we apply optical flow, though there exist several technical issues
waiting to solve for the design and implementation, to capture the local
coherence of adjacent ct images for reducing the artifacts in low-dose ct
reconstruction.",
1543,Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"first, our proposed approaches are evaluated on the ""mayo-clinic
low-dose ct grand challenge"" (mayo-clinic) dataset of lung ct images [19].the
dataset contains 2250 two dimensional slices from 9 patients for training, and
the remaining 128 slices from 1 patient are reserved for testing.",
1544,Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"the simulation process is
identical to that of mayo-clinic.",
1545,Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"to evaluate the stability and generalization of our model and the
baselines trained on mayo-clinic dataset, we also test them on the rider
dataset.",
1546,Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"due to the bias in the datasets
collected from different facilities, the performances of all the models are
declined to some extents.",
1547,Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"in future,
we will evaluate our network on real-world ct images from local hospital and use
the reconstructed images to support doctors for the diagnosis and recognition of
lung nodules.",
1548,Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"cone beam ct (cbct) is the most widely used imaging modality
for igrt.a major challenge especially for cbct imaging of the thorax and
upperabdomen is the respiratory motion that introduces blurring of the anatomy,
reducing the localization accuracy and the sharpness of the image.a technique
used to alleviate motion artifacts is respiratory correlated cbct (4dcbct) [16].",
1549,Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"given input-target pairs x, y ∈ r we can
define the regression problem in the one-dimensional setting as finding f * : r
→ r which satisfies the following:which can be minimized point-wise [3],
yielding:in noise2noise [5], input-target pairs are two samples of the same
image that only differ because of some independent mean-zero noise (x + δ 1 , x
+ δ 2 ) withthen f * will recover the input image without any noise:denoising
for tomography with noise2inverse.",
1550,Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"we can address this problem by carefully choosing subsets
of projections that result in respiratory-uncorrelated reconstructions.",
1551,Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"the second is
the supervised approach proposed by [6], where we replace the model with the
msd, for a fair comparison.",
1552,DULDA: Dual-Domain Unsupervised Learned Descent Algorithm for PET Image Reconstruction,"however,
pet images often suffer from a high level of noise due to several physical
degradation factors as well as the ill-conditioning of the pet reconstruction
problem.as a result, the quality of pet images can be compromised, leading to
difficulties in accurate diagnosis.",
1553,DULDA: Dual-Domain Unsupervised Learned Descent Algorithm for PET Image Reconstruction,"this challenge is further compounded by the high dose exposure
associated with pet imaging.",
1554,DULDA: Dual-Domain Unsupervised Learned Descent Algorithm for PET Image Reconstruction,"as a typical inverse problem, pet image reconstruction can be modeled in a
variational form and cast as an optimization task, as follows:where y is the
measured sinogram data, y is the mean of the measured sinogram.x is the pet
activity image to be reconstructed, l(y|x) is the poisson loglikelihood of
measured sinogram data.",
1555,DULDA: Dual-Domain Unsupervised Learned Descent Algorithm for PET Image Reconstruction,"a total of 5 realizations were
simulated and each was trained/tested independently for bias and variance
calculation [15].",
1556,DULDA: Dual-Domain Unsupervised Learned Descent Algorithm for PET Image Reconstruction,"the quantitative and bias-variance results
are shown in table 1.",
1557,DULDA: Dual-Domain Unsupervised Learned Descent Algorithm for PET Image Reconstruction,"both dip method and dulda
have a better crc and bias performance compared with mlem and em-tv.",
1558,Low-Dose CT Image Super-Resolution Network with Dual-Guidance Feature Distillation and Dual-Path Content Communication,"to balance the
high image quality and low radiation damage compared to normaldose ct (ndct),
numerous algorithms have been proposed for ldct superresolution [3,4].in the
past decades, image post-processing techniques attracted much attention from
researchers because they did not rely on the vendor-specific parameters [2] like
iterative reconstruction algorithms [1,23] and could be easily applied to
current ct workflows [29].",
1559,Low-Dose CT Image Super-Resolution Network with Dual-Guidance Feature Distillation and Dual-Path Content Communication,"(2) most of them
extracted the features with a fixed resolution, failing to effectively leverage
multi-scale features which are essential to image restoration task [27,32].(3)
they connected the sr task and the ldct denoising task stiffly, leading to
smooth texture, residual artifacts and unclear edges.to deal with those issues,
as shown in fig.",
1560,Low-Dose CT Image Super-Resolution Network with Dual-Guidance Feature Distillation and Dual-Path Content Communication,"to deal with this problem, we develop a dualpath architecture by
introducing the shared denoising head into sr task where the parameters of sr
heads and denoising heads in different paths are shared respectively.",
1561,Low-Dose CT Image Super-Resolution Network with Dual-Guidance Feature Distillation and Dual-Path Content Communication,"jdnsr blurs the issue structural information, e.g.",
1562,Low-Dose CT Image Super-Resolution Network with Dual-Guidance Feature Distillation and Dual-Path Content Communication,"2, that is, our method could
suppress more artifacts than other methods, especially at the edges of the
pancreas and the texture and structure of the issues with in the kidney.",
1563,Low-Dose CT Image Super-Resolution Network with Dual-Guidance Feature Distillation and Dual-Path Content Communication,"facing the existing problem
that reconstructed results suffer from residual artifacts, we design a
dualguidance feature distillation backbone which consists of dgfm and sab to
extract deep visual information.",
1564,Non-iterative Coarse-to-Fine Transformer Networks for Joint Affine and Deformable Image Registration,"traditional methods usually formulate medical image registration as a
time-consuming iterative optimization problem [3,4].",
1565,Non-iterative Coarse-to-Fine Transformer Networks for Joint Affine and Deformable Image Registration,"the φ is parameterized as a
displacement field, and we parametrized the image registration problem as a
function r θ (i f , i m ) = φ using nice-trans.",
1566,Trackerless Volume Reconstruction from Intraoperative Ultrasound Images,"despite the increasing use of ious in surgery, its integration into
laparoscopic workflows (i.e., laparoscopic intraoperative ultrasound) remains
challenging due to combined problems.performing ious during laparoscopic liver
surgery poses significant challenges, as laparoscopy has poor ergonomics and
narrow fields of view, and on the other hand, ious demands skills to manipulate
the probe and analyze images.",
1567,Trackerless Volume Reconstruction from Intraoperative Ultrasound Images,"motivated
by the weakness of the state-of-the-art methods when it comes to large
non-linear probe motions, and the difficulty of integrating imu sensors in the
case of minimally invasive procedures, we introduce a new method for pose
estimation and volume reconstruction in the context of minimally invasive
trackerless ultrasound imaging.",
1568,Trackerless Volume Reconstruction from Intraoperative Ultrasound Images,"such motion is predominant in
the context highlighted above and is the source of additional nonlinearity in
the pose estimation problem.",
1569,Trackerless Volume Reconstruction from Intraoperative Ultrasound Images,"first and end stages of the sequences were removed from
the six acquired sequences, as they were considered to be largely stationary,
and aiming to avoid training bias.",
1570,Trackerless Volume Reconstruction from Intraoperative Ultrasound Images,"due to the difficulty of including
an imu sensor in our ivus catheter, the results of both methods were reported
from the monet paper where the models have been trained on arm scans, see [15]
for more details.",
1571,Trackerless Volume Reconstruction from Intraoperative Ultrasound Images,"this remains a challenge
for the community even in the case of linear probe motions.",
1572,Trackerless Volume Reconstruction from Intraoperative Ultrasound Images,"our method was evaluated on ex vivo porcine data and
achieved translation and orientation errors of 0.449±0.189 mm and 1.3±1.5 •
respectively with a fair drift error.",
1573,CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,"[19] leveraged adversarial training to increase the step size of the inverse
diffusion process and further designed a cycle-consistent architecture for
unpaired mri translation.however, current dm-based methods focus on one-to-one
mri translation, promising to be improved by many-to-one methods, which requires
dedicated design to balance the multiple conditions introduced by multi-modal
mri.",
1574,CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,"-propose an auto-weight
adaptation to balance multi-conditions and maximise the chance of leveraging
relevant multi-modal information.",
1575,CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,"it is critical to balance multiple conditions, maximizing relevant information
and minimising redundant information.",
1576,CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,"the autoactivation is
governed by the learnable weight ν and bias o.",
1577,CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,"where is a small constant added
to the equation to avoid the issue of derivation at the zero point.",
1578,InverseSR: 3D Brain MRI Super-Resolution Using a Latent Diffusion Model,"while these methods have shown promise in mri sr, they have so far been
limited to 2d slices [18,25], rendering them unsuitable for 3d brain mris slice
imputation.in this study, we propose solving the mri sr problem by building
powerful, 3d-native image priors through a recently proposed hr image generative
model, the latent diffusion model (ldm) [21,22].",
1579,InverseSR: 3D Brain MRI Super-Resolution Using a Latent Diffusion Model,"we solve the inverse problem by
finding the optimal latent code z in the latent space of the pre-trained
generative model, which could restore a given lr mri i, using a known corruption
function f .",
1580,InverseSR: 3D Brain MRI Super-Resolution Using a Latent Diffusion Model,"in this study, we focus on slice imputation, yet our method could
be applied to other medical image sr problems by implementing different
corruption functions f .",
1581,InverseSR: 3D Brain MRI Super-Resolution Using a Latent Diffusion Model,"[14]
introduced a method to train a cnn for mri sr on any given combination of
contrasts, resolutions and orientations.solving inverse problems using
generative models.",
1582,InverseSR: 3D Brain MRI Super-Resolution Using a Latent Diffusion Model,"a common way to solve the inverse problem using an ldm is to
use the encoder e to first encode the given image x into the latent space z 0 =
e(x) [10,12,20], followed by ddim (denoising diffusion implicit models)
inversion [9,24] to encode z 0 into the noise latent code z t [20].",
1583,InverseSR: 3D Brain MRI Super-Resolution Using a Latent Diffusion Model,"more recent
works [7,10,13,17,25] have used diffusion models for inverse problems due to
their superior performance.",
1584,InverseSR: 3D Brain MRI Super-Resolution Using a Latent Diffusion Model,"this network ε θ is conditioned on four conditional variables c: age,
gender, ventricular volume and brain volume, which are all introduced by
cross-attention layers [22].",
1585,InverseSR: 3D Brain MRI Super-Resolution Using a Latent Diffusion Model,"gender is a binary variable, while the rest of the
covariates are scaled to [0, 1].",
1586,InverseSR: 3D Brain MRI Super-Resolution Using a Latent Diffusion Model,"unlike end-to-end supervised
approaches, which require retraining each time there is a distribution shift
over the input, our method is capable of being adapted to different settings of
mri sr problems at test time.",
1587,InverseSR: 3D Brain MRI Super-Resolution Using a Latent Diffusion Model,"experiments in this
paper focus on slice imputation, but our method could be adapted to other mri
under-sampling problems by implementing different corruption functions f .",
1588,Topology-Preserving Computed Tomography Super-Resolution Based on Dual-Stream Diffusion Model,"with the
advancement of artificial intelligence, super-resolution (sr) techniques based
on neural networks indicate new approaches to this problem.",
1589,Topology-Preserving Computed Tomography Super-Resolution Based on Dual-Stream Diffusion Model,"λ τ is the
self-regulating factor.when λ 1 is about the same with λ 2 , λ τ is closed to λ
1 ; and when λ 1 is much smaller to λ 2 , λ τ is closed to λ 2 , which can
achieve a balance between two conditions.",
1590,Topology-Preserving Computed Tomography Super-Resolution Based on Dual-Stream Diffusion Model,"here we used a parameter λ l1 to balance
these two losses.in the meantime, a structure-constraint loss is also necessary
to help the network achieve better performance in structure consistency.",
1591,Topology-Preserving Computed Tomography Super-Resolution Based on Dual-Stream Diffusion Model,"denoting the
structure-domain output as g struct dssp (y t ), the structure-constraint loss
can be presented ashowever, the image enhancement described above involves
overly complex calculations, making back-propagation difficult in the training
process.",
1592,Topology-Preserving Computed Tomography Super-Resolution Based on Dual-Stream Diffusion Model,"the problem of inconsistent structure is also
reflected in the value of vif and smse on both gan-based methods and sr3.lesion
detection and vessel segmentation on super-resolved ct.",
1593,Topology-Preserving Computed Tomography Super-Resolution Based on Dual-Stream Diffusion Model,"in this paper, we have established a dual-stream diffusion model framework to
address the problem of topology distortion and artifact introduction that
generally exists in the medical super-resolution results.",
1594,LightNeuS: Neural Surface Reconstruction in Endoscopy Using Illumination Decline,this is the problem we address here.,
1595,LightNeuS: Neural Surface Reconstruction in Endoscopy Using Illumination Decline,"unfortunately, this solves only half the problem because these
techniques provide very sparse reconstructions and going from there to dense
ones remains an open problem.",
1596,LightNeuS: Neural Surface Reconstruction in Endoscopy Using Illumination Decline,"and occlusions, specularities, varying albedos,
and specificities of endoscopic lighting make it a challenging one.to overcome
these difficulties, we rely on two properties of endoscopic images:-endoluminal
cavities such as the gastrointestinal tract, and in particular the human colon,
are watertight surfaces.",
1597,LightNeuS: Neural Surface Reconstruction in Endoscopy Using Illumination Decline,"together, these two
changes make the minimization problem better posed and the automatic depth
estimation more reliable.our results show that exploiting the illumination is
key to unlocking implicit neural surface reconstruction in endoscopy.",
