,title,extracted_keyword_sent
0,Anatomy-Driven Pathology Detection on Chest X-rays,none
1,Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET,none
2,AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor,none
3,Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,none
4,Unsupervised Discovery of 3D Hierarchical Structure with Generative Diffusion Features,none
5,S 2 ME: Spatial-Spectral Mutual Teaching and Ensemble Learning for Scribble-Supervised Polyp Segmentation,none
6,Tracking Adaptation to Improve SuperPoint for 3D Reconstruction in Endoscopy,none
7,Black-box Domain Adaptative Cell Segmentation via Multi-source Distillation,"accordingly, direct knowledge transfer
using the output of the source domain predictor may lead to feature bias in the
student model due to the unavoidable covariance [20] between the target and
source domains."
8,Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning,none
9,PET-Diffusion: Unsupervised PET Enhancement Based on the Latent Diffusion Model,"however, acquiring high-quality pet images requires
injecting a sufficient dose (standard dose) of radionuclides into the human
body, which poses unacceptable radiation hazards for pregnant women and infants
even following the as low as reasonably achievable (alara) principle [19]."
10,PET-Diffusion: Unsupervised PET Enhancement Based on the Latent Diffusion Model,"denoting the output of previous layer as z p et ,
the ct-guided cross-attention can be formulated as follows:where d is the number
of channels, b is the position bias, and conv(•) denotes the 1 × 1 × 1
convolution with stride of 1."
11,3D Arterial Segmentation via Single 2D Projections and Depth Supervision in Contrast-Enhanced CT Images,"the cohort consists of 141 patients with pancreatic ductal
adenocarcinoma, of an equal ratio of male to female patients."
12,Mesh2SSM: From Surface Meshes to Statistical Shape Models of Anatomy,"mesh2ssm also includes an analysis
network that operates on the learned correspondences to obtain a data-driven
template point cloud (i.e., template point cloud), which can replace the initial
template, and hence reducing the bias that could arise from template selection."
13,Mesh2SSM: From Surface Meshes to Statistical Shape Models of Anatomy,"incorporating template feedback loop via vae [13,21] analysis module helps in
mitigating bias and capturing non-linear characteristics of the data."
14,Cross-Adversarial Local Distribution Regularization for Semi-supervised Medical Image Segmentation,none
15,Infusing Physically Inspired Known Operators in Deep Models of Ultrasound Elastography,"it should be noted in contrast to [5] in which
only out-of-range samples were contributing to the loss, in this work, all
samples contribute to l vd to reduce the estimation bias.3-smoothness of epr is
considered by:4-picture loss is defined as l v = l vd + λ vs × l vs , where λ vs
is the weight of the smoothness loss."
16,SLPD: Slide-Level Prototypical Distillation for WSIs,"however, the
obtained clustering centers, i.e., the prototypes, are inclined to represent the
visual bias related to staining or scanning procedure rather than medically
relevant features [33]."
17,PROnet: Point Refinement Using Shape-Guided Offset Map for Nuclei Instance Segmentation,none
18,Many Tasks Make Light Work: Learning to Localise Medical Anomalies from Multiple Synthetic Tasks,none
19,TPRO: Text-Prompting-Based Weakly Supervised Histopathology Tissue Segmentation,none
20,VesselVAE: Recursive Variational Autoencoders for 3D Blood Vessel Synthesis,none
21,MetaLR: Meta-tuning of Learning Rates for Transfer Learning in Medical Imaging,"moreover, although the generalization validation on the training data batch may
introduce bias, providing sufficient training data ultimately benefits the
performance."
22,DAS-MIL: Distilling Across Scales for MIL Classification of Histological WSIs,"through
knowledge distillation, we encour-age agreement across the predictions delivered
at different resolutions, while individual scale features are learned in
isolation to preserve the diversity in terms of information content."
23,Pick the Best Pre-trained Model: Towards Transferability Estimation for Medical Image Segmentation,none
24,vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images,none
25,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"domain shift is typically caused by various factors, including
differences in acquisition protocols (e.g., parameters, imaging methods,
modalities) and characteristics of data (e.g., age, gender, the severity of the
disease and so on).domain adaptation (da) has been proposed and investigated to
combat distribution shift in medical image segmentation."
26,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"the infant brain
mri dataset for cross-age segmentation; 2)."
27,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"the first dataset, i.e., cross-age infant segmentation [20], was used
for cross-age infant brain image segmentation, while the second dataset, i.e.,
brats2018 [21], was used for hgg to lgg domain adaptation.the first dataset is
for infant brain segmentation (white matter, gray matter and cerebrospinal
fluid)."
28,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"to build the cross-age dataset, we take advantage 10 brain mris of
6-month-old from iseg2019 [20], and also build 3-month-old and 12-month-old
in-house datasets."
29,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"the quantitative comparison results of cross-age infant brain
segmentation is presented in table 1, and due to space limitations, we put the
experimental results of the brain tumor segmentation task in table 1 of
supplementary material, sec.3."
30,Spectral Adversarial MixUp for Few-Shot Unsupervised Domain Adaptation,none
31,Gall Bladder Cancer Detection from US Images with only Image Level Labels,none
32,Structured State Space Models for Multiple Instance Learning in Digital Pathology,none
33,Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision,none
34,Geometry-Invariant Abnormality Detection,none
35,Interpretable Medical Image Classification Using Prototype Learning and Privileged Information,none
36,Incremental Learning for Heterogeneous Structure Segmentation in Brain Tumor MRI,none
37,ArSDM: Colonoscopy Images Synthesis with Adaptive Refinement Semantic Diffusion Models,"through extensive
experiments, we found inaccurate sample images with coarse polyp boundary that
is not aligned properly with the original masks may introduce large biases and
noises to the datasets."
38,Synthetic Augmentation with Large-Scale Unconditional Pre-training,"by ensuring that the fine-tuning
process is representative of the entire dataset through even sampling from each
tissue type, we can eliminate bias towards any particular tissue type."
39,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation,none
40,Longitudinal Multimodal Transformer Integrating Imaging and Latent Clinical Signatures from Routine EHRs for Pulmonary Nodule Classification,none
41,Partially Supervised Multi-organ Segmentation via Affinity-Aware Consistency Learning and Cross Site Feature Alignment,none
42,Centroid-Aware Feature Recalibration for Cancer Grading in Pathology Images,none
43,Explaining Massive-Training Artificial Neural Networks in Medical Image Analysis Task Through Visualizing Functions Within the Models,none
44,FeSViBS: Federated Split Learning of Vision Transformer with Block Sampling,none
45,TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"first,
pure vit has several limitations itself [6], including ignoring local
information within each patch, extracting only single-scale features, and
lacking inductive bias."
46,Adaptive Region Selection for Active Learning in Whole Slide Image Semantic Segmentation,none
47,COLosSAL: A Benchmark for Cold-Start Active Learning for 3D Medical Image Segmentation,none
48,Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation,none
49,Continual Learning for Abdominal Multi-organ and Tumor Segmentation,none
50,Efficient Subclass Segmentation in Medical Images,"while mixing up only the semantic foreground provides a way of exchanging
knowledge between similar foreground objects while lifting the confirmation bias
in pseudo labeling [1]."
51,Towards AI-Driven Radiology Education: A Self-supervised Segmentation-Based Framework for High-Precision Medical Image Editing,none
52,Localized Region Contrast for Enhancing Self-supervised Learning in Medical Image Segmentation,"in
the opposite, when the number of samples n is large, the sampling bias can be
high, since the number of pixels can be smaller than n ."
53,FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation,none
54,Faithful Synthesis of Low-Dose Contrast-Enhanced Brain MRI Scans Using Noise-Preserving Conditional GANs,none
55,A Spatial-Temporal Deformable Attention Based Framework for Breast Lesion Detection in Videos,none
56,DeDA: Deep Directed Accumulator,"despite the effectiveness of general inductive
biases like translation equivariance [15] and locality [16], the diverse nature
of the gradient field map of the qsm images presents normalized gradient vectors
(the darker the blue, the larger the gradient vector's magnitude)."
57,DeDA: Deep Directed Accumulator,"consequently, the question of how
to incorporate domain-specific inductive biases, or priors, beyond general ones
into neural networks for medical image processing remains an open challenge.in
this study, we strive to answer this question by addressing the identification
problem associated with a specific type of multiple sclerosis (ms) lesion,
referred to as a chronic active lesion, or rim+ lesion."
58,DeDA: Deep Directed Accumulator,"transformer-based networks with fewer inductive biases rely heavily on the
use of a large training dataset or depends strongly on the feature reuse [19],
as a result, these networks as well as cnns with deeper structures are prone to
overfit small datasets.implementation details: a stratified five-fold
cross-validation procedure was applied to train and validate the performance,
and all experiments including ablation study were carried out within this
setting."
59,OpenAL: An Efficient Deep Active Learning Framework for Open-Set Pathology Image Classification,none
60,SFusion: Self-attention Based N-to-One Multimodal Fusion Block,"therefore, it has to simulate
missing data by crudely zero-padding or replacing it with similar modalities,
which inevitably introduces a bias in computation and causes performance
degradation [5,18,25].transformer has achieved success in the field of computer
vision, demonstrating that self-attention mechanism has the ability to capture
the latent correlation of image tokens."
61,VISA-FSS: A Volume-Informed Self Supervised Approach for Few-Shot 3D Segmentation,none
62,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"thus,
existing public skin datasets usually suffer from imbalanced problems which then
results in class bias of classifier, for example, poor model performance
especially on tail lesion types.to tackle the challenge of learning unbiased
classifiers with imbalanced data, many previous works focus on three main ideas,
including re-sampling data [1,18], re-weighting loss [2,15,22] and re-balancing
training strategies [10,23]."
63,SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation,none
64,UniSeg: A Prompt-Driven Universal Segmentation Model as Well as A Strong Representation Learner,"(2) most segmentation tasks face the limitation of a small
labeled dataset, especially for 3d segmentation tasks, since pixel-wise 3d image
annotation is labor-intensive, time-consuming, and susceptible to operator bias."
65,Cross-Modulated Few-Shot Image Generation for Colorectal Tissue Classification,none
66,Unpaired Cross-Modal Interaction Learning for COVID-19 Segmentation on Limited CT Images,none
67,Structure-Preserving Instance Segmentation via Skeleton-Aware Distance Transform,none
68,DAST: Differentiable Architecture Search with Transformer for 3D Medical Image Segmentation,"the transformer block is crafted with
longrange dependency inside sequences with marginal inductive bias."
69,DAST: Differentiable Architecture Search with Transformer for 3D Medical Image Segmentation,"intrinsically, it
shall benefit from inductive biases of these two popular deep learning
ingredients."
70,DAST: Differentiable Architecture Search with Transformer for 3D Medical Image Segmentation,"such models benefit from the different
inductive biases introduced by these two operations."
71,MultiTalent: A Multi-dataset Approach to Medical Image Segmentation,none
72,Co-assistant Networks for Label Correction,none
73,Pre-trained Diffusion Models for Plug-and-Play Medical Image Enhancement,none
74,Robust T-Loss for Medical Image Segmentation,"in addition, medical image
annotations can be affected by human bias and poor inter-annotator agreement
[23], further complicating the process."
75,Multi-Head Multi-Loss Model Calibration,none
76,Guiding the Guidance: A Comparative Analysis of User Guidance Signals for Interactive Segmentation of Volumetric Images,none
77,Laplacian-Former: Overcoming the Limitations of Vision Transformers in Local Texture Detection,none
78,Understanding Silent Failures in Medical Image Classification,none
79,Evidence Reconciled Neural Network for Out-of-Distribution Detection in Medical Images,none
80,Scale-Aware Test-Time Click Adaptation for Pulmonary Nodule and Mass Segmentation,none
81,WeakPolyp: You only Look Bounding Box for Polyp Segmentation,"this indirect supervision avoids the misleading of box-shape bias of
annotations."
82,WeakPolyp: You only Look Bounding Box for Polyp Segmentation,"because
there is a strong box-shape bias in b."
83,WeakPolyp: You only Look Bounding Box for Polyp Segmentation,"training with this bias, the model is
forced to predict the box-shape mask, unable to maintain the polyp's contours."
84,WeakPolyp: You only Look Bounding Box for Polyp Segmentation,"this indirect supervision
separates p 1 /p 2 from b so that p 1 /p 2 is not affected by the shape bias of
b while obtaining the position and extent of polyps."
85,WeakPolyp: You only Look Bounding Box for Polyp Segmentation,"because both t 1 /t 2 and b are
box-like masks, we directly calculate the supervision loss between them without
worrying about the misguidance of box-shape bias."
86,Shifting More Attention to Breast Lesion Segmentation in Ultrasound Videos,none
87,ACC-UNet: A Completely Convolutional UNet Model for the 2020s,"smeswin-unet fell behind
in all the cases, despite having such a large number of parameters, which in
turn probably makes it difficult to be trained on small-scale datasets.however,
our model combining the design principles of transformers with the inductive
bias of cnns seemed to perform best in all the different categories with much
lower parameters."
88,ACC-UNet: A Completely Convolutional UNet Model for the 2020s,"the
resultant acc-unet possesses the inductive bias of cnns infused with long-range
and multi-level feature accumulation of transformers."
89,FocalUNETR: A Focal Transformer for Boundary-Aware Prostate Segmentation Using CT Images,"despite good progress, these methods often have
limitations in capturing long-range relationships and global context information
[2] due to the inherent bias of convolutional operations."
90,FocalUNETR: A Focal Transformer for Boundary-Aware Prostate Segmentation Using CT Images,"after obtaining the pooled feature mapsx l l 1 , we calculate the
query at the first level and key and value for all levels using three linear
projection layers f q , f k , and f v :for the queries inside the i-th window q
i ∈ r d×sw×sw , we extract the s l r × s l r keys and values from k l and v l
around the window where the query lies in and then gather the keys and values
from all l to obtainfinally, a relative position bias is added to compute the
focal sa forwhere b = {b l } l 1 is the learnable relative position bias [24]."
91,Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,none
92,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"[1] introduced a robust class-wise sampling strategy to
address the learning bias by maintaining performance indicators on the fly and
using fuzzy fusion to dynamically obtain the class-wise sampling rates."
93,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"[10] proposed cld to address the data bias by weighting the overall loss
function based on the voxel number of each class."
94,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"the key idea of heterogeneous co-training
is that individual learners in an ensemble model should be both accurate and
diverse, as stated in the error-ambiguity decomposition [8].to achieve this, we
propose distdw (distribution-aware debiased weighting) and diffdw (diff
iculty-aware debiased weighting) strategies to guide the two sub-models to
tackle different biases, leading to heterogeneous learning directions."
95,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"specifically, distdw solves the data bias by calculating the imbalance ratio
with the unlabeled data and forcing the model to focus on extreme minority
classes through careful function design."
96,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"1(b)), diffdw is
designed to solve the learning bias."
97,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"1(c)), which satisfies the design ethos of a heterogeneous framework.the
key contributions of our work can be summarized as follows: 1) we first state
the homogeneity issue of cps and improve it with a novel dual-debiased
heterogeneous co-training framework targeting the class imbalance issue; 2) we
propose two novel weighting strategies, distdw and diffdw, which effectively
solve two critical issues of ssl: data and learning biases; 3) we introduce two
public datasets, synapse [9] and amos [7], as new benchmarks for
class-imbalanced semi-supervised medical image segmentation."
98,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"dhc
leverages the benefits of combining two diverse and accurate sub-models with two
distinct learning objectives: alleviating data bias and learning bias."
99,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"to mitigate the data distribution bias, we propose a simple yet efficient
reweighing strategy, distdw."
100,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"blindly forcing the model to prioritize minority classes may
further exacerbate the learning bias, as some challenging classes may not be
learned to an adequate extent."
101,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"distdw
('distdw-distdw') alleviates the bias of baseline on majority classes and thus
segments the minority classes (ra, la, es, etc.) very well."
102,DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"to
achieve it, we propose two diverse and accurate weighting strategies: distdw for
eliminating the data bias of majority classes and diffdw for eliminating the
learning bias of well-performed classes."
103,Anatomical-Aware Point-Voxel Network for Couinaud Segmentation in Liver CT,none
104,HENet: Hierarchical Enhancement Network for Pulmonary Vessel Segmentation in Non-contrast CT Images,none
105,Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels,"that is, the bias of the estimation is bounded above by the
calibration error and this explains why the calibration of the teacher would be
important for the student."
106,Semi-supervised Domain Adaptive Medical Image Segmentation Through Consistency Regularized Disentangled Contrastive Learning,none
107,BerDiff: Conditional Bernoulli Diffusion Model for Medical Image Segmentation,none
108,Annotator Consensus Prediction for Medical Image Segmentation with Diffusion Models,none
109,Anti-adversarial Consistency Regularization for Data Augmentation: Applications to Robust Medical Image Segmentation,none
110,Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk,none
111,Learning Reliability of Multi modality Medical Images for Tumor Segmentation via Evidence Identified Denoising Diffusion Probabilistic Models,none
112,Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network,breast cancer is the leading cause of cancer-related fatalities among women.
113,Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network,"currently, it holds the highest incidence rate of cancer among women in the
u.s., and in 2022 it accounted for 31% of all newly diagnosed cancer cases [1]."
114,Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network,"this is primarily because the
architectural design of vits does not rely on the same inductive biases in
feature extraction which allow cnns to learn spatially invariant
features.accordingly, numerous prior studies introduced modifications to the
original vit network specifically designed for bus image classification
[13,14,23]."
115,Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network,"moreover,
multitask learning acts as a regularizer by introducing inductive bias and
prevents overfitting [25] (particularly with vits), and with that, can mitigate
the challenges posed by small bus dataset sizes."
116,Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network,"to avoid data
leakage and bias, we selected the train, test, and validation sets based on the
cases, i.e., the images from one case (patient) were assigned to only one of the
training, validation, and test sets."
117,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"the convolution operation in cnn provides a strong inductive bias
which is translational equivalent and efficient in capturing local features like
boundary and texture."
118,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"however, this inductive bias limits the representation
power of cnn models which means a potentially lower performance ceiling on more
challenging tasks [7]."
119,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"it has a
u-shaped structure where the encoder is a swin-transformer [16].although
transformers have achieved certain success in medical imaging, the lack of
inductive bias makes them harder to be trained and requires much more training
data to avoid overfitting."
120,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"besides lacking
inductive bias and enough training data, one extra reason could be that
transformers are computationally much expensive and harder to tune."
121,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"coatnet [5] unifies convolution and
self-attention with relative attention, while convit [7] uses gated positional
self-attention which is equipped with a soft convolutional inductive bias."
122,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"although swin-transformer uses local window attention to introduce
inductive bias like convolutions, self-attentions can still mess up with the
local details."
123,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"although existing
window-based attention already has a convolution-like inductive bias, it is
still not good enough for learning local details as convolutions."
124,SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"by only adding one resconv block at the beginning of each resolution
level, the features can be well-regularized while not too constrained by the
convolution inductive bias, and the computation cost will not increase by a lot."
125,SimPLe: Similarity-Aware Propagation Learning for Weakly-Supervised Breast Cancer Segmentation in DCE-MRI,"breast cancer is the most common cause of cancer-related deaths among women all
around the world [8]."
126,Uncertainty-Informed Mutual Learning for Joint Medical Image Classification and Segmentation,none
127,Conditional Diffusion Models for Weakly Supervised Medical Image Segmentation,none
128,DBTrans: A Dual-Branch Vision Transformer for Multi-Modal Brain Tumor Segmentation,none
129,HartleyMHA: Self-attention in Frequency Domain for Resolution-Robust and Parameter-Efficient 3D Image Segmentation,none
130,MDViT: Multi-domain Vision Transformer for Small Medical Image Segmentation Datasets,"however, due to the lack of inductive biases, such as
weight sharing and locality, vits are more data-hungry than cnns, i.e., require
more data to train [31]."
131,MDViT: Multi-domain Vision Transformer for Small Medical Image Segmentation Datasets,"various strategies have been
proposed to address vits' data-hunger (table 1), mainly: adding inductive bias
by constructing a hybrid network that fuses a cnn with a vit [39], imitating
cnns' shifted filters and convolutional operations [7], or enhancing spatial
information learning [22]; sharing knowledge by transferring knowledge from a
cnn [31] or pertaining vits on multiple related tasks and then fine-tuning on a
down-stream task [37]; increasing data via augmentation [34]; and non-supervised
pre-training [8]."
132,MDViT: Multi-domain Vision Transformer for Small Medical Image Segmentation Datasets,"previous mis
vits mitigated the data-hunger in one dataset by adding inductive bias, e.g.,
swinunet the online version contains supplementary material available at
https://doi.org/10.1007/978-3-031-43901-8 43."
133,M-GenSeg: Domain Adaptation for Target Modality Tumor Segmentation with Annotation-Efficient Supervision,none
134,Edge-Aware Multi-task Network for Integrating Quantification Segmentation and Uncertainty Prediction of Liver Tumor on Multi-modality Non-contrast MRI,none
135,RCS-YOLO: A Fast and High-Accuracy Object Detector for Brain Tumor Detection,none
136,Certification of Deep Learning Models for Medical Image Segmentation,none
137,Category-Level Regularized Unlabeled-to-Labeled Learning for Semi-supervised Prostate Segmentation with Multi-site Unlabeled Data,none
138,A Sheaf Theoretic Perspective for Robust Prostate Segmentation,"recent methods have utilized adversarial techniques,
such as advbias [11], which trains the model to generate bias field deformations
and enhance its robustness.randconv [33] incorporates a randomized convolution
layer to learn textural invariant features."
139,MedNeXt: Transformer-Driven Scaling of ConvNets for Medical Image Segmentation,"however, transformers are plagued by
the necessity of large annotated datasets to maximize performance benefits owing
to their limited inductive bias."
140,MedNeXt: Transformer-Driven Scaling of ConvNets for Medical Image Segmentation,"to retain the
inherent inductive bias of convolutions while taking advantage of architectural
improvements of transformers, the convnext [22] was recently introduced to
re-establish the competitive performance of convolutional networks for natural
images."
141,MedNeXt: Transformer-Driven Scaling of ConvNets for Medical Image Segmentation,"out-of-the-box
data-efficient solutions such as nnunet [13], using variants of a standard unet
[5], have still remained effective across a wide range of tasks.the convnext
architecture marries the scalability and long-range spatial representation
learning capabilities of vision [7] and swin transformers [21] with the inherent
inductive bias of convnets."
142,MedNeXt: Transformer-Driven Scaling of ConvNets for Medical Image Segmentation,"compression layer: convolution
layer with 1 × 1 × 1 kernel and c output channels performing channel-wise
compression of the feature maps.mednext is convolutional and retains the
inductive bias inherent to conv-nets that allows easier training on sparse
medical datasets."
143,MedNeXt: Transformer-Driven Scaling of ConvNets for Medical Image Segmentation,"specifically, swin transformers use a bias matrix b ∈
r (2m -1)×(2m -1) to store learnt relative positional embeddings, where m is the
number of patches in an attention window."
144,MedNeXt: Transformer-Driven Scaling of ConvNets for Medical Image Segmentation,"the authors proposed spatially
interpolating an existing bias matrix to the larger size as a pretraining step,
instead of training from scratch, which demonstrated improved performance."
145,Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,none
146,A2FSeg: Adaptive Multi-modal Fusion Network for Medical Image Segmentation,none
147,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"in addition, information of patient age and tumor
position is also used."
148,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"specifically, the in-house dataset collected in cooperation hospitals
contains pre-operative multimodal mr images, including t1, t1 contrast enhanced
(t1c), t2, and flair, of 1726 patients (age 49.7 ± 13.1) with confirmed diffuse
glioma types."
149,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"besides the inhouse
dataset, a public dataset brats2019, including pre-operative multimodal mr
images of 210 non-censored patients (age 61.4 ± 12.2), is adopted as the
external independent testing dataset."
150,Medical Boundary Diffusion Model for Skin Lesion Segmentation,none
151,H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation,none
152,TransNuSeg: A Lightweight Multi-task Transformer for Nuclei Segmentation,none
153,Learnable Cross-modal Knowledge Distillation for Multi-modal Learning with Missing Modality,"however, the aforementioned methods neglect the contribution biases
of different modalities and failed to consider keeping that knowledge.aiming at
this issue, we propose the non-dedicated training model1 learnable cross-modal
knowledge distillation (lckd) for tackling the missing modality issue."
154,QCResUNet: Joint Subject-Level and Voxel-Level Prediction of Segmentation Quality,none
155,EGE-UNet: An Efficient Group Enhanced UNet for Skin Lesion Segmentation,none
156,Diffusion Kinetic Model for Breast Cancer Segmentation in Incomplete DCE-MRI,none
157,Morphology-Inspired Unsupervised Gland Segmentation via Selective Semantic Grouping,none
158,EoFormer: Edge-Oriented Transformer for Brain Tumor Segmentation,"specifically, we explain the re-parameterization of the eol
module as follows:where ' * ' represents the convolution operation, w conv means
the weights of the convolution and b conv denotes the bias, and up(•) is the
spatial broadcasting operation ,which upgrades the bias b ∈ r 1×c×1×1×1 into
up(b) ∈ r 1×c×3×3×3 ."
159,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"however, official datasets released, e.g., ham10000 [10] only
contains melanoma samples and all of the samples are with light skins according
to our inspection using ita scores.bias mitigation: researchers have addressed
bias and heterogeneity in deep learning models [18,29]."
160,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"the key insight is a novel data
preprocessing method that utilizes edge detection and mixup to isolate and
highlight skin lesions and reduce bias."
161,Factor Space and Spectrum for Medical Hyperspectral Image Segmentation,none
162,Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,none
163,Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"all images were acquired at an average age of 30.6 years on a signa
3.0t scanner with an eight-channel standard head coil."
164,CARL: Cross-Aligned Representation Learning for Multi-view Lung Cancer Histology Classification,none
165,Self- and Semi-supervised Learning for Gastroscopic Lesion Detection,none
166,Revisiting Feature Propagation and Aggregation in Polyp Segmentation,none
167,"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies",none
168,Automatic Bleeding Risk Rating System of Gastric Varices,none
169,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"bias in medicine has demonstrated a notable challenge for providing
comprehensive and equitable care."
170,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"implicit biases can negatively affect patient
care, particularly for marginalized populations with lower socioeconomic status
[30]."
171,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"evidence has demonstrated that implicit biases in healthcare providers
could contribute to exacerbating these healthcare inequalities and create a more
unfair system for people of lower socioeconomic status [30]."
172,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"based on the data
with racial bias, the unfairness presents in developing evaluative algorithms."
173,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"along these advancements, bias in
healthcare and ai are exposing poignant gaps in the field's understanding of
model implementation and their utility [25,26]."
174,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"ai model quality relies on input
data and addressing bias is a crucial research area."
175,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"systemic bias poses a
greater threat to ai model's applications, as these biases can be baked right
into the model's decision process [22].pulmonary embolism (pe) is an example of
health disparities related to race."
176,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"black patients exhibit a 50% higher
age-standardized pe fatality rate and a twofold risk for pe hospitalization than
white patients [18,24]."
177,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"survival
analysis is often used in pe to assess how survival is affected by different
variables, using a statistical method like kaplan-meier method and cox
proportional-hazards regression model [7,12,14].however, one issue with
traditional survival analysis is bias from single modal data that gets
compounded when curating multimodal datasets, as different combinations of modes
and datasets create with a unified structure."
178,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"multimodal data sets are useful
for fair ai model development as the bias complementary from different sources
can make de-biased decisions and assessments."
179,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"in that process, the biases of
each individual data set will get pooled together, creating a multimodal data
set that inherits multiple biases, such as racial bias [1,15,23]."
180,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"in addition,
it has been found that creating multimodal datasets without any debiasing
techniques does not improve performance significantly and does increase bias and
reduce fairness [5]."
181,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"overall, a holistic approach to model development would be
beneficial in reducing bias aggregation in multimodal datasets."
182,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"in recent years,
disentangled representation learning (drl) [4] for bias disentanglement improves
model generalization for fairness [3,6,27].we developed a pe outcome model that
predicted mortality and detected bias in the output."
183,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"we then implemented methods
to remove racial bias in our dataset and model and output unbiased pe outcomes
as a result."
184,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"our contributions are as follows: (1) we identified bias diversity
in multimodal information using a survival prediction fusion framework."
185,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"(2) we
proposed a de-biased survival prediction framework with demographic bias
disentanglement."
186,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"this section describes the detail of how we identify the varying degrees of bias
in multimodal information and illustrates bias using the relative difference in
survival outcomes."
187,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"we will first introduce our pulmonary embolism multimodal
datasets, including survival and race labels."
188,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the pulmonary embolism dataset used in this study from 918
patients (163 deceased, median age 64 years, range 13-99 years, 52% female),
including 3978 ctpa images and 918 clinical reports, which were identified via
retrospective review across three institutions."
189,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"for each patient, the race labels, survival time-to-event labels and
pesi variables are collected from clinical data, and the 11 pesi variables are
used to calculate the pesi scores, which include age, sex, comorbid illnesses
(cancer, heart failure, chronic lung disease), pulse, systolic blood pressure,
respiratory rate, temperature, altered mental status, and arterial oxygen
saturation at the time of diagnosis [2].diverse bias of multimodal survival
prediction model."
190,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"this
redundancy leads to model overfitting on race, compromising the fairness of risk
prediction across different races."
191,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"besides, clinical data in the form of text
reports and pesi variables objectively reflect the patient's physiological
information and the physician's diagnosis, exhibiting smaller race biases in
correlation with survival across different races."
192,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"2, we
present a feature-level de-biased sp module that enhances fairness in survival
outcomes by decoupling race attributes, as shown in the lower right of fig."
193,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"in the de-biased sp module, firstly, two separate encoders e m i and e m c are
formulated to embed features f m into disentangled latent vectors for
race-intrinsic attributes z id or race-conflicting attributes z sur implied
survival information [16]."
194,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"then, the linear classifiers c m i and c m c
constructed to predict the race label y id with concatenated vector z = [z id ;
z sur ]."
195,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"to disentangle survival features from the race identification, we use
the generalized cross-entropy (gce) loss [31] to train e m c and c m c to
overfit to race label while training e m i and c m i with crossentropy (ce)
loss."
196,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"1 reweight and enhance
the learning of the race-intrinsic attributes [20]."
197,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"2, but the parameters of id or survival branch are
only updated by their respective losses:to promote race-intrinsic learning in e
m i and c m i , we apply diversify with latent vectors swapping."
198,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"as the random combination are generated from different samples, the
swapping decreases the correlation of these feature vectors, thereby enhancing
the race-intrinsic attributes."
199,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"in
general, our framework including de-biased sp modules shows significantly better
predictions in testing set than the pesi-based outcome estimation with c-indexes
of 0.669, 0.654, 0.697, 0.043 for the overall testset, white testset, color
testset and race bias."
200,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the de-biased results outperform the baseline in overall
survival c-index and show a lower race bias, especially in imaging-and
fusion-based predictions."
201,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the results indicate the effectiveness of the proposed
de-biasing in mitigating race inequity."
202,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the results also prove the observations
for the different biases present in different modalities, especially in the ctpa
images containing more abundant race-related information."
203,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the disentangled
representations, transformed from latent space to a 2d plane via tsne and
color-coded by race [9], are shown in fig."
204,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"we observe the disentanglement in
the visualization of the id features z id , while the survival features z sur
eliminate the race bias."
205,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the lack of apparent race bias observed in both the
original features and those encoded in the baseline can be attributed to the
subordinate role that id features play in the multimodal information."
206,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"in addition, the predictions of
the de-biased framework show favorable performance, and our multimodal fusion
demonstrates a more pronounced discriminative ability in the k-m survival
analysis compared to the single-modal results.we conducted ablation studies to
examine the effect of the two key components, including swapping feature
augmentation and race-balance resampling."
207,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the swapping augmentation provides a strong bias
correction effect for image data with obvious bias."
208,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"in this work, we developed a de-biased survival prediction framework based on
the race-disentangled representation."
209,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"we detected indications of racial bias in our dataset and
conducted an analysis of the multimodal diversity."
210,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"experimental results
illustrate that our approach is effective for eliminating racial bias while
resulting in an overall improved model performance."
211,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the proposed technique is
clinically relevant as it can address the pervasive presence of racial bias in
healthcare systems and offer a solution for minimizing or eliminating bias
without pausing to evaluate their affection for the models and tools."
212,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"our study
is significant as it highlights and evaluates the negative impact of racial bias
on deep learning models."
213,Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the research in our paper demonstrates and proves that eliminating
racial biases from data improves performance, and yields a more precise and
robust survival prediction tool."
214,Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"breast cancer impacts women globally [15] and mammographic screening for women
over a certain age has been shown to reduce mortality [7,10,23]."
215,Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"recently,
several studies [8,32,33] revealed the potential of artificial intelligence (ai)
to develop a better risk assessment model to identify women who may benefit from
supplemental screening or a personalized screening interval and these may lead
to improved screening outcomes.in clinical practice, breast density and
traditional statistical methods for predicting breast cancer risks such as the
gail [14] and the tyrer-cuzick models [27] have been used to estimate an
individual's risk of developing breast cancer."
216,Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"for medical applications, x typically
represents patient information like age, family history, genetic makeup, and
diagnostic test results (e.g., a mammogram)."
217,Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"women with dense breasts have a four-to six-fold higher
risk of breast cancer [2]."
218,Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,none
219,M&M: Tackling False Positives in Mammography with a Multi-view and Multi-instance Learning Sparse Detector,none
220,Reversing the Abnormal: Pseudo-Healthy Generative Networks for Anomaly Detection,none
221,SHISRCNet: Super-Resolution and Classification Network for Low-Resolution Breast Cancer Histopathology Image,"breast cancer is one of the high-mortality cancers among women in the 21st
century."
222,SHISRCNet: Super-Resolution and Classification Network for Low-Resolution Breast Cancer Histopathology Image,"every year, 1.2 million women around the world suffer from breast
cancer and about 0.5 million die of it [3]."
223,Text-Guided Foundation Model Adaptation for Pathological Image Classification,none
224,Distributionally Robust Image Classifiers for Stroke Diagnosis in Accelerated MRI,none
225,Contrastive Feature Decoupling for Weakly-Supervised Disease Detection,none
226,Multiple Prompt Fusion for Zero-Shot Lesion Detection Using Vision-Language Models,none
227,Fast Non-Markovian Diffusion Model for Weakly Supervised Anomaly Detection in Brain MR Images,none
228,MUVF-YOLOX: A Multi-modal Ultrasound Video Fusion Network for Renal Tumor Diagnosis,none
229,Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"b
1 and b 2 are bias vectors."
230,Learning with Synthesized Data for Generalizable Lesion Detection in Real PET Images,none
231,What Do AEs Learn? Challenging Common Assumptions in Unsupervised Anomaly Detection,none
232,Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"we further stratify patients by our signature after
grouping them by tumor size and ca19-9, two clinically used preoperative
criteria for selection, and also age."
233,DCAug: Domain-Aware and Content-Consistent Cross-Cycle Framework for Tumor Augmentation,none
234,Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,none
235,Self-supervised Polyp Re-identification in Colonoscopy,none
236,YONA: You Only Need One Adjacent Reference-Frame for Accurate and Fast Video Polyp Detection,none
237,Boosting Breast Ultrasound Video Classification by the Guidance of Keyframe Feature Centers,none
238,Text-Guided Cross-Position Attention for Segmentation: Case of Medical Image,none
239,Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fréchet Domain Distance,none
240,Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"such metrics cannot reflect the
lesion-level accuracy (how many lesion instances are correctly detected and
classified) and may bias to large lesions when a patient has multiple tumors."
241,Self-supervised Learning for Endoscopic Video Analysis,none
242,Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"in addition,
clinical indicators (e.g., age, gender) also can be integrated by the coxph
model."
243,ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,none
244,DARC: Distribution-Aware Re-Coloring Model for Generalizable Nucleus Segmentation,none
245,An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,none
246,Detection of Basal Cell Carcinoma in Whole Slide Images,"this
introduces evaluation bias and leads to sub-optimal results.to mitigate
evaluation bias on width, we propose a new sc-net that promotes the fairness of
channels during training."
247,IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis,none
248,Multi-scale Prototypical Transformer for Whole Slide Image Classification,none
249,Thyroid Nodule Diagnosis in Dynamic Contrast-Enhanced Ultrasound via Microvessel Infiltration Awareness,none
250,Label-Free Nuclei Segmentation Using Intra-Image Self Similarity,none
251,Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,none
252,NASDM: Nuclei-Aware Semantic Histopathology Image Generation Using Diffusion Models,"as such, generative models can be sampled to emphasize each
disease subtype equally and generate more balanced datasets, thus preventing
dataset biases getting amplified by the models [7]."
253,NASDM: Nuclei-Aware Semantic Histopathology Image Generation Using Diffusion Models,"a common issue in deep learning with h&e stained histopathology slides is the
visual bias introduced by variations in the staining protocol and the raw
materials of chemicals leading to different colors across slides prepared at
different labs [1]."
254,DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,none
255,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning,"the bias and error generated in each level of the
representation model will accumulate in the final decision model."
256,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning,"the multi-stage framework
accumulated the training bias and noise, which caused an auc gap of hipt [5] to
mae [7] and pama, especially trained with only 10% labeled wsis."
257,Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,"cervical cancer is a common and severe disease that affects millions of women
globally, particularly in developing countries [9]."
258,Instance-Aware Diffusion Model for Gland Segmentation in Colon Histology Images,none
259,Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs,"such scheduling of the weights is done so that in the beginning of
the training, the weights are uniform in order not to wrongly bias the network
when the embeddings are still indiscriminative."
260,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis,none
261,Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,none
262,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,none
263,Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology,none
264,Progressive Attention Guidance for Whole Slide Vulvovaginal Candidiasis Screening,"it is the most prevalent human candidal infection,
estimated to afflict approximately 75% of all women at least once in their
lifetime [1,20], resulting in huge consumption of medical resources."
265,CellGAN: Conditional Cervical Cell Synthesis for Augmenting Cytopathological Image Classification,"then, we pass c through learnable affine transformations,
such that the class embedding is specialized to the scaling and bias parameters
controlling adaptive instance normalization (adain) [13] in each upblock."
266,An Anti-biased TBSRTC-Category Aware Nuclei Segmentation Framework with a Multi-label Thyroid Cytology Benchmark,"innovatively, our approach can
help reduce bias in the learning process of the segmentation model with the
routine unbalanced training set."
267,Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,"breast cancer (bc) is one of the most common malignant tumors in women worldwide
and it causes nearly 0.7 million deaths in 2020 [26]."
268,Semi-supervised Pathological Image Segmentation via Cross Distillation of Multiple Attentions,"since using a model's prediction to supervise itself may over-fit its bias,
chen et al."
269,Semi-supervised Pathological Image Segmentation via Cross Distillation of Multiple Attentions,"since the three branches have different decision boundaries, using the
predictions from one branch as pseudo labels to supervise the others would avoid
each branch over-fitting its bias."
270,Towards Novel Class Discovery: A Study in Novel Skin Lesions Clustering,none
271,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,none
272,Robust Cervical Abnormal Cell Detection via Distillation from Local-Scale Consistency Refinement,cervical cancer is the second most common cancer among adult women.
273,StainDiff: Transfer Stain Styles of Histology Images with Denoising Diffusion Probabilistic Models and Self-ensemble,none
274,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"the mean and median
age of patients at the date of dissection was 47 and 50 years, respectively."
275,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"the
data set comprised 13 male and 27 female patients, corresponding to a slight
gender imbalance."
276,Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"breast cancer (bc) is the most common cancer diagnosed among females and the
second leading cause of cancer death among women after lung cancer [1]."
277,Gene-Induced Multimodal Pre-training for Image-Omic Classification,none
278,Histopathology Image Classification Using Deep Manifold Contrastive Learning,none
279,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,none
280,Multi-scope Analysis Driven Hierarchical Graph Transformer for Whole Slide Image Based Cancer Survival Prediction,none
281,Mining Negative Temporal Contexts for False Positive Suppression in Real-Time Ultrasound Lesion Detection,none
282,Iteratively Coupled Multiple Instance Learning from Instance to Bag Classifier for Whole Slide Image Classification,none
283,Artifact Restoration in Histology Images with Diffusion Probabilistic Models,none
284,Thinking Like Sonographers: A Deep CNN Model for Diagnosing Gout from Musculoskeletal Ultrasound,none
285,Scribble-Based 3D Multiple Abdominal Organ Segmentation via Triple-Branch Multi-Dilated Network with Pixel- and Class-Wise Consistency,none
286,Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"breast cancer is the most prevalent form of cancer among women and can have
serious physical and mental health consequences if left unchecked [5]."
287,CTFlow: Mitigating Effects of Computed Tomography Acquisition and Reconstruction with Normalizing Flows,none
288,Probabilistic Modeling Ensemble Vision Transformer Improves Complex Polyp Segmentation,none
289,DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,"breast cancer (bc) is the most common cancer in women and incidence is
increasing [14]."
290,DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,"the in-house
dataset comprises 43,258 mammography exams from 10,670 women between 2004-2020,
collected from a hospital with irb approvals."
291,DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,"in this study, we randomly select
20% women of the full dataset, comprising 6,000 normal (bi-rads = 1) and 28,732
abnormal (bi-rads = 1) images."
292,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,none
293,Skin Lesion Correspondence Localization in Total Body Photography,none
294,Anatomy-Informed Data Augmentation for Enhanced Prostate Cancer Detection,none
295,Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,none
296,Radiomics-Informed Deep Learning for Classification of Atrial Fibrillation Sub-Types from Left-Atrium CT Volumes,none
297,Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-Based Hierarchical Fusion Network with Attention Mechanism,"breast cancer is the most common cancer and the leading cause of cancer death in
women [18]."
298,Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"rigorous
clinical evaluations can establish the safety and efficacy of ai-based
techniques, identify potential biases and limitations, and facilitate the
integration of clinical expertise to ensure accurate and meaningful results
[13]."
299,Automated CT Lung Cancer Screening Workflow Using 3D Camera,none
300,Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"age-related macular degeneration (amd) is the leading cause of blindness in the
elderly, affecting nearly 200 million people worldwide [24]."
301,Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"we
also include a demographic baseline using age and sex."
302,Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"in all tasks the
standard biomarkers are only marginally more indicative of risk than the
patient's age and sex."
303,Multi-task Learning of Histology and Molecular Markers for Classifying Diffuse Glioma,none
304,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,none
305,CLIP-Lung: Textual Knowledge-Guided Lung Nodule Malignancy Prediction,"consequently, aligning these distinct feature types becomes challenging,
resulting in a bias towards the text features associated with malignant nodules."
306,EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"when a deep learning model overfits specific
artifacts instead of learning the correct dermoscopic patterns, it may fail to
identify skin lesions in real-world environments where the artifacts are absent
or inconsistent.to alleviate the artifact bias and enhance the model's
generalization ability, we rethink the problem from the domain generalization
(dg) perspective, where a model trained within multiple different but related
domains are expected to perform well in unseen test domains."
307,EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"(2) trap set debiasing: we train
and test our epvt with its baseline on six trap sets [3] with increasing bias
levels, ranging from 0 (randomly split training and testing sets from the
isic2019 dataset) to 1 (the highest bias level where the correlation between
artifacts and class label is in the opposite direction in the dataset splits)."
308,EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"each point on the graph represents an algorithm that
is trained and tested on a specific bias degree split.the graph shows that the
erm baseline performs better than our epvt when the bias is low (0 and 0.3)."
309,EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"as the
bias degree increases, the correlation between artifacts and class labels
decreases, and overfitting the train set causes the performance of erm to drop
dramatically on the test set with a significant distribution difference."
310,EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"in
contrast, our epvt exhibits greater robustness to different bias levels."
311,EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"notably, our epvt outperforms the erm baseline by 9.4% on the bias 1
dataset.prompt weights analysis: to verify whether our model has learned the
correct domain prompts for target domain prediction, we analyze and plot the
results in fig."
312,Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"for labels with continuous values such as
age, the value normalized to 0 ∼ 1 is w p i ."
313,Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"specifically, embedding setare
the input tokens, the attention value α and output token e are computed as
follows:where e i is from e, w q , w k and w v are weight matrices of query, key
and value, respectively, w r and w o are transformation matrices, and b 1 and b
2 are bias vectors."
314,Developing Large Pre-trained Model for Breast Tumor Segmentation from Ultrasound Images,"breast cancer is a serious health problem with high incidence and wide
prevalence for women throughout the world [1,2]."
315,3D Mitochondria Instance Segmentation with Spatio-Temporal Transformers,none
316,Physics-Informed Conditional Autoencoder Approach for Robust Metabolic CEST MRI at 7T,none
317,Diffusion-Based Data Augmentation for Nuclei Image Segmentation,none
318,Deep Unsupervised Clustering for Conditional Identification of Subgroups Within a Digital Pathology Image Set,none
319,A Texture Neural Network to Predict the Abnormal Brachial Plexus from Routine Magnetic Resonance Imaging,none
320,CircleFormer: Circular Nuclei Detection in Whole Slide Images with Circle Queries and Attention,none
321,Self-supervised Dense Representation Learning for Live-Cell Microscopy with Time Arrow Prediction,"resnet [9]) that lack this symmetry, we here directly incorporate this
inductive bias via a permutation-equivariant head h that is a generalization of
the set permutation-equivariant layer proposed in [32] to dense inputs."
322,Prompt-MIL: Boosting Multi-instance Learning Schemes via Task-Specific Prompt Tuning,none
323,Prompt-Based Grouping Transformer for Nucleus Detection and Classification,none
324,Maximum-Entropy Estimation of Joint Relaxation-Diffusion Distribution Using Multi-TE Diffusion MRI,none
325,Simulation of Arbitrary Level Contrast Dose in MRI Using an Iterative Global Transformer Model,none
326,TractCloud: Registration-Free Tractography Parcellation with a Novel Local-Global Streamline Point Cloud Representation,none
327,Relaxation-Diffusion Spectrum Imaging for Probing Tissue Microarchitecture,none
328,Exploring Unsupervised Cell Recognition with Prior Self-activation Maps,"it combines the advantage of correlation filters
and deep learning but needs iterative training and finetuning.cnns with
inductive biases have priority over local features of the nuclei with dense
distribution and semi-regular shape."
329,Brain Anatomy-Guided MRI Analysis for Assessing Clinical Progression of Cognitive Impairment with Structural MRI,"all mris
are preprocessed via the following pipeline: 1) bias field correction, 2) skull
stripping, 3) affine registration to the mni space, 4) resampling to 1 × 1 × 1
mm 3 , 5) deformable registration to aal3 [19] with syn [20], and 6) warping 166
regions-of-interest (rois) of aal3 back to mri volumes.proposed method."
330,Brain Anatomy-Guided MRI Analysis for Assessing Clinical Progression of Cognitive Impairment with Structural MRI,"such
partition is repeated five times independently to avoid any bias introduced by
random partition, and the mean and standard deviation results are recorded."
331,Brain Anatomy-Guided MRI Analysis for Assessing Clinical Progression of Cognitive Impairment with Structural MRI,"second, among 10 deep models, our bar produces the lowest
standard deviation in most cases (especially on sen and spe), suggesting its
robustness to bias introduced by random data partition in the downstream task."
332,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning,none
333,B-Cos Aligned Transformers Learn Human-Interpretable Features,"5: when bvt
is trained from scratch, the model faces a trade-off between learning the weight
and input alignment and finding the appropriate inductive bias to solve the
classification task."
334,B-Cos Aligned Transformers Learn Human-Interpretable Features,"by reintroducing many of the inductive biases of cnns
through the window attention in the case of swin or transfer learning in the
case of bvt, the model likely overcomes this initial problem.moreover, we would
like to emphasize that the modified models have no negative impact on the
model's performance."
335,Single-subject Multi-contrast MRI Super-resolution via Implicit Neural Representations,"moreover, unlike
conventional super-resolution models trained on a cohort, a personalized model
is of clinical relevance to avoid the danger of potential misdiagnosis caused by
cohort-learned biases."
336,Single-subject Multi-contrast MRI Super-resolution via Implicit Neural Representations,"key reasons behind inr's success can be attributed to
overcoming the low-frequency bias of multi-layer perceptrons (mlp) [21,24,25]."
337,Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"patients with gbm generally have a very poor survival rate;
the median overall survival time is about 14 months [17]; and the overall
survival time is affected by many factors, including patient characteristics
(e.g., age and physical status), tissue histopathology (e.g., cellular density
and nuclear atypia), and molecular pathology (e.g., mutations and gene
expression levels) [1,14,15]."
338,Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"it publicly released preprocessed
restingstate fmri data of 1000 healthy right-handed subjects with an average age
21.5 ± 2.9 years and approximately equal numbers of males and females from the
brain genomics superstruct project (gsp) [5], where the concrete image
acquisition parameters and preprocessing procedures can be found as well."
339,Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"in all
experiments, we conducted five-fold crossvalidation ten times in order to reduce
the effect of sampling bias."
340,A Multi-task Network for Anatomy Identification in Endoscopic Pituitary Surgery,none
341,Intraoperative CT Augmentation for Needle-Based Liver Interventions,none
342,Optical Coherence Elastography Needle for Biomechanical Characterization of Deep Tissue,none
343,Pelvic Fracture Segmentation Using a Multi-scale Distance-Weighted Neural Network,none
344,Towards Multi-modal Anatomical Landmark Detection for Ultrasound-Guided Brain Tumor Resection with Contrastive Learning,none
345,Deep Reinforcement Learning Based System for Intraoperative Hyperspectral Video Autofocusing,"we
randomise the order of the focal powers to reduce systematic bias caused by the
response of the liquid lens."
346,Surgical Video Captioning with Mutual-Modal Concept Alignment,none
347,Imitation Learning from Expert Video Data for Dissection Trajectory Prediction in Endoscopic Surgical Procedure,none
348,Regularized Kelvinlet Functions to Model Linear Elasticity for Image-to-Physical Registration of the Breast,none
349,Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"we kept the size of the training set constant to not introduce size
biases."
350,Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,none
351,FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"ν denote a
penalty factor on these soft constraints, and b is the biases."
352,FocalErrorNet: Uncertainty-Aware Focal Modulation Network for Inter-modal Registration Error Estimation in Ultrasound-Guided Neurosurgery,none
353,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,none
354,A Novel Video-CTU Registration Method with Structural Point Similarity for FURS Navigation,none
355,Cascade Transformer Encoded Boundary-Aware Multibranch Fusion Networks for Real-Time and Accurate Colonoscopic Lesion Segmentation,none
356,Unified Brain MR-Ultrasound Synthesis Using Multi-modal Hierarchical Representations,"we evaluated our method on a dataset of 66
consecutive adult patients with brain gliomas who were surgically treated at the
brigham and women's hospital, boston usa, where both pre-operative 3d t2-space
and pre-dural opening intraoperative us (ius) reconstructed from a tracked
handheld 2d probe were acquired."
357,StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,none
358,X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,none
359,Structure-Preserving Synthesis: MaskGAN for Unpaired MR-CT Translation,"we targeted the age group from 6-24 months since
pediatric patients are more susceptible to ionizing radiation and experience a
greater cancer risk (up to 24% increase) from radiation exposure [7]."
360,Structure-Preserving Synthesis: MaskGAN for Unpaired MR-CT Translation,"furthermore, surgery for craniosynostosis, a birth defect in which the skull
bones fuse too early, typically occurs during this age [5,16]."
361,FreeSeed: Frequency-Band-Aware and Self-guided Network for Sparse-View CT Reconstruction,none
362,Co-learning Semantic-Aware Unsupervised Segmentation for Pathological Image Registration,none
363,Fast Reconstruction for Deep Learning PET Head Motion Correction,none
364,Revealing Anatomical Structures in PET to Generate CT for Attenuation Correction,none
365,An Explainable Deep Framework: Towards Task-Specific Fusion for Multi-to-One MRI Synthesis,"to learn the weight automatically,
we use a trainable fully connected (fc) layer to predict the initial weight ω 0
∈ r n from c.where w and b are weights and bias for the fc layer, = 10 -5 to
avoid dividing 0 in the following equation."
366,Geometric Ultrasound Localization Microscopy,none
367,Reflectance Mode Fluorescence Optical Tomography with Consumer-Grade Cameras,none
368,DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"our neural network is
trained using patches from the ""gold atlas -male pelvis -gentle radiotherapy""
[14] dataset, which is comprised of 18 patients each with a ct, mr t1, and mr t2
volumes."
369,Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"due to the bias in the datasets
collected from different facilities, the performances of all the models are
declined to some extents."
370,Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,none
371,DULDA: Dual-Domain Unsupervised Learned Descent Algorithm for PET Image Reconstruction,"a total of 5 realizations were
simulated and each was trained/tested independently for bias and variance
calculation [15]."
372,DULDA: Dual-Domain Unsupervised Learned Descent Algorithm for PET Image Reconstruction,"the quantitative and bias-variance results
are shown in table 1."
373,DULDA: Dual-Domain Unsupervised Learned Descent Algorithm for PET Image Reconstruction,"both dip method and dulda
have a better crc and bias performance compared with mlem and em-tv."
374,Low-Dose CT Image Super-Resolution Network with Dual-Guidance Feature Distillation and Dual-Path Content Communication,none
375,Non-iterative Coarse-to-Fine Transformer Networks for Joint Affine and Deformable Image Registration,none
376,Trackerless Volume Reconstruction from Intraoperative Ultrasound Images,"first and end stages of the sequences were removed from
the six acquired sequences, as they were considered to be largely stationary,
and aiming to avoid training bias."
377,CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,"the autoactivation is
governed by the learnable weight ν and bias o."
378,InverseSR: 3D Brain MRI Super-Resolution Using a Latent Diffusion Model,"this network ε θ is conditioned on four conditional variables c: age,
gender, ventricular volume and brain volume, which are all introduced by
cross-attention layers [22]."
379,InverseSR: 3D Brain MRI Super-Resolution Using a Latent Diffusion Model,"gender is a binary variable, while the rest of the
covariates are scaled to [0, 1]."
380,Topology-Preserving Computed Tomography Super-Resolution Based on Dual-Stream Diffusion Model,none
381,LightNeuS: Neural Surface Reconstruction in Endoscopy Using Illumination Decline,none
