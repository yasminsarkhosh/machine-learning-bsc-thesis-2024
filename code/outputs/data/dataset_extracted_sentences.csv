,title,extracted_keyword_sent
0,Anatomy-Driven Pathology Detection on Chest X-rays (vol1),"these region boxes are easier to annotate -the physiological shape of a
healthy subject's thorax can be learned relatively easily by medical students
-and generalize better than those of pathologies, such that huge labeled
datasets are available -we propose anatomy-driven pathology detection (adpd), a
pathology detection approach for chest x-rays, trained with pathology
classification labels together with anatomical region bounding boxes as proxies
for pathologies."
1,Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET (vol1),the dataset is composed of 23 oncological patients with different tumor types.
2,Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET (vol1),"dpet data was acquired on a biograph vision quadra for 65 min, over 62 frames."
3,Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET (vol1),"the dataset included the label maps of 7 organs
(bones, lungs, heart, liver, kidneys, spleen, aorta) and one image-derived input
function a(t) [bq/ml] from the descending aorta per patient."
4,Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET (vol1),"further details on
the dataset are presented elsewhere the pet frames and the label map were
resampled to an isotropic voxel size of 2.5 mm."
5,Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET (vol1),"then, the dataset was split
patient-wise into training, validation, and test set, with 10, 4, and 9 patients
respectively."
6,Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET (vol1),"details on the dataset split are available in the supplementary
material (table"
7,AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor (vol1),"however, most deep
learning approaches for segmentation require fully or partially labeled training
datasets, which can be time-consuming and expensive to annotate."
8,AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor (vol1),"-we demonstrate the superiority of ame-cam over state-of-the-art cam
methods in extracting segmentation results from classification networks on the
2021 brain tumor segmentation challenge (brats 2021) we evaluate our method on
the brain tumor segmentation challenge (brats) dataset in this section, we
compare the segmentation performance of the proposed ame-cam
with five state-of-the-art weakly-supervised segmentation methods, namely
grad-cam compared to the unsupervised baseline (ul), c&f is unable to separate
the tumor and the surrounding tissue due to low contrast, resulting in low dice
scores in all experiments."
9,AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor (vol1),"experimental results on the four modalities of the
2021 brats dataset demonstrate the superiority of our approach compared with
other cam-based weakly-supervised segmentation methods."
10,AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor (vol1),"specifically, ame-cam
achieves the highest dice score for all patients in all datasets and modalities."
11,Unsupervised Discovery of 3D Hierarchical Structure with Generative Diffusion Features (vol1),"we compare our method with state-of-the-art unsupervised 3d structure discovery
approaches including clustering using 3d feature learning for the synthetic
datasets, we used k = 2 (background and cell) for level 1, k = 4 (background,
cell, vesicle, mitochondria) for level 2, and k = 8 (background, cell, vesicle,
mitochondria, and 4 small protein aggregates) for level 3 predictions."
12,Unsupervised Discovery of 3D Hierarchical Structure with Generative Diffusion Features (vol1),"table for the brain tumor
segmentation (brats'19) dataset, we use the whole tumor (wt) segmentation mask
for evaluation, which is detectable based on the flair images alone."
13,Unsupervised Discovery of 3D Hierarchical Structure with Generative Diffusion Features (vol1),"the evaluation
metric, as in the brats'19 challenge we perform ablation studies on the brats'19
dataset (table this might be due to the fact that predictive modeling involves
learning from a distribution of images and a model may therefore extract useful
knowledge from a collection of images."
14,Unsupervised Discovery of 3D Hierarchical Structure with Generative Diffusion Features (vol1),"our method outperforms
existing unsupervised segmentation approaches and discovers meaningful
hierarchical concepts on challenging biologically-inspired synthetic datasets
and on the brats brain tumor dataset."
15,Unsupervised Discovery of 3D Hierarchical Structure with Generative Diffusion Features (vol1),"while we tested our approach for
unsupervised image segmentation it is conceivable that it could also be useful
in semisupervised settings and that could be applied to data types other than
images."
16,S 2 ME: Spatial-Spectral Mutual Teaching and Ensemble Learning for Scribble-Supervised Polyp Segmentation (vol1),none
17,Tracking Adaptation to Improve SuperPoint for 3D Reconstruction in Endoscopy (vol1),none
18,Black-box Domain Adaptative Cell Segmentation via Multi-source Distillation (vol1),"dataset and setting: we collect four pathology image datasets to validate our
proposed approach."
19,Black-box Domain Adaptative Cell Segmentation via Multi-source Distillation (vol1),"firstly, we acquire 50 images from a cohort of patients with
triple negative breast cancer (tnbc), which is released by naylor et al
experimental results: to validate our method, we compare it with the following
approaches: (1) cellsegssda in addition, the experimental results also show that
simply combining multiple source data into a traditional single source will
result in performance degradation in some cases, which also proves the
importance of studying multi-source domain adaptation methods."
20,Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning (vol1),"in recent years, deep learning (dl) methods have demonstrated remarkable
performance in detecting and localizing tumors on ultrasound images domain
adaptation (da) has been extensively studied to alleviate the aforementioned
limitations, the goal of which is to reduce the domain gap caused by the
diversity of datasets from different domains to alleviate the problem of
pseudo-label-based uda, in this work, we propose an advanced uda framework based
on self-supervised da with a test-time finetuning network."
21,Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning (vol1),"• our framework is effective at preserving privacy, since it
carries out da using only pre-trained network parameters, without transferring
any patient data."
22,Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning (vol1),"• we applied our framework to the task of segmenting breast
cancer from ultrasound imaging data, demonstrating its superior performance over
competing uda methods."
23,Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning (vol1),"due to the low resolution of
ultrasound images, manual segmentation of breast cancer is challenging even for
expert clinicians, resulting in a sparse number of labeled data."
24,Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning (vol1),"additionally, our framework is
well-suited to a scenario in which access to source domain data is limited, due
to data privacy protocols."
25,PET-Diffusion: Unsupervised PET Enhancement Based on the Latent Diffusion Model (vol1),"the keys of
our upete include 1) compressing the 3d pet images into a lower dimensional
space for reducing the computational cost of diffusion model, 2) adopting the
poisson noise, which is the dominant noise in pet imaging our work had three
main features/contributions: i) proposing a clinicallyapplicable unsupervised
pet enhancement framework, ii) designing three targeted strategies for improving
the diffusion model, including pet image compression, poisson diffusion, and
ct-guided cross-attention, and iii) achieving better performance than
state-of-the-art methods on the collected pet datasets."
26,Cross-Adversarial Local Distribution Regularization for Semi-supervised Medical Image Segmentation (vol1),"therefore, there is a growing interest in
developing semi-supervised learning that leverages both labeled and unlabeled
data to improve the performance of image segmentation models existing
semi-supervised segmentation methods exploit smoothness assumption, e.g., the
data samples that are closer to each other are more likely to to have the same
label."
27,Cross-Adversarial Local Distribution Regularization for Semi-supervised Medical Image Segmentation (vol1),"we have seen such
perturbations being be added to natural input images at data-level in this
paper, we propose a novel cross-adversarial local distribution regularization
for semi-supervised medical image segmentation for smoothness assumption
enhancement"
28,Infusing Physically Inspired Known Operators in Deep Models of Ultrasound Elastography (vol1),"we use publicly available data collected from a breast phantom (model 059, cirs:
tissue simulation & phantom technology, norfolk, va) using an alpinion e-cube
r12 research us machine (bothell, wa, usa)."
29,Infusing Physically Inspired Known Operators in Deep Models of Ultrasound Elastography (vol1),"this data is available online at http://code.sonography.ai
in in vivo data was collected at johns hopkins hospital from patients with liver
cancer during open-surgical rf thermal ablation by a research antares siemens
system using a vf 10-5 linear array with the sampling frequency of 40 mhz and
the center frequency of 6.67 mhz."
30,Infusing Physically Inspired Known Operators in Deep Models of Ultrasound Elastography (vol1),"we selected 600 rf frame pairs of this
dataset for the training of the networks."
31,SLPD: Slide-Level Prototypical Distillation for WSIs (vol1),none
32,PROnet: Point Refinement Using Shape-Guided Offset Map for Nuclei Instance Segmentation (vol1),"(4) ablation and evaluation studies on two public datasets demonstrate our
model's ability to outperform state-of-the-art techniques not only with ideal
labels but also with shifted labels."
33,TPRO: Text-Prompting-Based Weakly Supervised Histopathology Tissue Segmentation (vol1),none
34,MetaLR: Meta-tuning of Learning Rates for Transfer Learning in Medical Imaging (vol1),"transfer learning has become a standard practice in medical image analysis as
collecting and annotating data in clinical scenarios can be costly."
35,MetaLR: Meta-tuning of Learning Rates for Transfer Learning in Medical Imaging (vol1),"the
pre-trained parameters endow better generalization to dnns than the models
trained from scratch diversity between domains and tasks and privacy concerns
related to pre-training data."
36,MetaLR: Meta-tuning of Learning Rates for Transfer Learning in Medical Imaging (vol1),"2) we enhance metalr
with a proportional hyper-lr and a validation scheme using batched training data
to improve the algorithm's stability and efficacy."
37,DAS-MIL: Distilling Across Scales for MIL Classification of Histological WSIs (vol1),"( it is available on the gdc data transfer portal and comprises two subsets of
cancer: lung adenocarcinoma (luad) and lung squamous cell carcinoma (lusc),
counting 541 and 513 wsis, respectively."
38,vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images (vol1),"medical image segmentation often relies on supervised model training secondly,
the resulting models may not generalize well to unseen data domains."
39,vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images (vol1),"ssl pre-trains a model backbone to extract informative
representations from unlabeled data."
40,vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images (vol1),"pre-training the backbone in a self-supervised manner enables scaling to larger
datasets across multiple data and task domains."
41,vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images (vol1),"in medical imaging, this is
particularly useful given the growing number of available datasets."
42,vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images (vol1),"second, we
employ vox2vec to pre-train a fpn architecture on a diverse collection of six
unannotated datasets, totaling over 6,500 ct images of the thorax and abdomen."
43,vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images (vol1),"finally, we compare the
pretrained model with the baselines on 22 segmentation tasks on seven ct
datasets in three setups: linear probing, non-linear probing, and fine-tuning."
44,vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images (vol1),"the mean value and standard deviation of dice score across 5 folds on the btcv
dataset for all models in all evaluation setups are presented in table
nevertheless, vox2vec-fpn significantly outperforms other models in linear and
non-linear regimes."
45,vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images (vol1),"we
reproduce the key results on msd challenge ct datasets, which contain tumor and
organ segmentation tasks."
46,vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images (vol1),"by pre-training a fpn backbone to
extract informative representations from unlabeled data, our method scales to
large datasets across multiple task domains."
47,vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images (vol1),"we plan to investigate further how the performance of vox2vec
scales with the increasing size of the pre-training dataset and the pre-trained
architecture size."
48,vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images (vol1),"another interesting research direction is exploring the
effectiveness of vox2vec with regard to domain adaptation to address the
challenges of domain shift between different medical imaging datasets obtained
from different sources."
49,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation (vol1),"we
evaluate our proposed method on two multi-domain datasets: 1)."
50,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation (vol1),"the infant brain
mri dataset for cross-age segmentation; 2)."
51,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation (vol1),"the brats2018 dataset for
cross-grade tumor segmentation."
52,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation (vol1),"our proposed method was evaluated using two medical image segmentation da
datasets."
53,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation (vol1),"the first dataset, i.e., cross-age infant segmentation the first
dataset is for infant brain segmentation (white matter, gray matter and
cerebrospinal fluid)."
54,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation (vol1),"to build the cross-age dataset, we take advantage 10 brain
mris of 6-month-old from iseg2019 the 2nd dataset is for brain tumor
segmentation (enhancing tumor, peritumoral edema and necrotic and non-enhancing
tumor core), which has 285 mri samples (210 hgg and 75 lgg)."
55,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation (vol1),"we also visualize
the segmentation results on a typical test sample of the infant brain dataset in
fig."
56,Gall Bladder Cancer Detection from US Images with only Image Level Labels (vol1),"gallbladder cancer detection in ultrasound images: we use the public gbc us
dataset note that, we use only the image labels for training."
57,Gall Bladder Cancer Detection from US Images with only Image Level Labels (vol1),"polyp detection in colonoscopy images: we use the publicly available
kvasir-seg since the patient information is not available with the data, we use
random stratified splitting for 5-fold cross-validation."
58,Structured State Space Models for Multiple Instance Learning in Digital Pathology (vol1),"extensive experiments on three publicly
available datasets show the potential of such models for the processing of
gigapixel-sized images, under both weakly and multi-task schemes."
59,Structured State Space Models for Multiple Instance Learning in Digital Pathology (vol1),"camelyon16 tcga-luad is a tcga lung adenocarcinoma dataset that contains 541
wsis along with genetic information about each patient."
60,Structured State Space Models for Multiple Instance Learning in Digital Pathology (vol1),"we obtained genetic
information for this cohort using xena browser tcga-rcc is a tcga dataset for
three kidney cancer subtypes (denoted kich, kirc, and kirp)."
61,Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision (vol1),"this information can be leveraged to assess treatment response, e.g., by
analyzing the evolution of size and morphology for a given tumor in practice,
the development of automatic and reliable lesion tracking solutions is hindered
by the complexity of the data (over different modalities), the absence of large,
annotated datasets, and the difficulties associated with lesion identification
(i.e., varying sizes, poses, shapes, and sparsely distributed locations)."
62,Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision (vol1),"furthermore, a significant
focus and contribution of our research is the experimental study at a very large
scale: we (1) train a pixel-wise self-supervised system using a very large and
diverse dataset of 52,487 ct volumes and (2) evaluate on two publicly available
datasets."
63,Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision (vol1),"notably, one of the datasets, nlst, presents challenging cases with
68% of lesions being very small (i.e., radius < 5 mm)."
64,Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision (vol1),"the method is generic,
it does not require expert annotations or longitudinal data for training and can
generalize to different types of tumors/organs/modalities."
65,Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision (vol1),"through large-scale experiments and validation on two longitudinal datasets, we
highlight the superiority of the proposed method in comparison to
state-of-theart."
66,Geometry-Invariant Abnormality Detection (vol1),"most recent approaches
have focused on improvements in performance rather than flexibility, thus
limiting approaches to specific input types -little research has been carried
out to generate models unhindered by variations in data geometries."
67,Geometry-Invariant Abnormality Detection (vol1),"often,
research assumes certain similarities in data acquisition parameters, from image
dimensions to voxel dimensions and fields-of-view (fov)."
68,Geometry-Invariant Abnormality Detection (vol1),"these restrictions are
then carried forward during inference unsupervised methods have become an
increasingly prominent field for automatic anomaly detection by eliminating the
necessity of acquiring accurately labelled data even though these methods are
state-of-the-art, they have stringent data requirements, such as having a
consistent geometry of the input data, e.g., in a whole-body imaging scenario,
it is not possible to crop a region of interest and feed it to the algorithm, as
this cropped region will be wrongly detected as an anomaly."
69,Geometry-Invariant Abnormality Detection (vol1),"through adapting the vq-vae transformer approach in the proposed model was
trained on the data described in sect."
70,Geometry-Invariant Abnormality Detection (vol1),"generally, the variation scanners and acquisition protocols can cause failures
in models trained on data from single sources."
71,Geometry-Invariant Abnormality Detection (vol1),"not only
does the proposed model showcase strong and statistically-significant
performance improvements on varying image resolutions and fov, but also on
whole-body data."
72,Geometry-Invariant Abnormality Detection (vol1),"through this, we demonstrate that one can improve the
adaptability and flexibility to varying data geometries while also improving
performance."
73,Geometry-Invariant Abnormality Detection (vol1),"such flexibility also increases the pool of potential training
data, as they dont require the same fov."
74,Interpretable Medical Image Classification Using Prototype Learning and Privileged Information (vol2),data.
75,Interpretable Medical Image Classification Using Prototype Learning and Privileged Information (vol2),"the proposed approach is evaluated using the publicly available lidc-idri
dataset consisting of 1018 clinical thoracic ct scans from patients with
non-small cell lung cancer (nsclc) experiment designs."
76,ArSDM: Colonoscopy Images Synthesis with Adaptive Refinement Semantic Diffusion Models (vol2),none
77,Synthetic Augmentation with Large-Scale Unconditional Pre-training (vol2),datasets.
78,Synthetic Augmentation with Large-Scale Unconditional Pre-training (vol2),"we employ three public datasets of histopathology images during the
large-scale pre-training procedure."
79,Synthetic Augmentation with Large-Scale Unconditional Pre-training (vol2),"the first one is the h&e breast cancer
dataset to replicate a scenario where only a small annotated dataset is
available for training, we have opted to utilize a subset of 5,000 (5%) samples
for finetuning."
80,Synthetic Augmentation with Large-Scale Unconditional Pre-training (vol2),"it is worth
noting that the labels for these samples have been kept, which allows the
fine-tuning process to be guided by labeled data, leading to better predictions
on the specific task or domain being trained."
81,Synthetic Augmentation with Large-Scale Unconditional Pre-training (vol2),"by ensuring that the fine-tuning
process is representative of the entire dataset through even sampling from each
tissue type, we can eliminate bias towards any particular tissue type."
82,Synthetic Augmentation with Large-Scale Unconditional Pre-training (vol2),"the related data use
declaration and acknowledgment can be found in our supplementary materials."
83,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation (vol2),"a must-have ingredient for training a deep neural network (dnn) is a large
number of labelled data that is not always available in real-world applications."
84,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation (vol2),"this challenge of data annotation becomes even worse for medical image
segmentation tasks that require pixel-level annotation by experts."
85,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation (vol2),"data
augmentation (da) is a recognized approach to tackle this challenge."
86,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation (vol2),"common da
strategies create new samples by using predefined transformations such as
rotation, translation, and colour jitter to existing data, where the performance
gains heavily relies on the choice of augmentation operations and parameters to
mitigate this reliance, recent efforts have focused on learning optimal
augmentation operations for a given task and dataset however, to date, all
existing approaches to learning deformable registrationbased da assume a perfect
alignment of image pairs to learn the transformations."
87,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation (vol2),"this allows us to add shape
diversity to the objects of interest in an image regardless of their positions
or sizes, eventually facilitating transferring the learned variations across
datasets."
88,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation (vol2),"we demonstrated the effectiveness of the presented object-centric
diffeomorphic augmentation in kidney tumour segmentation, including using shape
variations of kidney tumours learned from the same dataset (kits we focus on da
for tumour segmentation because tumours can occur at different
locations of an organ with substantially different orientations and sizes."
89,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation (vol2),"inspired from where the
integration can be done via a specialized solver generative modeling: the data
generation process can be described as: where z is the latent variable assumed
to follow an isotropic gaussian prior, p φ (θ|z) is modeled by a neural network
parameterized by φ, and p(x tgt |θ, x src ) follows the deformable
transformation as described in equation ( we define variational approximations
of the posterior density as q ψ (z|x src , x tgt ), modeled by a convolutional
neural network that expects two inputs x src and x tgt ."
90,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation (vol2),"figure data: we then used g(z) to generate deformation-based augmentations to
increase
the size and diversity of training samples for kidney tumour segmentation on
kits."
91,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation (vol2),"to assess the effect of augmentations on different sizes of labelled data,
we considered training using 25%, 50%, 75%, and 100% of the kits training set."
92,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation (vol2),"we considered two da scenarios: augment with transformations learned from kits
(within-data augmentation) versus from lits (cross-data augmentation)."
93,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation (vol2),"as demonstrated by the
experimental results, this allows us to not only introduce new variations to
unfixed objects like tumours in an image but also transfer the knowledge of
shape variations across datasets."
94,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation (vol2),"in the long term, it would be interesting to explore ways to
transfer knowledge about more general forms of variations across datasets."
95,Centroid-Aware Feature Recalibration for Cancer Grading in Pathology Images (vol2),"cafe
module adjusts the input embedding vectors with respect to the class centroids
(i.e., training data distribution)."
96,Centroid-Aware Feature Recalibration for Cancer Grading in Pathology Images (vol2),"assuming that the classes are well separated
in the feature space, the centroid embedding vectors can serve as reference
points to represent the data distribution of the training data."
97,Centroid-Aware Feature Recalibration for Cancer Grading in Pathology Images (vol2),"during inference, we fix the centroid
embedding vectors so that the recalibrated embedding vectors do not vary much
compared to the input embedding vectors even though the data distribution
substantially changes, leading to improved stability and robustness of the
feature representation."
98,Centroid-Aware Feature Recalibration for Cancer Grading in Pathology Images (vol2),"the experimental results demonstrate that cafenet achieves the
state-of-the-art cancer grading performance in colorectal cancer grading
datasets."
99,Centroid-Aware Feature Recalibration for Cancer Grading in Pathology Images (vol2),"two publicly available colorectal cancer datasets we conducted a series of
comparative experiments to evaluate the effectiveness
of cafenet for cancer grading, in comparison to several existing methods: 1)
three dcnnbased models: resnet we evaluated the performance of colorectal cancer
grading by the proposed
cafenet and other competing models using five evaluation metrics, including
accuracy (acc), precision, recall, f1-score (f1), and quadratic weighted kappa
(κ w )."
100,Centroid-Aware Feature Recalibration for Cancer Grading in Pathology Images (vol2),"in the experiments on colorectal cancer datasets
against several competing models, the proposed network demonstrated that it has
a better learning capability as well as a generalizability in classifying
pathology images into different cancer grades."
101,Centroid-Aware Feature Recalibration for Cancer Grading in Pathology Images (vol2),"however, the experiments were
only conducted on two public colorectal cancer datasets from a single institute."
102,Explaining Massive-Training Artificial Neural Networks in Medical Image Analysis Task Through Visualizing Functions Within the Models (vol2),"our xai technique was applied to explain the mtann model's decision in a liver
tumor segmentation task in addition, since most liver tumors' shape is
ellipsoidal, the liver tumors can also be enhanced by the hessian-based method
and utilized in the model to improve the performance seven cases and 24 cases in
the dynamic contrast-enhanced ct scans dataset were used for training and
testing, respectively."
103,TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification (vol2),"while most multi-phase liver lesion classification studies
use datasets with no more than three phases (without dl phase for its difficulty
of collection) or no more than six lesion classes, we validate the whole
framework on an in-house dataset with four phases of abdominal ct and seven
classes of liver lesions."
104,TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification (vol2),"considering the disproportion of axial lesion slice
number and the relatively small scale of the dataset, we adopt a 2-d network in
classification part instead of 3-d in pre-processing part and achieve a 90.9%
accuracy."
105,Adaptive Region Selection for Active Learning in Whole Slide Image Semantic Segmentation (vol2),"we test our method using a breast cancer metastases segmentation
task on the public camelyon16 dataset and demonstrate that determining the
selected regions individually provides greater flexibility and efficiency than
selecting regions with a uniform predefined shape and size, given the
variability in histological tissue structures."
106,Adaptive Region Selection for Active Learning in Whole Slide Image Semantic Segmentation (vol2),"to validate our segmentation framework, we first
train on the fully-annotated data (average performance of five repetitions
reported)."
107,Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation (vol2),"in this work, we focus on the explainability of the
classification of brain tumours using probe-based confocal laser endomicroscopy
(pcle) data."
108,Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation (vol2),"performance evaluation on pcle data shows that our improved
explainability method outperforms the sota."
109,Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation (vol2),dataset.
110,Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation (vol2),"the developed explainability framework has been validated on an in vivo
and ex vivo pcle dataset of meningioma, glioblastoma and metastases of an
invasive ductal carcinoma (idc)."
111,Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation (vol2),"our dataset includes 38 meningioma
videos, 24 glioblastoma and 6 idc."
112,Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation (vol2),"the data has been curated to remove
noisy images and similar frames."
113,Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation (vol2),"this resulted in a training dataset of 2500
frames per class (7500 frames in total) and a testing dataset of the same size."
114,Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation (vol2),"the dataset is split into a training and testing subset, with the division done
on the patient level."
115,Continual Learning for Abdominal Multi-organ and Tumor Segmentation (vol2),"in contrast, deep learning models suffer
from catastrophic forgetting the medical domain faces a similar problem: the
ability to dynamically extend a model to new classes is critical for multiple
organ and tumor segmentation, wherein the key obstacle lies in mitigating
'forgetting.' a typical strategy involves retaining some previous data."
116,Continual Learning for Abdominal Multi-organ and Tumor Segmentation (vol2),"q1: can
we relieve the forgetting problem without needing previous data and annotations?"
117,Continual Learning for Abdominal Multi-organ and Tumor Segmentation (vol2),"first, inspired by knowledge distillation methods in
continual learning we focus on organ/tumor segmentation because it is one of the
most critical tasks in medical imaging segment liver tumors in the lits dataset."
118,Continual Learning for Abdominal Multi-organ and Tumor Segmentation (vol2),"on the private dataset, the learning trajectory is to first segment 13 organs,
followed by continual segmentation of three gastrointestinal tracts and four
cardiovascular system structures."
119,Continual Learning for Abdominal Multi-organ and Tumor Segmentation (vol2),"numerical results on an in-house dataset and two public
datasets demonstrate that the proposed method outperforms the continual learning
baseline methods in the challenging multiple organ and tumor segmentation tasks."
120,Efficient Subclass Segmentation in Medical Images (vol2),"this segmentation result is supervised by the
superposition of the pseudo label map z pse and subclass labels z, with
weighting factor α: the intuition behind this framework is to simultaneously
leverage the information from both unlabeled and labeled data by incorporating a
more robust supervision from transform-invariant pseudo labels."
121,Towards AI-Driven Radiology Education: A Self-supervised Segmentation-Based Framework for High-Precision Medical Image Editing (vol2),"however, designing educational materials solely
based on real-world data poses several challenges."
122,Towards AI-Driven Radiology Education: A Self-supervised Segmentation-Based Framework for High-Precision Medical Image Editing (vol2),"future challenges
include improving scalability with fewer manual operations, validating
segmentation maps from a more objective perspective, and comparing our proposed
algorithm with existing methods, such as those based on superpixels data use
declaration and acknowledgment: the pelvic mri and chest ct datasets were
collected from the national cancer center hospital."
123,Towards AI-Driven Radiology Education: A Self-supervised Segmentation-Based Framework for High-Precision Medical Image Editing (vol2),"the study, data use, and
data protection procedures were approved by the ethics committee of the national
cancer center, tokyo, japan (protocol number 2016-496)."
124,COLosSAL: A Benchmark for Cold-Start Active Learning for 3D Medical Image Segmentation(vol2),"however, we observe that typiclust (shown as
orange) achieves comparable or superior performance compared to random selection
across all tasks in our benchmark, whereas other approaches can significantly
under-perform on certain tasks, especially challenging ones like the liver
dataset."
125,FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation (vol2),training data.
126,FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation (vol2),"the real-world dataset used in experiments is provided by the
fets challenge organizer, which is the training set of the whole dataset about
brain tumor segmentation."
127,FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation (vol2),"in order to evaluate the performance of fedgrav, we
partition the dataset composed of 341 data samples experiment results on the
cifar-10."
128,FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation (vol2),"we first validate the proposed method on the
cifar-10 dataset."
129,FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation (vol2),table experiment results on miccai fets2021 training dataset.
130,FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation (vol2),"in order to verify the robustness of our method and its performance in
real-world data, we conduct the experiment on the miccai fets2021 training
dataset."
131,FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation (vol2),"we evaluated our
method on cifar-10 and real-world miccai federated tumor segmentation challenge
(fets) datasets, and the superior results demonstrated the effectiveness and
robustness of our fedgrav."
132,Faithful Synthesis of Low-Dose Contrast-Enhanced Brain MRI Scans Using Noise-Preserving Conditional GANs (vol2),"complementary to the
development of higher relaxivity contrast agents in recent years, generative
models have been used to overcome data scarcity in the computer vision and
medical imaging community."
133,Faithful Synthesis of Low-Dose Contrast-Enhanced Brain MRI Scans Using Noise-Preserving Conditional GANs (vol2),"in particular, for image-to-image translation
tasks, these conditional gans have been successfully applied using paired with
this in mind, the contributions of this work are as follows: -synthesis of gbca
behavior at various doses using conditional gans, -loss enabling interpolation
of dose levels present in training data, -noise-preserving content loss function
to generate realistic synthetic images."
134,A Spatial-Temporal Deformable Attention Based Framework for Breast Lesion Detection in Videos (vol2),"we
conduct extensive experiments on a public breast lesion ultrasound video
dataset, named bluvd-186"
135,DeDA: Deep Directed Accumulator (vol2),none
136,OpenAL: An Efficient Deep Active Learning Framework for Open-Set Pathology Image Classification (vol2),"deep learning techniques have achieved unprecedented success in the field of
medical image classification, but this is largely due to large amount of
annotated data active learning (al) is an effective approach to address this
issue from a data selection perspective, which selects the most informative
samples from an unlabeled sample pool for experts to label and improves the
performance of the trained model with reduced labeling cost recently, ning et
al."
137,OpenAL: An Efficient Deep Active Learning Framework for Open-Set Pathology Image Classification (vol2),"we conducted two
experiments with different matching ratios (ratio of the number of target class
samples to the total number of samples) on a public 9-class colorectal cancer
pathology image dataset."
138,OpenAL: An Efficient Deep Active Learning Framework for Open-Set Pathology Image Classification (vol2),"to validate the effectiveness of openal, we conducted two experiments with
different matching ratios (the ratio of the number of samples in the target
class to the total number of samples) on a 9-class public colorectal cancer
pathology image classification dataset (nct-crc-he-100k) metrics."
139,SFusion: Self-attention Based N-to-One Multimodal Fusion Block (vol2),"as a
data-dependent fusion strategy, sfusion can automatically learn the latent
correlations between different modalities and builds a shared feature
representation."
140,SFusion: Self-attention Based N-to-One Multimodal Fusion Block (vol2),"the entire fusion process is based on available data without
simulating missing modalities."
141,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification (vol2),"long-tailed problem is usually caused by differences in incidence
rate and difficulties in data collection."
142,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification (vol2),"some diseases are common while others
are rare, making it difficult to collect balanced data to tackle the challenge
of learning unbiased classifiers with imbalanced data, many previous works focus
on three main ideas, including re-sampling data recently, contrastive learning
(cl) methods pose great potential for representation learning when trained on
imbalanced data to address the above issues, we propose a class-enhancement
contrastive learning (ecl) method for skin lesion classification, differences
between scl and ecl are illustrated in fig."
143,SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation (vol2),datasets and pre-trained model.
144,SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation (vol2),"we conducted experiments on automating liver
tumor segmentation in contrast-enhanced ct scans, a crucial task in liver cancer
diagnosis and surgical planning collecting large-scale data from our hospital
and training a new model will be expensive."
145,SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation (vol2),"we collected a dataset from our in-house hospital comprising
941 ct scans with eight categories: hepatocellular carcinoma, cholangioma,
metastasis, hepatoblastoma, hemangioma, focal nodular hyperplasia, cyst, and
others."
146,SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation (vol2),"we utilized a pre-trained model for liver
segmentation using supervised learning on two public datasets metrics."
147,UniSeg: A Prompt-Driven Universal Segmentation Model as Well as A Strong Representation Learner (vol3),"thanks to both designs,
our uniseg achieves superior performance on 11 upstream datasets and two
downstream datasets, setting a new record."
148,UniSeg: A Prompt-Driven Universal Segmentation Model as Well as A Strong Representation Learner (vol3),"in our future work, we plan to design
a universal model that can effectively process multiple dimensional data."
149,Cross-Modulated Few-Shot Image Generation for Colorectal Tissue Classification (vol3),"however, shortage of pathologists worldwide along with the complexity of
histopathological data make this task time consuming and challenging."
150,Cross-Modulated Few-Shot Image Generation for Colorectal Tissue Classification (vol3),"the corresponding dataset we conduct experiments on human colorectal cancer
dataset"
151,Structure-Preserving Instance Segmentation via Skeleton-Aware Distance Transform (vol3),"dataset and
evaluation metric."
152,Structure-Preserving Instance Segmentation via Skeleton-Aware Distance Transform (vol3),we use the gland segmentation challenge dataset
153,DAST: Differentiable Architecture Search with Transformer for 3D Medical Image Segmentation (vol3),"to verify the effectiveness and generalization of our searched architectures
from dast, we validate the searched architecture (from pancreas data set) on
this challenging task."
154,Pre-trained Diffusion Models for Plug-and-Play Medical Image Enhancement (vol3),"however, acquiring such paired data is challenging in real clinical scenarios."
155,Pre-trained Diffusion Models for Plug-and-Play Medical Image Enhancement (vol3),"although it is possible to simulate low-quality images from high-quality images,
the models derived from such data may have limited generalization ability when
applied to real data recently, pre-trained diffusion models in this paper, we
aim at addressing the limitations of existing image enhancement methods and the
scarcity of pre-trained diffusion models for medical images."
156,Evidence Reconciled Neural Network for Out-of-Distribution Detection in Medical Images (vol3),"detecting out-of-distribution (ood) samples is crucial in real-world
applications of machine learning, especially in medical imaging analysis where
misdiagnosis can pose significant risks deep learning-based ood detection
methods with uncertainty estimation, such as evidential deep learning (edl) to
address this limitation, we propose an evidence reconciled neural network
(ernn), which aims to reliably detect those samples that are similar to the
training data but still with different distributions (near ood), while maintain
accuracy for in-distribution (id) classification."
157,Evidence Reconciled Neural Network for Out-of-Distribution Detection in Medical Images (vol3),"extensive experiments on both isic2019 dataset and in-house pancreas tumor
dataset demonstrate that the proposed ernn significantly improves the
reliability and accuracy of ood detection for clinical applications."
158,Evidence Reconciled Neural Network for Out-of-Distribution Detection in Medical Images (vol3),"in this section, we conduct a detailed ablation study to clearly demonstrate the
effectiveness of our major technical components, which consist of evaluation of
evidential head, evaluation of the proposed evidence reconcile block on both
isic 2019 dataset and our in-house pancreas tumor dataset."
159,Scale-Aware Test-Time Click Adaptation for Pulmonary Nodule and Mass Segmentation (vol3),none
160,WeakPolyp: You only Look Bounding Box for Polyp Segmentation (vol3),none
161,Shifting More Attention to Breast Lesion Segmentation in Ultrasound Videos (vol3),none
162,FocalUNETR: A Focal Transformer for Boundary-Aware Prostate Segmentation Using CT Images (vol3),none
163,Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation (vol3),"for instance, structures such as the left ventricle and the myocardium wall in
the ultrasound datasets have large components of their contour oriented along
the vertical direction which allows the univariate and bivariate models to
perform as well, if not better, than the asymmetric model."
164,Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation (vol3),"the contrast between the left ventricle and myocardium in
the images of the private cardiac us dataset is small, which explains why the
simpler univariate and bivariate models perform well."
165,Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation (vol3),"this is why on very noisy
and poorly contrasted data, the univariate or the bivariate model might be
preferable to using the asymmetric model."
166,Anatomical-Aware Point-Voxel Network for Couinaud Segmentation in Liver CT (vol3),"extensive experiments on two publicly available datasets named
3dircadb"
167,HENet: Hierarchical Enhancement Network for Pulmonary Vessel Segmentation in Non-contrast CT Images (vol3),none
168,Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels (vol3),none
169,Anti-adversarial Consistency Regularization for Data Augmentation: Applications to Robust Medical Image Segmentation (vol4),"we present a novel data augmentation method for semantic segmentation using a
flexible anti-adversarial consistency regularization."
170,Anti-adversarial Consistency Regularization for Data Augmentation: Applications to Robust Medical Image Segmentation (vol4),"extensive
experiments with various backbones and datasets confirm the effectiveness of our
method."
171,Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk (vol4),none
172,Learning Reliability of Multi-modality Medical Images for Tumor Segmentation via Evidence-Identified Denoising Diffusion Probabilistic Models (vol4),none
173,Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network (vol4),none
174,SimPLe: Similarity-Aware Propagation Learning for Weakly-Supervised Breast Cancer Segmentation in DCE-MRI (vol4),dataset.
175,SimPLe: Similarity-Aware Propagation Learning for Weakly-Supervised Breast Cancer Segmentation in DCE-MRI (vol4),"we evaluated our method on an in-house breast dce-mri dataset collected
from the cancer center of sun yat-sen university."
176,Conditional Diffusion Models for Weakly Supervised Medical Image Segmentation (vol4),"for both datasets,
we repeat the evaluation protocols for four times and report the average metrics
and their standard deviation on test set."
177,Conditional Diffusion Models for Weakly Supervised Medical Image Segmentation (vol4),"we benchmark our methods against previous
wsss works on two datasets in table from the results, we can make several key
observations."
178,Conditional Diffusion Models for Weakly Supervised Medical Image Segmentation (vol4),"firstly, our proposed method, even without classifier guidance,
outperform all other wsss methods including the classifier guided diffusion
model cg-diff on both datasets for all three metrics."
179,Conditional Diffusion Models for Weakly Supervised Medical Image Segmentation (vol4),"secondly, all wsss methods have performance
drop on kidney dataset compared with brats dataset."
180,Conditional Diffusion Models for Weakly Supervised Medical Image Segmentation (vol4),"this demonstrates that the
kidney segmentation task is a more challenging task for wsss than brain tumor
task, which may be caused by the small training size and diverse appearance
across slices in the chaos dataset."
181,Conditional Diffusion Models for Weakly Supervised Medical Image Segmentation (vol4),"the default setting is cg-cdm on
brats dataset with q = 400, r = 10, τ = 0.95, and s = 10."
182,DBTrans: A Dual-Branch Vision Transformer for Multi-Modal Brain Tumor Segmentation (vol4),"however, the data in
each slice is related to three views, discarding any of them may lead to the
loss of local information, which may cause the degradation of performance the
contributions of our proposed method can be described as follows: 1) based on
transformer, we construct dual-branch encoder and decoder layers that assemble
two attention mechanisms, being able to model close-window and distant-window
dependencies without any extra computational cost."
183,DBTrans: A Dual-Branch Vision Transformer for Multi-Modal Brain Tumor Segmentation (vol4),"3) for the multi-modal data adopt in the task of samm-bts, we
improve the channel attention mechanism in se-net by applying se-weights to
features from both branches in the encoder and decoder layers."
184,DBTrans: A Dual-Branch Vision Transformer for Multi-Modal Brain Tumor Segmentation (vol4),datasets.
185,M-GenSeg: Domain Adaptation for Target Modality Tumor Segmentation with Annotation-Efficient Supervision (vol4),none
186,Edge-Aware Multi-task Network for Integrating Quantification Segmentation and Uncertainty Prediction of Liver Tumor on Multi-modality Non-contrast MRI (vol4),none
187,RCS-YOLO: A Fast and High-Accuracy Object Detector for Brain Tumor Detection (vol4),"however, the increasingly complex network
architecture in cnn-based models, such as resnet repvgg to evaluate the proposed
rcs-yolo model, we used the brain tumor detection 2020
dataset (br35h) to highlight the accuracy and rapidity of the proposed model for
the detection
of brain tumor medical image data set, table it can be seen that rcs-yolo with
the advantages of incorporating the rcs-osa module performs well."
188,RCS-YOLO: A Fast and High-Accuracy Object Detector for Brain Tumor Detection (vol4),"evaluation of the brain mri dataset
shows superior performance for brain tumor detection in terms of both speed and
precision, as compared to yolov6, yolov7, and yolov8 models."
189,Category-Level Regularized Unlabeled-to-Labeled Learning for Semi-supervised Prostate Segmentation with Multi-site Unlabeled Data (vol4),"recently, deep
learningbased approaches have greatly improved the accuracy and efficiency of
automatic prostate mri segmentation regarding quantity , the abundance of
unlabeled data serves as a way to regularize the model and alleviate overfitting
to the limited labeled data."
190,A Sheaf Theoretic Perspective for Robust Prostate Segmentation (vol4),"deep learning models are
susceptible to textural shifts and artefacts which is often seen in mri due to
variations in the complex acquisition protocols across multiple sites the most
common approach to tackle domain shifts is with data augmentation the
contributions of this paper are summarized as follows: 1."
191,MedNeXt: Transformer-Driven Scaling of ConvNets for Medical Image Segmentation (vol4),"transformers the convnext architecture marries the scalability and long-range
spatial representation learning capabilities of vision in this work, we maximize
the potential of a convnext design while uniquely addressing challenges of
limited datasets in medical image segmentation."
192,Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images (vol4),"this is primarily due to their
ability to learn informative hierarchical features directly from data."
193,Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images (vol4),"in the proposed kspc-net, a cnn is employed
to learn directly from the data to produce the pixel-wise bandwidth feature map
and initial segmentation map, which are used to define the tuning parameters in
the kspc module."
194,Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images (vol4),"more
specifically, we use the classic unet the dataset is from the hecktor challenge
in miccai 2021 (head and neck tumor
segmentation challenge)."
195,Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images (vol4),"the hecktor training dataset consists of 224 patients
diagnosed with oropharyngeal cancer in this paper, we present a novel network,
kspc-net, for the segmentation in 2d
pet images, which integrates kspc into the unet architecture in an end-toend
differential manner."
196,Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images (vol4),"promising performance was achieved by
our proposed kspc-net compared to the state-of-the-art approaches on the miccai
2021 challenge dataset (hecktor)."
197,A2FSeg: Adaptive Multi-modal Fusion Network for Medical Image Segmentation (vol4),"-we conduct experiments on the
brats 2020 dataset and achieve the sota segmentation performance, having a mean
dice core of 89.79% for the whole tumor, 82.72% for the tumor core, and 66.71%
for the enhancing tumor."
198,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping (vol4),"notably, tumor types have been found to be strongly
correlated with the prognosis of diffuse glioma our method is evaluated using
pre-operative multimodal mr brain images of 1726 diffuse glioma patients
collected from cooperation hospitals and a public dataset brats2019 diffuse
glioma can be classified into three histological types: the
oligodendroglioma, the astrocytoma, and the glioblastoma the tumor subtyping
network is trained independently before being integrated into the backbone."
199,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping (vol4),"to
solve the inherent issue of imbalanced tumor type in the training data collected
in clinic, a novel ordinal manifold mixup based feature augmentation is applied
in the training of the tumor subtyping network."
200,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping (vol4),"it is worth noting that the
ground truth of tumor types, which is determined after craniotomy, is available
in the training data, while for the testing data, tumor types are not required,
because tumor-type-related features can be learned from the pre-operative
multimodal mr brain images."
201,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping (vol4),"in the in-house dataset, the proportions of the three tumor types are
20.9% (oligodendroglioma), 28.7% (astrocytoma), and 50.4% (glioblastoma), which
is consistent with the statistical report in in the original manifold mixup
where y k i and y k j stand for the labels of the
k-th tumor type of the i-th and j-th patients, respectively, and λ ∈ [0, 1] is a
weighting factor."
202,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping (vol4),"in our experiment, both in-house and public datasets are used to evaluate our
method."
203,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping (vol4),"specifically, the in-house dataset collected in cooperation hospitals
contains pre-operative multimodal mr images, including t1, t1 contrast enhanced
(t1c), t2, and flair, of 1726 patients (age 49.7 ± 13.1) with confirmed diffuse
glioma types."
204,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping (vol4),"besides the inhouse
dataset, a public dataset brats2019, including pre-operative multimodal mr
images of 210 non-censored patients (age 61.4 ± 12.2), is adopted as the
external independent testing dataset."
205,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping (vol4),"all images of the in-house and brats2019
datasets go through the same pre-processing stage, including image normalization
and affine transformation to mni152 besides our method, four state-of-the-art
methods, including random forest based method (rf) where d = {x 1 , ..., x n }
is the dataset containing all patients, t i and t j are ground truth of survival
times of the i-th and j-th patients, r i and r j are the days predicted by rf,
mcsp, and pgsp or risks predicted by the deep cox proportional hazard models
(i.e., deepconvsurv and our method), 1 x<y = 1 if x < y, else 0, and δ i = 0 or
1 when the i-th patient is censored or non-censored."
206,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping (vol4),"as rf, mcsp, and pgsp
cannot use the censored data in the in-house dataset, 80% of the non-censored
data (594 patients) are randomly selected as the training data, and the rest 20%
non-censored data (149 patients) are for testing."
207,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping (vol4),"so besides the 80% non-censored patients, all censored data (983
patients) are also included in the training data."
208,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping (vol4),"for the in-house dataset, the
resulting c-indices are 0.744 (baseline-1) and 0.735 (baseline-2)."
209,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping (vol4),"for the
external independent testing dataset brats2019, the resulting c-indices are
0.738 (baseline-1) and 0.714 (baseline-2), and our method still has more than 6%
improvement comparing with baseline-2."
210,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping (vol4),"both in-house and public
datasets containing 1936 patients were used in the experiment."
211,Medical Boundary Diffusion Model for Skin Lesion Segmentation (vol4),none
212,H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation (vol4),"with the emergence of multimodal datasets (e.g., brats in addition to the
progress on the fusion of multimodal features, improving the model
representation ability is also an effective way to boost segmentation
performance."
213,H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation (vol4),"extensive experimental results on two
publicly available datasets demonstrate the effectiveness of our proposed
method."
214,TransNuSeg: A Lightweight Multi-task Transformer for Nuclei Segmentation (vol4),none
215,QCResUNet: Joint Subject-Level and Voxel-Level Prediction of Segmentation Quality (vol4),none
216,Learnable Cross-modal Knowledge Distillation for Multi-modal Learning with Missing Modality(vol4),"multi-modal learning has become a popular research area in computer vision and
medical image analysis, with modalities spanning across various media types,
including texts, audio, images, videos and multiple sensor data."
217,Learnable Cross-modal Knowledge Distillation for Multi-modal Learning with Missing Modality(vol4),"the experiments are conducted on the brain tumour
segmentation benchmark brats2018 let us represent the n -modality data with m l
= {x ∈ x denotes the l th data
sample and the superscript (i) indexes the modality."
218,Learnable Cross-modal Knowledge Distillation for Multi-modal Learning with Missing Modality(vol4),"multi-modal segmentation is composed not only of multiple modalities, but also
of multiple tasks, such as the three types of tumours in brats2018 dataset that
represent the three tasks."
219,EGE-UNet: An Efficient Group Enhanced UNet for Skin Lesion Segmentation (vol4),none
220,Diffusion Kinetic Model for Breast Cancer Segmentation in Incomplete DCE-MRI (vol4),"we verify the
effectiveness of our proposed diffusion kinetic model (dkm) on dce-mri-based
breast cancer segmentation using breast-mri-nact-pilot dataset • we propose a
diffusion kinetic model that implicitly exploits hemodynamic priors in dce-mri
and effectively generates high-quality segmentation maps only requiring
pre-contrast images."
221,Diffusion Kinetic Model for Breast Cancer Segmentation in Incomplete DCE-MRI (vol4),"in particular, the diffusion loss for the
reverse diffusion process can be formulated as follows: where θ represents the
denoising model that employs an u-net structure, x 0 and x k are the
pre-contrast and post-contrast images, respectively, is gaussian distribution
data ∼ n (0, i), and t is a timestep."
222,Diffusion Kinetic Model for Breast Cancer Segmentation in Incomplete DCE-MRI (vol4),"dataset: to demonstrate the effectiveness of our proposed dkm, we evaluate our
method on 4d dce-mri breast cancer segmentation using the breast-mri-nact-pilot
dataset we propose a diffusion kinetic model by exploiting hemodynamic priors in
dce-mri
to effectively generate high-quality segmentation results only requiring
precontrast images."
223,Morphology-Inspired Unsupervised Gland Segmentation via Selective Semantic Grouping (vol4),none
224,EoFormer: Edge-Oriented Transformer for Brain Tumor Segmentation (vol4),none
225,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness (vol4),"first, there lacks of a
well-segmented dataset with manual labels on lyme disease."
226,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness (vol4),"on one hand, some
datasets-such as ham10000 second, the segmentation of lyme lesion is itself
challenging due to the nature of em pattern."
227,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness (vol4),"furthermore, clinical data collected for training is usually
imbalanced in some properties, e.g., more samples with light skins compared with
dark skins."
228,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness (vol4),"therefore, existing skin disease segmentation in this paper, we
present the first lyme disease dataset that contains labeled segmentation and
skin tones."
229,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness (vol4),"our lyme disease dataset contains two parts: (i) a classification
dataset, composed of more than 3,000 diseased skin images that are either
obtained from public resources or clinicians with patient-informed consent, and
(ii) a segmentation dataset containing 185 samples that are manually annotated
for three regions-i.e., background, skin (light vs."
230,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness (vol4),"our
dataset with manual labels is available at this url secondly, we design a simple
yet novel data preprocessing and alternation method, called edgemixup, to
improve lyme disease segmentation and diagnosis fairness on samples with
different skin-tones."
231,Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer (vol5),"we adopted the training dataset of hecktor 2022 (refer to
https://hecktor.grand-cha llenge.org/), including 488 h&n cancer patients
acquired from seven medical centers we resampled pet-ct images into isotropic
voxels where 1 voxel corresponds to 1 mm 3 ."
232,Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer (vol5),"extensive
experiments have shown that the proposed framework and blocks enable our xsurv
to outperform state-of-the-art survival prediction methods on the
well-benchmarked hecktor 2022 dataset."
233,ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment (vol5),"therefore, the contributions of this work can be summarized as: 1) a
novel graph-based model for predicting survival that extracts both local and
global properties by identifying morphological super-nodes; 2) introducing a
fine-coarse feature distillation module with 3 various strategies to aggregate
interactions at different scales; 3) outperforming sota approaches in both risk
prediction and patient stratification scenarios on two datasets; 4) publishing
two large and rare prostate cancer datasets containing more than 220 graphs for
active surveillance and 240 graphs for brachytherapy cases."
234,ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment (vol5),"the code and graph
embeddings are publicly available at https://github.com/pazadimo/all-in 2
related works we utilize two prostate cancer (pca) datasets to evaluate the
performance of our
proposed model."
235,ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment (vol5),"radical therapy is considered
overtreatment in these patients, so they are instead monitored with regular
serum prostate-specific antigen (psa) measurements, physical examinations,
sequential biopsies, and magnetic resonance imaging the second dataset (pca-bt)
includes 105 pca patients with low to high risk disease who went through
brachytherapy."
236,An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment (vol5),"however, this results in high
interobserver variability among pathologists, primarily due to the large (> 50%)
disagreement among pathologists for immune cell phenotyping in this paper, we
introduce a new dataset that can be readily used out-ofthe-box with any
artificial intelligence (ai)/deep learning algorithms for spatial
characterization of tumor immune microenvironment and several other use cases."
237,An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment (vol5),"to date, only two denovo stained datasets have been released publicly: bci h&e
and singleplex ihc her2 dataset the complete staining protocols for this dataset
are given in the accompanying
supplementary material."
238,An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment (vol5),"we have released the first ai-ready restained and co-registered mif and mihc
dataset for head-and-neck squamous cell carcinoma patients."
239,An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment (vol5),"this dataset can be
used for virtual phenotyping given standard clinical hematoxylin images, virtual
clinical ihc dab generation with ground truth segmentations (to train
highquality segmentation models across multiple cancer types) created from
cleaner mif images, as well as for generating standardized clean mif images from
neighboring h&e and ihc sections for registration and 3d reconstruction of
tissue specimens."
240,An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment (vol5),"in the future, we will release similar datasets for additional
cancer types as well as release for this dataset corresponding whole-cell
segmentations via impartial https://github.com/nadeemlab/impartial."
241,An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment (vol5),"it is also supported in part by the moffitt's
total cancer care initiative, collaborative data services, biostatistics and
bioinformatics, and tissue core facilities at the h."
242,Detection of Basal Cell Carcinoma in Whole Slide Images (vol5),"figure we validated our algorithm using the curated skin cancer dataset and
sc-net as a
supernet, testing both heavy and light models."
243,Detection of Basal Cell Carcinoma in Whole Slide Images (vol5),"to
ensure a fair comparison on our dataset, we selected several papers in the field
of pathological image analysis, such as evaluation metrics."
244,Detection of Basal Cell Carcinoma in Whole Slide Images (vol5),"with scnet and
evolutionary search, we obtained optimal architectures, achieving 96.2% top-1
and 96.5% accuracy on a skin cancer dataset, improvements of 4.8% and 4.7% over
baselines."
245,Detection of Basal Cell Carcinoma in Whole Slide Images (vol5),"future work will apply our approach to larger datasets for
wider-scale validation."
246,IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis (vol5),we evaluate our model with three datasets.
247,IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis (vol5),"(1) luad-gm dataset: the objective is
to predict the epidermal growth factor receptor (egfr) gene mutations in
patients with lung adenocarcinoma (luad) using 723 whole slide image (wsi)
slices, where 47% of cases have egfr mutations."
248,IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis (vol5),"(2) tcga-nsclc and tcga-rcc
datasets: cancer type classification is performed using the cancer genome atlas
(tcga) dataset."
249,IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis (vol5),"the tcga-nsclc dataset comprised two subtypes, lung squamous
cell carcinoma (lusc) and lung adenocarcinoma (luad), while the tcga-rcc dataset
included three subtypes: renal chromophobe cell carcinoma (kich), renal clear
cell carcinoma (kirc), and renal papillary cell carcinoma (kirp)."
250,Multi-scale Prototypical Transformer for Whole Slide Image Classification (vol5),none
251,Thyroid Nodule Diagnosis in Dynamic Contrast-Enhanced Ultrasound via Microvessel Infiltration Awareness (vol5),none
252,Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer (vol5),none
253,NASDM: Nuclei-Aware Semantic Histopathology Image Generation Using Diffusion Models (vol5),none
254,DiffDP: Radiotherapy Dose Prediction via a Diffusion Model (vol5),"overall, the contributions of this paper can be concluded as
follows: dataset and evaluations."
255,DiffDP: Radiotherapy Dose Prediction via a Diffusion Model (vol5),"we measure the performance of our model on an in-house
rectum cancer dataset which contains 130 patients who underwent volumetric
modulated arc therapy (vmat) treatment at west china hospital."
256,DiffDP: Radiotherapy Dose Prediction via a Diffusion Model (vol5),"extensive experiments on
an in-house dataset with 130 rectum cancer patients demonstrate the superiority
of our method."
257,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning (vol5),"the proposed approach was evaluated on a public tcga-lung dataset and an
in-house endometrial dataset and compared with 6 state-of-the-art methods."
258,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning (vol5),tcga-lung dataset is collected from the cancer genome atlas (tcga) data portal.
259,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning (vol5),"the dataset includes a total of 3,064 wsis, which consist of three categories,
namely tumor-free (normal), lung adenocarcinoma (luad), and lung squamous cancer
(lusc), endometrial dataset includes 3,654 wsis of endometrial pathology, which
includes 8 categories, namely well/moderately/low-differentiated endometrioid
adenocarcinoma, squamous differentiation carcinoma, plasmacytoid carcinoma,
clear cell carcinoma, mixed-cell adenocarcinoma, and benign tumor."
260,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning (vol5),"each dataset
was randomly divided into training, validation and test sets according to 6:1:3
while keeping each category of data proportionally."
261,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning (vol5),"we conducted wsi multi-type
classification experiments on the two datasets."
262,Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images (vol5),"first,
they are not able to get rid of their reliance on detection models, which means
they have a high need for expensive detection data labeling to train the
detection model."
263,Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images (vol5),"cervical cancer cell detection datasets involve labeling
individual and small bounding boxes in a large number of cells."
264,Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images (vol5),dataset and experimental setup.
265,Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images (vol5),"first, we label a
dataset with cell-level bounding boxes to train a detection model."
266,Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images (vol5),"the detection
dataset has 3761 images and 7623 cell-level annotations."
267,Instance-Aware Diffusion Model for Gland Segmentation in Colon Histology Images (vol5),"our proposed
method was trained and tested on the 2015 mic-cai gland segmentation (glas)
challenge dataset"
268,Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs (vol5),"our
formulation of this loss was inspired by the recent research findings that
contrastive loss benefits model robustness under label noise lastly, to support
further research in virtual ihc-restaining, we present the multi-ihc stain
translation (mist) as a new public dataset."
269,Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs (vol5),"the mist dataset contains 4k+
training and 1k testing aligned h&e-ihc patches for each of the following ihc
stains that are critical for breast cancer diagnostics: her2, ki67, er (estrogen
receptor) and pr (progesterone receptor)."
270,Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs (vol5),datasets.
271,Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs (vol5),"the following datasets are used in our experiments: the breast cancer
immunohistochemical (bci) challenge dataset implementation details."
272,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis (vol5),"the extensive experiments with
promising results on two public wsi datasets from tcga projects, i.e., kidney
carcinoma (kica) and esophageal carcinoma (esca), validate the effectiveness and
efficiency of our framework on both tumor subtyping and staging tasks."
273,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis (vol5),datasets and evaluation metrics.
274,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis (vol5),"we assess the efficacy of the proposed higt
framework by testing it on two publicly available datasets (kica and esca) from
the cancer genome atlas (tcga) repository."
275,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis (vol5),"the datasets are described below in
more detail: -kica dataset."
276,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis (vol5),"the kica dataset consists of 371 cases of kidney
carcinoma, of which 279 are classified as early-stage and 92 as late-stage."
277,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis (vol5),-esca dataset.
278,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis (vol5),"the esca dataset comprises 161 cases of esophageal carcinoma, with 96 cases
classified as early-stage and 65 as late-stage."
279,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans (vol5),"colorectal cancer is the third most common malignant tumor, and nearly half of
all patients with colorectal cancer develop liver metastasis during the course
of the disease extensive existing works have demonstrated the power of deep
learning on various spatial-temporal data, and can potentially be applied
towards the problem of crlm."
280,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans (vol5),"for example, originally designed for natural data,
several mainstream models such as e3d-lstm however, all these methods have only
demonstrated their effectiveness towards 3d/4d data (i.e., time-series 2d/3d
images), and it is not clear how to best extend them to work with the 5d cect
data."
281,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans (vol5),part of the reason is due to the lack of public availability of such data.
282,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans (vol5),"when extending these models towards 5d cect data, some decisions need to be
made, for example: 1) what is the most effective way to incorporate the phase
information?"
283,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans (vol5),"e3d-lstm in this paper, we investigate how state-of-art deep
learning models can be applied to the crlm prediction task using our 5d cect
dataset."
284,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans (vol5),"we evaluate the effectiveness of bi-directional lstm and explore the
possible method of incorporating different phases in the cect dataset."
285,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans (vol5),"specifically, we show that the best prediction accuracy can be achieved by
enhancing e3d-lstm our dataset follows specific inclusion criteria: -no tumor
appears on the ct
scans."
286,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans (vol5),"-we already determined whether or not the patients had
liver metastases within 2 years after the surgery, and manually labeled the
dataset based on this."
287,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans (vol5),"our retrospective dataset includes two
cohorts from two hospitals."
288,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans (vol5),additional statistics on our dataset are presented in table
289,Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology (vol5),"for breast cancer metastasis detection in lymph node tissue, we used wsis
of h&estained healthy lymph node tissue and lymph node tissue with breast cancer
metastases from the publicly available camelyon16 challenge data set for cell of
origin (coo) prediction of activated b-cell like (abc) or germinal center b-cell
like (gcb) tumors in diffuse large b-cell lymphoma (dlbcl), we used data from
the phase 3 goya (nct01287741) and phase 2 cavalli (nct02055820) clinical
trials, hereafter referred to as ct1 and ct2, respectively."
290,Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology (vol5),"ct1
was used for training and testing the classifier and ct2 was used only as an
independent holdout data set."
291,Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology (vol5),"for these data sets we used artifact-free tiles
from regions annotated by expert pathologists to contain tumor tissue."
292,Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology (vol5),"examples of our cellular explainability method
applied to weakly supervised tumor detection on wsis from the camelyon16 data
set using a-mil are shown in fig."
293,Progressive Attention Guidance for Whole Slide Vulvovaginal Candidiasis Screening (vol5),none
294,CellGAN: Conditional Cervical Cell Synthesis for Augmenting Cytopathological Image Classification (vol5),"as the wsi data per sample has a huge size, the idea of
identifying abnormal cells in a hierarchical manner has been proposed and
investigated by several studies using deep learning to alleviate the shortage of
sufficient data to supervise classification, one may adopt traditional data
augmentation techniques, which yet may bring little improvement due to scarcely
expanded data diversity aiming at augmenting the performance of cervical
abnormality screening, we develop a novel conditional generative adversarial
network in this paper, namely cellgan, to synthesize cytopathological images for
various cell types."
295,An Anti-biased TBSRTC-Category Aware Nuclei Segmentation Framework with a Multi-label Thyroid Cytology Benchmark (vol5),none
296,Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis (vol5),"according
to the data format, there are two main multi-modal pre-training approaches, as
shown in fig."
297,Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis (vol5),"to our best knowledge, this is the first pre-training work based on
multi-modal pathological data."
298,Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis (vol5),"we evaluate the proposed method on two public
datasets as herohe challenge and bci challenge, which shows that our method
achieves state-of-theart performance."
299,Semi-supervised Pathological Image Segmentation via Cross Distillation of Multiple Attentions (vol5),"recently, deep learning has achieved remarkable performance in pathological
image segmentation when trained with a large and well-annotated dataset
semi-supervised learning (ssl) is a potential technique to reduce the annotation
cost via learning from a limited number of labeled data along with a large
amount of unlabeled data."
300,Semi-supervised Pathological Image Segmentation via Cross Distillation of Multiple Attentions (vol5),"unlike mc-net+ the contribution of this work is three-fold: 1) a
novel framework named cdma based on mtnet is introduced for semi-supervised
pathological image segmentation, which leverages different attention mechanisms
for generating diverse and complementary predictions for unlabeled images; 2) a
cross decoder knowledge distillation method is proposed for robust and efficient
learning from noisy pseudo labels, which is combined with an average
prediction-based uncertainty minimization to improve the model's performance; 3)
experimental results show that the proposed cdma outperforms eight
state-of-the-art ssl methods on the public digestpath dataset"
301,Towards Novel Class Discovery: A Study in Novel Skin Lesions Clustering (vol5),"specifically, we first use contrastive learning to pretrain the model based on
all data from known and unknown categories to learn a robust and general
semantic feature representation."
302,Towards Novel Class Discovery: A Study in Novel Skin Lesions Clustering (vol5),"we conducted extensive experiments on the dermoscopy dataset isic
2019, and the experimental results show that our method outperforms other
state-of-the-art comparison algorithms by a large margin."
303,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction (vol5),"cancers are a group of heterogeneous diseases reflecting deep interactions
between pathological and genomics variants in tumor tissue environments the
major goal of multimodal data learning is to extract complementary contextual
information across modalities to tackle above challenges, we propose a
pathology-and-genomics multimodal framework (i.e., pathomics) for survival
prediction (fig."
304,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction (vol5),datasets.
305,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction (vol5),all image and genomics data are publicly available.
306,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction (vol5),"we collected wsis
from the cancer genome atlas colon adenocarcinoma (tcga-coad) dataset
(cc-by-3.0) experimental settings and implementations."
307,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction (vol5),"we implement two types of
settings that involve internal and external datasets for model pretraining and
finetuning."
308,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction (vol5),"as shown in fig the number of epochs for pretraining and finetuning
are 25, the batch size is 1, the optimizer is adam developing data-efficient
multimodal learning is crucial to advance the survival
assessment of cancer patients in a variety of clinical data scenarios."
309,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction (vol5),"importantly, our
approach opens up perspectives for exploring the key insights of intrinsic
genotypephenotype interactions in complex cancer data across modalities."
310,Robust Cervical Abnormal Cell Detection via Distillation from Local-Scale Consistency Refinement (vol5),"if diagnosed
early, it can be effectively treated and cured with the development of deep
learning although the above-mentioned attempts can improve the screening
performance significantly, there are several issues that need to be addressed:
1) object detection methods often require accurate annotated data to guarantee
performance with robustness and generalization."
311,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis (vol5),"in this work, we proposed and examined novel data augmentation strategies based
on the idea of interpolations of feature vectors in the mil setting."
312,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis (vol5),"with the baseline data
augmentation approaches, the maximum improvements were 0.03, and 0.02 for the
frozen, and 0.01, and 0.05 for the paraffin data set."
313,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis (vol5),"the multilinear intra-mixup method, however,
exhibited the best scores for 3 out of 4 combinations and the best overall mean
accuracy for both, the frozen and the paraffin data set."
314,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis (vol5),"also a clear trend with
increasing scores in the case of an increasing ratio of augmented data (β) is
visible."
315,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis (vol5),"with regard to the different data
sets, we noticed a stronger, positive effect in case of the frozen section data
set."
316,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis (vol5),"this is supposed to be due to the clearly higher variability of the frozen
sections corresponding with a need for a higher variability in the training
data."
317,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis (vol5),"we suppose that this is due
to the fact that the additional loss of the dual-stream architecture exhibits a
valuable regularization tool to reduce the amount of needed training data."
318,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis (vol5),"with
the proposed intra-mixup augmentation strategy, this effect diminishes, since
the amount and quality of training data is increased."
319,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis (vol5),"to conclude, we proposed
novel data augmentation strategies based on the idea of interpolations of image
descriptors in the mil setting."
320,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis (vol5),"in the future, additional
experiments will be conducted including stain normalization methods and larger
benchmark data sets to provide further insights."
321,Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors (vol5),"breast cancer (bc) is the most common cancer diagnosed among females and the
second leading cause of cancer death among women after lung cancer among
different types of imaging biomarkers, histopathological images are generally
considered the golden standard for bc prognosis since they can confer important
cell-level information that can reflect the aggressiveness of bc to deal with
the above challenges, several researchers began to design domain adaption
algorithms, which utilize the labeled data from a related cancer subtype to help
predict the patients' survival in the target domain."
322,Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors (vol5),"next, we aligned the aggregated tumor or tils features from
the two domains separately using maximum mean discrepancy(mmd) here, we adopted
mmd for feature alignment due to its ability to measure the distance between two
distributions without explicit assumptions on the data distribution, we showed
the objective function of mmd in our method as follows: where h is a hilbert
space, f represents the features from the source, f represents the feature from
the target, r represents the layer number, k ∈ {l, t } referred to tils or tumor
node."
323,Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors (vol5),"in
order to measure the dissimilarity between p i and q i , the kullback-leibler
(kl) divergence is adapted on the third layer of gat, which can be formulated
as: according to eq.( datasets."
324,Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors (vol5),"we conducted our experiments on the breast invasive carcinoma (brca)
dataset from the cancer genome atlas (tcga)."
325,Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors (vol5),"specifically, the brca dataset
includes 661 patients with hematoxylin and eosin (he)-stained pathological
imaging and corresponding survival information."
326,Gene-Induced Multimodal Pre-training for Image-Omic Classification (vol5),"furthermore, to model the high-order relevance of the two
modalities, we combine cls tokens of paired image and genomic data to form
unified representations and propose a triplet learning module to differentiate
patient-level positive and negative samples in a mini-batch."
327,Gene-Induced Multimodal Pre-training for Image-Omic Classification (vol5),datasets.
328,Gene-Induced Multimodal Pre-training for Image-Omic Classification (vol5),"we verify the effectiveness of our method on the caner genome atlas
(tcga) non-small cell lung cancer (nsclc) dataset, which contains two cancer
subtypes, i.e., lung squamous cell carcinoma (lusc) and lung adenocarcinoma
(luad)."
329,Gene-Induced Multimodal Pre-training for Image-Omic Classification (vol5),"the pre-training process of
all algorithms is conducted on the training set, without any extra data
augmentation."
330,Gene-Induced Multimodal Pre-training for Image-Omic Classification (vol5),"note that our genetic encoder, groupmsa, is fully supervised
pre-trained on unimodal genetic data to accelerate convergence and it is frozen
during gimp training process."
331,Histopathology Image Classification Using Deep Manifold Contrastive Learning (vol5),"the dataset for the former task was collected from 168 patients
with 332 wsis from seoul national university hospital."
332,Histopathology Image Classification Using Deep Manifold Contrastive Learning (vol5),"the liver cancer dataset for the latter task was composed of 323 wsis,
in which the wsis can be further classified into hepatocellular carcinomas
(hccs) (collected from pathology ai platform we used a pre-trained vgg16 with
imagenet as the initial encoder, which was
further modified via deep manifold model training using the proposed manifold
and cross-entropy loss functions."
333,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides (vol5),"-we developed a comprehensive
pipeline for constructing tumor-associated stroma datasets across multiple data
sources, and employed adversarial training and neighborhood consistency
regularization techniques to learn robust multimodal-invariant image
representations."
334,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides (vol5),"however, using data from multiple
modalities can introduce systematic shifts, which can impact the performance of
a deep learning model."
335,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides (vol5),"the optimization process aims to achieve a
balance between these two goals, resulting in an embedding space that encodes as
much information as possible about tumor-associated stroma identification while
not encoding any information on the data source."
336,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides (vol5),"in our study, we utilized three datasets for tumor-associated stroma analysis."
337,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides (vol5),"(1) dataset a comprises 513 tiles extracted from the whole mount slides of 40
patients, sourced from the archives of the pathology department at cedars-sinai
medical center (irb# pro00029960)."
338,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides (vol5),"it combines two sets of tiles: 224 images
from 20 patients featuring stroma, normal glands, low-grade and highgrade cancer
(2) dataset b included 97 whole mount slides with an average size of over
174,000×142,000 pixels at 40x magnification."
339,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides (vol5),"(3) dataset c
comprised 6134 negative biopsy slides obtained from 262 patients' biopsy
procedures, where all samples were diagnosed as negative."
340,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides (vol5),"dataset a was utilized for training the
stroma segmentation model."
341,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides (vol5),"extensive data augmentation techniques, such as image
scaling and staining perturbation, were employed during the training process."
342,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides (vol5),"this model was then applied to generate stroma masks for all
slides in datasets b and c."
343,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides (vol5),"to precisely isolate stroma tissues and avoid data
bleeding from epithelial tissues, we only extracted patches where over 99.5% of
the regions were identified as stroma at 40x magnification to construct the
stroma classification dataset."
344,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides (vol5),"to incorporate multi-modal
information, we randomly sampled negative stroma patches from all biopsy slides
in dataset c."
345,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides (vol5),"future research can focus on validating our
approach on larger and more diverse datasets and expanding the method to a
patient-level prediction system, ultimately improving prostate cancer diagnosis
and treatment."
346,Multi-scope Analysis Driven Hierarchical Graph Transformer for Whole Slide Image Based Cancer Survival Prediction (vol5),none
347,Mining Negative Temporal Contexts for False Positive Suppression in Real-Time Ultrasound Lesion Detection (vol5),none
348,Iteratively Coupled Multiple Instance Learning from Instance to Bag Classifier for Whole Slide Image Classification (vol5),"our experiments utilized two datasets, with the first being the publicly
available breast cancer dataset, camelyon16 the second dataset is a private
hepatocellular carcinoma (hcc) dataset collected from sir run run shaw hospital,
hangzhou, china."
349,Iteratively Coupled Multiple Instance Learning from Instance to Bag Classifier for Whole Slide Image Classification (vol5),"this dataset comprises a total of 1140 valid tumor wsis scanned
at 40× magnification, and the objective is to identify the severity of each case
based on the edmondson-steiner (es) grading."
350,Artifact Restoration in Histology Images with Diffusion Probabilistic Models (vol5),none
351,Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer (vol6),"we adopted the training dataset of hecktor 2022 (refer to
https://hecktor.grand-cha llenge.org/), including 488 h&n cancer patients
acquired from seven medical centers we resampled pet-ct images into isotropic
voxels where 1 voxel corresponds to 1 mm 3 ."
352,Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer (vol6),"extensive
experiments have shown that the proposed framework and blocks enable our xsurv
to outperform state-of-the-art survival prediction methods on the
well-benchmarked hecktor 2022 dataset."
353,ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment (vol6),"therefore, the contributions of this work can be summarized as: 1) a
novel graph-based model for predicting survival that extracts both local and
global properties by identifying morphological super-nodes; 2) introducing a
fine-coarse feature distillation module with 3 various strategies to aggregate
interactions at different scales; 3) outperforming sota approaches in both risk
prediction and patient stratification scenarios on two datasets; 4) publishing
two large and rare prostate cancer datasets containing more than 220 graphs for
active surveillance and 240 graphs for brachytherapy cases."
354,ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment (vol6),"the code and graph
embeddings are publicly available at https://github.com/pazadimo/all-in 2
related works we utilize two prostate cancer (pca) datasets to evaluate the
performance of our
proposed model."
355,ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment (vol6),"radical therapy is considered
overtreatment in these patients, so they are instead monitored with regular
serum prostate-specific antigen (psa) measurements, physical examinations,
sequential biopsies, and magnetic resonance imaging the second dataset (pca-bt)
includes 105 pca patients with low to high risk disease who went through
brachytherapy."
356,An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment (vol6),"however, this results in high
interobserver variability among pathologists, primarily due to the large (> 50%)
disagreement among pathologists for immune cell phenotyping in this paper, we
introduce a new dataset that can be readily used out-ofthe-box with any
artificial intelligence (ai)/deep learning algorithms for spatial
characterization of tumor immune microenvironment and several other use cases."
357,An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment (vol6),"to date, only two denovo stained datasets have been released publicly: bci h&e
and singleplex ihc her2 dataset the complete staining protocols for this dataset
are given in the accompanying
supplementary material."
358,An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment (vol6),"we have released the first ai-ready restained and co-registered mif and mihc
dataset for head-and-neck squamous cell carcinoma patients."
359,An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment (vol6),"this dataset can be
used for virtual phenotyping given standard clinical hematoxylin images, virtual
clinical ihc dab generation with ground truth segmentations (to train
highquality segmentation models across multiple cancer types) created from
cleaner mif images, as well as for generating standardized clean mif images from
neighboring h&e and ihc sections for registration and 3d reconstruction of
tissue specimens."
360,An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment (vol6),"in the future, we will release similar datasets for additional
cancer types as well as release for this dataset corresponding whole-cell
segmentations via impartial https://github.com/nadeemlab/impartial."
361,An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment (vol6),"it is also supported in part by the moffitt's
total cancer care initiative, collaborative data services, biostatistics and
bioinformatics, and tissue core facilities at the h."
362,Detection of Basal Cell Carcinoma in Whole Slide Images (vol6),"figure we validated our algorithm using the curated skin cancer dataset and
sc-net as a
supernet, testing both heavy and light models."
363,Detection of Basal Cell Carcinoma in Whole Slide Images (vol6),"to
ensure a fair comparison on our dataset, we selected several papers in the field
of pathological image analysis, such as evaluation metrics."
364,Detection of Basal Cell Carcinoma in Whole Slide Images (vol6),"with scnet and
evolutionary search, we obtained optimal architectures, achieving 96.2% top-1
and 96.5% accuracy on a skin cancer dataset, improvements of 4.8% and 4.7% over
baselines."
365,Detection of Basal Cell Carcinoma in Whole Slide Images (vol6),"future work will apply our approach to larger datasets for
wider-scale validation."
366,IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis (vol6),we evaluate our model with three datasets.
367,IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis (vol6),"(1) luad-gm dataset: the objective is
to predict the epidermal growth factor receptor (egfr) gene mutations in
patients with lung adenocarcinoma (luad) using 723 whole slide image (wsi)
slices, where 47% of cases have egfr mutations."
368,IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis (vol6),"(2) tcga-nsclc and tcga-rcc
datasets: cancer type classification is performed using the cancer genome atlas
(tcga) dataset."
369,IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis (vol6),"the tcga-nsclc dataset comprised two subtypes, lung squamous
cell carcinoma (lusc) and lung adenocarcinoma (luad), while the tcga-rcc dataset
included three subtypes: renal chromophobe cell carcinoma (kich), renal clear
cell carcinoma (kirc), and renal papillary cell carcinoma (kirp)."
370,Multi-scale Prototypical Transformer for Whole Slide Image Classification (vol6),none
371,Thyroid Nodule Diagnosis in Dynamic Contrast-Enhanced Ultrasound via Microvessel Infiltration Awareness (vol6),none
372,Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer (vol6),none
373,NASDM: Nuclei-Aware Semantic Histopathology Image Generation Using Diffusion Models (vol6),none
374,DiffDP: Radiotherapy Dose Prediction via a Diffusion Model (vol6),"overall, the contributions of this paper can be concluded as
follows: dataset and evaluations."
375,DiffDP: Radiotherapy Dose Prediction via a Diffusion Model (vol6),"we measure the performance of our model on an in-house
rectum cancer dataset which contains 130 patients who underwent volumetric
modulated arc therapy (vmat) treatment at west china hospital."
376,DiffDP: Radiotherapy Dose Prediction via a Diffusion Model (vol6),"extensive experiments on
an in-house dataset with 130 rectum cancer patients demonstrate the superiority
of our method."
377,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning (vol6),"the proposed approach was evaluated on a public tcga-lung dataset and an
in-house endometrial dataset and compared with 6 state-of-the-art methods."
378,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning (vol6),tcga-lung dataset is collected from the cancer genome atlas (tcga) data portal.
379,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning (vol6),"the dataset includes a total of 3,064 wsis, which consist of three categories,
namely tumor-free (normal), lung adenocarcinoma (luad), and lung squamous cancer
(lusc), endometrial dataset includes 3,654 wsis of endometrial pathology, which
includes 8 categories, namely well/moderately/low-differentiated endometrioid
adenocarcinoma, squamous differentiation carcinoma, plasmacytoid carcinoma,
clear cell carcinoma, mixed-cell adenocarcinoma, and benign tumor."
380,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning (vol6),"each dataset
was randomly divided into training, validation and test sets according to 6:1:3
while keeping each category of data proportionally."
381,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning (vol6),"we conducted wsi multi-type
classification experiments on the two datasets."
382,Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images (vol6),"first,
they are not able to get rid of their reliance on detection models, which means
they have a high need for expensive detection data labeling to train the
detection model."
383,Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images (vol6),"cervical cancer cell detection datasets involve labeling
individual and small bounding boxes in a large number of cells."
384,Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images (vol6),dataset and experimental setup.
385,Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images (vol6),"first, we label a
dataset with cell-level bounding boxes to train a detection model."
386,Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images (vol6),"the detection
dataset has 3761 images and 7623 cell-level annotations."
387,Instance-Aware Diffusion Model for Gland Segmentation in Colon Histology Images (vol6),"our proposed
method was trained and tested on the 2015 mic-cai gland segmentation (glas)
challenge dataset"
388,Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs (vol6),"our
formulation of this loss was inspired by the recent research findings that
contrastive loss benefits model robustness under label noise lastly, to support
further research in virtual ihc-restaining, we present the multi-ihc stain
translation (mist) as a new public dataset."
389,Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs (vol6),"the mist dataset contains 4k+
training and 1k testing aligned h&e-ihc patches for each of the following ihc
stains that are critical for breast cancer diagnostics: her2, ki67, er (estrogen
receptor) and pr (progesterone receptor)."
390,Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs (vol6),datasets.
391,Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs (vol6),"the following datasets are used in our experiments: the breast cancer
immunohistochemical (bci) challenge dataset implementation details."
392,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis (vol6),"the extensive experiments with
promising results on two public wsi datasets from tcga projects, i.e., kidney
carcinoma (kica) and esophageal carcinoma (esca), validate the effectiveness and
efficiency of our framework on both tumor subtyping and staging tasks."
393,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis (vol6),datasets and evaluation metrics.
394,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis (vol6),"we assess the efficacy of the proposed higt
framework by testing it on two publicly available datasets (kica and esca) from
the cancer genome atlas (tcga) repository."
395,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis (vol6),"the datasets are described below in
more detail: -kica dataset."
396,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis (vol6),"the kica dataset consists of 371 cases of kidney
carcinoma, of which 279 are classified as early-stage and 92 as late-stage."
397,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis (vol6),-esca dataset.
398,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis (vol6),"the esca dataset comprises 161 cases of esophageal carcinoma, with 96 cases
classified as early-stage and 65 as late-stage."
399,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans (vol6),"colorectal cancer is the third most common malignant tumor, and nearly half of
all patients with colorectal cancer develop liver metastasis during the course
of the disease extensive existing works have demonstrated the power of deep
learning on various spatial-temporal data, and can potentially be applied
towards the problem of crlm."
400,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans (vol6),"for example, originally designed for natural data,
several mainstream models such as e3d-lstm however, all these methods have only
demonstrated their effectiveness towards 3d/4d data (i.e., time-series 2d/3d
images), and it is not clear how to best extend them to work with the 5d cect
data."
401,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans (vol6),part of the reason is due to the lack of public availability of such data.
402,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans (vol6),"when extending these models towards 5d cect data, some decisions need to be
made, for example: 1) what is the most effective way to incorporate the phase
information?"
403,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans (vol6),"e3d-lstm in this paper, we investigate how state-of-art deep
learning models can be applied to the crlm prediction task using our 5d cect
dataset."
404,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans (vol6),"we evaluate the effectiveness of bi-directional lstm and explore the
possible method of incorporating different phases in the cect dataset."
405,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans (vol6),"specifically, we show that the best prediction accuracy can be achieved by
enhancing e3d-lstm our dataset follows specific inclusion criteria: -no tumor
appears on the ct
scans."
406,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans (vol6),"-we already determined whether or not the patients had
liver metastases within 2 years after the surgery, and manually labeled the
dataset based on this."
407,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans (vol6),"our retrospective dataset includes two
cohorts from two hospitals."
408,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans (vol6),additional statistics on our dataset are presented in table
409,Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology (vol6),"for breast cancer metastasis detection in lymph node tissue, we used wsis
of h&estained healthy lymph node tissue and lymph node tissue with breast cancer
metastases from the publicly available camelyon16 challenge data set for cell of
origin (coo) prediction of activated b-cell like (abc) or germinal center b-cell
like (gcb) tumors in diffuse large b-cell lymphoma (dlbcl), we used data from
the phase 3 goya (nct01287741) and phase 2 cavalli (nct02055820) clinical
trials, hereafter referred to as ct1 and ct2, respectively."
410,Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology (vol6),"ct1
was used for training and testing the classifier and ct2 was used only as an
independent holdout data set."
411,Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology (vol6),"for these data sets we used artifact-free tiles
from regions annotated by expert pathologists to contain tumor tissue."
412,Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology (vol6),"examples of our cellular explainability method
applied to weakly supervised tumor detection on wsis from the camelyon16 data
set using a-mil are shown in fig."
413,Progressive Attention Guidance for Whole Slide Vulvovaginal Candidiasis Screening (vol6),none
414,CellGAN: Conditional Cervical Cell Synthesis for Augmenting Cytopathological Image Classification (vol6),"as the wsi data per sample has a huge size, the idea of
identifying abnormal cells in a hierarchical manner has been proposed and
investigated by several studies using deep learning to alleviate the shortage of
sufficient data to supervise classification, one may adopt traditional data
augmentation techniques, which yet may bring little improvement due to scarcely
expanded data diversity aiming at augmenting the performance of cervical
abnormality screening, we develop a novel conditional generative adversarial
network in this paper, namely cellgan, to synthesize cytopathological images for
various cell types."
415,An Anti-biased TBSRTC-Category Aware Nuclei Segmentation Framework with a Multi-label Thyroid Cytology Benchmark (vol6),none
416,Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis (vol6),"according
to the data format, there are two main multi-modal pre-training approaches, as
shown in fig."
417,Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis (vol6),"to our best knowledge, this is the first pre-training work based on
multi-modal pathological data."
418,Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis (vol6),"we evaluate the proposed method on two public
datasets as herohe challenge and bci challenge, which shows that our method
achieves state-of-theart performance."
419,Semi-supervised Pathological Image Segmentation via Cross Distillation of Multiple Attentions (vol6),"recently, deep learning has achieved remarkable performance in pathological
image segmentation when trained with a large and well-annotated dataset
semi-supervised learning (ssl) is a potential technique to reduce the annotation
cost via learning from a limited number of labeled data along with a large
amount of unlabeled data."
420,Semi-supervised Pathological Image Segmentation via Cross Distillation of Multiple Attentions (vol6),"unlike mc-net+ the contribution of this work is three-fold: 1) a
novel framework named cdma based on mtnet is introduced for semi-supervised
pathological image segmentation, which leverages different attention mechanisms
for generating diverse and complementary predictions for unlabeled images; 2) a
cross decoder knowledge distillation method is proposed for robust and efficient
learning from noisy pseudo labels, which is combined with an average
prediction-based uncertainty minimization to improve the model's performance; 3)
experimental results show that the proposed cdma outperforms eight
state-of-the-art ssl methods on the public digestpath dataset"
421,Towards Novel Class Discovery: A Study in Novel Skin Lesions Clustering (vol6),"specifically, we first use contrastive learning to pretrain the model based on
all data from known and unknown categories to learn a robust and general
semantic feature representation."
422,Towards Novel Class Discovery: A Study in Novel Skin Lesions Clustering (vol6),"we conducted extensive experiments on the dermoscopy dataset isic
2019, and the experimental results show that our method outperforms other
state-of-the-art comparison algorithms by a large margin."
423,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction (vol6),"cancers are a group of heterogeneous diseases reflecting deep interactions
between pathological and genomics variants in tumor tissue environments the
major goal of multimodal data learning is to extract complementary contextual
information across modalities to tackle above challenges, we propose a
pathology-and-genomics multimodal framework (i.e., pathomics) for survival
prediction (fig."
424,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction (vol6),datasets.
425,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction (vol6),all image and genomics data are publicly available.
426,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction (vol6),"we collected wsis
from the cancer genome atlas colon adenocarcinoma (tcga-coad) dataset
(cc-by-3.0) experimental settings and implementations."
427,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction (vol6),"we implement two types of
settings that involve internal and external datasets for model pretraining and
finetuning."
428,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction (vol6),"as shown in fig the number of epochs for pretraining and finetuning
are 25, the batch size is 1, the optimizer is adam developing data-efficient
multimodal learning is crucial to advance the survival
assessment of cancer patients in a variety of clinical data scenarios."
429,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction (vol6),"importantly, our
approach opens up perspectives for exploring the key insights of intrinsic
genotypephenotype interactions in complex cancer data across modalities."
430,Robust Cervical Abnormal Cell Detection via Distillation from Local-Scale Consistency Refinement (vol6),"if diagnosed
early, it can be effectively treated and cured with the development of deep
learning although the above-mentioned attempts can improve the screening
performance significantly, there are several issues that need to be addressed:
1) object detection methods often require accurate annotated data to guarantee
performance with robustness and generalization."
431,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis (vol6),"in this work, we proposed and examined novel data augmentation strategies based
on the idea of interpolations of feature vectors in the mil setting."
432,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis (vol6),"with the baseline data
augmentation approaches, the maximum improvements were 0.03, and 0.02 for the
frozen, and 0.01, and 0.05 for the paraffin data set."
433,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis (vol6),"the multilinear intra-mixup method, however,
exhibited the best scores for 3 out of 4 combinations and the best overall mean
accuracy for both, the frozen and the paraffin data set."
434,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis (vol6),"also a clear trend with
increasing scores in the case of an increasing ratio of augmented data (β) is
visible."
435,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis (vol6),"with regard to the different data
sets, we noticed a stronger, positive effect in case of the frozen section data
set."
436,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis (vol6),"this is supposed to be due to the clearly higher variability of the frozen
sections corresponding with a need for a higher variability in the training
data."
437,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis (vol6),"we suppose that this is due
to the fact that the additional loss of the dual-stream architecture exhibits a
valuable regularization tool to reduce the amount of needed training data."
438,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis (vol6),"with
the proposed intra-mixup augmentation strategy, this effect diminishes, since
the amount and quality of training data is increased."
439,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis (vol6),"to conclude, we proposed
novel data augmentation strategies based on the idea of interpolations of image
descriptors in the mil setting."
440,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis (vol6),"in the future, additional
experiments will be conducted including stain normalization methods and larger
benchmark data sets to provide further insights."
441,Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors (vol6),"breast cancer (bc) is the most common cancer diagnosed among females and the
second leading cause of cancer death among women after lung cancer among
different types of imaging biomarkers, histopathological images are generally
considered the golden standard for bc prognosis since they can confer important
cell-level information that can reflect the aggressiveness of bc to deal with
the above challenges, several researchers began to design domain adaption
algorithms, which utilize the labeled data from a related cancer subtype to help
predict the patients' survival in the target domain."
442,Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors (vol6),"next, we aligned the aggregated tumor or tils features from
the two domains separately using maximum mean discrepancy(mmd) here, we adopted
mmd for feature alignment due to its ability to measure the distance between two
distributions without explicit assumptions on the data distribution, we showed
the objective function of mmd in our method as follows: where h is a hilbert
space, f represents the features from the source, f represents the feature from
the target, r represents the layer number, k ∈ {l, t } referred to tils or tumor
node."
443,Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors (vol6),"in
order to measure the dissimilarity between p i and q i , the kullback-leibler
(kl) divergence is adapted on the third layer of gat, which can be formulated
as: according to eq.( datasets."
444,Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors (vol6),"we conducted our experiments on the breast invasive carcinoma (brca)
dataset from the cancer genome atlas (tcga)."
445,Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors (vol6),"specifically, the brca dataset
includes 661 patients with hematoxylin and eosin (he)-stained pathological
imaging and corresponding survival information."
446,Gene-Induced Multimodal Pre-training for Image-Omic Classification (vol6),"furthermore, to model the high-order relevance of the two
modalities, we combine cls tokens of paired image and genomic data to form
unified representations and propose a triplet learning module to differentiate
patient-level positive and negative samples in a mini-batch."
447,Gene-Induced Multimodal Pre-training for Image-Omic Classification (vol6),datasets.
448,Gene-Induced Multimodal Pre-training for Image-Omic Classification (vol6),"we verify the effectiveness of our method on the caner genome atlas
(tcga) non-small cell lung cancer (nsclc) dataset, which contains two cancer
subtypes, i.e., lung squamous cell carcinoma (lusc) and lung adenocarcinoma
(luad)."
449,Gene-Induced Multimodal Pre-training for Image-Omic Classification (vol6),"the pre-training process of
all algorithms is conducted on the training set, without any extra data
augmentation."
450,Gene-Induced Multimodal Pre-training for Image-Omic Classification (vol6),"note that our genetic encoder, groupmsa, is fully supervised
pre-trained on unimodal genetic data to accelerate convergence and it is frozen
during gimp training process."
451,Histopathology Image Classification Using Deep Manifold Contrastive Learning (vol6),"the dataset for the former task was collected from 168 patients
with 332 wsis from seoul national university hospital."
452,Histopathology Image Classification Using Deep Manifold Contrastive Learning (vol6),"the liver cancer dataset for the latter task was composed of 323 wsis,
in which the wsis can be further classified into hepatocellular carcinomas
(hccs) (collected from pathology ai platform we used a pre-trained vgg16 with
imagenet as the initial encoder, which was
further modified via deep manifold model training using the proposed manifold
and cross-entropy loss functions."
453,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides (vol6),"-we developed a comprehensive
pipeline for constructing tumor-associated stroma datasets across multiple data
sources, and employed adversarial training and neighborhood consistency
regularization techniques to learn robust multimodal-invariant image
representations."
454,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides (vol6),"however, using data from multiple
modalities can introduce systematic shifts, which can impact the performance of
a deep learning model."
455,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides (vol6),"the optimization process aims to achieve a
balance between these two goals, resulting in an embedding space that encodes as
much information as possible about tumor-associated stroma identification while
not encoding any information on the data source."
456,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides (vol6),"in our study, we utilized three datasets for tumor-associated stroma analysis."
457,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides (vol6),"(1) dataset a comprises 513 tiles extracted from the whole mount slides of 40
patients, sourced from the archives of the pathology department at cedars-sinai
medical center (irb# pro00029960)."
458,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides (vol6),"it combines two sets of tiles: 224 images
from 20 patients featuring stroma, normal glands, low-grade and highgrade cancer
(2) dataset b included 97 whole mount slides with an average size of over
174,000×142,000 pixels at 40x magnification."
459,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides (vol6),"(3) dataset c
comprised 6134 negative biopsy slides obtained from 262 patients' biopsy
procedures, where all samples were diagnosed as negative."
460,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides (vol6),"dataset a was utilized for training the
stroma segmentation model."
461,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides (vol6),"extensive data augmentation techniques, such as image
scaling and staining perturbation, were employed during the training process."
462,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides (vol6),"this model was then applied to generate stroma masks for all
slides in datasets b and c."
463,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides (vol6),"to precisely isolate stroma tissues and avoid data
bleeding from epithelial tissues, we only extracted patches where over 99.5% of
the regions were identified as stroma at 40x magnification to construct the
stroma classification dataset."
464,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides (vol6),"to incorporate multi-modal
information, we randomly sampled negative stroma patches from all biopsy slides
in dataset c."
465,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides (vol6),"future research can focus on validating our
approach on larger and more diverse datasets and expanding the method to a
patient-level prediction system, ultimately improving prostate cancer diagnosis
and treatment."
466,Multi-scope Analysis Driven Hierarchical Graph Transformer for Whole Slide Image Based Cancer Survival Prediction (vol6),none
467,Mining Negative Temporal Contexts for False Positive Suppression in Real-Time Ultrasound Lesion Detection (vol6),none
468,Iteratively Coupled Multiple Instance Learning from Instance to Bag Classifier for Whole Slide Image Classification (vol6),"our experiments utilized two datasets, with the first being the publicly
available breast cancer dataset, camelyon16 the second dataset is a private
hepatocellular carcinoma (hcc) dataset collected from sir run run shaw hospital,
hangzhou, china."
469,Iteratively Coupled Multiple Instance Learning from Instance to Bag Classifier for Whole Slide Image Classification (vol6),"this dataset comprises a total of 1140 valid tumor wsis scanned
at 40× magnification, and the objective is to identify the severity of each case
based on the edmondson-steiner (es) grading."
470,Artifact Restoration in Histology Images with Diffusion Probabilistic Models (vol6),none
471,Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification (vol7),"radiologists typically focus on areas
with breast lesions during mammogram reading radiologists' eye movements can be
automatically and unobtrusively recorded during the process of reading
mammograms, providing a valuable source of data without the need for manual
labeling."
472,Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification (vol7),"previous studies have incorporated radiologists' eye-gaze as a form of
weak supervision, which directs the network's attention to the regions with
possible lesions mammography primarily detects two types of breast lesions:
masses and microcalcifications in this work, we propose a novel diagnostic
model, namely mammo-net, which integrates radiologists' gaze data and
interactive information between cc-view and mlo-view to enhance diagnostic
performance."
473,Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification (vol7),"to the best of our knowledge, this is the first work to integrate
gaze data into multi-view mammography classification."
474,Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification (vol7),"• we demonstrate the
effectiveness of our approach through experiments using mammography datasets,
which show the superiority of mammo-net."
475,Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification (vol7),"to achieve this, we integrate gaze data
as a form of weak supervision for both lesion positioning and interpretability
of the model."
476,Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification (vol7),"our experimental results on mammography datasets demonstrate the
superiority of our proposed model."
477,Probabilistic Modeling Ensemble Vision Transformer Improves Complex Polyp Segmentation (vol7),"• we evaluate the
performance of petnet on five widely adopted datasets, demonstrating its
superior ability to identify polyp camouflage and small polyp scenes, achieving
state-of-the-art performance in locating polyps with high precision."
478,DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning (vol7),"when training the model on other datasets, we use the tumor
set collected from the inbreast dataset."
479,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network (vol7),"to achieve this goal, we create a synthetic
dataset, which has separate annotations for normal kidneys and protruded
regions, and train a segmentation network to separate the protruded regions from
the normal kidney regions."
480,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network (vol7),"verify that the proposed framework
achieves a higher dice score compared to the standard 3d u-net using a publicly
available dataset."
481,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network (vol7),"the release of two public ct image datasets with kidney and tumor masks from the
2019/2021 kidney and kidney tumor segmentation challenge looking at the top 3
teams from each challenge in terms of focusing on protruded regions in kidneys,
our work is close to the second protuberance detection network is the same as
the base network except it starts from 8 channels instead of 16."
482,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network (vol7),"we train this
network using synthetic datasets."
483,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network (vol7),"the details of the dataset and training
procedures are described in sect."
484,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network (vol7),synthetic dataset.
485,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network (vol7),"however, annotating such
areas is time-consuming and preparing a large number of data is challenging."
486,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network (vol7),"alternatively, we create a synthetic dataset that mimics a kidney with
protrusions."
487,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network (vol7),the synthetic dataset is created through the following steps: 1.
488,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network (vol7),"if both of the following conditions are met, append to
the dataset."
489,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network (vol7),"although our network
is fully differentiable, since there is no separate annotation for protruded
regions other from the synthetic dataset, we freeze the parameters in
protuberance detection network."
490,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network (vol7),"to cope with isodensity tumors, which have similar intensity values
to their surrounding tissues, we created a synthetic dataset to train a network
that extracts protuberance from the kidney masks."
491,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network (vol7),"we evaluated our method using the publicly
available kits19 dataset, and showed that the proposed method can achieve a
higher sensitivity than existing approach."
492,Skin Lesion Correspondence Localization in Total Body Photography (vol7),"the framework is evaluated on a private dataset and a public dataset with
success rates that are comparable to those of the state-of-the-art method."
493,Skin Lesion Correspondence Localization in Total Body Photography (vol7),"in addition, the method may not work well with
longitudinal data that has non-isometric deformation due to huge variations in
body shape, inconsistent 3d reconstruction, or a dramatic change in pose and,
therefore, topology, such as an open armpit versus a closed one."
494,Skin Lesion Correspondence Localization in Total Body Photography (vol7),"in the future,
the method needs to be evaluated on longitudinal data with longer duration and
new lesions absent in the target."
495,Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer (vol7),"studies suggest that one way to improve these factors is through
data centric approaches i.e."
496,Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer (vol7),to focus on appropriate representation of data.
497,Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer (vol7),"specifically, representation of data as graphs has been shown to be effective
for medical diagnosis and analysis biological data, specially those acquired
intra-opertively, are heterogeneous by nature."
498,Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer (vol7),"while the use of ex-vivo data
collected under specific protocols are beneficial to develop baseline models,
intra-operative deployment of these models is challenging."
499,Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer (vol7),"for iknife, the
ex-vivo data is usually collected from homogeneous regions of resected specimens
under the guidance of a trained pathologist, versus the intra-operative data is
recorded continuously while the surgeon cutting through tissues with different
heterogeneity and pathology."
500,Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer (vol7),"deep ensembles ex-vivo: data is collected from fresh breast tissue samples from
the patients
referred to bcs at kingston health sciences center over two years."
501,Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer (vol7),"in addition to spectral data, clinicopathological
details such as the status of hormone receptors is also provided
post-surgically."
502,Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer (vol7),"evidential deep learning provides a welldefined theoretical framework to jointly
quantify classification prediction and uncertainty modeling by assuming the
class probability follows a dirichlet distribution in the context of surgical
margin assessment, the attentions reveal the relevant metabolic ranges to
cancerous tissue, while uncertainty helps identify and filter data with unseen
pathology."
503,Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-Based Hierarchical Fusion Network with Attention Mechanism (vol7),"the mris were acquired with philips ingenia all mris
were resampled to 1 mm isotropic voxels and uniformly sized, resulting in
volumes of 352 × 352 pixel images with 176 slices per mri, and subsequent
registration was performed based on advanced normalization tools (ants) we have
developed a multi-sequence fusion network based on multi-b-value dwi to
synthesize ce-mri, using source data including dwis and t1-weighted
fatsuppressed mri."
504,Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-Based Hierarchical Fusion Network with Attention Mechanism (vol7),"compared to existing methods, we avoid the challenges of
using full-sequence mri and aim to be selective on valuable source data dwi."
505,Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma (vol7),"ji measures
similarity of two datasets, which ranges from 0% to 100%."
506,Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma (vol7),"due to both real patients and synthetic patients were
involved in delineation, to erase the delineation memory of the same patient, we
separated the patients to two datasets, each with the same number of patients,
both two datasets with mixed real patients and synthetic patients without
overlaps (i.e., the ce-mri and vce-mri from the same patient are not in the same
dataset).when finished the first dataset delineation, there was a one-month
interval before the delineation of the second dataset."
507,Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma (vol7),"the average ji obtained from institution-1,
institution-2, and institution-3 dataset were similar with a result of 71.54%,
74.78% and 75.85%, respectively."
508,Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma (vol7),"for the institution-2 data, all synthetic patients
observed the same stages as real patients."
509,Automated CT Lung Cancer Screening Workflow Using 3D Camera (vol7),none
510,Multi-task Learning of Histology and Molecular Markers for Classifying Diffuse Glioma (vol7),none
511,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information (vol7),"to achieve this, we
efficiently exploit knowledge from multi-center datasets that are not tailored
for second-course gtv segmentation."
512,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information (vol7),"medical
images are sparsely labeled which are isolated by different tasks in order to
fully leverage both public and private datasets, the training objective should
not be specific to any tasks."
513,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information (vol7),"to adequately
monitor changes in tumor volume and integrate information from the initial
course into the subsequent course, a paired first-second courses dataset s p =
{i 1 p , i 2 p , g 1 p ; g 2 p } is necessary for training."
514,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information (vol7),"the paired dataset s p for the first and second courses is limited, whereas an
unpaired gtv dataset s v = {i v ; g v } can be easily obtained in a standard
clinical workflow with a substantial amount."
515,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information (vol7),"the transformed data is feed into the encoders e 1/2 as shown
in the following equations: , p 1 (g e ), p 2 (i e ), p 2 (g e ), when i e , g e
∈ s e ."
516,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information (vol7),datasets.
517,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information (vol7),"the paired first-second course dataset, s p , is collected from sun
yat-sen university cancer center (ethics approval number: b2023-107-01),
comprising paired ct scans of 69 distinct patients from south china."
518,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information (vol7),"we
collected the gtv dataset s v from medmind technology co., ltd., which has ct
scans from 179 patients."
519,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information (vol7),"to demonstrate the presence of a domain gap between the first and second
courses, we train sota methods with datasets s train p and s v , by feeding the
data sequentially into the network."
520,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information (vol7),the results presented in table figure combination of various datasets.
521,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information (vol7),"besides, to efficiently leverage prior
knowledge contained in various medical ct datasets, we train the network in an
information-querying manner."
522,CLIP-Lung: Textual Knowledge-Guided Lung Nodule Malignancy Prediction (vol7),none
523,EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition (vol7),"on the one hand, inspired by the emerging prompt learning techniques that embed
prompts into a model for adaptation to diverse downstream tasks our
contributions can be summarized as: (3) a domain mixup strategy is devised to
reduce the co-artifacts specific to dermoscopic images; (4) extensive
experiments on four out-of-distribution skin datasets and six biased isic
datasets demonstrate the outperforming generalization ability and robustness of
epvt under heterogeneous distribution shifts."
524,Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data (vol7),real-world pnens dataset.
525,Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data (vol7),"we validated our method on a real-world pnens dataset
from two centers."
526,Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data (vol7),"the dataset contained 264 and 28 patients in center 1 and
center 2, and a senior radiologist annotated the bounding boxes for all 408 and
28 lesions."
527,Developing Large Pre-trained Model for Breast Tumor Segmentation from Ultrasound Images (vol7),"five-fold cross
validation is performed on the dataset in all experiments to verify our proposed
network."
528,Developing Large Pre-trained Model for Breast Tumor Segmentation from Ultrasound Images (vol7),"for external validation, we further test our model on two independent
publicly-available datasets collected by stu-hospital (dataset 1) to verify the
advantages of our proposed model for breast tumor segmentation in
ultrasound images, we compare our deep-supervised convolutional network with the
state-ofthe-art tumor segmentation methods, including deepres representative
segmentation results using different methods are provided in fig."
529,Developing Large Pre-trained Model for Breast Tumor Segmentation from Ultrasound Images (vol7),"using a large clinical
dataset, our proposed model demonstrates not only state-of-the-art segmentation
performance, but also the outstanding generalizability to new ultrasound data
from different sites."
530,3D Mitochondria Instance Segmentation with Spatio-Temporal Transformers (vol8),"segmentation performance on
all three datasets."
531,Physics-Informed Conditional Autoencoder Approach for Robust Metabolic CEST MRI at 7T (vol8),data measurements.
532,Deep Unsupervised Clustering for Conditional Identification of Subgroups Within a Digital Pathology Image Set (vol8),her2 dataset.
533,Deep Unsupervised Clustering for Conditional Identification of Subgroups Within a Digital Pathology Image Set (vol8),"human epidermal growth factor receptor 2 (her2 or her2/neu) is a
protein involved in normal cell growth, which plays an important role in the
diagnosis and treatment of breast cancer deep clustering models applied to the
her2 dataset."
534,Deep Unsupervised Clustering for Conditional Identification of Subgroups Within a Digital Pathology Image Set (vol8),"we evaluate the performance and behavior of the dec, vade, and
cdvade models on the her2 dataset."
535,Deep Unsupervised Clustering for Conditional Identification of Subgroups Within a Digital Pathology Image Set (vol8),"we investigate whether the models will learn
to distinguish the her2 class labels, the scanner labels, or other potentially
meaningful data subgroups in a fully unsupervised fashion."
536,Deep Unsupervised Clustering for Conditional Identification of Subgroups Within a Digital Pathology Image Set (vol8),"to investigate the
clustering abilities of cdvade on the her2 dataset, we inject the her2 class
labels into the latent embedding space."
537,A Texture Neural Network to Predict the Abnormal Brachial Plexus from Routine Magnetic Resonance Imaging (vol8),"this paper constructed a bp dataset with
the most commonly used bp mris in our clinical practice."
538,A Texture Neural Network to Predict the Abnormal Brachial Plexus from Routine Magnetic Resonance Imaging (vol8),"the major contributions of this study
include 1) directed triangle construction idea for tpp, 2) huge number of tpp
matrices as the heterogeneity representations of bp, 3) tppnet with 15 layers
and huge number of channels, 4) the bp dataset containing mr images and their
corresponding roi masks."
539,A Texture Neural Network to Predict the Abnormal Brachial Plexus from Routine Magnetic Resonance Imaging (vol8),"to testify our proposed tppnet, a bp
dataset is constructed with 452 series including three most commonly used mr
sequences in clinical practice, i.e."
540,CircleFormer: Circular Nuclei Detection in Whole Slide Images with Circle Queries and Attention (vol8),"we evaluate our circleformer on the public monuseg dataset for
nuclei detection in whole slide images."
541,Self-supervised Dense Representation Learning for Live-Cell Microscopy with Time Arrow Prediction (vol8),"to demonstrate the utility of tap for a diverse set of specimen and microscopy
modalities we use the following four different datasets: hela."
542,Self-supervised Dense Representation Learning for Live-Cell Microscopy with Time Arrow Prediction (vol8),"for each dataset
we heuristically choose δt to roughly correspond to the time scale of observable
biological processes (i.e."
543,Prompt-MIL: Boosting Multi-instance Learning Schemes via Task-Specific Prompt Tuning (vol8),"compared to the full
fine-tuning method, our method achieved a relative improvement of 1.29% to
13.61% in accuracy and 3.22% to 27.18% in auroc on the three datasets."
544,Prompt-MIL: Boosting Multi-instance Learning Schemes via Task-Specific Prompt Tuning (vol8),"we
evaluated the training speed and memory consumption of our method and compared
to the full fine-tuning baseline on four different sized wsis in the bright
dataset."
545,Prompt-MIL: Boosting Multi-instance Learning Schemes via Task-Specific Prompt Tuning (vol8),"foundational models refer to those trained on
large-scale pathology datasets (e.g."
546,Prompt-MIL: Boosting Multi-instance Learning Schemes via Task-Specific Prompt Tuning (vol8),the entire tcga pan-cancer dataset
547,Prompt-Based Grouping Transformer for Nucleus Detection and Classification (vol8),"however, the transformer framework has a relatively large number of
parameters, which could cause high costs in fine-tuning the whole model on large
datasets."
548,Prompt-Based Grouping Transformer for Nucleus Detection and Classification (vol8),"inspired by the prompt tuning
methods consep 1 [10] is a colorectal nuclear dataset with three types,
consisting of 41
h&e stained image tiles from 16 colorectal adenocarcinoma whole-slide images
(wsis)."
549,Prompt-Based Grouping Transformer for Nucleus Detection and Classification (vol8),"we split them following the official partition is a breast cancer dataset
with three types and consists of 120 image tiles from 113 patients."
550,Relaxation-Diffusion Spectrum Imaging for Probing Tissue Microarchitecture (vol8),"recent advances in diffusion mri (dmri) and diffusion signal modeling equip
brain researchers with an in vivo probe into microscopic tissue compositions
multi-compartment models are typically used to characterize signals from, for
example, intra-and extra-neurite compartments here, we propose a unified
strategy to estimate using mte diffusion data (i) compartment specific t 2
relaxation times; (ii) non-t 2 -weighted (non-t 2 w) parameters of multi-scale
microstructure; and (iii) non-t 2 w multi-scale fodfs."
551,Relaxation-Diffusion Spectrum Imaging for Probing Tissue Microarchitecture (vol8),"we evaluate rdsi using both ex vivo monkey and in vivo human brain mte data,
acquired with fixed diffusion times across multiple b-values."
552,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning (vol8),"the proposed technique was tested on a healthy-subject dataset and on a dataset
containing tumor cases."
553,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning (vol8),"the first comprises 21 subjects of the human connectome
project (hcp) that were used for testing the automated methods tractseg and
classifyber to test the proposed method on pathological data, we used an
in-house dataset containing ten presurgical scans of patients with brain tumors."
554,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning (vol8),"manual
segmentation experiments using an interactive prototype of attractive were
initiated on the tumor data (holistic evaluation)."
555,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning (vol8),"additionally, reproducible
simulations on the freely available hcp and the internal tumor dataset were
created (algorithmic evaluation)."
556,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning (vol8),"the code used for these
experiments is publicly available for the algorithmic evaluation, the initial
training dataset was created with 20 randomly selected streamlines from the
whole-brain tractogram, which have been shown to be a decent number to start
training."
557,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning (vol8),"since some tracts contain only a fraction of streamlines from the
entire tractogram, it might be unlikely that the training dataset will contain
any streamline belonging to the target tract."
558,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning (vol8),"therefore, two streamlines of the
specific tract were further added to the training dataset, and class weights
were used to compensate for the class unbalance."
559,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning (vol8),"to ensure
that the initial dataset s rand contained streamlines from the target tract, the
expert initiated the active learning workflow by defining a small roi that
included fibers of the tract."
560,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning (vol8),"to allow comparison between the proposed
and traditional roi-based techniques, the or of subjects from the tumor dataset
were segmented using both approaches by an expert familiar with the respective
tool, and the time required was reported to measure efficiency."
561,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning (vol8),"note, in all
experiments, the classifier is trained from scratch every iteration, prototypes
are generated for each subject individually, and the classifier predicts on data
from the same subject it is trained with, as it performs subject-individual
tract segmentation and is not used as a fully automated method."
562,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning (vol8),"to ensure a
stable active learning setup that generalizes across different datasets, the
whole method was developed on the hcp and applied with fixed settings to the
tumor data active learning-based white matter tract segmentation enables the
identification
of arbitrary pathways and can be applied to cases where fully automated methods
are unfeasible."
563,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning (vol8),"the algorithmic evaluation
yielded consistent results from the fifth to the tenth iterations on both the
hcp and tumor datasets."
564,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning (vol8),"as expected, outcomes obtained from the tumor dataset
were not quite as good as those of the hcp dataset."
565,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning (vol8),"this trend is generally
observed in clinical datasets, which tend to exhibit lower performance levels
compared to high-quality datasets, which could be responsible for the decline in
the results."
566,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning (vol8),"for selected
scenarios, the ability of the classifier to generalize by learning from
previously annotated subjects will be investigated, which may even allow to
train a fully automatic classifier for new tracts once enough data is annotated."
567,B-Cos Aligned Transformers Learn Human-Interpretable Features (vol8),"we classify image patches from the public
colorectal cancer dataset nct-crc-he-100k domain-expert evaluation: our primary
objective is to develop an extension of the vision transformer that is more
transparent and trusted by medical professionals."
568,Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping (vol8),"second, resting-state fmri data are not routinely collected for gbm clinical
practices, which restricts the size of annotated datasets such that it is
infeasible to train a reliable prediction model based on deep learning for
survival prediction."
569,Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping (vol8),"similar to data augmentation schemes, we can artificially
boost data volume (i.e., fln maps) up to m times through producing m fln maps
for each patient in the a-lnm, which helps to mitigate the risk of over-fitting
and improve the performance of overall survival time prediction when learning a
deep neural network from a small sized dataset."
570,Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping (vol8),"to evaluate the
predictive power of the fln maps generated by our a-lnm, we conduct extensive
experiments on 235 gbm patients in the training dataset of brats 2020 2.1
materials gsp1000 processed connectome."
571,Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping (vol8),"it publicly released preprocessed
restingstate fmri data of 1000 healthy right-handed subjects with an average age
21.5 ± 2.9 years and approximately equal numbers of males and females from the
brain genomics superstruct project (gsp) brats 2020."
572,Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping (vol8),"it provided an open-access
pre-operative imaging training dataset to segment brain tumors of glioblastoma
(gbm, belonging to high grade glioma) and low grade glioma (lgg) patients, as
well as to predict overall survival time of gbm patients the union of all the
three tumor sub-regions was considered as the whole tumor, which is regarded as
the lesion in this paper."
573,Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping (vol8),"in this paper, we propose to investigate the feasibility of the novel
neuroimaging features, i.e., fln maps, for overall survival time prediction of
gbm patients in the training dataset of the brats 2020, in which one patient
alive was excluded, and the remaining 235 patients consisted of 89 short-term
survivors (less than 10 months), 59 mid-term survivors (between 10 and 15
months), and 87 long-term survivors (more than 15 months)."
574,Intraoperative CT Augmentation for Needle-Based Liver Interventions (vol9),"image fusion typically relies on the estimation
of rigid or non-rigid transformations between 2 images, to bring into the
intraoperative image structures of interest only visible in the preoperative
data."
575,Intraoperative CT Augmentation for Needle-Based Liver Interventions (vol9),"our future steps will essentially involve applying this method to
patient data and perform a small user study to evaluate the usefulness and
limitations of our approach."
576,Optical Coherence Elastography Needle for Biomechanical Characterization of Deep Tissue (vol9),"1, using force and position sensor data (see
supplementary material)."
577,Pelvic Fracture Segmentation Using a Multi-scale Distance-Weighted Neural Network (vol9),none
578,Towards Multi-modal Anatomical Landmark Detection for Ultrasound-Guided Brain Tumor Resection with Contrastive Learning (vol9),"gliomas are the most common central nervous system (cns) tumors in adults,
accounting for 80% of primary malignant brain tumors as the true underlying
deformation from brain shift is impossible to obtain and the differences of
image features between mri and us are large, quantitative validation of
automatic mri-us registration algorithms often rely on homologous anatomical
landmarks that are manually labeled between corresponding mri and
intra-operative us scans previously, many groups have proposed algorithms to
label landmarks in anatomical scans we employed the publicly available
easy-resect (retrospective evaluation of
cerebral tumors) dataset"
579,Deep Reinforcement Learning Based System for Intraoperative Hyperspectral Video Autofocusing (vol9),none
580,Surgical Video Captioning with Mutual-Modal Concept Alignment (vol9),neurosurgery video captioning dataset.
581,Surgical Video Captioning with Mutual-Modal Concept Alignment (vol9),"to evaluate the effectiveness of surgical
video captioning, we collect a large-scale dataset with 41 surgical videos of
endonasal skull base neurosurgery."
582,Surgical Video Captioning with Mutual-Modal Concept Alignment (vol9),"after
necessary data cleaning, we divide these surgical videos with resolution of 1,
920× 1, 080 into 11, 004 thirty-second video clips with clear surgical purposes."
583,Surgical Video Captioning with Mutual-Modal Concept Alignment (vol9),"these video clips are annotated under tool-tissue interaction (tti) principle
endovis image captioning dataset."
584,Surgical Video Captioning with Mutual-Modal Concept Alignment (vol9),"we further compare our method with
state-of-the-arts on the public endovis-2018 image captioning dataset
implementation details."
585,Regularized Kelvinlet Functions to Model Linear Elasticity for Image-to-Physical Registration of the Breast (vol9),"the first explores sensitivity
to regularized kelvinlet function hyperparameters k grab , k twist , ε grab ,
and ε twist and establishes optimal hyperparameters in a training dataset of 11
breast deformations."
586,Regularized Kelvinlet Functions to Model Linear Elasticity for Image-to-Physical Registration of the Breast (vol9),"this dataset consists of supine breast mr images simulating surgical
deformations from one breast cancer patient."
587,Learning Expected Appearances for Intraoperative Registration During Neurosurgery (vol9),"we address the important problem of intraoperative patient-to-image registration
in a new way by relying on preoperative data to synthesize plausible
transformations and appearances that are expected to be found intraoperatively."
588,Learning Expected Appearances for Intraoperative Registration During Neurosurgery (vol9),"our
experiments using clinical data showed that our method provides accurate
registration without manual intervention, that it is computationally efficient,
and it is invariant to the visual appearance of the cortex."
589,Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation (vol9),"we present
results on a clinical dataset comprising fifty post-operative glioblastoma (gbm)
patients."
590,FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery (vol9),"the study further compared gods with two other
novelty detection models: robust covariance and, one-class support vector
machine (oc-svm) results of a binary classification model using svm are also
shown in the supplementary section table table the gods uses two separating
hyperplanes to minimize the distance between
the two classifiers by learning a low-dimensional subspace containing flim data
properties of healthy labels."
591,FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery (vol9),"residual tumor labels are detected by calculating
the distance between the projected data points and the learned subspace."
592,FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery (vol9),"this is mainly due to the robustness of the model,
the ability to handle high-dimensional data, and the contrast in the flim decay
curves."
593,FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery (vol9),"the novelty detection model
generalizes to the healthy labels and considers data falling off the healthy
distribution as residual cancer."
594,FocalErrorNet: Uncertainty-Aware Focal Modulation Network for Inter-modal Registration Error Estimation in Ultrasound-Guided Neurosurgery (vol9),"in contrast, intra-operative ultrasound (ius) has gained popularity for
real-time imaging during surgery to monitor tissue deformation and surgical
tools because of its lower cost, portability, and flexibility recently,
automatic quality assessment for medical image registration has attracted
increasing attention for methodological development and assessment, we used the
resect
(retro-spective evaluation of cerebral tumors) dataset"
595,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery (vol9),"however, it is not trivial to determine this using traditional methods
due to poor textural definition of tissues and lack of per-pixel ground truth
depth data."
596,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery (vol9),"to validate our proposed solution for the newly formulated problem, we acquired
and publicly released two new datasets."
597,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery (vol9),"all data acquisition and devices were controlled by python and labview programs,
and complete data sets of the above images were collected on visually realistic
phantoms for multiple probe and laparoscope positions."
598,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery (vol9),"therefore,
our first newly acquired dataset, named jerry, contains 1200 sets of images."
599,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery (vol9),"since it is important to report errors in 3d and in millimeters, we recorded
another dataset similar to jerry but also including ground truth depth map for
all frames by using structured-lighting system these datasets have multiple uses
such as: -intersection point detection: detecting intersection points is an
important problem that can bring accurate surgical cancer visualization."
600,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery (vol9),"both the hardware and software
design of the proposed solution were illustrated and two newly acquired datasets
were publicly released."
601,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery (vol9),"we believe that our problem
reformulation and dataset release, together with the initial experimental
results, will establish a new benchmark for the surgical vision community."
602,A Novel Video-CTU Registration Method with Structural Point Similarity for FURS Navigation (vol9),"to the best of
our knowledge, this work shows the first study to continuously track the
flexible ureteroscope in preoperative data using a vision-based method."
603,Cascade Transformer Encoded Boundary-Aware Multibranch Fusion Networks for Real-Time and Accurate Colonoscopic Lesion Segmentation (vol9),none
604,Unified Brain MR-Ultrasound Synthesis Using Multi-modal Hierarchical Representations (vol10),none
605,StructuRegNet: Structure-Guided Multimodal 2D-3D Registration (vol10),dataset and preprocessing.
606,StructuRegNet: Structure-Guided Multimodal 2D-3D Registration (vol10),"our clinical dataset consists of 108 patients for
whom were acquired both a pre-operative h&n ct scan and 4 to 11 wsis after
laryngectomy (with a total amount of 849 wsis)."
607,StructuRegNet: Structure-Guided Multimodal 2D-3D Registration (vol10),"we split the dataset patient-wise into three
groups for training (64), validation hyperparameters."
608,StructuRegNet: Structure-Guided Multimodal 2D-3D Registration (vol10),"we drew our code from
cyclegan and voxelmorph implementations with modifications explained above, and
we thank the authors of msv-regsynnet for making their code and data available
to us evaluation."
609,StructuRegNet: Structure-Guided Multimodal 2D-3D Registration (vol10),"according to the mr/ct application in rt, we compared our model against
the state-of-the-art results of msv-regsynnet which were computed on the same
dataset."
610,StructuRegNet: Structure-Guided Multimodal 2D-3D Registration (vol10),"we also compared against
msv-regsynnet on its own validation dataset for generalization assessment: we
yielded comparable results for the first cohort and significantly better ones
for the second, which proves that structuregnet behaves well on other modalities
and that the structure awareness is an essential asset for better registration,
as pelvis is a location where organs are moving."
611,X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior (vol10),"we trained our model with a large dataset of 3500 cts of
patients with head-and-neck cancer, more exactly 2297 patients from the publicly
available the cancer imaging archive (tcia) 3d reconstruction."
612,Structure-Preserving Synthesis: MaskGAN for Unpaired MR-CT Translation (vol10),none
613,FreeSeed: Frequency-Band-Aware and Self-guided Network for Sparse-View CT Reconstruction (vol10),"freeseed achieves promising results with only image data and can be
further enhanced once the sinogram is available."
614,Co-learning Semantic-Aware Unsupervised Segmentation for Pathological Image Registration (vol10),"to create
such a mapping, we created a pseudo dataset by utilizing images from the oasis-1
and brats2020."
615,Co-learning Semantic-Aware Unsupervised Segmentation for Pathological Image Registration (vol10),"from the resulting t1 sequences, a pseudo dataset of 300 images
was randomly selected for further analysis."
616,Co-learning Semantic-Aware Unsupervised Segmentation for Pathological Image Registration (vol10),"appendix b provides a detailed
process for creating the pseudo dataset."
617,Co-learning Semantic-Aware Unsupervised Segmentation for Pathological Image Registration (vol10),real data with landmarks.
618,Co-learning Semantic-Aware Unsupervised Segmentation for Pathological Image Registration (vol10),"after creating the pseudo dataset, we warped
brain mr images without tumors to the atlas and used the resulting deformation
field as the gold standard for evaluation."
619,Revealing Anatomical Structures in PET to Generate CT for Attenuation Correction (vol10),"the data used in our experiments are collected from the cancer image archive
(tcia) each sample contains co-registered (acquired with pet-ct scans) ct, pet,
and nac-pet whole-body scans."
620,An Explainable Deep Framework: Towards Task-Specific Fusion for Multi-to-One MRI Synthesis (vol10),none
621,Geometric Ultrasound Localization Microscopy (vol10),none
622,Reflectance Mode Fluorescence Optical Tomography with Consumer-Grade Cameras (vol10),none
623,DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration (vol10),"in this experiment, we evaluate the performance of different methods for
estimating affine registration of the retrospective evaluation of cerebral
tumors (resect) miccai challenge dataset as the most challenging experiment, we
finally use our method to achieve
deformable registration of abdominal 3d freehand us to a ct or mr volume."
624,DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration (vol10),"we are
using a heterogeneous dataset of 27 cases, comprising liver cancer patients and
healthy volunteers, different ultrasound machines, as well as optical vs."
625,DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration (vol10),"all 3d ultrasound data sets are accurately calibrated, with overall
system errors in the range of commercial ultrasound fusion options."
626,Solving Low-Dose CT Reconstruction via GAN with Local Coherence (vol10),datasets.
627,Solving Low-Dose CT Reconstruction via GAN with Local Coherence (vol10),"first, our proposed approaches are evaluated on the ""mayo-clinic
low-dose ct grand challenge"" (mayo-clinic) dataset of lung ct images the dataset
contains 2250 two dimensional slices from 9 patients for training, and the
remaining 128 slices from 1 patient are reserved for testing."
628,Solving Low-Dose CT Reconstruction via GAN with Local Coherence (vol10),"to evaluate the
generalization of our model, we also consider another dataset rider with
nonsmall cell lung cancer under two ct scans baselines and evaluation metrics."
629,Solving Low-Dose CT Reconstruction via GAN with Local Coherence (vol10),"to evaluate the stability and
generalization of our model and the baselines trained on mayo-clinic dataset, we
also test them on the rider dataset."
630,Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT (vol10),"training deep learning models for medical
applications often needs new data."
631,Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT (vol10),"this was not the case for noise2aliasing, and
historical clinical data sufficed for training."
632,Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT (vol10),"we validated our method on
publicly available data first, we used the spare varian dataset to study whether
noise2aliasing can
match the performance of the supervised baseline and if it can outperform it
when adding noise to the projections."
633,Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT (vol10),"then, we use the internal dataset to
explore the requirements for the method to be applied to an existing clinical
dataset."
634,Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT (vol10),"the projections obtained during a scan are
sub-sampled according to the pseudo-average subset selection method described in
the datasets used in this study are two: 1."
635,Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT (vol10),"the spare varian dataset was used to
provide performance results on publicly available patient data."
636,Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT (vol10),"to more closely
resemble normal respiratory motion per projection image, the 8 min scan has been
used from each patient (five such scans are available in the dataset)."
637,Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT (vol10),"the
hyperparameters are optimized over the training dataset."
638,Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT (vol10),"an internal dataset
(irb approved) of 30 lung cancer patients' 4dcbcts from 2020 to 2022, originally
used for igrt, with 25 patients for training and 5 patients for testing."
639,Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT (vol10),the data were anonymized prior to analysis.
640,Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT (vol10),"projection
noise was added using the poisson distribution to the spare varian dataset to
evaluate the ability of the unsupervised method to reduce it."
641,Trackerless Volume Reconstruction from Intraoperative Ultrasound Images (vol10),"3 presents our current results on ex vivo porcine data, and finally, we conclude
in sect."
642,CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis (vol10),"magnetic resonance imaging (mri) is critical to the diagnosis, treatment, and
follow-up of brain tumour patients management despite the success, gan-based
models are challenged by the limited capability of adversarial learning in
modelling complex multi-modal data distributions diffusion model (dm) has
achieved state-of-the-art performance in synthesizing natural images, promising
to improve mri synthesis models."
643,LightNeuS: Neural Surface Reconstruction in Endoscopy Using Illumination Decline (vol10),none
