title,extracted_keyword_sent,sub groups,age,gender,sex,women,woman,female,male,geolocation,geographical,geographic,country,countries,city,cities,hospital,hospitals,clinic,clinics,society,societies,etnicity,etnicities,race,bias,biases,fair,unfair,fairness,transparency,awareness,imbalance,imbalanced,balance,balanced,problem,problems,issue,issues,challenge,challenges,difficult,difficulty,difficulties,patient,patients,demographics,demographic,data collection
Anatomy-Driven Pathology Detection on Chest X-rays,"it is
derived from the mimic-cxr dataset [9,10], which is based on imaging studies
from 65 079 patients performed at beth israel deaconess medical center in
boston, us.","65.079 patients, beth israel deaconess medical center, boston US, imaging studies",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET,the dataset is composed of 23 oncological patients with different tumor types.,"23 patients, oncology, different tumor types",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET,"the dataset included the label maps of 7 organs
(bones, lungs, heart, liver, kidneys, spleen, aorta) and one image-derived input
function a(t) [bq/ml] from the descending aorta per patient.","7 organs, bones, lungs, heart, liver, kidneys, spleen, aorta, patients, image of descending aorta",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET,"then, the dataset was split
patient-wise into training, validation, and test set, with 10, 4, and 9 patients
respectively.","23 patients, 10 patients for training, 4 patients for validation, 9 patients for test set ",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET,"in both cases, 75 axial slices per patient were extracted in a
pre-defined patient-specific range from the lungs to the bladder (included) and
were cropped to size 112 × 112 pixels.","patient, lungs, bladder",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET,"4.1 (see table 1).figure 2 shows the kps for four selected organs
as computed with the proposed dnn (kp dnn ), as computed with curve fit using
only the 9 patients of the test set (kp cf ) and using all 23 patients (kp ref
cf ) [16].","4 organs, patients, 23 patients in total",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET,"this is likely due to breathing and heartbeat motion artifacts, which
cannot be modeled properly with a 2tc km that assumes no motion between
frames.figure 3b-e shows the central coronal slice of the four kpis in an
exemplary patient.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor,"specifically, ame-cam achieves
the highest dice score for all patients in all datasets and modalities.",patients,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"similarly to the metavir score in d 1 histo
, we also binarize the ishak score, as proposed in [16,20], which results in two
cohorts of 34 healthy and 15 pathological patients.in all datasets, we select
the slices based on the liver segmentation of the patients.","patients, healty patients, pathological patients, liver, 34 healthy patients, 15 pathological patients",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"we first sample n patients, where n is the batch size, in a
balanced way with respect to the radiological/histological classes; namely, we
roughly have the same number of subjects per class.","patients, radiological class, histological class",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"for d 2 histo , which has fewer patients than the batch size, we use
a balanced sampling strategy with respect to the radiological/histological
classes with no obligation of one slice per patient in the batch.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"as we work
with 2d slices rather than 3d volumes, we compute the average probability per
patient of having the pathology.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"the evaluation results presented later are
based on the patient-level aggregated prediction.finally, we run our experiments
on a tesla v100 with 16gb of ram and a 6 cpu cores, and we used the
pytorch-lightning library to implement our models.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"first, we can
notice that our method outperforms all other pretraining methods in d 1 histo
and d 1+2 histo , which are the two datasets with more patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"the method depth-aware manages to correctly encode the
depth position but not the diagnostic class label.to assess the clinical
performance of the pretraining methods, we also compute the balanced accuracy
scores (bacc) of the trained classifiers, which is compared in table 2 to the
bacc achieved by radiologists who were asked to visually assess the presence or
absence of cirrhosis for the n=106 cases of d 1 histo .",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Unsupervised Discovery of 3D Hierarchical Structure with Generative Diffusion Features,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
S 2 ME: Spatial-Spectral Mutual Teaching and Ensemble Learning for Scribble-Supervised Polyp Segmentation,"these datasets are
collected from diversified patients in multiple medical centers with various
data acquisition systems.","patients, diversified patients, medical centers, data acquisition systems",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
S 2 ME: Spatial-Spectral Mutual Teaching and Ensemble Learning for Scribble-Supervised Polyp Segmentation,"to ensure the reliability of the mixed pseudo labels for
ensemble learning, we present the pixel-level adaptive fusion strategy according
to entropy maps of dual predictions to balance the strengths and weaknesses of
spatial and spectral branches.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Tracking Adaptation to Improve SuperPoint for 3D Reconstruction in Endoscopy,"obtaining 3d models from the intracorporeal scenes captured in
endoscopies is an essential step to enable these novel tasks and build
applications, for example, for improved monitoring of existing patients or
augmented reality during training or real explorations.3d reconstruction
strategies have been studied for long, and one crucial step in these strategies
is feature detection and matching which serves as input for structure from
motion (sfm) pipelines.","endoscopies, patients",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Black-box Domain Adaptative Cell Segmentation via Multi-source Distillation,"accordingly, direct knowledge transfer
using the output of the source domain predictor may lead to feature bias in the
student model due to the unavoidable covariance [20] between the target and
source domains.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Black-box Domain Adaptative Cell Segmentation via Multi-source Distillation,"firstly, we acquire 50 images from a cohort of patients with
triple negative breast cancer (tnbc), which is released by naylor et al [18].","images, patients, triple negative breast cancer, 50 images",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Black-box Domain Adaptative Cell Segmentation via Multi-source Distillation,"for single-source domain
adaptation approach, cellsegssda and sfda-dpl, we employ two strategies to
ensure the fairness of the experiments: (1) single-source, i.e.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning,"yet, acquiring large training datasets and
their corresponding labels, especially from a cohort of patients, can be costly
or even infeasible, which poses a significant challenge in developing a dl model
with high performance [7].",patients,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning,"this is due to
sensitive privacy issues in patients' data, particularly in collaborative
research, which restricts access to labels from different domains.",patients' data,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning,"• our framework is effective at preserving privacy, since it carries out da
using only pre-trained network parameters, without transferring any patient
data.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
PET-Diffusion: Unsupervised PET Enhancement Based on the Latent Diffusion Model,"however, acquiring high-quality pet images requires
injecting a sufficient dose (standard dose) of radionuclides into the human
body, which poses unacceptable radiation hazards for pregnant women and infants
even following the as low as reasonably achievable (alara) principle [19].","pregnant women, infants, images, human body",1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
PET-Diffusion: Unsupervised PET Enhancement Based on the Latent Diffusion Model,"denoting the output of previous layer as z p et ,
the ct-guided cross-attention can be formulated as follows:where d is the number
of channels, b is the position bias, and conv(•) denotes the 1 × 1 × 1
convolution with stride of 1.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
3D Arterial Segmentation via Single 2D Projections and Depth Supervision in Contrast-Enhanced CT Images,"the cohort consists of 141 patients with pancreatic ductal
adenocarcinoma, of an equal ratio of male to female patients.","patients, pancreatic ductal adenocarcinoma, male patients, female patients, 141 patients in total, equal ratio of male and female patients",0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Mesh2SSM: From Surface Meshes to Statistical Shape Models of Anatomy,"mesh2ssm also includes an analysis
network that operates on the learned correspondences to obtain a data-driven
template point cloud (i.e., template point cloud), which can replace the initial
template, and hence reducing the bias that could arise from template selection.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Mesh2SSM: From Surface Meshes to Statistical Shape Models of Anatomy,"dataset: we use the publicly available decath-pancreas dataset of 273
segmentations from patients who underwent pancreatic mass resection [24].","decath-pancreas, patients, 273 segmentations",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Mesh2SSM: From Surface Meshes to Statistical Shape Models of Anatomy,"incorporating template feedback loop via vae [13,21] analysis module helps in
mitigating bias and capturing non-linear characteristics of the data.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Cross-Adversarial Local Distribution Regularization for Semi-supervised Medical Image Segmentation,"the
third term is our cross-ald regularization, which is an enhancement of vat to
significantly improve the model performance.where λ cs and λ cross-ald are the
corresponding weights to balance the losses.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Infusing Physically Inspired Known Operators in Deep Models of Ultrasound Elastography,"it should be noted in contrast to [5] in which
only out-of-range samples were contributing to the loss, in this work, all
samples contribute to l vd to reduce the estimation bias.3-smoothness of epr is
considered by:4-picture loss is defined as l v = l vd + λ vs × l vs , where λ vs
is the weight of the smoothness loss.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Infusing Physically Inspired Known Operators in Deep Models of Ultrasound Elastography,"this data is available online at http://code.sonography.ai
in [16].in vivo data was collected at johns hopkins hospital from patients with
liver cancer during open-surgical rf thermal ablation by a research antares
siemens system using a vf 10-5 linear array with the sampling frequency of 40
mhz and the center frequency of 6.67 mhz.","in vivo data, john hopkins hospital, patients, liver cancer",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Infusing Physically Inspired Known Operators in Deep Models of Ultrasound Elastography,"the institutional review board
approved the study with the consent of the patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
SLPD: Slide-Level Prototypical Distillation for WSIs,"many histopathologic features have been established based on the morphologic
phenotypes of the tumor, such as tumor invasion, anaplasia, necrosis and
mitoses, which are then used for cancer diagnosis, prognosis and the estimation
of response-to-treatment in patients [3,9].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
SLPD: Slide-Level Prototypical Distillation for WSIs,"however, the
obtained clustering centers, i.e., the prototypes, are inclined to represent the
visual bias related to staining or scanning procedure rather than medically
relevant features [33].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
SLPD: Slide-Level Prototypical Distillation for WSIs,"tumors of different patients can exhibit morphological similarities in some
respects [17,21], so the correspondences across slides should be characterized
during learning.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
PROnet: Point Refinement Using Shape-Guided Offset Map for Nuclei Instance Segmentation,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Many Tasks Make Light Work: Learning to Localise Medical Anomalies from Multiple Synthetic Tasks,"this huge increase in pressure has led
to long patient-waiting times and fatigued radiologists who make more mistakes
[3].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
TPRO: Text-Prompting-Based Weakly Supervised Histopathology Tissue Segmentation,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
VesselVAE: Recursive Variational Autoencoders for 3D Blood Vessel Synthesis,"this subset consisted of 1694
healthy vessel segments reconstructed from 2d mra images of patients.","healthy vessel segments, 2d mra images, patients, 1694 healthy vessel segments",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
VesselVAE: Recursive Variational Autoencoders for 3D Blood Vessel Synthesis,"this decision reflects a
balance between the computational demands of depth-first tree traversal in each
training step and the complexity of the training meshes.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
MetaLR: Meta-tuning of Learning Rates for Transfer Learning in Medical Imaging,"moreover, although the generalization validation on the training data batch may
introduce bias, providing sufficient training data ultimately benefits the
performance.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DAS-MIL: Distilling Across Scales for MIL Classification of Histological WSIs,"on the one hand, annotating wsis requires strong medical expertise,
is expensive, time-consuming, and labels are usually provided at the slide or
patient level.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
DAS-MIL: Distilling Across Scales for MIL Classification of Histological WSIs,"through
knowledge distillation, we encour-age agreement across the predictions delivered
at different resolutions, while individual scale features are learned in
isolation to preserve the diversity in terms of information content.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Pick the Best Pre-trained Model: Towards Transferability Estimation for Medical Image Segmentation,"third, medical images face severe class imbalance problems, with
excessive differences between foreground and background.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Pick the Best Pre-trained Model: Towards Transferability Estimation for Medical Image Segmentation,"however, existing
algorithms rarely give additional attention to the class imbalance problem.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Pick the Best Pre-trained Model: Towards Transferability Estimation for Medical Image Segmentation,"in
the calculation of class consistency, we only sample the foreground voxels with
a pre-defined sampling number which is proportional to the voxel number of each
class in the image because of the severe class imbalance problem.feature
variety.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Pick the Best Pre-trained Model: Towards Transferability Estimation for Medical Image Segmentation,"most of the existing methods are inferior to ours because
they are not designed for segmentation tasks with a serious class imbalance
problem.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"domain shift is typically caused by various factors, including
differences in acquisition protocols (e.g., parameters, imaging methods,
modalities) and characteristics of data (e.g., age, gender, the severity of the
disease and so on).domain adaptation (da) has been proposed and investigated to
combat distribution shift in medical image segmentation.",,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"however, they
easily suffer from the balance between feature alignment and discrimination
ability of the model.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"the infant brain
mri dataset for cross-age segmentation; 2).",infant brain,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"to optimize the segmentation backbone network, we use a combined loss function,
l seg , that incorporates both dice loss [19] and cross-entropy loss with a
balance factor.by summing the above-introduced losses, the total loss to train
the segmentation network can be defined by eq.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"7.where λ is the scaling factor
to balance the losses.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"the first dataset, i.e., cross-age infant segmentation [20], was used
for cross-age infant brain image segmentation, while the second dataset, i.e.,
brats2018 [21], was used for hgg to lgg domain adaptation.the first dataset is
for infant brain segmentation (white matter, gray matter and cerebrospinal
fluid).",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"to build the cross-age dataset, we take advantage 10 brain mris of
6-month-old from iseg2019 [20], and also build 3-month-old and 12-month-old
in-house datasets.","10 brain mris, 6 month olds, 2018, 2019, 3 month olds, 12 month olds, in-house datasets",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"the quantitative comparison results of cross-age infant brain
segmentation is presented in table 1, and due to space limitations, we put the
experimental results of the brain tumor segmentation task in table 1 of
supplementary material, sec.3.",brain tumor,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Spectral Adversarial MixUp for Few-Shot Unsupervised Domain Adaptation,"however, most uda methods
require sufficient target samples, which are scarce in medical imaging due to
the limited accessibility to patient data.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Gall Bladder Cancer Detection from US Images with only Image Level Labels,"non-ionizing
radiation, low cost, and accessibility make us a popular non-invasive diagnostic
modality for patients with suspected gall bladder (gb) afflictions.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Gall Bladder Cancer Detection from US Images with only Image Level Labels,"on the
other hand, the image-level malignancy label is usually available at a low cost,
as it can be obtained readily from the diagnostic report of a patient without
additional effort from clinicians.instead of training a classification pipeline,
we propose to solve an object detection problem, which involves predicting a
bounding box for the malignancy.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Gall Bladder Cancer Detection from US Images with only Image Level Labels,"gallbladder cancer detection in ultrasound images: we use the public gbc us
dataset [3] consisting of 1255 image samples from 218 patients.","gallbladder, cancer, ulltrasound images, US, patients, 1255 image samples from 218 patients",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Gall Bladder Cancer Detection from US Images with only Image Level Labels,"the dataset
contains 990 non-malignant (171 patients) and 265 malignant (47 patients) gb
images (see fig.","dataset, 990 non-malignant (171 patients), 265 malignant (47 patients), gb images ",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Gall Bladder Cancer Detection from US Images with only Image Level Labels,"we did the cross-validation splits at the patient level, and
all images of any patient appeared either in the train or validation split.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Gall Bladder Cancer Detection from US Images with only Image Level Labels,"since kvasir-seg does not contain any control images, we add 600
non-polyp images randomly sampled from the polypgen [1] dataset.since the
patient information is not available with the data, we use random stratified
splitting for 5-fold cross-validation.","no patient information, 600 non-polyp images ",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Structured State Space Models for Multiple Instance Learning in Digital Pathology,"patient selection for such
treatment regimes is based principally on the assessment of tissue biopsies and
the characterisation of the tumor microenvironment.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Structured State Space Models for Multiple Instance Learning in Digital Pathology,"in our experiments, the average patch sequence length
arising from camelyon16 is 6129 (ranging from 127 to 27444).tcga-luad is a tcga
lung adenocarcinoma dataset that contains 541 wsis along with genetic
information about each patient.","lung, adenocarcinoma, 541 wsis, genetic information, patient",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Structured State Space Models for Multiple Instance Learning in Digital Pathology,"as a mil task, we chose the task of predicting the
patient mutation status of tp53, a tumor suppressor gene that is highly relevant
in oncology studies.","patient mutation, tp53, tumor supressor gene, oncology",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision,"based on longitudinal imaging for a given patient it requires establishing which
lesions are corresponding (i.e., same lesion, observed at different timepoints),
which lesions have disappeared and which are new compared to prior scanning.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision,"inspired by the pixel-wise contrastive
learning strategy introduced in [5], we choose to learn pixel-wise feature
representations that embed consistent anatomical information from unlabeled
(i.e., without lesion-related annotations) and unpaired (i.e., without the use
of longitudinal scans) data, overcoming barriers to data collection.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision,"for nlst, we randomly selected a subset of 1045 test images coming from
420 patients with up to 3 studies.","subset, 1045 test images, 420 patients",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Geometry-Invariant Abnormality Detection,"this can include variances in scanner quality and
resolution, in addition to the fov selected during patient scans.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Geometry-Invariant Abnormality Detection,"in addition, we calculate the area under the precision-recall curve
(auprc) as a suitable measure for segmentation performance under class
imbalance.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Geometry-Invariant Abnormality Detection,"detection and segmentation of anomalous regions, particularly for cancer
patients, is essential for staging, treatment and intervention planning.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Interpretable Medical Image Classification Using Prototype Learning and Privileged Information,"the proposed approach is evaluated using the publicly available lidc-idri
dataset consisting of 1018 clinical thoracic ct scans from patients with
non-small cell lung cancer (nsclc) [2,3].","1018 clinical thoracic ct scans, non-small lung cancer, patients",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Incremental Learning for Heterogeneous Structure Segmentation in Brain Tumor MRI,"to explicitly avoid the overwriting of previously
learned parameters, our d 3 f follows a ""divide-and-conquer"" strategy to balance
the old and new tasks with a fixed rigidity branch and a compensated learnable
plasticity branch, which is guided by our novel divergence-aware continuous
batch renormalization (cbrn).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Incremental Learning for Heterogeneous Structure Segmentation in Brain Tumor MRI,"simply enforcing the same statistics across domains
as [5,30,33] can weaken the model expressiveness [36].the recent brn [10]
proposes to rectify the data shift between each batch and the dataset by using
the moving average μ and σ along with the training:where η ∈ [0, 1] is applied
to balance the global statistics and the current batch.in addition, γ = σb σ and
β = μb -μ σ are used in both training and testing.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Incremental Learning for Heterogeneous Structure Segmentation in Brain Tumor MRI,"specifically, we have the slice-level
segmentation se, which is the averaged entropy of the pixel-wise softmax
prediction asin training, the overall optimization loss is formulated as
follows:where α is used to balance our hsi distillation and se minimization
terms, and i max is the scheduled iteration.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ArSDM: Colonoscopy Images Synthesis with Adaptive Refinement Semantic Diffusion Models,"thus assigning constant weights for all polyps
exacerbated the imbalance problem.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ArSDM: Colonoscopy Images Synthesis with Adaptive Refinement Semantic Diffusion Models,"through extensive
experiments, we found inaccurate sample images with coarse polyp boundary that
is not aligned properly with the original masks may introduce large biases and
noises to the datasets.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Synthetic Augmentation with Large-Scale Unconditional Pre-training,"by ensuring that the fine-tuning
process is representative of the entire dataset through even sampling from each
tissue type, we can eliminate bias towards any particular tissue type.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Longitudinal Multimodal Transformer Integrating Imaging and Latent Clinical Signatures from Routine EHRs for Pulmonary Nodule Classification,"in this work, we jointly learn from longitudinal medical imaging, demographics,
billing codes, medications, and lab values to classify spns.","medical imaging, demographics, billing codes, medications, lab values",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0
Longitudinal Multimodal Transformer Integrating Imaging and Latent Clinical Signatures from Routine EHRs for Pulmonary Nodule Classification,"we searched all records in our ehr archives for patients who had billing codes
from a broad set of pulmonary conditions, intending to capture pulmonary
conditions beyond just malignancy.","ehr, patients, billing codes, pulmonary conditions",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Longitudinal Multimodal Transformer Integrating Imaging and Latent Clinical Signatures from Routine EHRs for Pulmonary Nodule Classification,"we searched our institution's imaging archive for
patients with three chest cts within five years.","imaging archive, three chest cst, within 5 years",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Partially Supervised Multi-organ Segmentation via Affinity-Aware Consistency Learning and Cross Site Feature Alignment,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Centroid-Aware Feature Recalibration for Cancer Grading in Pathology Images,"however, the current pathology workflow is sub-optimal and
low-throughput since it is, by and large, manually conducted, and the large
volume of workloads can result in dysfunction or errors in cancer grading, which
have an adversarial effect on patient care and safety [2].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Explaining Massive-Training Artificial Neural Networks in Medical Image Analysis Task Through Visualizing Functions Within the Models,"the complexity of dl models
reduces interpretability and transparency substantially; therefore, the current
dl models are ""black-box"" [2].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Explaining Massive-Training Artificial Neural Networks in Medical Image Analysis Task Through Visualizing Functions Within the Models,"dynamic contrast-enhanced liver ct scans
consisting of 42 patients with 194 liver tumors in the portal venous phase from
the lits database [21] were used in this study.","dynamic constrast-enhanced ct scans, ct scans, liver, patients, 42 patients, 194 liver tumors, portal venous phase",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
FeSViBS: Federated Split Learning of Vision Transformer with Block Sampling,"the second dataset [2] termed ""bloodmnist""
is a multi-class dataset consisting of 17, 092 blood cell images for 8 different
imbalanced cell types.","17.092 blood cell images, 8 different imbalances cell types",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
FeSViBS: Federated Split Learning of Vision Transformer with Block Sampling,"following [25], we used balanced accuracy in all experiments to evaluate the
performance of the classification task across all datasets.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"in
hospitals, collected multi-phase cts are normally grouped by patients rather
than lesions, which makes single-phase lesion annotation insufficient for
feature fusion learning.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"however, the number of lesions inside a single patient
can vary from one to dozens and they can be of different types in realistic
cases.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"first,
pure vit has several limitations itself [6], including ignoring local
information within each patch, extracting only single-scale features, and
lacking inductive bias.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"the single-phase annotated lesion has the position and class labels in all
phases but they are not aligned, so we could have difficulty finding out which
lesions in different phases are the same with 2 or more lesions in one patient.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"to reduce errors caused by unregistered data and address the situation that one
patient has multiple lesions of different types, we pre-process the multi-phase
liver cts registered and grouped by lesions.the registration network is based on
voxelmorph [1], with a u-net learning registration field and moving data
transformed by the field.","multi-phase liver cts grouped by lesions, liver, cts, lesions types, patients",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"we choose an atlas phase art as
suggested by clinicians and other phases of cts are registered to the art phase
of every patient.after registration, a lesion matcher finds the same lesions in
different phases.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"after the pre-processing unit with window
dice threshold of 0.3, we screen 761 lesions from 444 patients with four phases
of cts, seven types of lesions (13.2% of hcc, 5.3% of hm, 11.3% of icc, 22.6% of
hh, 31.1% of hc, 8.7% of fnh, and 7.8% of ha), and totally 4820 slices.","761 lesions, 444 patients, 4 phases cts, 7 types of lesions, 4820 slices",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"to
handle the imbalance of dataset, we randomly select 586 lesions as the training
and validation set with no more than 700 axial slices in each lesion type, and
the rest 175 lesions constitute the test set.","randomly selection of 586 lesions for traning and validation, 175 lesions for test set",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"lesions from the same patient are
either assigned to the training and validation set or the test set, but not
both.implementations.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"considering the fairness, all the models below are
initialized with pre-trained weights and adopt 2-d structures using the same
slice-level classification strategy.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Adaptive Region Selection for Active Learning in Whole Slide Image Semantic Segmentation,"this is advantageous because extensive al step size tuning to balance
the annotation and computation costs can be avoided.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
COLosSAL: A Benchmark for Cold-Start Active Learning for 3D Medical Image Segmentation,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation,"each pcle video represents one tumour type
and corresponds to a different patient.","pcle video, one tumour type, patient",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation,"the dataset is split into a training and testing subset, with the division done
on the patient level.implementation.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Continual Learning for Abdominal Multi-organ and Tumor Segmentation,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Efficient Subclass Segmentation in Medical Images,"while mixing up only the semantic foreground provides a way of exchanging
knowledge between similar foreground objects while lifting the confirmation bias
in pseudo labeling [1].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Towards AI-Driven Radiology Education: A Self-supervised Segmentation-Based Framework for High-Precision Medical Image Editing,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Localized Region Contrast for Enhancing Self-supervised Learning in Medical Image Segmentation,"abd-110 is an abdomen
dataset from [25] that contains 110 ct images from patients with various
abdominal tumors and these ct images were taken during the treatment planning
stage.","abdomen, 110 ct images, patients, abdominal tumors, ct images taken during treatment planning",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Localized Region Contrast for Enhancing Self-supervised Learning in Medical Image Segmentation,"in
the opposite, when the number of samples n is large, the sampling bias can be
high, since the number of pixels can be smaller than n .",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Faithful Synthesis of Low-Dose Contrast-Enhanced Brain MRI Scans Using Noise-Preserving Conditional GANs,"however, these contrast agents are expensive and may cause nephrogenic systemic
fibrosis in patients with severely reduced kidney function [31].",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Faithful Synthesis of Low-Dose Contrast-Enhanced Brain MRI Scans Using Noise-Preserving Conditional GANs,"moreover, [17]
reported that gadolinium accumulates inside patients with unclear health
consequences, especially after repeated application.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
A Spatial-Temporal Deformable Attention Based Framework for Breast Lesion Detection in Videos,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DeDA: Deep Directed Accumulator,"despite the effectiveness of general inductive
biases like translation equivariance [15] and locality [16], the diverse nature
of the gradient field map of the qsm images presents normalized gradient vectors
(the darker the blue, the larger the gradient vector's magnitude).",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DeDA: Deep Directed Accumulator,"consequently, the question of how
to incorporate domain-specific inductive biases, or priors, beyond general ones
into neural networks for medical image processing remains an open challenge.in
this study, we strive to answer this question by addressing the identification
problem associated with a specific type of multiple sclerosis (ms) lesion,
referred to as a chronic active lesion, or rim+ lesion.","multiple sclerosis lesion, ms, ",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DeDA: Deep Directed Accumulator,"despite
several efforts to tackle the issue [4,18,24], a clinically reliable solution
remains elusive.given the limited amount of data and high class imbalance, it's
more advantageous to explicitly incorporate domain knowledge into the network as
priors.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DeDA: Deep Directed Accumulator,"transformer-based networks with fewer inductive biases rely heavily on the
use of a large training dataset or depends strongly on the feature reuse [19],
as a result, these networks as well as cnns with deeper structures are prone to
overfit small datasets.implementation details: a stratified five-fold
cross-validation procedure was applied to train and validate the performance,
and all experiments including ablation study were carried out within this
setting.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DeDA: Deep Directed Accumulator,"capturing these characteristics
poses a challenge for modern neural networks, especially given limited and
imbalanced training data.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
OpenAL: An Efficient Deep Active Learning Framework for Open-Set Pathology Image Classification,"upon analysis, our openal is capable of effectively maintaining the
balance of sample numbers across different classes during active learning.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
OpenAL: An Efficient Deep Active Learning Framework for Open-Set Pathology Image Classification,"this
severe sample imbalance weakens the performance of lfosa compared to random
selection initially.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
OpenAL: An Efficient Deep Active Learning Framework for Open-Set Pathology Image Classification,"furthermore, we constructed a more imbalanced
setting for the target classes lym (6000 samples), norm (3000 samples), and tum
(9000 samples), yet the cumulative sampling ratios of our method for these three
target classes remain fairly balanced, as shown in fig.","6000 samples, 3000 norm, 9000 turn samples",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
SFusion: Self-attention Based N-to-One Multimodal Fusion Block,"medical
images may be missing due to artifacts and diverse patient conditions [11].",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
SFusion: Self-attention Based N-to-One Multimodal Fusion Block,"therefore, it has to simulate
missing data by crudely zero-padding or replacing it with similar modalities,
which inevitably introduces a bias in computation and causes performance
degradation [5,18,25].transformer has achieved success in the field of computer
vision, demonstrating that self-attention mechanism has the ability to capture
the latent correlation of image tokens.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
SFusion: Self-attention Based N-to-One Multimodal Fusion Block,"during training, to simulate real missing modalities scenarios, each training
patient's data is fixed to one of 15 possible missing cases.",patient's data,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
SFusion: Self-attention Based N-to-One Multimodal Fusion Block,"for a comprehensive
evaluation, we test the performance of all 15 cases for each test patient.our
implementations are on an nvidia rtx 3090(24g) with pytorch 1.8.1.","15 cases, patient",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
VISA-FSS: A Volume-Informed Self Supervised Approach for Few-Shot 3D Segmentation,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"however, as data-hungry
approaches, deep learning models require large balanced and high-quality
datasets to meet the in scl, head classes are overtreated leading to
optimization concentrating on head classes.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"by contrast, ecl utilizes the
proxies to enhance the learning of tail classes and treats all classes equally
according to balanced contrastive theory [24].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"some diseases are common while others are rare, making it difficult
to collect balanced data [13].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"thus,
existing public skin datasets usually suffer from imbalanced problems which then
results in class bias of classifier, for example, poor model performance
especially on tail lesion types.to tackle the challenge of learning unbiased
classifiers with imbalanced data, many previous works focus on three main ideas,
including re-sampling data [1,18], re-weighting loss [2,15,22] and re-balancing
training strategies [10,23].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"despite the
great results achieved, these methods either manually interfere with the
original data distribution or improve the accuracy of minority classes at the
cost of reducing that of majority classes [12,13].recently, contrastive learning
(cl) methods pose great potential for representation learning when trained on
imbalanced data [4,14].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"(3) most methods only
consider the impact of sample size (""imbalanced data"") on the classification
accuracy of skin diseases, while ignoring the diagnostic difficulty of the
diseases themselves (""imbalanced diagnosis difficulty"").to address the above
issues, we propose a class-enhancement contrastive learning (ecl) method for
skin lesion classification, differences between scl and ecl are illustrated in
fig.",skin lesions,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"we propose a
novel hybrid-proxy model to generate proxies for enhancing different classes
with a reversed imbalanced strategy, i.e., the fewer samples in a class, the
more proxies the class has.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"furthermore,
we propose a balanced-hybrid-proxy loss, besides introducing balanced
contrastive learning (bcl) [24].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"moreover, we design a balanced-weighted
crossentropy loss which follows a curriculum learning schedule by considering
both imbalanced data and diagnosis difficulty.our contributions can be
summarized as follows: (1) we propose an ecl framework for long-tailed skin
lesion classification.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"(2) we present a
balanced-hybrid-proxy loss to balance the optimization of each class and
leverage relations among samples and proxies.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"(3) a new balancedweighted
cross-entropy loss is designed for an unbiased classifier, which considers both
""imbalanced data"" and ""imbalanced diagnosis difficulty"".",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"(4) experimental
results demonstrate that the proposed framework outperforms other
state-of-theart methods on two imbalanced dermoscopic image datasets and the
ablation study shows the effectiveness of each element.","dermoscopic images, two imbalanced dermoscopic image datasets",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"both the class-dependent proxies generated by
hybrid-proxy model and the embeddings of samples are used to calculate
balanced-weighted cross-entropy loss, thus capturing the rich relations of
samples and proxies.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"since samples in a mini-batch follow
imbalanced data distribution, these proxies are designed to be generated in a
reversed imbalanced way by giving more representative proxies of tail classes
for enhancing the information of minority samples.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"the proxy
number n p c can be obtained by calculating the imbalanced factor nmax nc of
each class:in this way, the tail classes have more proxies while head classes
have less, thus alleviating the imbalanced problem in a mini-batch.as we know, a
gradient descent algorithm will generally be executed to update the parameters
after training a mini-batch of samples.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"however, when dealing with an imbalanced
dataset, tail samples in a batch contribute little to the update of their
corresponding proxies due to the low probability of being sampled.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"to tackle the problem that scl loss pays more attention on head classes, we
introduce bcl and propose balanced-hybrid-proxy loss to treat classes equally.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"the proposed
balanced-hybrid-proxy loss pulls points (both samples and proxies) in the same
class together, while pushes apart samples from different classes in embedding
space by using dot product as a similarity measure, which can be formulated as
follows:where b c means the sample number of class c in a batch, τ is the
temperature parameter.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"taking both ""imbalanced data"" and ""imbalanced diagnosis difficulty"" into
consideration, we design a curriculum schedule and propose balanced-weighted
cross-entropy loss to train an unbiased classifier.","imbalanced data, imbalanced diagnosis difficulty ",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"we first train a general classifier, then in the
second stage we assign larger weight to tail classes for ""imbalanced data"".",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"in
the last stage, we utilize the results on the validation set as the diagnosis
difficulty indicator of skin disease types to update the weights for ""imbalanced
diagnosis difficulty"".",skin disease types,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"to ensure fairness, we re-train all methods by rerun their released codes
on our divided datasets with the same experimental settings.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"noticeably, our ecl
outperforms other imbalanced methods by great gains, e.g., 2.56% in pre on
isic2018 compared with scl and 4.33% in f1 on isic2019 dataset compared with
tsc.","isic2018, isic2019",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"first, we directly move the contrastive learning
(cl) branch and replaced the balanced-weighted cross-entropy (bwce) loss with
cross-entropy (ce) loss.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"however, the result of using proxies generated by reversed
balanced way in hybrid-proxy model (hpm) outperforms equal proxies in nearly all
metrics, which proves that giving more proxies to tail classes can effectively
enhance and enrich the information.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"hybrid-proxy model and
balanced-hybrid-proxy loss are proposed to tackle the problem that scl-based
methods pay less attention to the learning of tail classes.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"furthermore, balanced-weighted
cross-entropy loss is designed to help train an unbiased classifier by
considering both ""imbalanced data"" and ""imbalanced diagnosis difficulty"".",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation,"to ensure fairness and eliminate model ensemble effects,
we only used the model's prediction with k = 1 during testing.",to ensure fairness,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation,"specifically, we calculate
the class probability distribution vector for each sample based on the pixel
class in the mask and use coreset with these vectors to select 40 class-balanced
samples.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
UniSeg: A Prompt-Driven Universal Segmentation Model as Well as A Strong Representation Learner,"(2) most segmentation tasks face the limitation of a small
labeled dataset, especially for 3d segmentation tasks, since pixel-wise 3d image
annotation is labor-intensive, time-consuming, and susceptible to operator bias.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Cross-Modulated Few-Shot Image Generation for Colorectal Tissue Classification,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Unpaired Cross-Modal Interaction Learning for COVID-19 Segmentation on Limited CT Images,"it is difficult to directly learn cross-modal
dependencies using the features obtained by the encoder because ct and x-ray
data were collected from different patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Unpaired Cross-Modal Interaction Learning for COVID-19 Segmentation on Limited CT Images,"all ct images were acquired
without intravenous contrast enhancement from patients with positive reverse
transcription polymerase chain reaction (rt-pcr) for sars-cov-2.","ct images, patients, rt-pcr, sars-cov-2",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Unpaired Cross-Modal Interaction Learning for COVID-19 Segmentation on Limited CT Images,"the chestx-ray14 dataset comprises
112,120 x-ray images showing positive cases from 30,805 patients, encompassing
14 disease image labels pertaining to thoracic and lung ailments.","chest x-ray, 120 x-ray images, positive cases, 30.805 patients, patients, 12 disease image labels, thoracic and lung ailments",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Structure-Preserving Instance Segmentation via Skeleton-Aware Distance Transform,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DAST: Differentiable Architecture Search with Transformer for 3D Medical Image Segmentation,"the transformer block is crafted with
longrange dependency inside sequences with marginal inductive bias.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DAST: Differentiable Architecture Search with Transformer for 3D Medical Image Segmentation,"intrinsically, it
shall benefit from inductive biases of these two popular deep learning
ingredients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DAST: Differentiable Architecture Search with Transformer for 3D Medical Image Segmentation,"however, from a network design's perspective, it is not trivial to find the
right balance between convolutions and transformers inside the architecture.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DAST: Differentiable Architecture Search with Transformer for 3D Medical Image Segmentation,"on the
other hand, more convolutions are chosen than transformers, which implicitly
suggests that this balance between convolutions and transformers is better for
feature learning in segmentation.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DAST: Differentiable Architecture Search with Transformer for 3D Medical Image Segmentation,"such models benefit from the different
inductive biases introduced by these two operations.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
MultiTalent: A Multi-dataset Approach to Medical Image Segmentation,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Co-assistant Networks for Label Correction,"for fairness, in our
experiments, we adopt the same neural network for all comparison methods based
on their public codes and default parameter settings.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Pre-trained Diffusion Models for Plug-and-Play Medical Image Enhancement,"however,
ct imaging has relatively high radiation doses that can pose a risk of radiation
exposure to patients.","ct imaging, patients",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Pre-trained Diffusion Models for Plug-and-Play Medical Image Enhancement,"this makes mr imaging safer for patients, particularly for those who require
frequent or repeated scans.","mr imaging, patients",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Pre-trained Diffusion Models for Plug-and-Play Medical Image Enhancement,"specifically, we used the identity matrix i as the degradation operator for the
denoising task and scaled the projection difference h † (hx 0|t -y) with
coefficient σ to balance the information from measurement y and denoising output
x 0|t .",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Robust T-Loss for Medical Image Segmentation,"in addition, medical image
annotations can be affected by human bias and poor inter-annotator agreement
[23], further complicating the process.","medical image annotations, human bias, inter-annotator agreement",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Multi-Head Multi-Loss Model Calibration,"a binary classifier in a
balanced dataset, randomly predicting always one class with c = 0.5 +
confidence, has a perfect calibration and 50% accuracy.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Multi-Head Multi-Loss Model Calibration,"the annotated part of this dataset contains 10,662 images,
and it represents a challenging classification problem due a high amount of
classes (23) and highly imbalanced class frequencies [2].","10.662 images, 23 classes, highly class frequencies",1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Multi-Head Multi-Loss Model Calibration,"we attribute this to class imbalance and the large number of
categories: smoothing labels might be ineffective in this scenario.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Guiding the Guidance: A Comparative Analysis of User Guidance Signals for Interactive Segmentation of Volumetric Images,"we discard the
513 tumor-free patients, leaving us with 501 volumes.","501 volumes, 513 tumor-free patients (discarded)",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Laplacian-Former: Overcoming the Limitations of Vision Transformers in Local Texture Detection,"then, a parametric frequency
attention fusion strategy to balance the importance of shape and texture
features by recalibrating the frequency features.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Laplacian-Former: Overcoming the Limitations of Vision Transformers in Local Texture Detection,"then it applies the ef-att mechanism to capture contextual
information and selectively include various types of frequency information while
using the laplacian pyramid to balance the importance of shape and texture
features.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Laplacian-Former: Overcoming the Limitations of Vision Transformers in Local Texture Detection,"to ensure a balanced distribution of low and
high-frequency information in the model, it is necessary to efficiently
aggregate the features from all levels of the frequency domain.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Understanding Silent Failures in Medical Image Classification,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Evidence Reconciled Neural Network for Out-of-Distribution Detection in Medical Images,"to ensure fairness, we used pretrained resnet34 [9] as
backbone for all methods.",to ensure fairness,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Scale-Aware Test-Time Click Adaptation for Pulmonary Nodule and Mass Segmentation,"the main reason is that the lesion scale in the
two public datasets are relatively small, which matches the fact few patients
have very large nodule or mass.","lesion, patients",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Scale-Aware Test-Time Click Adaptation for Pulmonary Nodule and Mass Segmentation,"though these
methods have achieved impressive performance, they still struggle to accurately
segment the extremely imbalanced multi-scale lesions.recently, some click-based
lesion segmentation methods [19][20][21] introduce the click at the input or
feature level and modify the network accordingly, resulting in higher accuracy
results.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Scale-Aware Test-Time Click Adaptation for Pulmonary Nodule and Mass Segmentation,"additionally, we
also propose a multi-scale input encoder to further address the problem of
imbalanced lesion scales.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Scale-Aware Test-Time Click Adaptation for Pulmonary Nodule and Mass Segmentation,"however,
incorporating clicks in this way does not focus on addressing the extremely
imbalanced lesion scales.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Scale-Aware Test-Time Click Adaptation for Pulmonary Nodule and Mass Segmentation,"in datasets such as lidc and in-house, where the number imbalance of
multi-scale lesion phenomena is more notable, the multi-input method
consistently outperforms the other two baselines.",multi-scale lesion phenomena,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Scale-Aware Test-Time Click Adaptation for Pulmonary Nodule and Mass Segmentation,"the difference between the two scatter diagrams indicates that the
proposed sattca effectively alleviates the issue of extremely imbalanced lesion
scales, and improves the segmentation performance for large lesions.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Scale-Aware Test-Time Click Adaptation for Pulmonary Nodule and Mass Segmentation,"this paper introduces a novel approach called the scale-aware test-time click
adaptation for nodule and mass segmentation, which aims to address the issue of
extremely imbalanced lesion scale and poor segmentation performance on
largescale nodules and masses.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
WeakPolyp: You only Look Bounding Box for Polyp Segmentation,"this indirect supervision avoids the misleading of box-shape bias of
annotations.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
WeakPolyp: You only Look Bounding Box for Polyp Segmentation,"because
there is a strong box-shape bias in b.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
WeakPolyp: You only Look Bounding Box for Polyp Segmentation,"training with this bias, the model is
forced to predict the box-shape mask, unable to maintain the polyp's contours.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
WeakPolyp: You only Look Bounding Box for Polyp Segmentation,"this indirect supervision
separates p 1 /p 2 from b so that p 1 /p 2 is not affected by the shape bias of
b while obtaining the position and extent of polyps.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
WeakPolyp: You only Look Bounding Box for Polyp Segmentation,"because both t 1 /t 2 and b are
box-like masks, we directly calculate the supervision loss between them without
worrying about the misguidance of box-shape bias.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Shifting More Attention to Breast Lesion Segmentation in Ultrasound Videos,"note that the breast lesion locations of neighboring ultrasound video frames are
close, while the breast lesion location distance is large for different
ultrasound videos, which are often obtained from different patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
ACC-UNet: A Completely Convolutional UNet Model for the 2020s,"smeswin-unet fell behind
in all the cases, despite having such a large number of parameters, which in
turn probably makes it difficult to be trained on small-scale datasets.however,
our model combining the design principles of transformers with the inductive
bias of cnns seemed to perform best in all the different categories with much
lower parameters.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ACC-UNet: A Completely Convolutional UNet Model for the 2020s,"the
resultant acc-unet possesses the inductive bias of cnns infused with long-range
and multi-level feature accumulation of transformers.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
FocalUNETR: A Focal Transformer for Boundary-Aware Prostate Segmentation Using CT Images,"despite good progress, these methods often have
limitations in capturing long-range relationships and global context information
[2] due to the inherent bias of convolutional operations.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
FocalUNETR: A Focal Transformer for Boundary-Aware Prostate Segmentation Using CT Images,"after obtaining the pooled feature mapsx l l 1 , we calculate the
query at the first level and key and value for all levels using three linear
projection layers f q , f k , and f v :for the queries inside the i-th window q
i ∈ r d×sw×sw , we extract the s l r × s l r keys and values from k l and v l
around the window where the query lies in and then gather the keys and values
from all l to obtainfinally, a relative position bias is added to compute the
focal sa forwhere b = {b l } l 1 is the learnable relative position bias [24].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,"the camus dataset [20] contains cardiac ultrasounds from 500 patients,
for which two-chamber and four-chamber sequences were acquired.manual
annotations for the endocardium and epicardium borders of the left ventricle
(lv) and the left atrium were obtained from a cardiologist for the end-diastolic
(ed) and end-systolic (es) frames.","cardiac ultrasounds, 500 patients, patients, endocardium, epicardium, left ventricle, left atrium, end-diastolic frames, end-systolic frames",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,"the dataset is split into 400 training
patients, 50 validation patients, and 50 testing patients.","400 training patients, 50 validation patients, 50 testing patients",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,"this is a proprietary multi-site multi-vendor dataset
containing 2d echocardiograms of apical two and four chambers from 890 patients.",2d echocardiograms from 890 patients,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,"data comes from patients diagnosed with coronary artery disease, covid, or
healthy volunteers.","patients, diagnosed with coronary artery disease, covid, healhty volunteers",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,"the dataset is split into a training/validation set (80/20)
and an independent test set from different sites, comprised of 994
echocardiograms from 684 patients and 368 echocardiograms from 206 patients,
respectively.","994 echocardiograms from 684 patients, 368 validation echocardiograms from 206 patients",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"however, most of these methods do not
consider the class imbalance issue, which is common in medical image datasets.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"for example, multi-organ segmentation from ct scans requires to segment
esophagus, right adrenal gland, left adrenal gland, etc., where the class ratio
is quite imbalanced; see fig 1(a).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"as for liver tumor segmentation from ct
scans, usually the ratio for liver and tumor is larger than 16:1.recently, some
researchers proposed class-imbalanced semi-supervised methods [1,10] and
demonstrated substantial advances in medical image segmentation tasks.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"[1] introduced a robust class-wise sampling strategy to
address the learning bias by maintaining performance indicators on the fly and
using fuzzy fusion to dynamically obtain the class-wise sampling rates.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"[10] proposed cld to address the data bias by weighting the overall loss
function based on the voxel number of each class.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"2) and propose a novel dhc (dual-debiased heterogeneous
co-training) framework with two distinct dynamic weighting strategies leveraging
both labeled and unlabeled data, to tackle the class imbalance issues and
drawbacks of the cps baseline model.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"the key idea of heterogeneous co-training
is that individual learners in an ensemble model should be both accurate and
diverse, as stated in the error-ambiguity decomposition [8].to achieve this, we
propose distdw (distribution-aware debiased weighting) and diffdw (diff
iculty-aware debiased weighting) strategies to guide the two sub-models to
tackle different biases, leading to heterogeneous learning directions.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"specifically, distdw solves the data bias by calculating the imbalance ratio
with the unlabeled data and forcing the model to focus on extreme minority
classes through careful function design.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"then, after observing the inconsistency
between the imbalance degrees and the performances (see fig.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"1(b)), diffdw is
designed to solve the learning bias.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"1(c)), which satisfies the design ethos of a heterogeneous framework.the
key contributions of our work can be summarized as follows: 1) we first state
the homogeneity issue of cps and improve it with a novel dual-debiased
heterogeneous co-training framework targeting the class imbalance issue; 2) we
propose two novel weighting strategies, distdw and diffdw, which effectively
solve two critical issues of ssl: data and learning biases; 3) we introduce two
public datasets, synapse [9] and amos [7], as new benchmarks for
class-imbalanced semi-supervised medical image segmentation.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"these datasets
include sufficient classes and significant imbalance ratios (> 500 : 1), making
them ideal for evaluating the effectiveness of class-imbalance-targeted
algorithm designs.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"dhc
leverages the benefits of combining two diverse and accurate sub-models with two
distinct learning objectives: alleviating data bias and learning bias.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"to mitigate the data distribution bias, we propose a simple yet efficient
reweighing strategy, distdw.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"blindly forcing the model to prioritize minority classes may
further exacerbate the learning bias, as some challenging classes may not be
learned to an adequate extent.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"we introduce two new benchmarks on the
synapse [9] and amos [7] datasets for class-imbalanced semi-supervised medical
image segmentation.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"moreover, simply extending the
state-of-the-art semi-supervised classification methods [2,3,5,15,17], including
class-imbalanced designs [3,5,17] to segmentation, is a straightforward solution
to our task.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"as shown in table 1 and2, the general semi-supervised methods which do
not consider the class imbalance problem fail to capture effective features of
the minority classes and lead to terrible performances (colored with red).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"the
methods considered the class imbalance problem have better results on some
smaller minority classes such as gallbladder, portal & splenic veins and etc.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"however, they still fail in some minority classes (es, rag, and lag) since this
task is highly imbalanced.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"distdw
('distdw-distdw') alleviates the bias of baseline on majority classes and thus
segments the minority classes (ra, la, es, etc.) very well.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"this work proposes a novel dual-debiased heterogeneous co-training framework for
class-imbalanced semi-supervised segmentation.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"to
achieve it, we propose two diverse and accurate weighting strategies: distdw for
eliminating the data bias of majority classes and diffdw for eliminating the
learning bias of well-performed classes.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,"by combining the complementary
properties of distdw and diffdw, the overall framework can learn both the
minority classes and the difficult classes well in a balanced way.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Anatomical-Aware Point-Voxel Network for Couinaud Segmentation in Liver CT,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
HENet: Hierarchical Enhancement Network for Pulmonary Vessel Segmentation in Non-contrast CT Images,"although contrast-enhanced ct images have better
contrast for pulmonary vessels compared to non-contrast ct images, the
acquisition of contrast-enhanced ct images needs to inject a certain amount of
contrast agent to the patients.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
HENet: Hierarchical Enhancement Network for Pulmonary Vessel Segmentation in Non-contrast CT Images,"some patients have concerns about the possible
risk of contrast media [2].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels,"kits includes 210 annotated ct scans of kidney tumors from different
patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels,"that is, the bias of the estimation is bounded above by the
calibration error and this explains why the calibration of the teacher would be
important for the student.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Semi-supervised Domain Adaptive Medical Image Segmentation Through Consistency Regularized Disentangled Contrastive Learning,"brats consists of brain mris from 285 patients with t1, t2, t1ce, and flair
scans.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
BerDiff: Conditional Bernoulli Diffusion Model for Medical Image Segmentation,"brats 2021 consists of four different
sequence (t1, t2, flair, t1ce) mri images for each patient.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
BerDiff: Conditional Bernoulli Diffusion Model for Medical Image Segmentation,"our training set includes 55,174 2d images scanned from 1,126 patients,
and the test set comprises 3,991 2d images scanned from 125 patients.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
BerDiff: Conditional Bernoulli Diffusion Model for Medical Image Segmentation,"we have the following
three observations: 1) diffusion-based methods demonstrate significant
superiority over traditional approaches based on vae, gan, and autoregression
models for discrete segmentation tasks; 2) our berdiff outperforms other
diffusion-based models that use gaussian noise as the diffusion kernel; and 3)
our berdiff also outperforms the methods that explicitly model the annotator,
striking a good balance between diversity and accuracy.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Annotator Consensus Prediction for Medical Image Segmentation with Diffusion Models,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Anti-adversarial Consistency Regularization for Data Augmentation: Applications to Robust Medical Image Segmentation,"considering the rois are
usually small and underrepresented compared to the backgrounds, the loss of
information may cause a fatal class imbalance problem in semantic segmentation
tasks.in these regards, we tackle these issues with a novel augmentation method
without distorting the semantics of objects in image space.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk,"relevant to the field of multimodal segmentation are also
developments on unpaired multimodal segmentation, where cross-modality learning
is employed to take advantage of different image modalities covering the same
anatomy, but without the constraint to collect images from the same patients
[5,10,19].",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk,"although the methodologies comprising cyclegans and/or multiple
segmentation networks [10,19] seem promising, they can be excessively complex
for the task of han oar segmentation where both ct and mr image modalities from
the same patient are often available.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk,"when segmenting oars in the han region for the purpose of
rt planning, a multimodal segmentation model that can leverage the information
from ct and mr images of the same patient might be beneficial compared to
separate single-modal models.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk,"this can be mitigated with
image registration, but not completely, mainly due to different patient
positioning that especially affects the deformation of soft tissues, and various
modality-specific artifacts (e.g.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk,"the han-seg dataset comprises ct and t1-weighted mr images of 56 patients, which
were deformably registered with the simpleelastix registration tool, and
corresponding curated manual delineations of 30 oars (for details, please refer
to [14]).",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Learning Reliability of Multi modality Medical Images for Tumor Segmentation via Evidence Identified Denoising Diffusion Probabilistic Models,"but it is still tricky to integrate
multi-modality medical images due to the complexity of medical images.existing
methods for multi-modality medical image integration can be categorized into
three groups: (1) input-based integration methods that concatenate
multi-modality images at the beginning of the framework to fuse them directly [
19,21], (2) feature-based fusion methods that incorporate a fusion module to
merge feature maps [16,23], and (3) decision-based fusion methods that use
weighted averaging to balance the weights of different modalities [11,15].",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network,breast cancer is the leading cause of cancer-related fatalities among women.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network,"currently, it holds the highest incidence rate of cancer among women in the
u.s., and in 2022 it accounted for 31% of all newly diagnosed cancer cases [1].",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network,"this is primarily because the
architectural design of vits does not rely on the same inductive biases in
feature extraction which allow cnns to learn spatially invariant
features.accordingly, numerous prior studies introduced modifications to the
original vit network specifically designed for bus image classification
[13,14,23].",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network,"moreover,
multitask learning acts as a regularizer by introducing inductive bias and
prevents overfitting [25] (particularly with vits), and with that, can mitigate
the challenges posed by small bus dataset sizes.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network,"to avoid data
leakage and bias, we selected the train, test, and validation sets based on the
cases, i.e., the images from one case (patient) were assigned to only one of the
training, validation, and test sets.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"the convolution operation in cnn provides a strong inductive bias
which is translational equivalent and efficient in capturing local features like
boundary and texture.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"however, this inductive bias limits the representation
power of cnn models which means a potentially lower performance ceiling on more
challenging tasks [7].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"it has a
u-shaped structure where the encoder is a swin-transformer [16].although
transformers have achieved certain success in medical imaging, the lack of
inductive bias makes them harder to be trained and requires much more training
data to avoid overfitting.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"besides lacking
inductive bias and enough training data, one extra reason could be that
transformers are computationally much expensive and harder to tune.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"coatnet [5] unifies convolution and
self-attention with relative attention, while convit [7] uses gated positional
self-attention which is equipped with a soft convolutional inductive bias.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"although swin-transformer uses local window attention to introduce
inductive bias like convolutions, self-attentions can still mess up with the
local details.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"although existing
window-based attention already has a convolution-like inductive bias, it is
still not good enough for learning local details as convolutions.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,"by only adding one resconv block at the beginning of each resolution
level, the features can be well-regularized while not too constrained by the
convolution inductive bias, and the computation cost will not increase by a lot.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
SimPLe: Similarity-Aware Propagation Learning for Weakly-Supervised Breast Cancer Segmentation in DCE-MRI,"breast cancer is the most common cause of cancer-related deaths among women all
around the world [8].",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
SimPLe: Similarity-Aware Propagation Learning for Weakly-Supervised Breast Cancer Segmentation in DCE-MRI,"early diagnosis and treatment is beneficial to improve the
survival rate and prognosis of breast cancer patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
SimPLe: Similarity-Aware Propagation Learning for Weakly-Supervised Breast Cancer Segmentation in DCE-MRI,"the method obtained a dice value
of 83% using the interval-slice annotation, on a testing dataset containing only
28 patients.in this study, we propose a simple yet effective weakly-supervised
strategy, by using extreme points as annotations (see fig.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
SimPLe: Similarity-Aware Propagation Learning for Weakly-Supervised Breast Cancer Segmentation in DCE-MRI,"such setting can help alleviate class
imbalance issue.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Uncertainty-Informed Mutual Learning for Joint Medical Image Classification and Segmentation,"a total of 157 patients who suffer
the breast cancer are considered -43 achieve pcr and 114 non-pcr.for each case,
we cut out the slices in the 3d image and totally got 1,570 2d images, which are
randomly divided into the train, validation, and test datasets with 1,230, 170,
and 170 slices, respectively.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Conditional Diffusion Models for Weakly Supervised Medical Image Segmentation,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DBTrans: A Dual-Branch Vision Transformer for Multi-Modal Brain Tumor Segmentation,"compared with natural images,
medical image segmentation often requires higher accuracy to make subsequent
treatment plans for patients.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
DBTrans: A Dual-Branch Vision Transformer for Multi-Modal Brain Tumor Segmentation,"here we use parameter γ to balance the
two loss parts.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
HartleyMHA: Self-attention in Frequency Domain for Resolution-Robust and Parameter-Efficient 3D Image Segmentation,"to balance
between computational complexity and network capability, input size reductions
by image downsampling and patch-wise training are common approaches.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
MDViT: Multi-domain Vision Transformer for Small Medical Image Segmentation Datasets,"however, due to the lack of inductive biases, such as
weight sharing and locality, vits are more data-hungry than cnns, i.e., require
more data to train [31].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
MDViT: Multi-domain Vision Transformer for Small Medical Image Segmentation Datasets,"various strategies have been
proposed to address vits' data-hunger (table 1), mainly: adding inductive bias
by constructing a hybrid network that fuses a cnn with a vit [39], imitating
cnns' shifted filters and convolutional operations [7], or enhancing spatial
information learning [22]; sharing knowledge by transferring knowledge from a
cnn [31] or pertaining vits on multiple related tasks and then fine-tuning on a
down-stream task [37]; increasing data via augmentation [34]; and non-supervised
pre-training [8].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
MDViT: Multi-domain Vision Transformer for Small Medical Image Segmentation Datasets,"previous mis
vits mitigated the data-hunger in one dataset by adding inductive bias, e.g.,
swinunet the online version contains supplementary material available at
https://doi.org/10.1007/978-3-031-43901-8 43.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
M-GenSeg: Domain Adaptation for Target Modality Tumor Segmentation with Annotation-Efficient Supervision,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Edge-Aware Multi-task Network for Integrating Quantification Segmentation and Uncertainty Prediction of Liver Tumor on Multi-modality Non-contrast MRI,"simultaneous multi-index quantification (i.e., max diameter (md), center point
coordinates (x o , y o ), and area), segmentation, and uncertainty prediction of
liver tumor have essential significance for the prognosis and treatment of
patients [6,16].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
RCS-YOLO: A Fast and High-Accuracy Object Detector for Brain Tumor Detection,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Certification of Deep Learning Models for Medical Image Segmentation,"indeed, segmentation techniques and variations of 2d
and 3d u-nets are currently the state-of-the-art to identify and isolate tumors,
blood vessels, organs, or other structures within an image and provide crucial
help to physicians for medical diagnosis, screening, and prognosis
[32].nowadays, segmentation models are gaining widespread adoption in modern
clinical practice and are being used with increasing frequency, making the
results of these models critical for many patients.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Category-Level Regularized Unlabeled-to-Labeled Learning for Semi-supervised Prostate Segmentation with Multi-site Unlabeled Data,"unfortunately, such ""abundance"" may be unobtainable in practice, i.e., the
local unlabeled pool is also limited due to restricted image collection
capabilities or scarce patient samples.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Category-Level Regularized Unlabeled-to-Labeled Learning for Semi-supervised Prostate Segmentation with Multi-site Unlabeled Data,"yet, due to differences
in imaging protocols and variations in patient demographics, this solution
usually introduces data heterogeneity, lead-ing to a quality problem.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,1,0
Category-Level Regularized Unlabeled-to-Labeled Learning for Semi-supervised Prostate Segmentation with Multi-site Unlabeled Data,"inherently, the challenge of ms-ssl stems from
intra-class variation, which results from different imaging protocols, disease
progress and patient demographics.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,1,0
Category-Level Regularized Unlabeled-to-Labeled Learning for Semi-supervised Prostate Segmentation with Multi-site Unlabeled Data,"compared
to c1 and c2, scans from c3 to c6 are taken from patients with prostate cancer,
either for detection or staging purposes, which can cause inherent semantic
differences in the prostate region to further aggravate heterogeneity.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Category-Level Regularized Unlabeled-to-Labeled Learning for Semi-supervised Prostate Segmentation with Multi-site Unlabeled Data,"all methods are implemented
with the same backbone and training protocols to ensure fairness.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
A Sheaf Theoretic Perspective for Robust Prostate Segmentation,"recent methods have utilized adversarial techniques,
such as advbias [11], which trains the model to generate bias field deformations
and enhance its robustness.randconv [33] incorporates a randomized convolution
layer to learn textural invariant features.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
MedNeXt: Transformer-Driven Scaling of ConvNets for Medical Image Segmentation,"however, transformers are plagued by
the necessity of large annotated datasets to maximize performance benefits owing
to their limited inductive bias.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
MedNeXt: Transformer-Driven Scaling of ConvNets for Medical Image Segmentation,"to retain the
inherent inductive bias of convolutions while taking advantage of architectural
improvements of transformers, the convnext [22] was recently introduced to
re-establish the competitive performance of convolutional networks for natural
images.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
MedNeXt: Transformer-Driven Scaling of ConvNets for Medical Image Segmentation,"out-of-the-box
data-efficient solutions such as nnunet [13], using variants of a standard unet
[5], have still remained effective across a wide range of tasks.the convnext
architecture marries the scalability and long-range spatial representation
learning capabilities of vision [7] and swin transformers [21] with the inherent
inductive bias of convnets.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
MedNeXt: Transformer-Driven Scaling of ConvNets for Medical Image Segmentation,"compression layer: convolution
layer with 1 × 1 × 1 kernel and c output channels performing channel-wise
compression of the feature maps.mednext is convolutional and retains the
inductive bias inherent to conv-nets that allows easier training on sparse
medical datasets.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
MedNeXt: Transformer-Driven Scaling of ConvNets for Medical Image Segmentation,"specifically, swin transformers use a bias matrix b ∈
r (2m -1)×(2m -1) to store learnt relative positional embeddings, where m is the
number of patches in an attention window.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
MedNeXt: Transformer-Driven Scaling of ConvNets for Medical Image Segmentation,"the authors proposed spatially
interpolating an existing bias matrix to the larger size as a pretraining step,
instead of training from scratch, which demonstrated improved performance.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,"it enables the
extraction of semi-quantitative metrics such as standardized uptake values
(suvs), which normalize pixel intensities based on patient weight and
radiotracer dose [20].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,"however, the performance of kspc depends heavily on the
tuning parameters of bandwidth and threshold in the model, and it lacks
information from other patients.beyond tumour delineation, another important use
of functional images, such as pet images is their use for designing imrt dose
painting (dp).",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,"the hecktor training dataset consists of 224 patients
diagnosed with oropharyngeal cancer [1].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,"for each patient, fdg-pet input images
and corresponding labels in binary description (0 s and 1 s) for the primary
gross tumour volume are provided and co-registered to a size of 144 × 144 × 144
using bounding box information encompassing the tumour.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
A2FSeg: Adaptive Multi-modal Fusion Network for Medical Image Segmentation,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"[1] proposed a random forest model [2], which adopts the radiomics features [3]
of the brain tumor images, to predict the overall survival (os) time of diffuse
glioma patients.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"concerning the inherent issue of imbalanced tumor types in the training data
collected in clinic, a novel ordinal manifold mixup based feature augmentation
is presented and applied in the training stage of the tumor subtyping network.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"in this way, inconsistency between the augmented features and the corresponding
labels can be effectively reduced.our method is evaluated using pre-operative
multimodal mr brain images of 1726 diffuse glioma patients collected from
cooperation hospitals and a public dataset brats2019 [12] containing multimodal
mr brain images of 210 patients.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"the survival prediction backbone is a deep cox proportional hazard model [14]
which takes the multimodal mr brain images of diffuse glioma patients as inputs
and predicts the corresponding risks.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"the tumor subtyping network is a
classification network, which classifies the patient tumor types and feeds the
learned tumor-type-related features to the backbone to enhance the survival
prediction performance.the tumor subtyping network is trained independently
before being integrated into the backbone.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"to solve the inherent issue of
imbalanced tumor type in the training data collected in clinic, a novel ordinal
manifold mixup based feature augmentation is applied in the training of the
tumor subtyping network.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"assume that d = {x 1 , ...,
x n } is the dataset containing pre-operative multimodal mr brain images of
diffuse glioma patients, and n is the number of patients.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"the backbone is
responsible for deriving features from x i to predict the risk of the patient.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"in addition, information of patient age and tumor
position is also used.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"the backbone is based on the
deep cox proportional hazard model, and the loss function is defined as:where h
θ (x i ) represents the risk of the i-th patient predicted by the backbone, θ
stands for the parameters of the backbone, x i is the input multimodal mr brain
images of the i-th patient, r(t i ) is the risk group at time t i , which
contains all patients who are still alive before time t i , t i is the observed
time (time of death happened) of x i , and δ i = 0/1 for censored/non-censored
patient.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"the cross entropy is adopted as
the loss function of the tumor subtyping network, which is defined as:where y k
i and p k i are the ground truth (0 or 1) and the prediction (probability) of
the k-th tumor type (k = 1, 2, 3) of the i-th patient, respectively.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"to solve the imbalance issue
of tumor types in the training of the tumor subtyping network, a novel ordinal
manifold mixup based feature augmentation is presented.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"specifically, the augmented feature fi∼j and label ȳi∼j is defined
as:where y k i and y k j stand for the labels of the k-th tumor type of the i-th
and j-th patients, respectively, and λ ∈ [0, 1] is a weighting factor.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"as aforementioned, the survival time
of patients with different tumor types varies largely (oligodendroglioma >
astrocytoma > glioblastoma), so the tumor types can be regarded as risk grade,
which are ordered rather than categorical.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"finally, the ordinal loss, which is in the form of kl
divergence, is defined as:in our method, μ k and σ 2 k are calculated bywhere φ
θ and g are the encoder and gap of the tumor subtyping network, respectively, θ
is the parameter set of the encoder,stands for the subset containing the
pre-operative multimodal mr brain images of the patients with the k-th tumor
type, n k is the patient number in d k .",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"in the training stage of the
tumor subtyping network, each input batch contains pre-operative multimodal mr
brain images of n patients and can be divided into k = 3 subsets according to
their corresponding tumor types, i.e., d k , k = 1, 2, 3.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"specifically, the in-house dataset collected in cooperation hospitals
contains pre-operative multimodal mr images, including t1, t1 contrast enhanced
(t1c), t2, and flair, of 1726 patients (age 49.7 ± 13.1) with confirmed diffuse
glioma types.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"the patient number of each tumor type is 361 (oligodendroglioma),
495 (astrocytoma), and 870 (glioblastoma), respectively.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"in the 1726 patients,
743 have the corresponding overall survival time (dead, non-censored), and 983
patients have the last visiting time (alive, censored).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"besides the inhouse
dataset, a public dataset brats2019, including pre-operative multimodal mr
images of 210 non-censored patients (age 61.4 ± 12.2), is adopted as the
external independent testing dataset.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"according to the bounding boxes of all
1936 patients, the size of input 3d image patch is set to 96 × 96 × 64 voxels,
which can cover the entire tumor of every patient.besides our method, four
state-of-the-art methods, including random forest based method (rf) [18], deep
convolutional survival model (deepconvsurv) [19], multi-channel survival
prediction method (mcsp) [20], and imaging phenotype and genotype based survival
prediction method (pgsp) [9], are evaluated.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"concordance index (c-index) is adopted to quantify the
prediction accuracy:where d = {x 1 , ..., x n } is the dataset containing all
patients, t i and t j are ground truth of survival times of the i-th and j-th
patients, r i and r j are the days predicted by rf, mcsp, and pgsp or risks
predicted by the deep cox proportional hazard models (i.e., deepconvsurv and our
method), 1 x<y = 1 if x < y, else 0, and δ i = 0 or 1 when the i-th patient is
censored or non-censored.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"as rf, mcsp, and pgsp cannot use the censored data in
the in-house dataset, 80% of the non-censored data (594 patients) are randomly
selected as the training data, and the rest 20% non-censored data (149 patients)
are for testing.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"while deepconvsurv and our method are deep cox models, both
censored and non-censored patients can be utilized.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"so besides the 80%
non-censored patients, all censored data (983 patients) are also included in the
training data.table 1 shows the evaluation results of the in-house and the
external independent (brats2019) testing datasets using all methods under
evaluation.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"we proposed a new method for pre-operative survival prediction of diffuse glioma
patients, where a tumor subtyping network is integrated into the prediction
backbone.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"both in-house and public
datasets containing 1936 patients were used in the experiment.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Medical Boundary Diffusion Model for Skin Lesion Segmentation,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation,"to address this problem, we propose the densely connected
transformer (dct) module inspired by densenet [17] to balance computational cost
and representation capability.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation,"to mitigate the
pixel imbalance problem, we use a combined loss of focal loss [23] and dice loss
as the optimization target, defined as follows:where n refers to the total
number of pixels, p t and q t denote the predicted probability and ground truth
of the t-th pixel, respectively, and r = 2 is the modulation factor.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation,"pi-cai22
provides multimodal mr images of 220 patients with prostate cancer, including
t2-weighted imaging (t2w), high b-value diffusion-weighted imaging (dwi), and
apparent diffusion coefficient (adc) maps.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation,"overall, h-denseformer reaches an
effective balance of performance and computational cost compared to existing
cnns and hybrid structures.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation,"concretely, a
multi-path parallel embedding module and a densely connected transformer block
were developed and integrated to balance accuracy and computational complexity.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
TransNuSeg: A Lightweight Multi-task Transformer for Nuclei Segmentation,"for both datasets, we randomly split
80% of the samples on the patient level as the training set and the remaining
20% as the test set.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Learnable Cross-modal Knowledge Distillation for Multi-modal Learning with Missing Modality,"[5]
proposed an rfm module to fuse the modal features based on the sensitivity of
each modality to different tumor regions and a segmentation-based regularizer to
address the imbalanced training problem.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learnable Cross-modal Knowledge Distillation for Multi-modal Learning with Missing Modality,"however, the aforementioned methods neglect the contribution biases
of different modalities and failed to consider keeping that knowledge.aiming at
this issue, we propose the non-dedicated training model1 learnable cross-modal
knowledge distillation (lckd) for tackling the missing modality issue.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
QCResUNet: Joint Subject-Level and Voxel-Level Prediction of Segmentation Quality,"the
two parts are combined using a weight parameter λ to balance the different loss
components:3 experimentsfor this study, pre-operative multimodal mri scans of
varying grades of glioma were obtained from the 2021 brain tumor segmentation
(brats) challenge [1] training dataset (n = 1251).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
QCResUNet: Joint Subject-Level and Voxel-Level Prediction of Segmentation Quality,"however, this generated dataset suffered from
imbalance (fig.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
QCResUNet: Joint Subject-Level and Voxel-Level Prediction of Segmentation Quality,"training using such an imbalanced dataset is prone to
producing biased models that do not generalize well.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
QCResUNet: Joint Subject-Level and Voxel-Level Prediction of Segmentation Quality,"we performed a random search [2]
to determine the optimal hyperparameters (i.e., initial learning rate and loss
weight balance parameter λ) on the training and validation set.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
EGE-UNet: An Efficient Group Enhanced UNet for Skin Lesion Segmentation,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Diffusion Kinetic Model for Breast Cancer Segmentation in Incomplete DCE-MRI,"however, the
aforementioned methods require the complete dce-mri sequences and overlook the
difficulty in assessing complete temporal sequences and the missing time point
problem, especially post-contrast phase, due to the privacy protection and
patient conditions.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Diffusion Kinetic Model for Breast Cancer Segmentation in Incomplete DCE-MRI,"dataset: to demonstrate the effectiveness of our proposed dkm, we evaluate our
method on 4d dce-mri breast cancer segmentation using the breast-mri-nact-pilot
dataset [13], which contains a total of 64 patients with the contrastenhanced
mri protocol: a pre-contrast scan, followed by 2 consecutive postcontrast time
points (as shown in fig.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Diffusion Kinetic Model for Breast Cancer Segmentation in Incomplete DCE-MRI,no data augmentation techniques are used to ensure fairness.,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Diffusion Kinetic Model for Breast Cancer Segmentation in Incomplete DCE-MRI,"no data augmentation techniques are used to ensure
fairness.comparison with sota methods: the quantitative comparison of the
proposed method to recent state-of-the-art methdos is reported in table 1.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Morphology-Inspired Unsupervised Gland Segmentation via Selective Semantic Grouping,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
EoFormer: Edge-Oriented Transformer for Brain Tumor Segmentation,"specifically, we explain the re-parameterization of the eol
module as follows:where ' * ' represents the convolution operation, w conv means
the weights of the convolution and b conv denotes the bias, and up(•) is the
spatial broadcasting operation ,which upgrades the bias b ∈ r 1×c×1×1×1 into
up(b) ∈ r 1×c×3×3×3 .",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
EoFormer: Edge-Oriented Transformer for Brain Tumor Segmentation,"the brats 2020 dataset [14]
consists of mri image data from 369 patients, with each patient having four
modalities (t1, t1ce, t2 and t2-flair) of skull-striped mri, which are aligned
to a standard brain template.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
EoFormer: Edge-Oriented Transformer for Brain Tumor Segmentation,"the training/validation/test split follows
315/16/37 according to recent works [10,23].the medseg dataset includes mri
images of t1, t1ce, t2, and t2 flair modalities from 255 patients with
medulloblastoma.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
EoFormer: Edge-Oriented Transformer for Brain Tumor Segmentation,"the encoder effectively extracts features from
images by striking a balance between cnn and transformer architectures.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"medical image analysis has greatly benefited from advances in ai [1] yet some
improvements still remain to be addressed, importantly in areas that allow both
algorithmic performance and fairness [2], and in certain medical applications
that promise to significantly lessen morbidity and mortality.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"while the em pattern may appear simple to recognize,
its diagnosis can be challenging for those with or without a medical background
alike, as only 20% of united states patients have the stereotypical bull's eye
lesion [6].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"such dl-assisted segmentation not only helps clinicians in pre-screening
patients but also improves downstream tasks such as lesion classification.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"furthermore, clinical data collected for training is
usually imbalanced in some properties, e.g., more samples with light skins
compared with dark skins.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"therefore, existing skin disease segmentation [13] as
well as existing general segmentation works, such as u-net [14], polar training
[15], vit-adapter [16], and mfsnet [17], usually suffer from relatively low
performance and reduced fairness [2,18,19].in this paper, we present the first
lyme disease dataset that contains labeled segmentation and skin tones.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"our lyme
disease dataset contains two parts: (i) a classification dataset, composed of
more than 3,000 diseased skin images that are either obtained from public
resources or clinicians with patient-informed consent, and (ii) a segmentation
dataset containing 185 samples that are manually annotated for three
regions-i.e., background, skin (light vs.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"our
dataset with manual labels is available at this url [20].secondly, we design a
simple yet novel data preprocessing and alternation method, called edgemixup, to
improve lyme disease segmentation and diagnosis fairness on samples with
different skin-tones.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"such an
improvement is an iterative process that gradually improves lesion edge
detection and segmentation fairness until convergence.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"then, the detected,
converged edge in the first step also helps classification of lyme diseases via
mixup with improved fairness.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"our
results show that edgemixup is able to increase segmentation utility and improve
fairness.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"we also show that the improved segmentation further improves
classification fairness as well as joint fairness-utility metrics compared to
existing debiasing methods, e.g., ad [21] and st-debias [22].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"in this section, we first give the definition for model fairness, and we then
describe the design of edgemixup for the purpose of de-biasing in fig.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"2
edgemixup improves model fairness on light and dark skin samples in both
segmentation and classification tasks, and it has two major components: (i) edge
detection using mixup, and (ii) data preprocessing and alteration for downstream
tasks.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"note that the
initial edge detection is irrelevant to the sample size of a particular
subpopulation, thus improving the fairness.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"that is, even if the original
dataset is imbalanced, as long as one sample from a subpopulation exists, the
color range of the sample's lesion is considered in the initial detection.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"all skin images are either collected from publicly
available sources or from clinicians with patient informed consent.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"one
prominent observation is that ls images are more abundant than ds images due to
a disparity in the availability of ds imagery found from either public sources
or from clinicians with patient consent.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"our evaluation metrics include (i) jaccard index (iou score), which
measures the similarity between a predicted mask and the manually annotated
ground truth, and (ii) the gap between jaccard values (j gap ) to measure
fairness.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"table 2 shows the performance and fairness of edgemixup and different
baselines.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"our evaluation metrics include accuracy gap, the (rawlsian) minimum
accuracy across subpopulations, area under the receiver operating characteristic
curve (auc), and joint metrics (cai α and cauci α ).table 3 shows utility
performance (acc and auc) and fairness results (gaps of acc and auc between ls
and ds subpopulations).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"however, official datasets released, e.g., ham10000 [10] only
contains melanoma samples and all of the samples are with light skins according
to our inspection using ita scores.bias mitigation: researchers have addressed
bias and heterogeneity in deep learning models [18,29].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"first, masking sensitive
factors in imagery is shown to improve fairness in object detection and action
recognition [30].",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"the key insight is a novel data
preprocessing method that utilizes edge detection and mixup to isolate and
highlight skin lesions and reduce bias.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Factor Space and Spectrum for Medical Hyperspectral Image Segmentation,"following [23,27], we partition the datasets into training, validation, and
test sets using a patient-centric hard split approach with a ratio of 3:1:1.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Factor Space and Spectrum for Medical Hyperspectral Image Segmentation,"specifically, each patient's data is allocated entirely to one of the three
sets, ensuring that the same patient's data do not appear in multiple sets.we
use data augmentation techniques such as rotation and flipping, and train with
an adam optimizer using a combination of dice loss and cross-entropy loss for 8
batch size and 100 epochs.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,"the periodic acquisition and analysis of volumetric ct and mri scans of oncology
patients is essential for the evaluation of the disease status, the selection of
the treatment, and the response to treatment.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,"currently, scans are acquired
every 2-12 months according to the patient's characteristics, disease stage, and
treatment regime.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,"as
treatments improve and patients live longer, the number of scans in longitudinal
studies increases and their interpretation is more challenging and
time-consuming.radiological follow-up requires the quantitative analysis of
lesions and patterns of lesion changes in subsequent scans.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,"experimental results on lung (83 cts, 19 patients) and liver (77 cects, 18
patients) datasets show that our method yields high classification accuracy.to
the best of our knowledge, ours is the first method to perform longitudinal
lesion matching and lesion changes pattern detection.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,", s n be a series of n ≥ 2 consecutive patient scans
acquired at timesis a set of vertices v i j corresponding to the lesions
associated with the lesion segmentation masks l i = l i 1 , l i 2 , .",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,"we evaluated our method with two studies on retrospectively collected patient
datasets that were manually annotated by an expert radiologist.dataset: lung and
liver ct studies were retrospectively obtained from two medical centers
(hadassah univ hosp jerusalem israel) during the routine clinical examination of
patients with metastatic disease.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,"each patient study consists of at least 3
scans.dlung consists of 83 chest ct scans from 19 patients with a mean 4.4 ± 2.0
scans/patient, a mean time interval between consecutive scans of 125.9 ± 81.3
days, and voxel sizes of 0.6-1.0 × 0.6-1.0 × 1.0-3.0 mm 3 .",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,"dliver consists of
77 abdominal cect scans from 18 patients with a mean 4.3 ± 2.0 scans/patient, a
mean time interval between consecutive scans of 109.7 ± 93.5 days, and voxel
sizes of 0.6-1.0 × 0.6-1.0 × 0.8-5.0 mm 3 .lesions in both datasets were
annotated by an expert radiologist, yielding a total of 1,178 lung and 800 liver
lesions, with a mean of 14.2 ± 19.1 and 10.4 ± 7.9 lesions/scan (lesions with
<20 voxels were excluded).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,"the use of graph-based methods for lesion tracking and detection of patterns of
lesion changes was shown to achieve high accuracy in classifying changes in
individual lesion and identifying patterns of lesion changes in liver and lung
longitudinal ct studies of patients with metastatic disease.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,"this approach has
proven to be useful in detecting missed, faint, and surmised to be present
lesions, otherwise hardly detectable by examining the scans separately or in
pairs, leveraging the added information provided by evaluating all patient's
scans simultaneously using the labels from the lesion changes graph and
non-consecutive edges.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"neuropsychiatric systemic lupus erythematosus (npsle) refers to a complex
autoimmune disease that damages the brain nervous system of patients.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"the
clinical symptoms of npsle include cognitive disorder, epilepsy, mental illness,
etc., and patients with npsle have a nine-fold increased mortality compared to
the general population [11].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"however, the high overlap of clinical symptoms with other
psychiatric disorders and the absence of early non-invasive biomarkers make
accurate diagnosis difficult and time-consuming [3].although conventional
magnetic resonance imaging (mri) tools are widely used to detect brain injuries
and neuronal lesions, around 50% of patients with npsle present no brain
abnormalities in structural mri [17].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"figure 1
shows spectra images of four participants including healthy controls (hc) and
patients with npsle.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"it can be seen that the visual differences between patients
with npsle and hcs in the spectra of the volumes are subtle.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"dataset and preprocessing: the t2-weighted mr images of 39 participants
including 23 patients with npsle and 16 hcs were gathered from our affiliated
hospital.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"all images were acquired at an average age of 30.6 years on a signa
3.0t scanner with an eight-channel standard head coil.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"we also found
that glu+gln/cr+pcr in ri decreased, which indicates that the excitatory
neurotransmitter glu in the brain of patients with npsle may have lower
activity.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
CARL: Cross-Aligned Representation Learning for Multi-view Lung Cancer Histology Classification,"we
observed that l ce is hundred times smaller than l sim , so this study uses an
empirical value of λ = 110 to balance the magnitude of two terms.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
CARL: Cross-Aligned Representation Learning for Multi-view Lung Cancer Histology Classification,"exclusion criteria involves
patients diagnosed with large cell carcinoma or not otherwise specified, along
with cases that have contouring inaccuracies or lacked tumor delineation [9,13].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
CARL: Cross-Aligned Representation Learning for Multi-view Lung Cancer Histology Classification,"in summary, we propose a novel multi-view method called cross-aligned
representation learning (carl) for accurately distinguishing between adc and scc
using multi-view ct images of nsclc patients.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Self- and Semi-supervised Learning for Gastroscopic Lesion Detection,"some appearances of lesions are quite
rare and can only be observed in a few patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Self- and Semi-supervised Learning for Gastroscopic Lesion Detection,"in semi-supervised
learning, ppg generates pseudo-labels for unlabeled data relying on the
similarity to the prototype feature vectors, which achieves a better balance
between lesion discovery and noise avoidance.memory module.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Self- and Semi-supervised Learning for Gastroscopic Lesion Detection,"collection : lgmdd collects about 1m+ gastroscopic
images from 2 hospitals of about 500 patients and their diagnosis reports.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Revisiting Feature Propagation and Aggregation in Polyp Segmentation,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","in the uk, approximately 11,500 patients are diagnosed with rectal cancer each
year [19].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","a common form of treatment for such patients is neoadjuvant therapy,
including chemotherapy and radiotherapy, which can be given to patients with
locally advanced rectal cancer to shrink the tumour prior to surgery.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","recent
evidence suggests that 10-20% of patients will have a complete pathological
response to neoadjuvant therapy and can therefore avoid surgery altogether
[2,5].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","however, one third of patients do not benefit from radiotherapy treatment
prior to surgery [8], hence it is important to determine how a patient will
respond to radiotherapy with a personalized approach in order to avoid
overtreatment.histology-based digital biomarkers enable the possibility to
predict a patient's response to therapy.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","various studies have investigated the link between cms and patient outcomes,
suggesting that patients with tumour classified as cms4, which features stromal
invasion [9] and shows significantly higher stroma content [15], have worse
survival rates compared to the other cms classes [5].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","other work has looked at predicting
chemoradiotherapy response in rectal cancer patients from h&e images using
different approaches, but without providing contextual interpretations
[19,22].as opposed to predicting response to radiotherapy alone, we aim to
analyse this prediction in the context of the overall tissue architecture and
the tumour biology as captured by cms.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","pathologists and oncologists can use this information to inspect the validity of
the prediction result and interrogate key aspects of the spatial biology that is
critical for patient management.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","we achieve 0.82 auc predicting
complete response to radiotherapy using deep learning on wsis for crc patients,
whilst providing novel interpretability of the results.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","these epithelial segmentation masks were generated at 10x
magnification (1 µm 2 /pixel) with a u-net [17] which was trained and validated
on 666 full tissue sections belonging to 362 patients from the focus cohort
[18].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","grampian and aristotle are used in both
training and validation, with a 70/30% training-validation split, keeping any
wsis from a single patient in the same dataset.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","we address this imbalance in
the supplementary materials.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","there are 365 slides total in our dataset, from 249
patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","we use
weighted metrics due to the class imbalance in our dataset.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","for example, the model demonstrates that
cms4 patients are less likely to respond to radiotherapy.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","importantly, this level of visualisation is not
only accessible to pathologists, this joint prediction model also enhances the
communication between pathologists and oncologists which is critical for patient
management.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Automatic Bleeding Risk Rating System of Gastric Varices,"esophagogastric varices are one of the common manifestations in patients with
liver cirrhosis and portal hypertension and occur in about 50 percent of
patients with liver cirrhosis [3,6].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Automatic Bleeding Risk Rating System of Gastric Varices,"the occurrence of esophagogastric variceal
bleeding is the most serious adverse event in patients with cirrhosis, with a
6-week acute bleeding mortality rate as high as 15%-20% percent [14].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Automatic Bleeding Risk Rating System of Gastric Varices,"it is
crucial to identify high-risk patients and offer prophylactic treatment at the
appropriate time.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Automatic Bleeding Risk Rating System of Gastric Varices,"in this work, we collect a gv bleeding risks rating dataset
(gvbleed) that contains 1678 gastroscopy images from 411 patients with different
levels of gv bleeding risks.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Automatic Bleeding Risk Rating System of Gastric Varices,data collection and annotation.,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
Automatic Bleeding Risk Rating System of Gastric Varices,"all of these cases are collected
from 411 patients in a grade-iii class-a hospital during the period from 2017 to
2022.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Automatic Bleeding Risk Rating System of Gastric Varices,"in the current version, images from patients with ages elder than 18 are
retained 1 .",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"bias in medicine has demonstrated a notable challenge for providing
comprehensive and equitable care.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"implicit biases can negatively affect patient
care, particularly for marginalized populations with lower socioeconomic status
[30].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"evidence has demonstrated that implicit biases in healthcare providers
could contribute to exacerbating these healthcare inequalities and create a more
unfair system for people of lower socioeconomic status [30].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"based on the data
with racial bias, the unfairness presents in developing evaluative algorithms.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"in an algorithm used to predict healthcare costs, black patients who received
the same health risk scores as white patients were consistently sicker [21].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"along these advancements, bias in
healthcare and ai are exposing poignant gaps in the field's understanding of
model implementation and their utility [25,26].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"ai model quality relies on input
data and addressing bias is a crucial research area.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"systemic bias poses a
greater threat to ai model's applications, as these biases can be baked right
into the model's decision process [22].pulmonary embolism (pe) is an example of
health disparities related to race.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"black patients exhibit a 50% higher
age-standardized pe fatality rate and a twofold risk for pe hospitalization than
white patients [18,24].",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"hospitalized black patients with pe were younger than
whites.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"racial disparities exist
in pe and demonstrate the inequities that affect black patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"survival
analysis is often used in pe to assess how survival is affected by different
variables, using a statistical method like kaplan-meier method and cox
proportional-hazards regression model [7,12,14].however, one issue with
traditional survival analysis is bias from single modal data that gets
compounded when curating multimodal datasets, as different combinations of modes
and datasets create with a unified structure.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"multimodal data sets are useful
for fair ai model development as the bias complementary from different sources
can make de-biased decisions and assessments.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"in that process, the biases of
each individual data set will get pooled together, creating a multimodal data
set that inherits multiple biases, such as racial bias [1,15,23].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"in addition,
it has been found that creating multimodal datasets without any debiasing
techniques does not improve performance significantly and does increase bias and
reduce fairness [5].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"overall, a holistic approach to model development would be
beneficial in reducing bias aggregation in multimodal datasets.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"in recent years,
disentangled representation learning (drl) [4] for bias disentanglement improves
model generalization for fairness [3,6,27].we developed a pe outcome model that
predicted mortality and detected bias in the output.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"we then implemented methods
to remove racial bias in our dataset and model and output unbiased pe outcomes
as a result.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"our contributions are as follows: (1) we identified bias diversity
in multimodal information using a survival prediction fusion framework.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"(2) we
proposed a de-biased survival prediction framework with demographic bias
disentanglement.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"(3) the multimodal cph learning models improve fairness with
unbiased features.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"this section describes the detail of how we identify the varying degrees of bias
in multimodal information and illustrates bias using the relative difference in
survival outcomes.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"we will first introduce our pulmonary embolism multimodal
datasets, including survival and race labels.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the pulmonary embolism dataset used in this study from 918
patients (163 deceased, median age 64 years, range 13-99 years, 52% female),
including 3978 ctpa images and 918 clinical reports, which were identified via
retrospective review across three institutions.",,1,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"for each patient, the race labels, survival time-to-event labels and
pesi variables are collected from clinical data, and the 11 pesi variables are
used to calculate the pesi scores, which include age, sex, comorbid illnesses
(cancer, heart failure, chronic lung disease), pulse, systolic blood pressure,
respiratory rate, temperature, altered mental status, and arterial oxygen
saturation at the time of diagnosis [2].diverse bias of multimodal survival
prediction model.",,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the feature with the highest pe
probability from a patient's multiple ctpas is considered as the most pe-related
visual representation.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"next, the gatortron [29] model is employed to recognize
clinical concepts and identify medical relations for getting accurate patient
information from pe clinical reports.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the framework also consists of a cox proportional hazard (coxph) model [7] that
is trained to predict patient ranking using a multimodal combination of risk
predictions from the above three sp modules.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"these coxph models calculate the
corresponding time-to-event evaluation and predict the fusion of patients' risk
as the survival outcome.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"this
redundancy leads to model overfitting on race, compromising the fairness of risk
prediction across different races.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"besides, clinical data in the form of text
reports and pesi variables objectively reflect the patient's physiological
information and the physician's diagnosis, exhibiting smaller race biases in
correlation with survival across different races.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"2, we
present a feature-level de-biased sp module that enhances fairness in survival
outcomes by decoupling race attributes, as shown in the lower right of fig.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"in the de-biased sp module, firstly, two separate encoders e m i and e m c are
formulated to embed features f m into disentangled latent vectors for
race-intrinsic attributes z id or race-conflicting attributes z sur implied
survival information [16].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"then, the linear classifiers c m i and c m c
constructed to predict the race label y id with concatenated vector z = [z id ;
z sur ].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"to disentangle survival features from the race identification, we use
the generalized cross-entropy (gce) loss [31] to train e m c and c m c to
overfit to race label while training e m i and c m i with crossentropy (ce)
loss.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"1 reweight and enhance
the learning of the race-intrinsic attributes [20].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"2, but the parameters of id or survival branch are
only updated by their respective losses:to promote race-intrinsic learning in e
m i and c m i , we apply diversify with latent vectors swapping.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"as the random combination are generated from different samples, the
swapping decreases the correlation of these feature vectors, thereby enhancing
the race-intrinsic attributes.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the weights λ sw
and λ sur are assigned as 0.5 and 0.8, respectively, to balance the feature
disentanglement and survival prediction.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the outputs from each patient's medical history, clinical
diagnosis, observations, and radiologist impression are separately generated and
concatenated to form the 1024 × 4 features.we build the encoders of the baseline
sp modules and de-biased sp modules with multi-layer perceptron (mlp) neural
networks and relu activation.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"in
general, our framework including de-biased sp modules shows significantly better
predictions in testing set than the pesi-based outcome estimation with c-indexes
of 0.669, 0.654, 0.697, 0.043 for the overall testset, white testset, color
testset and race bias.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the de-biased results outperform the baseline in overall
survival c-index and show a lower race bias, especially in imaging-and
fusion-based predictions.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the results indicate the effectiveness of the proposed
de-biasing in mitigating race inequity.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the results also prove the observations
for the different biases present in different modalities, especially in the ctpa
images containing more abundant race-related information.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the disentangled
representations, transformed from latent space to a 2d plane via tsne and
color-coded by race [9], are shown in fig.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"we observe the disentanglement in
the visualization of the id features z id , while the survival features z sur
eliminate the race bias.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the lack of apparent race bias observed in both the
original features and those encoded in the baseline can be attributed to the
subordinate role that id features play in the multimodal information.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"3, is used to compare
the survival prediction between high-risk and lowrisk patient groups.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"in addition, the predictions of
the de-biased framework show favorable performance, and our multimodal fusion
demonstrates a more pronounced discriminative ability in the k-m survival
analysis compared to the single-modal results.we conducted ablation studies to
examine the effect of the two key components, including swapping feature
augmentation and race-balance resampling.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the swapping augmentation provides a strong bias
correction effect for image data with obvious bias.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"in this work, we developed a de-biased survival prediction framework based on
the race-disentangled representation.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"we detected indications of racial bias in our dataset and
conducted an analysis of the multimodal diversity.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"experimental results
illustrate that our approach is effective for eliminating racial bias while
resulting in an overall improved model performance.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the proposed technique is
clinically relevant as it can address the pervasive presence of racial bias in
healthcare systems and offer a solution for minimizing or eliminating bias
without pausing to evaluate their affection for the models and tools.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"our study
is significant as it highlights and evaluates the negative impact of racial bias
on deep learning models.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the proposed de-biased method has already shown the
capacity to relieve them, which is vital when serving patients with an accurate
analysis.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the research in our paper demonstrates and proves that eliminating
racial biases from data improves performance, and yields a more precise and
robust survival prediction tool.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"breast cancer impacts women globally [15] and mammographic screening for women
over a certain age has been shown to reduce mortality [7,10,23].",,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"however, these imaging
techniques are expensive and add additional burdens for the patient.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"recently,
several studies [8,32,33] revealed the potential of artificial intelligence (ai)
to develop a better risk assessment model to identify women who may benefit from
supplemental screening or a personalized screening interval and these may lead
to improved screening outcomes.in clinical practice, breast density and
traditional statistical methods for predicting breast cancer risks such as the
gail [14] and the tyrer-cuzick models [27] have been used to estimate an
individual's risk of developing breast cancer.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"recently, deep
neural network based models that predict a patient's risk score directly from
mammograms have shown promising results [3,8,9,20,33].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"these models do not
require additional patient information and have been shown to outperform
traditional statistical models.when prior mammograms are available, radiologists
compare prior exams to the current mammogram to aid in the detection of breast
cancer.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"integrating prior mammograms into deep learning
models for breast cancer risk prediction can provide a more comprehensive
evaluation of a patient's breast health.in this paper, we introduce a deep
neural network that makes use of prior mammograms, to assess a patient's risk of
developing breast cancer, dubbed prime+ (prior mammogram enabled risk
prediction).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"we hypothesize that mammographic parenchymal pattern changes
between current and prior allow the model to better assess a patient's risk.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"our
method is based on a transformer model that uses attention [30], similar to how
radiologists would compare current and prior mammograms.the method is trained
and evaluated on a large and diverse dataset of over 9,000 patients and shown to
outperform a model based on state-of-the art risk prediction techniques for
mammography [33].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"for medical applications, x typically
represents patient information like age, family history, genetic makeup, and
diagnostic test results (e.g., a mammogram).",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"1).we typically want to estimate the hazard function h(t),
which measures the rate at which patients experience the event of interest at
time t, given that they have survived up to that point.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"specifically, h(t) is 1 if the
patient is diagnosed with cancer within t years and 0 otherwise.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"we compiled an in-house mammography dataset comprising 16,113 exams (64,452
images) from 9,113 patients across institutions from the united states, gathered
between 2010 and 2021.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"we partitioned the dataset by patient to create
training, validation, and test sets.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"the validation set contains 800 exams (198
cancer, 210 benign, 392 normal) from 400 patients, and the test set contains
1,200 exams (302 cancer, 290 benign, 608 normal) from 600 patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"our results suggest that
incorporating changes in patients using prior mammograms and a transformer
decoder improves the performance of breast cancer risk prediction
models.analysis based on density.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"women with dense breasts have a four-to six-fold higher
risk of breast cancer [2].",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"for the ldct, we annotate more than 12,852 nodules from 8,271 patients
from the nlst dataset [14].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"for the ncct, we annotate over 4,029 nodules from
over 2,565 patients from our collaborating hospital.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"data collection and curation: nlst is the first large-scale ldct dataset for
low-dose ct lung cancer screening purpose [14].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"there are 8,271 patients
enrolled in this study.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"1 j ← seg loss(m, s) + 3 i=1 cls loss(y, p i ) update loss18: end for patient,
and
localized and labeled the nodules in the scan as benign or malignant based on
the rough candidate nodule location and whether the patient develops lung cancer
provided by nlst metadata.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"the in-house cohort was retrospectively collected from 2,565 patients
at our collaborating hospital between 2019 and 2022.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"the training set contains 9,910 (9,413 benign and 497 malignant) nodules from
6,366 patients at nlst, and 2,592 (843 benign and 1,749 malignant) nodules from
2,113 patients at the in-house cohort.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"the validation set contains 1,499 (1,426
benign and 73 malignant) nodules from 964 patients at nlst.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"the nlst test set
has 1,443 (1,370 benign and 73 malignant) nodules from 941 patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"the
in-house test set has 1,437 (1,298 benign and 139 malignant) nodules from 452
patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
M&M: Tackling False Positives in Mammography with a Multi-view and Multi-instance Learning Sparse Detector,"we split the
data into train/val/test with an 80:10:10 ratio at the patient level; (2)
inhouse-a: an evaluation dataset collected from a u.s.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Reversing the Abnormal: Pseudo-Healthy Generative Networks for Anomaly Detection,"stroke is
a leading cause of death and disability, where early detection and treatment can
significantly improve patient outcomes.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Reversing the Abnormal: Pseudo-Healthy Generative Networks for Anomaly Detection,"we believe that our proposed method will open new avenues
for interpretable, fast, and accurate anomaly segmentation and support various
clinical-oriented downstream tasks, such as investigating progression of
disease, patient stratification and treatment planning.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
SHISRCNet: Super-Resolution and Classification Network for Low-Resolution Breast Cancer Histopathology Image,"breast cancer is one of the high-mortality cancers among women in the 21st
century.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
SHISRCNet: Super-Resolution and Classification Network for Low-Resolution Breast Cancer Histopathology Image,"every year, 1.2 million women around the world suffer from breast
cancer and about 0.5 million die of it [3].",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
SHISRCNet: Super-Resolution and Classification Network for Low-Resolution Breast Cancer Histopathology Image,"accurate identification of cancer
types will make a correct assessment of the patient's risk and improve the
chances of survival.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
SHISRCNet: Super-Resolution and Classification Network for Low-Resolution Breast Cancer Histopathology Image,"considering the improvement of
histopathological images' acquisition equipment will cost lots of money while
significantly increasing patients' expense of detection.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
SHISRCNet: Super-Resolution and Classification Network for Low-Resolution Breast Cancer Histopathology Image,"we use f ocal loss [16] to alleviate the class imbalanced data problem
of the hr and sr images' classification.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Text-Guided Foundation Model Adaptation for Pathological Image Classification,"to extend our
evaluation into the real-world setting with insufficient data, we additionally
choose 1, 2, 4, 8, or 16 wsis with the largest numbers of patches from each
class as the training set.the evaluation metric is patient-wise accuracy, where
the prediction of a wsi is obtained by a soft vote over the patches, and
accuracy is averaged class-wise.implementation.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Text-Guided Foundation Model Adaptation for Pathological Image Classification,"a class-balanced sampling strategy is adopted by choosing one
image from each class in turn.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Distributionally Robust Image Classifiers for Stroke Diagnosis in Accelerated MRI,"nevertheless, the long acquisition time for a
brain mri (20 to 30 min) imposes challenges, especially in cases of acute stroke
where rapid diagnosis is essential and patient movement during this distressing
period of time commonly limits evaluation.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Distributionally Robust Image Classifiers for Stroke Diagnosis in Accelerated MRI,"our dataset included mri brain scans from 226 patients performed at an urban
tertiary referral academic medical center that is a comprehensive stroke center.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Distributionally Robust Image Classifiers for Stroke Diagnosis in Accelerated MRI,"clinical scans of adult patients aged 18-89 years with recent (acute or
subacute) strokes were identified between 1/1/2013 and 1/1/2021 for inclusion in
this study via a search of the philips performance bridge.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Distributionally Robust Image Classifiers for Stroke Diagnosis in Accelerated MRI,"scans meeting this
criteria were downloaded and simultaneously anonymized to preserve patient
anonymity and prevent disclosure of protected health information as part of this
irb exempt study.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Distributionally Robust Image Classifiers for Stroke Diagnosis in Accelerated MRI,"no patient demographic information was retained for the scans,
as it was considered to represent an unnecessary risk for accidental release of
protected health information.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0
Distributionally Robust Image Classifiers for Stroke Diagnosis in Accelerated MRI,"for both erm-and drlbased vit models, we maximized the f1
score of the stroke class on the training set to calculate the optimal decision
threshold for stroke prediction, in order to balance the precision and recall.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Contrastive Feature Decoupling for Weakly-Supervised Disease Detection,"as a result, the difficulty of data collection restricts the
development of the supervised cad.due to the difficulty of acquiring the
abundant annotated training data, the current sota method, i.e., csm [14],
proposes a mil-based wvad manner to specifically tackle one specific disease
detection task, i.e., colorectal cancer diagnosis via colonoscopy.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
Multiple Prompt Fusion for Zero-Shot Lesion Detection Using Vision-Language Models,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Fast Non-Markovian Diffusion Model for Weakly Supervised Anomaly Detection in Brain MR Images,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
MUVF-YOLOX: A Multi-modal Ultrasound Video Fusion Network for Renal Tumor Diagnosis,"compared with ct and mri, ceus is radiation-free,
cost-effective, and safe in patients with renal dysfunction.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"despite this, the clinical
pathological analysis presents certain challenges and complexities, with the
ultimate diagnosis relying on patients rather than slides.specifically, in
clinical problems of pathological image analysis, doctors usually summarize
patient-level labels based on slide labels as the diagnostic results [1,6].",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"for
example, for the pathological discrimination diagnosis task of intestinal
tuberculosis(itb) and crohn's desease(cd), the categories of postoperative
slides are divided into three types (normal, cd, itb), and doctors will
summarize the binary results of patients (itb or cd) based on slide-level labels
[6].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"similar situations exist in other tasks, such as the classification of
breast cancer metastases in lymph nodes, where slide categories may have
different classifications, and the corresponding diagnosis of the same patient
is whether the cancer has spread to the regional lymph nodes (n-stage) [1].",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"1, actual pathological image analysis involves the
relationships of patches, slides, and patients, which is called a multi-level
multi-instance learning (ml-mil) problem.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"among them, for patients and slides,
patients are bags while slides are instances, and for slides and patches, slides
are bags while patches are instances.there are generally two methods to solve
the ml-mil problem.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"the second method is
to treat slide-patient as a new mil problem according to the traditional mil
thinking, where slides are regarded as instances and patient labels as bags.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"although this method seems reasonable, the number of patients is usually
relatively small, and deep learning models usually require a large amount of
data for training.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"therefore, the insufficient number of samples at the
slide-patient level may make it difficult for the model to learn enough
information.to address the multi-level multi-instance learning (ml-mil) problem
in medical field, we propose a novel framework called patients and slides are
equal (p&sre).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"inspired by the iterative labeling process in medical diagnosis,
this framework treats patients and slides as instances at the same level and
uses transformers and attention mechanisms to build connections between them.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"this simple yet effective method allows for interaction between patient-level
and slidelevel information to correct their respective features and improve
classification performance.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"our framework consists of two steps: first, at the
patch-slide level, a common mil framework is used to train a mil neural network
and obtain slide-level feature vectors; then, at the slide-patient level, we use
self-attention mechanisms to combine the slides of the same patient into
patient-level feature vectors, and treat these patient-level feature vectors
together with all slide-level feature vectors of the same patient as instances
at the same level, which are inputted into transformers for feature interaction
and prediction of patient-and slide-level labels.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"before this, no other
framework had directly tackled this specific problem, making our proposal a
ground-breaking step in the application of ml-mil in healthcare; 2) proposing a
simple yet highly effective method that leverages self-attention mechanisms and
transformer models to enhance the interaction between slide and patient
information.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"this innovative approach not only improves the classification
performance at the patient level but also at the slide level, showcasing its
effectiveness and versatility; 3) conducting extensive experiments on two
separate datasets.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"the second part is the patient-slide level mil,
which generates patient-level features using attention mechanism and interacts
the features with transformer.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"to enhance readability, we first provide the
following symbolization for ml-mil: for a patient x i , it has a patient-level
classification label y i .",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"for patient x i , there may exist n i slides s i ={s
j |j=1 to n i }, where the classification label for each slide s j is denoted as
z j .",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"here, i,j, and k are indices for patient, slide, and patch levels,
respectively.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"after performing patch-slide level mil, we move on to patient-slide level mil.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"in general mil algorithms, the patient is regarded as the bag and the slide as
the instance.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"however, considering the diagnostic process in clinical practice,
we propose to treat both patients and slides as instances at the same level.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"specifically, our p&sre framework for patient-slide level consists of two parts:
patient-level feature generation based on self-attention and patient-slide
feature interaction based on transformer [11].patient-level feature generation
based on self-attention.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"therefore, we directly use a fully connected (fc)
layer to integrate the feature-level features into patient-level features v i
through attention mechanism, serving as patient instances.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"then, we perform a weighted average of the vectors
based on this weight to obtain the patient feature v i :patient-slide feature
interaction based on transformer.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"after doctors summarize the patient-level results, they typically review the
slides to double-check the diagnosis results.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"this patient-slide feature
interaction (psfi) naturally lends itself to the construction of a transformer,
and information exchange and integration between slides and patient level are
bidirectional.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"by using the
self-attention-based transformer structure, each input token is treated equally
(i.e., viewed as the same instance level), and tokens can interact extensively
with each other, enabling mutual correction between patients and slides and even
between slides.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"specifically, we merge the slide feature set {h j } and the
patient feature v i into the input tokensand then input them into a multi-layer
transformer through self-attention and feed-forward neural network layers to
obtain the interaction information between slides and output tokens t out i
:where d is the dimension of the token, and t k and t l come from t in i .",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"b
1 and b 2 are bias vectors.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"finally, we obtain
the output tokensthen, all output tokens are input into a shared fc layer, and
the patient's predicted logits y i and the predicted classification logits {z j
|j = 1 to n i } for each slide are output.training progress and loss function.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"during training, we sampled one patient at a time and pre-extracted their
batch-level features for all slides, in order to save gpu memory.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"due to the
issue of class imbalance in both slide level and patient level, we use the lade
[7] loss function.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"cd-itb is a private dataset consisting of 853 slides from 163
patients, with binary patient-level labels of cd or itb in a ratio of 103:60 and
tri-class slide-level labels of cd, itb, and normal slides in a ratio of
436:121:296, respectively.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"on average, there were 5 slides per patient.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"we adopted a patient-level stratification
approach for 5-fold cross-validation, with 20% of the training set randomly
assigned as the validation set for each fold.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"camelyon17 [1] is a publicly dataset, and its
training set comprises 500 slides from 100 breast cancer patients with lymph
node metastases.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,there were 5 slides per patient on average.,,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"the patients are divided into two
groups based on their pn stage, namely lymph node positive and lymph node
negative, in proportions of 24:76, respectively.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"following the reference [4], we employed a transformer with 8 heads and 8
layers in the patient-slide feature interactions.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"at
the patient level, we used two approaches for prediction: maxs, where the
feature of the instance that achieves the maximum positive probability from the
slide-level mil model is selected to patient-level model, and maxmins, where the
mean value of features of the maximum and minimum positive probability from the
slide-level mil model is selected to patient-level model.the results of 5-fold
cv at the slide and patient levels are reported in table 1 and table 2,
respectively.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"abmil with p&sre improves the f1 score from 0.565 to 0.579 for the
cd-itb dataset and from 0.529 to 0.571 for the camelyon17 dataset at the
slide-level, and improves the f1 score from 0.522 to 0.599 for the cd-itb
dataset and from 0.842 to 0.861 for the camelyon17 dataset at the patient-level.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"therefore, the ablation experiments demonstrate the effectiveness of p&sre in
enhancing the classification performance at both the slide and patient levels.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"for instance, we did
not explore the possibility of treating patches as an equivalent level to slides
and patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"the primary reason is that the vast number of patches required for
analysis is significantly larger than that of slides and patients, which
presents a computational challenge for training.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"we first classify the process from patch to slide to the patient in
medical pathology diagnosis as a multi-level mil problem.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"based on existing
state-of-the-art mil methods, we then extend the framework to p&sre, which
conducts feature extraction and interaction at the slide-patient level.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"by
introducing a transformer, the framework enables iterative interaction and
correction of information between patients and slides, resulting in better
performance at both the patient level and slide level compared to existing
state-of-the-art algorithms on two validation datasets.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Learning with Synthesized Data for Generalizable Lesion Detection in Real PET Images,"most of
current dg methods rely on multiple sources of data to learn a generalizable
model, i.e., multisource dg (mdg); however, multi-source data collection is
often difficult in real practice due to privacy concerns or budget deficits.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
Learning with Synthesized Data for Generalizable Lesion Detection in Real PET Images,"the combo loss l det can further help address the data
imbalance issue [22], i.e., lesions have significantly fewer voxels than the
non-lesion regions including the background.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
What Do AEs Learn? Challenging Common Assumptions in Unsupervised Anomaly Detection,"finding anomalies in medical images is especially hard due to large
inter-patient variance of normality, the irregular appearance-, and often rare
occurrence of diseases.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"neoadjuvant chemotherapy
can increase the likelihood of achieving a margin-negative resection and avoid
unnecessary surgery in patients with aggressive tumor types [23].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"providing
accurate and objective preoperative biomarkers is crucial for triaging patients
who are most likely to benefit from neoadjuvant chemotherapy.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"however, current
clinical markers such as larger tumor size and high carbohydrate antigen (ca)
19-9 level may not be sufficient to accurately tailor neoadjuvant treatment for
patients [19].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"therefore, multi-phase contrast-enhanced ct has a great potential
to enable personalized prognostic prediction for pdac, leveraging its ability to
provide a wealth of texture information that can aid in the development of
accurate and effective prognostic models [2,10].previous studies have utilized
image texture analysis with hand-crafted features to predict the survival of
patients with pdacs [1], but the representational fig.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"our proposed model has the
potential to be used in combination with clinical factors for risk
stratification and treatment decisions for patients with pdac.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"between pdac and vesselsthe vascular involvement in patients with pdac affects
the resectability and treatment planning [5].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"in this study, we used data from shengjing hospital to train our method
with 892 patients, and data from three other centers, including guangdong
provincial people's hospital, tianjin medical university and sun yatsen
university cancer center for independent testing with 178 patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"pdac masks for 340 patients were manually labeled by a
radiologist from shengjing hospital with 18 years of experience in pancreatic
cancer, while the rest were predicted using self-learning models [11,24] and
checked by the same annotator.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"combining the texture-aware transformer and
regular structure information improved the results from 0.630 to 0.648, as tumor
invasion strongly affects the survival of pdac patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"to demonstrate the added value of our signature as a tool to select
patients for neoadjuvant treatment before surgery, we plotted kaplan-meier
survival curves in fig.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"we further stratify patients by our signature after
grouping them by tumor size and ca19-9, two clinically used preoperative
criteria for selection, and also age.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"our signature could significantly stratify
patients in all cases and those in the high-risk group had worse outcomes and
might be considered as potential neoadjuvant treatment candidates (e.g.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"33
high-risk patients with larger tumor size and high ca19-9).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"furthermore, our model can be combined with
established high-risk features to aid in the patient selections who might
benefit from neoadjuvant therapy before surgery.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
DCAug: Domain-Aware and Content-Consistent Cross-Cycle Framework for Tumor Augmentation,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"the five-year survival rate for gc is approximately 33% [16],
which is mainly attributed to patients being diagnosed with advanced-stage
disease harboring unresectable tumors.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"however, patients with
early-stage disease have a substantially higher five-year survival rate of
around 72% [16].",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"it is a non-invasive, relatively
low-cost, and safe procedure that exposes patients to less radiation dose and
does not require the use of contrast injection that may cause serious side
effects (compared to multi-phase contrastenhanced ct).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"these results demonstrate the potential
of our approach for opportunistic screening of gastric cancer in asymptomatic
patients using non-contrast ct scans.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"however, our framework is specifically designed
for noncontrast ct scans, which is beneficial for asymptomatic patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"their cluster representations demonstrate a remarkable balance
of intra-cluster similarity and inter-class discrepancy.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"inspired by this, we
further develop a deep classification model on top of learnable cluster
representations.specifically, given image x ∈ r h×w ×d , annotation y ∈ r k×hw d
, and patient class p ∈ l, our model consists of three components: 1) a cnn
backbone to extract its pixel-wise features f ∈ r c×hw d (fig.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"our study analyzed a dataset of ct scans collected
from guangdong province people's hospital between years 2018 and 2020, with
2,139 patients consisting of 787 gastric cancer and 1,352 normal cases.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"we used
the latest patients in the second half of 2020 as a hold-out test set, resulting
in a training set of 687 gastric cancer and 1,204 normal cases, and a test set
of 100 gastric cancer and 148 normal cases.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"all patients underwent multi-phase cts with a median spacing
of 0.75 × 0.75 × 5.0 mm and an average size of (512, 512, 108) voxel.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"no
patient information or records were provided to the readers.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"in table 2, we report the performance of patient-level detection and tumor-level
localization stratified by tumor (t) stage.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"our method surpasses or performs on par with
established screening tools [4,7,10] in terms of sensitivity for gastric cancer
detection at a similar specificity level with a relatively large testing patient
size (n = 1151 by integrating the internal and external test sets), as shown in
table 3.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Self-supervised Polyp Re-identification in Colonoscopy,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
YONA: You Only Need One Adjacent Reference-Frame for Accurate and Fast Video Polyp Detection,"for the fairness of the experiments, we
keep the same dataset settings for yona and all other methods.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Boosting Breast Ultrasound Video Classification by the Guidance of Keyframe Feature Centers,"for fairness comparison, we train these models
using both video and image data, treating images as static videos.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Boosting Breast Ultrasound Video Classification by the Guidance of Keyframe Feature Centers,"it is worth
noting that these two models without coherence loss obtain very low sensitivity
and high specificity, which means the model predictions are imbalanced and
intend to make benign predictions.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Text-Guided Cross-Position Attention for Segmentation: Case of Medical Image,"monuseg [8] contains
30 digital microscopic tissue images of several patients and qata-cov19 are
covid-19 chest x-ray images.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Text-Guided Cross-Position Attention for Segmentation: Case of Medical Image,"sij is the dataset privately prepared for this study
which consists of 804 mri slices of nineteen healthy subjects and sixty patients
diagnosed with axial spondyloarthritis.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fréchet Domain Distance,"the model is trained to perform binary classification of
wsis from lymph nodes of breast cancer patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fréchet Domain Distance,"showing how fdd can help to identify subsets of patient
cases for which mil performance is worse than reported on the in-domain test
data; 3.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fréchet Domain Distance,"grand challenge camelyon data [16] potentially large shift as some patients have
already started neoadjuvant treatment as well as the tissue may be affected from
the procedure of sentinel lymph node removal.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fréchet Domain Distance,"we deem that the information needed to do this type of subset
divisions would be available without labelling since the patient cases in a
clinical setting would already contain such information.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"early detection and accurate diagnosis of liver tumors may improve overall
patient outcomes, in which imaging plays a key role [11].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"dynamic
contrast-enhanced (dce) ct is widely used for diagnostics, but it requires
iodine contrast injection which can cause reaction and potential risks in
patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"after an incidental tumor is
found, the patient may undergo further imaging examination such as a multi-phase
dce ct for differential diagnosis [11], which can provide useful discriminative
information such as the vascularity of lesions and the pattern of contrast agent
enhancement [19].",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"(1) tumor screening involves
finding tumor patients in a large pool of healthy subjects and patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"most
existing works in tumor segmentation and detection did not explicitly consider
it since their training and testing images are all tumor patients.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"we collect a large-scale dataset with both tumor and
non-tumor subjects, where the non-tumor subjects includes not only healthy ones,
but also patients with various diffuse liver diseases such as steatosis and
hepatitis to improve the robustness of the algorithm.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"such metrics cannot reflect the
lesion-level accuracy (how many lesion instances are correctly detected and
classified) and may bias to large lesions when a patient has multiple tumors.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,patient-level metrics (e.g.,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"therefore, we assess our algorithm thoroughly with pixel, lesion, and
patient-level metrics.algorithms for liver tumor segmentation have focused on
improving the feature extraction backbone of a fully-convolutional cnn
[9,13,15,23].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"the pixelwise segmentation architectures may not be optimal for
lesion and patient-level evaluation metrics since they cannot consider a lesion
or an image holistically.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"inspired by them, we
propose a novel end-to-end framework named pixel-lesion-patient network (plan)
for lesion segmentation and classification, as well as patient classification.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"it contains three branches with bottomup cooperation: the segmentation map from
the pixel branch helps to initialize the lesion branch, which is an improved
mask transformer aiming to segment and classify each lesion; the patient branch
aggregates information from the whole image and predicts image-level labels of
each lesion type, with regularization terms to encourage consistency with the
lesion branch.we collected a large-scale multi-phase dataset containing 810
non-tumor subjects and 939 tumor patients.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"on the non-contrast
tumor screening and diagnosis task, plan achieves 95.0%, 96.4%, and 0.965 in
patient-level sensitivity, specificity, and average auc for malignant and benign
patients, in contrast to 94.4%, 93.7%, and 0.889 for the widely-used nnu-net
[8].",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,we also hope to make patient-level diagnoses for each ct scan.,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"(3) a patient branch is
attached to make dedicated image-level predictions with a proposed
lesion-patient consistency loss.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"we propose a simple approach
to remedy this issue by sampling an extra n foreground pixels for each
lesion.patient branch.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,a patient-level diagnosis is useful for triage.,,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"intuitively, we can also infer
patient-level labels from segmentation results by checking if there is any
lesion in the predicted mask.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"we equip plan with a dedicated
patient branch to aggregate such global information to make better patient-level
prediction.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"since one patient can have multiple liver tumors of different types,
in our problem, we give each image several hierarchical binary labels.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"we employ the dual-path transformer block [17] to
fuse multi-scale features from the pixel encoder and decoder to generate a
feature map, followed by global average pooling and a linear classification
layer to predict the c + 3 labels.a lesion-patient consistency loss is further
proposed to encourage coherence of the lesion and patient-level predictions.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"inspired by multi-instance learning [6], we compute a pseudo patient-level
prediction c ∈ r c from the lesion-level predictions by max-pooling the class
probability of each class across all lesion queries (discarding the no-object
class).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"we also have the probability vector from the patient branch p ∈ r c
corresponding to the c fine-grained classes.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"1, where l pixel is the
combined crossentropy (ce) and dice loss for the pixel branch as in nnu-net [8];
l lesion-class is the ce loss [3] for lesion classification in the lesion
branch; l lesion-mask is the combined ce and dice loss [3] for binary lesion
segmentation in the lesion branch with the foreground-enhanced sampling
strategy; l patient is the binary ce loss for the multi-label classification
task in the patient branch.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"our dataset contains 810 normal subjects and 939 patients with liver
tumors.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"each normal subject has a non-contrast (nc) ct, while each patient has a
dynamic contrast-enhanced (dce) ct scan with nc, arterial, and venous phases.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"in the former setting, both
normal and patient data are used and randomly split into 1149 training, 100
validation, and 500 testing.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"in the latter one, only patient data are used with
641 training, 100 validation, and 200 testing.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"another hold-out set of 150
patients and 100 normal cts are used for reader study to compare our accuracy
with two radiologists.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"extensive data
augmentation is applied including random cropping, scaling, flipping, elastic
deformation, and brightness adjustment [8].during training, we first pretrain
the backbone and the pixel branch for 500 epochs, and then train the whole
network for another 500 epochs.patient-level results.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"for the
baselines, patient-level labels are inferred from their predicted masks by
counting lesion pixels.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"as displayed in table 1, plan achieves the best accuracy
on all tasks, especially in nc preliminary diagnosis tasks, which demonstrates
the effectiveness of its dedicated patient branch that can explicitly aggregate
features from the whole image.lesion and pixel-level results.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"in this work, we focus more on patient and lesion-level metrics.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,we consider patients with only one tumor type in this study.,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"the
efficacy of the lesion and patient branches has been analyzed above based on the
lesion and patient-level results.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"in the patient level,
[5] achieved auc=0.75 in nc ct tumor screening, while our auc is 0.985.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Self-supervised Learning for Endoscopic Video Analysis,"furthermore, the ability to recognize phases allows
real-time monitoring and decision-making assistance during surgery, thus
improving patient safety and outcomes.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Self-supervised Learning for Endoscopic Video Analysis,"additionally, we present our large-scale data collection
(see fig.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
Self-supervised Learning for Endoscopic Video Analysis,"we compiled a dataset of laparoscopic procedures videos exclusively
performed on patients aged 18 years or older.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Self-supervised Learning for Endoscopic Video Analysis,"we
have curated a dataset comprising 13,979 colonoscopy videos of patients aged 18
years or older.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"survival prediction, a regression
task that models the survival outcomes of patients, is crucial for h&n cancer
patients: it provides early prognostic information to guide treatment planning
and potentially improves the overall survival outcomes of patients [2].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"[22] attempted to address
this limitation by proposing a multi-scale non-local attention fusion (mnaf)
block for survival prediction of glioma patients, in which multi-modality
features were fused via non-local attention mechanism [23] at multiple scales.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"following existing multi-task deep survival models [11,16,[24][25][26], our
xsurv is endto-end trained for survival prediction and pt-mln segmentation using
a combined loss: l = l surv +λ(l pt +l mln ), where the λ is a parameter to
balance the survival prediction term l surv and the pt/mln segmentation terms l
pt /mln .",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"in addition,
clinical indicators (e.g., age, gender) also can be integrated by the coxph
model.",,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"we adopted the training dataset of hecktor 2022 (refer to
https://hecktor.grand-cha llenge.org/), including 488 h&n cancer patients
acquired from seven medical centers [7], while the testing dataset was excluded
as its ground-truth labels are not released.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"each patient underwent pretreatment
pet/ct and has clinical indicators.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"the patients from two centers (chum and chuv) were used for
testing and other patients for training, which split the data into 386/102
patients in training/testing sets.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"as such, there is a paucity of efforts that
embark on utilizing machine learning models for patient prognostication and
survival analysis (for example, predicting risk of cancer recurrence or expected
patient survival).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"while prognostication and survival analysis offer invaluable
insights for patient management, biological studies and drug development
efforts, they require careful tracking of patients for a lengthy period of time;
rendering this as a task that requires a significant amount of effort and
funding.in the machine learning domain, patient prognostication can be treated
as a weakly supervised problem, which a model would predict the outcome (e.g.,
time to cancer recurrence) based on the histopathology images.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"hence, locally focused methods are
unable to benefit from the coarse properties of slides due to their high
dimensions which may lead to poor performance.this paper aims to investigate the
potential of extracting fine and coarse features from histopathology slides and
integrating them for risk stratification in cancer patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"therefore, the
contributions of this work can be summarized as: 1) a novel graph-based model
for predicting survival that extracts both local and global properties by
identifying morphological super-nodes; 2) introducing a fine-coarse feature
distillation module with 3 various strategies to aggregate interactions at
different scales; 3) outperforming sota approaches in both risk prediction and
patient stratification scenarios on two datasets; 4) publishing two large and
rare prostate cancer datasets containing more than 220 graphs for active
surveillance and 240 graphs for brachytherapy cases.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"for p n , which is the n-th patient, a set of patches {patch j } m j=1 is
extracted from the related whole slide images.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"finally, a specific
graph (g n ) for the n-th patient (p n ) can be constructed by assuming patches
as nodes.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"therefore, for each
patient such as p n , we have a graph defined by adjacency matrix a n with size
m × m and features matrix z n (g n = graph(z n , a n )).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"the final model ( θ )
with parameters θ utilizes g n and s n to predict the risk associated with this
patient: due to computational limits and large number of patches available for
each
patient, we utilize a self-supervised approach to train an encoder to reduce the
inputs' feature space size.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"this term is motivated by
the original mincut problem and intends to solve it for the the patients' graph.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"here, we take a balanced policy
between the independence and knowledge mixture of the two routes by only sharing
the weights without using any guidance.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"the first set (pca-as) includes 179 pca patients who were
managed with active surveillance (as).",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"radical therapy is considered
overtreatment in these patients, so they are instead monitored with regular
serum prostate-specific antigen (psa) measurements, physical examinations,
sequential biopsies, and magnetic resonance imaging [23].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"although majority of patients in our cohort are classified as low-risk based on
nccn guidelines [21], a significant subset of them experienced disease upgrade
that triggered definitive therapy (range: 6.2 to 224 months after diagnosis).the
second dataset (pca-bt) includes 105 pca patients with low to high risk disease
who went through brachytherapy.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"we utilize concordance-index (c-index) that measures the
relative ordering of patients with observed events and un-censored cases
relative to censored instances [2].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"superior performance of our mca policy implies that balanced
exploitation of fine and coarse features with shared weights may provide more
robust contextual information compared to using mixed guided information or
utilizing them independently.patient stratification.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"the capacity of stratifying
patients into risk groups (e.g., low and high risk) is another criterion that we
employ to assess the utility of models in clinical practice.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"we evaluate model
performances via kaplan-meier curve [15] (cut-off set as the ratio of patients
with recurrence within 3 years of therapy initiation for pca-bt and the ratio of
upgraded cases for pca-as), logrank test [6] (with 0.05 as significance level),
and median outcome associated with risk groups (table 1 and fig.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"our model
stratified pca-as patients into high-and low-risk groups with median time to
progression of 36.5 and 131.7 months, respectively.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"while none of the baselines are capable of assigning patients into
risk groups with statistical significance, our distillation policies achieve
significant separation in both pca-as and pca-bt datasets; suggesting that
global histo-morphological properties improve patient stratification
performance.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"furthermore, our findings have significant clinical implications as
they identify, for the first time, highrisk prostate cancer patients who are
otherwise known to be low-risk based on clinico-pathological parameters.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"this
group should be managed differently from the rest of the low-risk prostate
cancer patients in the clinic.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"while a
prognostic biomarker provides information about a patient's outcome (without
specific recommendation on the next course of action), a predictive biomarker
gives insights about the effect of a therapeutic intervention and potential
actions that can be taken.ablation study.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"achieving higher c-indices in our all model versions indicates the
important role of coarse features and global context in patient risk estimation
in addition to local patterns.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
DARC: Distribution-Aware Re-Coloring Model for Generalizable Nucleus Segmentation,"the images are extracted from 16
colorectal adenocarcinoma wsis, each of which belongs to an individual patient,
and scanned with an omnyx vl120 scanner within the department of pathology at
university hospitals coventry and warwickshire, uk.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"accurate spatial characterization of tumor immune microenvironment is critical
for precise therapeutic stratification of cancer patients (e.g.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"the demographics and other relevant information for all eight
head-and-neck squamous cell carcinoma patients is given in table 1.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"after that, hematoxylin-and dapi-stained rois were used as
references to align mihc and mif rois again using fiji and subdivided into
512×512 patches, resulting in total of 268 co-registered mihc and mif patches
(∼33 co-registered mif/mihc images per patient).",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"lyon19 ihc cd3/cd8 images are taken from breast, colon, and
prostate cancer patients.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"we have released the first ai-ready restained and co-registered mif and mihc
dataset for head-and-neck squamous cell carcinoma patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Detection of Basal Cell Carcinoma in Whole Slide Images,"however, current nas methods often overlook
fairness in architecture ranking, impeding the discovery of top-performing
models.in this study, we utilized the nas approach to identify the optimal
network for skin cancer detection.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Detection of Basal Cell Carcinoma in Whole Slide Images,"we observed that conventional nas methods often
overlook fairness ranking during the search, hindering the search for optimal
solutions.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Detection of Basal Cell Carcinoma in Whole Slide Images,"a balanced evolutionary algorithm
is then used to select the optimal structure from the search space, with the
candidate structures' performance evaluated using mini-batch patch data.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Detection of Basal Cell Carcinoma in Whole Slide Images,"however, the ua principle leads to channel
training imbalance in the supernet due to its constraints, as illustrated in
fig.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Detection of Basal Cell Carcinoma in Whole Slide Images,"this
introduces evaluation bias and leads to sub-optimal results.to mitigate
evaluation bias on width, we propose a new sc-net that promotes the fairness of
channels during training.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Detection of Basal Cell Carcinoma in Whole Slide Images,"therefore, the training degree t
(d) of the d-th channel in our proposed method istherefore, the training degree
t for each channel will always be equal to the same constant value of the width,
independent of the channel index, ensuring fairness in terms of channel (filter)
levels.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Detection of Basal Cell Carcinoma in Whole Slide Images,the patient data were separated between training and testing to prevent overlap.,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Detection of Basal Cell Carcinoma in Whole Slide Images,"by formulating sc-net as a balanced supernet, we
ensure fair ranking and treatment of all potential architectures.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis,"(1) luad-gm dataset: the objective is
to predict the epidermal growth factor receptor (egfr) gene mutations in
patients with lung adenocarcinoma (luad) using 723 whole slide image (wsi)
slices, where 47% of cases have egfr mutations.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Multi-scale Prototypical Transformer for Whole Slide Image Classification,"when the
positive and negative instances in the bag are highly imbalanced, the mil models
are prone to incorrectly discriminate these positive instances when using simple
aggregation operations.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Multi-scale Prototypical Transformer for Whole Slide Image Classification,"a wsi dataset t can be defined as:where x i denotes a
patient, y i the label of x i , i j i is the j-th instance of x i , n is the
number of patients and n is the number of instances.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Thyroid Nodule Diagnosis in Dynamic Contrast-Enhanced Ultrasound via Microvessel Infiltration Awareness,"the l total is denoted as follows:where λ 1 , λ 2 , λ 3 are
the hyper-parameters to balance the corresponding loss.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Thyroid Nodule Diagnosis in Dynamic Contrast-Enhanced Ultrasound via Microvessel Infiltration Awareness,"our dataset contained 282 consecutive patients who underwent thyroid
nodule examination at nanjing drum tower hospital.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Thyroid Nodule Diagnosis in Dynamic Contrast-Enhanced Ultrasound via Microvessel Infiltration Awareness,"all patients performed
dynamic ceus examination by an experienced sonographer using an iu22 scanner
(philips healthcare, bothell, wa) equipped with a linear transducer l9-3 probe.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Thyroid Nodule Diagnosis in Dynamic Contrast-Enhanced Ultrasound via Microvessel Infiltration Awareness,"all data were approved by the institutional review board of
nanjing drum tower hospital, and all patients signed the informed consent before
enrollment into the study.implementation details.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Label-Free Nuclei Segmentation Using Intra-Image Self Similarity,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"immunotherapy (io) is the standard treatment for patients with advanced
non-small cell lung cancer (nsclc) [19] but only 27-45% of patients respond to
this treatment [21].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"therefore, better algorithms and improved biomarkers are
essential for identifying which cancer patients are most likely to respond to io
in advance of treatment.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"we demonstrate the efficacy of triaangil for
characterizing tme in the context of predicting 1) response to io with immune
checkpoint inhibitors (ici), 2) overall survival (os), in patients with nsclc,
and 3) providing novel insights into the spatial interplay between different
immune cell subtype.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"tils),
to show that a high density of tils is associated with improved patient survival
and treatment response in nsclc [3,24].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"these approaches include methods that connect cells
regardless of their type (1) using global graphs (gg) such as voronoi that
connect all nuclei [2,14], or (2) using cell cluster graphs (ccg) [16] to create
multiple nuclear subgraphs based on cell-to-cell proximity to predict tumor
aggressiveness and patient outcome [16].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"by
focusing on every set, triangil allows for capturing higher-order and balanced
spatial triadic relationships [4] between cell families, while keeping the
computational complexity relatively low.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"the cohort employed in this study was composed of pre-treatment tumor biopsy
specimens from patients with nsclc from five centers (two centers for training
(s t ) and three centers for independent validation (s v )).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"the entire analysis
was carried out using 122 patients in experiment 1 (73 in s t , and 49 in s v )
and 135 patients in experiment 2 (81 in s t , and 54 in s v ).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"for every patient, multiple density measures including the number of different
cells types and their ratios are calculated [3,24] (supplemental table 2).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"architectural features (e.g., perimeter, triangle area, edge length) were then
calculated on these global graphs for each patient.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"for every patient, subgraphs are built on nuclei regardless of their type and
only based on their euclidean distance.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"spatil: for each
patient, first, subgraphs are built on individual cell types based on a distance
parameter.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"design: triangil was also trained to differentiate between patients who
responded to io and those who did not.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"for our study, the responders to io were
identified as those patients with complete response, partial response, and
stable disease, and non-responders were patients with progressive disease.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"a
linear discriminant analysis (lda) classifier was trained on s t to predict
which patients would respond to io.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"design: s t
was used to construct a least absolute shrinkage and selection operator (lasso)
[28] regularized cox proportional hazards model [6] using the triangil features,
to obtain risk score for each patient.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"the median risk score in s t was used as a threshold in both s t and s
v to dichotomize patients into low-risk/high-risk categories.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"the c-index
evaluates the correlation between risk predictions and survival times, aiming to
maximize the discrimination between high-risk and low-risk patients [11].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"os is
the time between the initiation of io to the death of the patient.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"the patients
were censored if the date of death was unknown.result: figure 2 presents some
triangil features in a field of view for a patient with long-term survival and
another with short-term survival.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"triangil was
predictive of response after io (n = 122) and also demonstrated a strong
correlation with os in nsclc patients treated with io (n = 135).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
NASDM: Nuclei-Aware Semantic Histopathology Image Generation Using Diffusion Models,"as such, generative models can be sampled to emphasize each
disease subtype equally and generate more balanced datasets, thus preventing
dataset biases getting amplified by the models [7].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
NASDM: Nuclei-Aware Semantic Histopathology Image Generation Using Diffusion Models,"it is also challenging to capture long-tailed distributions
and synthesize rare samples from imbalanced datasets using gans.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
NASDM: Nuclei-Aware Semantic Histopathology Image Generation Using Diffusion Models,"a common issue in deep learning with h&e stained histopathology slides is the
visual bias introduced by variations in the staining protocol and the raw
materials of chemicals leading to different colors across slides prepared at
different labs [1].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"radiotherapy, one of the mainstream treatments for cancer patients, has gained
notable advancements in past decades.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"consequently, it is essential to develop a robust
methodology to automatically predict the dose distribution for cancer patients,
relieving the burden on dosimetrists and accelerating the radiotherapy
procedure.recently, the blossom of deep learning (dl) has promoted the automatic
medical image processing tasks [4][5][6], especially for dose prediction
[7][8][9][10][11][12][13][14].",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"[7] modified the
traditional 2d unet [15] to predict the dose of prostate cancer patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"therefore, introducing a diffusion model to the dose prediction task is a
worthwhile endeavor.in this paper, we investigate the feasibility of applying a
diffusion model to the dose prediction task and propose a diffusion-based model,
called diffdp, to automatically predict the clinically acceptable dose
distribution for rectum cancer patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"(3) the
proposed diffdp is extensively evaluated on a clinical dataset consisting of 130
rectum cancer patients, and the results demonstrate that our approach
outperforms other state-of-the-art methods.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"an image
set of cancer patient is defined as {x, y}, where x ∈ r h ×w ×(2+o) represents
the structure images, ""2"" signifies the ct image and the segmentation mask of
the ptv, and o denotes the total number of segmentation mask of oars.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"we measure the performance of our model on an in-house
rectum cancer dataset which contains 130 patients who underwent volumetric
modulated arc therapy (vmat) treatment at west china hospital.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"concretely, for
every patient, the ct images, ptv segmentation, oars segmentations, and the
clinically planned dose distribution are included.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"we randomly select 98 patients for model training, 10
patients for validation, and the remaining 22 patients for test.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"in this paper, we introduce a novel diffusion-based dose prediction (diffdp)
model for predicting the radiotherapy dose distribution of cancer patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"moreover, we propose a structure encoder to extract anatomical
information from patient anatomy images and enable the model to concentrate on
the dose constraints within several essential organs.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"extensive experiments on
an in-house dataset with 130 rectum cancer patients demonstrate the superiority
of our method.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning,"however, these methods still rely on at least patient-level annotations.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning,"the bias and error generated in each level of the
representation model will accumulate in the final decision model.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning,"the multi-stage framework
accumulated the training bias and noise, which caused an auc gap of hipt [5] to
mae [7] and pama, especially trained with only 10% labeled wsis.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,"cervical cancer is a common and severe disease that affects millions of women
globally, particularly in developing countries [9].",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,"3, our method has shorter
inference time and a good balance between accuracy and inference time.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Instance-Aware Diffusion Model for Gland Segmentation in Colon Histology Images,"we
enhance our loss function by incorporating two components, l d and l s , and
utilize the γ parameter to optimize the balance between these two losses.where
the l s in our model represents the measure of overlap between the predicted
instance mask and the ground truth s gt [14], and the l d is the loss of
diffusiondet.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Instance-Aware Diffusion Model for Gland Segmentation in Colon Histology Images,"in this work,
we chose γ = 5 to balance these two losses.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs,"such scheduling of the weights is done so that in the beginning of
the training, the weights are uniform in order not to wrongly bias the network
when the embeddings are still indiscriminative.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"although some classification methods achieve promising performance on balanced
and clean medical datasets, balanced datasets with high-accuracy annotations are
time-consuming and expensive.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"besides, pruning clean and balanced datasets
require a large amount of crucial clinical data, which is insufficient for
large-scale deep learning.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"therefore, we focus on a more practical yet
unexplored setting for handling imbalanced medical data with noisy labels,
utilizing all available lowcost data with possible noisy annotations.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"noisy
imbalanced datasets arise due to the lack of high-quality annotations [11] and
skewed data distributions [18] where the number of instances largely varies
across different classes.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"therefore, noisy-labeled, imbalanced datasets with various class
hardness remain a persistent challenge in medical classification.existing
approaches for non-ideal medical image classification can be summarized into
noisy classification, imbalanced recognition, and noisy imbalanced
identification.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"however, imbalanced data creates different confidence distributions of clean and
noisy data in the majority class and minority class as shown in fig.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"imbalanced recognition approaches
[9,15,21] utilize augmented embeddings and imbalance-invariant training loss to
re-balance the long-tailed medical data artificially, but the disturbance from
noisy labels leads to uncasual feature learning, impeding the recognition of
tail classes.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"noisy longtailed identification technique [25] has achieved
promising results by addressing noise and imbalance concerns sequentially.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"in the noisy imbalanced classification setting, we denote a medical dataset as
{(x i , y i )} n i=1 where y i is the corresponding label of data x i and n is
the total amount of instances.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"we aim to train a robust medical image classification model composed of a
representation backbone and a classifier head on label noise and imbalance
distribution, resulting in a minimized loss on the testing dataset: we decompose
the non-linear mapping p(y = c|x) as a product of two space
mappings p g (y = c|z) • p h (z|x).",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"given that backbone mapping is independent
of noisy imbalanced effects, we conduct further disentanglement by defining e as
the negative effects and p as constant for fixed probability mappings:the
induction derives from the assumption that the incorrect mapping p g (y = c|z,
e) conditions on both pure latent to logits mapping p g (y = c|z) and adverse
effects p g (y = c|e).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"by bayes theorem, we decompose the effect into imbalance,
noise, and mode (hardness), where the noise effect depends on skew distribution
and hardness effect; and the hardness effect is noise-invariant.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"currently,
noise removal methods only address pure noise effects (p g (e n |y = c)), while
imbalance recognition methods can only resolve imbalanced distribution, which
hinders the co-removal of adverse influences.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"however, they fail to consider the influence of imbalanced
distributions, which might cause a biased gradient direction on the optimization
subspace.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"by the law of large numbers, all
constructed distributions should be symmetric according to the balanced
distribution to obtain a uniform expectation.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"with a pre-defined noise selection threshold as τ
, we have the final clean score as: in contrast to two-stage noise removal and
imbalance classification techniques,
our approach applies a multi-stage protocol: warm-up phases, noise removal
phases, and fine-tuning phases as shown in fig.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"finally, in the fine-tuning phases, we
apply mixup technique [13,25,26] to rebuild a hybrid distribution from noisy
pairs and clean pairs by:where α kl := v(x k ) v(x l ) denotes the balanced
scale; and {(x kl , ŷkl )} are the mixed clean data for classifier fine-tuning.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"sqrt sampler is applied to re-balance the data, and cross-stage kl [12] and ce
loss are the fine-tuning loss functions.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"we evaluated our approach on two medical image datasets with imbalanced class
distributions and noisy labels.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"to emulate imbalanced scenarios, we prune the
class sizes of the training set into an imbalanced distribution as [5].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"the imbalanced ratios [12] of
ham10000 and chaoyang are 59 and 20, respectively.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"we compare our model with state-of-the-art methods which contain noisy methods
(including dividemix [13], nl [16], gce [27], co-learning [19]), imbalance
methods (including focal loss [14], sqrt-rs [17], pg-rs [10], cb-focal [5], eql
[21], eql v2 [20], cece [5], clas [28], fcd [12]), and noisy imbalanced
classification methods (including h2e [25], nl+sqrt-rs, gce+sqrt-rs, gce+focal).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"further, our multi-stage noise removal technique outperforms single mer and
rcgm, revealing that the decomposition for noise effect and hardness effect
works on noisy imbalanced datasets.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"we propose a multi-step framework for noisy long-imbalanced medical image
classification.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"we address three practical adverse effects including data noise,
imbalanced distribution, and class hardness.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,"to solve these difficulties, we
conduct multi-environment risk minimization (mer) and rescaling class-aware
gaussian mixture modeling (rcgm) together for robust feature learning.extensive
results on two public medical image datasets have verified that our framework
works on the noisy imbalanced classification problem.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"colorectal cancer is the third most common malignant tumor, and nearly half of
all patients with colorectal cancer develop liver metastasis during the course
of the disease [6,16].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"patients with colorectal cancer typically undergo contrast-enhanced computed
tomography (cect) scans multiple times during follow-up visits after surgery for
early detection of crlm, generating a 5d dataset.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"when patients undergo cect
scans to detect crlm, typically three phases are captured: the unenhanced plain
scan phase (p), the portal venous phase (v), and the arterial phase (a).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"that means patients have not been diagnosed as crlm when they took the
scans.-patients were previously diagnosed with colorectal cancer tnm stage i to
stage iii, and recovered from colorectal radical surgery.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"-patients have two or
more times of cect scans.-we already determined whether or not the patients had
liver metastases within 2 years after the surgery, and manually labeled the
dataset based on this.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"the first cohort consists of 201 patients and the
second cohort includes 68 patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"patients may have different numbers
of ct scans, ranging from 2 to 6, depending on the number of follow-up visits.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"we selected 170 patients who underwent three or more cect scans from our
original dataset, and cropped the images to only include the liver area, as
shown in fig.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"to handle the imbalanced training dataset, we selected and
duplicated 60% of positive cases and 20% of negative cases by applying standard
scale jittering (ssj) [5].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"we applied the same augmentation
technique consistently to all phases and timestamps of each patient's data.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"1, patients b and c are diagnosed with positive crlm
later.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"mpbd-lstm correctly yields a positive prediction for patient b with a
confidence of 0.82, but incorrectly yields a negative prediction for patient c
with a confidence of 0.77.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"with similar confidence in the two cases, the error
is likely due to the relatively smaller liver size of patient c.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"how to effectively address
inter-patient variability in the dataset, perhaps by better fusing the 5d
features, requires further research from the community in the future.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Progressive Attention Guidance for Whole Slide Vulvovaginal Candidiasis Screening,"it is the most prevalent human candidal infection,
estimated to afflict approximately 75% of all women at least once in their
lifetime [1,20], resulting in huge consumption of medical resources.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Progressive Attention Guidance for Whole Slide Vulvovaginal Candidiasis Screening,"the class
imbalance makes it difficult to conduct discriminative learning and to find
candida.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Progressive Attention Guidance for Whole Slide Vulvovaginal Candidiasis Screening,"dataset-small is balanced with 100 positive wsis and
100 negative wsis.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Progressive Attention Guidance for Whole Slide Vulvovaginal Candidiasis Screening,"we further validate upon an
imbalanced dataset-large of 7654 wsis.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
CellGAN: Conditional Cervical Cell Synthesis for Augmenting Cytopathological Image Classification,"then, we pass c through learnable affine transformations,
such that the class embedding is specialized to the scaling and bias parameters
controlling adaptive instance normalization (adain) [13] in each upblock.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
An Anti-biased TBSRTC-Category Aware Nuclei Segmentation Framework with a Multi-label Thyroid Cytology Benchmark,"innovatively, our approach can
help reduce bias in the learning process of the segmentation model with the
routine unbalanced training set.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
An Anti-biased TBSRTC-Category Aware Nuclei Segmentation Framework with a Multi-label Thyroid Cytology Benchmark,"the traditional method of
integrating gaussian noise in the mean teacher [18] may be problematic when
working with cytopathology images that have an imbalanced color distribution.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
An Anti-biased TBSRTC-Category Aware Nuclei Segmentation Framework with a Multi-label Thyroid Cytology Benchmark,"patient-level
images were partitioned first for training and test images, and patch-level
curation was performed.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,"breast cancer (bc) is one of the most common malignant tumors in women worldwide
and it causes nearly 0.7 million deaths in 2020 [26].",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,"the reconstruction loss is computed by the mean
squared error between the original images x, y and the generative images x , y ,
which is computed aswe use an adjustable hyperparameter θ to balance the losses
of two modalities.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Semi-supervised Pathological Image Segmentation via Cross Distillation of Multiple Attentions,"since using a model's prediction to supervise itself may over-fit its bias,
chen et al.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Semi-supervised Pathological Image Segmentation via Cross Distillation of Multiple Attentions,"since the three branches have different decision boundaries, using the
predictions from one branch as pseudo labels to supervise the others would avoid
each branch over-fitting its bias.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Towards Novel Class Discovery: A Study in Novel Skin Lesions Clustering,"the overall contrastive loss can be
expressed as:, where μ denotes the balance coefficient.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Towards Novel Class Discovery: A Study in Novel Skin Lesions Clustering,"for
each sample in the current batch, we compute the similarity between its features
and the features of each sample in the memory bank:then based on this feature
similarity, we obtain the final pseudo labels as:k , where ρ is the balance
coefficient.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Towards Novel Class Discovery: A Study in Novel Skin Lesions Clustering,"since the dataset suffers from
severe category imbalance, we randomly sampled 500 samples from those major
categories (mel, nv, bcc, bkl) to maintain category balance.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"therefore, synergizing multimodal data could
deepen a crossscale understanding towards improved patient prognostication.the
major goal of multimodal data learning is to extract complementary contextual
information across modalities [4].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"overall, we formulate the objective of multimodal feature learning by
converting image patches and tabular genomics data into groupwise embeddings,
and then extracting multimodal patient-wise embeddings.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"the abr and the
group-wise embedding i n ∈ r 1×256 are defined as:where w,v1 and v2 are the
learnable parameters.patient-wise multimodal feature embedding.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"to aggregate
patient-wise multimodal feature embedding from the group-wise representations,
as shown in fig.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"in the pathological image
stream, the patient-wise image representation is aggregated by n group
representations as, where p ∈ p and p is the number of patients.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"similarly, the
patient-wise genomics representation is aggregated as g p ∈ r n ×256 .",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"after
generating patient-wise representation, we utilize two transformer layers [27]
to extract feature embeddings for each modality as follows:where msa denotes
multi-head self-attention [27] (see appendix 1), l denotes the layer index of
the transformer, and h p could either be i p or g p .",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"ideally, the image
and genomics embeddings belonging to the same patient should have a higher
relevance between each other.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"we collected wsis
from the cancer genome atlas colon adenocarcinoma (tcga-coad) dataset
(cc-by-3.0) [8,21] and rectum adenocarcinoma (tcga-read) dataset (cc-by-3.0)
[8,20], which contain 440 and 153 patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"finally, we included 426 patients of tcga-coad and 145 patients of
tcga-read.experimental settings and implementations.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"we followed the previous studies [5][6][7] to partition the overall
survival (os) months into four non-overlapping intervals by using the quartiles
of event times of uncensored patients for discretized-survival c-index
calculation (see appendix 2).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"in addition, our model reflects
its efficiency on the limited finetuning data (e.g., 75 patients are used for
finetuning on tcga-read, which are only 22% of tcga-coad finetuning data).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"for the
tcga-read dataset, as the number of uncensored patients is limited, we use 75%,
50%, and 25% of the finetuning data to allow at least one uncensored patient to
be included for finetuning.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"developing data-efficient multimodal learning is crucial to advance the survival
assessment of cancer patients in a variety of clinical data scenarios.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"we
demonstrated that the proposed pathomics framework is useful for improving the
survival prediction of colon and rectum cancer patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Robust Cervical Abnormal Cell Detection via Distillation from Local-Scale Consistency Refinement,cervical cancer is the second most common cancer among adult women.,,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Robust Cervical Abnormal Cell Detection via Distillation from Local-Scale Consistency Refinement,"nevertheless, delayed
diagnosis of cervical cancer until an advanced stage will have a negative impact
on patient prognosis and consume medical resources.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
StainDiff: Transfer Stain Styles of Histology Images with Denoising Diffusion Probabilistic Models and Self-ensemble,"finally, the overall loss function is l = l d + γl c , balanced by the
coefficient γ.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"in spite of the large amount of data, the number of labeled samples in
mil (represented by the number of individual, globally labelled wsis) is often
small and/or imbalanced [6].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"variations were proposed,
to be applied to latent representations [17] as well as to balance data sets
[6].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"we investigated various
settings consisting of instancebased only (inst), embedding-based only (emb) and
the dual-stream approach with weightings 3/1, 2/2 (balanced) and 1/3 for the
instance and the embedding-based pathways.as comparison, several other
augmentation methods on feature level are investigated including random
sampling, selective random sampling and random noise.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"the mean and median
age of patients at the date of dissection was 47 and 50 years, respectively.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"the
data set comprised 13 male and 27 female patients, corresponding to a slight
gender imbalance.",,0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"due to the almost balanced setting, the overall
classification accuracy (mean and standard deviation) is finally reported.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"in our analysis, we focused on the embedding-based configuration and on
the balanced combined approach (referred to as 2/2).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"breast cancer (bc) is the most common cancer diagnosed among females and the
second leading cause of cancer death among women after lung cancer [1].",,0,0,0,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"thus, effective and accurate prognosis of
bc as well as stratifying cancer patients into different subgroups for
personalized cancer management has attracted more attention than ever
before.among different types of imaging biomarkers, histopathological images are
generally considered the golden standard for bc prognosis since they can confer
important cell-level information that can reflect the aggressiveness of bc [4].",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"for instance, lu et al [5] presented a
novel approach for predicting the prognosis of er-positive bc patients by
quantifying nuclear shape and orientation from histopathological images.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"however, due to the high-cost of
collecting survival information from the patients, it is still a challenge to
build effective machine learning models for specific bc subtypes with limited
annotation data.to deal with the above challenges, several researchers began to
design domain adaption algorithms, which utilize the labeled data from a related
cancer subtype to help predict the patients' survival in the target domain.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"specifically, alirezazadeh et al [7] presented a new representation
learning-based unsupervised domain adaption method to predict the clinical
outcome of cancer patients on the target domain.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"it can be expected that better
prognosis performance can be achieved if we leveraged the tils-tumor interaction
information to resolve the survival analysis task on the target domain.based on
the above considerations, in this paper, we proposed a tils-tumor interactions
guided unsupervised domain adaptation (t2uda) algorithm to predict the patients'
survival on the target bc subtype.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"we evaluated the performance of
our method on the breast invasive carcinoma (brca) cohort derived from the
cancer genome atlas (tcga), and the experimental results indicated that t2uda
outperforms other domain adaption methods for predicting patients' clinical
outcomes.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"the cox proportional hazard model was applied to predict the patients' clinical
outcome [16], and its negative log partial likelihood function can be formulated
as:where x i represents the output of the last layer for the prognosis task and
r (t i ) is the risk set at time t i , which represents the set of patients that
are still under risk before time t.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,sample i refers to censored patient ifoverall objective.,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"specifically, the brca dataset
includes 661 patients with hematoxylin and eosin (he)-stained pathological
imaging and corresponding survival information.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"among the collected brca
patients in tcga, the number of er positive(er+) and er negative(er-) patients
are 515 and 146, respectively.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"instead of directly aligning regions, our proposed method
focused on similar tils-tumor interactions and aligning patches of the same
tissue.we also evaluated the contributions of the key components of our
framework and found that t2uda performed better than source only and t2uda-v1,
which shows the advantage of minimizing differences in tils-tumor interaction
weights.in addition, we also evaluated the patient stratification performance of
different methods.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"3, our proposed t2uda outperformed feature
alignment-based methods (such as ddc and deepjdot), adversarial-based methods
(such as dann and mdd), and t2uda-v1 in stratification performance, proving that
considering the interaction between tils and tumors as migration knowledge leads
to better prognostic results.we also examined the consistency of important edges
in each group of stratified patients based on the tils-tumor interaction weights
calculated by the gat-based framework in the source and target domains.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"4(b), the weights of the edges connecting tumor
and tils regions were higher for patients in the low survival risk group in both
source and target domains.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"in this paper, we presented an unsupervised domain adaptation algorithm that
leverages tils-tumor interactions to predict patients' survival in a target bc
subtype(t2uda).",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Gene-Induced Multimodal Pre-training for Image-Omic Classification,"furthermore, to model the high-order relevance of the two modalities, we combine
cls tokens of paired image and genomic data to form unified representations and
propose a triplet learning module to differentiate patient-level positive and
negative samples in a mini-batch.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Gene-Induced Multimodal Pre-training for Image-Omic Classification,"it is worth mentioning that although our
unified representation fuses features from the whole gene expression cohort and
partial wsis in a mini-batch, we can still learn high-order relevance and
discriminative patient-level information between these two modalities in
pre-training thanks to the triplet learning module.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Gene-Induced Multimodal Pre-training for Image-Omic Classification,"after extracting the input patch embeddings and gene
sequence separately, we concatenate cls img and cls ge as cls pat ∈ r 2d to
represent patient-level characteristics.suppose we obtain a triplet list {x, x +
, x -} during current iteration, where x, x + , x -are concatenated tokens of
anchor cls pat , positive cls pat , and negative cls pat , respectively.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Gene-Induced Multimodal Pre-training for Image-Omic Classification,"to
enhance the global modeling capability, i.e., extracting more precise
patient-level features, we expect that the distance between the anchor and the
positive sample gets closer, while the negative sample is farther away.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Gene-Induced Multimodal Pre-training for Image-Omic Classification,"applying the pre-trained backbone to image-omic classification task
is straightforward, since gimp pre-training allows it to learn representative
patient-level features.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Gene-Induced Multimodal Pre-training for Image-Omic Classification,"we collect corresponding rna-seq fpkm
data for each patient and the length of the input genomic sequence is 60,480.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Gene-Induced Multimodal Pre-training for Image-Omic Classification,"2 (c) and (d), cls pat with gimp pre-trained are well separated between
luad and lusc, i.e., gimp pays more attention to the categoryrelated feature
distribution and could extract more discriminative patient-level features during
triplet learning.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Histopathology Image Classification Using Deep Manifold Contrastive Learning,"the dataset for the former task was collected from 168 patients
with 332 wsis from seoul national university hospital.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Histopathology Image Classification Using Deep Manifold Contrastive Learning,"the k-nearest neighbors graph and
the geodesic distance matrix are updated once every five training epochs, which
is empirically chosen to balance running time and accuracy.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"if significant pca is detected on
biopsies and the patient has organ-confined cancer with no contraindications,
radical prostatectomy (rp) is the standard of care [3,4].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"machine learning algorithms have been used to
quantify the percentage of tumor to stroma in bladder cancer patients, but
required dichotomizing patients based on a threshold [14].",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"software has been
used to segment tumor and stroma tissue in breast cancer patient samples, but
the method required constant supervision by a pathologist [15].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"the optimization process aims to achieve a
balance between these two goals, resulting in an embedding space that encodes as
much information as possible about tumor-associated stroma identification while
not encoding any information on the data source.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"in our study, we utilized three datasets for tumor-associated stroma
analysis.(1) dataset a comprises 513 tiles extracted from the whole mount slides
of 40 patients, sourced from the archives of the pathology department at
cedars-sinai medical center (irb# pro00029960).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"it combines two sets of tiles:
224 images from 20 patients featuring stroma, normal glands, low-grade and
highgrade cancer [22], along with 289 images from 20 patients with dense
high-grade cancer (gleason grades 4 and 5) and cribriform/non-cribriform glands
[23].",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"(3) dataset c comprised 6134 negative biopsy slides obtained from 262
patients' biopsy procedures, where all samples were diagnosed as negative.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"future research can focus on validating our
approach on larger and more diverse datasets and expanding the method to a
patient-level prediction system, ultimately improving prostate cancer diagnosis
and treatment.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Multi-scope Analysis Driven Hierarchical Graph Transformer for Whole Slide Image Based Cancer Survival Prediction,"the ability to predict the future risk of patients with cancer can significantly
assist clinical management decisions, such as treatment and monitoring [21].",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Multi-scope Analysis Driven Hierarchical Graph Transformer for Whole Slide Image Based Cancer Survival Prediction,"deepattnmisl [26] extracted the phenotype patterns of the patient via a
clustering algorithm, which provides meaningful medical prior to guide the
aggregation of patch features.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Multi-scope Analysis Driven Hierarchical Graph Transformer for Whole Slide Image Based Cancer Survival Prediction,"for the network training, cox loss [26] is adopted for the survival prediction
task, which is defined as:where δ i denote the censorship of i-th patient, o(i)
and o(j) denote the survival output of i-th and j-th patient in a batch,
respectively.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Multi-scope Analysis Driven Hierarchical Graph Transformer for Whole Slide Image Based Cancer Survival Prediction,"the concordance index (ci) [23] is used to measure the
fraction of all pairs of patients whose survival risks are correctly ordered.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Multi-scope Analysis Driven Hierarchical Graph Transformer for Whole Slide Image Based Cancer Survival Prediction,"moreover, to
evaluate the ability of patients stratification, the kaplan-meier (km) analysis
is used [23].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Mining Negative Temporal Contexts for False Positive Suppression in Real-Time Ultrasound Lesion Detection,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Iteratively Coupled Multiple Instance Learning from Instance to Bag Classifier for Whole Slide Image Classification,"however, the lack of reliable supervision directly hinders the
performance of these methods, and serious class-imbalance problems could arise,
as tumor patches may only account for a small portion of the entire wsi [12].in
contrast, mil-based methods have become increasingly preferred due to their only
demand for slide-level labels [18].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Iteratively Coupled Multiple Instance Learning from Instance to Bag Classifier for Whole Slide Image Classification,"since the number of
instances is very large in wsi datasets, we empirically recommend to choose to
run icmil one iteration for fine-tuning g(•) to achieve the balance between
performance gain and time consumption.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Artifact Restoration in Histology Images with Diffusion Probabilistic Models,"furthermore, our approach is trained solely with artifact-free images, which
reduces the difficulty in data collection.the major contributions are two-fold.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
Thinking Like Sonographers: A Deep CNN Model for Diagnosing Gout from Musculoskeletal Ultrasound,"however, misdiagnosis of gout can occur frequently when a patient's clinical
characteristics are atypical.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Thinking Like Sonographers: A Deep CNN Model for Diagnosing Gout from Musculoskeletal Ultrasound,"(1) where to
adjust: modeling sonographers' gaze map to emphasize the region that needs
adjust; (2) what to adjust: classify the instances to systemically detect
predictions made based on unreasonable/biased reasoning and adjust; (3) how to
adjust: developing a training mechanism to strike the balance between gout
prediction accuracy and attention reasonability.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Thinking Like Sonographers: A Deep CNN Model for Diagnosing Gout from Musculoskeletal Ultrasound,"3) how to adjust: a
training mechanism is developed to strike the balance between gout diagnosis and
attention accuracy for improving cnn.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Thinking Like Sonographers: A Deep CNN Model for Diagnosing Gout from Musculoskeletal Ultrasound,"we proposed a training mechanism (algorithm 1) which can strike the balance
between the gout diagnosis error and the reasonability error of attention region
to promote the cnns to ""think like sonographers"".",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Thinking Like Sonographers: A Deep CNN Model for Diagnosing Gout from Musculoskeletal Ultrasound,"for sample in rp and uip, α
can be set 0.5 to strike the balance between accuracy and reasonability.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Thinking Like Sonographers: A Deep CNN Model for Diagnosing Gout from Musculoskeletal Ultrasound,"gaze
data collection.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
Thinking Like Sonographers: A Deep CNN Model for Diagnosing Gout from Musculoskeletal Ultrasound,"this removed the need to collect eye movement
maps during the training and testing phases, significantly lightening the
workload of data collection.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
Scribble-Based 3D Multiple Abdominal Organ Segmentation via Triple-Branch Multi-Dilated Network with Pixel- and Class-Wise Consistency,"we used the publicly available abdomen ct dataset word [17] for experiments,
which consists of 150 abdominal ct volumes from patients with rectal cancer,
prostate cancer or cervical cancer before radiotherapy.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"breast cancer is the most prevalent form of cancer among women and can have
serious physical and mental health consequences if left unchecked [5].",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"by identifying breast cancer early, patients can receive targeted treatment
before the disease progresses.deep neural networks have been widely adopted for
breast cancer diagnosis to alleviate the workload of radiologists.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"furthermore, there are differences between
multi-view mammograms of the same patient, arising from variations in breast
shape and density.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"we employ the noise-contrastive
estimation framework [6] to maximize the mutual information, which is a
contrastive learning framework:where s(i, p v ) evaluates the correlation
between multi-view fused representations and single-view representations
[17]:where n (i) is a reconstruction of p v generated by a fully connected
network n from i and the euclidean norm || • || 2 is applied to obtain
unit-length vectors.in contrastive learning, we consider the same patient
mammograms as positive samples and those from different patient mammograms in
the same batch p i v = p v \{p i v } as negative samples [17].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"minimizing the
similarity between the same patient mammograms enables the model to learn shared
features.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"maximizing the dissimilarity between different patient mammograms
enhances the model's robustness.in short, we require the fusion representation i
to reversely reconstruct multiview representations p v so that more
view-invariant information can be passed to i.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"to address the problem of imbalanced classes, we utilized a
weighted loss function that assigns higher weights to malign cases in order to
balance the number of benign and malign cases.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
CTFlow: Mitigating Effects of Computed Tomography Acquisition and Reconstruction with Normalizing Flows,"(2) aapm-mayo clinic low-dose ct ""grand challenge"" dataset,
a publicly available grand challenge dataset consisting of 5,936 abdominal ct
images from 10 patient cases reconstructed at 1.0 mm slice thickness.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
CTFlow: Mitigating Effects of Computed Tomography Acquisition and Reconstruction with Normalizing Flows,"images from eight patient cases were used for training, and two cases were
reserved for validation.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Probabilistic Modeling Ensemble Vision Transformer Improves Complex Polyp Segmentation,"to balance the trade-off between computational speed and feature representation
capability, we utilize the pre-trained pvtv2-b2 model [18] as the backbone.mixed
transformer attention(mta) layer is composed of local-global gaussian-weighted
self-attention (lgg-sa) and external attention (ea).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Probabilistic Modeling Ensemble Vision Transformer Improves Complex Polyp Segmentation,"λ is a hyperparameter used to
balance the binary and gaussian losses.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,"breast cancer (bc) is the most common cancer in women and incidence is
increasing [14].",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,"the tumors and symmetrical mammograms are combined by an
alpha blending-based method [17], which can be denoted by x|fake =the alpha
weights α k is a 2d gaussian distribution map, in which the co-variance is
determined by the size of k-th tumor t, representing the transparency of the
pixels of the tumor.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,"the in-house
dataset comprises 43,258 mammography exams from 10,670 women between 2004-2020,
collected from a hospital with irb approvals.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,"in this study, we randomly select
20% women of the full dataset, comprising 6,000 normal (bi-rads = 1) and 28,732
abnormal (bi-rads = 1) images.",,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,"each dataset is randomly
split into training, validation, and testing sets at the patient level in an
8:1:1 ratio, respectively (except for that inbreast which is split with a ratio
of 6:2:2, to keep enough normal samples for the test).table 1.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,"thus, early detection of kidney tumors can
help to improve patient's prognosis.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,"while this method demonstrated high sensitivity (95%), its false
positives per patient remained high (15 false positives per patient).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Skin Lesion Correspondence Localization in Total Body Photography,"however, establishing skin
lesion correspondences across multiple scans from different patient visits has
not been well investigated in the context of full-body imaging.several
techniques have been proposed to match skin lesions across pairs of 2d images
[9][10][11][12][13][14]16,17,25].",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Anatomy-Informed Data Augmentation for Enhanced Prostate Cancer Detection,"inducing this kind of
soft tissue deformation ultimately led to improved model performance in
patient-and lesion-level pca detection on an independent test set.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Anatomy-Informed Data Augmentation for Enhanced Prostate Cancer Detection,"we apply
either our proposed transformation to the rectum or the bladder, random
deformable or no transformation in randomly selected exams and conduct a strict
turing test with clinicians having different levels of radiology expertise (a
freshly graduated clinician (c.e.) and resident radiologists (c.m., k.s.z.), 1.5
-3 years of experience in prostate mri) to determine if they can notice the
artificial deformation.finally, we quantify the effect of our proposed
transformation on the clinical task of patient-level pca diagnosis and
lesion-level pca detection.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Anatomy-Informed Data Augmentation for Enhanced Prostate Cancer Detection,"to consider clinically informative results, we
use the partial area under the receiver operating characteristic (pauroc) for
patient-level evaluation with the sensitivity threshold of 78.75%, which is 90%
of the sensitivity of radiologists for pi-rads ≥ 4.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Anatomy-Informed Data Augmentation for Enhanced Prostate Cancer Detection,"every patient
underwent extended systematic and targeted mri trans-rectal ultrasound-fusion
transperineal biopsy.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Anatomy-Informed Data Augmentation for Enhanced Prostate Cancer Detection,"compared to the standard nnu-net settings, we implemented balanced
sampling regarding the prevalence of cspca and reduced the number of epochs to
350 to avoid overfitting.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Anatomy-Informed Data Augmentation for Enhanced Prostate Cancer Detection,"in table 1 we summarize the patient-level pauroc and f 1 -scores; and
lesion-level froc results on the independent test set showing the advantage of
using anatomy-informed da.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Anatomy-Informed Data Augmentation for Enhanced Prostate Cancer Detection,"extending the basic da scheme with the proposed anatomy-informed deformation not
only increased the sensitivity closely matching the radiologists' patient-level
diagnostic performance but also improved the detection of pca on a lesion level.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Anatomy-Informed Data Augmentation for Enhanced Prostate Cancer Detection,"interestingly, while the use of random deformable transformation also improved
lesion-level performance, it did not approach the diagnostic performance of the
radiologists, unlike the anatomy-informed da.at the selected patient-and
object-level working points, the model with the proposed rectum-and
bladder-informed da scheme reached the best results with significant
improvements (p < 0.05) compared to the model with the basic da setting by
increasing the f 1 -score with 5.11% and identifying 4 more lesions (5.3%) from
the 76 lesions in our test set.the time overhead introduced by anatomy-informed
augmentation caused no increase in the training time, the gpu remained the main
bottleneck.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,"particularly, graph transformer networks (gtn) has have shown to
further enhance the transparency of underlying relation between the graph nodes
and decision making via attention mechanism [11].biological data, specially
those acquired intra-opertively, are heterogeneous by nature.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,"ex-vivo: data is collected from fresh breast tissue samples from the patients
referred to bcs at kingston health sciences center over two years.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,"the study is
approved by the institutional research ethics board and patients consent to be
included.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,"in total 51 cancer and 149 normal spectra are collected and
stratified into five folds (4 for cross validation and 1 prospectively) with
each patient restricted to one fold only.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,"to fit the dirichlet distribution to the
output layer of our network, we use a loss function consisting of the prediction
error l p i and the evidence adjustmentwhere λ is the annealing coefficient to
balance the two terms.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,"to demonstrate the robustness of the model and ensure it is not
overfitting, we also report the performance of the ensemble model from the
4-fold cross validation study on the 5th unseen prospective test fold.clinical
relevance: hormone receptor status plays an important role in determining breast
cancer prognosis and tailoring treatment plans for patients [6].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,"lastly, when compared to other state-ofthe-art
baselines with uncertainty estimation mechanisms, the proposed evidential graph
transformer network (average balanced accuracy of 91.6 ± 4.3% in table 1)
outperforms mc dropout [9], deep ensembles [15], and masksembles [7] (86.1 ±
5.7%, 88.5 ± 6.8%, and 89.2 ± 5.4% respectively [19]).the estimated
probabilities in evidence based models are directly correlated with model
confidence and therefore more interpretable.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,"average(standard deviation) of accuracy (acc), balanced accuracy (bac)
sensitivity (sen), specificity (spc), and the area under the curve (auc) for the
proposed evidential graph transformer in comparison with graph transformer
(gtn), graph convolution (gcn), and non-graph convolution (cnn) baselines.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Radiomics-Informed Deep Learning for Classification of Atrial Fibrillation Sub-Types from Left-Atrium CT Volumes,"recent works have shown that automatic classification of af sub-types can be
done using ct volumes of the left atrium and surrounding eat, which can be used
to screen for patients with high risk of peaf.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Radiomics-Informed Deep Learning for Classification of Atrial Fibrillation Sub-Types from Left-Atrium CT Volumes,"to
summarize our key contributions: -we propose a novel radiomics-informed deep
learning (ridl) method for af sub-type classification from ct volumes, which
achieves state-of-the-art results and can be used to screen for patients with
high risk of peaf.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Radiomics-Informed Deep Learning for Classification of Atrial Fibrillation Sub-Types from Left-Atrium CT Volumes,"we use a dataset of 172 patients containing 94 paaf and 78 peaf cases
collected from the sun yat-sen memorial hospital in china.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Radiomics-Informed Deep Learning for Classification of Atrial Fibrillation Sub-Types from Left-Atrium CT Volumes,"overall, our method is a novel
way of combining radiomic and deep learning approaches, and can be used to
improve accuracy of peaf screening from ct volumes for better preventive care of
high-risk patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-Based Hierarchical Fusion Network with Attention Mechanism,"breast cancer is the most common cancer and the leading cause of cancer death in
women [18].",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-Based Hierarchical Fusion Network with Attention Mechanism,"early detection of breast cancer allows patients to receive timely
treatment, which may have less burden and a higher probability of survival [6].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-Based Hierarchical Fusion Network with Attention Mechanism,"however, the use
of gadolinium-based contrast agents (gbca) requires iv-cannulation, which is a
burden to patients, time consuming and cumbersome in a screening situation.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-Based Hierarchical Fusion Network with Attention Mechanism,"studies have shown that dwi could be used to detect
lesions, distinguish malignant from benign breast lesions, predict patient
prognosis, etc [1,3,7,8,17].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-Based Hierarchical Fusion Network with Attention Mechanism,"dwi may be a valuable alternative in breast cancer detection in patients with
contraindications to gbca [3].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-Based Hierarchical Fusion Network with Attention Mechanism,"we retrospectively collected 765 patients
with breast cancer presenting at our cancer institute from january 2015 to
november 2020, all patients had biopsy-proven breast cancers (all cancers
included in this study were invasive breast cancers, and ductal carcinoma in
situ had been excluded).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-Based Hierarchical Fusion Network with Attention Mechanism,"our proposed model can potentially be used to synthesize ce-mri,
which is expected to reduce or avoid the use of gbca, thereby optimizing
logistics and minimizing potential risks to patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"despite the
superior tumor-to-normal tissue contrast of ce-mri, the use of gbcas during mri
scanning can result in a fatal systemic disease known as nephrogenic systemic
fibrosis (nsf) in patients with renal insufficiency [4].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"it was reported that the
incidence rate of nsf is around 4% after gbca administration in patients with
severe renal insufficiency, and the mortality rate can reach 31% [6].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"currently,
there is no effective treatment for nsf, making it crucial to find a ce-mri
alternative for patients at risk of nsf.in recent years, artificial intelligence
(ai), especially deep learning, plays a gamechanging role in medical imaging
[7,8], which showed great potential to eliminate the use of the toxic gbcas
through synthesizing virtual contrast-enhanced mri (vce-mri) from
gadolinium-free sequences, such as t1-weighted (t1w) and t2-weighted (t2w) mri
[9][10][11][12].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"in addition to the advantage of eliminating the
use of gbca, vce-mri synthesis can also speed up the clinical workflow by
eliminating the need for acquiring ce-mri scan, which saves time for both
clinical staff and patients.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"rigorous
clinical evaluations can establish the safety and efficacy of ai-based
techniques, identify potential biases and limitations, and facilitate the
integration of clinical expertise to ensure accurate and meaningful results
[13].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"patient data was retrospectively collected from three oncology centers in hong
kong.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"this dataset included 303 biopsy-proven (stage i-ivb) npc patients who
received radiation treatment during 2012-2016.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"the three hospitals were labelled
as institution-1 (110 patients), institution-2 (58 patients), and institution-3
(135 patients), respectively.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"for each patient, t1w mri, t2w mri,
gadolinium-based ce-mri, and planning ct were retrieved.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"mri images were
automatically registered as mri images for each patient were scanned in the same
position.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"due to
the retrospective nature of this study, patient consent was waived.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"for model
development, 288 patients were used for model development and 15 patients were
used to synthesize vce-mri for clinical evaluation.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"the details of patient
characteristics and the number split for training and testing of each dataset
were illustrated in table 1.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"the effectiveness of this network in vce-mri synthesis for npc patients
has been demonstrated by li et al.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"different from the original
study, which used single institutional data for model development and utilized
min-max value of the whole dataset for data normalization, in this work, we used
mean and standard deviation of each individual patient to normalize mri
intensities due to the heterogeneity of the mri intensities across institutions
[15].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"considering the clinical burden of oncologists, 15 patients
were included for clinical evaluations.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"to evaluate the reality of
vce-mri, oncologists were invited to differentiate the synthetic patients (i.e.,
image volumes that generated from synthetic vce-mri) from real patients (i.e.,
image volumes that generated from real ce-mri).",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"paired two-tailed t-test (with a significance
level of p = 0.05) was applied to analyses if the scores obtained from real
patients and synthetic patients are significantly different.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"an accurate tumor delineation improves local control and reduce toxicity
to surrounding normal tissues, thus potentially improving patient survival [20].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"for comparison, ce-mri was also imported to
eclipse for tumor delineation but assigned as a different patient, which were
shown to oncologists in a random and blind manner.to mimic the real clinical
setting, contrast-free t1w, t2w mri and corresponding ct of each patient were
imported into the eclipse system since sometimes t1w and t2w mri will also be
referenced during tumor delineation.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"due to both real patients and synthetic
patients were involved in delineation, to erase the delineation memory of the
same patient, we separated the patients to two datasets, each with the same
number of patients, both two datasets with mixed real patients and synthetic
patients without overlaps (i.e., the ce-mri and vce-mri from the same patient
are not in the same dataset).when finished the first dataset delineation, there
was a one-month interval before the delineation of the second dataset.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"after the
delineation of all patients, the dice similarity coefficient (dsc) [21] and
hausdorff distance (hd) [22] of the gtvs delineated from real patients and
corresponding synthetic patients were calculated to evaluate the accuracy of
delineated contours.dice similarity coefficient (dsc).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"the dsc can be expressed as:where c ce and c
vce represent the contours delineated from real patients and synthetic patients,
respectively.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"for institution-1, 2 real patients were judged as
synthetic and 1 synthetic patient was considered as real.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"for institution-2, 2
real patients were determined as synthetic and 4 synthetic patients were
determined as real.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"for institution-3, 2 real patients were judged as synthetic
and 3 synthetic patients were considered as real.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"in total, 6 real patients were
judged as synthetic and 8 synthetic patients were judged as real.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"the overall clarity scores of
tumorto-normal tissue interface for real and synthetic patients were 3.67 with a
median of 4 and 3.47 with a median of 4, respectively.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"the average scores for real
and synthetic patients were 3.6 and 3, 3.6 and 3.8, 3.8 and 3.6 for
institution-1, institution-2, and institution-3, respectively.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"5 real patients
got a higher score than synthetic patients and 3 synthetic patients obtained a
higher score than real patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"the scores of the other 7 patient pairs were
the same.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"in total, 126 risk areas were recorded from the
ce-mri for all of the evaluation patients, while 10 (7.94%) false positive high
risk invasion areas and 9 (7.14%) false negative high risk invasion areas were
recorded from vce-mri.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"13 patient pairs obtained the
same staging results.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"for the institution-2 data, all synthetic patients
observed the same stages as real patients.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"for the two t-stage disagreement patients, one synthetic patient was staged as
phase iv while the corresponding real patient was staged as phase iii, the other
synthetic patient was staged as i while corresponding real patient was staged as
phase iii.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"figure 2 illustrated the delineated
primary gtv contours from an average patient with the dsc of 0.765 and hd of
1.938 mm.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"the green contour shows the primary gtv that delineated form the
synthetic patient, while the red contour was delineated from corresponding real
gbca-based patient.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"in this study, we conducted a series of clinical evaluations to validate the
clinical efficacy of vce-mri in rt of npc patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"while recent advances in human body modeling [4,5,12,13,15] have
allowed for automation of patient positioning, scout scans are still required as
they are used by automatic exposure control system in the ct scanners to compute
the dose to be delivered in order to maintain constant image quality [3].since
ldct scans are obtained in a single breath-hold and do not require any contrast
medium to be injected, the scout scan consumes a significant portion of the
scanning workflow time.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"furthermore, any
patient movement during the time between the two scans may cause misalignment
and incorrect dose profile, which could ultimately result in a repeat of the
entire process.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"finally, while minimal, the radiation dose administered to the
patient is further increased by a scout scan.we introduce a novel method for
estimating patient scanning parameters from non-ionizing 3d camera images to
eliminate the need for scout scans during pre-scanning.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"for ldct lung cancer
screening, our framework automatically estimates the patient's lung position
(which serves as a reference point to start the scan), the patient's isocenter
(which is used to determine the table height for scanning), and an estimate of
patient's water equivalent diameter (wed) profiles along the craniocaudal
direction which is a well established method for defining size specific dose
estimate (ssde) in ct imaging [8,9,11,18].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"we trained our
models on a large collection of ct scans acquired from over 60, 000 patients
from over 15 sites across north america, europe and asia.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"-a generative model of
patient wed trained on over 60, 000 patients.-a novel method for real-time
refinement of wed, which can be used for dose modulation water equivalent
diameter (wed) is a robust patient-size descriptor [17] used
for ct dose planning.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"the wed of a patient is thus a function
taking as input a craniocaudal coordinate and outputting the wed of the patient
at that given position.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"we then train an
encoder network to map the patient depth image to the wed manifold.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"in this approach, our latent vector represents the encoding of a
patient in the latent space.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"this way, a single autodecoder can learn
patient-specific continuous wed functions.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"while the depth image provides critical information on the patient anatomy, it
may not always be sufficient to accurately predict the wed profiles.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"for
example, some patients may have implants or other medical devices that cannot be
guessed solely from the depth image.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"additionally, since the encoder is trained
on a smaller data collection, it may not be able to perfectly project the depth
image to the wed manifold.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"first, we use our encoder network to initialize
the latent vector to a point in the manifold that is close to the current
patient.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"as the
table moves and the patient gets scanned, ct data is being acquired and ground
truth wed can be computed for portion of the body that has been scanned, along
with the corresponding craniocaudal coordinate.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"our ct scan dataset consists of 62, 420 patients from 16 different sites across
north america, asia and europe.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"our 3d camera dataset consists of 2, 742 pairs
of depth image and ct scan from 2, 742 patients from 6 different sites across
north america and europe acquired using a ceiling-mounted kinect 2 camera.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"our
evaluation set consists of 110 pairs of depth image and ct scan from 110
patients from a separate site in europe.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,patient positioning is the first step in lung cancer screening workflow.,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"we
propose to estimate the table position by regressing the patient isocenter and
the starting point of the scan by estimating the location of the patient's lung
top.starting position.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"we define the starting position of the scan as the
location of the patient's lung top.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"we trained a denseunet [7] taking the camera
depth image as input and outputting a gaussian heatmap centered at the patient's
lung top location.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"we trained our model on 2, 742 patients using
adaloss [14] and the adam [6] optimizer with a learning rate of 0.001 and a
batch size of 32 for 400 epochs.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"we report an accuracy of 100% on our
evaluation set of 110 patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"the patient isocenter is
defined as the centerline of the patient's body.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"we trained a densenet [1]
taking the camera depth image as input and outputting the patient isocenter.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"we trained our model on 2, 742 patients using adadelta [16]
with a batch size of 64 for 300 epochs.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"we trained our autodecoder model on our unpaired ct scan dataset of 62, 420
patients with a latent vector of size 32.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"the encoder was trained on our paired
ct scan and depth image dataset of 2, 742 patients.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"we trained this baseline model on 2, 742 patients using the adadelta
[6] optimizer with a learning rate of 0.001 and a batch size of 32.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"figure 4 presents a
qualitative evaluation on patients with different body morphology.finally, we
evaluated the clinical relevancy of our approach by computing the relative error
as described in the international electrotechnical commission (iec) standard iec
62985:2019 on methods for calculating size specific dose estimates (ssde) for
computed tomography [2].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"the δ rel metric is defined as:where:-ŵ ed(z) is the
predicted water equivalent diameter -w ed(z) is the ground truth water
equivalent diameter z is the position along the craniocaudal axis of the
patient.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"age-related macular degeneration (amd) is the leading cause of blindness in the
elderly, affecting nearly 200 million people worldwide [24].",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"patients with early
stages of the disease exhibit few symptoms until suddenly converting to the late
stage, at which point their central vision rapidly deteriorates [12].",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"clinicians
currently diagnose amd, and stratify patients, using biomarkers derived from
optical coherence tomography (oct), which provides high-resolution images of
fig.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"however, the widely adopted amd grading system
[7,13], which coarsely groups patients into broad categories for early and
intermediate amd, only has limited prognostic value for late amd.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"clinicians
suspect that this is due to the grading system's reliance on static biomarkers
that are unable to capture temporal dynamics which contain critical information
for assessing progression risk.in their search for new biomarkers, clinicians
have annotated known biomarkers in longitudinal datasets that monitor patients
over time and mapped them against disease progression [2,16,19].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"at the core of our method is the novel
strategy to represent patient time series as trajectories in a latent feature
space.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"after strict quality control, the development
dataset consists of 46,496 scans of 6,236 eyes from 3,456 patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"the
unseen dataset is larger, containing 114,062 scans of 7,253 eyes from 3,819
patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"visual acuity scores, which measured the patient's functional quality of vision
using a logmar chart, are available at 83,964 time points.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"naively clustering whole time series of patients ignores two characteristics of
longitudinal data.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"firstly, individual time series are not directly comparable
as patients enter and leave the study at different stages of their overall
progression.secondly, longer time series can record multiple successive
transitions in disease stage.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"2, matches two sub-trajectories, u and v , of
patients who progress between the same start and end states:since all
sub-trajectories cover a similar temporal duration, d transition also
differentiates between fast and slow progressors and stable periods of no
progression.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"however, by ignoring intermediary images, this metric does not
respect the disease pathway along which patients progress.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"two teams of two ophthalmologists then
review 20 sub-trajectories from distinct patients in each cluster, interpreting
and summarising any consistently observed temporal dynamics.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"we
also include a demographic baseline using age and sex.",,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"each experiment uses 10-fold cross
validation on random 80/20 partitions, while ensuring a patient-wise split.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"in all tasks the
standard biomarkers are only marginally more indicative of risk than the
patient's age and sex.",,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"as late stage patients were overrepresented in our datasets, we
also intend to apply our method to datasets with greater numbers of patients
progressing from earlier disease stages.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Multi-task Learning of Histology and Molecular Markers for Classifying Diffuse Glioma,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"gross tumor volume (gtv)
represents the area of the tumor that can be identified with a high degree of
certainty and is of paramount importance in clinical practice.in the clinical
setting, patients may undergo a second round of rt treatment to achieve complete
tumor control when initial treatment fails to completely eradicate cancer [16].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"during the second course of rt, a ct image i
2 of the same patient is acquired.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"the paired first-second course dataset, s p , is collected from sun
yat-sen university cancer center (ethics approval number: b2023-107-01),
comprising paired ct scans of 69 distinct patients from south china.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"we
collected the gtv dataset s v from medmind technology co., ltd., which has ct
scans from 179 patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"additionally, we collect s e from segthor [12],
consisting of ct scans and esophagus annotations from 40 patients who did not
implementation details.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"notably, the paired first-second course dataset s test p pertains
to the same group of patients, thereby ensuring that any performance drop can be
attributed solely to differences in courses of rt, rather than variations across
different patients.figure 2 illustrates the reduction in the gtv area after the
initial course of rt, where the transverse plane is taken from the same location
relative to the vertebrae (yellow lines).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
CLIP-Lung: Textual Knowledge-Guided Lung Nodule Malignancy Prediction,"lidc-idri [1] is a dataset for pulmonary nodule classification or
detection based on low-dose ct, which involves 1,010 patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
CLIP-Lung: Textual Knowledge-Guided Lung Nodule Malignancy Prediction,"consequently, aligning these distinct feature types becomes challenging,
resulting in a bias towards the text features associated with malignant nodules.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"when a deep learning model overfits specific
artifacts instead of learning the correct dermoscopic patterns, it may fail to
identify skin lesions in real-world environments where the artifacts are absent
or inconsistent.to alleviate the artifact bias and enhance the model's
generalization ability, we rethink the problem from the domain generalization
(dg) perspective, where a model trained within multiple different but related
domains are expected to perform well in unseen test domains.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"(2) trap set debiasing: we train
and test our epvt with its baseline on six trap sets [3] with increasing bias
levels, ranging from 0 (randomly split training and testing sets from the
isic2019 dataset) to 1 (the highest bias level where the correlation between
artifacts and class label is in the opposite direction in the dataset splits).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"each point on the graph represents an algorithm that
is trained and tested on a specific bias degree split.the graph shows that the
erm baseline performs better than our epvt when the bias is low (0 and 0.3).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"as the
bias degree increases, the correlation between artifacts and class labels
decreases, and overfitting the train set causes the performance of erm to drop
dramatically on the test set with a significant distribution difference.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"in
contrast, our epvt exhibits greater robustness to different bias levels.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"notably, our epvt outperforms the erm baseline by 9.4% on the bias 1
dataset.prompt weights analysis: to verify whether our model has learned the
correct domain prompts for target domain prediction, we analyze and plot the
results in fig.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"this phenomenon is especially common in rare tumors like
pancreatic neuroendocrine neoplasms (pnens).in order to overcome above
challenges, some studies [3,9,13,18] used multilabel method because of the
following advantages: 1) the input of the model is only a single modality such
as images, which is easy to apply clinically; 2) the model learns multi-label
and multi-disciplinary knowledge, which is consistent with clinical logic; 3)
multi-label simultaneous prediction, which meets the need of clinical
multi-dimensional description of patients.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"for labels with continuous values such as
age, the value normalized to 0 ∼ 1 is w p i .",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"specifically, embedding setare
the input tokens, the attention value α and output token e are computed as
follows:where e i is from e, w q , w k and w v are weight matrices of query, key
and value, respectively, w r and w o are transformation matrices, and b 1 and b
2 are bias vectors.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"all patients with arterial phase computed tomography (ct)
images were included.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"the dataset contained 264 and 28 patients in center 1 and
center 2, and a senior radiologist annotated the bounding boxes for all 408 and
28 lesions.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"taking a
patient as a sample, we chose the dataset from center 1 as the internal dataset,
of which the samples with most of the main labels were used as dataset 1 (219
lesions) and was split into 5 folds, and the remaining samples are randomly
divided into the training set dataset 2 (138 lesions) and the validation set
dataset 3 (51 lesions), the training set and the validation set of the
corresponding folds were added during cross-validation, respectively.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Developing Large Pre-trained Model for Breast Tumor Segmentation from Ultrasound Images,"breast cancer is a serious health problem with high incidence and wide
prevalence for women throughout the world [1,2].",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
3D Mitochondria Instance Segmentation with Spatio-Temporal Transformers,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Physics-Informed Conditional Autoencoder Approach for Robust Metabolic CEST MRI at 7T,"cest imaging was performed in seven subjects, including two
glioblastoma patients, after written informed consent was obtained to
investigate the dependence of cest effects on b 1 in brain tissue.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Physics-Informed Conditional Autoencoder Approach for Robust Metabolic CEST MRI at 7T,"the
test set consisted of the two tumor patients and one healthy subject.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Physics-Informed Conditional Autoencoder Approach for Robust Metabolic CEST MRI at 7T,"quantified maps of amide, rnoe and amine for another tumor patient is
shown in supplementary fig.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Diffusion-Based Data Augmentation for Nuclei Image Segmentation,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Deep Unsupervised Clustering for Conditional Identification of Subgroups Within a Digital Pathology Image Set,"due to model complexity and limited training data, ml
performance often varies across data subgroups or domains, such as different
patient subpopulations or varied data acquisition scenarios.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Deep Unsupervised Clustering for Conditional Identification of Subgroups Within a Digital Pathology Image Set,"deep unsupervised clustering
algorithms could map the medical imaging data back to their causal factors or
underlying domains, such as image acquisition equipment, patient subpopulations,
or other meaningful data subgroups.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
A Texture Neural Network to Predict the Abnormal Brachial Plexus from Routine Magnetic Resonance Imaging,"brachial plexus syndrome occurs not infrequently in patients with malignant
disease.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
A Texture Neural Network to Predict the Abnormal Brachial Plexus from Routine Magnetic Resonance Imaging,"following irb approval for this study, we search for patients with metastatic
breast cancer who had a breast cancer mri performed between 2010 and 2020 and
had morphologically positive bp on the mri report from our electronic medical
records (emr) in * hospital.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
A Texture Neural Network to Predict the Abnormal Brachial Plexus from Routine Magnetic Resonance Imaging,"only patients that
had all three sequences segmented (t2, t1 and post-gadolinium) were included in
the dataset.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
CircleFormer: Circular Nuclei Detection in Whole Slide Images with Circle Queries and Attention,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Self-supervised Dense Representation Learning for Live-Cell Microscopy with Time Arrow Prediction,"resnet [9]) that lack this symmetry, we here directly incorporate this
inductive bias via a permutation-equivariant head h that is a generalization of
the set permutation-equivariant layer proposed in [32] to dense inputs.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Prompt-MIL: Boosting Multi-instance Learning Schemes via Task-Specific Prompt Tuning,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Prompt-Based Grouping Transformer for Nucleus Detection and Classification,"we split them following the official partition [1,10].is a breast cancer
dataset with three types and consists of 120 image tiles from 113 patients.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Maximum-Entropy Estimation of Joint Relaxation-Diffusion Distribution Using Multi-TE Diffusion MRI,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Simulation of Arbitrary Level Contrast Dose in MRI Using an Iterative Global Transformer Model,"however,
gbcas have several disadvantages like contraindications in patients with reduced
renal function [2], patient inconvenience, high operation costs and
environmental side effects [3].",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Simulation of Arbitrary Level Contrast Dose in MRI Using an Iterative Global Transformer Model,"to this effect, we introduce a vision transformer based dl model1
that can synthesize brain 2 mri images that correspond to arbitrary dose levels,
by training on a highly imbalanced dataset with only t1w pre-contrast, t1w 10%
low-dose, and t1w ce standard dose images.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Simulation of Arbitrary Level Contrast Dose in MRI Using an Iterative Global Transformer Model,"iterative learning design: dl based models tend to perform poorly when the
training data is highly imbalanced [11].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Simulation of Arbitrary Level Contrast Dose in MRI Using an Iterative Global Transformer Model,"we
first utilize this design paradigm for the dose simulation task and train an
end-to-end model on a highly imbalanced dataset where only t1w pre-contrast, t1w
low-dose, and t1w post-contrast are available.as shown in fig.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Simulation of Arbitrary Level Contrast Dose in MRI Using an Iterative Global Transformer Model,"for downstream task assessment we
used 159 patient studies from another site (site b) using gadobenate
dimeglumine.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Simulation of Arbitrary Level Contrast Dose in MRI Using an Iterative Global Transformer Model,"for each patient, 3d t1w mprage scans were acquired for the
pre-contrast, low-dose, and post-contrast images.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
TractCloud: Registration-Free Tractography Parcellation with a Novel Local-Global Streamline Point Cloud Representation,"in the challenging btp (tumor patients) dataset, tractcloud reg-free
obtains significantly lower tda values than sota methods and comparable
performance to tractcloud regist .",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Relaxation-Diffusion Spectrum Imaging for Probing Tissue Microarchitecture,"our studies suggest that rdsi provides useful information on
microvascularity and necrosis helpful for facilitating early stratification of
patients with gliomas (fig.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Exploring Unsupervised Cell Recognition with Prior Self-activation Maps,"it combines the advantage of correlation filters
and deep learning but needs iterative training and finetuning.cnns with
inductive biases have priority over local features of the nuclei with dense
distribution and semi-regular shape.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Brain Anatomy-Guided MRI Analysis for Assessing Clinical Progression of Cognitive Impairment with Structural MRI,"the dm contains 1) 45 health control (hc)
subjects and 2) 37 diabetes mellitus patients with mild ci (mci).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Brain Anatomy-Guided MRI Analysis for Assessing Clinical Progression of Cognitive Impairment with Structural MRI,"all mris
are preprocessed via the following pipeline: 1) bias field correction, 2) skull
stripping, 3) affine registration to the mni space, 4) resampling to 1 × 1 × 1
mm 3 , 5) deformable registration to aal3 [19] with syn [20], and 6) warping 166
regions-of-interest (rois) of aal3 back to mri volumes.proposed method.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Brain Anatomy-Guided MRI Analysis for Assessing Clinical Progression of Cognitive Impairment with Structural MRI,"such
partition is repeated five times independently to avoid any bias introduced by
random partition, and the mean and standard deviation results are recorded.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Brain Anatomy-Guided MRI Analysis for Assessing Clinical Progression of Cognitive Impairment with Structural MRI,"second, among 10 deep models, our bar produces the lowest
standard deviation in most cases (especially on sen and spe), suggesting its
robustness to bias introduced by random data partition in the downstream task.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Brain Anatomy-Guided MRI Analysis for Assessing Clinical Progression of Cognitive Impairment with Structural MRI,"cnd classification is more
challenging, which could be due to the more imbalanced training data in this
task (as shown in table sii of supplementary materials).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Brain Anatomy-Guided MRI Analysis for Assessing Clinical Progression of Cognitive Impairment with Structural MRI,"there are a total of 42
subjects (i.e., 17 mci and 25 hc) used for training in this task, which are
fewer but more balanced than the two tasks in the lld study (see table sii).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Brain Anatomy-Guided MRI Analysis for Assessing Clinical Progression of Cognitive Impairment with Structural MRI,"these results imply that data
imbalance may be an important issue affecting the performance of deep learning
models when the number of training samples is limited.segmentation results.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning,"consequently, they are
unsuitable for tasks such as preoperative planning of neurosurgical patients, as
they may produce incomplete or false segmentations, which could have harmful
consequences during surgery [19].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning,"we focused on the left optic radiation (or), the left
cortico-spinal tract (cst), and the left arcuate-fasciculus (af), representing a
variety of established tracts.to test the proposed method on pathological data,
we used an in-house dataset containing ten presurgical scans of patients with
brain tumors.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
B-Cos Aligned Transformers Learn Human-Interpretable Features,"5: when bvt
is trained from scratch, the model faces a trade-off between learning the weight
and input alignment and finding the appropriate inductive bias to solve the
classification task.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
B-Cos Aligned Transformers Learn Human-Interpretable Features,"by reintroducing many of the inductive biases of cnns
through the window attention in the case of swin or transfer learning in the
case of bvt, the model likely overcomes this initial problem.moreover, we would
like to emphasize that the modified models have no negative impact on the
model's performance.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Single-subject Multi-contrast MRI Super-resolution via Implicit Neural Representations,"in clinical practice, magnetic resonance imaging (mri) provides important
information for diagnosing and monitoring patient conditions [4,16].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Single-subject Multi-contrast MRI Super-resolution via Implicit Neural Representations,"as multi-parametric
isotropic 3d scans are not always feasible to acquire due to time-constraints
[19], motion [9], and patient's condition [10], super-resolution offers a
convenient alternative to obtain the same from anisotropic 2d scans.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Single-subject Multi-contrast MRI Super-resolution via Implicit Neural Representations,"moreover, unlike
conventional super-resolution models trained on a cohort, a personalized model
is of clinical relevance to avoid the danger of potential misdiagnosis caused by
cohort-learned biases.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Single-subject Multi-contrast MRI Super-resolution via Implicit Neural Representations,"in this work, we mitigate these gaps by proposing a novel
multi-contrast super-resolution framework that only requires the
patient-specific low-resolution mr scans of different sequences (and views) as
supervision.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Single-subject Multi-contrast MRI Super-resolution via Implicit Neural Representations,"key reasons behind inr's success can be attributed to
overcoming the low-frequency bias of multi-layer perceptrons (mlp) [21,24,25].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Single-subject Multi-contrast MRI Super-resolution via Implicit Neural Representations,"in this section, we first formally introduce the problem of joint
super-resolution of multi-contrast mri from only one image per contrast per
patient.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Single-subject Multi-contrast MRI Super-resolution via Implicit Neural Representations,"in each dataset, we select 25 patients that
fulfill the isotropic acquisition criteria for both ground truth hr scans.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"patients with gbm generally have a very poor survival rate;
the median overall survival time is about 14 months [17]; and the overall
survival time is affected by many factors, including patient characteristics
(e.g., age and physical status), tissue histopathology (e.g., cellular density
and nuclear atypia), and molecular pathology (e.g., mutations and gene
expression levels) [1,14,15].",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"although these factors, particularly molecular
information, have usually proved to be strong predictors of survival in gbm,
there remain substantial challenges and unmet clinical needs to exploit easily
accessible, noninvasive neuroimaging data acquired preoperatively to predict
overall survival time of gbm patients, which can benefit treatment planning.to
do so, magnetic resonance imaging (mri) and its derived radiomics have been
widely used to study gbm preoperative prognosis over the last few decades.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"[2] first applied a forest of trees to assign an
importance value to each of the 1022 radiomic features extracted from t1 mri,
and then the 32 most important features were fed to the random forest regressor
for predicting overall survival time of a gbm patient.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"first, due to mass effect and physical infiltration of gbm in the
brain, fcs estimated directly from gbm patients' resting-state fmri might be
inaccurate, especially when the tumors are near or in the regions of interest.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"in order to circumvent these issues, in this paper we
introduce a novel neuroimaging feature family, namely functional lesion network
(fln) maps that are generated by our augmented lesion network mapping (a-lnm),
for overall survival time prediction of gbm patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"by
embedding the lesion into a normative functional connectome and computing
functional connectivity between the lesion and the rest of the brain using fmri
of all healthy subjects in the normative cohort, lnm has been successfully
employed to the identification of the brain network underlying particular
symptoms or behavioral deficits in stoke [4,13].the details of our workflow are
described as follows.1) we first manually segment the whole tumor (regarded as
lesion in this paper) on structural mri for all gbm patients, and the resulting
lesion masks are mapped onto a reference brain template, e.g., the mni152 2mm 3
template.2) the proposed a-lnm is next used to generate fln maps for each gbm
patient by using resting-state fmri from a large cohort of healthy subjects.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"specifically, for each patient, we correlate the mean bold time series of all
voxels within the lesion with the bold time series of every voxel in the whole
brain for all n subjects in the normative cohort, producing n functional
disconnection (fdc) maps of voxel-wise correlation values (transformed to
zscores).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"similar to data augmentation schemes, we can artificially
boost data volume (i.e., fln maps) up to m times through producing m fln maps
for each patient in the a-lnm, which helps to mitigate the risk of over-fitting
and improve the performance of overall survival time prediction when learning a
deep neural network from a small sized dataset.for this reason, we propose the
name ""augmented lnm (a-lnm)"", compared to the traditional lnm where only one fln
map is generated per patient by averaging all the n fdc maps.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"to evaluate the predictive
power of the fln maps generated by our a-lnm, we conduct extensive experiments
on 235 gbm patients in the training dataset of brats 2020 [18] to classify the
patients into three overall survival time groups viz.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"it publicly released preprocessed
restingstate fmri data of 1000 healthy right-handed subjects with an average age
21.5 ± 2.9 years and approximately equal numbers of males and females from the
brain genomics superstruct project (gsp) [5], where the concrete image
acquisition parameters and preprocessing procedures can be found as well.",,1,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"it provided an open-access pre-operative imaging training dataset to
segment brain tumors of glioblastoma (gbm, belonging to high grade glioma) and
low grade glioma (lgg) patients, as well as to predict overall survival time of
gbm patients [18].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"this training dataset contained 133 lgg and 236 gbm patients,
and each patient had four mri modalities, including t1, post-contrast
t1-weighted, t2-weighted, and t2 fluid attenuated inversion recovery.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"in this paper, we propose to investigate the feasibility of the novel
neuroimaging features, i.e., fln maps, for overall survival time prediction of
gbm patients in the training dataset of the brats 2020, in which one patient
alive was excluded, and the remaining 235 patients consisted of 89 short-term
survivors (less than 10 months), 59 mid-term survivors (between 10 and 15
months), and 87 long-term survivors (more than 15 months).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"as stated above,
the whole tumor is referred to as a lesion for each gbm patient.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"from the manual
expert segmentation labels of lesions in the 235 gbm patients of the brats 2020,
we co-register the lesion masks to the mni152 2mm 3 template by employing a
symmetric normalization algorithm in antspy [3].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"after lesion mapping, we introduce a modified lnm (called augmented lnm (a-lnm)
in this paper) to generate fln maps for each gbm patient by using resting-state
fmri of all 1000 gsp healthy subjects, as described below.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"i) for each patient,
the lesion is viewed as a seed region to calculate fdc in the healthy subjects
with restingstate fmri.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"ii) different from the commonly used lnm where
the resulting 1000 fdc maps are thresholded or averaged to obtain a single fln
map for each patient, the a-lnm generates many fln maps for each patient in a
manner that partitions all the 1000 fdc maps into disjoint subsets of equal size
and averages each subset to produce one fln map.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"3 of this paper, according to experimental
results, we divided the 1000 fdc maps into 100 subsets, and randomly chose 10
out of the resulting 100 fln maps for each patient as input to the downstream
prediction model.deep neural network for overall survival time prediction.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"the features are then combined using the average pooling
operation and fed to a fully-connected layer with kernel size (1, 1, 1) to
classify each gbm patient into one of the three overall survival time groups
(i.e., short-term survival, mid-term survival, and long-term survival).",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"we evaluated
the classification performance of our proposed method using 235 gbm patients in
the brats 2020 training dataset, because only these 235 patients had both
overall survival time and manual expert segmentation labels of lesions.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"in all
experiments, we conducted five-fold crossvalidation ten times in order to reduce
the effect of sampling bias.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"patients whose
frontal lobe is affected by tumors showed more executive dysfunction, apathy,
and disinhibition [11].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"on the dominant left hemisphere, the cams of long-term
survivors and mid-term survivors overlapped at the superior temporal gyrus and
wernicke's area which are involved in the sensation of sound and language
comprehension respectively, and have been associated with decreased survival in
patients with high-grade glioma [26].",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"in this paper, we introduce a novel neuroimaging feature family, called a-lnm
derived fln maps, for overall survival time prediction of gbm patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"a-lnm
was presented to generate plenty of fln maps for each gbm patient by
partitioning the fdc maps obtained from resting-state fmri of 1000 gsp healthy
subjects into disjoint subsets of equal size and averaging each subset.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"we
applied a 3d resnet-based backbone network to extract features from the
generated fln maps and classify gbm patients into three overall survival time
groups.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
A Multi-task Network for Anatomy Identification in Endoscopic Pituitary Surgery,"failure to appreciate these critical
parasellar neurovascular structures can lead to their injury, and adverse
outcomes for the patient [9,11].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
A Multi-task Network for Anatomy Identification in Endoscopic Pituitary Surgery,"an extension of logits
cross-entropy, logits focal loss, was used instead as it accounts for data
imbalance between classes.centroid detection: 5-models were trialed: 3-models
consisted of encoders with a convolution layer and linear activation; and
2-models consisted of encoderdecoders with an average pooling layer and sigmoid
activation with 0.3 dropout.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
A Multi-task Network for Anatomy Identification in Endoscopic Pituitary Surgery,"to account for structure data imbalance, images were randomly
split such that the number of structures in each fold is approximately even.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
A Multi-task Network for Anatomy Identification in Endoscopic Pituitary Surgery,"all
patients have provided informed consent, and the study was registered with the
local governance committee.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Intraoperative CT Augmentation for Needle-Based Liver Interventions,"ct-guidance is a widely used imaging modality for placing
the needles, monitoring the treatment, and following up patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Intraoperative CT Augmentation for Needle-Based Liver Interventions,"once the network has been trained on the patient-specific preoperative data, the
next step is to augment and visualize the intraoperative ncct.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Intraoperative CT Augmentation for Needle-Based Liver Interventions,"our future steps will essentially involve applying this method to
patient data and perform a small user study to evaluate the usefulness and
limitations of our approach.aknowledgments.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Optical Coherence Elastography Needle for Biomechanical Characterization of Deep Tissue,"furthermore, the prostate is
known to display large bulk displacement caused by patient movement and needle
insertions [20,24] in addition to actual sample compression (fig.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Pelvic Fracture Segmentation Using a Multi-scale Distance-Weighted Neural Network,"these data is collected from 100 patients (aged 18-74 years,
41 females) who were to undergo pelvic reduction surgery at beijing jishuitan
hospital between 2018 and 2022, under irb approval (202009-04).",,1,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Pelvic Fracture Segmentation Using a Multi-scale Distance-Weighted Neural Network,"the deep
supervision and smooth transition strategies stabilized the training, and
achieved the overall best results, with balanced local and global
performance.the average inference time for the fracture segmentation network was
12 s.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Towards Multi-modal Anatomical Landmark Detection for Ultrasound-Guided Brain Tumor Resection with Contrastive Learning,"early surgical
treatment to remove the maximum amount of cancerous tissues while preserving the
eloquent brain regions can improve the patient's survival rate and functional
outcomes of the procedure [2].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Towards Multi-modal Anatomical Landmark Detection for Ultrasound-Guided Brain Tumor Resection with Contrastive Learning,"table 1 lists the mean and standard deviation of landmark identification errors
(in mm) between the predicted position and the ground truth in intra-operative
us for each patient of the resect dataset.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Towards Multi-modal Anatomical Landmark Detection for Ultrasound-Guided Brain Tumor Resection with Contrastive Learning,"in the table, we also provide the
severity of brain shift for each patient.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Deep Reinforcement Learning Based System for Intraoperative Hyperspectral Video Autofocusing,"we
randomise the order of the focal powers to reduce systematic bias caused by the
response of the liquid lens.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Surgical Video Captioning with Mutual-Modal Concept Alignment,"we split these video
clips at patientlevel, where the video clips of 31 patients are used for
training and the rest of 10 patients are utilized for test.endovis image
captioning dataset.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Imitation Learning from Expert Video Data for Dissection Trajectory Prediction in Endoscopic Surgical Procedure,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Regularized Kelvinlet Functions to Model Linear Elasticity for Image-to-Physical Registration of the Breast,"image-to-physical registration is a necessary process for computer-assisted
surgery to align preoperative imaging to the intraoperative physical space of
the patient to in-form surgical decision making.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Regularized Kelvinlet Functions to Model Linear Elasticity for Image-to-Physical Registration of the Breast,"despite seed information and large resections, reoperation rates are
still high (~17%) emphasizing the need for additional guidance technologies such
as computer-assisted surgery systems with nonrigid registration
[7].intraoperative data available for registration is often sparse and subject
to data collection noise.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
Regularized Kelvinlet Functions to Model Linear Elasticity for Image-to-Physical Registration of the Breast,"the second validates the registration method in a breast
cancer patient and compares registration accuracy and computation time to
previously proposed methods.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Regularized Kelvinlet Functions to Model Linear Elasticity for Image-to-Physical Registration of the Breast,"sparse tracked ultrasound data collection patterns were projected on
the posterior surface for use as the third data feature.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
Regularized Kelvinlet Functions to Model Linear Elasticity for Image-to-Physical Registration of the Breast,"three
hyperparameter sweeps were used: this dataset consists of supine breast mr
images simulating surgical
deformations from one breast cancer patient.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Regularized Kelvinlet Functions to Model Linear Elasticity for Image-to-Physical Registration of the Breast,"a 71-year-old patient with invasive
mammary carcinoma in the left breast was enrolled in a study approved by the
institutional review board at vanderbilt university.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"we address the important problem of intraoperative patient-to-image registration
in a new way by relying on preoperative data to synthesize plausible
transformations and appearances that are expected to be found intraoperatively.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"indeed, the extent of tumor removal is highly
correlated with patients' chances of survival and complete resection must be
balanced against the risk of causing new neurological deficits [5] making
accurate intraoperative registration a critical component of
neuronavigation.most existing techniques perform patient-to-image registration
using intraoperative mri [11], cbct [19] or ultrasound [9,17,20].",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"we propose a novel approach for patient-to-image registration that registers the
intraoperative 2d view through the surgical microscope to preoperative mri 3d
images by learning expected appearances.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"this set is used to train
a patient-specific pose regressor network to obtain a model that is
texture-invariant and is cross-modality to bridge the mri and rgb camera
modalities.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"in addition, our
method is patient-specific, centered around m, since each model is trained
specifically for a given patient.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"patient's head during neurosurgery.we use the l-bfgs optimizer and 5
convolutional layers of vgg-19 to generate each image following [1] to find the
resulting parameters θ.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"the model is trained for each case (patient)
for 200 epochs using mini-batches of size 8 with adam optimizer and a learning
rate of 0.001 and decays exponentially to 0.0001 over the course of the
optimization.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"we tested our method retrospectively on 6 clinical datasets from 6
patients (cases) (see fig.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"we kept the size of the training set constant to not introduce size
biases.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"training
patient-specific models from preoperative imaging transfers computational tasks
to the preoperative stage so that patient-to-image registration can be performed
in near real-time from live images acquired from a surgical
microscope.limitations.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"we introduced expected appearances, a novel learning-based method for
intraoperative patient-to-image registration that uses synthesized expected
images of the operative field to register preoperative scans with intraoperative
views through the surgical microscope.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"radiotherapy (rt) has proven effective and efficient in treating cancer
patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"hence, this manual segmentation step is very time-consuming and
must be performed accurately and, more importantly, must be patient-safe.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"in the field of rt
planning for brain tumor patients, the recent study of [17] shows that current
dl-based segmentation algorithms for target structures carry a significant
chance of producing false positive outliers, which can have a considerable
negative effect on applied radiation dose, and ultimately, they may impact
treatment effectiveness.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"we present results on a clinical
dataset comprising fifty post-operative glioblastoma (gbm) patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"a segmentation model
(u-net [20]) is trained to output target segmentation predictions for the gross
tumor volume (gtv) based on patient mri sequences.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"a
pixel-wise mean squared error between both dose predictions is then a
segmentation model (u-net [20]) is trained to output target segmentation
predictions ( st ) for the gross tumor volume (gtv) based on patient mri
sequences imr.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"originally proposed for head and neck cancer [12], this approach has been
recently extended for brain tumor patients [9] with levels of prediction error
below 2.5 gy, which is less than 5% of the prescribed dose.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"we refer the reader to [9] for further details.segmentation models:
to develop and test the proposed approach, we employed a separate in-house
dataset (i.e., different cases than those used to train the dose predictor
model) of 50 cases from post-operative gmb patients receiving standard rt
treatment.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"4, the standard bce+softdice
model would yield a centrally located radiation dose, with strong negative
clinical impact to the patient.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"the ultimate goal of dl-based segmentation for rt planning is to provide
reliable and patient-safe segmentations for dosimetric planning and optimally
targeting tumor lesions and sparing of healthy tissues.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"these first results on a dataset of post-operative gbm
patients show the ability of the proposed doselo to deliver improved
dosimetric-compliant segmentation results.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"residual tumor in the cavity after head and neck cancer (hnc) surgery is a
significant concern as it increases the risk of cancer recurrence and can
negatively impact the patient's prognosis [1].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"one significant challenge in developing a flim-based
classifier to detect tumor in the surgical cavity is the presence of highly
imbalanced labels.surgeons aim to perform an en bloc resection, removing the
entire tumor and a margin of healthy tissue around it to ensure complete
excision.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"to address the technical challenge of highly imbalanced label distribution and
the need for intraoperative real-time cavity imaging, we developed an
intraoperative flim guidance model to identify residual tumors by classifying
residual cancer as anomalies.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"our proposed approach identified all patients with
psm.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"finally, the
patient's surgical cavity was scanned to check for residual tumor.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"the research was performed under the approval of the uc davis institutional
review board (irb) and with the patient's informed consent.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"all patients were
anesthetized, intubated, and prepared for surgery as part of the standard of
care.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"n = 22 patients are represented in this study, comprising hnc in the
palatine tonsil (n = 15) and the base of the tongue (n = 7).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"for each patient,
the operating surgeon conducted an en bloc surgical tumor resection procedure
(achieved by tors-electrocautery instruments), and the resulting excised
specimen was sent to a surgical pathology room for grossing.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"1).after the
surgical excision of the tumor, an in vivo flim scan of approximately 90 s was
conducted within the patient's surgical cavity, where the tumor was excised.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"ν denote a
penalty factor on these soft constraints, and b is the biases.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"the evaluation followed a leave-one-patient-out
cross-validation approach.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"three novelty detection models were evaluated, and all three models
could identify the presence of residual tumors in the cavity for the three
patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"the oc-svm and
robust covariance reported a high standard deviation, indicating that the
performance of the classification model is inconsistent across different
patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"moreover, the current approach
correctly identified all patients with psms (see fig.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"the flimbased
classification model could help guide the surgical team in real-time, providing
information on the location and extent of cancerous tissue.in context to the
standard of care, the proposed residual tumor detection model exhibits high
patient-level sensitivity (sensitivity = 1) in detecting patients with psms.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"in
contrast, defect-driven ifsa reports a patient-level sensitivity of 0.5 [6,7].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,our approach exhibits a low patient-level specificity compared to ifsa.,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"therefore, completely resecting
cancerous tissue and improving patient outcomes.the false positive predictions
from the classification model presented two trends: false positives in an
isolated region and false positives spreading across a larger region.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"the model will be validated on a larger patient cohort in future work and
address the limitations of the point-level false positive and negative
predictions.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
FocalErrorNet: Uncertainty-Aware Focal Modulation Network for Inter-modal Registration Error Estimation in Ultrasound-Guided Neurosurgery,"resection of early-stage brain tumors can greatly reduce the mortality rate of
patients.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
FocalErrorNet: Uncertainty-Aware Focal Modulation Network for Inter-modal Registration Error Estimation in Ultrasound-Guided Neurosurgery,"an example of
an mri-ius pair from a patient is shown in fig.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
FocalErrorNet: Uncertainty-Aware Focal Modulation Network for Inter-modal Registration Error Estimation in Ultrasound-Guided Neurosurgery,"for registration error regression in surgical applications, knowledge regarding
the reliability of the automated results is instrumental for the safety and
wellbeing of the patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
FocalErrorNet: Uncertainty-Aware Focal Modulation Network for Inter-modal Registration Error Estimation in Ultrasound-Guided Neurosurgery,"to prevent information leakage, we ensured that each patient was
included in only one of the split sets.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
FocalErrorNet: Uncertainty-Aware Focal Modulation Network for Inter-modal Registration Error Estimation in Ultrasound-Guided Neurosurgery,"one limitation of our work
lies in the limited patient data, as public ius datasets are scarce, while the
settings and properties of us scanners can vary, potentially affecting the dl
model designs.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"in practice, imprecise
intraoperative cancer tissue detection and visualization results in missed
cancer or the unnecessary removal of healthy tissues, which leads to increased
costs and potential harm to the patient.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"there is a pressing need for more
reliable and accurate intraoperative visualization tools for minimally invasive
surgery (mis) to improve surgical outcomes and enhance patient care.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"hence, stereo image data was also adopted in this paper.if the
problem of inferring the intersection point is treated as a geometric problem,
both data collection and intra-operative registration would be difficult, which
inspired us to approach this problem differently.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,data collection.,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
A Novel Video-CTU Registration Method with Structural Point Similarity for FURS Navigation,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Cascade Transformer Encoded Boundary-Aware Multibranch Fusion Networks for Real-Time and Accurate Colonoscopic Lesion Segmentation,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Unified Brain MR-Ultrasound Synthesis Using Multi-modal Hierarchical Representations,"we evaluated our method on a dataset of 66
consecutive adult patients with brain gliomas who were surgically treated at the
brigham and women's hospital, boston usa, where both pre-operative 3d t2-space
and pre-dural opening intraoperative us (ius) reconstructed from a tracked
handheld 2d probe were acquired.",,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"it has
received growing attention in medical imaging due to the various contexts where
it applies, like image fusion between 2d real-time acquisitions and either
pre-operative 3d images for guided interventions or reference planning volumes
for patient positioning in radiation therapy (rt).",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"we defined the number of iterations as a hyperparameter to reach a good
balance between computational time and similarity maximization.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"our clinical dataset consists of 108 patients for
whom were acquired both a pre-operative h&n ct scan and 4 to 11 wsis after
laryngectomy (with a total amount of 849 wsis).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"we split the dataset patient-wise into three
groups for training (64), validation (20), and testing (24).",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"we implemented our
model with pytorch1.13 framework and trained for 600 (800 for mr/ct) epochs with
a batch size of 8 (4 for mr/ct) patients parallelized over 4 nvidia gtx 1080
tis.evaluation.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"tomographic imaging estimates body density using hundreds of x-ray projections,
but it's slow and harmful to patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"acquisition time may be too high for
certain applications, and each projection adds dose to the patient.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"this can improve image-guided therapies and preoperative planning,
especially for radiotherapy, which requires precise patient positioning with
minimal radiation exposure.however, this task is an ill-posed inverse problem:
x-ray measurements are the result of attenuation integration across the body,
which makes them very fig.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"compared to nerf-based methods, our method exploits prior
knowledge from many patients to require only two projections.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"we evaluate our
method on reconstructing cancer patients' head-and-neck cts, which involves
intricate and complicated structures.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"in practice, we take operator a as a 3d cone beam
projection that simulates x-ray attenuation across the patient, adapted from
[21,27].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"we trained our model with a large dataset of 3500 cts of
patients with head-and-neck cancer, more exactly 2297 patients from the publicly
available the cancer imaging archive (tcia) [1,6,16,17,28,32] and 1203 from
private internal data, after obtention of ethical approbations.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"to
evaluate our approach, we used an external private cohort of 80 patients who had
undergone radiotherapy for head-and-neck cancer, with their consent.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"by grid search on the
validation set, we selected the best weights that well balance between structure
and fine-grained details, λ 2 = 10, λ p = 0.1, λ w = 0.1, λ c = 0.05, λ n = 10.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"our method
achieves better fitting of the patient structure, including bones, tissues, and
air separations, almost matching the real ct volume.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"in some clinical procedures, an
earlier ct volume of the patient may be available and can be used as an
additional input for nerp [23].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"this approach may provide coarse
reconstructions for patients with rare abnormalities, as most learning methods,
but a larger dataset or developing a prior including tissue abnormalities could
improve robustness.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Structure-Preserving Synthesis: MaskGAN for Unpaired MR-CT Translation,"unfortunately, ct imaging exposes patients
to ionizing radiation, which can damage dna and increase cancer risk [9],
especially in children and adolescents.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Structure-Preserving Synthesis: MaskGAN for Unpaired MR-CT Translation,data collection.,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
Structure-Preserving Synthesis: MaskGAN for Unpaired MR-CT Translation,"we collected 270 volumetric t1-weighted mri and 267 thinslice
ct head scans with bony reconstruction performed in pediatric patients under
routine scanning protocols1 .",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Structure-Preserving Synthesis: MaskGAN for Unpaired MR-CT Translation,"we targeted the age group from 6-24 months since
pediatric patients are more susceptible to ionizing radiation and experience a
greater cancer risk (up to 24% increase) from radiation exposure [7].",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Structure-Preserving Synthesis: MaskGAN for Unpaired MR-CT Translation,"furthermore, surgery for craniosynostosis, a birth defect in which the skull
bones fuse too early, typically occurs during this age [5,16].",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Structure-Preserving Synthesis: MaskGAN for Unpaired MR-CT Translation,"13 mri-ct
volumes from the same patients that were captured less than three months apart
are registered using rigid registration algorithms.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
FreeSeed: Frequency-Band-Aware and Self-guided Network for Sparse-View CT Reconstruction,"we conduct experiments on the dataset of ""the 2016 nih-aapm mayo clinic low dose
ct grand challenge"" [8], which contains 5,936 ct slices in 1 mm image thickness
from 10 anonymous patients, where a total of 5,410 slices from 9 patients,
resized to 256 × 256 resolution, are randomly selected for training and the 526
slices from the remaining one patient for testing without patient overlap.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Co-learning Semantic-Aware Unsupervised Segmentation for Pathological Image Registration,"furthermore, l sym denotes the registration loss of
symnet [14], which aims to balance the losses of orientation consistency,
regularization and magnitude.segnet.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Co-learning Semantic-Aware Unsupervised Segmentation for Pathological Image Registration,"to perform the longitudinal registration task, we registered each
pre-operative scan to the corresponding follow-up scan of the same patient and
measured the mean target registration error (tre) of the paired landmarks using
the resulting deformation field.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Fast Reconstruction for Deep Learning PET Head Motion Correction,"marker-based hmt such as polaris vicra (ndi, canada) use
light-reflecting markers on the patient's head and track the markers for motion
correction [6].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Fast Reconstruction for Deep Learning PET Head Motion Correction,"however, vicra is not routinely used in the clinic, as setup and
calibration of the tracking device can be complicated and attaching markers to
each patient increases the logistical burden of the scan.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Revealing Anatomical Structures in PET to Generate CT for Attenuation Correction,"the data used in our experiments are collected from the cancer image archive
(tcia) [4] (https://www.cancerimagingarchive.net/collections/), where a series
of public datasets with different types of lesions, patients, and scanners are
open-access.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Revealing Anatomical Structures in PET to Generate CT for Attenuation Correction,"such
inconsistent metrics suggest that the global intensity similarity may have a
competing relationship with anatomical consistency in the learning procedure,
thus it is not advisable to balance them in a single network.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
An Explainable Deep Framework: Towards Task-Specific Fusion for Multi-to-One MRI Synthesis,"to learn the weight automatically,
we use a trainable fully connected (fc) layer to predict the initial weight ω 0
∈ r n from c.where w and b are weights and bias for the fc layer, = 10 -5 to
avoid dividing 0 in the following equation.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Geometric Ultrasound Localization Microscopy,"also, the
jaccard index reflects an outperforming balance of true positive and false
negative mb detections by our approach.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Reflectance Mode Fluorescence Optical Tomography with Consumer-Grade Cameras,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"our neural network is
trained using patches from the ""gold atlas -male pelvis -gentle radiotherapy""
[14] dataset, which is comprised of 18 patients each with a ct, mr t1, and mr t2
volumes.",,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"the dataset comprises 8 sets of mr and ct volumes, both depicting the
abdominal region of a single patient and exhibiting notable deformations.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"as the most challenging experiment, we finally use our method to achieve
deformable registration of abdominal 3d freehand us to a ct or mr volume.we are
using a heterogeneous dataset of 27 cases, comprising liver cancer patients and
healthy volunteers, different ultrasound machines, as well as optical vs.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"when a patient is located in a ct equipment, a set of consecutive
cross-sectional images are generated.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"first, our proposed approaches are evaluated on the ""mayo-clinic
low-dose ct grand challenge"" (mayo-clinic) dataset of lung ct images [19].the
dataset contains 2250 two dimensional slices from 9 patients for training, and
the remaining 128 slices from 1 patient are reserved for testing.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"we randomly
select 4 patients with 1827 slices from the dataset.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"due to the bias in the datasets
collected from different facilities, the performances of all the models are
declined to some extents.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,radiotherapy (rt) is one of the cornerstones of cancer patients.,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"from the projections, it is possible to extract a respiratory signal [12], which
indicates the position of the organs within the patient during breathing.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"this was not the case for noise2aliasing, and
historical clinical data sufficed for training.we validated our method on
publicly available data [15] against a supervised approach [6] and applied it to
an internal clinical dataset of 30 lung cancer patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"the spare varian dataset was used to provide performance
results on publicly available patient data.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"to more closely resemble normal
respiratory motion per projection image, the 8 min scan has been used from each
patient (five such scans are available in the dataset).",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"training is performed
over 4 patients while 1 patient is used as a test set.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"an internal dataset (irb approved) of 30
lung cancer patients' 4dcbcts from 2020 to 2022, originally used for igrt, with
25 patients for training and 5 patients for testing.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"the metrics in table 1 show
mean and standard deviation across all phases for a single patient.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"noise2alisting trained
on 25 patients and tested on 5 achieved mean psnr of 35.24 and ssim of 0.91,
while the clinical method achieved mean psnr of 29.97 and 0.74 ssim with p-value
of 0.048 for the psnr and 0.0015 for the ssim, so noise2aliasing was
significantly better according to both metrics.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"overall, using more patients results in better noise reduction and
sharper reconstructions (see fig.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"with fewer patients, the model is
more conservative and tends to keep more noise, but also smudges the interface
between tissues and bones.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"with more patients, more of the view-aliasing is
addressed, and the reconstruction is sharper, however, a few small anatomical
structures tend to be suppressed by the model.especially between fat tissue and
skin and around the bones.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"however, the model also tends to remove small
anatomical structures as high-frequency objects that cannot be distinguished
from the noise.when applied to a clinical dataset, noise2aliasing benefits from
more patients being included in the dataset, however, qualitatively good
performance is already achieved with 5 patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"no additional data collection
was required and the method can be applied without major changes to the current
clinical practice.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"as future work, we plan to study noise2aliasing
in the presence of changes in the breathing frequency and amplitude between
patients and during a scan.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
DULDA: Dual-Domain Unsupervised Learned Descent Algorithm for PET Image Reconstruction,"forty 128 × 128 × 40 3d zubal brain phantoms [24] were used in the simulation
study as ground truth, and one clinical patient brain images with different dose
level were used for the robust analysis.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
DULDA: Dual-Domain Unsupervised Learned Descent Algorithm for PET Image Reconstruction,"a total of 5 realizations were
simulated and each was trained/tested independently for bias and variance
calculation [15].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DULDA: Dual-Domain Unsupervised Learned Descent Algorithm for PET Image Reconstruction,"the quantitative and bias-variance results
are shown in table 1.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DULDA: Dual-Domain Unsupervised Learned Descent Algorithm for PET Image Reconstruction,"both dip method and dulda
have a better crc and bias performance compared with mlem and em-tv.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
DULDA: Dual-Domain Unsupervised Learned Descent Algorithm for PET Image Reconstruction,"to test the robustness of proposed dulda, we forward-project one patient brain
image data with different dose level and reconstructed it with the trained dulda
model.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
DULDA: Dual-Domain Unsupervised Learned Descent Algorithm for PET Image Reconstruction,"the patient is
scanned with a ge discovery mi 5-ring pet/ct system.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Low-Dose CT Image Super-Resolution Network with Dual-Guidance Feature Distillation and Dual-Path Content Communication,"to balance the
high image quality and low radiation damage compared to normaldose ct (ndct),
numerous algorithms have been proposed for ldct superresolution [3,4].in the
past decades, image post-processing techniques attracted much attention from
researchers because they did not rely on the vendor-specific parameters [2] like
iterative reconstruction algorithms [1,23] and could be easily applied to
current ct workflows [29].",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Low-Dose CT Image Super-Resolution Network with Dual-Guidance Feature Distillation and Dual-Path Content Communication,avg ct is the average image among adjacent ct slices of each patient.,,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Low-Dose CT Image Super-Resolution Network with Dual-Guidance Feature Distillation and Dual-Path Content Communication,"we first calculate
the average ct image of adjacent ct slices of each patient to provide the 3d
spatial structure information of ct volume.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Non-iterative Coarse-to-Fine Transformer Networks for Joint Affine and Deformable Image Registration,"these nice registration methods show advantages in both registration accuracy
and runtime on the benchmark task of intra-patient brain mri registration.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Non-iterative Coarse-to-Fine Transformer Networks for Joint Affine and Deformable Image Registration,"we evaluated the proposed nice-trans on the task of inter-patient brain mri
registration, which is a common benchmark task in medical image registration
studies [7][8][9][12][13][14][15][16][17][18].",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Non-iterative Coarse-to-Fine Transformer Networks for Joint Affine and Deformable Image Registration,"first, the experiment (table 1)
demonstrated that our nice-trans can well address the inherent misalignments
among inter-patient brain mri images, but the sensitivity of affine registration
to different degrees of misalignments is still awaiting further exploration.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Non-iterative Coarse-to-Fine Transformer Networks for Joint Affine and Deformable Image Registration,"second, in this study, we evaluated the nice-trans on the benchmark task of
inter-patient brain mri registration, while we believe that our nice-trans also
could apply to other image registration applications (e.g., brain tumor
registration [37]).",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Trackerless Volume Reconstruction from Intraoperative Ultrasound Images,"this information is then used to register the 3d ultrasound image with
the patient's anatomy.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Trackerless Volume Reconstruction from Intraoperative Ultrasound Images,"frames were cropped to remove the patient and probe
characteristics, then down-sampled to a size of 128 × 128 with an image spacing
of 0.22 mm per pixel.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
Trackerless Volume Reconstruction from Intraoperative Ultrasound Images,"first and end stages of the sequences were removed from
the six acquired sequences, as they were considered to be largely stationary,
and aiming to avoid training bias.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,"magnetic resonance imaging (mri) is critical to the diagnosis, treatment, and
follow-up of brain tumour patients [26].",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,"multiple mri modalities offer
complementary information for characterizing brain tumours and enhancing patient
l.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,"[19] leveraged adversarial training to increase the step size of the inverse
diffusion process and further designed a cycle-consistent architecture for
unpaired mri translation.however, current dm-based methods focus on one-to-one
mri translation, promising to be improved by many-to-one methods, which requires
dedicated design to balance the multiple conditions introduced by multi-modal
mri.",,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,"-propose an auto-weight
adaptation to balance multi-conditions and maximise the chance of leveraging
relevant multi-modal information.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,"it is critical to balance multiple conditions, maximizing relevant information
and minimising redundant information.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,"the autoactivation is
governed by the learnable weight ν and bias o.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,"the brats 2018 contains mri scans from
285 glioma patients.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,"therefore, cola-diff could serve as a useful tool for generating mri to reduce
the burden of mri scanning and benefit patients and healthcare providers.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0
InverseSR: 3D Brain MRI Super-Resolution Using a Latent Diffusion Model,"this network ε θ is conditioned on four conditional variables c: age,
gender, ventricular volume and brain volume, which are all introduced by
cross-attention layers [22].",,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
InverseSR: 3D Brain MRI Super-Resolution Using a Latent Diffusion Model,"gender is a binary variable, while the rest of the
covariates are scaled to [0, 1].",,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Topology-Preserving Computed Tomography Super-Resolution Based on Dual-Stream Diffusion Model,"λ τ is the
self-regulating factor.when λ 1 is about the same with λ 2 , λ τ is closed to λ
1 ; and when λ 1 is much smaller to λ 2 , λ τ is closed to λ 2 , which can
achieve a balance between two conditions.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Topology-Preserving Computed Tomography Super-Resolution Based on Dual-Stream Diffusion Model,"here we used a parameter λ l1 to balance
these two losses.in the meantime, a structure-constraint loss is also necessary
to help the network achieve better performance in structure consistency.",,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
LightNeuS: Neural Surface Reconstruction in Endoscopy Using Illumination Decline,none,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
