<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Modeling Alzheimers’ Disease Progression from Multi-task and Self-supervised Learning Perspective with Brain Networks</title>
				<funder ref="#_PmpYMU6">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_2XYCYCC">
					<orgName type="full">Science Project of Liaoning Province</orgName>
				</funder>
				<funder ref="#_ancd5EX">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Wei</forename><surname>Liang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Engineering</orgName>
								<orgName type="institution">Northeastern University</orgName>
								<address>
									<settlement>Shenyang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Intelligent Computing in Medical Image of Ministry of Education</orgName>
								<orgName type="institution">Northeastern University</orgName>
								<address>
									<settlement>Shenyang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kai</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Engineering</orgName>
								<orgName type="institution">Northeastern University</orgName>
								<address>
									<settlement>Shenyang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Intelligent Computing in Medical Image of Ministry of Education</orgName>
								<orgName type="institution">Northeastern University</orgName>
								<address>
									<settlement>Shenyang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Peng</forename><surname>Cao</surname></persName>
							<email>caopeng@mail.neu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Engineering</orgName>
								<orgName type="institution">Northeastern University</orgName>
								<address>
									<settlement>Shenyang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Intelligent Computing in Medical Image of Ministry of Education</orgName>
								<orgName type="institution">Northeastern University</orgName>
								<address>
									<settlement>Shenyang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">National Frontiers Science Center for Industrial Intelligence and Systems Optimization</orgName>
								<address>
									<postCode>110819</postCode>
									<settlement>Shenyang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pengfei</forename><surname>Zhao</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">The Affiliated Brain Hospital of Nanjing Medical University</orgName>
								<address>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaoli</forename><surname>Liu</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution" key="instit1">DAMO Academy</orgName>
								<orgName type="institution" key="instit2">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jinzhu</forename><surname>Yang</surname></persName>
							<email>yangjinzhu@cse.neu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Engineering</orgName>
								<orgName type="institution">Northeastern University</orgName>
								<address>
									<settlement>Shenyang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Key Laboratory of Intelligent Computing in Medical Image of Ministry of Education</orgName>
								<orgName type="institution">Northeastern University</orgName>
								<address>
									<settlement>Shenyang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">National Frontiers Science Center for Industrial Intelligence and Systems Optimization</orgName>
								<address>
									<postCode>110819</postCode>
									<settlement>Shenyang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Osmar</forename><forename type="middle">R</forename><surname>Zaiane</surname></persName>
							<affiliation key="aff5">
								<orgName type="department">Alberta Machine Intelligence Institute</orgName>
								<orgName type="institution">University of Alberta</orgName>
								<address>
									<settlement>Edmonton</settlement>
									<region>AB</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Modeling Alzheimers’ Disease Progression from Multi-task and Self-supervised Learning Perspective with Brain Networks</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="310" to="319"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">DE6D53ED16CD44FBAD306E989247D418</idno>
					<idno type="DOI">10.1007/978-3-031-43907-0_30</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-23T22:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Self-supervised learning</term>
					<term>Multi-task learning</term>
					<term>Cognitive scores</term>
					<term>Brain networks</term>
					<term>Longitudinal prediction</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Alzheimer's disease (AD) is a common irreversible neurodegenerative disease among elderlies. Establishing relationships between brain networks and cognitive scores plays a vital role in identifying the progression of AD. However, most of the previous works focus on a single time point, without modeling the disease progression with longitudinal brain networks data. Besides, the longitudinal data is insufficient for sufficiently modeling the predictive models. To address these issues, we propose a S S Self-supervised M M Multi-Task learning P P Progression model SMP-Net for modeling the relationship between longitudinal brain networks and cognitive scores. Specifically, the proposed model is trained in a selfsupervised way by designing a masked graph auto-encoder and a temporal contrastive learning that simultaneously learn the structural and evolutional features from the longitudinal brain networks. Furthermore, we propose a temporal multi-task learning paradigm to model the relationship among multiple cognitive scores prediction tasks. Experiments on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset show the effectiveness of our method and achieve consistent improvements over state-of-the-art methods in terms of Mean Absolute Error (MAE), Pearson Correlation Coefficient (PCC) and Concordance Correlation Coefficient (CCC). Our code is available at https://github.com/IntelliDAL/ Graph/tree/main/SMP-Net.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Alzheimer's disease (AD) is a progressive neurodegenerative disease, which affects the quality of life as it causes memory loss, difficulty in thinking and learning <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b22">23]</ref>. Establishing relationships between brain networks and cognitive scores plays a vital role in identifying the early stage of AD <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b16">17]</ref>. Though there has been substantial progress in AD diagnostics with brain networks <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b13">14]</ref>, most of the current studies focus on a single time point, without exploring longitudinal modeling for disease progression with brain networks. Some learning-based methods are proposed for the longitudinal prediction of AD progression with multi-modal data but generally fail in utilizing brain networks due to the large heterogeneity of brain networks between individuals as well as developmental stages <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b19">20]</ref>.</p><p>The cognitive scores prediction with longitudinal brain networks via deep learning models faces many challenges as follows: (i) The available longitudinal brain networks are scarce due to few volunteers or subject dropout <ref type="bibr" target="#b9">[10]</ref>. Predicting cognitive scores with limited data is extremely challenging for the deep learning model training. (ii) Longitudinal brain networks provide rich structure information and disease progression characteristics, accounting for poor generalization for the pure supervised learning due to the insufficient supervision. <ref type="bibr">(iii)</ref> The relationship between the brain networks and cognitive scores at multiple time points is varied, hindering the accurate prediction performance at multiple time points with a single task model.</p><p>To cope with the above challenges, we propose a self-supervised multi-task learning paradigm for AD progression modeling with longitudinal brain networks. The proposed paradigm consists of a self-supervised spatio-temporal representation learning module for exploiting the spatio-temporal characteristics of longitudinal brain networks and a temporal multi-task module for modeling the relationship among cognitive scores prediction tasks at multiple time points. In summary, our contributions are threefold: 1) To the best of our knowledge, our work is the first attempt to predict cognitive scores with longitudinal brain networks through a self-supervised multi-task paradigm. 2) We design a self-supervised spatio-temporal representation learning module (SSTR), involving masked graph auto-encoder and temporal contrastive learning are jointly pre-trained to capture the structural and evolutional features of longitudinal brain networks simultaneously. The SSTR module can lead to more robust high-level representations for longitudinal brain networks. 3) We assume that inherent correlations exist among the prediction tasks at multiple future time points. Consequently, we propose a temporal multi-task learning paradigm to assist multiple time points cognitive scores prediction, which enhances the model generalization by exploiting the commonalities and differences among different prediction tasks when limited data is available. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem Formalization</head><p>The input to the proposed model is a set of N subjects, each of which has T longitudinal brain networks. Let </p><formula xml:id="formula_0">X i = [G 1 i , ..., G t i , ..., G T i ] ∈ R T * M</formula><formula xml:id="formula_1">Y i = [Y T +1 i , ..., Y T +k i ] for subject i, where Y T +k i = [Y T +k,1 i , ..., Y T +k,p i</formula><p>] and Y T +k,p i is the p-th cognitive score of subject i at time T + k. As illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>, our aim is to build a model f to predict cognitive scores at time [T + 1, ..., T + k] with brain networks at time [1, ..., T ], which is formulated as:</p><formula xml:id="formula_2">{Y T +1 , Y T +2 , ..., Y T +k } = f (G 1 , G 2 , ..., G T ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Overview</head><p>The overview of the proposed SMP-Net is shown in Fig. <ref type="figure" target="#fig_1">2</ref>. As shown in Fig. <ref type="figure" target="#fig_1">2</ref>, the proposed SMP-Net consists of two modules: Self-supervised spatio-temporal representation learning module (SSTR) for exploiting the spatio-temporal characteristics of longitudinal brain network data itself and a temporal multi-task learning module for modeling the relationship among cognitive scores prediction tasks at multiple time points. SSTR involves a masked graph auto-encoder and a temporal contrastive learning, both of which are jointly pre-trained to learn the structural and evolutional brain networks representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Self-supervised Spatio-Temporal Representation Learning</head><p>Although brain networks provide rich structure information, the pure supervised learning scheme limits the representation capacity of the models due to insufficient supervision. To solve this problem, we introduce the self-supervised spatio-temporal representation learning module, SSTR. The procedure of SSTR involves two stages as follow: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stage 1 Masked Graph Auto-encoder for Graph Reconstruction.</head><p>In stage 1, a masked graph auto-encoder, containing a topology-aware encoder and a decoder, is designed to exploit the crucial structural information in brain networks. To sufficiently exploit the graph structure, we randomly mask some nodes and the associated edges. The unmasked nodes and edges fed into the topologyaware encode to learn the latent representations. Let H u indicate the feature map in the encoding stage. We define the adjacent matrix of the unmasked nodes as A u , which is taken as the input of the topology-aware encoder, that is</p><formula xml:id="formula_3">H (0) u = A u .</formula><p>The topology-aware encoder consists of three parts: 1) The edge convolution with multiple cross-shaped filters for capturing the locality in the graph according to</p><formula xml:id="formula_4">H (l) u = EC(H (l-1) u ) = M i=0 M j=0 H u (l-1) (i,•) w r + H u (l-1) (•,j) w c ,</formula><p>where w r ∈ R 1×M and w c ∈ R M ×1 are convolution kernels. 2) The node convolution for learning the latent node embedding. It is defined as:</p><formula xml:id="formula_5">H (l) n = NC(H (l-1) u ) = M i=1 H u (l-1) (i,•) w l-1</formula><p>n , where w n is the learned filter vector,</p><formula xml:id="formula_6">H (l)</formula><p>n ∈ R M ×Dn is the latent unmasked node embedding and D n is the channels in NC.</p><p>3) The graph aggregation for achieving the global graph embedding through:</p><formula xml:id="formula_7">H (l) g = GA(H (l-1) n ) = M i=1 H n (l-1) (i,•) w g ,</formula><p>where w g is the learned filter vector, H g ∈ R M ×Dg is the graph embedding and D g is the dimensionality in GA.</p><p>The decoder takes the masked nodes and the latent unmasked node embeddings as inputs, and then produces predictions for the masked nodes and edges by graph convolution operations and the masked edge prediction. The graph convolution is defined as: (l) , where A ∈ R M ×M is the binary adjacency matrix, W denotes trainable weight, H ∈ R M ×D n is the node embedding and D n is the hidden layer size of graph convolutional layers. The masked edge prediction is defined as: Â = H (l+1) (H (l+1) )</p><formula xml:id="formula_8">H (l+1) = σ( AH (l) n W (l) ) + b</formula><p>T . The reconstruction loss between the prediction graphs and corresponding targets is</p><formula xml:id="formula_9">L rec = N i=1 T t=1 ||A t i -Ât i || 2 2</formula><p>, where Ât i is the reconstructed brain networks of subject i at time t.</p><p>Stage 2 Temporal Contrastive Learning. The longitudinal brain networks of a subject acquired at multiple visits characterize gradual disease progression of the brain over time, which manifests a temporal progression trajectory when projected to the latent space. We assume that brain networks features at two consecutive time points from the same subject are similar, while dissimilar from different subjects. Based on this assumption, we introduce a temporal contrastive loss by enforcing an across-sample relationship in the learning process. Specifically, H t g(i) is the brain network features of subject i at time t, H t g(i) and H t+1 g(j)</p><p>are considered as the positive sample pair if i = j, otherwise they are considered as the negative sample pair. The temporal contrastive framework aims to enlarge the similarity between positive sample pair, and reduce it between the negative sample pair. The similarity calculation function s can be any distance function, and here we utilize cosine similarity. The loss for temporal contrastive learning can be represented as:</p><formula xml:id="formula_10">L con = -log N i=1 T -1 t=1 exp(s(H t g(i) , H t+1 g(i) )/τ ) N j=1,j =i exp(s(H t g(i) , H t+1 g(j) )/τ ) , (<label>1</label></formula><formula xml:id="formula_11">)</formula><p>where τ is a temperature factor that controls the model's discrimination against negative sample pair and exp(.) is an exponential function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Temporal Multi-task Learning</head><p>Existing studies have demonstrated the effectiveness of multi-task learning for the extraction of a robust feature representation <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b23">24]</ref>. In this regard, to further exploit the correlation among the prediction tasks at multiple future time points, we design a temporal multi-task learning paradigm. Specifically, the temporal multi-task learning module consists of a shared network and multiple taskspecific networks, all of which are designed with a Long Short-Term Memory (LSTM) architecture <ref type="bibr" target="#b3">[4]</ref>. The shared network is trained for modeling the shared information h t s among cognitive scores prediction tasks at multiple time points. The q-th task-specific network aims to capture the task-specific information h t q from the shared network and the brain networks features at time t. The temporal multi-task learning module can be seen as an end-to-end architecture with the shared and task-specific parameters of W s , W q . By learning these parameters jointly, we arrive at a collaborative learning method to jointly improve the performance of the prediction tasks at multiple time points. The shared information h t s and task-specific information h t q are formulated as h t s = LST M (Hg t , h t-1 s , W s ) and h t q = LST M ([Hg t , h t s ], h t-1 q , W q ). The output of the temporal multi-task learning module is formulated as:</p><formula xml:id="formula_12">Ŷ t = W 2 (W 1 h t q + b 1 ) + b 2 ,</formula><p>where W 1 , W 2 , b 1 , b 2 are learnable parameters of LSTM. Errors between the actual observations Y t and predictions Ŷ t are used to update the model parameters through the regression loss as follow:</p><formula xml:id="formula_13">L reg = k i=1 T t=2 (||Y t -Ŷ t || 1 + ||Y T +i -Ŷ T +i || 1 )<label>(2)</label></formula><p>The overall loss function L is described as Eq. ( <ref type="formula">3</ref>), where λ con and λ rec are the weights for contrastive loss and reconstruction loss, respectively.</p><formula xml:id="formula_14">L = L reg + λ con L con + λ rec L rec (3)</formula><p>3 Experiments</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset and Experimental Settings</head><p>In this work, we choose 219 longitudinal resting-state fMRI scans of 73 subjects from the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset <ref type="bibr" target="#b10">[11]</ref> <ref type="foot" target="#foot_0">1</ref> . AAL template is used to obtain 90 ROIs for every subject <ref type="bibr" target="#b17">[18]</ref>. We predict nine cognitive scores at time M24, M36 and M48 with brain networks times of M0, M6 and M12 to evaluate our proposed SMP-Net. The number of samples for the three tasks are 73, 35 and 31, respectively. During the model training, the Adam optimizer is used with a momentum of 0.9 and a weight decay of 0.01. The learning rate is set to 10 -3 . The hidden layer size of LSTM and graph convolutional layers are set to 64 and 48, respectively. The values of hyperparameter λ c and λ r are set to 1. The model is trained with 20 epochs in the self-supervised spatio-temporal representation learning stage and 300 epochs in the temporal multi-task learning stage with a batch size of 16. To avoid over-fitting due to the limited subjects, in all experiments, we repeat the 5-fold cross-validation 10 times with different random seeds. We finally report the average results. Three commonly used metrics are adopted to evaluate all methods, including Mean Absolute Error (MAE), Pearson Correlation Coefficient (PCC) and Concordance Correlation Coefficient (CCC). CCC reflects both the correlation and the absolute error between the true and the predicted cognitive scores. Due to limited space, we report the results in terms of CCC in this paper. The results in terms of MAE and CC are shown in the supplementary material. To ensure a fair comparison, the hyperparameters of comparable methods are optimized to achieve their best performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Effectiveness Evaluation</head><p>We compare the performance of our SMP-Net with three state-of-the-art (SOTA) sequential graph learning methods: evolveGCN <ref type="bibr" target="#b12">[13]</ref>, stGCN <ref type="bibr" target="#b21">[22]</ref> and DySAT <ref type="bibr" target="#b15">[16]</ref> as well as a baseline method: GCN <ref type="bibr" target="#b6">[7]</ref>. Table <ref type="table" target="#tab_1">1</ref> summarizes the results of all 3) The temporal multi-task paradigm of SMP-Net effectively exploits the inherent correlation among multiple prediction tasks at different time points, which facilitate to improve the model performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Discussion</head><p>Ablation Analysis. To valid the effect of each proposed module, we consider the following variants for evaluation: 1) SMP-Net-c: the temporal contrastive loss is removed; 2) SMP-Net-r: the reconstruction loss is removed; 3) SMP-Netrc: both temporal contrastive loss and graph reconstruction loss are removed; 4) SMP-Net-m: the temporal multi-task paradigm is ignored.  indicating the effectiveness of the temporal multi-task paradigm. It also indicates that the multi-task paradigm in SMP-Net is more helpful for the prediction at farther time points. The reason is that prediction tasks at farther time points are more difficult due to the insignificant relationship between the brain networks and the cognitive scores. Temporal multi-task paradigm enforces the long-term prediction to benefit from short-term prediction, making the prediction tasks at farther time points gain more improvements. Moreover, we can observe that models with SSTR perform better than the ones without SSTR. For instance, SMP-Net-m and SMP-Net show superior performance than SMP-Net-r, SMP-Net-c and SMP-Net-rc. This demonstrates that SSTR facilitates the learning of structural and evolutional features in the condition of limited samples and insufficient supervision, thereby leading to more robust high-level representations for downstream tasks.</p><p>Evaluating Robustness. To evaluate the robustness of the SSTR module, we pre-train SMP-Net with fMRI at three time points (M0, M6, M12) and fine-tune it with different downstream tasks of predicting cognitive scores at different time points. As shown in Fig. <ref type="figure" target="#fig_2">3</ref>, MSP-Net provides comparatively stable performance on different fine-tuning tasks, demonstrating that features learned with our pretrained model are robust to the different fine-tuning tasks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>This paper proposes an AD progression model SMP-Net from multi-task and self-supervised learning perspective with longitudinal brain networks. In the proposed SMP-Net, self-supervised spatio-temporal representation learning is designed to learn more robust structural and evolutional features from longitudinal brain networks. The temporal multi-task paradigm is designed for boosting the ability of cognitive score prediction at multiple time points. Experimental results on the ADNI dataset with fewer samples demonstrate the advantage of self-supervised spatio-temporal representation learning and temporal multi-task learning.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Illustration of our task. The inputs of the model are T history brain networks, and the outputs are the predicted cognitive scores at the multiple future time points (T + 1, T + 2, ..., T + k).</figDesc><graphic coords="3,59,10,63,62,159,76,53,68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Illustration of the proposed SMP-Net framework.</figDesc><graphic coords="4,64,98,54,29,322,36,195,40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Average MAE and CC of the pre-trained model fine-tuning on three different downstream tasks. AVL M0 M6 denotes that fMRI data at M0 and M6 are available.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Experimental results in terms of CCC. The best results are bold and the superscript symbol * indicates that the proposed method significantly outperformed that method with p-value = 0.01. methods in terms of CCC on the ADNI dataset. As reported in the supplementary material, consistent conclusions are obtained by SMP-Net in terms of MAE and CC. Based on the experimental results, we have the following observations: First, evolveGCN, stGCN and DySAT consistently outperform GCN, indicating that evolveGCN, stGCN and DySAT are able to capture the dynamism underlying a brain networks sequence through a recurrent model, which contributes to improve performance in disease prediction. Second, DySAT shows a higher average CCC than evolveGCN and stGCN. One possible reason is that DySAT utilizes joint structural and temporal self-attention, which enables it to learn more efficient dynamic graph representation compared with evolveGCN and stGCN. Finally, our proposed SMP-Net maintains a stable and competitive performance at all the time points, demonstrating that 1) SMP-Net can learn more expressive representations of brain networks structure by masked graph auto-encoder for graph reconstruction module. 2) SMP-Net sufficiently takes advantage of the temporal and subject correlation in disease progression by temporal contrastive learning.</figDesc><table><row><cell cols="9">Cognitive scores CDRSB ADAS11 MMSE RAVLT imm learn ADAS13 RAVLT forget RAVLT perc forget MOCA Average</cell></row><row><cell>M24 GCN</cell><cell>0.190  *</cell><cell>0.286  *</cell><cell>0.139  *  0.346  *</cell><cell>0.280  *  0.319  *</cell><cell>0.320  *</cell><cell>0.311  *</cell><cell cols="2">0.201  *  0.266 (0.045)  *</cell></row><row><cell>evolveGCN</cell><cell>0.351  *</cell><cell>0.415  *</cell><cell>0.141  *  0.487  *</cell><cell>0.399  *  0.427  *</cell><cell>0.283  *</cell><cell>0.433  *</cell><cell cols="2">0.272  *  0.356 (0.078)  *</cell></row><row><cell>stGCN</cell><cell>0.310  *</cell><cell>0.391  *</cell><cell>0.265  *  0.458  *</cell><cell>0.323  *  0.415  *</cell><cell>0.279  *</cell><cell>0.405  *</cell><cell cols="2">0.373  *  0.358 (0.078)  *</cell></row><row><cell>DySAT</cell><cell>0.574  *</cell><cell>0.416  *</cell><cell>0.438  *  0.342  *</cell><cell>0.588 0.588 0.588 0.353  *</cell><cell>0.597  *</cell><cell>0.230  *</cell><cell cols="2">0.531  *  0.452 (0.051)  *</cell></row><row><cell>SMP-Net</cell><cell>0.617 0.617 0.617</cell><cell>0.798 0.798 0.798</cell><cell>0.658 0.658 0.658 0.798 0.798 0.798</cell><cell>0.525 0.809 0.809 0.809</cell><cell>0.654 0.654 0.654</cell><cell>0.819 0.819 0.819</cell><cell>0.666 0.666 0.666</cell><cell>0.705 (0.038) 0.705 (0.038) 0.705 (0.038)</cell></row><row><cell>M36 GCN</cell><cell>0.152  *</cell><cell>0.229  *</cell><cell>0.122  *  0.314  *</cell><cell>0.055  *  0.254  *</cell><cell>0.099  *</cell><cell>0.214  *</cell><cell cols="2">0.213  *  0.184 (0.076)  *</cell></row><row><cell>evolveGCN</cell><cell>0.350  *</cell><cell>0.450  *</cell><cell>0.114  *  0.563  *</cell><cell>0.508  *  0.450  *</cell><cell>0.341  *</cell><cell>0.431  *</cell><cell cols="2">0.219  *  0.381 (0.124)  *</cell></row><row><cell>stGCN</cell><cell>0.246  *</cell><cell>0.410  *</cell><cell>0.323  *  0.439  *</cell><cell>0.333  *  0.430  *</cell><cell>0.226  *</cell><cell>0.491  *</cell><cell cols="2">0.341  *  0.360 (0.131)  *</cell></row><row><cell>DySAT</cell><cell>0.556 0.556 0.556</cell><cell>0.355  *</cell><cell>0.561  *  0.543  *</cell><cell>0.577 0.577 0.577 0.281  *</cell><cell>0.629 0.629 0.629</cell><cell>0.140  *</cell><cell cols="2">0.569  *  0.468 (0.048)  *</cell></row><row><cell>SMP-Net</cell><cell>0.490</cell><cell>0.754 0.754 0.754</cell><cell>0.593 0.593 0.593 0.801 0.801 0.801</cell><cell>0.496 0.788 0.788 0.788</cell><cell>0.571</cell><cell>0.832 0.832 0.832</cell><cell>0.663 0.663 0.663</cell><cell>0.665 (0.060) 0.665 (0.060) 0.665 (0.060)</cell></row><row><cell>M48 GCN</cell><cell>0.144  *</cell><cell>0.313  *</cell><cell>0.159  *  0.431  *</cell><cell>0.141  *  0.316  *</cell><cell>0.168  *</cell><cell>0.324  *</cell><cell cols="2">0.097  *  0.233 (0.091)  *</cell></row><row><cell>evolveGCN</cell><cell>0.471  *</cell><cell>0.342  *</cell><cell>0.103  *  0.484  *</cell><cell>0.397  *  0.368  *</cell><cell>0.512  *</cell><cell>0.542  *</cell><cell cols="2">0.108  *  0.370 (0.084)  *</cell></row><row><cell>stGCN</cell><cell>0.276  *</cell><cell>0.300  *</cell><cell>0.296  *  0.424  *</cell><cell>0.392  *  0.321  *</cell><cell>0.450  *</cell><cell>0.557  *</cell><cell cols="2">0.299  *  0.368 (0.096)  *</cell></row><row><cell>DySAT</cell><cell>0.609 0.609 0.609</cell><cell>0.347  *</cell><cell>0.416  *  0.378  *</cell><cell>0.640  *  0.268  *</cell><cell>0.675  *</cell><cell>0.146  *</cell><cell cols="2">0.441  *  0.436 (0.085)  *</cell></row><row><cell>SMP-Net</cell><cell>0.561</cell><cell>0.694 0.694 0.694</cell><cell>0.554 0.554 0.554 0.798 0.798 0.798</cell><cell>0.518 0.518 0.518 0.752 0.752 0.752</cell><cell>0.749 0.749 0.749</cell><cell>0.869 0.869 0.869</cell><cell>0.570 0.570 0.570</cell><cell>0.674 (0.083) 0.674 (0.083) 0.674 (0.083)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc></figDesc><table /><note><p>summarizes the results of ablation studies in terms of CCC. It is apparent that SMP-Net outperforms all of the variants. Specifically, SMP-Net consistently outperforms SMPT-Net-m 11.0%, 12.7% and 23.8% at time M24, M36 and M48, respectively,</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 .</head><label>2</label><figDesc>Average CCC results of ablation studies. The best results are bold and the superscript symbol * indicates that the proposed method significantly outperformed that method with p-value = 0.01.</figDesc><table><row><cell cols="6">Methods SMP-Net-rc SMP-Net-r SMP-Net-c SMP-Net-m SMP-Net</cell></row><row><cell>M24</cell><cell>0.299  *</cell><cell>0.382  *</cell><cell>0.472  *</cell><cell>0.635  *</cell><cell>0.705 0.705 0.705</cell></row><row><cell>M36</cell><cell>0.319  *</cell><cell>0.410  *</cell><cell>0.490  *</cell><cell>0.590  *</cell><cell>0.665 0.665 0.665</cell></row><row><cell>M48</cell><cell>0.313  *</cell><cell>0.434  *</cell><cell>0.468  *</cell><cell>0.544  *</cell><cell>0.674 0.674 0.674</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>http://adni.loni.usc.edu/.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This research was supported by the <rs type="funder">National Natural Science Foundation of China</rs> (No. <rs type="grantNumber">62076059</rs>), the <rs type="funder">Science Project of Liaoning Province</rs> (<rs type="grantNumber">2021-MS-105</rs>) and the 111 Project (<rs type="grantNumber">B16009</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_ancd5EX">
					<idno type="grant-number">62076059</idno>
				</org>
				<org type="funding" xml:id="_2XYCYCC">
					<idno type="grant-number">2021-MS-105</idno>
				</org>
				<org type="funding" xml:id="_PmpYMU6">
					<idno type="grant-number">B16009</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43907-0 30.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multimodal hypergraph diffusion network with dual prior for Alzheimer classification</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Aviles-Rivero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Runkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Papadakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Kourtzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Schönlieb</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16437-8_69</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16437-8" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022, Part III</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13433</biblScope>
			<biblScope unit="page">69</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Joint highorder multi-task feature learning to predict the progression of Alzheimer&apos;s disease</title>
		<author>
			<persName><forename type="first">L</forename><surname>Brand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Risacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saykin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-00928-1_63</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-00928-163" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2018, Part I</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Schnabel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Davatzikos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Alberola-López</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Fichtinger</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">11070</biblScope>
			<biblScope unit="page" from="555" to="562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Orthogonal latent space learning with feature weighting and graph learning for multimodal Alzheimer&apos;s disease diagnosis</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D N</forename><surname>Initiative</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page">102698</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Supervised Sequence Labelling with Recurrent Neural Networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-24797-2_4</idno>
		<ptr target="https://doi.org/10.1007/978-3-642-24797-24" />
	</analytic>
	<monogr>
		<title level="j">SCI</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">385</biblScope>
			<biblScope unit="page" from="37" to="45" />
			<date type="published" when="2012">2012</date>
			<publisher>Springer</publisher>
			<pubPlace>Heidelberg</pubPlace>
		</imprint>
	</monogr>
	<note>Long short-term memory</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Disease prediction with edge-variational graph convolutional networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Chung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page">102375</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep recurrent model for individualized prediction of Alzheimer&apos;s disease progression</title>
		<author>
			<persName><forename type="first">W</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">I</forename><surname>Suk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D N</forename><surname>Initiative</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">237</biblScope>
			<biblScope unit="page">118143</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Rethinking modeling Alzheimer&apos;s disease progression from a multi-task learning perspective with deep recurrent neural network</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Zaiane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Biol. Med</title>
		<imprint>
			<biblScope unit="volume">138</biblScope>
			<biblScope unit="page">104935</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">MUSCLE: multi-task self-supervised continual learning to pretrain deep models for X-ray images of multiple body parts</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liao</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16452-1_15</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16452-115" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022, Part VIII</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13438</biblScope>
			<biblScope unit="page" from="151" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">What we can do and what we cannot do with fMRI</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Logothetis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">453</biblScope>
			<biblScope unit="page" from="869" to="878" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Tadpole challenge: prediction of longitudinal evolution in Alzheimer&apos;s disease</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">V</forename><surname>Marinescu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.03909</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Interpretable differential diagnosis for Alzheimer&apos;s disease and frontotemporal dementia</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Clément</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mansencal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Coupé</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16431-6_6</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16431-66" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022, Part I</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13431</biblScope>
			<biblScope unit="page" from="55" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">EvolveGCN: evolving graph convolutional networks for dynamic graphs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pareja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="5363" to="5370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Disease prediction using graph convolutional networks: application to autism spectrum disorder and Alzheimer&apos;s disease</title>
		<author>
			<persName><forename type="first">S</forename><surname>Parisot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="117" to="130" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Feature robustness and sex differences in medical imaging: a case study in MRI-based Alzheimer&apos;s disease detection</title>
		<author>
			<persName><forename type="first">E</forename><surname>Petersen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16431-6_9</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16431-69" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022, Part I</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13431</biblScope>
			<biblScope unit="page" from="88" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">DySAT: deep neural representation learning on dynamic graphs via self-attention networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on Web Search and Data Mining</title>
		<meeting>the 13th International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="519" to="527" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Brain-aware replacements for supervised contrastive learning in detection of Alzheimer&apos;s disease</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Seyfioglu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16431-6_44</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16431-644" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022, Part I</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13431</biblScope>
			<biblScope unit="page" from="461" to="470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Automated anatomical labeling of activations in SPM using a macroscopic anatomical parcellation of the MNI MRI single-subject brain</title>
		<author>
			<persName><forename type="first">N</forename><surname>Tzourio-Mazoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="273" to="289" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Dual-graph learning convolutional networks for interpretable Alzheimer&apos;s disease diagnosis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16452-1_39</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16452-1" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022, Part VIII</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13438</biblScope>
			<biblScope unit="page">39</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Multi-modal sequence learning for Alzheimer&apos;s disease progression prediction with incomplete variable-length longitudinal data</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page">102643</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Disentangled sequential graph autoencoder for preclinical Alzheimer&apos;s disease characterizations from ADNI study</title>
		<author>
			<persName><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87196-3_34</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87196-334" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021, Part II</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12902</biblScope>
			<biblScope unit="page" from="362" to="372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Spatio-temporal graph convolutional networks: a deep learning framework for traffic forecasting</title>
		<author>
			<persName><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.04875</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">3D global Fourier network for Alzheimer&apos;s disease diagnosis using structural MRI</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16431-6_4</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16431-64" />
	</analytic>
	<monogr>
		<title level="m">MIC-CAI 2022, Part I</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13431</biblScope>
			<biblScope unit="page" from="34" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Aggregative self-supervised feature learning from limited medical images</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16452-1_6</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16452-16" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022, Part VIII</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13438</biblScope>
			<biblScope unit="page" from="57" to="66" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
