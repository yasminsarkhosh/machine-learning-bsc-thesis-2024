<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Small-Sample Method with EEG Signals Based on Abductive Learning for Motor Imagery Decoding</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Tianyang</forename><surname>Zhong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Automation</orgName>
								<orgName type="institution">Northwestern Polytechnical University</orgName>
								<address>
									<postCode>710072</postCode>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaozheng</forename><surname>Wei</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Automation</orgName>
								<orgName type="institution">Northwestern Polytechnical University</orgName>
								<address>
									<postCode>710072</postCode>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Enze</forename><surname>Shi</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Northwestern Polytechnical University</orgName>
								<address>
									<postCode>710072</postCode>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiaxing</forename><surname>Gao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Automation</orgName>
								<orgName type="institution">Northwestern Polytechnical University</orgName>
								<address>
									<postCode>710072</postCode>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chong</forename><surname>Ma</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Automation</orgName>
								<orgName type="institution">Northwestern Polytechnical University</orgName>
								<address>
									<postCode>710072</postCode>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yaonai</forename><surname>Wei</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Automation</orgName>
								<orgName type="institution">Northwestern Polytechnical University</orgName>
								<address>
									<postCode>710072</postCode>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Songyao</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Automation</orgName>
								<orgName type="institution">Northwestern Polytechnical University</orgName>
								<address>
									<postCode>710072</postCode>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lei</forename><surname>Guo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Automation</orgName>
								<orgName type="institution">Northwestern Polytechnical University</orgName>
								<address>
									<postCode>710072</postCode>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Junwei</forename><surname>Han</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tianming</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Automation</orgName>
								<orgName type="institution">Northwestern Polytechnical University</orgName>
								<address>
									<postCode>710072</postCode>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">University of Georgia</orgName>
								<address>
									<postCode>30602</postCode>
									<settlement>Athens</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Tuo</forename><surname>Zhang</surname></persName>
							<email>tuozhang@nwpu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Automation</orgName>
								<orgName type="institution">Northwestern Polytechnical University</orgName>
								<address>
									<postCode>710072</postCode>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Small-Sample Method with EEG Signals Based on Abductive Learning for Motor Imagery Decoding</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="416" to="424"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">77A373141B4D8C1618C25B9CFC52AF2D</idno>
					<idno type="DOI">10.1007/978-3-031-43907-0_40</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-23T22:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>MI Decoding</term>
					<term>Small-Sample</term>
					<term>Abductive Learning</term>
					<term>Visualization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Motor imagery (MI) electroencephalogram (EEG) decoding, as a core component widely used in noninvasive brain-computer interface (BCI) system, is critical to realize the interaction purpose of physical world and brain activity. However, the conventional methods are challenging to obtain desirable results for two main reasons: there is a small amount of labeled data making it difficult to fully exploit the features of EEG signals, and lack of unified expert knowledge among different individuals. To handle these dilemmas, a novel small-sample EE -G decoding method based on abductive learning (SSE-ABL) is proposed in this paper, which integrates perceiving module that can extract multiscale features of multi-channel EEG in semantic level and knowledge base module of brain science. The former module is trained via pseudo-labels of unlabeled EEG signals generated by abductive learning, and the latter is refined via the label distribution predicted by semi-supervised learning. Experimental results demonstrate that SSE-ABL has a superior performance compared with state-of-the-art methods and is also convenient for visualizing the underlying information flow of EEG decoding.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Brain computer interface (BCI) technology plays an increasingly crucial role in the rehabilitation process of patients with nerve damage. However, the lack of large-scale labeled data makes the identification results more vulnerable to be affected. BCI technology with motor imagery (MI), which can decode neural activities through EEG signals to identify the movement intention of the human being, is widely applied in the field of EEG decoding, where the substantial problem of BCI decoding is to extract as much effective information as possible from the multi-channel and non-linear EEG signals for understanding the oscillating activities in the brain <ref type="bibr" target="#b0">[1]</ref>.</p><p>According to the development of EEG signal processing technology, the traditional EEG signal feature extraction methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref> rely on rich human experience or expert knowledge. Furthermore, the existing deep learning models for EEG motion decoding <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref> rely on a large amount of labeled data. More recently, the active learning framework <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref> based on semi-supervised learning is used to solve a feature extraction problem with a large amount of unlabeled data, but it is sensitive to the initial model accuracy and sampling strategy. Therefore, there is still an unsolved urgent challenge that needs to be considered further, which is how to make biologically reasonable use of the information contained in a large number of unlabeled EEG data on the above basis.</p><p>The starting point of this paper is that the following biological findings can be observed in the MI decoding <ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref>: 1) the EEG rhythm energy in the contralateral motor sensory area (MSA) of the cerebral cortex is significantly reduced, while that in the ipsilateral MSA is increased, 2) different functional brain regions activities can be reflected by different sub-bands of EEG signals, and 3) the distribution density of different rhythms are clearly distinguished. And the rules are similar to the knowledge reasoning used in human decision-making. Then, the purpose of this paper is to employ these knowledge constraints to guide the model to extract MI information from unlabeled EEG data in a mutually beneficial way.</p><p>Therefore, based on abductive learning (ABL) <ref type="bibr" target="#b10">[11]</ref>, this article proposes a smallsample EEG decoding method, which can adaptively extract abstract features from complex and dynamic EEG signals, and an efficient knowledge base is designed to constrain the training process of the model. The main contributions are listed as follows:</p><p>1) A novel EEG decoding method is proposed to tackle the MIR (motion intention recognition) problem with small-sample EEG signals. This method does not rely on strict mathematical assumptions for datasets and its accuracy and robustness are well-maintained under strong interference. 2) A multi-scale feature fusion network is designed to enhance abstract features, which can capture temporal and frequency information across multi-channel EEG signals and spatial relationships among different electrodes. 3) An effective knowledge base module of motor imagery is constructed and symbolized, which can upgrade the model space under this constraint by mining the potential facts of large-scale unlabeled EEG signals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Definition and Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem Definition</head><p>In the SSE-ABL framework for EEG decoding, the given input is defined as Input = {X l , X u , KB θ }, where tensor X l denotes labeled EEG data, tensor X u denotes unlabeled EEG data, the data size of X u is much larger than that of X l , and KB θ denotes knowledge base on brain science in MI task. Concretely, X l = {(x l1 , y l1 ), (x l2 , y l2 ), . . . , (x li , y li )}, where variable x li represents multi-channel EEG signals, and y li implies the corresponding labels. And the assignment of X l is to learn a mapping from x to y. X u = {x u1 , x u2 , . . . , x uj |i j}, where x uj denotes unlabeled multi-channel EEG signals, which are utilized to boost representative capability of the above mapping. KB θ consists of a series of first-order logic sentences with learnable parameters θ , which integrate labels EEG data X l and unlabeled data X u to optimize a perceptual model and train parameters θ with the constraint of knowledge base. The final result is regarded as Output = {f , W, θ }, where f is a mapping from EEG signals to motion intention, W ∈ R m×n indicates the proportion of the m th sub-band to the n th channel in EEG data, θ ∈ R k represents the contribution rate of the k th channel to the whole in MIR. The SSE-ABL algorithm yields the corresponding pseudo-labels to the unlabeled data by the classifier optimized by a small amount of labeled EEG signals, and the produced labels may be incorrect due to the small number of training samples, which is difficult to guarantee good performance. Therefore, the SSE-ABL modifies the pseudo-labels and optimizes the internal parameters of the knowledge base at the same time, so that the consistency of them is maximized under the constraint of the knowledge base. Formally, the problem definition of the SSE-ABL can be summarized as an optimization problem of searching Output under a given Input:</p><formula xml:id="formula_0">min f ,W,θ Loss label (y li , f li ) + Loss unlabel (δ(y uj ), f uj ) (1) s.t. argmax δ constraint δ y uj , f li , KB θ (2)</formula><p>where y uj is the pseudo-label corresponding to the j th unlabeled instance, which is generated by the perceptual module. δ(•) indicates a heuristic function obtained by optimization, which aims to revise pseudo-labels by logical abduction process. In addition to correcting inconsistent pseudo-labels, this goal also helps the knowledge base to learn accurate parameter θ . It can be seen from Eq. 1 and Eq. 2 that the major challenge is how to mine the effective information of massive unlabeled EEG data under the KB θ constraints and react to the iterative update of itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Architecture of the SSE-ABL Framework</head><p>The proposed method, as shown in Fig. <ref type="figure" target="#fig_0">1</ref>, consists of four phases. A workflow outline of the proposed method in this paper is displayed in Algorithm 1.</p><p>1) Phase 1 (Sample Representation): For the purpose of promoting the ability to describe the local and global details of the brain activities, a time-frequency-space data representation method based on brain region division is proposed, which makes the receptive field of view cover the whole brain region in a fine-grained way. 2) Phase 2 (Multiscale Feature Fusion): Inspired by the neuroscience findings shown in Sect. 1, a multi-scale feature fusion model is proposed to adaptively integrate time-frequency-space information of EEG signals aiming at reducing the potential difference of feature distribution and selectively focusing on the MI-related materials. 3) Phase 3 (Motion Intention Estimation): Based on the common laws of EEG signals distribution, a motor intention evaluation model is constructed, in which the rules are used as the supervisory information to judge the authenticity of motor imagery recognition, so as to ensure that the overall process conforms to the actual criteria. 4) Phase 4 (Abductive Reasoning Optimization): When the classifier is insufficienttrained, the pseudo-labels could be wrong, the SSE-ABL method in this paper needs to correct the wrong pseudo-labels to achieve consistent abductions by using gradient free optimization method under the principle of minimal inconsistency <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Sample Representation</head><p>The preprocessed EEG signals are first divided into five bands containing delta (1-4 Hz), theta (4-8 Hz), alpha (8-14 Hz), beta (14-31 Hz) and gamma (31-50 Hz) wavebands by using digital band-pass filters whose corresponding cut-off frequency is performed according to the division standard in <ref type="bibr" target="#b0">[1]</ref>, and the segmentation process is completed by utilizing the local time window method (0.5s). Then, the comprehensive information of these rhythm signals about brain activities is obtained by continuous wavelet transform method (CWT) <ref type="bibr" target="#b13">[14]</ref>, and the time-frequency expression (tf t ∈ R N ×C×H ×W ) of the EEG data is obtained by convolution layer, normalization layer, nonlinear activation function and max pooling layer operations (defined asConv(•)), as described in Eq. 3.</p><formula xml:id="formula_1">tf t = Conv Cat (t,i) Cat (ch,j) ( 1 √ s +∞ ∫ -∞ div (i,j) (f (i) (t))ψ s,a tdt)<label>(3)</label></formula><p>where</p><formula xml:id="formula_2">f (i) (t) ∈ R N denotes the i th ∈ {1, 2, . . . , M } segment signal of EEG, div (i,j) (•)</formula><p>represents the decomposition of the signal f (i) (t) into j sub-bands. The inner product process is the principle of CWT, Cat (x,y) implies that the y th tensor data is concatenated according to the x th dimension. The procedure of fusing time-frequency information directly in multiple frequency bands may ignore the spatial distribution of the electrode. Therefore, multi-channel EEG signals are executed across the channel direction through the channel-by-channel convolutional operations, which aims at capturing spatial dynamic correlation characteristics (S t ∈ R N ×C×H ×W ) among brain regions, as shown in Eq. 4.</p><formula xml:id="formula_3">S t = Cat Append g Wf (i) (t) + b (4)</formula><p>where g(•) implies 1-D convolutional operation, tensor W and b denotes convolution weights and bias, Append (•) means adding each element in turn. With the above configurations, the mixed sample (MS t ∈ R N ×2C×H ×W ), which is composed of tf t andS t , are represented as 4-D tensor, where (C, H , W ) is the number of channels and the resolution of the feature map respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Multiscale Feature Fusion</head><p>Given the mixed samples, the multiscale feature fusion model embeds them into feature vectors and extracts the time-frequency-space features of multi-channel EEG signals. We introduce the embedding layers in phase 2 to better describe the semantic and location information of EEG and improve the EEG transformer encoder to pay attention to seizing the global and local information of long-term EEG signals. Concretely, the normalized operation, the position mark of multiple MS t and the order inside it are added to attain the input of the network by conducting token, segment and position embedding steps, respectively, as showed in Eq. 5.</p><formula xml:id="formula_4">Input = Tok(MS t ) + Seg(MS t ) + Pos(MS t ) (5)</formula><p>Note that the addition here is bitwise addition. Tok, Seg and Pos correspond to the above three operations. Then tensor-patches in MS t are vectorized and carried to the network to calculate temporal and spatial self-attention block described in <ref type="bibr" target="#b14">[15]</ref>, as showed in Algorithm 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Motion Intention Estimation</head><p>We construct MI classification module based on attention mechanism and knowledge rules, which consists of two parts: domain knowledge expressed by first-order logic formula and learnable parameters weights, as shown in Fig. <ref type="figure" target="#fig_1">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>We adopt the 2008 BCI competition IV-2a EEG dataset (https://www.bbci.de/competiti on/iv/) including 9 subjects with a 250 Hz sampling rate and band-pass filtered from 0.5 to 100 Hz, which consists of four MI tasks: imagine left hand (class 1), right hand (class 2), foot (class 3) and tongue (class 4) movements. And the preprocessing operations in this article refers to eliminating the wrong experiments and using digital band-pass filters of 1-50 Hz. In the experiments, all methods with self-teaching plan are set to the same number of modules using the default hyperparameters in the source code.</p><p>The following experimental tests of the proposed method (SSE-ABL) are designed to conduct: 1) Compared with the current mainstream algorithms containing transformer (TF) <ref type="bibr" target="#b15">[16]</ref>, BERT <ref type="bibr" target="#b16">[17]</ref> and MEET <ref type="bibr" target="#b14">[15]</ref> models to verify the performance of the SSE-ABL. 2) By changing proportion of training dataset size to verify the robustness of the SSE-ABL under the interference of different small-sample data, that is, the extrapolation ability.</p><p>3) The visualization of the underlying information flow of EEG decoding by the proposed method is displayed. As shown in Table <ref type="table" target="#tab_0">1</ref> are the accuracy results of experiments 1 and 2, which consists of three parts in the case of 10%, 50% and100% labeled data as the training set. And there are 9 subjects and average accuracy in the horizontal direction. It can be seen from the first and second part that SSE-ABL has obvious advantages in the individual accuracy and overall average accuracy of different subjects, up to 89.19%, 80.03% and 92.8 2%, 81.53% respectively. By comparing the first two parts, can be found that when the labeling rate is low, the benefits of using both unlabeled data and MI knowledge are much higher during EEG decoding. Further comparison with the third part shows that the performance can even be competitive the methods with the 100% training set.</p><p>Then, the visualization results of experiment 3 is exhibited in Fig. <ref type="figure" target="#fig_2">3</ref>,which is the analysis of FC 1 , FC 3 , CP 1 , CP 3 and FC 2 , FC 4 , CP 2 , CP 4 channels (corresponding to the left and right brain regions respectively) when imagining a left-handed task. And there are also three parts: the time domain EEG signal (P1), the time-frequency analysis (P2) and visualization analysis of the SSE-ABL (P3). From the time domain perspective shown in the P1, it seems that there is not much discrimination that can separate specific motor imagery tasks. However, it can be found in the P2 that the energy distribution on the left and right sides of the brain can be clearly found by the data representation method proposed in this paper, which can be distinguished by the brightness of the color. At the same time, there is also a phenomenon that the energy of the right brain region is lower than that of the left brain region, which is consistent with biological cognition. Moreover, it can be observed in the P3 that the high energy component of EEG signals is surrounded by a large amount of dark red, which is the information that the SS-ABL algorithm focuses on. And the contribution rates of the above channels to this recognition task are marked under the channels, respectively, which gives us an intuitive understanding of the EEG signal decoding process. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>A novel small-sample method with EEG signals based on abductive reasoning is studied for MI recognition. This method solves the problem of low precision and poor robustness ability of EEG decoding under a small amount of labeled data. The multiscale feature fusion module based on self-attention mechanism improves the ability of adaptive feature mining by capturing time-frequency-space information cover the whole brain region, which realizes the enhancement of abstract features. An effective knowledge base module of motor imagery is constructed and symbolized, which can upgrade the model space under this constraint by mining the potential facts of large-scale unlabeled EEG signals.</p><p>Through the comparison experiments with other mainstream inversion methods, it can be founded that our method with 10% and 50% labeled EEG data can reach the accuracy of 80.03% and 81.53%, achieving the high precision standard of EEG decoding. In the future, we will consider a fine-grained visualization method of EEG signals in the case of partial data damage, such as signal coupling.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Architecture of the proposed SSE-ABL method.</figDesc><graphic coords="4,56,46,56,36,340,03,176,02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. MIR rules of the knowledge base KB. Part 1): the domain knowledge for MI type is to revise pseudo-labels and inference. 2) the contribution weights for different channels.</figDesc><graphic coords="6,58,47,316,73,335,17,169,33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Visual analysis of the typical channels (FC 1-4 and CP 1-4 ) when imaging left hand movements through the SSE-ABL method.</figDesc><graphic coords="8,56,97,207,77,338,47,189,73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Performance comparison of SSE-ABL method to state-of-the-art methods as the proportion change of training dataset in term of accuracy metrics (%) for BCI IV-2a dataset.</figDesc><table><row><cell>Method</cell><cell>Sub1 Sub2 Sub3 Sub4 Sub5 Sub6 Sub7 Sub8 Sub9 AVE</cell></row><row><cell>TF-10</cell><cell>74.10 73.27 73.41 74.69 70.63 76.07 89.27 81.61 75.55 76.51</cell></row><row><cell>BERT-10</cell><cell>72.30 69.72 76.01 71.27 65.12 72.91 82.97 82.42 75.31 74.23</cell></row><row><cell>MEET-10</cell><cell>78.63 66.80 73.62 74.70 67.91 75.92 86.73 82.51 73.29 75.57</cell></row><row><cell>SSE-ABL</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>-10 79.22 76.01 78.90 78.43 72.44 78.66 89.19 88.05 79.40 80.03</head><label></label><figDesc></figDesc><table><row><cell>TF-50</cell><cell>79.03 76.59 79.24 77.48 73.53 79.36 89.38 88.26 80.54 80.38</cell></row><row><cell>BERT-50</cell><cell>79.85 75.93 78.83 77.56 73.05 78.79 89.83 88.73 79.76 80.26</cell></row><row><cell>MEET-50</cell><cell>80.20 76.26 78.93 78.59 73.19 79.56 90.51 89.19 79.83 80.70</cell></row><row><cell>SSE-ABL-</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>50 80.78 76.68 79.34 78.91 73.62 79.95 90.56 92.82 81.07 81.53</head><label></label><figDesc></figDesc><table><row><cell>TF-100</cell><cell>80.91 75.36 79.12 78.68 74.13 77.38 91.21 91.32 80.09 80.91</cell></row><row><cell>BERT-100</cell><cell>81.65 77.13 79.92 79.16 73.59 80.34 89.72 92.68 81.39 81.73</cell></row><row><cell>MEET-100</cell><cell>81.42 77.98 79.53 78.51 73.06 79.98 90.44 92.46 81.38 81.64</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A multi-scale fusion convolutional neural network based on attention mechanism for the visualization analysis of EEG signals decoding</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">K</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neur. Sys. Rehabil. Eng</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2615" to="2626" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A survey on deep learning-based non-invasive brain signals: recent advances and new frontiers</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">N</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neur. Eng</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">31002</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Decrypting the electrophysiological individuality of the human brain: identification of individuals based on resting-state EEG activity</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Valizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Riener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Elmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">197</biblScope>
			<biblScope unit="page" from="470" to="481" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Spatial-frequency convolutional self-attention network for EEG emotion recognition</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="page">108740</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Capsule neural networks on spatio-temporal EEG frames for cross-subjectemotion recognition</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Jana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sabath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Agrawal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomed. Signal Process. Control</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page">103361</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Local-global active learning based on a graph convolutional network for semi-supervised classification of hyperspectral imagery</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Lett</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Semi-supervised Gaussian processes active learning model for imbalanced small data based on tri-training with data enhancement</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Y</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="17510" to="11724" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Theta band oscillations reflect more than entrainment: behavioral and neural evidence demonstrates an active chunking process</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">B</forename><surname>Teng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Doelling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Poeppel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2770" to="2782" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A novel electroencephalogram-derived measure of disrupted delta wave activity during sleep predicts all-cause mortality risk</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lechat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">A</forename><surname>Melaku</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Am. Thorac. Soc</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="649" to="658" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">EEG theta power is an early marker of cognitive decline in dementia due to Alzheimer&apos;s disease</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Musaeus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Engedal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Høgh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Alzheimers Dis</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1359" to="1371" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fast abductive learning by similarity-based consistency optimization</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">W</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural. Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="26574" to="26584" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Bridging machine learning and logical reasoning by abductive learning</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Abductive learning: towards bridging machine learning and logical reasoning</title>
		<author>
			<persName><forename type="first">Z.-H</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11432-018-9801-4</idno>
		<ptr target="https://doi.org/10.1007/s11432-018-9801-4" />
	</analytic>
	<monogr>
		<title level="j">Sci. China Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1" to="3" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Feature extraction and classification of lower limb motion based on sEMG signal</title>
		<author>
			<persName><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="132882" to="132892" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Z</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Q</forename><surname>Kang</surname></persName>
		</author>
		<title level="m">MEET: Multi-band EEG Transformer</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Transformer-based spatial-temporal feature learning for EEG decoding</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.11170</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
