<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Co-assistant Networks for Label Correction</title>
				<funder ref="#_5PW6jJQ">
					<orgName type="full">NSFC</orgName>
				</funder>
				<funder ref="#_JxNfrm5 #_xK5WNhp">
					<orgName type="full">University of Electronic Science and Technology of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xuan</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">University of Electronic Science and Technology of China</orgName>
								<address>
									<postCode>611731</postCode>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Weiheng</forename><surname>Fu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">University of Electronic Science and Technology of China</orgName>
								<address>
									<postCode>611731</postCode>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Xiaoshuang Shi (B</roleName><forename type="first">Tian</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">University of Electronic Science and Technology of China</orgName>
								<address>
									<postCode>611731</postCode>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaoshuang</forename><surname>Shi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hengtao</forename><surname>Shen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">University of Electronic Science and Technology of China</orgName>
								<address>
									<postCode>611731</postCode>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaofeng</forename><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">University of Electronic Science and Technology of China</orgName>
								<address>
									<postCode>611731</postCode>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Co-assistant Networks for Label Correction</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="159" to="168"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">5809A952422C69D8A6286D7B3B30AEFA</idno>
					<idno type="DOI">10.1007/978-3-031-43898-1_16</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-23T22:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Corrupted labels</term>
					<term>Label correction</term>
					<term>CNN</term>
					<term>GCN</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The presence of corrupted labels is a common problem in the medical image datasets due to the difficulty of annotation. Meanwhile, corrupted labels might significantly deteriorate the performance of deep neural networks (DNNs), which have been widely applied to medical image analysis. To alleviate this issue, in this paper, we propose a novel framework, namely Co-assistant Networks for Label Correction (CNLC), to simultaneously detect and correct corrupted labels. Specifically, the proposed framework consists of two modules, i.e., noise detector and noise cleaner. The noise detector designs a CNN-based model to distinguish corrupted labels from all samples, while the noise cleaner investigates class-based GCNs to correct the detected corrupted labels. Moreover, we design a new bi-level optimization algorithm to optimize our proposed objective function. Extensive experiments on three popular medical image datasets demonstrate the superior performance of our framework over recent state-of-the-art methods. Source codes of the proposed method are available on https://github.com/shannak-chen/CNLC.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The success of deep neural networks (DNNs) mainly depends on the large number of samples and the high-quality labels. However, either of them is very difficult to be obtained for conducting medical image analysis with DNNs. In particular, obtaining high-quality labels needs professional experience so that corrupted labels can often be found in medical datasets, which can seriously degrade the effectiveness of medical image analysis. Moreover, sample annotation needs expensive cost. Hence, correcting corrupted labels might be one of effective solutions to solve the issues of high-quality labels.</p><p>Numerous works have been proposed to tackle the issue of corrupted labels. Based on whether correcting corrupted labels, previous methods can be roughly divided into two categories, i.e., robustness-based methods <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b16">17]</ref> and label correction methods <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b21">22]</ref>. Robustness-based methods are designed to utilize various techniques, such as dropout, augmentation and loss regularization, to avoid the adverse impact of corrupted labels, thereby outputting a robust model. Label correction methods are proposed to first detect corrupted labels and then correct them. For example, co-correction <ref type="bibr" target="#b8">[9]</ref> simultaneously trains two models and corrects labels for medical image analysis, and LCC <ref type="bibr" target="#b4">[5]</ref> first regards the outputs of DNN as the class probability of the training samples and then changes the labels of samples with low class probability. Label correction methods are significant for disease diagnosis, because physicians can double check the probably mislabeled samples to improve diagnosis accuracy. However, current label correction methods still have limitations to be addressed. First, they cannot detect and correct all corrupted labels, and meanwhile they usually fail to consider boosting the robustness of the model itself, so that the effectiveness of DNNs is possibly degraded. Second, existing label correction methods often ignore to take into account the relationship among the samples so that influencing the effectiveness of label correction.</p><p>To address the aforementioned issues, in this paper, we propose a new co-assistant framework, namely Co-assistant Networks for Label Correction (CNLC) (shown in Fig. <ref type="figure" target="#fig_0">1</ref>), which consists of two modules, i.e., noise detector and noise cleaner. Specifically, the noise detector first adopts a convolutional neural network (CNN <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b19">20]</ref>) to predict the class probability of samples, and then the loss is used to partition all the training samples for each class into three subgroups, i.e., clean samples, uncertain samples and corrupted samples. Moreover, we design a robust loss (i.e., a resistance loss) into the CNN framework to avoid model overfitting on corrupted labels and thus exploring the first issue in previous label correction methods. The noise cleaner constructs a graph convolutional network (GCN <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref>) model for each class to correct the corrupted labels. During the process of noise cleaner, we consider the relationship among samples (i.e., the local topology structure preservation by GCN) to touch the second issue in previous methods. In particular, our proposed CNLC iteratively updates the noise detector and the noise cleaner, which results in a bi-level optimization problem <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b9">10]</ref> Compared to previous methods, the contributions of our method is two-fold. First, we propose a new label correction method (i.e., a co-assistant framework) to boost the model robustness for medical image analysis by two sequential modules. Either of them adaptively adjusts the other, and thus guaranteeing to output a robust label correction model. Second, two sequential modules in our framework results in a bi-level optimization problem. We thus design a bi-level optimization algorithm to solve our proposed objective function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>In this section, our proposed method first designs a noise detector to discriminate corrupted samples from all samples, and then investigates a noise cleaner to correct the detected corrupted labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Noise Detector</head><p>Noise detector is used to distinguish corrupted samples from clean samples. The prevailing detection method is designed to first calculate the loss of DNNs on all training samples and then distinguish corrupted samples from clean ones based on their losses. Specifically, the samples with small losses are regarded as clean samples while the samples with large losses are regarded as corrupted samples.</p><p>Different from previous literature <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>, our noise detector involves two steps, i.e., CNN and label partition, to partition all training samples for each class into three subgroups, i.e., clean samples, uncertain samples and corrupted samples. Specifically, we first employ CNN with the cross-entropy loss as the backbone to obtain the loss of all training samples. Since the cross-entropy loss is easy to overfit on corrupted labels without extra noise-tolerant term <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b20">21]</ref>, we change it to the following resistant loss in CNN:</p><formula xml:id="formula_0">L r = 1 b b i=1 -log p t i [ ỹi ] + λ (t) b b i=1 C j=1 -p t i [j] log p t-1 i [j],<label>(1)</label></formula><p>where b is the number of samples in each batch, p t i [j] represents the j-th class prediction of the i-th sample in the t-th epoch, ỹi ∈ {0, 1, ..., C -1} denotes the corrupted label of the i-th sample x i , C denotes the number of classes and λ(t) is a time-related hyper-parameter. In Eq. ( <ref type="formula" target="#formula_0">1</ref>), the first term is the cross-entropy loss. The second term is the resistance loss which is proposed to smooth the update of model parameters so that preventing model overfitting on corrupted labels to some extent <ref type="bibr" target="#b11">[12]</ref>.</p><p>In label partition, based on the resistant loss in Eq. ( <ref type="formula" target="#formula_0">1</ref>), the training samples for each class are divided into three subgroups, i.e., clean samples, uncertain Fig. <ref type="figure">2</ref>. Cross-entropy loss distribution and GMM probability on different noise rates on BreakHis <ref type="bibr" target="#b12">[13]</ref>. "clean" denotes the samples with the ground-truth labels, while "corrupted" denotes the samples with the corrupted labels.</p><p>samples, and corrupted samples. Specifically, the samples with n 1 smallest losses are regarded as clean samples and the samples with n 1 largest loss values are regarded as corrupted samples, where n 1 is experimentally set as 5.0% of all training sample for each class. The rest of the training samples for each class are regarded as uncertain samples.</p><p>In noise detector, our goal is to identify the real clean samples and real corrupted samples, which are corresponded to set as positive samples and negative samples in noise cleaner. If we select a large number of either clean samples or corrupted samples (e.g., larger than 5.0% of all training samples), they may contain false positive samples or false negative samples, so that the effectiveness of the noise cleaner will be influenced. As a result, our noise detector partitions all training samples for each class into three subgroups, including a small proportion of clean samples and corrupted samples, as well as uncertain samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Noise Cleaner</head><p>Noise cleaner is designed to correct labels of samples with corrupted labels. Recent works often employ DNNs (such as CNN <ref type="bibr" target="#b7">[8]</ref> and MLP <ref type="bibr" target="#b14">[15]</ref>) to correct the corrupted labels. First, these methods ignore to take into account the relationship among the samples, such as local topology structure preservation, i.e., one of popular techniques in computer vision and machine learning, which ensures that nearby samples have similar labels and dissimilar samples have different labels. In particular, based on the partition mentioned in the above section, the clean samples within the same class should have the same label and the corrupted samples should have different labels from clean samples within the same class. This indicates that it is necessary to preserve the local topology structure of samples within the same class. Second, in noise detector, we only select a small proportion of clean samples and corrupted samples for the construction of noise cleaner. Limited number of samples cannot guarantee to build robust noise cleaner. In this paper, we address the above issues by employing semi-supervised learning, i.e., a GCN for each class, which keeps the local topology structure of samples on both labeled samples and unlabeled samples. Specifically, our noise cleaner includes three components, i.e., noise rate estimation, class-based GCNs, and corrupted label correction.</p><p>The inputs of each class-based GCN include labeled samples and unlabeled samples. The labeled samples consist of positive samples (i.e., the clean samples of this class with the new label z ic = 1 for the i-th sample in the c-th class) and negative samples (i.e., the corrupted samples of this class with the new label z ic = 0). The unlabeled samples include a subset of the uncertain samples from all classes and corrupted samples of other classes. We follow the principle to select uncertain samples for each class, i.e., the higher the resistant loss in Eq. ( <ref type="formula" target="#formula_0">1</ref>), the higher the probability of the sample belonging to corrupted samples. Moreover, the number of uncertain samples is determined by noise rate estimation.</p><p>Given the resistant loss in Eq. ( <ref type="formula" target="#formula_0">1</ref>), in noise rate estimation, we estimate the noise rate of the training samples by employing a Gaussian mixed model (GMM) composed of two Gaussian models. As shown in Fig. <ref type="figure">2</ref>, we observe that the mean value of Gaussian model for corrupted samples is greater than that of Gaussian model for clean samples. Thus, the Gaussian model with a large mean value is probably the curve of corrupted labels. Based on this, given two outputs of the GMM model for the i-th sample, its output with a larger mean value and the output with a smaller mean value, respectively, are denoted as M i,1 and M i,2 , so the following definition v i is used to determine if the i-th samples is noise:</p><formula xml:id="formula_1">v i = 1, M i,1 &gt; M i,2 0, otherwise .<label>(2)</label></formula><p>Hence, the noise rate r of training samples is calculated by:</p><formula xml:id="formula_2">r = n i=1 v i n , (<label>3</label></formula><formula xml:id="formula_3">)</formula><p>where n represents the total number of samples in training dataset. Supposing the number of samples in the c-th class is s c , the number of uncertain samples of each class is s c × r -n 1 . Hence, the total number of unlabeled samples for each class is n × r -n 1 in noise cleaner. Given 2 × n 1 labeled samples and n × r -n 1 unlabeled samples, the classbased GCN for each class conducts semi-supervised learning to predict n × r samples, including n × r -n 1 unlabeled samples and n 1 corrupted samples for this class. The semi-supervised loss L ssl includes a binary cross-entropy loss L bce for labeled samples and an unsupervised loss L mse <ref type="bibr" target="#b7">[8]</ref> for unlabeled samples, i.e., L ssl = L bce + L mse , where L bce and L mse are defined as:</p><formula xml:id="formula_4">L bce = -1 2n 1 2n1 i=1 z ic logq t ic + (1 -z ic ) log 1 -q t ic , (<label>4</label></formula><formula xml:id="formula_5">)</formula><formula xml:id="formula_6">L mse = 1 n × r -n 1 n×r+n1 i=2n1+1 q t ic -qt-1 ic 2 , (<label>5</label></formula><formula xml:id="formula_7">)</formula><p>where q t ic denotes the prediction of the i-th sample in the t-th epoch for the class c, qt ic is updated by qt ic =</p><formula xml:id="formula_8">ρ×q t-1 ic +(1-ρ)×q t-1 ic (t)</formula><p>, where (t) is related to time <ref type="bibr" target="#b7">[8]</ref>.</p><p>In corrupted label correction, given C well-trained GCNs and the similarity scores on each class for a subset of uncertain samples and all corrupted samples, their labels can be determined by: ỹi = argmax 0≤c≤C-1 (q ic ) .</p><p>(6)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Objective Function</head><p>The optimization of the noise detector is associated with the corrupted label set ỹ, which is determined by noise cleaner. Similarly, the embedding of all samples E is an essential input of the noise cleaner, which is generated by the noise detector. As the optimizations of two modules are nested, the objective function of our proposed method is the following bi-level optimization problem: In this paper, we construct a bi-level optimization algorithm to search optimal network parameters of the above objective function. Specifically, we optimize the noise detector to output an optimal feature matrix E * , which is used for the construction of the noise cleaner. Furthermore, the output ỹ * of the noise cleaner is used to optimize the noise detector. This optimization process alternatively optimize two modules until the noise cleaner converges. We list the optimization details of our proposed algorithm in the supplemental materials.</p><formula xml:id="formula_9">⎧ ⎨ ⎩ min θ L r f t (x; θ) , f t-1 (x; θ) , ỹ , min ωc L bce (g t c (A c , E c ; ω c ) , z c ) + L mse g t c (A c , E c ; ω c ) , g t-1 c (A c , E c ; ω c ) , (<label>7</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Settings</head><p>The used datasets are BreakHis <ref type="bibr" target="#b12">[13]</ref>, ISIC <ref type="bibr" target="#b2">[3]</ref>, and NIHCC <ref type="bibr" target="#b15">[16]</ref>. BreakHis consists of 7,909 breast cancer histopathological images including 2,480 benigns and 5,429 malignants. We randomly select 5,537 images for training and 2,372 ones for testing. ISIC has 12,000 digital skin images where 6,000 are normal and 6,000 are with melanoma. We randomly choose 9,600 samples for training and the remaining ones for testing. NIHCC has 10,280 frontal-view X-ray images, where 5,110 are normal and 5,170 are with lung diseases. We randomly select 8,574 images for training and the rest of images for testing. In particular, the random selection in our experiments guarantees that three datasets (i.e., the training set, the testing set, and the whole set) have the same ratio for each class. Moreover, we assume that all labels in the used raw datasets are clean, so we add corrupted labels with different noise rates = {0, 0.2, 0.4} into these datasests, where = 0 means that all labels in the training set are clean.</p><p>We compare our proposed method with six popular methods, including one fundamental baseline (i.e., Cross-Entropy (CE)), three robustness-based methods (i.e., Co-teaching (CT) <ref type="bibr" target="#b5">[6]</ref>, Nested Co-teaching (NCT) <ref type="bibr" target="#b1">[2]</ref> and Self-Paced Resistance Learning (SPRL) <ref type="bibr" target="#b11">[12]</ref>), and two label correction methods (i.e., Co-Correcting (CC) <ref type="bibr" target="#b8">[9]</ref> and Self-Ensemble Label Correction (SELC) <ref type="bibr" target="#b10">[11]</ref>). For fairness, in our experiments, we adopt the same neural network for all comparison methods based on their public codes and default parameter settings. We evaluate the effectiveness of all methods in terms of four evaluation metrics, i.e., classification accuracy (ACC), specificity (SPE), sensitivity (SEN) and area under the ROC curve (AUC).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results and Analysis</head><p>Table <ref type="table" target="#tab_0">1</ref> presents the classification results of all methods on three datasets. Due to the space limitation, we present the results at = 0.0 of all methods in the supplemental materials. First, our method obtains the best results, followed by CT, NCT, SPRL, CELC, CC, and CE, on all datasets in terms of four evalua- This might be because our proposed method not only utilizes a robust method to train a CNN for distinguishing corrupted labels from clean labels, but also corrects them by considering their relationship among the samples within the same class. Second, all methods outperform the fundamental baseline (i.e., CE) on all cases. For example, the accuracy of CC improves by 4.8% and 28.2% compared with CE at = 0.2 and = 0.4, respectively, on ISIC. The reason is that the cross-entropy loss easily results in the overfitting issue on corrupted labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Ablation Study</head><p>To verify the effectiveness of the noise cleaner, we compare our method with the following comparison methods: 1) W/O NC: without noise cleaner, and 2) MLP: replace GCN with Multi-Layer Perceptron, i.e., without considering the relationship among samples. Due to the space limitation, we only show results on ISIC, which is listed in the first and second rows of Table <ref type="table" target="#tab_1">2</ref>. The methods with noise cleaner (i.e., MLP and CNLC) outperform the method without noise cleaner W/O NC. For example, CNLC improves by 4.2% compared with W/O NC at = 0.4. Thus, the noise cleaner plays an critical role in CNLC. Additionally, CNLC obtains better performance than MLP because it considers the relationship among samples. Both of the above observations verify the conclusion mentioned in the last section again.</p><p>To verify the effectiveness of the resistance loss in Eq. ( <ref type="formula" target="#formula_0">1</ref>), we remove the second term in Eq. ( <ref type="formula" target="#formula_0">1</ref>) to have a new comparison method CNLC-RL and list the results in the third row of Table <ref type="table" target="#tab_1">2</ref>. Obviously, CNLC outperforms CNLC-RL. For example, CNLC improves by 1.0% and 2.3%, respectively, compared to CNLC-RL, in terms of four evaluation metrics at = 0.2 and = 0.4. The reason is that the robustness loss can prevent the model from overfitting on corrupted labels, and thus boosting the model robustness. This verifies the effectiveness of the resistance loss defined in Eq. (1) for medical image analysis, which has been theoretically and experimentally verified in the application of natural images <ref type="bibr" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we proposed a novel co-assistant framework, to solve the problem of DNNs with corrupted labels for medical image analysis. Experiments on three medical image datasets demonstrate the effectiveness of the proposed framework. Although our method has achieved promising performance, its accuracy might be further boosted by using more powerful feature extractors, like pre-train models on large-scale public datasets or some self-supervised methods, e.g., contrastive learning. In the future, we will integrate these feature extractors into the proposed framework to further improve its effectiveness.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The architecture of the proposed CNLC framework consists of two modules, i.e., noise detector and noise cleaner. The noise detector outputs the embedding of all training samples and classifies the training samples of each class into three subgroups, including clean samples, uncertain samples and corrupted samples. The noise cleaner constructs a GCN for each class to correct the labels of both corrupted samples and a subset of uncertain samples for all classes.</figDesc><graphic coords="2,42,81,54,59,338,80,112,12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>) where f t (x; θ) denotes the output of the upper-level (i.e., the noise detector) in the t-th epoch, A c and E c represent the adjacency matrix and the feature matrix of class c, z c are labels of labeled samples in class c, g t c (A c , E c ; ω c ) and g t-1 c (A c , E c ; ω c ) denote the output of GCN model for class c at the t-th and t-1-th epochs, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>The classification results (average ± std) on three datasets. CNLC 84.9±0.4 85.0±1.4 84.8±2.3 84.9±0.4 77.9±0.2 73.8±1.7 82.1±1.4 78.0±0.2</figDesc><table><row><cell></cell><cell></cell><cell>= 0.2</cell><cell></cell><cell></cell><cell></cell><cell>= 0.4</cell><cell></cell></row><row><cell cols="3">Dataset Method ACC</cell><cell>SEN</cell><cell>SPE</cell><cell>AUC</cell><cell>ACC</cell><cell>SEN</cell><cell>SPE</cell><cell>AUC</cell></row><row><cell></cell><cell>CE</cell><cell cols="7">82.7±1.7 87.2±2.4 73.1±3.2 80.1±1.7 64.4±2.4 67.0±2.4 58.9±5.5 62.9±3.0</cell></row><row><cell></cell><cell>CT</cell><cell cols="7">87.3±1.0 92.5±5.6 76.1±8.5 84.3±0.6 84.4±0.3 93.8±1.3 63.9±2.0 78.9±0.4</cell></row><row><cell></cell><cell>NCT</cell><cell cols="7">87.4±0.1 95.0±0.4 70.8±1.0 82.9±0.3 82.9±0.4 98.0±0.2 49.8±1.7 73.9±0.7</cell></row><row><cell>BreakHis</cell><cell>SPRL</cell><cell cols="7">86.1±0.1 95.9±0.5 64.8±3.5 80.4±0.4 82.0±0.1 99.0±0.2 44.6±3.2 71.8±1.5</cell></row><row><cell></cell><cell>CC</cell><cell cols="7">87.8±0.0 95.9±0.2 70.1±0.4 83.0±0.1 84.1±0.1 97.8±0.1 54.1±0.0 76.0±0.2</cell></row><row><cell></cell><cell>SELC</cell><cell cols="7">86.6±0.1 95.9±0.1 66.3±2.6 81.1±0.3 82.7±0.1 98.1±0.1 49.0±3.0 73.5±0.5</cell></row><row><cell></cell><cell cols="8">CNLC 90.1±0.2 95.0±0.4 79.3±1.2 87.1±0.4 85.2±0.1 94.3±0.8 65.3±2.0 79.8±0.5</cell></row><row><cell></cell><cell>CE</cell><cell cols="7">80.4±1.4 79.8±3.8 81.1±3.7 80.4±1.4 60.1±2.0 58.2±4.5 62.1±4.2 59.5±2.8</cell></row><row><cell></cell><cell>CT</cell><cell cols="7">88.1±0.3 88.0±0.6 88.2±0.6 88.1±0.3 84.3±0.3 78.7±0.6 90.0±0.4 84.3±0.3</cell></row><row><cell></cell><cell>NCT</cell><cell cols="7">88.3±0.1 86.5±0.5 90.2±0.3 88.4±0.1 82.1±0.3 75.8±1.1 88.7±0.7 85.2±0.3</cell></row><row><cell>ISIC</cell><cell>SPRL</cell><cell cols="7">88.5±0.1 88.5±0.1 88.5±0.3 88.5±0.1 84.1±0.2 83.1±0.4 85.0±0.3 84.1±0.2</cell></row><row><cell></cell><cell>CC</cell><cell cols="7">84.5±0.2 82.4±0.5 86.7±0.1 84.5±0.2 83.8±0.1 81.2±0.2 86.5±0.1 83.8±0.1</cell></row><row><cell></cell><cell>SELC</cell><cell cols="7">88.1±0.0 86.5±0.5 89.8±0.4 88.1±0.1 79.2±0.4 65.3±1.2 93.5±0.3 79.4±0.4</cell></row><row><cell></cell><cell cols="8">CNLC 90.4±0.2 89.1±0.4 91.8±0.2 90.4±0.2 85.5±0.2 83.2±0.6 87.9±0.3 85.5±0.2</cell></row><row><cell></cell><cell>CE</cell><cell cols="7">78.4±1.4 70.0±5.2 86.8±3.6 78.4±1.4 66.9±1.7 61.9±6.8 71.8±6.5 66.9±1.7</cell></row><row><cell></cell><cell>CT</cell><cell cols="7">82.7±0.3 78.7±0.9 86.6±0.7 82.7±0.3 73.7±0.3 68.8±0.7 78.6±0.7 73.7±0.2</cell></row><row><cell></cell><cell>NCT</cell><cell cols="7">81.9±0.1 83.9±0.7 79.9±1.0 81.9±0.1 73.7±0.1 69.8±0.4 77.6±0.2 73.7±0.1</cell></row><row><cell>NIHCC</cell><cell>SPRL</cell><cell cols="7">82.3±0.1 77.1±0.3 87.6±0.3 82.4±0.1 74.8±0.1 65.9±0.3 83.8±0.2 74.9±0.1</cell></row><row><cell></cell><cell>CC</cell><cell cols="7">78.0±0.1 65.5±0.4 90.5±0.2 78.0±0.1 67.7±0.1 54.3±0.3 81.2±0.1 67.8±0.1</cell></row><row><cell></cell><cell>SELC</cell><cell cols="7">79.6±0.2 78.2±0.4 81.1±0.9 79.6±0.2 71.4±0.1 72.9±0.5 69.9±0.5 71.4±0.1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>The classification results (average ± std) of the ablation study on ISIC.</figDesc><table><row><cell></cell><cell>= 0.2</cell><cell></cell><cell></cell><cell></cell><cell>= 0.4</cell><cell></cell><cell></cell></row><row><cell cols="2">Method ACC</cell><cell>SEN</cell><cell>SPE</cell><cell>AUC</cell><cell>ACC</cell><cell>SEN</cell><cell>SPE</cell><cell>AUC</cell></row><row><cell cols="9">W/O NC 88.5±0.2 86.7±0.8 89.1±1.9 88.1±0.5 81.9±0.7 78.9±2.6 85.0±2.3 82.0±0.1</cell></row><row><cell>MLP</cell><cell cols="8">90.0±0.2 89.0±0.2 91.0±0.4 90.0±0.2 84.1±0.3 77.6±0.7 90.7±0.5 84.2±0.3</cell></row><row><cell cols="9">CNLC-RL 89.5±0.4 88.4±1.0 90.6±0.9 89.5±0.4 83.5±0.4 82.2±1.0 84.9±0.6 83.5±0.4</cell></row><row><cell>CNLC</cell><cell cols="8">90.4±0.2 89.1±0.4 91.8±0.2 90.4±0.2 85.5±0.2 83.2±0.2 87.9±0.3 85.5±0.2</cell></row><row><cell cols="9">tion metrics. For example, our method on average improves by 2.4% and 15.3%,</cell></row><row><cell cols="9">respectively, compared to the best comparison method (i.e., CT) and the worst</cell></row><row><cell cols="5">comparison method (i.e., CE), on all cases.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This paper is supported by <rs type="funder">NSFC</rs> <rs type="grantNumber">62276052</rs>, Medico-Engineering Cooperation Funds from <rs type="funder">University of Electronic Science and Technology of China</rs> (No. <rs type="grantNumber">ZYGX2022YGRH009</rs> and No. <rs type="grantNumber">ZYGX2022YGRH014</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_5PW6jJQ">
					<idno type="grant-number">62276052</idno>
				</org>
				<org type="funding" xml:id="_JxNfrm5">
					<idno type="grant-number">ZYGX2022YGRH009</idno>
				</org>
				<org type="funding" xml:id="_xK5WNhp">
					<idno type="grant-number">ZYGX2022YGRH014</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43898-1_16.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A closer look at memorization in deep networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Arpit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="233" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Boosting co-teaching with compression regularization for label noise</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Suykens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2688" to="2692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Skin lesion analysis toward melanoma detection: a challenge at the 2017 international symposium on biomedical imaging (ISBI), hosted by the international skin imaging collaboration (ISIC)</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Codella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Biomedical Imaging</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="168" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Bilevel programming for hyperparameter optimization and meta-learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Franceschi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frasconi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Salzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grazzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1568" to="1577" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">LCC: towards efficient label completion and correction for supervised medical image learning in smart diagnosis</title>
		<author>
			<persName><forename type="first">K</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Kui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Netw. Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="page" from="51" to="59" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Co-teaching: robust training of deep neural networks with extremely noisy labels</title>
		<author>
			<persName><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Mentornet: learning data-driven curriculum for very deep neural networks on corrupted labels</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2304" to="2313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Temporal ensembling for semi-supervised learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.02242</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Co-correcting: noise-tolerant medical image classification via mutual label correction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3580" to="3592" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Investigating bi-level optimization for learning and vision from a unified perspective: a survey and beyond</title>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="10045" to="10067" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Selc: self-ensemble label correction improves learning with noisy labels</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.01156</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Self-paced resistance learning against overfitting on noisy labels. Pattern Recogn</title>
		<author>
			<persName><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="page">109080</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A dataset for breast cancer histopathological image classification</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Spanhol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Petitjean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Heutte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1455" to="1462" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Joint optimization framework for learning with noisy labels</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ikami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yamasaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Aizawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="5552" to="5560" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Unext: MLP-based rapid medical image segmentation network</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M J</forename><surname>Valanarasu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16443-9_3</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16443-9_3" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13435</biblScope>
			<biblScope unit="page" from="23" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Chestx-ray8: hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bagheri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Summers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2097" to="2106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Combating noisy labels by agreement: a joint training method with co-regularization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>An</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="13726" to="13735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Dual-graph learning convolutional networks for interpretable Alzheimer&apos;s disease diagnosis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16452-1_39</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16452-1_39" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13438</biblScope>
			<biblScope unit="page" from="406" to="415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Multi-scale enhanced graph convolutional network for early mild cognitive impairment detection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59728-3_23</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-59728-3_23" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12267</biblScope>
			<biblScope unit="page" from="228" to="237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">How does disagreement help generalization against label corruption?</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="7164" to="7173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Understanding deep learning (still) requires rethinking generalization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="107" to="115" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Meta label correction for noisy label learning</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Awadallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dumais</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="11053" to="11061" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
