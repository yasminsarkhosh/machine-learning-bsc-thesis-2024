<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SMRD: SURE-Based Robust MRI Reconstruction with Diffusion Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Batu</forename><surname>Ozturkler</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
								<address>
									<postCode>94305</postCode>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chao</forename><surname>Liu</surname></persName>
							<email>chaoliu@nvidia.com</email>
							<affiliation key="aff1">
								<orgName type="institution">NVIDIA Corporation</orgName>
								<address>
									<postCode>95051</postCode>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Benjamin</forename><surname>Eckart</surname></persName>
							<email>beckart@nvidia.com</email>
							<affiliation key="aff1">
								<orgName type="institution">NVIDIA Corporation</orgName>
								<address>
									<postCode>95051</postCode>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Morteza</forename><surname>Mardani</surname></persName>
							<email>mmardani@nvidia.com</email>
							<affiliation key="aff1">
								<orgName type="institution">NVIDIA Corporation</orgName>
								<address>
									<postCode>95051</postCode>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiaming</forename><surname>Song</surname></persName>
							<email>jiaming.tsong@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="institution">NVIDIA Corporation</orgName>
								<address>
									<postCode>95051</postCode>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jan</forename><surname>Kautz</surname></persName>
							<email>jkautz@nvidia.com</email>
							<affiliation key="aff1">
								<orgName type="institution">NVIDIA Corporation</orgName>
								<address>
									<postCode>95051</postCode>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SMRD: SURE-Based Robust MRI Reconstruction with Diffusion Models</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="199" to="209"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">803187E15A221BDE2A55761875763868</idno>
					<idno type="DOI">10.1007/978-3-031-43898-1_20</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-23T22:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>MRI Reconstruction</term>
					<term>Diffusion models</term>
					<term>Measurement Noise</term>
					<term>Test-time Tuning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Diffusion models have recently gained popularity for accelerated MRI reconstruction due to their high sample quality. They can effectively serve as rich data priors while incorporating the forward model flexibly at inference time, and they have been shown to be more robust than unrolled methods under distribution shifts. However, diffusion models require careful tuning of inference hyperparameters on a validation set and are still sensitive to distribution shifts during testing. To address these challenges, we introduce SURE-based MRI Reconstruction with Diffusion models (SMRD), a method that performs test-time hyperparameter tuning to enhance robustness during testing. SMRD uses Stein's Unbiased Risk Estimator (SURE) to estimate the mean squared error of the reconstruction during testing. SURE is then used to automatically tune the inference hyperparameters and to set an early stopping criterion without the need for validation tuning. To the best of our knowledge, SMRD is the first to incorporate SURE into the sampling stage of diffusion models for automatic hyperparameter selection. SMRD outperforms diffusion model baselines on various measurement noise levels, acceleration factors, and anatomies, achieving a PSNR improvement of up to 6 dB under measurement noise. The code will be made publicly available.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Magnetic Resonance Imaging (MRI) is a widely applied imaging technique for medical diagnosis since it is non-invasive and able to generate high-quality clinical images without exposing the subject to radiation. The imaging speed is of vital importance for MRI <ref type="bibr" target="#b18">[19]</ref> in that long imaging limits the spatial and temporal resolution and induces reconstruction artifacts such as subject motion during the imaging process. One possible way to speed up the imaging process is to use multiple receiver coils, and reduce the amount of captured data by subsampling the k-space and exploiting the redundancy in the measurements <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b23">24]</ref>. In recent years, Deep-Learning (DL) based methods have shown great potential as a data-driven approach in achieving faster imaging and better reconstruction quality. DL-based methods can be categorized into two families: unrolled methods that alternate between measurement consistency and a regularization step based on a feed-forward network <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b35">35]</ref>; conditional generative models that use measurements as guidance during the generative process <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b20">21]</ref>. Compared with unrolled methods, generative approaches have recently been shown to be more robust when test samples are out of the training distribution due to their stronger ability to learn the data manifold <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b14">15]</ref>. Among generative approaches, diffusion models have recently achieved the state of the art performance <ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b32">33]</ref>.</p><p>However, measurements in MRI are often noisy due to the imaging hardware and thermal fluctuations of the subject <ref type="bibr" target="#b25">[26]</ref>. As a result, DL-based methods fail dramatically when a distribution shift due to noise or other scanning parameters occurs during training and testing <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b16">17]</ref>. Although diffusion models were shown to be robust against distribution shifts in noisy inverse problems <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b26">27]</ref> and MRI reconstruction, the hyperparameters that balance the measurement consistency and prior are tuned manually during validation where ground truth is available <ref type="bibr" target="#b14">[15]</ref>. These hyperparameters may not generalize well to test settings as shown in Fig. <ref type="figure" target="#fig_0">1</ref>, and ground truth data may not be available for validation.</p><p>In this paper, we propose a framework with diffusion models for MRI reconstruction that is robust to measurement noise and distribution shifts. To achieve robustness, we perform test-time tuning when ground truth data is not available at test time, using Stein's Unbiased Risk Estimator (SURE) <ref type="bibr" target="#b30">[31]</ref> as a surrogate loss function for the true mean-squared error (MSE). SURE is used to tune the weight of the balance between measurement consistency and the learned prior for each diffusion step such that the measurement consistency adapts to the measurement noise level during the inference process. SURE is then used to perform early stopping to prevent overfitting to measurement noise at inference.</p><p>We evaluate our framework on FastMRI <ref type="bibr" target="#b36">[36]</ref> and Mridata <ref type="bibr" target="#b21">[22]</ref>, and show that it achieves state-of-the-art performance across different noise levels, acceleration rates and anatomies without fine-tuning the pre-trained network or performing validation tuning, with no access to the target distribution. In summary, our contributions are three-fold:</p><p>-We propose a test-time hyperparameter tuning algorithm that boosts the robustness of the pre-trained diffusion models against distribution shifts; -We propose to use SURE as a surrogate loss function for MSE and incorporate it into the sampling stage for test-time tuning and early stopping without access to ground truth data from the target distribution; -SMRD achieves state-of-the-art performance across different noise levels, acceleration rates, and anatomies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>SURE for MRI Reconstruction. SURE has been used for tuning parameters of compressed sensing <ref type="bibr" target="#b13">[14]</ref>, as well as for unsupervised training of DL-based methods for MRI reconstruction <ref type="bibr" target="#b0">[1]</ref>. To the best of our knowledge, SURE has not yet been applied to the sampling stage of diffusion models in MRI reconstruction or in another domain.</p><p>Adaptation in MRI Reconstruction. Several proposals have been made for adaptation to a target distribution in MRI reconstruction using self-supervised losses for unrolled models <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b34">34]</ref>. Later, <ref type="bibr" target="#b2">[3]</ref> proposed single-shot adaptation for test-time tuning of diffusion models by performing grid search over hyperparameters with a ground truth from the target distribution. However, this search is computationally costly, and the assumption of access to samples from the target distribution is limiting for imaging cases where ground truth is not available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Accelerated MRI Reconstruction Using Diffusion Models</head><p>The sensing model for accelerated MRI can be expressed as</p><formula xml:id="formula_0">y = ΩF Sx + ν (1)</formula><p>where y is the measurements in the Fourier domain (k-space), x is the real image, S are coil sensitivity maps, F is the Fourier transform, Ω is the undersampling mask, ν is additive noise, and A = ΩF S denotes the forward model. Diffusion models are a recent class of generative models showing remarkable sample fidelity for computer vision tasks <ref type="bibr" target="#b12">[13]</ref>. A popular class of diffusion models is score matching with Langevin dynamics <ref type="bibr" target="#b27">[28]</ref>. Given i.i.d. training samples from a high-dimensional data distribution (denoted as p(x)), diffusion models can estimate the scores of the noise-perturbed data distributions. First, the data distribution is perturbed with Gaussian noise of different intensities with standard deviation β t for various timesteps t, such that p βt (x|x) = N (x|x, β 2 t I) <ref type="bibr" target="#b27">[28]</ref>, leading to a series of perturbed data distributions p(x t ). Then, the score function ∇ xt log p(x t ) can be estimated by training a joint neural network, denoted as f (x t ; t), via denoising score matching <ref type="bibr" target="#b31">[32]</ref>. After training the score function, annealed Langevin Dynamics can be used to generate new samples <ref type="bibr" target="#b28">[29]</ref> </p><formula xml:id="formula_1">x + t = xt + ηtf (xt; t) + √ 2ηtζt 4: xt+1 = h(xt, λt) = (A H A + λtI) -1 (x zf + λtx + t ) 5: sample μ ∼ N (0, I) 6: SURE(t) = h(xt, λt) -x zf 2 μ T (h(xt + μ, λt) -h(xt, λt))/N 7: λt+1 = λt -α∇ λ t SURE(t) 8: if mean(SURE[t -w : t]) &gt; mean(SURE[t -2w : t -w]) then 9:</formula><p>break 10: return xt+1 from a noise distribution x 0 ∼ N (0, I), annealed Langevin Dynamics is run for T steps</p><formula xml:id="formula_2">x t+1 = x t + η t ∇ xt log p(x t ) + 2η t ζ t (2)</formula><p>where η t is a sampling hyperparameter, and ζ t ∼ N (0, I). For MRI reconstruction, measurement consistency can be incorporated via sampling from the posterior distribution p(x t |y) <ref type="bibr" target="#b14">[15]</ref>:</p><formula xml:id="formula_3">x t+1 = x t + η t ∇ xt log p(x t |y) + 2η t ζ t (3)</formula><p>The form of ∇ xt log p(x t |y) depends on the specific inference algorithm <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Stein's Unbiased Risk Estimator (SURE)</head><p>SURE is a statistical technique which serves as a surrogate for the true mean squared error (MSE) when the ground truth is unknown. Given the ground truth image x, the zero-filled image can be formulated as x zf = x + z, where z is the noise due to undersampling. Then, SURE is an unbiased estimator of MSE = xx 2 2 <ref type="bibr" target="#b30">[31]</ref> and can be calculated as:</p><formula xml:id="formula_4">SURE = x -x zf 2 2 -Nσ 2 + σ 2 tr( ∂ x ∂x zf )<label>(4)</label></formula><p>where x zf is the input of a denoiser, x is the prediction of a denoiser, N is the dimensionality of x. In practical applications, the noise variance σ 2 is not known a priori. In such cases, it can be assumed that the reconstruction error is not large, and the sample variance between the zero-filled image and the reconstruction can be used to estimate the noise variance, where σ 2 ≈ xx zf 2 2 /N <ref type="bibr" target="#b10">[11]</ref>. Then, SURE can be rewritten as:</p><formula xml:id="formula_5">SURE ≈ x -x zf 2 N tr( ∂ x ∂x zf )<label>(5)</label></formula><p>A key assumption behind SURE is that the noise process that relates the zero-filled image to the ground truth is i.i.d. normal, namely z ∼ N(0, σ 2 I). However, this assumption does not always hold in the case of MRI reconstruction due to undersampling in k-space that leads to structured aliasing. In this case, density compensation can be applied to enforce zero-mean residuals and increase residual normality <ref type="bibr" target="#b10">[11]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">SURE-Based MRI Reconstruction with Diffusion Models</head><p>Having access to SURE at test time enables us to monitor it as a proxy for the true MSE. Our goal is to optimize inference hyperparameters in order to minimize SURE. To do this, we first consider the following optimization problem at time-step t:</p><formula xml:id="formula_6">x t+1 = arg min x Ax -y 2 2 + λ t x -x t 2 2<label>(6)</label></formula><p>where we introduce a time-dependent regularization parameter λ t . The problem in Eq. 6 can be solved using alternating minimization (which we call AM-Langevin):</p><formula xml:id="formula_7">x + t = x t + η t f (x t ; t) + 2η t ζ t (<label>7</label></formula><formula xml:id="formula_8">)</formula><formula xml:id="formula_9">x t+1 = arg min x Ax -y 2 2 + λ t x -x + t 2 2<label>(8)</label></formula><p>Equation 8 can be solved using the conjugate gradient (CG) algorithm, with the iterates</p><formula xml:id="formula_10">x t+1 = h(x t , λ t ) = (A H A + λ t I) -1 (x zf + λ t x + t )<label>(9)</label></formula><p>where A H is the Hermitian transpose of A, x zf = A H y is the zero-filled image, and h denotes the full update including the Langevin Dynamics and CG. This allows us to explicitly control the balance between the prior through the score function and the regularization through λ t .</p><p>Monte-Carlo SURE. Calculating SURE requires evaluating the trace of the Jacobian tr( ∂xt+1 ∂x zf ), which can be computationally intensive. Thus, we approximate this term using Monte-Carlo SURE <ref type="bibr" target="#b24">[25]</ref>. Given an N -dimensional noise vector μ from N (0, I) and the perturbation scale , the approximation is: This approximation is typically quite tight for some small value ; see e.g., <ref type="bibr" target="#b10">[11]</ref>. Then, at time step t, SURE is given as</p><formula xml:id="formula_11">tr( ∂x t+1 ∂x zf ) ≈ μ T (h(x t + μ, λ t ) -h(x t , λ t ))/<label>(10)</label></formula><formula xml:id="formula_12">SURE(t) = h(x t , λ t ) -x zf 2 N μ T (h(x t + μ, λ t ) -h(x t , λ t ))<label>(11)</label></formula><p>where h(x t , λ t ) is the prediction which depends on the input x zf , shown in Eq. 9.</p><p>Tuning λ t . By allowing λ t to be a learnable, time-dependent variable, we can perform test-time tuning (TTT) for λ t by updating it in the direction that minimizes SURE. As both SURE(t) and λ t are time-dependent, the gradients can be calculated with backpropagation through time (BPTT). In SMRD, for the sake of computation, we apply truncated BPTT, and only consider gradients from the current time step t. Then, the λ t update rule is:</p><formula xml:id="formula_13">λ t+1 = λ t -α∇ λt SURE(t) (<label>12</label></formula><formula xml:id="formula_14">)</formula><p>where α is the learning rate for λ t .</p><p>Early Stopping (ES). Under measurement noise, it is critical to prevent overfitting to the measurements. We employ early-stopping (ES) by monitoring the moving average of SURE loss with a window size w at test time. Intuitively, we perform early stopping when the SURE loss does not decrease over a certain window. We denote the early-stopping iteration as T ES . Our full method is shown in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Experiments were performed with PyTorch on a NVIDIA Tesla V100 GPU <ref type="bibr" target="#b22">[23]</ref>.</p><p>For baselines and SMRD, we use the score function from <ref type="bibr" target="#b14">[15]</ref> which was trained on a subset of the FastMRI multi-coil brain dataset. We refer the reader to <ref type="bibr" target="#b14">[15]</ref> for implementation details regarding the score function. For all AM-Langevin variants, we use 5 CG steps. In SMRD, for tuning λ t , we use the Adam optimizer <ref type="bibr" target="#b15">[16]</ref> with a learning rate of α = 0.2 and λ 0 = 2. In the interest of inference speed, we fixed λ t after t = 500, as convergence was observed in earlier iterations. For SURE early stopping, we use window size w = 160. For evaluation, we used </p><formula xml:id="formula_15">PSNR/SSIM. R R = 12 R = 16 σ ×10 -3 σ = 0 σ = 2.5 σ = 5 σ = 0 σ = 2.5 σ = 5</formula><p>Zero-filled 24.5/0.63 24.5/0.61 the multi-coil fastMRI brain dataset <ref type="bibr" target="#b36">[36]</ref> and the fully-sampled 3D fast-spin echo multi-coil knee MRI dataset from mridata.org <ref type="bibr" target="#b21">[22]</ref> with 1D equispaced undersampling and a 2D Poisson Disc undersampling mask respectively, as in <ref type="bibr" target="#b14">[15]</ref>. We used 6 volumes from the validation split for fastMRI, and 3 volumes for Mridata where we selected 32 middle slices from each volume so that both datasets had 96 test slices in total.</p><p>Noise Simulation. The noise source in MRI acquisition is modeled as additive complex-valued Gaussian noise added to each acquired k-space sample <ref type="bibr" target="#b19">[20]</ref>.</p><p>To simulate measurement noise, we add masked complex-gaussian noise to the masked k-space ν ∼ N (0, σ) with standard deviation σ, similar to <ref type="bibr" target="#b9">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Discussion</head><p>We compare with three baselines: (1) Csgm-Langevin <ref type="bibr" target="#b14">[15]</ref>, using the default hyperparameters that were tuned on two validation brain scans at R = 4;</p><p>(2) Csgm-Langevin with early stopping using SURE loss with window size w = 25;</p><p>(3) AM-Langevin where λ t = λ 0 and fixed throughout the inference.</p><p>For tuning AM-Langevin, we used a brain scan for validation at R = 4 in the noiseless case (σ = 0) similar to Csgm-Langevin, and the optimal value was λ 0 = 2.</p><p>We evaluate the methods across different measurement noise levels, acceleration rates and anatomies using the same pretrained score function from <ref type="bibr" target="#b14">[15]</ref>. Table <ref type="table" target="#tab_1">1</ref> shows a comparison of reconstruction methods applied to the FastMRI brain dataset where R = {4, 8}, and σ = {0, 0.0025, 0.005}. SMRD performs best   <ref type="table" target="#tab_2">2</ref> shows a comparison of reconstruction methods in the cross-dataset setup with the Mridata knee dataset where R = {12, 16}. SMRD outperformed baselines across every R and σ, and is on par with baselines when σ = 0. Figure <ref type="figure" target="#fig_1">2</ref> shows example reconstructions where R = 12, σ = 0. Hallucination artifacts are visible in baselines even with no added measurement noise, whereas SMRD mitigates these artifacts and produces a reconstruction with no hallucinations. Figure <ref type="figure" target="#fig_2">3a</ref> shows SSIM on a knee validation scan with varying noise levels σ and λ. As σ increases, the optimal λ value increases as well. Thus, hyperparameters tuned with σ = 0 do not generalize well under measurement noise change, illustrating the need for test-time tuning under distribution shift. Figure <ref type="figure" target="#fig_2">3b</ref> shows true MSE vs SURE for an example brain slice where σ = 0.0075, R = 8. SURE accurately estimates MSE, and the increase in loss occurs at similar iterations, enabling us to perform early stopping before true MSE increases. The evolution of images across iterations for this sample is shown in Fig. <ref type="figure" target="#fig_3">4</ref>. SMRD accurately captures the correct early stopping point. As a result of early stopping, SMRD mitigates artifacts, and produces a smoother reconstruction. Table <ref type="table" target="#tab_3">3</ref> shows the ablation study for different components of SMRD. TTT and ES both improve over AM-Langevin, where SMRD works best for all σ while being on par with others on σ = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We presented SMRD, a SURE-based TTT method for diffusion models in MRI reconstruction. SMRD does not require ground truth data from the target distribution for tuning as it uses SURE for estimating the true MSE. SMRD surpassed baselines across different shifts including anatomy shift, measurement noise change, and acceleration rate change. SMRD could be helpful to improve the safety and robustness of diffusion models for MRI reconstruction used in clinical settings. While we applied SMRD to MRI reconstruction, future work could explore the application of SMRD to other inverse problems and diffusion sampling algorithms and can be used to tune their inference hyperparameters.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Reconstruction of a brain slice from the FastMRI dataset with acceleration rate R = 8, and measurement noise level σ = 0.005. SMRD is robust to the measurement noise. Metrics are reported as PSNR/SSIM.</figDesc><graphic coords="2,41,79,60,20,340,21,56,02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Knee reconstruction with R = 12. Metrics are reported as PSNR/SSIM.</figDesc><graphic coords="5,55,98,59,90,340,66,63,13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. (a) SSIM on a validation scan (knee) with varying noise levels σ and regularization parameter λ parameter choices. As σ increases, the optimal λ value shifts to the right. (b) SURE and true MSE over sampling iterations. MSE and SURE start increasing at similar T due to overfitting to measurement noise.</figDesc><graphic coords="8,41,79,224,03,340,66,50,17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Iterations of inference for an example brain slice where R = 8, σ = 0.0075.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>. Starting Algorithm 1. SMRD: Test-time Tuning for Diffusion Models via SURE Input: measurement y, forward model A, initial λ0, window size w, learning rate α</figDesc><table /><note><p>1: sample x0 ∼ N (0, I) 2: for t ∈ 0, ..., T -1 do 3:</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>FastMRI brain dataset results. Metrics are reported as PSNR/SSIM.</figDesc><table><row><cell>R</cell><cell>R = 4</cell><cell></cell><cell></cell><cell>R = 8</cell><cell></cell><cell></cell></row><row><cell>σ ×10 -3</cell><cell>σ = 0</cell><cell>σ = 2.5</cell><cell>σ = 5</cell><cell>σ = 0</cell><cell>σ = 2.5</cell><cell>σ = 5</cell></row><row><cell>Zero-filled</cell><cell cols="6">27.8/0.81 27.1/0.63 25.3/0.43 23.2/0.69 23.1/0.61 22.7/0.43</cell></row><row><cell cols="7">Csgm-Langevin 36.3/0.78 25.1/0.36 18.5/0.16 34.7/0.79 21.3/0.32 15.8/0.15</cell></row><row><cell cols="7">Csgm-Lang.+ES 35.9/0.79 26.1/0.40 20.8/0.23 32.3/0.69 26.1/0.41 20.7/0.25</cell></row><row><cell>AM-Langevin</cell><cell cols="6">39.7/0.95 28.7/0.53 22.4/0.29 34.7/0.93 25.7/0.52 19.0/0.30</cell></row><row><cell>SMRD</cell><cell cols="6">36.5/0.89 33.5/0.78 29.4/0.59 32.4/0.80 31.4/0.75 28.6/0.61</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Cross-dataset results with the Mridata knee dataset. Metrics are reported as</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc><ref type="bibr" target="#b23">24</ref>.1/0.54 24.0/0.60 24.1/0.59 23.9/0.55 Ablation study for different components of our method on the Mridata multicoil knee dataset where R = 12. Metrics are reported as PSNR/SSIM.</figDesc><table><row><cell cols="6">Csgm-Langevin 31.4/0.82 24.2/0.49 21.7/0.29 31.8/0.79 24.4/0.50 22.1/0.32</cell></row><row><cell cols="6">Csgm-Lang.+ES 34.0/0.82 28.8/0.60 23.6/0.37 33.6/0.81 28.4/0.60 23.2/0.37</cell></row><row><cell>AM-Langevin</cell><cell cols="5">34.0/0.87 29.9/0.69 23.5/0.38 34.3/0.85 29.3/0.66 22.7/0.37</cell></row><row><cell>SMRD</cell><cell cols="5">35.0/0.84 33.5/0.82 29.4/0.67 34.1/0.82 32.8/0.80 29.2/0.67</cell></row><row><cell>σ (×10 -3 )</cell><cell></cell><cell>σ = 0</cell><cell>σ = 2.5</cell><cell>σ = 5</cell><cell>σ = 7.5</cell></row><row><cell>AM-Langevin</cell><cell></cell><cell cols="4">34.0/0.87 29.9/0.69 23.5/0.38 20.5/0.24</cell></row><row><cell cols="2">AM-Lang.+TTT</cell><cell cols="4">34.7/0.86 31.0/0.75 25.1/0.45 21.5/0.29</cell></row><row><cell>AM-Lang.+ES</cell><cell></cell><cell cols="4">35.3/0.85 32.9/0.80 28.3/0.61 25.2/0.45</cell></row><row><cell cols="6">AM-Lang.+TTT+ES (SMRD) 35.0/0.84 33.5/0.82 29.4/0.67 26.3/0.52</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43898-1_20.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Ensure: a general approach for unsupervised training of deep image reconstruction algorithms</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pramanik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jacob</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On instabilities of deep learning in image reconstruction and the potential costs of AI</title>
		<author>
			<persName><forename type="first">V</forename><surname>Antun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Renna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Adcock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl. Acad. Sci</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">48</biblScope>
			<biblScope unit="page" from="30088" to="30095" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Single-shot adaptation using score-based models for MRI reconstruction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Arvinte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jalal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Daras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dimakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Tamir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Society for Magnetic Resonance in Medicine, Annual Meeting</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Diffusion posterior sampling for general noisy inverse problems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Klasky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ryu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Klasky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Ye</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.10655</idno>
		<title level="m">Solving 3D inverse problems using pre-trained 2d diffusion models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Improving diffusion models for inverse problems using manifold constraints</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ryu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Ye</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.00941</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Score-based diffusion models for accelerated MRI</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">arXiv</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Adaptive diffusion priors for accelerated MRI reconstruction</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">U</forename><surname>Dar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.05876</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Test-time training can close the natural distribution shift performance gap in deep learning based compressed sensing</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Z</forename><surname>Darestani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Heckel</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="4754" to="4776" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Noise2recon: enabling SNR-robust MRI reconstruction with semi-supervised and self-supervised learning</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Desai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Uncertainty quantification in deep MRI reconstruction</title>
		<author>
			<persName><forename type="first">V</forename><surname>Edupuganti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mardani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vasanawala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pauly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="239" to="250" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning a variational network for reconstruction of accelerated MRI data</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hammernik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3055" to="3071" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Denoising diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6840" to="6851" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Sure-based automatic parameter selection for espirit calibration</title>
		<author>
			<persName><forename type="first">S</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Setsompop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Doneva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lustig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3423" to="3437" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Robust compressed sensing MRI with deep generative priors</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jalal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Arvinte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Daras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Dimakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Tamir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<title level="m">Adam: a method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Assessment of the generalization of learned image reconstruction and the potential for transfer learning</title>
		<author>
			<persName><forename type="first">F</forename><surname>Knoll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hammernik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kobler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Sodickson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="116" to="128" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Accelerated motion correction for MRI using score-based generative models</title>
		<author>
			<persName><forename type="first">B</forename><surname>Levac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jalal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Tamir</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.00199</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Sparse MRI: the application of compressed sensing for rapid MR imaging</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lustig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Pauly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1182" to="1195" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Noise in MRI</title>
		<author>
			<persName><forename type="first">A</forename><surname>Macovski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="494" to="497" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Deep generative adversarial networks for compressed sensing automates MRI</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mardani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.00051</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Mridata.org: an open archive for sharing MRI raw data</title>
		<author>
			<persName><forename type="first">F</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vasanawala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lustig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Int. Soc. Mag. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">PyTorch: an imperative style, high-performance deep learning library</title>
		<author>
			<persName><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Sense: sensitivity encoding for fast MRI</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Pruessmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Weiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Scheidegger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Boesiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="952" to="962" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Monte-Carlo sure: a black-box optimization of regularization parameters for general denoising algorithms</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Blu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Unser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1540" to="1554" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Signal-to-noise ratio in MRI</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Redpath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Br. J. Radiol</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">847</biblScope>
			<biblScope unit="page" from="704" to="707" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Pseudoinverse-guided diffusion models for inverse problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vahdat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mardani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=9_gsMA8MRKQ" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Generative modeling by estimating gradients of the data distribution</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Improved techniques for training score-based generative models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="12438" to="12448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Solving inverse problems in medical imaging with score-based generative models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=vaRCHVj0uGI" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Estimation of the mean of a multivariate normal distribution</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1135" to="1151" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A connection between score matching and denoising autoencoders</title>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1661" to="1674" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Measurement-conditioned denoising diffusion probabilistic model for under-sampled medical image reconstruction</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">13436</biblScope>
			<biblScope unit="page" from="655" to="664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Cham</forename><surname>Springer</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16446-0_62</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16446-0_62" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Zero-shot self-supervised learning for MRI reconstruction</title>
		<author>
			<persName><forename type="first">B</forename><surname>Yaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A H</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Akcakaya</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=085y6YPaYjP" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep ADMM-net for compressive sensing MRI</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><surname>Luxburg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Zbontar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.08839</idno>
		<title level="m">fastMRI: an open dataset and benchmarks for accelerated MRI</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
