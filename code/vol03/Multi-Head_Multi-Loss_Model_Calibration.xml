<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-Head Multi-Loss Model Calibration</title>
				<funder ref="#_CbWt7zf #_r7Z74d9">
					<orgName type="full">Australian Research Council</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Adrian</forename><surname>Galdran</surname></persName>
							<email>adrian.galdran@upf.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">BCN Medtech</orgName>
								<orgName type="institution" key="instit2">Universitat Pompeu Fabra</orgName>
								<address>
									<settlement>Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">AIML</orgName>
								<orgName type="institution" key="instit2">University of Adelaide</orgName>
								<address>
									<settlement>Adelaide</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory">Catalan Institution for Research and Advanced Studies (ICREA)</orgName>
								<address>
									<settlement>Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Johan</forename><forename type="middle">W</forename><surname>Verjans</surname></persName>
							<email>johan.verjans@adelaide.edu</email>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">AIML</orgName>
								<orgName type="institution" key="instit2">University of Adelaide</orgName>
								<address>
									<settlement>Adelaide</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory">Catalan Institution for Research and Advanced Studies (ICREA)</orgName>
								<address>
									<settlement>Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gustavo</forename><surname>Carneiro</surname></persName>
							<email>g.carneiro@surrey.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">AIML</orgName>
								<orgName type="institution" key="instit2">University of Adelaide</orgName>
								<address>
									<settlement>Adelaide</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory">Catalan Institution for Research and Advanced Studies (ICREA)</orgName>
								<address>
									<settlement>Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Miguel</forename><forename type="middle">A</forename><surname>González Ballester</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">BCN Medtech</orgName>
								<orgName type="institution" key="instit2">Universitat Pompeu Fabra</orgName>
								<address>
									<settlement>Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Surrey</orgName>
								<address>
									<settlement>Guildford</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory">Catalan Institution for Research and Advanced Studies (ICREA)</orgName>
								<address>
									<settlement>Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multi-Head Multi-Loss Model Calibration</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="108" to="117"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">ECE0E6F415EB3D69B2FCCB14A0F2EC58</idno>
					<idno type="DOI">10.1007/978-3-031-43898-1_11</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-23T22:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Model Calibration • Uncertainty Quantification</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Delivering meaningful uncertainty estimates is essential for a successful deployment of machine learning models in the clinical practice. A central aspect of uncertainty quantification is the ability of a model to return predictions that are well-aligned with the actual probability of the model being correct, also known as model calibration. Although many methods have been proposed to improve calibration, no technique can match the simple, but expensive approach of training an ensemble of deep neural networks. In this paper we introduce a form of simplified ensembling that bypasses the costly training and inference of deep ensembles, yet it keeps its calibration capabilities. The idea is to replace the common linear classifier at the end of a network by a set of heads that are supervised with different loss functions to enforce diversity on their predictions. Specifically, each head is trained to minimize a weighted Cross-Entropy loss, but the weights are different among the different branches. We show that the resulting averaged predictions can achieve excellent calibration without sacrificing accuracy in two challenging datasets for histopathological and endoscopic image classification. Our experiments indicate that Multi-Head Multi-Loss classifiers are inherently well-calibrated, outperforming other recent calibration techniques and even challenging Deep Ensembles' performance. Code to reproduce our experiments can be found at https://github.com/ agaldran/mhml_calibration.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction and Related Work</head><p>When training supervised computer vision models, we typically focus on improving their predictive performance, yet equally important for safety-critical tasks is their ability to express meaningful uncertainties about their own predictions <ref type="bibr" target="#b5">[4]</ref>. In the context of machine learning, we often distinguish two types of uncertainties: epistemic and aleatoric <ref type="bibr" target="#b14">[13]</ref>. Briefly speaking, epistemic uncertainty arises from imperfect knowledge of the model about the problem it is trained to solve, whereas aleatoric uncertainty describes ignorance regarding the data used for learning and making predictions. For example, if a classifier has learned to predict the presence of cancerous tissue on a colon histopathology, and it is tasked with making a prediction on a breast biopsy it may display epistemic uncertainty, as it was never trained for this problem <ref type="bibr" target="#b22">[21]</ref>. Nonetheless, if we ask the model about a colon biopsy with ambiguous visual content, i.e. a hard-todiagnose image, then it could express aleatoric uncertainty, as it may not know how to solve the problem, but the ambiguity comes from the data. This distinction between epistemic and aleatoric is often blurry, because the presence of one of them does not imply the absence of the other <ref type="bibr" target="#b13">[12]</ref>. Also, under strong epistemic uncertainty, aleatoric uncertainty estimates can become unreliable <ref type="bibr" target="#b32">[31]</ref>.</p><p>Producing good uncertainty estimates can be useful, e.g. to identify test samples where the model predicts with little confidence and which should be reviewed <ref type="bibr">[1]</ref>. A straightforward way to report uncertainty estimates is by interpreting the output of a model (maximum of its softmax probabilities) as its predictive confidence. When this confidence aligns with the actual accuracy we say that the model is calibrated <ref type="bibr" target="#b9">[8]</ref>. Model calibration has been studied for a long time, with roots going back to the weather forecasting field <ref type="bibr" target="#b4">[3]</ref>. Initially applied mostly for binary classification systems <ref type="bibr" target="#b8">[7]</ref>, the realization that modern neural networks tend to predict over-confidently <ref type="bibr" target="#b11">[10]</ref> has led to a surge of interest in recent years <ref type="bibr" target="#b9">[8]</ref>. Broadly speaking, one can attempt to promote calibration during training, by means of a post-processing stage, or by model ensembling.</p><p>Training-Time Calibration. Popular training-time approaches consist of reducing the predictive entropy by means of regularization <ref type="bibr" target="#b12">[11]</ref>, e.g. Label Smoothing <ref type="bibr" target="#b26">[25]</ref> or MixUp <ref type="bibr" target="#b31">[30]</ref>, or loss functions that smooth predictions <ref type="bibr" target="#b27">[26]</ref>. These techniques often rely on correctly tuning a hyper-parameter controlling the trade-off between discrimination ability and confidence, and can easily achieve better calibration at the expense of decreasing predictive performance <ref type="bibr" target="#b23">[22]</ref>. Examples of medical image analysis works adopting this approach are Difference between Confidence and Accuracy regularization <ref type="bibr" target="#b21">[20]</ref> for medical image diagnosis, or Spatially-Varying and Margin-Based Label Smoothing <ref type="bibr" target="#b15">[14,</ref><ref type="bibr" target="#b28">27]</ref>, which extend and improve Label Smoothing for biomedical image segmentation tasks.</p><p>Post-Hoc Calibration. Post-hoc calibration techniques like Temperature Scaling <ref type="bibr" target="#b11">[10]</ref> and its variants <ref type="bibr" target="#b7">[6,</ref><ref type="bibr" target="#b16">15]</ref> have been proposed to correct over or underconfident predictions by applying simple monotone mappings (fitted on a heldout subset of the training data) on the output probabilities of the model. Their greatest shortcoming is the dependence on the i.i.d. assumption implicitly made when using validation data to learn the mapping: these approaches suffer to generalize to unseen data <ref type="bibr" target="#b29">[28]</ref>. Other than that, these techniques can be combined with training-time methods and return compounded performance improvements.</p><p>Model Ensembling. A third approach to improve calibration is to aggregate the output of several models, which are trained beforehand so that they have some diversity in their predictions <ref type="bibr" target="#b6">[5]</ref>. In deep learning, model ensembles are considered to be the most successful method to generate meaningful uncertainty estimates <ref type="bibr" target="#b17">[16]</ref>. An obvious weakness of deep ensembles is the requirement of training and then keeping for inference purposes a set of models, which results in a computational overhead that can be considerable for larger architectures. Examples of applying ensembling in medical image computing include <ref type="bibr" target="#b18">[17,</ref><ref type="bibr" target="#b25">24]</ref>.</p><p>In this work we achieve model calibration by means of multi-head models trained with diverse loss functions. In this sense, our approach is closest to some recent works on multi-output architectures like <ref type="bibr" target="#b22">[21]</ref>, where a multi-branch CNN is trained on histopathological data, enforcing specialization of the different heads by backpropagating gradients through branches with the lowest loss. Compared to our approach, ensuring correct gradient flow to avoid dead heads requires ad-hoc computational tricks <ref type="bibr" target="#b22">[21]</ref>; in addition, no analysis on model calibration on in-domain data or aleatoric uncertainty was developed, focusing instead on anomaly detection. Our main contribution is a multi-head model that I) exploits multi-loss diversity to achieve greater confidence calibration than other learning-based methods, while II) avoiding the use of training data to learn post-processing mappings as most post-hoc calibration methods do, and III) sidesteping the computation overhead of deep ensembles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Calibrated Multi-Head Models</head><p>In this section we formally introduce multi-head models <ref type="bibr" target="#b20">[19]</ref>, and justify the need for enforcing diversity on them. Detailed derivations of all the results below are provided in the online supplementary materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Multi-Head Ensemble Diversity</head><p>Consider a K-class classification problem, and a neural network U θ taking an image x and mapping it onto a representation U θ (x) ∈ R N , which is linearly transformed by f into a logits vector z = f (U θ (x)) ∈ R K . This is then mapped into a vector of probabilities p ∈ [0, 1] K by a softmax operation p = σ(z), where p j = e zj / i e zi . If the label of x was y ∈ {1, ..., K}, we can measure the error associated to prediction p with the cross-entropy loss L CE (p, y) = -log(p y ).</p><p>We now wish to implement a multi-head ensemble model like the one shown in Fig. <ref type="figure" target="#fig_0">1</ref>. For this, we replace f by M different branches f 1 , ..., f M , each of them still taking the same input but mapping it to different logits z m = f m (U θ (x)). The resulting probability vectors p m = σ(z m ) are then averaged to obtain a final prediction p μ = (1/M ) m p m . We are interested in backpropagating the loss L CE (p μ , y) = -log(p μ y ) to find the gradient at each branch, ∇ z m L CE (p μ , y). Property 1: For the M-head classifier in Fig. <ref type="figure" target="#fig_0">1</ref>, the derivative of the crossentropy loss at head f m with respect to z m is given by where y is a one-hot representation of the label y.</p><formula xml:id="formula_0">∇ z m L CE (p μ , y) = p m y i p i y (p μ -y),<label>(1)</label></formula><p>From Eq. (1) we see that the gradient in branch m will be scaled depending on how much probability mass p m y is placed by f m on the correct class relative to the total mass placed by all heads. In other words, if every head learned to produce a similar prediction (not necessarily correct) for a particular sample, then the optimization process of this network would result in the same updates for all of them. As a consequence, diversity in the predictions that make up the output p μ of the network would be damaged.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Multi-Head Multi Loss Models</head><p>In view of the above, one way to obtain more diverse gradient updates in a multihead model during training could be to supervise each head with a different loss function. To this end, we will apply the weighted cross-entropy loss, given by L ω -CE (p, y) = -ω y log(p μ y ), where ω ∈ R K is a weight vector. In our case, we assign to each head a different weight vector ω m (as detailed below), in such a way that a different loss function L ω m -CE will supervise the intermediate output of each branch f m , similar to deep supervision strategies <ref type="bibr" target="#b19">[18]</ref> but enforcing diversity. The total loss of the complete model is the addition of the per-head losses and the overall loss acting on the average prediction:</p><formula xml:id="formula_1">L MH (p, y) = L CE (p μ , y) + M m=1 L ω m -CE (p m , y),<label>(2)</label></formula><p>where p = (p 1 , ..., p M ) is an array collecting all the predictions the network makes. Since L ω -CE results from just multiplying by a constant factor the conventional CE loss, we can readily calculate the gradient of L MH at each branch.</p><p>Property 2: For the Multi-Loss Multi-Head classifier shown in Fig. <ref type="figure" target="#fig_0">1</ref>, the gradient of the Multi-Head loss L MH at branch f m is given by:</p><formula xml:id="formula_2">∇ z m L MH (p, y) = ω m y + p m y i p i y (p μ -y).<label>(3)</label></formula><p>Note that having equal weight vectors in all branches fails to break the symmetry in the scenario of all heads making similar predictions. Indeed, if for any two given heads f mi , f mj we have ω mi = ω mj and p mi ≈ p mj , i.e. p m ≈ p μ ∀m, then the difference in norm of the gradients of two heads would be:</p><formula xml:id="formula_3">∇ z m i L MH (p, y) -∇ z m j L MH (p, y) 1 ≈ |ω mi y -ω mj y | • p μ -y 1 = 0.<label>(4)</label></formula><p>It follows that we indeed require a different weight in each branch. In this work, we design a weighting scheme to enforce the specialization of each head into a particular subset of the categories {c 1 , ..., c K } in the training set. We first assume that the multi-head model has less branches than the number of classes in our problem, i.e. M ≤ K, as otherwise we would need to have different branches specializing in the same category. In order to construct the weight vector ω m , we associate to branch f m a subset of N/K categories, randomly selected, for specialization, and these are weighed with ω m j = K. Then, the remaining categories in ω m receive a weight of ω m j = 1/K. For example, in a problem with 4 categories and 2 branches, we could have</p><formula xml:id="formula_4">ω 1 = [2, 1 /2, 2, 1 /2] and ω 2 = [ 1 /2, 2, 1 /2, 2].</formula><p>If N is not divisible by K, the reminder categories are assigned for specialization to random branches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Model Evaluation</head><p>When measuring model calibration, the standard approach relies on observing the test set accuracy at different confidence bands B. For example, taking all test samples that are predicted with a confidence around c = 0.8, a well-calibrated classifier would show an accuracy of approximately 80% in this test subset. This can be quantified by the Expected Calibration Error (ECE), given by:</p><formula xml:id="formula_5">ECE = N s=1 |B s | N |acc(B s ) -conf(B s )|,<label>(5)</label></formula><p>where s B s form a uniform partition of the unit interval, and acc(B s ), conf(B s ) are accuracy and average confidence (maximum softmax value) for test samples predicted with confidence in B s .</p><p>In practice, the ECE alone is not a good measure in terms of practical usability, as one can have a perfectly ECE-calibrated model with no predictive power <ref type="bibr" target="#b30">[29]</ref>. A binary classifier in a balanced dataset, randomly predicting always one class with c = 0.5 + confidence, has a perfect calibration and 50% accuracy. Proper Scoring Rules like Negative Log-Likelihood (NLL) or the Brier score are alternative uncertainty quality metrics <ref type="bibr" target="#b10">[9]</ref> that capture both discrimination ability and calibration: a model must be both accurate and calibrated to achieve a low PSR value. We report NLL, and also standard Accuracy, which contrary to ECE can be high even for badly-calibrated models. Finally, we show as summary metric the average rank when aggregating rankings of ECE, NLL, and accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Results</head><p>We now describe the data we used for experimentation, carefully analyze performance for each dataset, and end up with a discussion of our findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets and Architectures</head><p>We conducted experiments on two datasets: 1) the Chaoyang dataset<ref type="foot" target="#foot_0">1</ref> , which contains colon histopathology images. It has 6,160 images unevenly distributed in 4 classes (29%, 19%, 37%, 15%), with some amount of label ambiguity, reflecting high aleatoric uncertainty. As a consequence, the best model in the original reference <ref type="bibr" target="#b33">[32]</ref>, applying specific techniques to deal with label noise, achieved an accuracy of 83.4%. 2) Kvasir<ref type="foot" target="#foot_1">2</ref> , a dataset for the task of endoscopic image classification. The annotated part of this dataset contains 10,662 images, and it represents a challenging classification problem due a high amount of classes <ref type="bibr" target="#b24">(23)</ref> and highly imbalanced class frequencies <ref type="bibr" target="#b3">[2]</ref>. For the sake of readability we do not show measures of dispersion, but we add them to the supplementary material (Appendix B), together with further experiments on other datasets.</p><p>We implement the proposed approach by optimizing several popular neural network architectures, namely a common ResNet50 and two more recent models: a ConvNeXt <ref type="bibr" target="#b24">[23]</ref> and a Swin-Transformer <ref type="bibr" target="#b24">[23]</ref>. All models are trained for 50 epochs, which was observed enough for convergence, using Stochastic Gradient Descent with a learning rate of l = 1e-2. Code to reproduce our results and hyperparameter specifications are shared at https://github.com/agaldran/ mhml_calibration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Performance Analysis</head><p>Notation: We train three different multi-head classifiers: 1) a 2-head model where each head optimizes for standard (unweighted) CE, referred to as 2HSL (2 Heads-Single Loss); 2) a 2-head model but with each head minimizing a differently weighed CE loss as described in Sect. 2.2. We call this model 2HML (2 Heads-Multi Loss)); 3) Finally, we increase the number of heads to four, and we refer to this model as 4HML. For comparison, we include a standard singleloss one-head classifier (SL1H), plus models trained with Label Smoothing (LS <ref type="bibr" target="#b26">[25]</ref>), Margin-based Label Smoothing (MbLS <ref type="bibr" target="#b23">[22]</ref>), MixUp <ref type="bibr" target="#b31">[30]</ref>, and using the DCA loss <ref type="bibr" target="#b21">[20]</ref>. We also show the performance of Deep Ensembles (D-Ens <ref type="bibr" target="#b17">[16]</ref>). We analyze the impact of Temperature Scaling <ref type="bibr" target="#b11">[10]</ref> in Appendix A.</p><p>What we expect to see: Multi-Head Multi-Loss models should achieve a better calibration (low ECE) than other learning-based methods, ideally approaching Deep Ensembles calibration. We also expect to achieve good calibration without sacrificing predictive performance (high accuracy). Both goals would be reflected jointly by a low NLL value, and by a better aggregated ranking. Finally we would ideally observe improved performance as we increase the diversity (comparing 2HSL to 2HML) and as we add heads (comparing 2HML to 4HML).</p><p>Chaoyang: In Table <ref type="table" target="#tab_0">1</ref> we report the results on the Chaoyang dataset. Overall, accuracy is relatively low, since this dataset is challenging due to label ambiguity, and therefore calibration analysis of aleatoric uncertainty becomes meaningful here. As expected, we see how Deep Ensembles are the most accurate method, also with the lowest NLL, for two out of the three considered networks. However, we also observe noticeable differences between other learning-based calibration techniques and multi-head architectures. Namely, all other calibration methods achieve lower ECE than the baseline (SL1H) model, but at the cost of a reduced accuracy. This is actually captured by NLL and rank, which become much higher for these approaches. In contrast, 4HML achieves the second rank in two architectures, only behind Deep Ensembles when using a ResNet50 and a Swin-Transformer, and above any other 2HML with a ConvNeXt, even outperforming Deep Ensembles in this case. Overall, we can see a pattern: multi-loss multi-head models appear to be extremely well-calibrated (low ECE and NLL values) without sacrificing accuracy, and as we diversify the losses and increase the number of heads we tend to improve calibration. Kvasir: Next, we show in Table <ref type="table" target="#tab_1">2</ref> results for the Kvasir dataset. Deep Ensembles again reach the highest accuracy and excellent calibration. Interestingly, methods that smooth labels (LS, MbLS, MixUP) show a strong degradation in calibration and their ECE is often twice the ECE of the baseline SL1H model. We attribute this to class imbalance and the large number of categories: smoothing labels might be ineffective in this scenario. Note that models minimizing the DCA loss do manage to bring the ECE down, although by giving up accuracy. In contrast, all multi-head models improve calibration while maintaining accuracy. Remarkably, 4HML obtains lower ECE than Deep Ensembles in all cases. Also, for two out of the three architectures 4HML ranks as the best method, and for the other one 2HML reaches the best ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>Multi-Head Multi-Loss networks are classifiers with enhanced calibration and no degradation of predictive performance when compared to their single-head counterparts. This is achieved by simultaneously optimizing several output branches, each one minimizing a differently weighted Cross-Entropy loss. Weights are complementary, ensuring that each branch is rewarded for becoming specialized in a subset of the original data categories. Comprehensive experiments on two challenging datasets with three different neural networks show that Multi-Head Multi-Loss models consistently outperform other learning-based calibration techniques, matching and sometimes surpassing the calibration of Deep Ensembles.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. A multi-head multi-loss model with M =2 heads. An image x goes through a neural network U θ and then is linearly transformed by M heads {f m } M m=1 , followed by softmax operations σ, into probability vectors {p m } M m=1 . The final loss LMH is the sum of per-head weighted-CE losses Lω m -CE(p m , y) and the CE loss LCE(p μ , y) of the average prediction p μ = μ(p 1 , ..., p m ). We modify the weights ω m between branches to achieve more diverse gradients during training.</figDesc><graphic coords="4,58,47,53,96,335,89,125,74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Results on the Chaoyang dataset with different architectures and strategies. For each model, best and second best ranks are marked.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Results on the Kvasir dataset with different architectures and strategies. For each model, best and second best ranks are marked.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://bupt-ai-cz.github.io/HSA-NRL/.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://datasets.simula.no/hyper-kvasir/.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. This work was supported by a <rs type="grantName">Marie Sk lodowska-Curie Fellowship (No 892297</rs>) and by <rs type="funder">Australian Research Council</rs> grants (<rs type="grantNumber">DP180103232</rs> and <rs type="grantNumber">FT190100525</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_CbWt7zf">
					<idno type="grant-number">DP180103232</idno>
					<orgName type="grant-name">Marie Sk lodowska-Curie Fellowship (No 892297</orgName>
				</org>
				<org type="funding" xml:id="_r7Z74d9">
					<idno type="grant-number">FT190100525</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43898-1_11.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">D-Ens</forename></persName>
		</author>
		<idno>82.19 2.42 46.64 1.0</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">D-Ens</forename></persName>
		</author>
		<idno>90.76 3.83 32.09 2.3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Failure detection in medical image classification: a reality check and benchmarking testbed</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bernhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">D S</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Mach. Learn. Res</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">HyperKvasir, a comprehensive multi-class image and video dataset for gastrointestinal endoscopy</title>
		<author>
			<persName><forename type="first">H</forename><surname>Borgli</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41597-020-00622-y</idno>
		<ptr target="https://doi.org/10.1038/s41597-020-00622-y" />
	</analytic>
	<monogr>
		<title level="j">Sci. Data</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">283</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Verification of forecasts expressed in terms of probability</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Brier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mon. Weather Rev</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="1950">1950</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Tackling prediction uncertainty in machine learning for healthcare</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chua</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41551-022-00988-x</idno>
		<ptr target="https://doi.org/10.1038/s41551-022-00988-x" />
	</analytic>
	<monogr>
		<title level="j">Nature Biomed. Eng</title>
		<imprint>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2022-12">December 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Ensemble methods in machine learning</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Dietterich</surname></persName>
		</author>
		<idno type="DOI">10.1007/3-540-45014-9_1</idno>
		<ptr target="https://doi.org/10.1007/3-540-45014-9_1" />
	</analytic>
	<monogr>
		<title level="j">Multiple Classifier Systems</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Local temperature scaling for probability calibration</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Niethammer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Analysis and Comparison of Classification Metrics</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ferrer</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2209.05355</idno>
		<imprint>
			<date type="published" when="2022-09">September 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Classifier Calibration: How to assess and improve predicted class probabilities: a survey</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Filho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Perello-Nieto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Santos-Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Flach</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2112.10327</idno>
		<imprint>
			<date type="published" when="2021-12">December 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Strictly proper scoring rules, prediction, and estimation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gneiting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Raftery</surname></persName>
		</author>
		<idno type="DOI">10.1198/016214506000001437</idno>
		<ptr target="https://doi.org/10.1198/016214506000001437" />
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="issue">477</biblScope>
			<biblScope unit="page" from="359" to="378" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">On calibration of modern neural networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pleiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">A stitch in time saves nine: a train-time regularizing loss for improved neural network calibration</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hebbalaguppe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Prakash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Madan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Arora</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Quantifying Aleatoric and Epistemic Uncertainty in Machine Learning: Are Conditional Entropy and Mutual Information Appropriate Measures?</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hüllermeier</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2209.03302</idno>
		<imprint>
			<date type="published" when="2022-09">September 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Aleatoric and epistemic uncertainty in machine learning: an introduction to concepts and methods</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hüllermeier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Waegeman</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10994-021-05946-3</idno>
		<ptr target="https://doi.org/10.1007/s10994-021-05946-3" />
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="457" to="506" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Spatially varying label smoothing: capturing uncertainty from expert annotations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-78191-0_52</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-78191-0_52" />
	</analytic>
	<monogr>
		<title level="j">IPMI</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Beyond temperature scaling: Obtaining well-calibrated multi-class probabilities with Dirichlet calibration</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Perello Nieto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kängsepp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Silva Filho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Flach</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Simple and scalable predictive uncertainty estimation using deep ensembles</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Orthogonal ensemble networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Larrazabal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dolz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ferrante</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87199-4_56</idno>
		<idno>978-3-030-87199-4_56</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="j">MICCAI</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deeply-supervised nets</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AISTATS</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Why M Heads are Better than One: Training a Diverse Ensemble of Deep Networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Purushwalkam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cogswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.</idno>
		<ptr target="https://doi.org/10.48550/arXiv.1511.06314" />
		<imprint>
			<date type="published" when="2015-11">November 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Improved trainable calibration method for neural networks on medical imaging classification</title>
		<author>
			<persName><forename type="first">G</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jacobs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference (BMVC)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Predictive uncertainty estimation for out-of-distribution detection in digital pathology</title>
		<author>
			<persName><forename type="first">J</forename><surname>Linmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Elfwing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Van Der Laak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Litjens</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.media.2022.102655</idno>
		<ptr target="https://doi.org/10.1016/j.media.2022.102655" />
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">The devil is in the margin: marginbased label smoothing for network calibration</title>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ben Ayed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Galdran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dolz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Swin transformer: hierarchical vision transformer using shifted windows</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICCV48922.2021.00986</idno>
		<ptr target="https://doi.org/10.1109/ICCV48922.2021.00986" />
	</analytic>
	<monogr>
		<title level="j">ICCV</title>
		<imprint>
			<date type="published" when="2021-10">October 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Test-time adaptation with calibration of medical image classification nets for label distribution shift</title>
		<author>
			<persName><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16437-8_30</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16437-8_30" />
	</analytic>
	<monogr>
		<title level="j">MICCAI</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">When does label smoothing help?</title>
		<author>
			<persName><forename type="first">R</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Calibrating Deep Neural Networks using Focal Loss</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mukhoti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kulharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sanyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Golodetz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dokania</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Calibrating Segmentation Networks with Margin-based Label Smoothing</title>
		<author>
			<persName><forename type="first">B</forename><surname>Murugesan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Galdran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">B</forename><surname>Ayed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dolz</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2209.09641</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2209.09641" />
		<imprint>
			<date type="published" when="2022-09">September 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Can you trust your model&apos;s uncertainty? Evaluating predictive uncertainty under dataset shift</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ovadia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Understanding metric-related pitfalls in image analysis validation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Reinke</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2302.01790</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2302.01790" />
		<imprint>
			<date type="published" when="2023-02">February 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">On mixup training: improved calibration and predictive uncertainty for deep neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Thulasidasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chennupati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Bilmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Michalak</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A deeper look into aleatoric and epistemic uncertainty disentanglement</title>
		<author>
			<persName><forename type="first">M</forename><surname>Valdenegro-Toro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshops</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Hard sample aware noise robust learning for histopathology image classification</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jin</surname></persName>
		</author>
		<idno type="DOI">10.1109/TMI.2021.3125459</idno>
		<ptr target="https://doi.org/10.1109/TMI.2021.3125459" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="881" to="894" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
