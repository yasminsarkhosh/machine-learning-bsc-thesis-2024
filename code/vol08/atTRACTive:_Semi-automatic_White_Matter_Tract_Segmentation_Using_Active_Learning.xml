<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Robin</forename><surname>Peretzke</surname></persName>
							<email>robin.peretzke@dkfz-heidelberg.de</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Division of Medical Image Computing (MIC)</orgName>
								<orgName type="department" key="dep2">German Cancer Research Center (DKFZ)</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Medical Faculty Heidelberg</orgName>
								<orgName type="institution">Heidelberg University</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Klaus</forename><forename type="middle">H</forename><surname>Maier-Hein</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Division of Medical Image Computing (MIC)</orgName>
								<orgName type="department" key="dep2">German Cancer Research Center (DKFZ)</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Medical Faculty Heidelberg</orgName>
								<orgName type="institution">Heidelberg University</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">German Cancer Consortium (DKTK)</orgName>
								<address>
									<addrLine>Partner Site Heidelberg</addrLine>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">National Center for Tumor Diseases (NCT)</orgName>
								<orgName type="institution">NCT Heidelberg</orgName>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="laboratory">Pattern Analysis and Learning Group</orgName>
								<orgName type="institution">Heidelberg University Hospital</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff6">
								<orgName type="department">HIDSS4Health -Helmholtz Information and Data Science School for Health</orgName>
								<address>
									<settlement>Karlsruhe, Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff7">
								<orgName type="department">Faculty of Mathematics and Computer Science</orgName>
								<orgName type="institution">Heidelberg University</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jonas</forename><surname>Bohn</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Division of Medical Image Computing (MIC)</orgName>
								<orgName type="department" key="dep2">German Cancer Research Center (DKFZ)</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">National Center for Tumor Diseases (NCT)</orgName>
								<orgName type="institution">NCT Heidelberg</orgName>
							</affiliation>
							<affiliation key="aff8">
								<orgName type="department">Faculty of Bioscience</orgName>
								<orgName type="institution">Heidelberg University</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yannick</forename><surname>Kirchhoff</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Division of Medical Image Computing (MIC)</orgName>
								<orgName type="department" key="dep2">German Cancer Research Center (DKFZ)</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff6">
								<orgName type="department">HIDSS4Health -Helmholtz Information and Data Science School for Health</orgName>
								<address>
									<settlement>Karlsruhe, Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff7">
								<orgName type="department">Faculty of Mathematics and Computer Science</orgName>
								<orgName type="institution">Heidelberg University</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Saikat</forename><surname>Roy</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Division of Medical Image Computing (MIC)</orgName>
								<orgName type="department" key="dep2">German Cancer Research Center (DKFZ)</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff7">
								<orgName type="department">Faculty of Mathematics and Computer Science</orgName>
								<orgName type="institution">Heidelberg University</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sabrina</forename><surname>Oberli-Palma</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Division of Medical Image Computing (MIC)</orgName>
								<orgName type="department" key="dep2">German Cancer Research Center (DKFZ)</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Daniela</forename><surname>Becker</surname></persName>
							<affiliation key="aff9">
								<orgName type="department">Department of Neurosurgery</orgName>
								<orgName type="institution">Heidelberg University Hospital</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff10">
								<orgName type="institution" key="instit1">IU</orgName>
								<orgName type="institution" key="instit2">International University of Applied Sciences</orgName>
								<address>
									<settlement>Erfurt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pavlina</forename><surname>Lenga</surname></persName>
							<affiliation key="aff9">
								<orgName type="department">Department of Neurosurgery</orgName>
								<orgName type="institution">Heidelberg University Hospital</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Peter</forename><surname>Neher</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Division of Medical Image Computing (MIC)</orgName>
								<orgName type="department" key="dep2">German Cancer Research Center (DKFZ)</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">National Center for Tumor Diseases (NCT)</orgName>
								<orgName type="institution">NCT Heidelberg</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Partnership Between DKFZ</orgName>
								<orgName type="institution">University Medical Center Heidelberg</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="237" to="246"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">38806CA024D855C144920B5C01E120FF</idno>
					<idno type="DOI">10.1007/978-3-031-43993-3_23</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-23T22:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>DWI and tractography</term>
					<term>Active learning</term>
					<term>Tract segmentation</term>
					<term>Fiber tracking</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Accurately identifying white matter tracts in medical images is essential for various applications, including surgery planning and tract-specific analysis. Supervised machine learning models have reached state-of-the-art solving this task automatically. However, these models are primarily trained on healthy subjects and struggle with strong anatomical aberrations, e.g. caused by brain tumors. This limitation makes them unsuitable for tasks such as preoperative planning, wherefore time-consuming and challenging manual delineation of the target tract is typically employed. We propose semi-automatic entropy-based active learning for quick and intuitive segmentation of white matter tracts from whole-brain tractography consisting of millions of streamlines. The method is evaluated on 21 openly available healthy subjects from the Human Connectome Project and an internal dataset of ten neurosurgical cases. With only a few annotations, the proposed approach enables segmenting tracts on tumor cases comparable to healthy subjects (dice = 0.71), while the performance of automatic methods, like TractSeg dropped substantially (dice = 0.34) in comparison to healthy subjects. The method is implemented as a prototype named atTRACTive in the freely available software MITK Diffusion. Manual experiments on tumor data showed higher efficiency due to lower segmentation times compared to traditional ROI-based segmentation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Diffusion-weighted MRI enables visualization of brain white matter structures. It can be used to generate tractography data consisting of millions of synthetic fibers or streamlines for a single subject stored in a tractogram that approximate groups of biological axons <ref type="bibr" target="#b0">[1]</ref>. Many applications require streamlines to be segmented into individual tracts corresponding to known anatomy. Tract segmentations are used for a variety of tasks, including surgery planning or tract-specific analysis of psychiatric and neurodegenerative diseases <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b16">17]</ref>.</p><p>Automated methods built on supervised machine learning algorithms have attained the current state-of-the-art in segmenting tracts <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b20">21]</ref>. Those are trained using various features, either directly from diffusion data in voxel space or from tractography data. Models may output binary masks containing the target white matter tract, or perform a classification on streamline level. However, such algorithms are commonly trained on healthy subjects and have shown issues in processing cases with anatomical abnormalities, e.g. brain tumors <ref type="bibr" target="#b19">[20]</ref>. Consequently, they are unsuitable for tasks such as preoperative planning of neurosurgical patients, as they may produce incomplete or false segmentations, which could have harmful consequences during surgery <ref type="bibr" target="#b18">[19]</ref>. Additionally, supervised techniques are restricted to fixed sets of predetermined tracts and are trained on substantial volumes of hard-to-generate pre-annotated reference data.</p><p>Manual methods are still frequently used for all cases not yet covered by automatic methods, such as certain populations like children, animal species, new acquisition schemes or special tracts of interests. Experts determine regions of interest (ROI) in areas where a particular tract is supposed to traverse or through which it must not pass, and segmentations can be accomplished either (1) by virtually excluding and maintaining streamlines from tractography according to the defined ROI or (2) by using these regions for tract-specific ROI-based tractography. Both approaches require a similar effort, although the latter is more commonly used. The correct definition of ROIs can be time-consuming and challenging, especially for inexperienced users. Despite these limitations, ROI-based techniques are currently without vivid alternatives for segmenting tracts that automated methods cannot handle.</p><p>Methods to simplify tract segmentation have been proposed before. Clustering approaches were developed to reduce complexity of large amounts of streamlines in the input data <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6]</ref>. Tractome is a tool that allows interactive segmentation of such clusters by representing them as single streamlines that can interactively be included or excluded from the target tract <ref type="bibr" target="#b13">[14]</ref>. Although the approach has shown promise, it has not yet supplanted conventional ROIbased techniques.</p><p>We propose a novel semi-automated tract segmentation method for efficient and intuitive identification of arbitrary white matter tracts. The method employs entropy-based active learning of a random forest classifier trained on features of the dissimilarity representation <ref type="bibr" target="#b12">[13]</ref>. Active learning has been utilized for several cases in the medical domain, while it has never been applied in the context of tract segmentation <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b15">16]</ref>. It reduces manual efforts by iteratively identifying the most informative or ambiguous samples, here, streamlines, during classifier training, to be annotated by a human expert. The method is implemented as the tool atTRACTive in MITK Diffusion<ref type="foot" target="#foot_0">1</ref> , enabling researchers to quickly and intuitively segment tracts in pathological datasets or other situations not covered by automatic techniques, simply by annotating a few but informative streamlines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Binary Classification for Tract Segmentation</head><p>To create a segmentation of a white matter tract from an individual wholebrain tractogram T , streamlines which not belong to this tract must be excluded from the tractography data. This is formulated as a binary classification of a streamline s ∈ T , depending on whether it belongs to the target tract t (see Fig. <ref type="figure" target="#fig_0">1</ref> for a brief summary of the nomenclature of this work)</p><formula xml:id="formula_0">e(s) = 1, s ∈ t 0, else . (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>To perform the classification, supervised models have been trained on various features representing the data. We choose the dissimilarity representation proposed by Olivetti to classify streamlines, which has shown well performance and can be computed quickly for arbitrary data <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b12">13]</ref>. A number of n streamlines, in this case, n = 100, are used as prototypes forming a reference system of the entire tractogram. A streamline is expressed through a feature vector relative to this reference system. Briefly, a single streamline s = [x 1 , ..., x m ], i.e. a polyline containing varying numbers of ordered 3D points</p><formula xml:id="formula_2">x i = [x i , y i , z i ] ∈ R 3 , i = 1.</formula><p>..m, is described by its minimum average direct flip distance d MDF to each prototype <ref type="bibr" target="#b4">[5]</ref>. The d MDF of a streamline s a to a prototype p a is defined as</p><formula xml:id="formula_3">d MDF (p a , s a ) = min((d direct (p a , s a ), d f lipped (p a , s a ))<label>(2)</label></formula><p>where</p><formula xml:id="formula_4">d direct (p a , s a ) = 1 m m i=1 ||x pa i -x sa i || 2</formula><p>with m being the number of 3D points of the streamlines and</p><formula xml:id="formula_5">d flip (p a , s a ) = 1 m m i=1 ||x pa i -x sa m-i+1 || 2 .</formula><p>Additionally to d MDF , the endpoint distance d END between a streamline and a prototype is calculated, which is equal to d MDF , besides, only the start points x 1 and endpoints x m of the streamline and prototype are respected for the calculation <ref type="bibr" target="#b2">[3]</ref>. Hence, features for a single streamline are represented by a vector twice the number of prototypes. In order to calculate these, all streamlines must have the same number of 3D points and are thus resampled to m = 40 points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Active Learning for Tract Selection</head><p>Commonly, for training classifiers, large amounts of annotated and potentially redundant data are used, leading to high annotation efforts and long training times. Active learning reduces both by training machine learning models with only small and iteratively updated labeled subsets of the originally unlabeled data. The proposed workflow is initialized, as shown in Fig. <ref type="figure" target="#fig_1">2(a)</ref>, by presenting a randomly selected subset S rand = [s 1 , ..., s n ] of n = streamlines from an individual whole-brain tractogram to an expert for annotation, where S rand ⊂ T . Subsequently, the dissimilarity representation is calculated using initially 100 prototypes (Fig. <ref type="figure" target="#fig_1">2(b</ref>)), and a classifier is trained, in this case, a random forest. Within completing the training, which takes only a few seconds, the classifier predicts whether the remaining unlabeled streamlines belong to the target tract. Based on the predicted class labels, the target tract is presented (Fig. <ref type="figure" target="#fig_1">2(c)</ref>). Furthermore, the class probabilities p(s) determined by the random forest are used to estimate its uncertainty with respect to each sample by calculating the entropy E</p><formula xml:id="formula_6">E(s i ) = n i=1 p(s i ) log p(s i ).<label>(3)</label></formula><p>Next, a subset S Emax of streamlines with the highest entropy or uncertainty is selected to be labeled by the expert and is added to the training data (Fig. <ref type="figure" target="#fig_1">2 (c</ref>)) <ref type="bibr" target="#b7">[8]</ref>. Additionally, these streamlines are utilized as adaptive prototypes until a threshold of n = 100 adaptive prototype streamlines is reached.</p><p>Since the model selects ambiguous streamlines in the target tract region, utilizing them as supplementary prototypes improves feature expressiveness in this region of interest. This process is repeated iteratively until the expert accepts the prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data</head><p>The proposed technique was tested on a healthy-subject dataset and on a dataset containing tumor cases. The first comprises 21 subjects of the human connectome project (HCP) that were used for testing the automated methods TractSeg and Classifyber <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b17">18]</ref>. Visual examinations revealed false-negatives in the reference tracts, meaning that some streamlines that belong to the target tract were not included in the reference. These false-negatives did not affect the generation of accurate segmentation masks, since most false-negatives are occupied by true-positive streamlines, but negatively influenced our experiments. To reduce false-negatives, the reference segmentation mask as well as start-and end-region segmentations were used to reassign streamlines from the tractogram using two criteria: Streamlines must be inside the binary reference segmentation (1) and start and end in the assigned regions <ref type="bibr" target="#b1">(2)</ref>. As the initial size of ten million streamlines is computationally challenging and unsuitable for most tools, all tractograms were randomly down-sampled to one million streamlines. We focused on the left optic radiation (OR), the left cortico-spinal tract (CST), and the left arcuate-fasciculus (AF), representing a variety of established tracts.</p><p>To test the proposed method on pathological data, we used an in-house dataset containing ten presurgical scans of patients with brain tumors. Tractography was performed using probabilistic streamline tractography in MITK Diffusion. To reduce computational costs, we retained one million streamlines that passed through a manually inserted ROI located in an area traversed by the OR <ref type="bibr" target="#b14">[15]</ref>. Subjects have tumor appearance with varying sizes ((17.87±12.73 cm 3 )) in temporoloccipital, temporal, and occipital regions, that cause deformations around the OR and lead to deviations of the tract from the normative model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experimental Setup</head><p>To evaluate the proposed method, we conducted two types of experiments. Manual segmentation experiments using an interactive prototype of atTRACTive were initiated on the tumor data (holistic evaluation). Additionally, reproducible simulations on the freely available HCP and the internal tumor dataset were created (algorithmic evaluation). In order to mimic expert annotation during algorithmic evaluation, class labels were assigned to streamlines using previously generated references. The quality of the predictions was measured by calculating the dice score of the binary mask. The code used for these experiments is publicly available<ref type="foot" target="#foot_1">2</ref> .</p><p>For the algorithmic evaluation, the initial training dataset was created with 20 randomly selected streamlines from the whole-brain tractogram, which have been shown to be a decent number to start training. Since some tracts contain only a fraction of streamlines from the entire tractogram, it might be unlikely that the training dataset will contain any streamline belonging to the target tract. Therefore, two streamlines of the specific tract were further added to the training dataset, and class weights were used to compensate for the class unbalance. According to Fig. <ref type="figure" target="#fig_1">2</ref>, the dissimilarity representation was determined, the random forest classifier was trained and the converged model was used to predict on the unlabeled streamlines and to calculate the entropy. In each iteration, the ten streamlines with the highest entropy are added to the training dataset, which has been determined to be a good trade-off between annotation effort and prediction improvement. The process was terminated after 20 iterations, increasing the size of the training data from 22 to 222 out of one million streamlines.</p><p>The holistic evaluation was conducted with equal settings, except that the workflow was terminated when the prediction matched the expectation of the expert. To ensure that the initial dataset S rand contained streamlines from the target tract, the expert initiated the active learning workflow by defining a small ROI that included fibers of the tract. S rand was created by randomly sampling only those streamlines that pass through this ROI. To allow comparison between the proposed and traditional ROI-based techniques, the OR of subjects from the tumor dataset were segmented using both approaches by an expert familiar with the respective tool, and the time required was reported to measure efficiency.</p><p>Note, in all experiments, the classifier is trained from scratch every iteration, prototypes are generated for each subject individually, and the classifier predicts on data from the same subject it is trained with, as it performs subject-individual tract segmentation and is not used as a fully automated method. To ensure a stable active learning setup that generalizes across different datasets, the whole method was developed on the HCP and applied with fixed settings to the tumor data <ref type="bibr" target="#b9">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results</head><p>In Table <ref type="table" target="#tab_0">1</ref>, the dice score of the active learning simulation on the HCP and tumor data after the fifth, tenth, and twentieth iterations are shown and compared with outcomes of Classifyber and TractSeg. Results for the HCP data were already on par with the benchmark of automatic methods between the fifth and tenth iterations. On the tumor data, the performance of the proposed method remains above 0.7 while the performance of TractSeg drops substantially. Furthermore, Classifyber does not support the OR and is therefore not listed in Table <ref type="table" target="#tab_0">1</ref>. Figure <ref type="figure" target="#fig_2">3</ref> depicts the quantitative gain of active learning on the three tracts of the HCP data and compares it to pure random sampling by displaying the dice score depending on annotated streamlines. While active learning leads to an increase in the metric until the predictions at around five to ten iterations show no meaningful improvements, the random selection does not improve overall. Qualitative results of the algorithmic evaluation of the AF of a randomly chosen subject of the HCP dataset are shown in Fig. <ref type="figure" target="#fig_3">4(a)</ref>. Initially, the randomly sampled streamlines in the training data are distributed throughout the brain, while entropy-based selected streamlines from subsequent iterations cluster around the AF. The prediction improves iteratively, as indicated by a rising dice score. When accessing qualitative results of the pathological dataset visual inspection revealed particularly poorly performance of TractSeg in cases where OR fibers were in close proximity to tumor tissue, leading to fragmented segmentations, while complete segmentations were reached with active learning even for these challenging tracts after a few iterations, as shown in Fig. <ref type="figure" target="#fig_3">4(b)</ref>.</p><p>The initial manual experiments with atTRACTive were consistent with the simulations. The prediction aligned with the expectations of the expert at around five to seven iterations taking a mean of 4,5 min, while it took seven minutes on average to delineate the tract with ROI-based segmentation. During the iterations, streamlines around the target tract were suggested for labeling, and the prediction improved. Visual comparison yielded more false-positive streamlines with the ROI-based approach while atTRACTive created more compact tracts. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>Active learning-based white matter tract segmentation enables the identification of arbitrary pathways and can be applied to cases where fully automated methods are unfeasible. In this work, algorithmic evaluation as well as the implementation of the technique into the GUI-based tool atTRACTive including further holistic manual experiments were conducted. The algorithmic evaluation yielded consistent results from the fifth to the tenth iterations on both the HCP and tumor datasets. As expected, outcomes obtained from the tumor dataset were not quite as good as those of the HCP dataset. This trend is generally observed in clinical datasets, which tend to exhibit lower performance levels compared to high-quality datasets, which could be responsible for the decline in the results. Preliminary manual experiments with atTRACTive indicated active learning to have shorter segmentation times compared to traditional ROI-based techniques. These experiments are in line with the simulations as the generated tracts matched the expectations of the expert after around five to seven iterations, meaning that less than a hundred out of million annotated streamlines are required to train the model. Enhancements to the usability of the prototype are expected to further improve efficiency. A current limitation of atTRACTive is the selection of the initial subset, based on randomly sampling streamlines passing through a manually inserted ROI. This approach does not guarantee that streamlines of the target tract are included in the subset. In that case, the ROI has to be replaced or S rand needs to be regenerated.</p><p>Future analyses, evaluating the inter-and intra-rater variability compared to other interactive approaches, will be conducted on further tracts. For selected scenarios, the ability of the classifier to generalize by learning from previously annotated subjects will be investigated, which may even allow to train a fully automatic classifier for new tracts once enough data is annotated. To further optimize the method, the feature representation or sampling procedure could be improved. Uncertainty sampling may select redundant streamlines due to similar high entropy values. Instead, annotating samples with high entropy values being highly diverse or correcting false classifications could convey more information.</p><p>By introducing active learning into tract segmentation, we provide an efficient and intuitive alternative compared to traditional ROI-based approaches.</p><p>atTRACTive has the potential to interactively assist researchers in identifying arbitrary white matter tracts not captured by existing automated approaches.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Visualization of a tractogram T , a white matter tract t (arcuate fasciculus), its binary segmentation mask and a single streamline s containing 3D points xi .</figDesc><graphic coords="3,112,47,358,22,225,01,54,01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Active Learning workflow: Extraction of subset S rand of unlabeled streamlines from the whole-brain tractogram T for annotation (a). Initial and adaptive prototypes are used to compute dMDF and dEND for each streamline, followed by training the random forest classifier (b), which predicts on remaining unlabeled streamlines (c). Entropy reflecting the uncertainty is used to select a new subset SE max to annotate in the subsequent iterations until the human expert is satisfied with the prediction.</figDesc><graphic coords="4,47,79,363,98,328,48,168,85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Dice score of entropy-based active learning of the HCP dataset of the OR, CST, and AF ([T ract]ent) compared to random sampling ([T ract] rand )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Training data, prediction, segmentation mask, and dice-score after first, third, and fifth iteration of active learning with the reference of the AF (a) and tumor (blue) and OR segmentation (red) with reference, active learning outcome after the third iteration and TractSegs output (b). (Color figure online)</figDesc><graphic coords="8,90,75,209,78,287,56,97,09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Dice score of TractSeg and Classifyber on both datasets compared to entropybased active learning after the fifth, tenth, and twentieth iteration.</figDesc><table><row><cell>Tract</cell><cell>HCP dataset</cell><cell></cell><cell></cell><cell>Tumor dataset</cell></row><row><cell></cell><cell>CST</cell><cell>AF</cell><cell>OR</cell><cell>OR</cell></row><row><cell>Classifyber [3]</cell><cell cols="3">0.86 ± 0.01 0.84 ± 0.03 -</cell><cell>-</cell></row><row><cell>TractSeg [18]</cell><cell cols="4">0.86 ± 0.02 0.86 ± 0.03 0.83 ± 0.02 0.34 ± 0.19</cell></row><row><cell cols="5">Active Learningit=5 0.83 ± 0.05 0.86 ± 0.03 0.79 ± 0.11 0.71 ± 0.06</cell></row><row><cell cols="5">Active Learningit=10 0.88 ± 0.03 0.88 ± 0.02 0.85 ± 0.05 0.72 ± 0.05</cell></row><row><cell cols="5">Active Learningit=20 0.90 ± 0.03 0.90 ± 0.02 0.88 ± 0.02 0.73 ± 0.08</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://github.com/MIC-DKFZ/MITK-Diffusion.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://github.com/MIC-DKFZ/atTRACTive simulations.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">In vivo fiber tractography using DT-MRI data</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Basser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pajevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pierpaoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Duda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aldroubi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="625" to="632" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Diffusion MR tractography as a tool for surgical planning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Berman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Imaging Clin. N. Am</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="205" to="214" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Classifyber, a robust streamline-based linear classifier for white matter bundle segmentation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Bertò</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">224</biblScope>
			<biblScope unit="page">117402</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">QuickBundles, a method for tractography simplification</title>
		<author>
			<persName><forename type="first">E</forename><surname>Garyfallidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Correia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Nimmo-Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Neurosci</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">175</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Robust and efficient linear registration of white-matter fascicles in the space of streamlines</title>
		<author>
			<persName><forename type="first">E</forename><surname>Garyfallidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ocegueda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wassermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Descoteaux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="124" to="140" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Robust clustering of massive tractography datasets</title>
		<author>
			<persName><forename type="first">P</forename><surname>Guevara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1975" to="1993" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A transfer learning-based active learning framework for brain tumor classification</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Namdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Khalvati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">635766</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Entropy-based active learning for object recognition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Holub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Burl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008. 2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Semi-supervised active learning for covid-19 lung ultrasound multi-symptom classification</title>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1268" to="1273" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Toward realistic evaluation of deep active learning algorithms in image classification</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Lüth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Bungert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.10625</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">White matter tractography in bipolar disorder and schizophrenia</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Mcintosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biol. Psychiat</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1088" to="1092" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Diffusion tensor imaging and tractography of human brain development</title>
		<author>
			<persName><forename type="first">P</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Mckinstry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimaging Clin</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="43" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Supervised segmentation of fiber tracts</title>
		<author>
			<persName><forename type="first">E</forename><surname>Olivetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Avesani</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-24471-1_19</idno>
		<ptr target="https://doi.org/10.1007/978-3-642-24471-119" />
	</analytic>
	<monogr>
		<title level="m">SIMBAD 2011</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Pelillo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Hancock</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">7005</biblScope>
			<biblScope unit="page" from="261" to="274" />
		</imprint>
	</monogr>
	<note>LNCS</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Tractome: a visual data mining tool for brain connectivity analysis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Porro-Muñoz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Olivetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sharmin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Garyfallidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Avesani</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10618-015-0408-z</idno>
		<ptr target="https://doi.org/10.1007/s10618-015-0408-z" />
	</analytic>
	<monogr>
		<title level="j">Data Min. Knowl. Disc</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1258" to="1279" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Q-ball imaging</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Tuch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med.: Off. J. Int. Soc. Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1358" to="1372" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep reinforcement active learning for medical image classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Ng</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59710-8_4</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-59710-84" />
	</analytic>
	<monogr>
		<title level="m">MIC-CAI 2020, Part I</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12261</biblScope>
			<biblScope unit="page" from="33" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multiparametric mapping of white matter microstructure in catatonia</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wasserthal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuropsychopharmacology</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1750" to="1757" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">TractSeg-fast and accurate white matter tract segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wasserthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Neher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Maier-Hein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">183</biblScope>
			<biblScope unit="page" from="239" to="253" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Diffusion MRI tractography for neurosurgery: the basics, current state, technical reliability and challenges</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Poupon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Calamante</surname></persName>
		</author>
		<idno>15TR01</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Med. Biol</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">15</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Fibre tract segmentation for intraoperative diffusion MRI in neurosurgical patients using tract-specific orientation atlas and tumour deformation modelling</title>
		<author>
			<persName><forename type="first">F</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Aquilina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clayden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Assist. Radiol. Surg</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep white matter analysis (DeepWMA): fast and consistent tractography segmentation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Karayumak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Golby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>O'donnell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page">101761</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
