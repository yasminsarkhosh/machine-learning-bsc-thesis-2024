<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Large Margin Sparse Embeddings for Open Set Medical Diagnosis</title>
				<funder ref="#_Qq5bdWT">
					<orgName type="full">University Synergy Innovation Program of Anhui Province</orgName>
				</funder>
				<funder ref="#_DJSdB7b">
					<orgName type="full">Beijing Natural Science Foundation</orgName>
				</funder>
				<funder ref="#_XjJmBUh">
					<orgName type="full">Industrialization Research Project of Hefei Innovation Research Institute, Beihang University</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mingyuan</forename><surname>Liu</surname></persName>
							<email>liumingyuan95@buaa.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Biological Science and Medical Engineering</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lu</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Biological Science and Medical Engineering</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jicong</forename><surname>Zhang</surname></persName>
							<email>jicongzhang@buaa.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Biological Science and Medical Engineering</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Hefei Innovation Research Institute</orgName>
								<orgName type="institution">Beihang University</orgName>
								<address>
									<settlement>Hefei, Anhui</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning Large Margin Sparse Embeddings for Open Set Medical Diagnosis</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="548" to="558"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">4FC45B35699EBC65F7C293F03D7DF1AA</idno>
					<idno type="DOI">10.1007/978-3-031-43993-3_53</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-23T22:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Open set recognition</term>
					<term>Computer aided diagnosis</term>
					<term>Image classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Fueled by deep learning, computer-aided diagnosis achieves huge advances. However, out of controlled lab environments, algorithms could face multiple challenges. Open set recognition (OSR), as an important one, states that categories unseen in training could appear in testing. In medical fields, it could derive from incompletely collected training datasets and the constantly emerging new or rare diseases. OSR requires an algorithm to not only correctly classify known classes, but also recognize unknown classes and forward them to experts for further diagnosis. To tackle OSR, we assume that known classes could densely occupy small parts of the embedding space and the remaining sparse regions could be recognized as unknowns. Following it, we propose Open Margin Cosine Loss (OMCL) unifying two mechanisms. The former, called Margin Loss with Adaptive Scale (MLAS), introduces angular margin for reinforcing intraclass compactness and inter-class separability, together with an adaptive scaling factor to strengthen the generalization capacity. The latter, called Open-Space Suppression (OSS), opens the classifier by recognizing sparse embedding space as unknowns using proposed feature space descriptors. Besides, since medical OSR is still a nascent field, two publicly available benchmark datasets are proposed for comparison. Extensive ablation studies and feature visualization demonstrate the effectiveness of each design. Compared with state-of-the-art methods, MLAS achieves superior performances, measured by ACC, AUROC, and OSCR.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction and Related Work</head><p>Deep learning achieves great success in image-based disease classification. However, the computer-aided diagnosis is far from being solved when considering various requirements in real-world applications. As an important one, open set recognition (OSR) specifies that diseases unseen in training could appear in testing <ref type="bibr" target="#b22">[23]</ref>. It is practical in the medical field, caused by the difficulties of collecting a training dataset exhausting all diseases, and by the unpredictably appearing new or rare diseases. As a result, an OSR-informed model should not only accurately recognize known diseases but also detect unknowns and report them. Clinically, these models help construct trustworthy computer-aided systems. By forwarding unseen diseases to experts, not only the misdiagnosis of rare diseases could be avoided, but an early warning of a new disease outbreak could be raised.</p><p>There are many fields related to OSR but are essentially different. In classification with reject options <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9]</ref>, samples with low confidence are rejected to avoid misclassification. However, since its closed set nature, unknown classes could still be misclassified confidently <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b22">23]</ref>. Anomaly detection, novelty detection, and one-class classification <ref type="bibr" target="#b20">[21]</ref> aim at recognizing unknowns but ignore categorizing the known classes. In outlier detection or one-/few-show learning <ref type="bibr" target="#b26">[27]</ref>, samples of novel classes appear in training. In zero-shot learning <ref type="bibr" target="#b28">[29]</ref>, semantic information from novel classes could be accessed. Such as zebra, an unknown class, could be identified given the idea that they are stripped horses, and abundant samples of horse and stripe patterns. Differently, OSR knows nothing about novel classes and should have high classification accuracy of the known meanwhile recognize unknowns, as illustrated in Fig. <ref type="figure" target="#fig_0">1a</ref>). Due to limited space, some reviews <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b33">34]</ref> are recommended for more comprehensive conceptual distinctions.</p><p>Most OSR researches focus on natural images, while medical OSR is still in its infancy. In medical fields, representative work like T3PO <ref type="bibr" target="#b5">[6]</ref> introduces an extra task to predict the input image augmentation, and samples with low probabilities are regarded as unknowns. CSL <ref type="bibr" target="#b31">[32]</ref> uses generative adversarial neural networks (GAN) to generate proxy images and unknown anchors. As for natural images, a line of work tries to simulate unknowns using generated adversarial or counterfactual samples using GAN <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b32">33]</ref>. However, whether unknown patterns could be generated by learning from the known is unclear. Some works learn descriptive feature representations. They enhance better feature separation between unknowns and knowns or assume the known features following certain distributions so that samples away from distributional centers could be recognized as unknowns <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b34">35]</ref>. Differently, this work categorizes densely distributed known features and recognizes sparse embedding space as unknowns, regardless of the specific distribution.</p><p>This work tackles OSR under the assumption that known features could be assembled compactly in feature embedding space, and remaining sparse regions could be recognized as unknowns. Inspired by this, the Open Margin Cosine Loss (OMCL) is proposed merging two components, Margin Loss with Adaptive Scale (MLAS) and Open-Space Suppression (OSS). The former enhances known feature compactness and the latter recognizes sparse feature space as unknown. Specifically, MLAS introduces the angular margin to the loss function, which reinforces the intra-class compactness and inter-class separability. Besides, a learnable scaling factor is proposed to enhance the generalization capacity. OSS generates feature space descriptors that scatter across a bounded feature space. By categorizing them as unknowns, it opens a classifier by recognizing sparse feature space as unknowns and suppressing the overconfidence of the known. An embedding space example is demonstrated in Fig. <ref type="figure" target="#fig_0">1b</ref>), showing OMCL learns more descriptive features and more distinguishing known-unknown separation.</p><p>Considering medical OSR is still a nascent field, besides OMCL, we also proposed two publicly available benchmark datasets. One is microscopic images of blood cells, and the other is optical coherence tomography (OCT) of the eye fundus. OMCL shows good adaptability to different image modalities.</p><p>Our contributions are summarized as follows. Firstly, we propose a novel approach, OMCL for OSR in medical diagnosis. It reinforces intra-class compactness and inter-class separability, and meanwhile recognizes sparse feature space as unknowns. Secondly, an adaptive scaling factor is proposed to enhance the generalization capacity of OMCL. Thirdly, two benchmark datasets are proposed for OSR. Extensive ablation experiments and feature visualization demonstrate the effectiveness of each design. The superiority over state-of-the-art methods indicates the effectiveness of our method and the adaptability of OMCL on different image modalities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>In Sect. 2.1, the open set problem and the formation of cosine Softmax are introduced. The two mechanisms MLAS and OSS are sequentially elaborated in Sect. 2.2 and 2.3, followed by the overall formation of OMCL in Sect. 2.4.  Cosine Loss: The cosine Softmax is used as the basis of the OMCL. It transfers feature embeddings from the Euclidian space to a hyperspherical one, where feature differences depend merely on their angular separation rather than spatial distance. Given an image x i , its vectorized feature embedding z i , and its label y i , the derivation progress of the cosine Softmax is</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Preliminaries</head><formula xml:id="formula_0">S cos = e W T y i z i C j=1 e W T j z i ConventioanlF orm = e W y i z i cos(θy i ,i ) C j=1 e W j z i cos(θj,i) = e s•cos(θy i ,i) C j=1 e s•cos(θj,i) CosineF orm ,<label>(1)</label></formula><p>where W j denotes the weights of the last fully-connected layer (bias is set to 0 for simplicity). W j = 1 and z i = s are manually fixed to constant numbers 1 and s by L2 normalization. s is named the scaling factor. cos(θ j,i ) denotes the angle between W j and z i . By doing so, the direction of W j could be regarded as the prototypical direction of class j as shown in Fig. <ref type="figure" target="#fig_2">2a</ref>). Samples with large angular differences from their corresponding prototype will be punished and meanwhile class-wise prototypes will be pushed apart in the angular space. Compared with Softmax, the cosine form has a more explicit geometric interpretation, promotes more stabilized weights updating, and learns more discriminative embeddings <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b25">26]</ref>. Moreover, the L2 normalization constrains features to a bounded feature space, which allows us to generate feature space descriptors for opening a classifier (will be further discussed in Sect. 2.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Margin Loss with Adaptive Scale (MLAS)</head><p>MLAS serves three purposes. 1) By applying angular margin, the intra-class compactness and the inter-class separability are strengthened. 2) The threshold could represent the potential probability of the unknowns, which not only prepares for the open set but also learns more confident probabilities of the knowns.</p><p>3) A trainable scaling factor is designed to strengthen the generalization capacity. MLAS is:</p><formula xml:id="formula_1">S MLAS = e s•(cos(θy i ,i)-m) e s•(cos(θy i ,i )-m) + e s•t + C j=1,j =yi e s•cos(θj,i) (2)</formula><p>m, t, and s respectively denote margin, threshold, and learnable scaling factor, with corresponding geometric interpretation demonstrated in Fig. <ref type="figure" target="#fig_2">2b</ref>). By using the angular margin, the decision boundary could be more stringent. Without it, the decision boundary is cos(θ 1,i ) &gt; cos(θ 2,i ) for the i-th sample of class 1. It becomes cos(θ 1,i ) &gt; cos(θ 2,i ) + m when using the margin, which leads to stronger intra-class compactness. Moreover, the angular similarities with other classes are punished in the denominator to increase inter-class separability.</p><p>The threshold t could be regarded as an extra dimension that prepares for unknown classes. Given the conventional input of Softmax as [q 1  i , q 2 i , ..., q C i ] ∈ R C , ours could be understood as [q 1  i , q 2 i , ..., q C i , t] ∈ R C+1 . Since t is added, the class-wise output q c i before Softmax is forced to have a higher value to avoid misclassification (at least larger than t). It reinforces more stringent learning and hence increases the feature compactness in the hyperspherical space.</p><p>A large s makes the distribution more uniform, and a small s makes it collapses to a point mass. In this work, it is learnable, with a learning rate 0.1× the learning rate of the model. It theoretically offers stronger generalization capacity to various datasets and is experimentally observed to converge to different values in different data trails and could boost performances.</p><p>LMCL <ref type="bibr" target="#b25">[26]</ref> and NMCL <ref type="bibr" target="#b14">[15]</ref> are the most similar arts to ours. Differently, from the task perspective, these designs are proposed for closed-world problems. From the method perspective, an OSS mechanism is designed to tackle OSR leveraging generate pseudo-unknown features for discriminative learning. Moreover, an adaptive scaling factor is introduced for increasing generalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Open-Space Suppression (OSS)</head><p>OSS generates feature space descriptors of bounded feature space. By categorizing them into an extra C + 1 class, samples in sparse feature space could be recognized as unknown and the overconfidence of the known is suppressed.</p><p>OSS selects points scattered over the entire feature space, named descriptors, representing pseudo-unknown samples. Different from existing arts that generate pseudo-unknowns by learning from known samples, the OSS selects points scattered over the feature space. It guarantees all space could be possibly considered for simulating the potential unknowns. By competing with the known features, feature space with densely distributed samples is classified as the known, and the sparse space, represented by the descriptors, will be recognized as unknown.</p><p>In this work, the corresponding descriptor set, with M samples, is <ref type="figure">s</ref>, s] denotes random continuous uniform distribution ranges between -s to s, and d is the dimension of feature embeddings. s is trainable and the descriptors are dynamically generated with the training. Figure <ref type="figure" target="#fig_2">2c</ref>) demonstrates the geometric interpretation. During training, descriptors are concatenated with the training samples at the input of the last fully-connected layer, to equip the last layer with the discrimination capacity of known and unknown samples. The OSS is (θj,i)   (3) where t and s follow the same definition in MLAS.</p><formula xml:id="formula_2">D desc = {(z i , C + 1)} M i=1 , where z i ∈ U[-s, s] d subject to z i = s. U[-</formula><formula xml:id="formula_3">S OSS = e s•t e s•t + C j=1 e s•cos</formula><p>Most similar arts like AL <ref type="bibr" target="#b24">[25]</ref> attempts to reduce misclassification by abandoning ambiguous training images. Differently, we focus on OSR and exploit a novel discriminative loss with feature-level descriptors for OSR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Open Margin Cosine Loss (OMCL)</head><p>OMCL unifies MLAS and OSS into one formula, which is</p><formula xml:id="formula_4">L OM CL = - 1 N + M N +M i=1 I i log(S cos ) + λI i log(S MLAS ) + λI i log(S OSS ) (4)</formula><p>I i equals 1 if the i-th sample is training data, and equals 0 if it belongs to the feature space descriptors. λ is a weight factor. Since the output of the channel C +1 is fixed as t, no extra weights W C+1 are trained in the last fully-connected layer. As a result, OMCL does not increase the number of trainable weights in a neural network. During testing, just as in other works <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>, the maximum probability of known classes is taken as the index of unknowns, where a lower known probability indicates a high possibility of unknowns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Result</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets, Evaluation Metrics, and Implementation Details</head><p>Two datasets are adapted as new benchmarks for evaluating the OSR problem. Following protocols in natural images <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4]</ref>, half of the classes are selected as known and reminders as unknowns. Since the grouping affects the results, it is randomly repeated K times, leading to K independent data trials. The average results of K trials are used for evaluation. The specific groupings are listed in the supplementary material, so that future works could follow it for fair comparisons. BloodMnist contains 8 kinds of individual normal cells with 17,092 images <ref type="bibr" target="#b0">[1]</ref>. Our setting is based on the closed set split and prepossessing from <ref type="bibr" target="#b30">[31]</ref>. Classes are selected 5 rounds (K=5). In each trial, images belonging to 4 chosen classes are selected for training and closed-set evaluation. Images belonging to the other 4 classes in testing data are used for open set evaluation. OCTMnist has 109,309 optical coherence tomography (OCT) images <ref type="bibr" target="#b12">[13]</ref>, preprocessed following <ref type="bibr" target="#b30">[31]</ref>. Among the 4 classes, 1 is healthy and the other 3 are retinal diseases. In data trail splitting, the healthy class is always in the known set, which is consistent with real circumstances, and trails equal to 3 (K=3). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Comparison with State-of-the-Art Methods</head><p>As demonstrated in Table <ref type="table" target="#tab_0">1</ref>, the proposed OMCL surpasses state-of-the-art models, including typical discriminative methods, baseline <ref type="bibr" target="#b11">[12]</ref>, GCPL <ref type="bibr" target="#b29">[30]</ref>, and RPL <ref type="bibr" target="#b2">[3]</ref>; latest generative model DIAS <ref type="bibr" target="#b18">[19]</ref>; and ARPL+CS <ref type="bibr" target="#b1">[2]</ref> that hybrids both. All methods are implemented based on their official codes. Their best results after hyperparameter finetunes are reported. Results show the OMCL maintains the accuracy, meanwhile could effectively recognize unknowns.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Ablation Studies</head><p>Effectiveness of MLAS and OSS : Table <ref type="table" target="#tab_1">2</ref> demonstrates the respective contributions of MLAS and OSS in OMCL. Each of them enhances the performances and they could work complementarily to further improve performances.</p><p>Ablation Study of Adaptive Scaling Factor : Fig. <ref type="figure" target="#fig_3">3a</ref>) demonstrates the effectiveness of the adaptive scaling factor. Quantitatively, the adaptive design surpasses a fixed one. Moreover, Fig. <ref type="figure" target="#fig_3">3b</ref>) displays the scaling factor will converge to different values in different training trials. Both results demonstrate the effectiveness and the generalization capacity of the adaptive design.</p><p>Ablation Study of Hyperparameters t, m, and λ: Fig. <ref type="figure" target="#fig_4">4a</ref>), b), and c) respectively show the influence on results when using different hyperparameters. t and m are the threshold and angular margin, presented in Eq. 2, and λ is the trade-off parameter in Eq. 4 .</p><p>Ablation Study of M : Fig. <ref type="figure" target="#fig_4">4d</ref>) illustrates the effect of the number of feature space descriptors upon results. The ratio 1:1 is experimentally validated as a proper ratio. Because a randomly generated descriptor could be extremely close to a known feature point, but classified as a novel category, which may disturb the training. If the number of descriptors is far more than that of the training samples (the 5 times shown in Fig. <ref type="figure" target="#fig_4">4</ref>), the performance gets lower.</p><p>Feature Visualization: Fig. <ref type="figure" target="#fig_0">1b</ref>) visualizes the t-SNE results of features z of both known and unknown classes after dimension reduction. For each class, 200 samples are visualized and the perplexity of the t-SNE is set to 30. It shows that OMCL could learn better intra-class compactness and inter-class separability.</p><p>Moreover, samples of unknown classes tend to be pushed away from known classes, incidcating the effectiveness of our designs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, two publicly available benchmark datasets are proposed for evaluating the OSR problem in medical fields. Besides, a novel method called OMCL is proposed, under the assumption that known features could be assembled compactly in feature space and the sparse regions could be recognized as unknowns.</p><p>The OMCL unifies two mechanisms, MLAS and OSS, into a unified formula. The former reinforces intra-class compactness and inter-class separability of samples in the hyperspherical feature space, and an adaptive scaling factor is proposed to empower the generalization capability. The latter opens a classifier by categorizing sparse regions as unknown using feature space descriptors. Extensive ablation experiments and feature visualization demonstrate the effectiveness of each design. Compared to recent state-of-the-art methods, the proposed OMCL performs superior, measured by ACC, AUROC, and OSCR.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. a) Diagrams of the open set recognition problem, and b) the feature visualization of original closed set classifier and our proposed OMCL.</figDesc><graphic coords="2,68,46,54,35,316,06,113,35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Problem Setting : Both closed set and open set classifiers learn from the training set D train = {(x i , y i )} N i=1 with N image-label pairs (x i , y i ), where y i ∈ Y = {1, 2, ..., C} is a class label. In testing, closed set testing data D test shares the same label space Y with the training data. However, in the open set problem, unseen class y i = C + 1 could appear in testing i.e. y i ∈ Y open = {1, 2, ..., C, C + 1}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Geometric interpretation of the cosine Softmax, MLAS, and OSS. MLAS introduces angular margin m and threshold t to reinforce the intra-class compactness and the inter-class separability, together with an adaptive scaling factor to enhance the adaptability. OSS opens a classifier by recognizing the sparse feature space as unknowns using the proposed feature space descriptors.</figDesc><graphic coords="4,55,98,54,35,340,18,85,36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Ablation studies of adaptive scaling factor on BloodMnist dataset.</figDesc><graphic coords="8,55,98,173,63,340,18,66,70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Ablation studies of hyperparameters. Each result is the average of 5 trails on the BloodMnist dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Comparison with state-of-the-art methods. The average of multiple trials is reported.</figDesc><table><row><cell>Method (Pub'Year)</cell><cell cols="2">BloodMnist K=5</cell><cell></cell><cell cols="2">OCTMnist K=3</cell><cell></cell></row><row><cell></cell><cell cols="6">Accc% AUROCo% OSCRo% Accc% AUROCo% OSCRo%</cell></row><row><cell>Baseline [12] (ICLR'17)</cell><cell>98.0</cell><cell>84.3</cell><cell>84.4</cell><cell>94.3</cell><cell>64.1</cell><cell>62.8</cell></row><row><cell>GCPL [30] (CVPR'18)</cell><cell>98.1</cell><cell>85.5</cell><cell>85.0</cell><cell>94.8</cell><cell>65.5</cell><cell>64.2</cell></row><row><cell>RPL [3] (ECCV'20)</cell><cell>98.0</cell><cell>86.8</cell><cell>86.3</cell><cell>93.7</cell><cell>65.9</cell><cell>64.2</cell></row><row><cell cols="2">ARPL+CS [2] (TPAMI'21) 98.5</cell><cell>87.6</cell><cell>87.1</cell><cell>95.9</cell><cell>77.7</cell><cell>75.8</cell></row><row><cell>DIAS [19] (ECCV'22)</cell><cell>98.4</cell><cell>86.3</cell><cell>85.7</cell><cell>96.0</cell><cell>74.1</cell><cell>72.5</cell></row><row><cell>OMCL (Ours)</cell><cell>98.3</cell><cell>88.6</cell><cell>88.0</cell><cell>96.8</cell><cell>78.9</cell><cell>77.8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Ablation studies on the effectiveness of MLAS and OSS in OMCL. Each result is the average of 5 trials on BloodMnist dataset.</figDesc><table><row><cell cols="3">MLAS OSS Accc% AUROCo% OSCRo%</cell></row><row><cell>98.3</cell><cell>84.7</cell><cell>84.2</cell></row><row><cell>98.3</cell><cell>85.4</cell><cell>84.9</cell></row><row><cell>98.3</cell><cell>86.8</cell><cell>86.3</cell></row><row><cell>98.3</cell><cell>88.6</cell><cell>88.0</cell></row><row><cell cols="3">Metrics: Following previous arts [2,19], accuracy (ACC c ) validates closed set</cell></row><row><cell cols="3">classification. Area Under the Receiver Operating Characteristic (AUROC o ),</cell></row><row><cell cols="3">a threshold-independent value, measures the open set performances. Open Set</cell></row><row><cell cols="3">Classification Rate (OSCR o ) [4], considers both open set recognition and closed</cell></row><row><cell cols="3">set accuracy, where a larger OSCR indicates better performance.</cell></row><row><cell cols="3">Implementation Details: The classification network is ResNet18 [11], opti-</cell></row><row><cell cols="3">mized by Adam with an initial learning rate of 1e-3 and a batch size 64. The</cell></row><row><cell cols="3">number of training epochs is 200 and 100 for BloodMnist and OCTMnist respec-</cell></row><row><cell cols="3">tively because the number of training samples in BloodMnist is smaller. Margin</cell></row><row><cell cols="3">m, threshold t, λ are experimentally set to -0.1, 0.1, and 0.5 respectively. Images</cell></row><row><cell cols="3">are augmented by random crop, random horizontal flip, and normalization.</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement. This work is supported by <rs type="funder">Beijing Natural Science Foundation</rs> (Grant Number: <rs type="grantNumber">Z200024</rs>), the <rs type="funder">Industrialization Research Project of Hefei Innovation Research Institute, Beihang University</rs> (Grant Number: <rs type="grantNumber">BHKX-20-01</rs>), and the <rs type="funder">University Synergy Innovation Program of Anhui Province</rs> (Grant Number: <rs type="grantNumber">GXXT-2019-044</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_DJSdB7b">
					<idno type="grant-number">Z200024</idno>
				</org>
				<org type="funding" xml:id="_XjJmBUh">
					<idno type="grant-number">BHKX-20-01</idno>
				</org>
				<org type="funding" xml:id="_Qq5bdWT">
					<idno type="grant-number">GXXT-2019-044</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43993-3_53.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A dataset of microscopic peripheral blood cell images for development of automatic recognition systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Acevedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Merino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Alférez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Á</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Boldú</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rodellar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Brief</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">105474</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Adversarial reciprocal points learning for open set recognition</title>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="8065" to="8081" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning open set network with discriminative reciprocal points</title>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-58580-8_30</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-58580-8_30" />
	</analytic>
	<monogr>
		<title level="m">ECCV 2020</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Bischof</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J.-M</forename><surname>Frahm</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12348</biblScope>
			<biblScope unit="page" from="507" to="522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Reducing network agnostophobia</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Dhamija</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Günther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Boult</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Boosting deep open world recognition by clustering</title>
		<author>
			<persName><forename type="first">D</forename><surname>Fontanel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cermelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mancini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Bulo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robot. Autom. Lett</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="5985" to="5992" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Test time transform prediction for open set histopathological image recognition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Galdran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Hewitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ghaffari Laleh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Kather</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Carneiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>González Ballester</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16434-7_26</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16434-7_26" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13432</biblScope>
			<biblScope unit="page" from="263" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Selective classification for deep neural networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Geifman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>El-Yaniv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Recent advances in open set recognition: a survey</title>
		<author>
			<persName><forename type="first">C</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T-PAMI</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3614" to="3631" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Support vector machines with a reject option</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Grandvalet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rakotomamonjy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Keshet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Canu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning a neural-network-based representation for open set recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hassen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 SIAM International Conference on Data Mining</title>
		<meeting>the 2020 SIAM International Conference on Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="154" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A baseline for detecting misclassified and out-ofdistribution examples in neural networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Identifying medical diagnoses and treatable diseases by image-based deep learning</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Kermany</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell</title>
		<imprint>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1122" to="1131" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">OpenGAN: open-set recognition via open data generation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="813" to="822" />
		</imprint>
		<respStmt>
			<orgName>ICCV</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Negative margin matters: understanding margin in few-shot classification</title>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-58548-8_26</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-58548-8_26" />
	</analytic>
	<monogr>
		<title level="m">ECCV 2020</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Bischof</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J.-M</forename><surname>Frahm</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12349</biblScope>
			<biblScope unit="page" from="438" to="455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">SphereFace: deep hypersphere embedding for face recognition</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="212" to="220" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Large-scale long-tailed recognition in an open world</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2537" to="2546" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">PMAL: open set recognition via robust prototype mining</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Niu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AAAI</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1872" to="1880" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Difficulty-aware simulator for open set recognition</title>
		<author>
			<persName><forename type="first">W</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Seong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Heo</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-19806-9_21</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-19806-9_21" />
	</analytic>
	<monogr>
		<title level="m">ECCV 2022</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Avidan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Brostow</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Cissé</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Farinella</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Hassner</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13685</biblScope>
			<biblScope unit="page" from="365" to="381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Open set learning with counterfactual images</title>
		<author>
			<persName><forename type="first">L</forename><surname>Neal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Olson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Fern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-K</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-01231-1_38</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-01231-1_38" />
	</analytic>
	<monogr>
		<title level="m">ECCV 2018</title>
		<editor>
			<persName><forename type="first">V</forename><surname>Ferrari</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hebert</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Sminchisescu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">11210</biblScope>
			<biblScope unit="page" from="620" to="635" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep learning for anomaly detection: a review</title>
		<author>
			<persName><forename type="first">G</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V D</forename><surname>Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv. (CSUR)</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">A unified survey on anomaly, novelty, open-set, and out-of-distribution detection: solutions and future challenges</title>
		<author>
			<persName><forename type="first">M</forename><surname>Salehi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mirzaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Rohban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sabokrou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.14051</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Toward open set recognition</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Scheirer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>De Rezende Rocha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sapkota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Boult</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1757" to="1772" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">P-ODN: prototype-based open deep network for open set recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">7146</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Thulasidasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bilmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chennupati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mohd-Yusof</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.10964</idno>
		<title level="m">Combating label noise in deep learning using abstention</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">CosFace: large margin cosine loss for deep face recognition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="5265" to="5274" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Generalizing from a few examples: a survey on few-shot learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Ni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv. (CSUR)</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="34" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Energy-based open-world uncertainty modeling for confidence calibration</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="9302" to="9311" />
		</imprint>
		<respStmt>
			<orgName>ICCV</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Zero-shot learning-the good, the bad and the ugly</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Akata</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="4582" to="4591" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Robust classification with convolutional prototype learning</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3474" to="3482" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">MedMNIST v2-a large-scale lightweight benchmark for 2D and 3D biomedical image classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Data</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">41</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Centralized space learning for open-set computer-aided diagnosis</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1630</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Counterfactual zero-shot and open-set visual recognition</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">S</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="15404" to="15414" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Towards robust pattern recognition: a review</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="894" to="922" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Learning placeholders for open-set recognition</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Zhan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4401" to="4410" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
