<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CoactSeg: Learning from Heterogeneous Data for New Multiple Sclerosis Lesion Segmentation</title>
				<funder ref="#_a86bdAT">
					<orgName type="full">Monash Institute of Medical Engineering</orgName>
					<orgName type="abbreviated">MIME</orgName>
				</funder>
				<funder ref="#_cZZPSgQ">
					<orgName type="full">Novartis</orgName>
				</funder>
				<funder>
					<orgName type="full">Monash FIT Start-up Grant</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Yicheng</forename><surname>Wu</surname></persName>
							<email>yicheng.wu@monash.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Data Science &amp; AI</orgName>
								<orgName type="department" key="dep2">Faculty of Information Technology</orgName>
								<orgName type="institution">Monash University</orgName>
								<address>
									<postCode>3168</postCode>
									<settlement>Melbourne</settlement>
									<region>VIC</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhonghua</forename><surname>Wu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">SenseTime Research</orgName>
								<address>
									<postCode>069547</postCode>
									<country>Singapore, Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hengcan</forename><surname>Shi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Data Science &amp; AI</orgName>
								<orgName type="department" key="dep2">Faculty of Information Technology</orgName>
								<orgName type="institution">Monash University</orgName>
								<address>
									<postCode>3168</postCode>
									<settlement>Melbourne</settlement>
									<region>VIC</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bjoern</forename><surname>Picker</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Alfred Health Radiology</orgName>
								<orgName type="institution" key="instit2">Alfred Health</orgName>
								<address>
									<postCode>3004</postCode>
									<settlement>Melbourne</settlement>
									<region>VIC</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Central Clinical School</orgName>
								<orgName type="department" key="dep2">Faculty of Medicine, Nursing and Health Sciences</orgName>
								<orgName type="institution">Monash University</orgName>
								<address>
									<postCode>3800</postCode>
									<settlement>Melbourne</settlement>
									<region>VIC</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Winston</forename><surname>Chong</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Alfred Health Radiology</orgName>
								<orgName type="institution" key="instit2">Alfred Health</orgName>
								<address>
									<postCode>3004</postCode>
									<settlement>Melbourne</settlement>
									<region>VIC</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Central Clinical School</orgName>
								<orgName type="department" key="dep2">Faculty of Medicine, Nursing and Health Sciences</orgName>
								<orgName type="institution">Monash University</orgName>
								<address>
									<postCode>3800</postCode>
									<settlement>Melbourne</settlement>
									<region>VIC</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jianfei</forename><surname>Cai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Data Science &amp; AI</orgName>
								<orgName type="department" key="dep2">Faculty of Information Technology</orgName>
								<orgName type="institution">Monash University</orgName>
								<address>
									<postCode>3168</postCode>
									<settlement>Melbourne</settlement>
									<region>VIC</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">CoactSeg: Learning from Heterogeneous Data for New Multiple Sclerosis Lesion Segmentation</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="3" to="13"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">028961C5FFC992FDAA00090BC7778936</idno>
					<idno type="DOI">10.1007/978-3-031-43993-3_1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-23T22:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Multiple Sclerosis Lesion</term>
					<term>Longitudinal Relation</term>
					<term>Heterogeneous Data</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>New lesion segmentation is essential to estimate the disease progression and therapeutic effects during multiple sclerosis (MS) clinical treatments. However, the expensive data acquisition and expert annotation restrict the feasibility of applying large-scale deep learning models. Since single-time-point samples with all-lesion labels are relatively easy to collect, exploiting them to train deep models is highly desirable to improve new lesion segmentation. Therefore, we proposed a coaction segmentation (CoactSeg) framework to exploit the heterogeneous data (i.e., new-lesion annotated two-time-point data and all-lesion annotated single-time-point data) for new MS lesion segmentation. The CoactSeg model is designed as a unified model, with the same three inputs (the baseline, follow-up, and their longitudinal brain differences) and the same three outputs (the corresponding all-lesion and new-lesion predictions), no matter which type of heterogeneous data is being used. Moreover, a simple and effective relation regularization is proposed to ensure the longitudinal relations among the three outputs to improve the model learning. Extensive experiments demonstrate that utilizing the heterogeneous data and the proposed longitudinal relation constraint can significantly improve the performance for both new-lesion and all-lesion segmentation tasks. Meanwhile, we also introduce an in-house MS-23v1 dataset, including 38 Oceania single-time-point samples with all-lesion labels. Codes and the dataset are released at https://github.com/ycwu1997/CoactSeg.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Multiple sclerosis (MS) is a common inflammatory disease in the central nervous system (CNS), affecting millions of people worldwide <ref type="bibr" target="#b6">[7]</ref> and even leading to the disability of young population <ref type="bibr" target="#b18">[19]</ref>. During the clinical treatment of MS, lesion changes, especially the emergence of new lesions, are crucial criteria for estimating the effects of given anti-inflammatory disease-modifying drugs <ref type="bibr" target="#b1">[2]</ref>. However, MS lesions are usually small, numerous, and appear similar to Gliosis or other types of brain lesions, e.g., ischemic vasculopathy <ref type="bibr" target="#b7">[8]</ref>. Identifying MS lesion changes from multi-time-point data is still a heavy burden for clinicians. Therefore, automatically quantifying MS lesion changes is essential in constructing a computer-aided diagnosis (CAD) system for clinical applications.</p><p>Deep learning has been widely used for MS lesion segmentation from brain MRI sequences <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b24">25]</ref>. For example, the icobrain 5.1 framework <ref type="bibr" target="#b15">[16]</ref> combined supervised and unsupervised approaches and designed manual rules to fuse the final segmentation results. Some works <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b27">28]</ref> further studied the complementary features from other MRI modalities for MS lesion segmentation. Meanwhile, to train a better deep model, class-imbalance issues <ref type="bibr" target="#b25">[26]</ref> and prior brain structures <ref type="bibr" target="#b26">[27]</ref> have been respectively investigated to improve the performance. With the impressive performance achieved by existing pure MS lesion segmentation methods <ref type="bibr" target="#b10">[11]</ref>, recent attention has been shifted to analyze the longitudinal MS changes <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>, such as stable, new, shrinking, and enlarging lesions, with the focus on new MS lesion segmentation <ref type="bibr" target="#b8">[9]</ref>. However, collecting adequate well-labeled longitudinal MS lesion data for model learning is highly challenging since it needs multi-time-point data from the same set of patients, and requires costly and time-consuming expert annotations. Figure <ref type="figure" target="#fig_0">1</ref> shows the three types of heterogeneous MS lesion data: newlesion annotated two-time-point data, all-lesion annotated two-time-point data, and all-lesion annotated single-time-point data, each of which is associated with different costs. New-lesion annotated two-time-point data is the ideal one for learning new lesion segmentation, but with the highest data acquisition and annotation costs. Annotating all lesions in two-time-point data can reduce the annotation cost, but it requires accurate brain registration and rule-based postprocessing to identify lesion changes, which cannot avoid noise accumulation and often leads to sub-optimal performance. All-lesion annotated single-time-point data is with the cheapest data acquisition and annotation costs. This motivates us to raise the question: "Can we leverage all-lesion annotated single-time-point data to promote the new MS lesion segmentation?" Therefore, in this paper, we proposed a deep Coaction Segmentation (Coact-Seg) model that can unify heterogeneous data and annotations for the new MS lesion segmentation task. Specifically, CoactSeg takes three-channel inputs, including the baseline, follow-up, and corresponding differential brains, and produces all-lesion and new-lesion segmentation results at the same time. Moreover, a longitudinal relation constraint (e.g., new lesions should only appear at the follow-up scans) is proposed to regularize the model learning in order to integrate the two tasks (new and all lesion segmentation) and boost each other. Extensive experiments on two MS datasets demonstrate that our proposed CoactSeg model is able to achieve superior performance for both new and all MS lesion segmentation, e.g., obtaining 63.82% Dice on the public MICCAI-21 dataset <ref type="bibr" target="#b3">[4]</ref> and 72.32% Dice on our in-house MS-23v1 dataset, respectively. It even outperforms two neuro-radiologists on MICCAI-21.</p><p>Overall, the contributions of this work are three-fold:</p><p>-We propose a simple unified model CoactSeg that can be trained on both newlesion annotated two-time-point data and all-lesion annotated single-timepoint data in the same way, with the same input and output format; -We design a relation regularizer to ensure the longitudinal relations among all and new lesion predictions of the baseline, follow-up, and corresponding differential brains; -We construct an in-house MS-23v1 dataset, which includes 38 Oceania singletime-point 3D FLAIR scans with manual all-lesion annotations by experienced human experts. We will release this dataset publicly. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Datasets</head><p>We trained and evaluated our CoactSeg model on two MS segmentation datasets, as shown in Table <ref type="table" target="#tab_0">1</ref>. On the public MICCAI-21 dataset 1 , we only use its training set since it does not provide official labels of testing samples. Specifically, 40 two-time-point 3D FLAIR scans are captured by 15 MRI scanners at different locations. Among them, 11 scans do not contain any new MS lesions. The follow-up data were obtained around 1-3 years after the first examination. Four neuro-radiologists from different centers manually annotated new MS lesions, and a majority voting strategy was used to obtain the final ground truth. For pre-processing, the organizers only performed a rigid brain registration, and we further normalized all MRI scans to a fixed resolution of [0.5, 0.75, 0.75] mm. Since the public MS lesion data is not adequate <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4]</ref>, we further collected 38 single-time-point 3D FLAIR sequences as a new MS dataset (MS-23v1). Specifically, all samples were anonymized and captured by a 3T Siemens scanner in Alfred Health, Australia. To the best of our knowledge, this will be the first open-source dataset from Oceania for MS lesion segmentation, contributing to the diversity of existing public MS data. Two neuro-radiologists and one senior neuro-scientist segmented all MS lesions individually and in consensus using the MRIcron segmentation tool 2 . The voxel spacing of all samples is then normalized to an isotropic resolution of [0.8, 0.8, 0.8] mm.</p><p>Finally, when conducting the mixed training, we used a fixed data split in this paper (i.e., 62 samples for training and 16 for validation in total). Note that we followed the setting of the public challenge <ref type="bibr" target="#b3">[4]</ref>, which selects the new validation set from MICCAI-21 that does not include samples without any new MS lesions.   all-lesion and new-lesion predictions as</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Multi-head Architecture</head><formula xml:id="formula_0">p s1 al , p s2 al , p s nl = F θ (x s b , x s fu , x 0 d ) p t1 al , p t2 al , p t nl = F θ (x t b , x t fu , x t d ).<label>(1)</label></formula><p>For single-time-point samples x s ∈ X s , x s b and x s fu are identical as x s , and the difference map becomes an all-zero matrix x 0 d , with p s1 al , p s2 al and p s nl being the corresponding all-lesion and new-lesion predictions of x s . For two-time-point data x t ∈ X t , x t b and x t fu respectively denote the first and second time-point data samples, with p t1 al , p t2 al and p t nl being the all-lesion segmentation results at the first and second time-point and the new-lesion results of x t , respectively.</p><p>In this way, we unify the learning of both single and two-time-point data with heterogeneous annotations by using the same model F θ , with the same input and output formats. Note that, inspired by semi-supervised learning <ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref>, we mix x s and x t samples into each batch for training. Given the heterogeneous annotations, i.e., all-lesion labels for single-time-point data and new-lesion labels for two-time-point data, we apply the following corresponding supervisions:</p><formula xml:id="formula_1">L al = Dice(p s1 al , y s al ) + Dice(p s2 al , y s al ) L nl = Dice(p t nl , y t nl )<label>(2)</label></formula><p>where Dice refers to the common Dice loss for medical segmentation tasks. We use a 3D VNet <ref type="bibr" target="#b14">[15]</ref> as the backbone of F θ and three prediction heads are designed as individual convolutional blocks. Note that, the last prediction head also receives the features from the first two in order to capture the all-lesion information. Compared to the recent work <ref type="bibr" target="#b29">[30]</ref> for exploiting heterogeneous data, our architecture avoids the complicated design of dynamic prediction heads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Longitudinal Relation Regularization</head><p>Human experts usually identify new MS lesions by comparing the brain MRI scans at different time points. Inspired by this, we further propose a longitudinal relation constraint to compare samples from different time points:</p><formula xml:id="formula_2">L rr = ||p s1 al , p s2 al || 2 + ||p t1 al ⊗ y t nl , 0|| 2 + ||p t2 al ⊗ y t nl , 1|| 2<label>(3)</label></formula><p>where ⊗ is a masking operation. The first term in ( <ref type="formula" target="#formula_2">3</ref>) is to encourage the alllesion predictions p s1 al and p s2 al to be the same since there is no brain difference for single-time-point data. The second and third terms in (3) are to ensure that the new-lesion region can be correctly segmented as the foreground in p t2 al and as the background in p t1 al in two-time-point data with only new lesion labels y t nl . Finally, the overall loss function to train our CoactSeg model becomes a weighted sum of L al , L nl , and the regularization L rr :</p><formula xml:id="formula_3">L = L al + λ 1 × L nl + λ 2 × L rr (<label>4</label></formula><formula xml:id="formula_4">)</formula><p>where λ 1 and λ 2 are constants to balance different tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>Implementation Details. For training, we normalize all inputs as zero mean and unit variance. Then, among common augmentation operations, we use the random flip or rotation to perturb inputs. Since MS lesions are always small, we apply a weighted cropping strategy to extract 3D patches of size 80 × 80 × 80 to relieve the class imbalance problem <ref type="bibr" target="#b25">[26]</ref>. Specifically, if the input sample contains the foreground, we randomly select one of the foreground voxels as the patch center and shift the patch via a maximum margin of [-10, 10] voxels. Otherwise, we randomly crop 3D patches. The batch size is set as eight (i.e., four new-lesion two-time-point samples and four all-lesion single-time-point samples). We apply Adam optimizer with a learning rate of 1e-2. The overall training iterations are 20k. In the first 10k iterations, λ 1 and λ 2 are set to 1 and 0, respectively, in order to train the model for segmenting MS lesions at the early training stage. After that, we set λ 2 as 1 to apply the relation regularization. During testing, we extract the overlapped patches by a stride of 20 × 20 × 20 and then re-compose them into the entire results. Note that we follow <ref type="bibr" target="#b17">[18]</ref> to mask the non-brain regions and all experiments are only conducted in the brain regions with the same environment (Hardware: Single NVIDIA Tesla V100 GPU; Software: PyTorch 1.8.0, Python 3.8.10; Random Seed: 1337). The computational complexity of our model is 42.34 GMACs, and the number of parameters is 9.48 M. dataset) are used to evaluate the proposed CoactSeg. Besides common segmentation metrics <ref type="bibr" target="#b12">[13]</ref> including Dice, Jaccard, 95% Hausdorff Distance (95HD), and Average Surface Distance (ASD), we further follow <ref type="bibr" target="#b2">[3]</ref> to use the instance-level F1 score (F1) to denote the lesion-wise segmentation performance. Here, tiny lesions (i.e., fewer than 11 voxels) are not included in the F1 calculation as <ref type="bibr" target="#b2">[3]</ref>.   <ref type="bibr" target="#b13">[14]</ref>, our model can even predict new lesions with low contrast (indicated by the enlarged yellow rectangles in Fig. <ref type="figure" target="#fig_4">3</ref>). Table <ref type="table" target="#tab_1">2</ref> gives the quantitative results on MICCAI-21. We can see that: 1) Our model achieves good segmentation performance for new MS lesion segmentation and outperforms the second-best method <ref type="bibr" target="#b13">[14]</ref> by 7.01% in Dice; 2) Compared with human experts, our proposed model also outperforms two of them (i.e., #3 and #4) in terms of the segmentation and the shape-related metrics; 3) For the lesion-wise F1 score, our method significantly reduces the performance gap between deep models and human experts, achieving a comparable F1 with expert #3 (i.e., 61.96% vs. 62.88%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance for MS Lesion Segmentation. Two MS tasks (i.e., newlesion segmentation on MICCAI-21 and all-lesion segmentation on our MS-23v1</head><p>Figure <ref type="figure" target="#fig_6">4</ref> shows the all-lesion segmentation results of our CoactSeg model on our in-house MS-23v1 dataset. It can be seen that CoactSeg is able to segment most MS lesions, even for very tiny ones (highlighted by red arrows). Moreover, we can see that the segmentation results of the first two prediction heads are relatively consistent (i.e., the 2nd and 3rd columns of Fig. <ref type="figure" target="#fig_6">4</ref>), demonstrating the effectiveness of our proposed relation regularization. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we have presented a unified model CoactSeg for new MS lesion segmentation, which can predict new MS lesions according to the two-time-point inputs and their differences while at the same time segmenting all MS lesions. Our model effectively exploits heterogeneous data for training via a multi-head architecture and a relation regularization. Experimental results demonstrated that introducing all-lesion single-time-point data can significantly improve the new-lesion segmentation performance. Moreover, the relation constraint also facilitates the model to capture the longitudinal MS changes, leading to a further performance gain. Our in-house MS-23v1 dataset will be made public to help the MS lesion research. Future works will explore more longitudinal relations to study the fine-grained MS changes as well as consider more powerful constraints to address the domain gap <ref type="bibr" target="#b20">[21]</ref> and fairness <ref type="bibr" target="#b28">[29]</ref> problems. Moreover, we plan to collect and annotate more MS lesion data to improve the possibility of training large-scale deep models for clinical applications <ref type="bibr" target="#b16">[17]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Heterogeneous data and annotations: new-lesion annotated two-time-point data (Left), all-lesion two-time-point data (Middle), and all-lesion single-time-point data (Right), with different expert annotation and data acquisition costs. Here, we exploit additional single-time-point data (Right) to help new MS lesion segmentation.</figDesc><graphic coords="2,44,31,346,85,329,44,156,88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2</head><label>2</label><figDesc>Figure 2 illustrates the overall pipeline of our proposed CoactSeg model F θ . We construct a quadruple set (X b , X fu , X d , Y ) for the model training. Here, the longitudinal difference map x d ∈ X d is obtained by a subtraction operation between the baseline brain x b ∈ X b and its follow-up x fu ∈ X fu (i.e., x d = x fux b ). Therefore, given heterogeneous annotations, i.e., all-lesion labels y s al ∈ Y s al in single-time-point data and new-lesion labels y t nl ∈ Y t nl in two-time-point data, the CoactSeg model F θ is designed to exploit both for the model training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2</head><label>2</label><figDesc>Figure2shows that new-lesion regions are highlighted in the brain difference map x d . Hence, besides x b and x fu , CoactSeg also receives x d as inputs. It generates 1 https://portal.fli-iam.irisa.fr/msseg-2/. 2 https://www.nitrc.org/projects/mricron/.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>Fig.2. Pipeline of our proposed CoactSeg model F θ , which receives the baseline X b , follow-up X fu , and corresponding longitudinal brain differences X d as inputs. F θ segments all lesions P al and predicts new lesions P nl in the condition of X b , X fu and X d . Note that new-lesion regions would have higher intensities in X d .</figDesc><graphic coords="5,56,46,54,14,340,00,137,56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Exemplar results for new MS lesion segmentation on the MICCAI-21 dataset.</figDesc><graphic coords="7,56,46,292,16,340,00,101,20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3</head><label>3</label><figDesc>Figure3illustrates that our proposed CoactSeg accurately segments the tiny new lesions on MICCAI-21. Compared to the recent work<ref type="bibr" target="#b13">[14]</ref>, our model can even predict new lesions with low contrast (indicated by the enlarged yellow rectangles in Fig.3). Table2gives the quantitative results on MICCAI-21. We can see that: 1) Our model achieves good segmentation performance for new MS lesion segmentation and outperforms the second-best method [14] by 7.01% in Dice; 2) Compared with human experts, our proposed model also outperforms two of them (i.e., #3 and #4) in terms of the segmentation and the shape-related metrics; 3) For the lesion-wise F1 score, our method significantly reduces the performance gap between deep models and human experts, achieving a comparable F1 with expert #3 (i.e., 61.96% vs. 62.88%).Figure4shows the all-lesion segmentation results of our CoactSeg model on our in-house MS-23v1 dataset. It can be seen that CoactSeg is able to segment</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Exemplar results for all MS lesion segmentation obtained by our CoactSeg model on our in-house MS-23v1 dataset (2D View: Left; 3D View: Right).</figDesc><graphic coords="8,41,79,54,41,340,36,96,28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Details of the experimental datasets in this work. Note that the data split is fixed and shown in the 4th column (Order: Training, Validation).</figDesc><table><row><cell>Dataset</cell><cell cols="4">Region Modality # of subjects # of time points Annotation Type</cell></row><row><cell cols="2">MICCAI-21 [4] France FLAIR</cell><cell>40 (32, 8)</cell><cell>2</cell><cell>New lesions</cell></row><row><cell cols="2">MS-23v1 (Ours) Oceania FLAIR</cell><cell>38 (30, 8)</cell><cell>1</cell><cell>All lesions</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Comparisons of new-lesion segmentation on MICCAI-21. Note that the human experts' performance is shown based on their individually annotated results.</figDesc><table><row><cell>Method</cell><cell cols="4">Performance on MICCAI-21 (New MS Lesions)</cell><cell></cell></row><row><cell></cell><cell cols="5">Dice (%) ↑ Jaccard (%) ↑ 95HD (voxel) ↓ ASD (voxel) ↓ F1 (%) ↑</cell></row><row><cell>SNAC [14]</cell><cell>53.07</cell><cell>39.19</cell><cell>66.57</cell><cell>26.39</cell><cell>30.71</cell></row><row><cell cols="2">SNAC (VNet) [14] 56.81</cell><cell>42.85</cell><cell>26.58</cell><cell>12.49</cell><cell>57.59</cell></row><row><cell>Neuropoly [12]</cell><cell>56.33</cell><cell>43.23</cell><cell>54.95</cell><cell>24.16</cell><cell>17.47</cell></row><row><cell>CoactSeg (Ours)</cell><cell>63.82</cell><cell>51.68</cell><cell>30.35</cell><cell>12.14</cell><cell>61.96</cell></row><row><cell cols="2">Human Expert #1 77.52</cell><cell>65.76</cell><cell>27.83</cell><cell>5.47</cell><cell>82.34</cell></row><row><cell cols="2">Human Expert #2 66.89</cell><cell>58.11</cell><cell>N/A</cell><cell>N/A</cell><cell>68.19</cell></row><row><cell cols="2">Human Expert #3 58.56</cell><cell>46.51</cell><cell>60.99</cell><cell>12.41</cell><cell>62.88</cell></row><row><cell cols="2">Human Expert #4 60.68</cell><cell>49.95</cell><cell>N/A</cell><cell>N/A</cell><cell>66.58</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Ablation studies of our proposed CoactSeg model F θ and * indicates that we apply a stage-by-stage training strategy in the experiments. Table3further shows the ablation study for both new and all MS lesion segmentation tasks. It reveals that: 1) Introducing the heterogeneous data significantly improves the performance of new-lesion segmentation on MICCAI-21 with an average Dice gain of 2.64%; 2) Exploiting the relation regularization for mixed training can further improve the performance on the two datasets; 3) The simple stage-by-stage training strategy (See the Implementation Details 4) can better balance two tasks and achieve the overall best segmentation performance for both tasks.</figDesc><table><row><cell cols="2">Lrr Training Data</cell><cell></cell><cell cols="3">MICCAI-21 (New MS Lesions)</cell><cell cols="2">MS-23v1 (All MS Lesions)</cell><cell></cell></row><row><cell></cell><cell cols="8">MICCAI-21 MS-23v1 Dice (%) ↑ 95HD (voxel) ↓ F1 (%) ↑ Dice (%) ↑ 95HD (voxel) ↓ F1 (%) ↑</cell></row><row><cell>w/o</cell><cell></cell><cell></cell><cell>59.91</cell><cell>35.73</cell><cell>45.61</cell><cell>N/A</cell><cell></cell><cell></cell></row><row><cell>w/o</cell><cell></cell><cell></cell><cell>N/A</cell><cell></cell><cell></cell><cell>70.94</cell><cell>14.46</cell><cell>44.82</cell></row><row><cell>w/o</cell><cell></cell><cell></cell><cell>61.53</cell><cell>43.05</cell><cell>51.54</cell><cell>69.41</cell><cell>18.93</cell><cell>34.43</cell></row><row><cell>w/</cell><cell></cell><cell></cell><cell>58.49</cell><cell>50.17</cell><cell>51.35</cell><cell>N/A</cell><cell></cell><cell></cell></row><row><cell>w/</cell><cell></cell><cell></cell><cell>N/A</cell><cell></cell><cell></cell><cell>71.28</cell><cell>12.45</cell><cell>42.96</cell></row><row><cell>w/</cell><cell></cell><cell></cell><cell>62.15</cell><cell>43.26</cell><cell>56.97</cell><cell>70.44</cell><cell>12.88</cell><cell>44.04</cell></row><row><cell>w/</cell><cell>*</cell><cell>*</cell><cell>63.82</cell><cell>30.35</cell><cell>61.96</cell><cell>72.32</cell><cell>12.38</cell><cell>42.51</cell></row><row><cell cols="3">Ablation Study.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement. This work was supported in part by the <rs type="funder">Monash FIT Start-up Grant</rs>, in part by the <rs type="funder">Novartis</rs> (ID: <rs type="grantNumber">76765455</rs>), and in part by the <rs type="funder">Monash Institute of Medical Engineering (MIME)</rs> Project: <rs type="grantNumber">2022-13</rs>. We here appreciate the public repositories of SNAC [14] and Neuropoly [12], and also thanks for the efforts to collect and share the MS dataset [2] and the MS-23v1 dataset from <rs type="affiliation">Alfred Health, Australia</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_cZZPSgQ">
					<idno type="grant-number">76765455</idno>
				</org>
				<org type="funding" xml:id="_a86bdAT">
					<idno type="grant-number">2022-13</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Longitudinal multiple sclerosis lesion segmentation: resource and challenge</title>
		<author>
			<persName><forename type="first">A</forename><surname>Carass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">148</biblScope>
			<biblScope unit="page" from="77" to="102" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Msseg-2 challenge proceedings: multiple sclerosis new lesions segmentation challenge using a data management and processing infrastructure</title>
		<author>
			<persName><forename type="first">O</forename><surname>Commowick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cervenansky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cotton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dojat</surname></persName>
		</author>
		<idno>MICCAI 2021</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">126</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Objective evaluation of multiple sclerosis lesion segmentation using a data management and processing infrastructure</title>
		<author>
			<persName><forename type="first">O</forename><surname>Commowick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">13650</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multiple sclerosis lesions segmentation from multiple experts: the MICCAI 2016 challenge dataset</title>
		<author>
			<persName><forename type="first">O</forename><surname>Commowick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">244</biblScope>
			<biblScope unit="page">118589</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">4d deep learning for multiple-sclerosis lesion activity segmentation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Gessert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MIDL 2020</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multiple sclerosis lesion activity segmentation with attentionguided two-path CNNs</title>
		<author>
			<persName><forename type="first">N</forename><surname>Gessert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer. Med. Imaging Graph</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page">101772</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Placebo-controlled phase 3 study of oral bg-12 for relapsing multiple sclerosis</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">N. Engl. J. Med</title>
		<imprint>
			<biblScope unit="volume">367</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1098" to="1107" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<author>
			<persName><forename type="first">T</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MS or not MS: T2-weighted imaging (t2wi)-based radiomic findings distinguish MS from its mimics</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page">103756</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fully automated longitudinal segmentation of new or enlarged multiple sclerosis lesions using 3d convolutional neural networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Krüger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage: Clin</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page">102445</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multiple sclerosis cortical and WM lesion segmentation at 3t MRI: a deep learning method based on flair and mp2rage</title>
		<author>
			<persName><forename type="first">La</forename><surname>Rosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage: Clin</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page">102335</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multiple sclerosis lesion analysis in brain magnetic resonance images: techniques and clinical applications</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Biomed. Health Inf</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2680" to="2692" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Team neuropoly: description of the pipelines for the MICCAI 2021 MS new lesions segmentation challenge</title>
		<author>
			<persName><forename type="first">U</forename><surname>Macar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">N</forename><surname>Karthik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lemay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen-Adad</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.05409</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Maier-Hein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.01653</idno>
		<title level="m">Metrics reloaded: pitfalls and recommendations for image analysis validation</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Estimating lesion activity through feature similarity: a dual path UNET approach for the msseg2 MICCAI challenge</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mariano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yuling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Linda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chenyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Michael</surname></persName>
		</author>
		<ptr target="https://github.com/marianocabezas/msseg2" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">V-net: fully convolutional neural networks for volumetric medical image segmentation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Milletari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Ahmadi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="565" to="571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">icobrain MS 5.1: combining unsupervised and supervised approaches for improving the detection of multiple sclerosis lesions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rakić</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage: Clin</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page">102707</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Within-subject template estimation for unbiased longitudinal image analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Reuter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Schmansky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Rosas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fischl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1402" to="1418" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Automated brain extraction of multi-sequence MRI using artificial neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human Brain Mapping</title>
		<imprint>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Confirmed disability progression as a marker of permanent disability in multiple sclerosis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sharmin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. J. Neurol</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2321" to="2334" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">LG-net: lesion gate network for multiple sclerosis lesion inpainting</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cabezas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Barnett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87234-2_62</idno>
		<idno>978- 3-030-87234-2 62</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="660" to="669" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learn to ignore: domain adaptation for multi-site MRI analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wolleb</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16449-1_69</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16449-169" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="725" to="735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Mutual consistency learning for semi-supervised medical image segmentation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page">102530</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Exploring smoothness and class-separation for semi-supervised medical image segmentation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16443-9_4</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16443-94" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13435</biblScope>
			<biblScope unit="page" from="34" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Semi-supervised left atrium segmentation with mutual consistency training</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87196-3_28</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87196-328" />
	</analytic>
	<monogr>
		<title level="m">MIC-CAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="297" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Review of deep learning approaches for the segmentation of multiple sclerosis lesions on brain MRI</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Neuroinform</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">610967</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Qsmrim-net: imbalance-aware learning for identification of chronic active multiple sclerosis lesions on quantitative susceptibility maps</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neu-roImage: Clin</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">102979</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.07895</idno>
		<title level="m">Spatially covariant lesion segmentation</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">All-net: anatomical information lesion-wise loss function integrated into neural network for multiple sclerosis lesion segmentation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage: Clin</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">102854</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">On the interaction between node fairness and edge privacy in graph neural networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.12951</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Dodnet: learning to segment multi-organ and tumors from multiple partially labeled datasets</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2021</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1195" to="1204" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
