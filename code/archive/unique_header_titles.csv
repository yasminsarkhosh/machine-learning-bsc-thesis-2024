,header_titles
0,Introduction
1,Related Work
2,Model
3,Inference
4,Training
5,Dataset
6,Experimental Setup and Baselines
7,Method
8,Pathology Detection Results
9,Discussion and Conclusion
10,Conclusion.
11,Supplementary Information
12,Methodology and Materials
13,Kinetic Modelling
14,Proposed Pipeline
15,Curve Fit
16,Results
17,(Color figure online)
18,Discussion
19,Conclusion
20,Table 1 .
21,Attentive Multiple-Exit CAM (AME-CAM)
22,Implementation Details and Evaluation Protocol
23,Quantitative and Qualitative Comparison with State-of-the-Art
24,Effect of Different Aggregation Approaches:
25,Selected Exit
26,.721 ± 0.086 0.571 ± 0.101 14.940 ± 8.736
27,Experiments
28,Datasets
29,Architecture and Optimization
30,Results and Discussion
31,Background on Diffusion Models
32,Implementation Details
33,Preliminaries
34,S 2 ME: Spatial-Spectral Mutual Teaching and Ensemble Learning
35,Experimental Setup
36,Results and Analysis
37,Ablation Studies
38,0
39,Acknowledgements
40,Tracking Adaptation for Local Feature Learning
41,SfM as Supervision for Feature Extraction.
42,3D Reconstruction of Training Set Videos.
43,SfM Results
44,Conclusions
45,34851 45471 42727 33277 36403 19286 31851 34838.0 (
46,Knowledge Distillation by Weighted Logits Map:
47,Methodology
48,Test-Time Fine-Tuning (TTFT) Network and Its Pipeline
49,Parameter Fluctuation: Parameter Randomization Method
50,|X |
51,Experimental Set-Ups
52,Comparison Analysis
53,Ablation Study
54,Image Compression
55,Latent Diffusion Model
56,Ablation Analysis
57,Comparison with State-of-the-Art Methods
58,Generalization Evaluation
59,Conclusion and Limitations
60,Experimental Design
61,Correspondence Generation
62,Mesh Autoencoder (M-AE):
63,Implicit Field Decoder (IM-NET):
64,Analysis
65,Shape Variation Autoencoder (SP-VAE):
66,Experiments and Discussion
67,Limitations and Future Scope
68,3)
69,The Minimax Optimization of VAT
70,Adversarial Local Distribution
71,Cross-Adversarial Distribution Regularization
72,Multiple Particle-Based Search to Approximate the Cross-ALD Regularization
73,Cross-ALD Regularization Loss in Medical Semi-supervised Image Segmentation
74,Diversity of Adversarial Particle Comparison
75,Performance Evaluation on the ACDC and la Datasets
76,Materials and Methods
77,PICTURE
78,Known Operators
79,Unsupervised Training
80,Dataset and Quantitative Metrics
81,Network Architecture and Training
82,Compared Methods
83,Results and Discussions
84,Overview
85,Slide-Level Clustering
86,Intra-Slide Distillation
87,Inter-Slide Distillation
88,Experimental Results
89,Weakly-Supervised Classification
90,Number of Prototypes.
91,Refinement via Expectation Maximization Algorithm
92,Contribution:
93,Related Work:
94,Experiments and Results
95,Ablation and Sensitivity Analysis on Cross-Validation Structure:
96,Discussion:
97,Tumor epithelial Ɵssue
98,Classification with Deep Text Guidance
99,Knowledge Attention Module
100,Pseudo Label Generation
101,Compare with State-of-the-Arts
102,Methods
103,Formulation of Meta Learning Rate
104,Input:
105,Online Learning Rate Adaptation
106,Proportional Hyper Learning Rate
107,Generalizability Validation on Training Data Batch
108,Experimental Settings
109,Comparative Experiments
110,Results on Lesion Detection Tasks.
111,Discussion and Findings
112,The Effectiveness of Proportional Hyper-LR and Training Batches
113,Single-Scale.
114,TCGA Lung Dataset.
115,Comparison with the State-of-the-art
116,Model Analysis
117,Problem Formulation
118,Class Consistency with Feature Variety Constraint TE Method
119,Experiment on MSD Dataset
120,Sampling of Positive and Negative Pairs
121,Architecture
122,Loss Function
123,Evaluation Protocol
124,Pre-training
125,Evaluation
126,Learning Domain-Specific Prompts
127,Learning Domain-Aware Representation by Fusion
128,Adversarial Learning to Enhance the Generalization Ability
129,Total Loss
130,Comparison with State-of-the-Art (SOTA) Method
131,Domain-Distance-Modulated Spectral Sensitivity (DoDiSS)
132,Domain Distance Measurement.
133,DoDiSS Computation.
134,Sensitivity-Guided Spectral Adversarial Mixup (SAMix)
135,Method Effectiveness
136,Data Efficiency
137,.41 82.58 80.84 75.90
138,Contributions:
139,Our Method
140,Self-supervised Instance Learning:
141,Generality of the Method:
142,Ablation Study:
143,Neural State Space Models
144,MIL Training
145,Multitask Training
146,Data
147,Multitask Learning Results.
148,Background and Motivation
149,Problem Definition
150,Training Stage
151,Inference Stage
152,Datasets and Setup
153,Evaluation Metrics:
154,Background
155,Vector-Quantized Variational Autoencoder
156,Transformer
157,Anomaly Detection via Kernel Density Estimation Maps
158,VQ-VAE Spatial Conditioning
159,Transformer Spatial Conditioning
160,cBRN Guided Divergence-Aware Decoupled Dual-Flow
161,HSI Pseudo-label Distillation with Momentum MixUp Decay
162,Cross-Subset Structure Incremental Evolving
163,Cross-Modality Structure Incremental Evolving
164,Diffusion Sampler
165,Re-Weighting Module
166,Refinement Loss ℒ
167,Mask Conditioning
168,Adaptive Loss Re-weighting
169,Prediction-Guided Sample Refinement
170,ArSDM Experimental Settings
171,Downstream Experimental Settings
172,Quantitative Comparisons
173,Qualitative Analyses
174,Table 4 .
175,Diffusion Models
176,HistoDiffusion
177,Classifier-guided Conditional Synthesis.
178,Object-Centric Diffeomorphism as a Generative Model
179,Online Augmentations with Generative Models
180,Model:
181,Deformation-Based da for Kidney Tumour Segmentation
182,Discussion and Conclusions
183,Present Work.
184,Prototype Generation
185,Affinity-Aware Consistency Learning
186,Cross-Site Feature Alignment (CSFA) Module
187,Table 3 .
188,Centroid-Aware Feature Recalibration
189,Network Architecture
190,Result and Discussions
191,Table 1
192,MTANN Deep Learning
193,Sensitivity-Based Structure Optimization
194,Calculation of Weighted Function Maps
195,Unsupervised Hierarchical Clustering
196,Dynamic Contrast-Enhanced Liver CT
197,FeSViBS Framework
198,Conclusion and Future Directions
199,Pre-processing Unit
200,Convolutional Encoder and Convolutional Down-Sampler
201,Single-Phase Liver Transformer Block
202,Multi-phase Liver Transformer Block
203,Liver Lesion Classification
204,Region-Based Active Learning for WSI Annotation
205,Region Selection Methods
206,WSI Semantic Segmentation Framework
207,COLosSAL Benchmark Definition
208,3D Medical Image Datasets
209,Cold-Start AL Scenarios
210,Baseline Cold-Start Active Learners
211,Experiments and Analysis
212,Pseudo Labels for Multi-organ Segmentation
213,The Proposed Multi-organ Segmentation Model
214,Image-Aware Organ-Specific Heads:
215,Text Driven Head Parameter Generation:
216,Difference from Universal Model
217,Computational Complexity Analysis
218,Experiment and Result
219,Baselines and Metrics:
220,Implementation Details:
221,Results:
222,Contributions: Our contributions are as follows:
223,First Training Stage for Self-supervised Segmentation
224,Random Image Transformation:
225,Cross-view Consistency:
226,Second Training Stage for Faithful Image Synthesis
227,Inference Stage for Medical Image Editing
228,Evaluation of the Synthesized Images:
229,Pre-training Stage
230,Local Region
231,Fine-Tuning Stage
232,Pre-training Dataset
233,Fine-Tuning Datasets
234,Quantitative Results
235,Qualitative Results
236,FedGrav
237,Method Accuracy (%)
238,Datesets and Settings
239,MICCAI FeTS2021
240,Conditional GANs for Contrast Signal Synthesis
241,Noise-Preserving Content Loss
242,Numerical Results
243,Spatial-Temporal Deformable Attention
244,Spatial-Temporal Deformable Attention Based Encoder and Decoder
245,Multi-frame Prediction with Encoder Feature Shuffle
246,Dataset and Implementation Details
247,State-of-the-Art Comparison
248,Differentiable Directed Accumulation
249,Network Layer for DA-TR:
250,Comparator Methods and Implementation Details
251,Results and Ablation Study
252,Subject-wise Results:
253,Discussions
254,Framework Overview
255,Feature-Based Target Sample Selection
256,Model-Based Informative Sample Selection
257,"Dataset, Settings, Metrics and Competitors"
258,Performance Comparison
259,Method Overview
260,Correlation Extraction
261,Modal Attention
262,Baseline Methods
263,GFF.
264,Problem Setup
265,Self-supervised Task Generation
266,Volumetric Segmentation Strategy
267,Hybrid-Proxy Model
268,Balanced-Hybrid-Proxy Loss
269,Balanced-Weighted Cross-Entropy Loss
270,Algorithm 1 :
271,Table 2 .
272,Prompt-Based Visual Model
273,Diversified Visual Prompt Tuning
274,Tandem Selective Labeling
275,Encoder-Decoder Backbone
276,Universal Prompt
277,Dynamic Task Prompt
278,Transfer Learning
279,Datasets and Evaluation Metric
280,Controllable Fusion Block
281,Controllable Cross-modulated Layer Normalization (cLN):
282,Training and Inference
283,Human Evaluation Study
284,Approach
285,Multi-modal Encoder
286,Knowledge Condensation and Interaction
287,Task-Specific Networks
288,Materials
289,Compared with Advanced Segmentation Approaches
290,SDT Energy Function
291,SDT Network
292,Target SDT Generation.
293,Histopathology Instance Segmentation
294,Methods in Comparison.
295,Results.
296,Data Sets and Implementation Details
297,Comparison with DiNTS
298,KiTS'19 Experiments
299,MultiTalent
300,Baselines
301,Noise Detector
302,Noise Cleaner
303,Objective Function
304,Denoising Diffusion Probabilistic Models (DDPM) for Unconditional Image Generation
305,Image Enhancement with Denoising Algorithm
306,Pre-Trained Diffusion Models for Plug-and-play Medical Image Enhancement
307,Algorithm 1. Pre-trained DDPM for plug-and-play medical image enhancement
308,Setup
309,Results on the ISIC Dataset
310,Results on the Shenzhen Dataset
311,Dynamic Tolerance to Noise
312,Data Use Declaration and Acknowledgment
313,Introduction and Related Work
314,Calibrated Multi-Head Models
315,Multi-Head Ensemble Diversity
316,Multi-Head Multi Loss Models
317,Model Evaluation
318,Datasets and Architectures
319,Performance Analysis
320,Related Work.
321,Guidance Signals
322,Model Backbone and Datasets
323,Hyperparameters: Experiments
324,Additional Evaluation Metrics
325,Hyperparameters: Results
326,Additional Evaluation Metrics: Results
327,New Attention Models:
328,Drawbacks of Transformers:
329,Efficient Enhancement Transformer Block
330,Efficient Frequency Attention (EF-ATT)
331,Efficient Enhancement Multi-scale Bridge
332,Datasets:
333,Silent Failure Prevention Benchmark
334,None of the Evaluated Methods from the Literature Beats the Maximum Softmax Response Baseline Across a Realistic Range of Failure
335,Investigation of Silent Failure Sources
336,Deep Evidence Generation
337,Evidence Reconcile Block
338,Theorical Analysis of ERB
339,Comparison with the Methods
340,Restatement of Image Segmentation Based on Click
341,Scale-Aware Test-Time Click Adaptation
342,Training Objective of SaTTCA
343,Datasets and Evaluation Protocols
344,LIDC [1]:
345,LNDb [16]:
346,In-House Data (ours):
347,Mask-to-Box (M2B) Transformation
348,Scale Consistency (SC) Loss
349,Ultrasound Video Breast Lesion Segmentation Dataset
350,Proposed Method
351,Frequency-Based Feature Aggregation (FFA) Module
352,Two-Branch Decoder
353,Location-Based Contrastive Loss
354,Comparisons with State-of-the-Arts
355,Generalizability of Our Network
356,Hierarchical Aggregation of Neighborhood Context (HANC)
357,Multi Level Feature Compilation (MLFC)
358,ACC-UNet
359,Comparisons with State-of-the-Art Methods
360,Comparative Qualitative Results on the Five Datasets
361,FocalUNETR
362,The Auxiliary Task
363,Datasets and Implementation Details
364,Contouring Uncertainty
365,H
366,Visualization of Uncertainty
367,Evaluation Metrics
368,Maximum Calibration Error (MCE)
369,Heterogeneous Co-training Framework with Consistency Supervision
370,Distribution-aware Debiased Weighting (DistDW)
371,Difficulty-aware Debiased Weighting (DiffDW)
372,Liver Mask and Vessel Attention Map Generation
373,Couinaud Segmentation
374,Continuous Spatial Point Sampling Based on the Vessel Attention
375,Re
376,Datasets and Evaluation Metrics
377,Auto Contrast Enhancement
378,Cross-Scale Non-local Block
379,25 ± 0.13 Ours 85.90 ± 2.92 87.34
380,Acknowledgments
381,Existing Extensions
382,Dice Semimetric Losses
383,2-Δ IoU
384,Results on QUBIQ
385,Results on LiTS and KiTS
386,Future Works
387,Gaussian Fourier Domain Adaptation (GFDA)
388,CL on Disentangled Domain and Content
389,Consistency Constraint
390,Semi-supervised Fine-Tuning
391,Performance on SSDA
392,Performance on UDA
393,Ablation Experiments
394,Bernoulli Forward Process
395,Diverse Reverse Process
396,Detailed Procedure
397,Employing Multiple Generations. Since calculating x t-1 during inference includes the addition of 1 [t>1]
398,2)
399,Preliminary: Adversarial Attack and Anti-adversary
400,Baselines.
401,Evaluation.
402,Comparison with Existing Methods
403,Analysis on Anti-adversaries and Adversaries
404,Contributions.
405,Modality Fusion Module.
406,Parallel DDPM Path for Segmentation Feature Learning
407,EIL Integrates Multi-modality Images
408,Experiment and Results
409,Segmentation and Classification Branches/Tasks
410,Performance Evaluation and Comparative Analysis
411,Effectiveness of the Anatomy-Aware Attention (AAA) Block
412,Fig. 2. The SwinUNETR-V2 architecture
413,MSD Results.
414,Variations of SwinUNetR-V2
415,Generate Initial Pseudo-masks
416,Train Network with Initial Pseudo-masks
417,SimPLe-Based Fine-Tune and Retrain
418,Uncertainty Estimation for Classification and Segmentation
419,", . . . , α s(h,w) Q"
420,Uncertainty-Informed Mutual Learning
421,Mutual Learning Process
422,Training Conditional Denoising Diffusion Models
423,Gradient Map w.r.t Condition
424,Types Methods
425,Dual-Branch in Encoder
426,Shifted-W-MSA-Based Local Branch. The image embedding e
427,Dual-Branch in Decoder
428,Shifted-W-MCA-Based Global Branch.
429,Channel-Attention-Based Dual-Branch Fusion
430,Training Details
431,Fourier Neural Operator
432,Hartley Neural Operator (HNO)
433,Hartley Multi-head Attention (MHA)
434,Network Architectures -HNOSeg and HartleyMHA
435,Training Strategy
436,Data and Experimental Setups
437,MDViT
438,Domain Adapter (DA):
439,Mutual Knowledge Distillation (MKD):
440,Datasets and Evaluation Metrics:
441,Comparing Against BASE:
442,Ablation Studies and Plug-in Capability of DA:
443,M-GenSeg: Semi-supervised Segmentation
444,Loss Functions
445,CNN Encoder for Feature Extraction
446,Edge-Aware Feature Aggregation(EaFA) for Multi-modality Feature Selection and Fusion
447,Multi-task Prediction
448,Experimental Results and Discussion
449,RepVGG/RepConv ShuffleNet
450,RCS-Based One-Shot Aggregation
451,Detection Head
452,Dataset Details
453,P recision = T P T P + F P
454,Randomized Smoothing
455,Diffusion Probabilistic Models for Certification
456,Multi-site semi-supervised learning (MS-SSL)
457,Problem Formulation and Basic Architecture
458,Pseudo Labeling for Local Distribution Fitting
459,Category-Level Regularized Unlabeled-to-Labeled Learning
460,Stability Under Perturbations.
461,Persistent Homology
462,Cellular Sheaves
463,Shape Equivariant Learning
464,Shape Component Learning
465,Cellular Sheaves for Shape Composition
466,Composition:
467,Illustration:
468,Implementation
469,Comparison:
470,Fully ConvNeXt 3D Segmentation Architecture
471,Expansion Layer:
472,Resampling with Residual Inverted Bottlenecks
473,UpKern: Large Kernel Convolutions Without Saturation
474,"Compound Scaling of Depth, Width and Receptive Field"
475,"Configurations, Implementation and Baselines"
476,Performance Ablation of Architectural Improvements
477,Performance Comparison to Baselines
478,Kernel Smoothing Based Probability Contour
479,The KsPC-Net Architecture
480,Results on HECKTOR 2021 Dataset
481,Probability Contours
482,Experimental Settings and Implementation Details
483,Experimental Results and Comparison to Baseline Methods
484,The Survival Prediction Backbone
485,The Tumor Subtyping Network
486,The Ordinal Manifold Mixup
487,right).
488,Ablation Study of Survival Prediction
489,Boundary Evolution Image
490,Boundary Evolution Process
491,Paramterized Architecture with Image Prior
492,Evolution Uncertainty
493,Comparison with State-of-the-Arts
494,Detailed Analysis of the Evolution
495,Multi-path Parallel Embedding
496,Densely Connected Transformer
497,Segmentation Backbone Network
498,Dataset and Metrics
499,Parameter Sensitivity and Ablation Study
500,Overall Architecture
501,Teacher Election Procedure
502,Cross-Modal Knowledge Distillation
503,Missing Modality Feature Generation
504,Training and Testing
505,Data and Implementation Details
506,Overall Performance
507,Analyses
508,Data Generation
509,Statistical Analysis:
510,EGE-UNet
511,Comparative Results. The comparative experimental results presented in
512,Conclusions and Future Works
513,Diffusion Module
514,Segmentation Module
515,Model Training
516,Competing Methods and Evaluation Metrics:
517,Selective Proposal Mining
518,Morphology-Aware Semantic Grouping
519,Comparison with State-of-the-art Methods
520,Efficient Hybrid Encoder
521,Edge-Oriented Transformer Decoder
522,Dataset and Evaluation Metric
523,Ablation
524,Motivation
525,Initial Edge Detection:
526,9:
527,12:
528,21:
529,22:
530,23:
531,24:
532,25:
533,26:
534,27:
535,Dual-Stream Architecture with SpatioSpectral Representation
536,Low-Rank Decomposition and Skip Connection Ensemble
537,SA Spectral
538,Evaluation of the Proposed Dual-Stream Strategy
539,Problem Formalization
540,Classification of Changes in Lesions and in Patterns of Lesion Changes
541,Lesion Matching Computation
542,Sparse Coding Framework
543,Generalized Correntropic Loss
544,"Generalized Correntropy-Induced Exclusive 2,1"
545,Experimental Results and Conclusion
546,Conclusion:
547,Architecture Overview
548,Cross-View Representation Alignment Learning
549,View-Specific Representation Learning
550,Histologic Subtype Classification
551,Network Optimization
552,Hybrid Self-supervised Learning
553,Prototype-Based Pseudo-label Generation Method
554,Response branch
555,Cross-Region Attention Module
556,Region Constraint Module
557,Network Training
558,GVBleed Dataset
559,Results Analysis
560,Bias in Survival Prediction
561,De-biased Survival Prediction Model
562,Experiment
563,Discussions and Conclusions
564,Risk Prediction
565,Incorporating Prior Mammograms
566,abbreviated as PARE.
567,Context Segmentation
568,Intra Context Parse
569,Inter Prototype Recall
570,Updating Prototype Online:
571,Training Process of PARE
572,16:
573,17:
574,Train-Val-Test:
575,Experiment Results
576,Generalization on LDCT and NCCT:
577,Sparse R-CNN with Dual Classification Heads
578,Multi-view Reasoning
579,Multi-instance Learning
580,Table 2
581,Reversing Synthetic Anomalies
582,Ischemic Stroke Lesion Segmentation on T1w Brain MRI
583,Super-Resolution Module
584,Classification Module
585,The Results of Super-Resolution and Classification
586,Connecting Text and Imaging
587,Learning Visual Prompt
588,Distributionally Robust Learning
589,DRL for Deep Stroke Diagnosis Networks
590,Experimental Materials and Settings
591,Disease Detection
592,Contrastive Learning
593,Memory Bank Construction
594,Contrastive Feature Decoupling
595,Regularization
596,Dataset and Metric
597,PANDA-MIL.
598,Comparison Results
599,Language Syntax Based Prompt Fusion
600,Ensemble Learning Based Fusion
601,Fig. 1. Non-Markovian Diffusion Framework:
602,Non-Markovian Diffusion Model with Hybrid Condition
603,Accelerated Encoding and Sampling
604,Conclusion and Discussion
605,Overview of Framework
606,Dual-Attention Strategy for Multimodal Fusion
607,Video-Level Decision Generation
608,Materials and Implementations
609,Comparison with Other Methods
610,Patient-Slide Level MIL
611,Dataset and Evaluation
612,Comparisons and Results
613,Limitations
614,Synthesized Data Augmentation
615,Patch Gradient Reversal
616,Unsupervised Anomaly Detection: Assumptions
617,Auto-Encoders: Challenges
618,MorphAEus: Deformable Auto-encoders
619,Pathology Detection on Chest X-rays
620,Texture-Aware Vision Transformer: Combination of CNN and Transformer
621,Neural Distance: Positional and Structural Information
622,Comparisons.
623,Domain-Aware Contrastive Learning for Domain Adaptation
624,Significant in Improving Existing Tumor Augmentation Methods
625,Cross-Domain Consistency Learning for Content Preservation
626,Mask Transformers.
627,Knowledge Transfer from Contrast-Enhanced to Non-contrast CT.
628,Evaluation Metrics and Reader Study.
629,AI Models Surpass Experienced Radiologists on Non-contrast CT Scans.
630,Subgroup Analysis.
631,Single-Frame Representation for ReID
632,Multi-view Tracklet Representation for ReID
633,ReID Standalone Evaluation
634,ReID for CADx
635,Foreground Temporal Alignment
636,Background Dynamic Alignment
637,Cross-Frame Box-Assisted Contrastive Learning
638,Quantitative and Qualitative Comparison
639,Related Works
640,Video and Image Classification Network
641,Training with Coherence Loss
642,Total Training Loss
643,Comparison with Video Models
644,Configuration of Text-Image Encoder and Decoder
645,Text-Guided Cross Position Attention Module
646,Segmentation Performance
647,Application: Deep-Learning Based Disease Diagnosis
648,MIL Method
649,MIL Features
650,Fréchet Domain Distance
651,Domain Shift Quantification
652,Preliminary on Mask Transformer
653,Pixel-Lesion-Patient Network (PLAN)
654,Comparison with Radiologists.
655,Background and Related Work
656,Masked Siamese Networks
657,Private Datasets
658,PET-CT Merging Encoder
659,PT-MLN Diverging Decoder
660,Multi-task Learning
661,Radiomics Enhancement
662,Dataset and Preprocessing
663,Weakly Supervised Learning in Histopathology
664,Survival Analysis and GNNs in Histopathology
665,Self-supervised Encoder
666,Local Graph Neural Network
667,Super-Nodes Extractor
668,Fine-Coarse Distillation
669,Nucleus Image Re-Coloring
670,Distribution-Aware Instance Normalization
671,Experimental Results and Analyses
672,Region-of-Interest Selection and Image Registration
673,Concordance Study
674,Use Cases
675,IHC CD3/CD8 Scoring Using mIF Style Transfer
676,(b) Style Transfer:
677,Virtual Translation of Cheap mIHC to Expensive mIF Stains
678,Virtual Cellular Phenotyping on Standard Hematoxylin Images
679,Conclusions and Future Work
680,Data use Declaration and Acknowledgment:
681,One-Shot Channel Number Search
682,SC-Net as a Balanced Supernet
683,Balanced Evolutionary Search with SC-Net
684,"Acc(W, d, D"
685,Performance Evaluation
686,Conclusion and Future Work
687,Compliance with Ethical Standards
688,Backbone Network
689,Instance-Level Supervision
690,Bag-Level Supervision
691,Experiment Settings
692,Model Interpretation
693,MIL Problem Formulation
694,Multi-scale Prototypical Transformer (MSPT)
695,Prototypical Transformer (PT).
696,Experiment Setup and Evaluation Metrics
697,Comparisons Experiment
698,Temporal-Based Lesions Area Recognition (TLAR)
699,Temporal Projection Attention (TPA). Given a feature
700,Microvessel Infiltration Awareness (MIA)
701,Sigmoid Alpha Function (SAF).
702,Candidate Nucleus Generation
703,Data Purification and SSimNet Learning
704,Datasets and Settings
705,Previous Related Work and Novel Contributions
706,Notation
707,Node Linking and Computation of Graph-Interplay Features
708,Comparative Approaches
709,TIL density (DenTIL):
710,"GG: A Delaunay triangulation, a Voronoi diagram, and a Minimum Spanning"
711,CCG:
712,GNN:
713,Experiment 1: Immunotherapy Response Prediction in Lung Cancer
714,Concluding Remarks
715,Data Processing
716,Stain Normalization
717,Conditional Denoising Diffusion Probabilistic Model
718,Conditioning on Semantic Mask
719,Classifier-Free Guidance
720,Ablation over Guidance Scale (s)
721,Quantitative Analysis
722,Qualitative Analysis
723,Conclusion and Future Works
724,Diffusion Model
725,Structure Encoder
726,Noise Predictor
727,Algorithm 1:
728,Problem Formulation and Data Preparation
729,Masked WSI Representation Autoencoder
730,Position-Aware Cross-Attention
731,(III).
732,Kernel Reorientation
733,end end end
734,Effectiveness of the WSI Representation Learning
735,Comparison with SOTA Methods
736,Two-Stage Pipeline with Attention Guided Selection.
737,Contrastive Pre-training of Encoder.
738,Sample Numbers and Inference Time.
739,Image Encoder
740,Image Decoder
741,Mask Branch
742,Data and Evaluation Metrics:
743,Results on the GlaS Challenge Dataset:
744,Results on the CRAG Dataset:
745,The Supervised PatchNCE (SP) Loss
746,The Adaptive Supervised PatchNCE (ASP) Loss
747,Graph Construction
748,Hierarchical Graph Neural Network
749,Hierarchical Interaction ViT
750,Patch-Level Block.
751,Slide-Level Prediction
752,.90 ± 0.60 97.90 ± 1.40 Fig
753,Mapping Correction Decomposition
754,Minimizing Invariant Risk Across Multi-distributions
755,Rescaling Class-Aware Gaussian Mixture
756,Overall Learning Framework for Imbalanced and Noisy Data
757,MPBD-LSTM.
758,Data Augmentation and Selection
759,Experiment Setup
760,Embedding Extraction Scheme
761,Tile-Level Embeddings
762,Cell-Level Embeddings
763,Combined Embeddings
764,WSI Classification Tasks
765,Model Classification Performance
766,Model Explainability
767,Cellular Explainability Method. The cellular average embedding is
768,Detection Task for Pre-training
769,Transformer with Skip Self-Attention (SSA)
770,Aggregated Classification for WSI
771,Architecture of the Generator
772,Discriminator and Adversarial Training
773,Dataset and Experimental Setup
774,Evaluation of Image Synthesis Quality
775,Evaluation of Augmentation Effectiveness
776,Method Dice IoU
777,MMP-MAE
778,"i=λ2N,j=(1-λ2)N i=1"
779,Downstream Tasks
780,Method Comparison
781,Multi-attention Tri-Branch Network (MTNet)
782,Cross Decoder Knowledge Distillation (CDKD)
783,Average Prediction-Based Uncertainty Minimization
784,Patch Correction Network(PCN)
785,Classification Ranking Loss
786,ROI-Correlation Consistency (RCC) Learning
787,Optimization
788,Evaluation of Cervical Abnormal Cell Detection
789,Datasets. Evaluations of StainDiff are conducted on two datasets. (1)
790,Implementations.
791,Reverse Process and Cycle-Consistency Constraint.
792,Inter-MixUp and Intra-MixUp
793,Experimental Setting
794,Source Graph Construction
795,Calculating TILs-Tumor Interaction via Graph Attention Networks(GATs).
796,Prognosis Prediction by the Cox Proportional Hazard Model.
797,Implementation Details and Evaluation Metrics
798,Result and Discussion
799,Group Multi-head Self Attention
800,Patch Aggregator with Efficient Attention Operation
801,Gene-Induced Multimodal Fusion
802,Comparison Between GiMP and Other Methods
803,Deep Manifold Embedding Learning
804,MIL Classification
805,Implementation Detail
806,Stroma Tissue Segmentation
807,Stroma Classification with Spatial Patch Graphs
808,Neighbor Consistency Regularization for Noisy Labels
809,Adversarial Multi-modal Learning
810,Model Training and Evaluation
811,Hierarchical Graph Convolutional Network
812,Transformer-Based Prediction Head
813,Loss Function and Training Strategy.
814,Comparative Results
815,Interpretability of the Proposed Framework
816,Basic Real-Time Detector
817,Negative Temporal Context Aggregation
818,UltraDet for Real-Time Lesion Detection
819,Dateset
820,Main Results
821,Iterative Coupling of Embedder and Bag Classifier in ICMIL
822,Instance Aggregation Method in ICMIL
823,Label Propagation from Bag Classifier to Embedder
824,Ours
825,Where to Adjust
826,What to Adjust
827,How to Adjust
828,MSKUS
829,Stability Under Different Gaze Maps via t-Test.
830,Triple-Branch Multi-Dilated Network (TDNet)
831,Pixel-Wise and Class-Wise Consistency
832,Multi-view Projection-Based Class-Similarity Consistency (MPCC).
833,Overall Loss Function
834,Organ
835,Ablation Experiment
836,Gaze Supervision
837,Class Activation Map.
838,Interactive Information
839,Normalizing Flows
840,Image Quality
841,Nodule Detection
842,Encoder Group
843,Gaussian-Probabilistic Modeling Group
844,Ensemble Binary Decoders Group
845,Datasets Settings
846,Loss Setting
847,Comparative Analysis
848,Running in the Real World
849,Asymmetric Transformer-Based Classification Module
850,Disentangling via Self-adversarial Learning
851,Asymmetric Synthesis for Supervised Reconstruction
852,Comparison of Performance in Different Tasks:
853,Step1: Training Base Network
854,Step2: Training Protuberance Detection Network
855,Step3: End-to-End Training with Fusion Network
856,Datasets and Preprocessing
857,Training Details and Evaluation Metrics
858,Performance on CECT Images
859,Performance on NCCT Images
860,Landmark-Based Correspondences
861,Texture-Based Refinement
862,Iterative Skin Lesion Correspondence Localization Framework
863,Correspondence Localization Error and Success Rate
864,Usage of Texture on 3D Surface
865,Conclusions and Limitations
866,Mathematical Model of the Anatomy-Informed Deformation
867,Prostate MRI Data
868,Training Protocol
869,Data Curation
870,Intra-operative:
871,Graph Transformer Network:
872,Evidential Graph Transformer:
873,Network/Graph Ablation:
874,Ex-vivo Evaluation:
875,Intra-operative Deployment:
876,Feature Fusion of Locally Computed Radiomic Features with Low-Level DNN Features for Improved Local Context
877,Encouraging Complementary Deep and Radiomic Features Through Feature De-Correlation
878,Overall Framework
879,Comparison with State-of-the-Art Methodologies
880,Type
881,9 ± 0.6 86.3 ± 0.6 74.7 ± 1.5 76.9 ± 1.0
882,Patient Collection and Pre-processing
883,ADC =ln (S
884,Visualization
885,Data Description
886,VCE-MRI Synthesis Network
887,Clinical Evaluations
888,Image
889,Hausdorff Distance (HD).
890,Image Quality of VCE-MRI
891,Primary GTV delineation
892,WED Latent Space Training
893,Depth Encoder Training
894,Real-Time WED Refinement
895,Patient Preparation
896,Water Equivalent Diameter
897,Method (lateral)
898,OCT Image Datasets
899,Self-supervised Feature Space Using Contrastive Learning
900,Extracting Sub-trajectories via Partitioning
901,Sub-trajectory Distance Functions and Clustering
902,Qualitative and Quantitative Evaluation of Clusters
903,Hierarchical Multi-task Multi-instance Learning
904,"Co-occurrence Probability-Based, Label-Correlation Graph"
905,2) LC loss:
906,Dynamical Confidence Constraint
907,Results of Ablation Experiments
908,Summary
909,Tumor Volume Variation
910,Cancer Cell Proliferation
911,Reliance of GTV on Esophageal Anatomy
912,Domain Gap Between the First and Second Course
913,Evaluations of Second-Course GTV Segmentation Performance
914,Instance-Specific Attribute Weighting
915,Channel-Wise Conditional Prompt
916,Textual Knowledge-Guided Contrastive Learning
917,Experimental Results and Analysis
918,2.1 Overview Problem Formulation. In
919,Acknowledgements. This work was supported in part by
920,Domain-Specific Prompt Learning with Vision Transformer
921,Cross-Domain Knowledge Learning
922,Mitigating the Co-artifacts Issue
923,Transformer-Based Multi-label Model
924,Soft State Embeddings S.
925,Self-feedback Strategy
926,Comparison and Ablation Experiments
927,Performance of Different Inference Modes
928,Analysis of Noise Resistance
929,Baseline Framework
930,Unconditional Nuclei Structure Synthesis
931,Conditional Histopathology Image Synthesis
932,Effectiveness of the Proposed Data Augmentation Method
933,Variational Deep Embedding (VaDE)
934,Conditionally Decoded Variational Deep Embedding (CDVaDE)
935,Deep Embedding Clustering (DEC)
936,Related Works in Medical Imaging
937,Colored MNIST
938,Application to a Digital Pathology Dataset
939,Dataset Preparation and Preprocessing
940,Triple Point Pattern (TPP)
941,TPPNet
942,Preparations
943,Impact of Gray Level
944,Acc
945,Impact of Intensity Rescaling Approaches
946,Multi-Channels vs Solo-Channel
947,Comparisons
948,Representing Query with Anchor Circle
949,Circle Cross Attention
950,"MA((x, y), (x ref , y"
951,Circle Regression
952,Circle Instance Segmentation
953,Generalized Circle IoU
954,CC
955,Table 5 .
956,Permutation-equivariant Time Arrow Prediction Head:
957,Time Arrow Prediction Pretraining
958,Motivation:
959,Visual Prompt Tuning
960,Transformer-Based Centroid Detector
961,Grouping Transformer Based Classifier
962,Grouping Prompts Based Tuning
963,Comparison with the State-of-the-Art
964,On the Hausdorff Moment Problem
965,Maximum-Entropy Estimation
966,Dual Energy Minimization Problems
967,Synthetic Data
968,Comparison Methods
969,In Vivo rdMRI
970,Loss Functions and Model Convergence:
971,(c).
972,Discussions and Conclusion
973,Training and Testing Datasets
974,TractCloud Framework
975,Performance on the Labeled Atlas Dataset
976,Performance on the Independently Acquired Testing Datasets
977,Multi-compartment Model
978,Model Simplification via Spherical Mean
979,Estimation of Relaxation and Diffusion Parameters
980,Microstructure Indices
981,Data Acquisition and Processing
982,Ex Vivo Data: Compartment-Specific Parameters
983,In Vivo Data: Compartment-Specific Parameters
984,In Vivo Data: Neurite Morphology
985,Relation Between Relaxation and Diffusivity
986,fODFs
987,Proxy Task
988,ImageNet Pre-training:
989,Prior Self-activation Map
990,Result
991,Materials and Proposed Method
992,Binary Classification for Tract Segmentation
993,Active Learning for Tract Selection
994,Implementation and Evaluation Details
995,Domain-Expert Evaluation:
996,Generalization to Other Architectures
997,Implementation and Training.
998,Augmented Lesion Network Mapping (A-LNM).
999,Comparison Studies
1000,Brain Regions in Relation to GBM Survival
1001,Dataset Description
1002,Vessel Map Extraction
1003,Data Augmentation
1004,Neural Network
1005,Augmented CT
1006,Ablation Study and Additional Results
1007,Comparison with VoxelMorph:
1008,OCE Needle for Deep Tissue Indentation
1009,Indentation Experiments
1010,The Overall Segmentation Framework
1011,Fracture Segmentation Network
1012,Post-processing
1013,Data and Annotation
1014,Data and Landmark Annotation
1015,Contrastive Learning Framework
1016,Landmark Matching with a 2.5D Approach
1017,Landmark Matching with 3D SIFT
1018,Data Preprocessing
1019,Implementation Details and Evaluation
1020,Related Autofocusing Works
1021,Contributions
1022,Optical System
1023,Autofocus Policies
1024,Overview of SCA-Net
1025,Surgical Concept Learning
1026,Mutual-Modality Concept Alignment
1027,Comparison on Neurosurgery Video Captioning
1028,Comparison on EndoVis Image Captioning
1029,Implicit Modeling for Surgical Dissection Decision-Making
1030,Training Implicit Policy as Diffusion Models
1031,Conditional Sampling with Forward-Diffusion Guidance
1032,Experimental Dataset and Evaluation Metrics
1033,Regularized Kelvinlet Functions
1034,Registration Task
1035,Hyperparameters Sensitivity Analysis
1036,Registration Methods Comparison
1037,Limitations and Conclusion
1038,Intraoperative Registration Image Synthesis Pose Regression
1039,Expected Appearances Synthesis
1040,Pose Regression Network
1041,Validation and Evaluation of Texture Invariance.
1042,Deep Learning-Based Dose Prediction
1043,Dose Segmentation Loss (DOSELO)
1044,Data and Model Training
1045,Dose Prediction:
1046,Baselines and Implementation Details:
1047,RM AE
1048,FLIm Hardware and Data Acquisition
1049,Patient Cohort and FLIm Data Labeling
1050,FLIm Preprocessing
1051,Novelty Detection Model
1052,Classifier Training and Evaluation
1053,Classifier Augmented Display
1054,Uncertainty Quantification
1055,Experimental Setup and Implementation
1056,Error Regression Accuracy
1057,Validation of the Uncertainty Evaluation
1058,Robustness of the Proposed Model
1059,Intersection Detection as Segmentation
1060,Intersection Detection as Regression
1061,Video-CTU Registration
1062,Ureteroscopic Image Characteristics
1063,Ureteroscopic Structure Extraction
1064,Virtual CTU Depth Map Generation and Thresholding
1065,Structural Point Similarity and Optimization
1066,Luo et al. Ours
1067,Approaches
1068,Transformer Cascade Encoding
1069,Boundary-Aware Multibranch Fusion Decoding
1070,Hybrid Spatial-Frequency Loss
1071,Multi-modal Variational Auto-Encoders (MVAE).
1072,Hierarchical Latent representation
1073,Variational Posterior's Parametrization for Incomplete Inputs
1074,Optimization Strategy for Image Synthesis
1075,Conclusion and Future Work.
1076,Histology-to-CT Modality Translation
1077,Recursive Cascaded Plane Selection
1078,Deformable 2D-3D Registration
1079,Modality Translation
1080,Registration
1081,Manifold Learning
1082,Reconstruction from Biplanar Projections
1083,"Conclusion, Limitations, and Future Work"
1084,MaskGAN Architecture
1085,CycleGAN Supervision
1086,Mask and Cycle Shape Consistency Supervision
1087,Frequency-Band-Aware Artifact Modeling Network
1088,Self-guided Artifact Refinement Network
1089,Loss Function for FreeSeed
1090,Extending FreeSeed to Dual-Domain Framework
1091,Collaborative Optimization
1092,Network Modules
1093,3D Pseudo Brain MRI.
1094,Fast Reconstruction Images
1095,Motion Correction Framework
1096,Multi-sequence Fusion
1097,Task-Specific Enhanced Map
1098,Dataset and Evaluation Metrics
1099,Interpretability Visualization
1100,Feature Extraction
1101,Ellipse Intersection
1102,Clustering
1103,Search Space Regularization.
1104,Variant I. This variant relies upon direct inversion of the emission equation matrix S -1
1105,Data Collection
1106,Experimental Validation
1107,A Continuous formulation of the FDOT problem
1108,Architecture and Training.
1109,Affine Registration of Brain US-MR
1110,Deformable Registration of Abdominal MR-CT
1111,Deformable Registration of Abdominal US-CT and US-MR
1112,Generative Adversarial Network.
1113,GANs with Local Coherence
1114,Theoretical Background
1115,Noise2Aliasing
1116,Design Choices Based on the Proposition
1117,Parametric Form of Learnable Regularization
1118,Algorithm 1. Learned Descent Algorithm for PET image reconstruction
1119,Learned Descent Algorithm for PET
1120,Dual-Domain Unsupervised Training
1121,Implementation Details and Reference Methods
1122,Experimental Evaluations
1123,Target Function
1124,Datasets and Experiment Setup
1125,Non-iterative Coarse-to-fine Transformer Networks (NICE-Trans)
1126,Joint Affine and Deformable Registration
1127,Unsupervised Learning
1128,Sparse Optical Flow
1129,Gaussian Heatmaps
1130,Evaluation Metrics and Results
1131,Multi-conditioned Latent Diffusion Model
1132,Latent Space Network
1133,Structural Guidance
1134,Auto-Weight Adaptation
1135,Ablation Study and Multi-modal Exploitation Capabilities
1136,Deterministic DDIM Sampling.
1137,InverseSR(LDM):
1138,InverseSR(Decoder):
1139,Implementation:
1140,Dual-Stream Diffusion Model for Structure-Preserving Super-Resolution
1141,Imaging Enhancement Operator for Vascular and Blob Structure
1142,Datasets and Evaluation
1143,Qualitative and Quantitative Results
1144,LightNeuS
1145,Using Illumination Decline as a Depth Cue
1146,Endoscope Photometric Model
