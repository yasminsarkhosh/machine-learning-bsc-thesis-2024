,title,extracted_dataset_sent,
0,Anatomy-Driven Pathology Detection on Chest X-rays,"these region boxes are easier to annotate -the physiological shape of a healthy
subject's thorax can be learned relatively easily by medical students -and
generalize better than those of pathologies, such that huge labeled datasets are
available -we propose anatomy-driven pathology detection (adpd), a pathology
detection approach for chest x-rays, trained with pathology classification
labels together with anatomical region bounding boxes as proxies for
pathologies.",
1,Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET,the dataset is composed of 23 oncological patients with different tumor types.,x
2,Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET,"dpet data was acquired on a biograph vision quadra for 65 min, over 62 frames.",
3,Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET,"the dataset included the label maps of 7 organs (bones, lungs, heart, liver,
kidneys, spleen, aorta) and one image-derived input function a(t) [bq/ml] from
the descending aorta per patient.",x
4,Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET,"further details on the dataset are presented elsewhere the pet frames and the
label map were resampled to an isotropic voxel size of 2.5 mm.",
5,Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET,"then, the dataset was split patient-wise into training, validation, and test
set, with 10, 4, and 9 patients respectively.",x
6,Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET,details on the dataset split are available in the supplementary material (table,
7,AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor,"however, most deep learning approaches for segmentation require fully or
partially labeled training datasets, which can be time-consuming and expensive
to annotate.",
8,AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor,"-we demonstrate the superiority of ame-cam over state-of-the-art cam methods in
extracting segmentation results from classification networks on the 2021 brain
tumor segmentation challenge (brats 2021) we evaluate our method on the brain
tumor segmentation challenge (brats) dataset in this section, we compare the
segmentation performance of the proposed ame-cam with five state-of-the-art
weakly-supervised segmentation methods, namely grad-cam compared to the
unsupervised baseline (ul), c&f is unable to separate the tumor and the
surrounding tissue due to low contrast, resulting in low dice scores in all
experiments.",
9,AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor,"experimental results on the four modalities of the 2021 brats dataset
demonstrate the superiority of our approach compared with other cam-based
weakly-supervised segmentation methods.",x
10,AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor,"specifically, ame-cam achieves the highest dice score for all patients in all
datasets and modalities.",
11,Unsupervised Discovery of 3D Hierarchical Structure with Generative Diffusion Features,"we compare our method with state-of-the-art unsupervised 3d structure discovery
approaches including clustering using 3d feature learning for the synthetic
datasets, we used k = 2 (background and cell) for level 1, k = 4 (background,
cell, vesicle, mitochondria) for level 2, and k = 8 (background, cell, vesicle,
mitochondria, and 4 small protein aggregates) for level 3 predictions.",
12,Unsupervised Discovery of 3D Hierarchical Structure with Generative Diffusion Features,"table for the brain tumor segmentation (brats'19) dataset, we use the whole
tumor (wt) segmentation mask for evaluation, which is detectable based on the
flair images alone.",x
13,Unsupervised Discovery of 3D Hierarchical Structure with Generative Diffusion Features,"the evaluation metric, as in the brats'19 challenge we perform ablation studies
on the brats'19 dataset (table this might be due to the fact that predictive
modeling involves learning from a distribution of images and a model may
therefore extract useful knowledge from a collection of images.",x
14,Unsupervised Discovery of 3D Hierarchical Structure with Generative Diffusion Features,"our method outperforms existing unsupervised segmentation approaches and
discovers meaningful hierarchical concepts on challenging biologically-inspired
synthetic datasets and on the brats brain tumor dataset.",
15,Unsupervised Discovery of 3D Hierarchical Structure with Generative Diffusion Features,"while we tested our approach for unsupervised image segmentation it is
conceivable that it could also be useful in semisupervised settings and that
could be applied to data types other than images.",
16,S 2 ME: Spatial-Spectral Mutual Teaching and Ensemble Learning for Scribble-Supervised Polyp Segmentation,none,
17,Tracking Adaptation to Improve SuperPoint for 3D Reconstruction in Endoscopy,none,
18,Black-box Domain Adaptative Cell Segmentation via Multi-source Distillation,"dataset and setting: we collect four pathology image datasets to validate our
proposed approach.",x
19,Black-box Domain Adaptative Cell Segmentation via Multi-source Distillation,"firstly, we acquire 50 images from a cohort of patients with triple negative
breast cancer (tnbc), which is released by naylor et al experimental results: to
validate our method, we compare it with the following approaches: (1)
cellsegssda in addition, the experimental results also show that simply
combining multiple source data into a traditional single source will result in
performance degradation in some cases, which also proves the importance of
studying multi-source domain adaptation methods.",x
20,Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning,"in recent years, deep learning (dl) methods have demonstrated remarkable
performance in detecting and localizing tumors on ultrasound images domain
adaptation (da) has been extensively studied to alleviate the aforementioned
limitations, the goal of which is to reduce the domain gap caused by the
diversity of datasets from different domains to alleviate the problem of
pseudo-label-based uda, in this work, we propose an advanced uda framework based
on self-supervised da with a test-time finetuning network.",
21,Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning,"• our framework is effective at preserving privacy, since it carries out da
using only pre-trained network parameters, without transferring any patient
data.",
22,Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning,"• we applied our framework to the task of segmenting breast cancer from
ultrasound imaging data, demonstrating its superior performance over competing
uda methods.",
23,Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning,"due to the low resolution of ultrasound images, manual segmentation of breast
cancer is challenging even for expert clinicians, resulting in a sparse number
of labeled data.",
24,Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning,"additionally, our framework is well-suited to a scenario in which access to
source domain data is limited, due to data privacy protocols.",
25,PET-Diffusion: Unsupervised PET Enhancement Based on the Latent Diffusion Model,"the keys of our upete include 1) compressing the 3d pet images into a lower
dimensional space for reducing the computational cost of diffusion model, 2)
adopting the poisson noise, which is the dominant noise in pet imaging our work
had three main features/contributions: i) proposing a clinicallyapplicable
unsupervised pet enhancement framework, ii) designing three targeted strategies
for improving the diffusion model, including pet image compression, poisson
diffusion, and ct-guided cross-attention, and iii) achieving better performance
than state-of-the-art methods on the collected pet datasets.",
26,Cross-Adversarial Local Distribution Regularization for Semi-supervised Medical Image Segmentation,"therefore, there is a growing interest in developing semi-supervised learning
that leverages both labeled and unlabeled data to improve the performance of
image segmentation models existing semi-supervised segmentation methods exploit
smoothness assumption, e.g., the data samples that are closer to each other are
more likely to to have the same label.",
27,Cross-Adversarial Local Distribution Regularization for Semi-supervised Medical Image Segmentation,"we have seen such perturbations being be added to natural input images at
data-level in this paper, we propose a novel cross-adversarial local
distribution regularization for semi-supervised medical image segmentation for
smoothness assumption enhancement",
28,Infusing Physically Inspired Known Operators in Deep Models of Ultrasound Elastography,"we use publicly available data collected from a breast phantom (model 059, cirs:
tissue simulation & phantom technology, norfolk, va) using an alpinion e-cube
r12 research us machine (bothell, wa, usa).",x
29,Infusing Physically Inspired Known Operators in Deep Models of Ultrasound Elastography,"this data is available online at http://code.sonography.ai in in vivo data was
collected at johns hopkins hospital from patients with liver cancer during
open-surgical rf thermal ablation by a research antares siemens system using a
vf 10-5 linear array with the sampling frequency of 40 mhz and the center
frequency of 6.67 mhz.",x
30,Infusing Physically Inspired Known Operators in Deep Models of Ultrasound Elastography,we selected 600 rf frame pairs of this dataset for the training of the networks.,
31,SLPD: Slide-Level Prototypical Distillation for WSIs,none,
32,PROnet: Point Refinement Using Shape-Guided Offset Map for Nuclei Instance Segmentation,"(4) ablation and evaluation studies on two public datasets demonstrate our
model's ability to outperform state-of-the-art techniques not only with ideal
labels but also with shifted labels.",
33,TPRO: Text-Prompting-Based Weakly Supervised Histopathology Tissue Segmentation,none,
34,MetaLR: Meta-tuning of Learning Rates for Transfer Learning in Medical Imaging,"transfer learning has become a standard practice in medical image analysis as
collecting and annotating data in clinical scenarios can be costly.",
35,MetaLR: Meta-tuning of Learning Rates for Transfer Learning in Medical Imaging,"the pre-trained parameters endow better generalization to dnns than the models
trained from scratch diversity between domains and tasks and privacy concerns
related to pre-training data.",
36,MetaLR: Meta-tuning of Learning Rates for Transfer Learning in Medical Imaging,"2) we enhance metalr with a proportional hyper-lr and a validation scheme using
batched training data to improve the algorithm's stability and efficacy.",
37,DAS-MIL: Distilling Across Scales for MIL Classification of Histological WSIs,"( it is available on the gdc data transfer portal and comprises two subsets of
cancer: lung adenocarcinoma (luad) and lung squamous cell carcinoma (lusc),
counting 541 and 513 wsis, respectively.",
38,vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images,"medical image segmentation often relies on supervised model training secondly,
the resulting models may not generalize well to unseen data domains.",
39,vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images,"ssl pre-trains a model backbone to extract informative representations from
unlabeled data.",
40,vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images,"pre-training the backbone in a self-supervised manner enables scaling to larger
datasets across multiple data and task domains.",
41,vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images,"in medical imaging, this is particularly useful given the growing number of
available datasets.",
42,vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images,"second, we employ vox2vec to pre-train a fpn architecture on a diverse
collection of six unannotated datasets, totaling over 6,500 ct images of the
thorax and abdomen.",x
43,vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images,"finally, we compare the pretrained model with the baselines on 22 segmentation
tasks on seven ct datasets in three setups: linear probing, non-linear probing,
and fine-tuning.",
44,vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images,"the mean value and standard deviation of dice score across 5 folds on the btcv
dataset for all models in all evaluation setups are presented in table
nevertheless, vox2vec-fpn significantly outperforms other models in linear and
non-linear regimes.",
45,vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images,"we reproduce the key results on msd challenge ct datasets, which contain tumor
and organ segmentation tasks.",x
46,vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images,"by pre-training a fpn backbone to extract informative representations from
unlabeled data, our method scales to large datasets across multiple task
domains.",
47,vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images,"we plan to investigate further how the performance of vox2vec scales with the
increasing size of the pre-training dataset and the pre-trained architecture
size.",
48,vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images,"another interesting research direction is exploring the effectiveness of vox2vec
with regard to domain adaptation to address the challenges of domain shift
between different medical imaging datasets obtained from different sources.",
49,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,we evaluate our proposed method on two multi-domain datasets: 1).,
50,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,the infant brain mri dataset for cross-age segmentation; 2).,x
51,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,the brats2018 dataset for cross-grade tumor segmentation.,x
52,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"our proposed method was evaluated using two medical image segmentation da
datasets.",
53,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"the first dataset, i.e., cross-age infant segmentation the first dataset is for
infant brain segmentation (white matter, gray matter and cerebrospinal fluid).",
54,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"to build the cross-age dataset, we take advantage 10 brain mris of 6-month-old
from iseg2019 the 2nd dataset is for brain tumor segmentation (enhancing tumor,
peritumoral edema and necrotic and non-enhancing tumor core), which has 285 mri
samples (210 hgg and 75 lgg).",x
55,Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"we also visualize the segmentation results on a typical test sample of the
infant brain dataset in fig.",
56,Gall Bladder Cancer Detection from US Images with only Image Level Labels,"gallbladder cancer detection in ultrasound images: we use the public gbc us
dataset note that, we use only the image labels for training.",x
57,Gall Bladder Cancer Detection from US Images with only Image Level Labels,"polyp detection in colonoscopy images: we use the publicly available kvasir-seg
since the patient information is not available with the data, we use random
stratified splitting for 5-fold cross-validation.",x
58,Structured State Space Models for Multiple Instance Learning in Digital Pathology,"extensive experiments on three publicly available datasets show the potential of
such models for the processing of gigapixel-sized images, under both weakly and
multi-task schemes.",
59,Structured State Space Models for Multiple Instance Learning in Digital Pathology,"camelyon16 tcga-luad is a tcga lung adenocarcinoma dataset that contains 541
wsis along with genetic information about each patient.",x
60,Structured State Space Models for Multiple Instance Learning in Digital Pathology,"we obtained genetic information for this cohort using xena browser tcga-rcc is a
tcga dataset for three kidney cancer subtypes (denoted kich, kirc, and kirp).",x
61,Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision,"this information can be leveraged to assess treatment response, e.g., by
analyzing the evolution of size and morphology for a given tumor in practice,
the development of automatic and reliable lesion tracking solutions is hindered
by the complexity of the data (over different modalities), the absence of large,
annotated datasets, and the difficulties associated with lesion identification
(i.e., varying sizes, poses, shapes, and sparsely distributed locations).",
62,Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision,"furthermore, a significant focus and contribution of our research is the
experimental study at a very large scale: we (1) train a pixel-wise
self-supervised system using a very large and diverse dataset of 52,487 ct
volumes and (2) evaluate on two publicly available datasets.",x
63,Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision,"notably, one of the datasets, nlst, presents challenging cases with 68% of
lesions being very small (i.e., radius < 5 mm).",
64,Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision,"the method is generic, it does not require expert annotations or longitudinal
data for training and can generalize to different types of
tumors/organs/modalities.",
65,Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision,"through large-scale experiments and validation on two longitudinal datasets, we
highlight the superiority of the proposed method in comparison to
state-of-theart.",
66,Geometry-Invariant Abnormality Detection,"most recent approaches have focused on improvements in performance rather than
flexibility, thus limiting approaches to specific input types -little research
has been carried out to generate models unhindered by variations in data
geometries.",
67,Geometry-Invariant Abnormality Detection,"often, research assumes certain similarities in data acquisition parameters,
from image dimensions to voxel dimensions and fields-of-view (fov).",
68,Geometry-Invariant Abnormality Detection,"these restrictions are then carried forward during inference unsupervised
methods have become an increasingly prominent field for automatic anomaly
detection by eliminating the necessity of acquiring accurately labelled data
even though these methods are state-of-the-art, they have stringent data
requirements, such as having a consistent geometry of the input data, e.g., in a
whole-body imaging scenario, it is not possible to crop a region of interest and
feed it to the algorithm, as this cropped region will be wrongly detected as an
anomaly.",
69,Geometry-Invariant Abnormality Detection,"through adapting the vq-vae transformer approach in the proposed model was
trained on the data described in sect.",
70,Geometry-Invariant Abnormality Detection,"generally, the variation scanners and acquisition protocols can cause failures
in models trained on data from single sources.",
71,Geometry-Invariant Abnormality Detection,"not only does the proposed model showcase strong and statistically-significant
performance improvements on varying image resolutions and fov, but also on
whole-body data.",
72,Geometry-Invariant Abnormality Detection,"through this, we demonstrate that one can improve the adaptability and
flexibility to varying data geometries while also improving performance.",
73,Geometry-Invariant Abnormality Detection,"such flexibility also increases the pool of potential training data, as they
dont require the same fov.",
74,Interpretable Medical Image Classification Using Prototype Learning and Privileged Information,data.,
75,Interpretable Medical Image Classification Using Prototype Learning and Privileged Information,"the proposed approach is evaluated using the publicly available lidc-idri
dataset consisting of 1018 clinical thoracic ct scans from patients with
non-small cell lung cancer (nsclc) experiment designs.",x
76,ArSDM: Colonoscopy Images Synthesis with Adaptive Refinement Semantic Diffusion Models,none,
77,Synthetic Augmentation with Large-Scale Unconditional Pre-training,datasets.,
78,Synthetic Augmentation with Large-Scale Unconditional Pre-training,"we employ three public datasets of histopathology images during the large-scale
pre-training procedure.",x
79,Synthetic Augmentation with Large-Scale Unconditional Pre-training,"the first one is the h&e breast cancer dataset to replicate a scenario where
only a small annotated dataset is available for training, we have opted to
utilize a subset of 5,000 (5%) samples for finetuning.",x
80,Synthetic Augmentation with Large-Scale Unconditional Pre-training,"it is worth noting that the labels for these samples have been kept, which
allows the fine-tuning process to be guided by labeled data, leading to better
predictions on the specific task or domain being trained.",
81,Synthetic Augmentation with Large-Scale Unconditional Pre-training,"by ensuring that the fine-tuning process is representative of the entire dataset
through even sampling from each tissue type, we can eliminate bias towards any
particular tissue type.",x
82,Synthetic Augmentation with Large-Scale Unconditional Pre-training,"the related data use declaration and acknowledgment can be found in our
supplementary materials.",x
83,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation,"a must-have ingredient for training a deep neural network (dnn) is a large
number of labelled data that is not always available in real-world applications.",
84,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation,"this challenge of data annotation becomes even worse for medical image
segmentation tasks that require pixel-level annotation by experts.",
85,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation,data augmentation (da) is a recognized approach to tackle this challenge.,
86,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation,"common da strategies create new samples by using predefined transformations such
as rotation, translation, and colour jitter to existing data, where the
performance gains heavily relies on the choice of augmentation operations and
parameters to mitigate this reliance, recent efforts have focused on learning
optimal augmentation operations for a given task and dataset however, to date,
all existing approaches to learning deformable registrationbased da assume a
perfect alignment of image pairs to learn the transformations.",
87,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation,"this allows us to add shape diversity to the objects of interest in an image
regardless of their positions or sizes, eventually facilitating transferring the
learned variations across datasets.",
88,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation,"we demonstrated the effectiveness of the presented object-centric diffeomorphic
augmentation in kidney tumour segmentation, including using shape variations of
kidney tumours learned from the same dataset (kits we focus on da for tumour
segmentation because tumours can occur at different locations of an organ with
substantially different orientations and sizes.",
89,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation,"inspired from where the integration can be done via a specialized solver
generative modeling: the data generation process can be described as: where z is
the latent variable assumed to follow an isotropic gaussian prior, p φ (θ|z) is
modeled by a neural network parameterized by φ, and p(x tgt |θ, x src ) follows
the deformable transformation as described in equation ( we define variational
approximations of the posterior density as q ψ (z|x src , x tgt ), modeled by a
convolutional neural network that expects two inputs x src and x tgt .",
90,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation,"figure data: we then used g(z) to generate deformation-based augmentations to
increase the size and diversity of training samples for kidney tumour
segmentation on kits.",
91,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation,"to assess the effect of augmentations on different sizes of labelled data, we
considered training using 25%, 50%, 75%, and 100% of the kits training set.",
92,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation,"we considered two da scenarios: augment with transformations learned from kits
(within-data augmentation) versus from lits (cross-data augmentation).",
93,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation,"as demonstrated by the experimental results, this allows us to not only
introduce new variations to unfixed objects like tumours in an image but also
transfer the knowledge of shape variations across datasets.",
94,Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation,"in the long term, it would be interesting to explore ways to transfer knowledge
about more general forms of variations across datasets.",
95,Centroid-Aware Feature Recalibration for Cancer Grading in Pathology Images,"cafe module adjusts the input embedding vectors with respect to the class
centroids (i.e., training data distribution).",
96,Centroid-Aware Feature Recalibration for Cancer Grading in Pathology Images,"assuming that the classes are well separated in the feature space, the centroid
embedding vectors can serve as reference points to represent the data
distribution of the training data.",
97,Centroid-Aware Feature Recalibration for Cancer Grading in Pathology Images,"during inference, we fix the centroid embedding vectors so that the recalibrated
embedding vectors do not vary much compared to the input embedding vectors even
though the data distribution substantially changes, leading to improved
stability and robustness of the feature representation.",
98,Centroid-Aware Feature Recalibration for Cancer Grading in Pathology Images,"the experimental results demonstrate that cafenet achieves the state-of-the-art
cancer grading performance in colorectal cancer grading datasets.",
99,Centroid-Aware Feature Recalibration for Cancer Grading in Pathology Images,"two publicly available colorectal cancer datasets we conducted a series of
comparative experiments to evaluate the effectiveness of cafenet for cancer
grading, in comparison to several existing methods: 1) three dcnnbased models:
resnet we evaluated the performance of colorectal cancer grading by the proposed
cafenet and other competing models using five evaluation metrics, including
accuracy (acc), precision, recall, f1-score (f1), and quadratic weighted kappa
(κ w ).",x
100,Centroid-Aware Feature Recalibration for Cancer Grading in Pathology Images,"in the experiments on colorectal cancer datasets against several competing
models, the proposed network demonstrated that it has a better learning
capability as well as a generalizability in classifying pathology images into
different cancer grades.",
101,Centroid-Aware Feature Recalibration for Cancer Grading in Pathology Images,"however, the experiments were only conducted on two public colorectal cancer
datasets from a single institute.",x
102,Explaining Massive-Training Artificial Neural Networks in Medical Image Analysis Task Through Visualizing Functions Within the Models,"our xai technique was applied to explain the mtann model's decision in a liver
tumor segmentation task in addition, since most liver tumors' shape is
ellipsoidal, the liver tumors can also be enhanced by the hessian-based method
and utilized in the model to improve the performance seven cases and 24 cases in
the dynamic contrast-enhanced ct scans dataset were used for training and
testing, respectively.",x
103,TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"while most multi-phase liver lesion classification studies use datasets with no
more than three phases (without dl phase for its difficulty of collection) or no
more than six lesion classes, we validate the whole framework on an in-house
dataset with four phases of abdominal ct and seven classes of liver lesions.",
104,TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"considering the disproportion of axial lesion slice number and the relatively
small scale of the dataset, we adopt a 2-d network in classification part
instead of 3-d in pre-processing part and achieve a 90.9% accuracy.",
105,Adaptive Region Selection for Active Learning in Whole Slide Image Semantic Segmentation,"we test our method using a breast cancer metastases segmentation task on the
public camelyon16 dataset and demonstrate that determining the selected regions
individually provides greater flexibility and efficiency than selecting regions
with a uniform predefined shape and size, given the variability in histological
tissue structures.",x
106,Adaptive Region Selection for Active Learning in Whole Slide Image Semantic Segmentation,"to validate our segmentation framework, we first train on the fully-annotated
data (average performance of five repetitions reported).",
107,Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation,"in this work, we focus on the explainability of the classification of brain
tumours using probe-based confocal laser endomicroscopy (pcle) data.",
108,Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation,"performance evaluation on pcle data shows that our improved explainability
method outperforms the sota.",
109,Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation,dataset.,
110,Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation,"the developed explainability framework has been validated on an in vivo and ex
vivo pcle dataset of meningioma, glioblastoma and metastases of an invasive
ductal carcinoma (idc).",
111,Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation,"our dataset includes 38 meningioma videos, 24 glioblastoma and 6 idc.",x
112,Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation,the data has been curated to remove noisy images and similar frames.,
113,Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation,"this resulted in a training dataset of 2500 frames per class (7500 frames in
total) and a testing dataset of the same size.",x
114,Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation,"the dataset is split into a training and testing subset, with the division done
on the patient level.",x
115,Continual Learning for Abdominal Multi-organ and Tumor Segmentation,"in contrast, deep learning models suffer from catastrophic forgetting the
medical domain faces a similar problem: the ability to dynamically extend a
model to new classes is critical for multiple organ and tumor segmentation,
wherein the key obstacle lies in mitigating 'forgetting.' a typical strategy
involves retaining some previous data.",
116,Continual Learning for Abdominal Multi-organ and Tumor Segmentation,"q1: can we relieve the forgetting problem without needing previous data and
annotations?",
117,Continual Learning for Abdominal Multi-organ and Tumor Segmentation,"first, inspired by knowledge distillation methods in continual learning we focus
on organ/tumor segmentation because it is one of the most critical tasks in
medical imaging segment liver tumors in the lits dataset.",
118,Continual Learning for Abdominal Multi-organ and Tumor Segmentation,"on the private dataset, the learning trajectory is to first segment 13 organs,
followed by continual segmentation of three gastrointestinal tracts and four
cardiovascular system structures.",
119,Continual Learning for Abdominal Multi-organ and Tumor Segmentation,"numerical results on an in-house dataset and two public datasets demonstrate
that the proposed method outperforms the continual learning baseline methods in
the challenging multiple organ and tumor segmentation tasks.",
120,Efficient Subclass Segmentation in Medical Images,"this segmentation result is supervised by the superposition of the pseudo label
map z pse and subclass labels z, with weighting factor α: the intuition behind
this framework is to simultaneously leverage the information from both unlabeled
and labeled data by incorporating a more robust supervision from
transform-invariant pseudo labels.",
121,Towards AI-Driven Radiology Education: A Self-supervised Segmentation-Based Framework for High-Precision Medical Image Editing,"however, designing educational materials solely based on real-world data poses
several challenges.",
122,Towards AI-Driven Radiology Education: A Self-supervised Segmentation-Based Framework for High-Precision Medical Image Editing,"future challenges include improving scalability with fewer manual operations,
validating segmentation maps from a more objective perspective, and comparing
our proposed algorithm with existing methods, such as those based on superpixels
data use declaration and acknowledgment: the pelvic mri and chest ct datasets
were collected from the national cancer center hospital.",
123,Towards AI-Driven Radiology Education: A Self-supervised Segmentation-Based Framework for High-Precision Medical Image Editing,"the study, data use, and data protection procedures were approved by the ethics
committee of the national cancer center, tokyo, japan (protocol number
2016-496).",
124,Medical Image Computing and Computer Assisted Intervention – MICCAI 2023,"however, we observe that typiclust (shown as orange) achieves comparable or
superior performance compared to random selection across all tasks in our
benchmark, whereas other approaches can significantly under-perform on certain
tasks, especially challenging ones like the liver dataset.",
125,Medical Image Computing and Computer Assisted Intervention – MICCAI 2023,"multi-modal learning has become a popular research area in computer vision and
medical image analysis, with modalities spanning across various media types,
including texts, audio, images, videos and multiple sensor data.",
126,Medical Image Computing and Computer Assisted Intervention – MICCAI 2023,"the experiments are conducted on the brain tumour segmentation benchmark
brats2018 let us represent the n -modality data with m l = {x ∈ x denotes the l
th data sample and the superscript (i) indexes the modality.",
127,Medical Image Computing and Computer Assisted Intervention – MICCAI 2023,"multi-modal segmentation is composed not only of multiple modalities, but also
of multiple tasks, such as the three types of tumours in brats2018 dataset that
represent the three tasks.",
128,FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation,training data.,
129,FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation,"the real-world dataset used in experiments is provided by the fets challenge
organizer, which is the training set of the whole dataset about brain tumor
segmentation.",
130,FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation,"in order to evaluate the performance of fedgrav, we partition the dataset
composed of 341 data samples experiment results on the cifar-10.",
131,FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation,we first validate the proposed method on the cifar-10 dataset.,
132,FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation,table experiment results on miccai fets2021 training dataset.,
133,FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation,"in order to verify the robustness of our method and its performance in
real-world data, we conduct the experiment on the miccai fets2021 training
dataset.",
134,FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation,"we evaluated our method on cifar-10 and real-world miccai federated tumor
segmentation challenge (fets) datasets, and the superior results demonstrated
the effectiveness and robustness of our fedgrav.",
135,Faithful Synthesis of Low-Dose Contrast-Enhanced Brain MRI Scans Using Noise-Preserving Conditional GANs,"complementary to the development of higher relaxivity contrast agents in recent
years, generative models have been used to overcome data scarcity in the
computer vision and medical imaging community.",
136,Faithful Synthesis of Low-Dose Contrast-Enhanced Brain MRI Scans Using Noise-Preserving Conditional GANs,"in particular, for image-to-image translation tasks, these conditional gans have
been successfully applied using paired with this in mind, the contributions of
this work are as follows: -synthesis of gbca behavior at various doses using
conditional gans, -loss enabling interpolation of dose levels present in
training data, -noise-preserving content loss function to generate realistic
synthetic images.",
137,A Spatial-Temporal Deformable Attention Based Framework for Breast Lesion Detection in Videos,"we conduct extensive experiments on a public breast lesion ultrasound video
dataset, named bluvd-186",
138,DeDA: Deep Directed Accumulator,none,
139,OpenAL: An Efficient Deep Active Learning Framework for Open-Set Pathology Image Classification,"deep learning techniques have achieved unprecedented success in the field of
medical image classification, but this is largely due to large amount of
annotated data active learning (al) is an effective approach to address this
issue from a data selection perspective, which selects the most informative
samples from an unlabeled sample pool for experts to label and improves the
performance of the trained model with reduced labeling cost recently, ning et
al.",
140,OpenAL: An Efficient Deep Active Learning Framework for Open-Set Pathology Image Classification,"we conducted two experiments with different matching ratios (ratio of the number
of target class samples to the total number of samples) on a public 9-class
colorectal cancer pathology image dataset.",
141,OpenAL: An Efficient Deep Active Learning Framework for Open-Set Pathology Image Classification,"to validate the effectiveness of openal, we conducted two experiments with
different matching ratios (the ratio of the number of samples in the target
class to the total number of samples) on a 9-class public colorectal cancer
pathology image classification dataset (nct-crc-he-100k) metrics.",
142,SFusion: Self-attention Based N-to-One Multimodal Fusion Block,"as a data-dependent fusion strategy, sfusion can automatically learn the latent
correlations between different modalities and builds a shared feature
representation.",
143,SFusion: Self-attention Based N-to-One Multimodal Fusion Block,"the entire fusion process is based on available data without simulating missing
modalities.",
144,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"long-tailed problem is usually caused by differences in incidence rate and
difficulties in data collection.",
145,ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"some diseases are common while others are rare, making it difficult to collect
balanced data to tackle the challenge of learning unbiased classifiers with
imbalanced data, many previous works focus on three main ideas, including
re-sampling data recently, contrastive learning (cl) methods pose great
potential for representation learning when trained on imbalanced data to address
the above issues, we propose a class-enhancement contrastive learning (ecl)
method for skin lesion classification, differences between scl and ecl are
illustrated in fig.",
146,SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation,datasets and pre-trained model.,
147,SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation,"we conducted experiments on automating liver tumor segmentation in
contrast-enhanced ct scans, a crucial task in liver cancer diagnosis and
surgical planning collecting large-scale data from our hospital and training a
new model will be expensive.",
148,SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation,"we collected a dataset from our in-house hospital comprising 941 ct scans with
eight categories: hepatocellular carcinoma, cholangioma, metastasis,
hepatoblastoma, hemangioma, focal nodular hyperplasia, cyst, and others.",
149,SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation,"we utilized a pre-trained model for liver segmentation using supervised learning
on two public datasets metrics.",
150,UniSeg: A Prompt-Driven Universal Segmentation Model as Well as A Strong Representation Learner,"thanks to both designs, our uniseg achieves superior performance on 11 upstream
datasets and two downstream datasets, setting a new record.",
151,UniSeg: A Prompt-Driven Universal Segmentation Model as Well as A Strong Representation Learner,"in our future work, we plan to design a universal model that can effectively
process multiple dimensional data.",
152,Cross-Modulated Few-Shot Image Generation for Colorectal Tissue Classification,"however, shortage of pathologists worldwide along with the complexity of
histopathological data make this task time consuming and challenging.",
153,Cross-Modulated Few-Shot Image Generation for Colorectal Tissue Classification,"the corresponding dataset we conduct experiments on human colorectal cancer
dataset",
154,Structure-Preserving Instance Segmentation via Skeleton-Aware Distance Transform,dataset and evaluation metric.,
155,Structure-Preserving Instance Segmentation via Skeleton-Aware Distance Transform,we use the gland segmentation challenge dataset,
156,DAST: Differentiable Architecture Search with Transformer for 3D Medical Image Segmentation,"to verify the effectiveness and generalization of our searched architectures
from dast, we validate the searched architecture (from pancreas data set) on
this challenging task.",
157,Pre-trained Diffusion Models for Plug-and-Play Medical Image Enhancement,"however, acquiring such paired data is challenging in real clinical scenarios.",
158,Pre-trained Diffusion Models for Plug-and-Play Medical Image Enhancement,"although it is possible to simulate low-quality images from high-quality images,
the models derived from such data may have limited generalization ability when
applied to real data recently, pre-trained diffusion models in this paper, we
aim at addressing the limitations of existing image enhancement methods and the
scarcity of pre-trained diffusion models for medical images.",
159,Evidence Reconciled Neural Network for Out-of-Distribution Detection in Medical Images,"detecting out-of-distribution (ood) samples is crucial in real-world
applications of machine learning, especially in medical imaging analysis where
misdiagnosis can pose significant risks deep learning-based ood detection
methods with uncertainty estimation, such as evidential deep learning (edl) to
address this limitation, we propose an evidence reconciled neural network
(ernn), which aims to reliably detect those samples that are similar to the
training data but still with different distributions (near ood), while maintain
accuracy for in-distribution (id) classification.",
160,Evidence Reconciled Neural Network for Out-of-Distribution Detection in Medical Images,"extensive experiments on both isic2019 dataset and in-house pancreas tumor
dataset demonstrate that the proposed ernn significantly improves the
reliability and accuracy of ood detection for clinical applications.",
161,Evidence Reconciled Neural Network for Out-of-Distribution Detection in Medical Images,"in this section, we conduct a detailed ablation study to clearly demonstrate the
effectiveness of our major technical components, which consist of evaluation of
evidential head, evaluation of the proposed evidence reconcile block on both
isic 2019 dataset and our in-house pancreas tumor dataset.",
162,Scale-Aware Test-Time Click Adaptation for Pulmonary Nodule and Mass Segmentation,none,
163,WeakPolyp: You only Look Bounding Box for Polyp Segmentation,none,
164,Shifting More Attention to Breast Lesion Segmentation in Ultrasound Videos,none,
165,FocalUNETR: A Focal Transformer for Boundary-Aware Prostate Segmentation Using CT Images,none,
166,Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,"for instance, structures such as the left ventricle and the myocardium wall in
the ultrasound datasets have large components of their contour oriented along
the vertical direction which allows the univariate and bivariate models to
perform as well, if not better, than the asymmetric model.",
167,Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,"the contrast between the left ventricle and myocardium in the images of the
private cardiac us dataset is small, which explains why the simpler univariate
and bivariate models perform well.",
168,Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,"this is why on very noisy and poorly contrasted data, the univariate or the
bivariate model might be preferable to using the asymmetric model.",
169,Anatomical-Aware Point-Voxel Network for Couinaud Segmentation in Liver CT,extensive experiments on two publicly available datasets named 3dircadb,
170,HENet: Hierarchical Enhancement Network for Pulmonary Vessel Segmentation in Non-contrast CT Images,none,
171,Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels,none,
172,Anti-adversarial Consistency Regularization for Data Augmentation: Applications to Robust Medical Image Segmentation,"we present a novel data augmentation method for semantic segmentation using a
flexible anti-adversarial consistency regularization.",
173,Anti-adversarial Consistency Regularization for Data Augmentation: Applications to Robust Medical Image Segmentation,"extensive experiments with various backbones and datasets confirm the
effectiveness of our method.",
174,Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk,none,
175,Learning Reliability of Multi-modality Medical Images for Tumor Segmentation via Evidence-Identified Denoising Diffusion Probabilistic Models,none,
176,Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network,none,
177,SimPLe: Similarity-Aware Propagation Learning for Weakly-Supervised Breast Cancer Segmentation in DCE-MRI,dataset.,
178,SimPLe: Similarity-Aware Propagation Learning for Weakly-Supervised Breast Cancer Segmentation in DCE-MRI,"we evaluated our method on an in-house breast dce-mri dataset collected from the
cancer center of sun yat-sen university.",
179,Conditional Diffusion Models for Weakly Supervised Medical Image Segmentation,"for both datasets, we repeat the evaluation protocols for four times and report
the average metrics and their standard deviation on test set.",
180,Conditional Diffusion Models for Weakly Supervised Medical Image Segmentation,"we benchmark our methods against previous wsss works on two datasets in table
from the results, we can make several key observations.",
181,Conditional Diffusion Models for Weakly Supervised Medical Image Segmentation,"firstly, our proposed method, even without classifier guidance, outperform all
other wsss methods including the classifier guided diffusion model cg-diff on
both datasets for all three metrics.",
182,Conditional Diffusion Models for Weakly Supervised Medical Image Segmentation,"secondly, all wsss methods have performance drop on kidney dataset compared with
brats dataset.",
183,Conditional Diffusion Models for Weakly Supervised Medical Image Segmentation,"this demonstrates that the kidney segmentation task is a more challenging task
for wsss than brain tumor task, which may be caused by the small training size
and diverse appearance across slices in the chaos dataset.",
184,Conditional Diffusion Models for Weakly Supervised Medical Image Segmentation,"the default setting is cg-cdm on brats dataset with q = 400, r = 10, τ = 0.95,
and s = 10.",
185,DBTrans: A Dual-Branch Vision Transformer for Multi-Modal Brain Tumor Segmentation,"however, the data in each slice is related to three views, discarding any of
them may lead to the loss of local information, which may cause the degradation
of performance the contributions of our proposed method can be described as
follows: 1) based on transformer, we construct dual-branch encoder and decoder
layers that assemble two attention mechanisms, being able to model close-window
and distant-window dependencies without any extra computational cost.",
186,DBTrans: A Dual-Branch Vision Transformer for Multi-Modal Brain Tumor Segmentation,"3) for the multi-modal data adopt in the task of samm-bts, we improve the
channel attention mechanism in se-net by applying se-weights to features from
both branches in the encoder and decoder layers.",
187,DBTrans: A Dual-Branch Vision Transformer for Multi-Modal Brain Tumor Segmentation,datasets.,
188,M-GenSeg: Domain Adaptation for Target Modality Tumor Segmentation with Annotation-Efficient Supervision,none,
189,Edge-Aware Multi-task Network for Integrating Quantification Segmentation and Uncertainty Prediction of Liver Tumor on Multi-modality Non-contrast MRI,none,
190,RCS-YOLO: A Fast and High-Accuracy Object Detector for Brain Tumor Detection,"however, the increasingly complex network architecture in cnn-based models, such
as resnet repvgg to evaluate the proposed rcs-yolo model, we used the brain
tumor detection 2020 dataset (br35h) to highlight the accuracy and rapidity of
the proposed model for the detection of brain tumor medical image data set,
table it can be seen that rcs-yolo with the advantages of incorporating the
rcs-osa module performs well.",
191,RCS-YOLO: A Fast and High-Accuracy Object Detector for Brain Tumor Detection,"evaluation of the brain mri dataset shows superior performance for brain tumor
detection in terms of both speed and precision, as compared to yolov6, yolov7,
and yolov8 models.",
192,Category-Level Regularized Unlabeled-to-Labeled Learning for Semi-supervised Prostate Segmentation with Multi-site Unlabeled Data,"recently, deep learningbased approaches have greatly improved the accuracy and
efficiency of automatic prostate mri segmentation regarding quantity , the
abundance of unlabeled data serves as a way to regularize the model and
alleviate overfitting to the limited labeled data.",
193,A Sheaf Theoretic Perspective for Robust Prostate Segmentation,"deep learning models are susceptible to textural shifts and artefacts which is
often seen in mri due to variations in the complex acquisition protocols across
multiple sites the most common approach to tackle domain shifts is with data
augmentation the contributions of this paper are summarized as follows: 1.",
194,MedNeXt: Transformer-Driven Scaling of ConvNets for Medical Image Segmentation,"transformers the convnext architecture marries the scalability and long-range
spatial representation learning capabilities of vision in this work, we maximize
the potential of a convnext design while uniquely addressing challenges of
limited datasets in medical image segmentation.",
195,Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,"this is primarily due to their ability to learn informative hierarchical
features directly from data.",
196,Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,"in the proposed kspc-net, a cnn is employed to learn directly from the data to
produce the pixel-wise bandwidth feature map and initial segmentation map, which
are used to define the tuning parameters in the kspc module.",
197,Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,"more specifically, we use the classic unet the dataset is from the hecktor
challenge in miccai 2021 (head and neck tumor segmentation challenge).",
198,Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,"the hecktor training dataset consists of 224 patients diagnosed with
oropharyngeal cancer in this paper, we present a novel network, kspc-net, for
the segmentation in 2d pet images, which integrates kspc into the unet
architecture in an end-toend differential manner.",
199,Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,"promising performance was achieved by our proposed kspc-net compared to the
state-of-the-art approaches on the miccai 2021 challenge dataset (hecktor).",
200,A2FSeg: Adaptive Multi-modal Fusion Network for Medical Image Segmentation,"-we conduct experiments on the brats 2020 dataset and achieve the sota
segmentation performance, having a mean dice core of 89.79% for the whole tumor,
82.72% for the tumor core, and 66.71% for the enhancing tumor.",
201,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"notably, tumor types have been found to be strongly correlated with the
prognosis of diffuse glioma our method is evaluated using pre-operative
multimodal mr brain images of 1726 diffuse glioma patients collected from
cooperation hospitals and a public dataset brats2019 diffuse glioma can be
classified into three histological types: the oligodendroglioma, the
astrocytoma, and the glioblastoma the tumor subtyping network is trained
independently before being integrated into the backbone.",
202,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"to solve the inherent issue of imbalanced tumor type in the training data
collected in clinic, a novel ordinal manifold mixup based feature augmentation
is applied in the training of the tumor subtyping network.",
203,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"it is worth noting that the ground truth of tumor types, which is determined
after craniotomy, is available in the training data, while for the testing data,
tumor types are not required, because tumor-type-related features can be learned
from the pre-operative multimodal mr brain images.",
204,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"in the in-house dataset, the proportions of the three tumor types are 20.9%
(oligodendroglioma), 28.7% (astrocytoma), and 50.4% (glioblastoma), which is
consistent with the statistical report in in the original manifold mixup where y
k i and y k j stand for the labels of the k-th tumor type of the i-th and j-th
patients, respectively, and λ ∈ [0, 1] is a weighting factor.",
205,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"in our experiment, both in-house and public datasets are used to evaluate our
method.",
206,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"specifically, the in-house dataset collected in cooperation hospitals contains
pre-operative multimodal mr images, including t1, t1 contrast enhanced (t1c),
t2, and flair, of 1726 patients (age 49.7 ± 13.1) with confirmed diffuse glioma
types.",
207,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"besides the inhouse dataset, a public dataset brats2019, including pre-operative
multimodal mr images of 210 non-censored patients (age 61.4 ± 12.2), is adopted
as the external independent testing dataset.",
208,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"all images of the in-house and brats2019 datasets go through the same
pre-processing stage, including image normalization and affine transformation to
mni152 besides our method, four state-of-the-art methods, including random
forest based method (rf) where d = {x 1 , ..., x n } is the dataset containing
all patients, t i and t j are ground truth of survival times of the i-th and
j-th patients, r i and r j are the days predicted by rf, mcsp, and pgsp or risks
predicted by the deep cox proportional hazard models (i.e., deepconvsurv and our
method), 1 x<y = 1 if x < y, else 0, and δ i = 0 or 1 when the i-th patient is
censored or non-censored.",
209,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"as rf, mcsp, and pgsp cannot use the censored data in the in-house dataset, 80%
of the non-censored data (594 patients) are randomly selected as the training
data, and the rest 20% non-censored data (149 patients) are for testing.",
210,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"so besides the 80% non-censored patients, all censored data (983 patients) are
also included in the training data.",
211,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"for the in-house dataset, the resulting c-indices are 0.744 (baseline-1) and
0.735 (baseline-2).",
212,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"for the external independent testing dataset brats2019, the resulting c-indices
are 0.738 (baseline-1) and 0.714 (baseline-2), and our method still has more
than 6% improvement comparing with baseline-2.",
213,Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"both in-house and public datasets containing 1936 patients were used in the
experiment.",
214,Medical Boundary Diffusion Model for Skin Lesion Segmentation,none,
215,H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation,"with the emergence of multimodal datasets (e.g., brats in addition to the
progress on the fusion of multimodal features, improving the model
representation ability is also an effective way to boost segmentation
performance.",
216,H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation,"extensive experimental results on two publicly available datasets demonstrate
the effectiveness of our proposed method.",
217,TransNuSeg: A Lightweight Multi-task Transformer for Nuclei Segmentation,none,
218,QCResUNet: Joint Subject-Level and Voxel-Level Prediction of Segmentation Quality,none,
219,EGE-UNet: An Efficient Group Enhanced UNet for Skin Lesion Segmentation,none,
220,Diffusion Kinetic Model for Breast Cancer Segmentation in Incomplete DCE-MRI,"we verify the effectiveness of our proposed diffusion kinetic model (dkm) on
dce-mri-based breast cancer segmentation using breast-mri-nact-pilot dataset •
we propose a diffusion kinetic model that implicitly exploits hemodynamic priors
in dce-mri and effectively generates high-quality segmentation maps only
requiring pre-contrast images.",
221,Diffusion Kinetic Model for Breast Cancer Segmentation in Incomplete DCE-MRI,"in particular, the diffusion loss for the reverse diffusion process can be
formulated as follows: where θ represents the denoising model that employs an
u-net structure, x 0 and x k are the pre-contrast and post-contrast images,
respectively, is gaussian distribution data ∼ n (0, i), and t is a timestep.",
222,Diffusion Kinetic Model for Breast Cancer Segmentation in Incomplete DCE-MRI,"dataset: to demonstrate the effectiveness of our proposed dkm, we evaluate our
method on 4d dce-mri breast cancer segmentation using the breast-mri-nact-pilot
dataset we propose a diffusion kinetic model by exploiting hemodynamic priors in
dce-mri to effectively generate high-quality segmentation results only requiring
precontrast images.",
223,Morphology-Inspired Unsupervised Gland Segmentation via Selective Semantic Grouping,none,
224,EoFormer: Edge-Oriented Transformer for Brain Tumor Segmentation,none,
225,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"first, there lacks of a well-segmented dataset with manual labels on lyme
disease.",
226,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"on one hand, some datasets-such as ham10000 second, the segmentation of lyme
lesion is itself challenging due to the nature of em pattern.",
227,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"furthermore, clinical data collected for training is usually imbalanced in some
properties, e.g., more samples with light skins compared with dark skins.",
228,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"therefore, existing skin disease segmentation in this paper, we present the
first lyme disease dataset that contains labeled segmentation and skin tones.",
229,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"our lyme disease dataset contains two parts: (i) a classification dataset,
composed of more than 3,000 diseased skin images that are either obtained from
public resources or clinicians with patient-informed consent, and (ii) a
segmentation dataset containing 185 samples that are manually annotated for
three regions-i.e., background, skin (light vs.",
230,EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"our dataset with manual labels is available at this url secondly, we design a
simple yet novel data preprocessing and alternation method, called edgemixup, to
improve lyme disease segmentation and diagnosis fairness on samples with
different skin-tones.",
231,Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"we adopted the training dataset of hecktor 2022 (refer to
https://hecktor.grand-cha llenge.org/), including 488 h&n cancer patients
acquired from seven medical centers we resampled pet-ct images into isotropic
voxels where 1 voxel corresponds to 1 mm 3 .",
232,Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"extensive experiments have shown that the proposed framework and blocks enable
our xsurv to outperform state-of-the-art survival prediction methods on the
well-benchmarked hecktor 2022 dataset.",
233,Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"we adopted the training dataset of hecktor 2022 (refer to
https://hecktor.grand-cha llenge.org/), including 488 h&n cancer patients
acquired from seven medical centers we resampled pet-ct images into isotropic
voxels where 1 voxel corresponds to 1 mm 3 .",
234,Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"extensive experiments have shown that the proposed framework and blocks enable
our xsurv to outperform state-of-the-art survival prediction methods on the
well-benchmarked hecktor 2022 dataset.",
235,ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"therefore, the contributions of this work can be summarized as: 1) a novel
graph-based model for predicting survival that extracts both local and global
properties by identifying morphological super-nodes; 2) introducing a
fine-coarse feature distillation module with 3 various strategies to aggregate
interactions at different scales; 3) outperforming sota approaches in both risk
prediction and patient stratification scenarios on two datasets; 4) publishing
two large and rare prostate cancer datasets containing more than 220 graphs for
active surveillance and 240 graphs for brachytherapy cases.",
236,ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"the code and graph embeddings are publicly available at
https://github.com/pazadimo/all-in 2 related works we utilize two prostate
cancer (pca) datasets to evaluate the performance of our proposed model.",
237,ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"radical therapy is considered overtreatment in these patients, so they are
instead monitored with regular serum prostate-specific antigen (psa)
measurements, physical examinations, sequential biopsies, and magnetic resonance
imaging the second dataset (pca-bt) includes 105 pca patients with low to high
risk disease who went through brachytherapy.",
238,ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"therefore, the contributions of this work can be summarized as: 1) a novel
graph-based model for predicting survival that extracts both local and global
properties by identifying morphological super-nodes; 2) introducing a
fine-coarse feature distillation module with 3 various strategies to aggregate
interactions at different scales; 3) outperforming sota approaches in both risk
prediction and patient stratification scenarios on two datasets; 4) publishing
two large and rare prostate cancer datasets containing more than 220 graphs for
active surveillance and 240 graphs for brachytherapy cases.",
239,ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"the code and graph embeddings are publicly available at
https://github.com/pazadimo/all-in 2 related works we utilize two prostate
cancer (pca) datasets to evaluate the performance of our proposed model.",
240,ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"radical therapy is considered overtreatment in these patients, so they are
instead monitored with regular serum prostate-specific antigen (psa)
measurements, physical examinations, sequential biopsies, and magnetic resonance
imaging the second dataset (pca-bt) includes 105 pca patients with low to high
risk disease who went through brachytherapy.",
241,An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"however, this results in high interobserver variability among pathologists,
primarily due to the large (> 50%) disagreement among pathologists for immune
cell phenotyping in this paper, we introduce a new dataset that can be readily
used out-ofthe-box with any artificial intelligence (ai)/deep learning
algorithms for spatial characterization of tumor immune microenvironment and
several other use cases.",
242,An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"to date, only two denovo stained datasets have been released publicly: bci h&e
and singleplex ihc her2 dataset the complete staining protocols for this dataset
are given in the accompanying supplementary material.",
243,An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"we have released the first ai-ready restained and co-registered mif and mihc
dataset for head-and-neck squamous cell carcinoma patients.",
244,An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"this dataset can be used for virtual phenotyping given standard clinical
hematoxylin images, virtual clinical ihc dab generation with ground truth
segmentations (to train highquality segmentation models across multiple cancer
types) created from cleaner mif images, as well as for generating standardized
clean mif images from neighboring h&e and ihc sections for registration and 3d
reconstruction of tissue specimens.",
245,An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"in the future, we will release similar datasets for additional cancer types as
well as release for this dataset corresponding whole-cell segmentations via
impartial https://github.com/nadeemlab/impartial.",
246,An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"it is also supported in part by the moffitt's total cancer care initiative,
collaborative data services, biostatistics and bioinformatics, and tissue core
facilities at the h.",
247,An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"however, this results in high interobserver variability among pathologists,
primarily due to the large (> 50%) disagreement among pathologists for immune
cell phenotyping in this paper, we introduce a new dataset that can be readily
used out-ofthe-box with any artificial intelligence (ai)/deep learning
algorithms for spatial characterization of tumor immune microenvironment and
several other use cases.",
248,An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"to date, only two denovo stained datasets have been released publicly: bci h&e
and singleplex ihc her2 dataset the complete staining protocols for this dataset
are given in the accompanying supplementary material.",
249,An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"we have released the first ai-ready restained and co-registered mif and mihc
dataset for head-and-neck squamous cell carcinoma patients.",
250,An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"this dataset can be used for virtual phenotyping given standard clinical
hematoxylin images, virtual clinical ihc dab generation with ground truth
segmentations (to train highquality segmentation models across multiple cancer
types) created from cleaner mif images, as well as for generating standardized
clean mif images from neighboring h&e and ihc sections for registration and 3d
reconstruction of tissue specimens.",
251,An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"in the future, we will release similar datasets for additional cancer types as
well as release for this dataset corresponding whole-cell segmentations via
impartial https://github.com/nadeemlab/impartial.",
252,An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"it is also supported in part by the moffitt's total cancer care initiative,
collaborative data services, biostatistics and bioinformatics, and tissue core
facilities at the h.",
253,Detection of Basal Cell Carcinoma in Whole Slide Images,"figure we validated our algorithm using the curated skin cancer dataset and
sc-net as a supernet, testing both heavy and light models.",
254,Detection of Basal Cell Carcinoma in Whole Slide Images,"to ensure a fair comparison on our dataset, we selected several papers in the
field of pathological image analysis, such as evaluation metrics.",
255,Detection of Basal Cell Carcinoma in Whole Slide Images,"with scnet and evolutionary search, we obtained optimal architectures, achieving
96.2% top-1 and 96.5% accuracy on a skin cancer dataset, improvements of 4.8%
and 4.7% over baselines.",
256,Detection of Basal Cell Carcinoma in Whole Slide Images,"future work will apply our approach to larger datasets for wider-scale
validation.",
257,Detection of Basal Cell Carcinoma in Whole Slide Images,"figure we validated our algorithm using the curated skin cancer dataset and
sc-net as a supernet, testing both heavy and light models.",
258,Detection of Basal Cell Carcinoma in Whole Slide Images,"to ensure a fair comparison on our dataset, we selected several papers in the
field of pathological image analysis, such as evaluation metrics.",
259,Detection of Basal Cell Carcinoma in Whole Slide Images,"with scnet and evolutionary search, we obtained optimal architectures, achieving
96.2% top-1 and 96.5% accuracy on a skin cancer dataset, improvements of 4.8%
and 4.7% over baselines.",
260,Detection of Basal Cell Carcinoma in Whole Slide Images,"future work will apply our approach to larger datasets for wider-scale
validation.",
261,IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis,we evaluate our model with three datasets.,
262,IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis,"(1) luad-gm dataset: the objective is to predict the epidermal growth factor
receptor (egfr) gene mutations in patients with lung adenocarcinoma (luad) using
723 whole slide image (wsi) slices, where 47% of cases have egfr mutations.",
263,IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis,"(2) tcga-nsclc and tcga-rcc datasets: cancer type classification is performed
using the cancer genome atlas (tcga) dataset.",
264,IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis,"the tcga-nsclc dataset comprised two subtypes, lung squamous cell carcinoma
(lusc) and lung adenocarcinoma (luad), while the tcga-rcc dataset included three
subtypes: renal chromophobe cell carcinoma (kich), renal clear cell carcinoma
(kirc), and renal papillary cell carcinoma (kirp).",
265,IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis,we evaluate our model with three datasets.,
266,IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis,"(1) luad-gm dataset: the objective is to predict the epidermal growth factor
receptor (egfr) gene mutations in patients with lung adenocarcinoma (luad) using
723 whole slide image (wsi) slices, where 47% of cases have egfr mutations.",
267,IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis,"(2) tcga-nsclc and tcga-rcc datasets: cancer type classification is performed
using the cancer genome atlas (tcga) dataset.",
268,IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis,"the tcga-nsclc dataset comprised two subtypes, lung squamous cell carcinoma
(lusc) and lung adenocarcinoma (luad), while the tcga-rcc dataset included three
subtypes: renal chromophobe cell carcinoma (kich), renal clear cell carcinoma
(kirc), and renal papillary cell carcinoma (kirp).",
269,Multi-scale Prototypical Transformer for Whole Slide Image Classification,none,
270,Thyroid Nodule Diagnosis in Dynamic Contrast-Enhanced Ultrasound via Microvessel Infiltration Awareness,none,
271,Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,none,
272,NASDM: Nuclei-Aware Semantic Histopathology Image Generation Using Diffusion Models,none,
273,DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"overall, the contributions of this paper can be concluded as follows: dataset
and evaluations.",
274,DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"we measure the performance of our model on an in-house rectum cancer dataset
which contains 130 patients who underwent volumetric modulated arc therapy
(vmat) treatment at west china hospital.",
275,DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"extensive experiments on an in-house dataset with 130 rectum cancer patients
demonstrate the superiority of our method.",
276,DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"overall, the contributions of this paper can be concluded as follows: dataset
and evaluations.",
277,DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"we measure the performance of our model on an in-house rectum cancer dataset
which contains 130 patients who underwent volumetric modulated arc therapy
(vmat) treatment at west china hospital.",
278,DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"extensive experiments on an in-house dataset with 130 rectum cancer patients
demonstrate the superiority of our method.",
279,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning,"the proposed approach was evaluated on a public tcga-lung dataset and an
in-house endometrial dataset and compared with 6 state-of-the-art methods.",
280,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning,tcga-lung dataset is collected from the cancer genome atlas (tcga) data portal.,
281,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning,"the dataset includes a total of 3,064 wsis, which consist of three categories,
namely tumor-free (normal), lung adenocarcinoma (luad), and lung squamous cancer
(lusc), endometrial dataset includes 3,654 wsis of endometrial pathology, which
includes 8 categories, namely well/moderately/low-differentiated endometrioid
adenocarcinoma, squamous differentiation carcinoma, plasmacytoid carcinoma,
clear cell carcinoma, mixed-cell adenocarcinoma, and benign tumor.",
282,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning,"each dataset was randomly divided into training, validation and test sets
according to 6:1:3 while keeping each category of data proportionally.",
283,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning,we conducted wsi multi-type classification experiments on the two datasets.,
284,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning,"the proposed approach was evaluated on a public tcga-lung dataset and an
in-house endometrial dataset and compared with 6 state-of-the-art methods.",
285,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning,tcga-lung dataset is collected from the cancer genome atlas (tcga) data portal.,
286,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning,"the dataset includes a total of 3,064 wsis, which consist of three categories,
namely tumor-free (normal), lung adenocarcinoma (luad), and lung squamous cancer
(lusc), endometrial dataset includes 3,654 wsis of endometrial pathology, which
includes 8 categories, namely well/moderately/low-differentiated endometrioid
adenocarcinoma, squamous differentiation carcinoma, plasmacytoid carcinoma,
clear cell carcinoma, mixed-cell adenocarcinoma, and benign tumor.",
287,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning,"each dataset was randomly divided into training, validation and test sets
according to 6:1:3 while keeping each category of data proportionally.",
288,Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning,we conducted wsi multi-type classification experiments on the two datasets.,
289,Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,"first, they are not able to get rid of their reliance on detection models, which
means they have a high need for expensive detection data labeling to train the
detection model.",
290,Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,"cervical cancer cell detection datasets involve labeling individual and small
bounding boxes in a large number of cells.",
291,Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,dataset and experimental setup.,
292,Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,"first, we label a dataset with cell-level bounding boxes to train a detection
model.",
293,Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,the detection dataset has 3761 images and 7623 cell-level annotations.,
294,Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,"first, they are not able to get rid of their reliance on detection models, which
means they have a high need for expensive detection data labeling to train the
detection model.",
295,Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,"cervical cancer cell detection datasets involve labeling individual and small
bounding boxes in a large number of cells.",
296,Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,dataset and experimental setup.,
297,Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,"first, we label a dataset with cell-level bounding boxes to train a detection
model.",
298,Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,the detection dataset has 3761 images and 7623 cell-level annotations.,
299,Instance-Aware Diffusion Model for Gland Segmentation in Colon Histology Images,"our proposed method was trained and tested on the 2015 mic-cai gland
segmentation (glas) challenge dataset colorectal cancer is a prevalent form of
cancer characterized by colorectal adenocarcinoma, which develops in the colon
or rectum's inner lining and exhibits glandular structures recently, diffusion
model in this paper, we propose a new method for gland instance segmentation
based on the diffusion model.",
300,Instance-Aware Diffusion Model for Gland Segmentation in Colon Histology Images,"our proposed method was trained and tested on the 2015 mic-cai gland
segmentation (glas) challenge dataset",
301,Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs,"our formulation of this loss was inspired by the recent research findings that
contrastive loss benefits model robustness under label noise lastly, to support
further research in virtual ihc-restaining, we present the multi-ihc stain
translation (mist) as a new public dataset.",
302,Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs,"the mist dataset contains 4k+ training and 1k testing aligned h&e-ihc patches
for each of the following ihc stains that are critical for breast cancer
diagnostics: her2, ki67, er (estrogen receptor) and pr (progesterone receptor).",
303,Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs,datasets.,
304,Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs,"the following datasets are used in our experiments: the breast cancer
immunohistochemical (bci) challenge dataset implementation details.",
305,Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs,"our formulation of this loss was inspired by the recent research findings that
contrastive loss benefits model robustness under label noise lastly, to support
further research in virtual ihc-restaining, we present the multi-ihc stain
translation (mist) as a new public dataset.",
306,Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs,"the mist dataset contains 4k+ training and 1k testing aligned h&e-ihc patches
for each of the following ihc stains that are critical for breast cancer
diagnostics: her2, ki67, er (estrogen receptor) and pr (progesterone receptor).",
307,Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs,datasets.,
308,Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs,"the following datasets are used in our experiments: the breast cancer
immunohistochemical (bci) challenge dataset implementation details.",
309,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis,"the extensive experiments with promising results on two public wsi datasets from
tcga projects, i.e., kidney carcinoma (kica) and esophageal carcinoma (esca),
validate the effectiveness and efficiency of our framework on both tumor
subtyping and staging tasks.",
310,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis,datasets and evaluation metrics.,
311,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis,"we assess the efficacy of the proposed higt framework by testing it on two
publicly available datasets (kica and esca) from the cancer genome atlas (tcga)
repository.",
312,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis,the datasets are described below in more detail: -kica dataset.,
313,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis,"the kica dataset consists of 371 cases of kidney carcinoma, of which 279 are
classified as early-stage and 92 as late-stage.",
314,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis,-esca dataset.,
315,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis,"the esca dataset comprises 161 cases of esophageal carcinoma, with 96 cases
classified as early-stage and 65 as late-stage.",
316,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis,"the extensive experiments with promising results on two public wsi datasets from
tcga projects, i.e., kidney carcinoma (kica) and esophageal carcinoma (esca),
validate the effectiveness and efficiency of our framework on both tumor
subtyping and staging tasks.",
317,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis,datasets and evaluation metrics.,
318,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis,"we assess the efficacy of the proposed higt framework by testing it on two
publicly available datasets (kica and esca) from the cancer genome atlas (tcga)
repository.",
319,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis,the datasets are described below in more detail: -kica dataset.,
320,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis,"the kica dataset consists of 371 cases of kidney carcinoma, of which 279 are
classified as early-stage and 92 as late-stage.",
321,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis,-esca dataset.,
322,HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis,"the esca dataset comprises 161 cases of esophageal carcinoma, with 96 cases
classified as early-stage and 65 as late-stage.",
323,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"colorectal cancer is the third most common malignant tumor, and nearly half of
all patients with colorectal cancer develop liver metastasis during the course
of the disease extensive existing works have demonstrated the power of deep
learning on various spatial-temporal data, and can potentially be applied
towards the problem of crlm.",
324,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"for example, originally designed for natural data, several mainstream models
such as e3d-lstm however, all these methods have only demonstrated their
effectiveness towards 3d/4d data (i.e., time-series 2d/3d images), and it is not
clear how to best extend them to work with the 5d cect data.",
325,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,part of the reason is due to the lack of public availability of such data.,
326,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"when extending these models towards 5d cect data, some decisions need to be
made, for example: 1) what is the most effective way to incorporate the phase
information?",
327,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"e3d-lstm in this paper, we investigate how state-of-art deep learning models can
be applied to the crlm prediction task using our 5d cect dataset.",
328,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"we evaluate the effectiveness of bi-directional lstm and explore the possible
method of incorporating different phases in the cect dataset.",
329,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"specifically, we show that the best prediction accuracy can be achieved by
enhancing e3d-lstm our dataset follows specific inclusion criteria: -no tumor
appears on the ct scans.",
330,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"-we already determined whether or not the patients had liver metastases within 2
years after the surgery, and manually labeled the dataset based on this.",
331,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,our retrospective dataset includes two cohorts from two hospitals.,
332,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"additional statistics on our dataset are presented in table colorectal cancer is
the third most common malignant tumor, and nearly half of all patients with
colorectal cancer develop liver metastasis during the course of the disease
extensive existing works have demonstrated the power of deep learning on various
spatial-temporal data, and can potentially be applied towards the problem of
crlm.",
333,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"for example, originally designed for natural data, several mainstream models
such as e3d-lstm however, all these methods have only demonstrated their
effectiveness towards 3d/4d data (i.e., time-series 2d/3d images), and it is not
clear how to best extend them to work with the 5d cect data.",
334,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,part of the reason is due to the lack of public availability of such data.,
335,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"when extending these models towards 5d cect data, some decisions need to be
made, for example: 1) what is the most effective way to incorporate the phase
information?",
336,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"e3d-lstm in this paper, we investigate how state-of-art deep learning models can
be applied to the crlm prediction task using our 5d cect dataset.",
337,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"we evaluate the effectiveness of bi-directional lstm and explore the possible
method of incorporating different phases in the cect dataset.",
338,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"specifically, we show that the best prediction accuracy can be achieved by
enhancing e3d-lstm our dataset follows specific inclusion criteria: -no tumor
appears on the ct scans.",
339,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"-we already determined whether or not the patients had liver metastases within 2
years after the surgery, and manually labeled the dataset based on this.",
340,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,our retrospective dataset includes two cohorts from two hospitals.,
341,MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,additional statistics on our dataset are presented in table,
342,Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology,"for breast cancer metastasis detection in lymph node tissue, we used wsis of
h&estained healthy lymph node tissue and lymph node tissue with breast cancer
metastases from the publicly available camelyon16 challenge data set for cell of
origin (coo) prediction of activated b-cell like (abc) or germinal center b-cell
like (gcb) tumors in diffuse large b-cell lymphoma (dlbcl), we used data from
the phase 3 goya (nct01287741) and phase 2 cavalli (nct02055820) clinical
trials, hereafter referred to as ct1 and ct2, respectively.",
343,Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology,"ct1 was used for training and testing the classifier and ct2 was used only as an
independent holdout data set.",
344,Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology,"for these data sets we used artifact-free tiles from regions annotated by expert
pathologists to contain tumor tissue.",
345,Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology,"examples of our cellular explainability method applied to weakly supervised
tumor detection on wsis from the camelyon16 data set using a-mil are shown in
fig.",
346,Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology,"for breast cancer metastasis detection in lymph node tissue, we used wsis of
h&estained healthy lymph node tissue and lymph node tissue with breast cancer
metastases from the publicly available camelyon16 challenge data set for cell of
origin (coo) prediction of activated b-cell like (abc) or germinal center b-cell
like (gcb) tumors in diffuse large b-cell lymphoma (dlbcl), we used data from
the phase 3 goya (nct01287741) and phase 2 cavalli (nct02055820) clinical
trials, hereafter referred to as ct1 and ct2, respectively.",
347,Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology,"ct1 was used for training and testing the classifier and ct2 was used only as an
independent holdout data set.",
348,Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology,"for these data sets we used artifact-free tiles from regions annotated by expert
pathologists to contain tumor tissue.",
349,Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology,"examples of our cellular explainability method applied to weakly supervised
tumor detection on wsis from the camelyon16 data set using a-mil are shown in
fig.",
350,Progressive Attention Guidance for Whole Slide Vulvovaginal Candidiasis Screening,none,
351,CellGAN: Conditional Cervical Cell Synthesis for Augmenting Cytopathological Image Classification,"as the wsi data per sample has a huge size, the idea of identifying abnormal
cells in a hierarchical manner has been proposed and investigated by several
studies using deep learning to alleviate the shortage of sufficient data to
supervise classification, one may adopt traditional data augmentation
techniques, which yet may bring little improvement due to scarcely expanded data
diversity aiming at augmenting the performance of cervical abnormality
screening, we develop a novel conditional generative adversarial network in this
paper, namely cellgan, to synthesize cytopathological images for various cell
types.",
352,CellGAN: Conditional Cervical Cell Synthesis for Augmenting Cytopathological Image Classification,"as the wsi data per sample has a huge size, the idea of identifying abnormal
cells in a hierarchical manner has been proposed and investigated by several
studies using deep learning to alleviate the shortage of sufficient data to
supervise classification, one may adopt traditional data augmentation
techniques, which yet may bring little improvement due to scarcely expanded data
diversity aiming at augmenting the performance of cervical abnormality
screening, we develop a novel conditional generative adversarial network in this
paper, namely cellgan, to synthesize cytopathological images for various cell
types.",
353,An Anti-biased TBSRTC-Category Aware Nuclei Segmentation Framework with a Multi-label Thyroid Cytology Benchmark,none,
354,Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,"according to the data format, there are two main multi-modal pre-training
approaches, as shown in fig.",
355,Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,"to our best knowledge, this is the first pre-training work based on multi-modal
pathological data.",
356,Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,"we evaluate the proposed method on two public datasets as herohe challenge and
bci challenge, which shows that our method achieves state-of-theart performance.",
357,Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,"according to the data format, there are two main multi-modal pre-training
approaches, as shown in fig.",
358,Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,"to our best knowledge, this is the first pre-training work based on multi-modal
pathological data.",
359,Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,"we evaluate the proposed method on two public datasets as herohe challenge and
bci challenge, which shows that our method achieves state-of-theart performance.",
360,Semi-supervised Pathological Image Segmentation via Cross Distillation of Multiple Attentions,"recently, deep learning has achieved remarkable performance in pathological
image segmentation when trained with a large and well-annotated dataset
semi-supervised learning (ssl) is a potential technique to reduce the annotation
cost via learning from a limited number of labeled data along with a large
amount of unlabeled data.",
361,Semi-supervised Pathological Image Segmentation via Cross Distillation of Multiple Attentions,"unlike mc-net+ the contribution of this work is three-fold: 1) a novel framework
named cdma based on mtnet is introduced for semi-supervised pathological image
segmentation, which leverages different attention mechanisms for generating
diverse and complementary predictions for unlabeled images; 2) a cross decoder
knowledge distillation method is proposed for robust and efficient learning from
noisy pseudo labels, which is combined with an average prediction-based
uncertainty minimization to improve the model's performance; 3) experimental
results show that the proposed cdma outperforms eight state-of-the-art ssl
methods on the public digestpath dataset automatic segmentation of tumor lesions
from pathological images plays an important role in accurate diagnosis and
quantitative evaluation of cancers.",
362,Semi-supervised Pathological Image Segmentation via Cross Distillation of Multiple Attentions,"recently, deep learning has achieved remarkable performance in pathological
image segmentation when trained with a large and well-annotated dataset
semi-supervised learning (ssl) is a potential technique to reduce the annotation
cost via learning from a limited number of labeled data along with a large
amount of unlabeled data.",
363,Semi-supervised Pathological Image Segmentation via Cross Distillation of Multiple Attentions,"unlike mc-net+ the contribution of this work is three-fold: 1) a novel framework
named cdma based on mtnet is introduced for semi-supervised pathological image
segmentation, which leverages different attention mechanisms for generating
diverse and complementary predictions for unlabeled images; 2) a cross decoder
knowledge distillation method is proposed for robust and efficient learning from
noisy pseudo labels, which is combined with an average prediction-based
uncertainty minimization to improve the model's performance; 3) experimental
results show that the proposed cdma outperforms eight state-of-the-art ssl
methods on the public digestpath dataset",
364,Towards Novel Class Discovery: A Study in Novel Skin Lesions Clustering,"specifically, we first use contrastive learning to pretrain the model based on
all data from known and unknown categories to learn a robust and general
semantic feature representation.",
365,Towards Novel Class Discovery: A Study in Novel Skin Lesions Clustering,"we conducted extensive experiments on the dermoscopy dataset isic 2019, and the
experimental results show that our method outperforms other state-of-the-art
comparison algorithms by a large margin.",
366,Towards Novel Class Discovery: A Study in Novel Skin Lesions Clustering,"specifically, we first use contrastive learning to pretrain the model based on
all data from known and unknown categories to learn a robust and general
semantic feature representation.",
367,Towards Novel Class Discovery: A Study in Novel Skin Lesions Clustering,"we conducted extensive experiments on the dermoscopy dataset isic 2019, and the
experimental results show that our method outperforms other state-of-the-art
comparison algorithms by a large margin.",
368,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"cancers are a group of heterogeneous diseases reflecting deep interactions
between pathological and genomics variants in tumor tissue environments the
major goal of multimodal data learning is to extract complementary contextual
information across modalities to tackle above challenges, we propose a
pathology-and-genomics multimodal framework (i.e., pathomics) for survival
prediction (fig.",
369,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,datasets.,
370,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,all image and genomics data are publicly available.,
371,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"we collected wsis from the cancer genome atlas colon adenocarcinoma (tcga-coad)
dataset (cc-by-3.0) experimental settings and implementations.",
372,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"we implement two types of settings that involve internal and external datasets
for model pretraining and finetuning.",
373,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"as shown in fig the number of epochs for pretraining and finetuning are 25, the
batch size is 1, the optimizer is adam developing data-efficient multimodal
learning is crucial to advance the survival assessment of cancer patients in a
variety of clinical data scenarios.",
374,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"importantly, our approach opens up perspectives for exploring the key insights
of intrinsic genotypephenotype interactions in complex cancer data across
modalities.",
375,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"our finetuning cancers are a group of heterogeneous diseases reflecting deep
interactions between pathological and genomics variants in tumor tissue
environments the major goal of multimodal data learning is to extract
complementary contextual information across modalities to tackle above
challenges, we propose a pathology-and-genomics multimodal framework (i.e.,
pathomics) for survival prediction (fig.",
376,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,datasets.,
377,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,all image and genomics data are publicly available.,
378,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"we collected wsis from the cancer genome atlas colon adenocarcinoma (tcga-coad)
dataset (cc-by-3.0) experimental settings and implementations.",
379,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"we implement two types of settings that involve internal and external datasets
for model pretraining and finetuning.",
380,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"as shown in fig the number of epochs for pretraining and finetuning are 25, the
batch size is 1, the optimizer is adam developing data-efficient multimodal
learning is crucial to advance the survival assessment of cancer patients in a
variety of clinical data scenarios.",
381,Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"importantly, our approach opens up perspectives for exploring the key insights
of intrinsic genotypephenotype interactions in complex cancer data across
modalities.",
382,Robust Cervical Abnormal Cell Detection via Distillation from Local-Scale Consistency Refinement,"if diagnosed early, it can be effectively treated and cured with the development
of deep learning although the above-mentioned attempts can improve the screening
performance significantly, there are several issues that need to be addressed:
1) object detection methods often require accurate annotated data to guarantee
performance with robustness and generalization.",
383,Robust Cervical Abnormal Cell Detection via Distillation from Local-Scale Consistency Refinement,"if diagnosed early, it can be effectively treated and cured with the development
of deep learning although the above-mentioned attempts can improve the screening
performance significantly, there are several issues that need to be addressed:
1) object detection methods often require accurate annotated data to guarantee
performance with robustness and generalization.",
384,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"in this work, we proposed and examined novel data augmentation strategies based
on the idea of interpolations of feature vectors in the mil setting.",
385,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"with the baseline data augmentation approaches, the maximum improvements were
0.03, and 0.02 for the frozen, and 0.01, and 0.05 for the paraffin data set.",
386,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"the multilinear intra-mixup method, however, exhibited the best scores for 3 out
of 4 combinations and the best overall mean accuracy for both, the frozen and
the paraffin data set.",
387,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"also a clear trend with increasing scores in the case of an increasing ratio of
augmented data (β) is visible.",
388,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"with regard to the different data sets, we noticed a stronger, positive effect
in case of the frozen section data set.",
389,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"this is supposed to be due to the clearly higher variability of the frozen
sections corresponding with a need for a higher variability in the training
data.",
390,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"we suppose that this is due to the fact that the additional loss of the
dual-stream architecture exhibits a valuable regularization tool to reduce the
amount of needed training data.",
391,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"with the proposed intra-mixup augmentation strategy, this effect diminishes,
since the amount and quality of training data is increased.",
392,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"to conclude, we proposed novel data augmentation strategies based on the idea of
interpolations of image descriptors in the mil setting.",
393,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"in the future, additional experiments will be conducted including stain
normalization methods and larger benchmark data sets to provide further
insights.",
394,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"in this work, we proposed and examined novel data augmentation strategies based
on the idea of interpolations of feature vectors in the mil setting.",
395,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"with the baseline data augmentation approaches, the maximum improvements were
0.03, and 0.02 for the frozen, and 0.01, and 0.05 for the paraffin data set.",
396,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"the multilinear intra-mixup method, however, exhibited the best scores for 3 out
of 4 combinations and the best overall mean accuracy for both, the frozen and
the paraffin data set.",
397,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"also a clear trend with increasing scores in the case of an increasing ratio of
augmented data (β) is visible.",
398,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"with regard to the different data sets, we noticed a stronger, positive effect
in case of the frozen section data set.",
399,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"this is supposed to be due to the clearly higher variability of the frozen
sections corresponding with a need for a higher variability in the training
data.",
400,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"we suppose that this is due to the fact that the additional loss of the
dual-stream architecture exhibits a valuable regularization tool to reduce the
amount of needed training data.",
401,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"with the proposed intra-mixup augmentation strategy, this effect diminishes,
since the amount and quality of training data is increased.",
402,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"to conclude, we proposed novel data augmentation strategies based on the idea of
interpolations of image descriptors in the mil setting.",
403,MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"in the future, additional experiments will be conducted including stain
normalization methods and larger benchmark data sets to provide further
insights.",
404,Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"breast cancer (bc) is the most common cancer diagnosed among females and the
second leading cause of cancer death among women after lung cancer among
different types of imaging biomarkers, histopathological images are generally
considered the golden standard for bc prognosis since they can confer important
cell-level information that can reflect the aggressiveness of bc to deal with
the above challenges, several researchers began to design domain adaption
algorithms, which utilize the labeled data from a related cancer subtype to help
predict the patients' survival in the target domain.",
405,Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"next, we aligned the aggregated tumor or tils features from the two domains
separately using maximum mean discrepancy(mmd) here, we adopted mmd for feature
alignment due to its ability to measure the distance between two distributions
without explicit assumptions on the data distribution, we showed the objective
function of mmd in our method as follows: where h is a hilbert space, f
represents the features from the source, f represents the feature from the
target, r represents the layer number, k ∈ {l, t } referred to tils or tumor
node.",
406,Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"in order to measure the dissimilarity between p i and q i , the kullback-leibler
(kl) divergence is adapted on the third layer of gat, which can be formulated
as: according to eq.( datasets.",
407,Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"we conducted our experiments on the breast invasive carcinoma (brca) dataset
from the cancer genome atlas (tcga).",
408,Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"specifically, the brca dataset includes 661 patients with hematoxylin and eosin
(he)-stained pathological imaging and corresponding survival information.",
409,Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"breast cancer (bc) is the most common cancer diagnosed among females and the
second leading cause of cancer death among women after lung cancer among
different types of imaging biomarkers, histopathological images are generally
considered the golden standard for bc prognosis since they can confer important
cell-level information that can reflect the aggressiveness of bc to deal with
the above challenges, several researchers began to design domain adaption
algorithms, which utilize the labeled data from a related cancer subtype to help
predict the patients' survival in the target domain.",
410,Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"next, we aligned the aggregated tumor or tils features from the two domains
separately using maximum mean discrepancy(mmd) here, we adopted mmd for feature
alignment due to its ability to measure the distance between two distributions
without explicit assumptions on the data distribution, we showed the objective
function of mmd in our method as follows: where h is a hilbert space, f
represents the features from the source, f represents the feature from the
target, r represents the layer number, k ∈ {l, t } referred to tils or tumor
node.",
411,Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"in order to measure the dissimilarity between p i and q i , the kullback-leibler
(kl) divergence is adapted on the third layer of gat, which can be formulated
as: according to eq.( datasets.",
412,Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"we conducted our experiments on the breast invasive carcinoma (brca) dataset
from the cancer genome atlas (tcga).",
413,Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"specifically, the brca dataset includes 661 patients with hematoxylin and eosin
(he)-stained pathological imaging and corresponding survival information.",
414,Gene-Induced Multimodal Pre-training for Image-Omic Classification,"furthermore, to model the high-order relevance of the two modalities, we combine
cls tokens of paired image and genomic data to form unified representations and
propose a triplet learning module to differentiate patient-level positive and
negative samples in a mini-batch.",
415,Gene-Induced Multimodal Pre-training for Image-Omic Classification,datasets.,
416,Gene-Induced Multimodal Pre-training for Image-Omic Classification,"we verify the effectiveness of our method on the caner genome atlas (tcga)
non-small cell lung cancer (nsclc) dataset, which contains two cancer subtypes,
i.e., lung squamous cell carcinoma (lusc) and lung adenocarcinoma (luad).",
417,Gene-Induced Multimodal Pre-training for Image-Omic Classification,"the pre-training process of all algorithms is conducted on the training set,
without any extra data augmentation.",
418,Gene-Induced Multimodal Pre-training for Image-Omic Classification,"note that our genetic encoder, groupmsa, is fully supervised pre-trained on
unimodal genetic data to accelerate convergence and it is frozen during gimp
training process.",
419,Gene-Induced Multimodal Pre-training for Image-Omic Classification,"furthermore, to model the high-order relevance of the two modalities, we combine
cls tokens of paired image and genomic data to form unified representations and
propose a triplet learning module to differentiate patient-level positive and
negative samples in a mini-batch.",
420,Gene-Induced Multimodal Pre-training for Image-Omic Classification,datasets.,
421,Gene-Induced Multimodal Pre-training for Image-Omic Classification,"we verify the effectiveness of our method on the caner genome atlas (tcga)
non-small cell lung cancer (nsclc) dataset, which contains two cancer subtypes,
i.e., lung squamous cell carcinoma (lusc) and lung adenocarcinoma (luad).",
422,Gene-Induced Multimodal Pre-training for Image-Omic Classification,"the pre-training process of all algorithms is conducted on the training set,
without any extra data augmentation.",
423,Gene-Induced Multimodal Pre-training for Image-Omic Classification,"note that our genetic encoder, groupmsa, is fully supervised pre-trained on
unimodal genetic data to accelerate convergence and it is frozen during gimp
training process.",
424,Histopathology Image Classification Using Deep Manifold Contrastive Learning,"the dataset for the former task was collected from 168 patients with 332 wsis
from seoul national university hospital.",
425,Histopathology Image Classification Using Deep Manifold Contrastive Learning,"the liver cancer dataset for the latter task was composed of 323 wsis, in which
the wsis can be further classified into hepatocellular carcinomas (hccs)
(collected from pathology ai platform we used a pre-trained vgg16 with imagenet
as the initial encoder, which was further modified via deep manifold model
training using the proposed manifold and cross-entropy loss functions.",
426,Histopathology Image Classification Using Deep Manifold Contrastive Learning,"the dataset for the former task was collected from 168 patients with 332 wsis
from seoul national university hospital.",
427,Histopathology Image Classification Using Deep Manifold Contrastive Learning,"the liver cancer dataset for the latter task was composed of 323 wsis, in which
the wsis can be further classified into hepatocellular carcinomas (hccs)
(collected from pathology ai platform we used a pre-trained vgg16 with imagenet
as the initial encoder, which was further modified via deep manifold model
training using the proposed manifold and cross-entropy loss functions.",
428,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"-we developed a comprehensive pipeline for constructing tumor-associated stroma
datasets across multiple data sources, and employed adversarial training and
neighborhood consistency regularization techniques to learn robust
multimodal-invariant image representations.",
429,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"however, using data from multiple modalities can introduce systematic shifts,
which can impact the performance of a deep learning model.",
430,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"the optimization process aims to achieve a balance between these two goals,
resulting in an embedding space that encodes as much information as possible
about tumor-associated stroma identification while not encoding any information
on the data source.",
431,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"in our study, we utilized three datasets for tumor-associated stroma analysis.",
432,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"(1) dataset a comprises 513 tiles extracted from the whole mount slides of 40
patients, sourced from the archives of the pathology department at cedars-sinai
medical center (irb# pro00029960).",
433,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"it combines two sets of tiles: 224 images from 20 patients featuring stroma,
normal glands, low-grade and highgrade cancer (2) dataset b included 97 whole
mount slides with an average size of over 174,000×142,000 pixels at 40x
magnification.",
434,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"(3) dataset c comprised 6134 negative biopsy slides obtained from 262 patients'
biopsy procedures, where all samples were diagnosed as negative.",
435,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,dataset a was utilized for training the stroma segmentation model.,
436,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"extensive data augmentation techniques, such as image scaling and staining
perturbation, were employed during the training process.",
437,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"this model was then applied to generate stroma masks for all slides in datasets
b and c.",
438,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"to precisely isolate stroma tissues and avoid data bleeding from epithelial
tissues, we only extracted patches where over 99.5% of the regions were
identified as stroma at 40x magnification to construct the stroma classification
dataset.",
439,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"to incorporate multi-modal information, we randomly sampled negative stroma
patches from all biopsy slides in dataset c.",
440,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"future research can focus on validating our approach on larger and more diverse
datasets and expanding the method to a patient-level prediction system,
ultimately improving prostate cancer diagnosis and treatment.",
441,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"-we developed a comprehensive pipeline for constructing tumor-associated stroma
datasets across multiple data sources, and employed adversarial training and
neighborhood consistency regularization techniques to learn robust
multimodal-invariant image representations.",
442,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"however, using data from multiple modalities can introduce systematic shifts,
which can impact the performance of a deep learning model.",
443,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"the optimization process aims to achieve a balance between these two goals,
resulting in an embedding space that encodes as much information as possible
about tumor-associated stroma identification while not encoding any information
on the data source.",
444,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"in our study, we utilized three datasets for tumor-associated stroma analysis.",
445,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"(1) dataset a comprises 513 tiles extracted from the whole mount slides of 40
patients, sourced from the archives of the pathology department at cedars-sinai
medical center (irb# pro00029960).",
446,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"it combines two sets of tiles: 224 images from 20 patients featuring stroma,
normal glands, low-grade and highgrade cancer (2) dataset b included 97 whole
mount slides with an average size of over 174,000×142,000 pixels at 40x
magnification.",
447,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"(3) dataset c comprised 6134 negative biopsy slides obtained from 262 patients'
biopsy procedures, where all samples were diagnosed as negative.",
448,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,dataset a was utilized for training the stroma segmentation model.,
449,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"extensive data augmentation techniques, such as image scaling and staining
perturbation, were employed during the training process.",
450,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"this model was then applied to generate stroma masks for all slides in datasets
b and c.",
451,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"to precisely isolate stroma tissues and avoid data bleeding from epithelial
tissues, we only extracted patches where over 99.5% of the regions were
identified as stroma at 40x magnification to construct the stroma classification
dataset.",
452,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"to incorporate multi-modal information, we randomly sampled negative stroma
patches from all biopsy slides in dataset c.",
453,Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"future research can focus on validating our approach on larger and more diverse
datasets and expanding the method to a patient-level prediction system,
ultimately improving prostate cancer diagnosis and treatment.",
454,Multi-scope Analysis Driven Hierarchical Graph Transformer for Whole Slide Image Based Cancer Survival Prediction,none,
455,Mining Negative Temporal Contexts for False Positive Suppression in Real-Time Ultrasound Lesion Detection,none,
456,Iteratively Coupled Multiple Instance Learning from Instance to Bag Classifier for Whole Slide Image Classification,"our experiments utilized two datasets, with the first being the publicly
available breast cancer dataset, camelyon16 the second dataset is a private
hepatocellular carcinoma (hcc) dataset collected from sir run run shaw hospital,
hangzhou, china.",
457,Iteratively Coupled Multiple Instance Learning from Instance to Bag Classifier for Whole Slide Image Classification,"this dataset comprises a total of 1140 valid tumor wsis scanned at 40×
magnification, and the objective is to identify the severity of each case based
on the edmondson-steiner (es) grading.",
458,Iteratively Coupled Multiple Instance Learning from Instance to Bag Classifier for Whole Slide Image Classification,"our experiments utilized two datasets, with the first being the publicly
available breast cancer dataset, camelyon16 the second dataset is a private
hepatocellular carcinoma (hcc) dataset collected from sir run run shaw hospital,
hangzhou, china.",
459,Iteratively Coupled Multiple Instance Learning from Instance to Bag Classifier for Whole Slide Image Classification,"this dataset comprises a total of 1140 valid tumor wsis scanned at 40×
magnification, and the objective is to identify the severity of each case based
on the edmondson-steiner (es) grading.",
460,Artifact Restoration in Histology Images with Diffusion Probabilistic Models,none,
461,Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"radiologists typically focus on areas with breast lesions during mammogram
reading radiologists' eye movements can be automatically and unobtrusively
recorded during the process of reading mammograms, providing a valuable source
of data without the need for manual labeling.",
462,Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"previous studies have incorporated radiologists' eye-gaze as a form of weak
supervision, which directs the network's attention to the regions with possible
lesions mammography primarily detects two types of breast lesions: masses and
microcalcifications in this work, we propose a novel diagnostic model, namely
mammo-net, which integrates radiologists' gaze data and interactive information
between cc-view and mlo-view to enhance diagnostic performance.",
463,Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"to the best of our knowledge, this is the first work to integrate gaze data into
multi-view mammography classification.",
464,Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"• we demonstrate the effectiveness of our approach through experiments using
mammography datasets, which show the superiority of mammo-net.",
465,Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"to achieve this, we integrate gaze data as a form of weak supervision for both
lesion positioning and interpretability of the model.",
466,Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"our experimental results on mammography datasets demonstrate the superiority of
our proposed model.",
467,Probabilistic Modeling Ensemble Vision Transformer Improves Complex Polyp Segmentation,"• we evaluate the performance of petnet on five widely adopted datasets,
demonstrating its superior ability to identify polyp camouflage and small polyp
scenes, achieving state-of-the-art performance in locating polyps with high
precision.",
468,DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,"when training the model on other datasets, we use the tumor set collected from
the inbreast dataset.",
469,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,"to achieve this goal, we create a synthetic dataset, which has separate
annotations for normal kidneys and protruded regions, and train a segmentation
network to separate the protruded regions from the normal kidney regions.",
470,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,"verify that the proposed framework achieves a higher dice score compared to the
standard 3d u-net using a publicly available dataset.",
471,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,"the release of two public ct image datasets with kidney and tumor masks from the
2019/2021 kidney and kidney tumor segmentation challenge looking at the top 3
teams from each challenge in terms of focusing on protruded regions in kidneys,
our work is close to the second protuberance detection network is the same as
the base network except it starts from 8 channels instead of 16.",
472,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,we train this network using synthetic datasets.,
473,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,the details of the dataset and training procedures are described in sect.,
474,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,synthetic dataset.,
475,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,"however, annotating such areas is time-consuming and preparing a large number of
data is challenging.",
476,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,"alternatively, we create a synthetic dataset that mimics a kidney with
protrusions.",
477,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,the synthetic dataset is created through the following steps: 1.,
478,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,"if both of the following conditions are met, append to the dataset.",
479,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,"although our network is fully differentiable, since there is no separate
annotation for protruded regions other from the synthetic dataset, we freeze the
parameters in protuberance detection network.",
480,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,"to cope with isodensity tumors, which have similar intensity values to their
surrounding tissues, we created a synthetic dataset to train a network that
extracts protuberance from the kidney masks.",
481,Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,"we evaluated our method using the publicly available kits19 dataset, and showed
that the proposed method can achieve a higher sensitivity than existing
approach.",
482,Skin Lesion Correspondence Localization in Total Body Photography,"the framework is evaluated on a private dataset and a public dataset with
success rates that are comparable to those of the state-of-the-art method.",
483,Skin Lesion Correspondence Localization in Total Body Photography,"in addition, the method may not work well with longitudinal data that has
non-isometric deformation due to huge variations in body shape, inconsistent 3d
reconstruction, or a dramatic change in pose and, therefore, topology, such as
an open armpit versus a closed one.",
484,Skin Lesion Correspondence Localization in Total Body Photography,"in the future, the method needs to be evaluated on longitudinal data with longer
duration and new lesions absent in the target.",
485,Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,"studies suggest that one way to improve these factors is through data centric
approaches i.e.",
486,Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,to focus on appropriate representation of data.,
487,Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,"specifically, representation of data as graphs has been shown to be effective
for medical diagnosis and analysis biological data, specially those acquired
intra-opertively, are heterogeneous by nature.",
488,Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,"while the use of ex-vivo data collected under specific protocols are beneficial
to develop baseline models, intra-operative deployment of these models is
challenging.",
489,Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,"for iknife, the ex-vivo data is usually collected from homogeneous regions of
resected specimens under the guidance of a trained pathologist, versus the
intra-operative data is recorded continuously while the surgeon cutting through
tissues with different heterogeneity and pathology.",
490,Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,"deep ensembles ex-vivo: data is collected from fresh breast tissue samples from
the patients referred to bcs at kingston health sciences center over two years.",
491,Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,"in addition to spectral data, clinicopathological details such as the status of
hormone receptors is also provided post-surgically.",
492,Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,"evidential deep learning provides a welldefined theoretical framework to jointly
quantify classification prediction and uncertainty modeling by assuming the
class probability follows a dirichlet distribution in the context of surgical
margin assessment, the attentions reveal the relevant metabolic ranges to
cancerous tissue, while uncertainty helps identify and filter data with unseen
pathology.",
493,Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-Based Hierarchical Fusion Network with Attention Mechanism,"the mris were acquired with philips ingenia all mris were resampled to 1 mm
isotropic voxels and uniformly sized, resulting in volumes of 352 × 352 pixel
images with 176 slices per mri, and subsequent registration was performed based
on advanced normalization tools (ants) we have developed a multi-sequence fusion
network based on multi-b-value dwi to synthesize ce-mri, using source data
including dwis and t1-weighted fatsuppressed mri.",
494,Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-Based Hierarchical Fusion Network with Attention Mechanism,"compared to existing methods, we avoid the challenges of using full-sequence mri
and aim to be selective on valuable source data dwi.",
495,Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"ji measures similarity of two datasets, which ranges from 0% to 100%.",
496,Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"due to both real patients and synthetic patients were involved in delineation,
to erase the delineation memory of the same patient, we separated the patients
to two datasets, each with the same number of patients, both two datasets with
mixed real patients and synthetic patients without overlaps (i.e., the ce-mri
and vce-mri from the same patient are not in the same dataset).when finished the
first dataset delineation, there was a one-month interval before the delineation
of the second dataset.",
497,Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"the average ji obtained from institution-1, institution-2, and institution-3
dataset were similar with a result of 71.54%, 74.78% and 75.85%, respectively.",
498,Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"for the institution-2 data, all synthetic patients observed the same stages as
real patients.",
499,Automated CT Lung Cancer Screening Workflow Using 3D Camera,none,
500,Multi-task Learning of Histology and Molecular Markers for Classifying Diffuse Glioma,none,
501,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"to achieve this, we efficiently exploit knowledge from multi-center datasets
that are not tailored for second-course gtv segmentation.",
502,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"medical images are sparsely labeled which are isolated by different tasks in
order to fully leverage both public and private datasets, the training objective
should not be specific to any tasks.",
503,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"to adequately monitor changes in tumor volume and integrate information from the
initial course into the subsequent course, a paired first-second courses dataset
s p = {i 1 p , i 2 p , g 1 p ; g 2 p } is necessary for training.",
504,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"the paired dataset s p for the first and second courses is limited, whereas an
unpaired gtv dataset s v = {i v ; g v } can be easily obtained in a standard
clinical workflow with a substantial amount.",
505,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"the transformed data is feed into the encoders e 1/2 as shown in the following
equations: , p 1 (g e ), p 2 (i e ), p 2 (g e ), when i e , g e ∈ s e .",
506,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,datasets.,
507,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"the paired first-second course dataset, s p , is collected from sun yat-sen
university cancer center (ethics approval number: b2023-107-01), comprising
paired ct scans of 69 distinct patients from south china.",
508,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"we collected the gtv dataset s v from medmind technology co., ltd., which has ct
scans from 179 patients.",
509,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"to demonstrate the presence of a domain gap between the first and second
courses, we train sota methods with datasets s train p and s v , by feeding the
data sequentially into the network.",
510,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,the results presented in table figure combination of various datasets.,
511,Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"besides, to efficiently leverage prior knowledge contained in various medical ct
datasets, we train the network in an information-querying manner.",
512,CLIP-Lung: Textual Knowledge-Guided Lung Nodule Malignancy Prediction,none,
513,EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"on the one hand, inspired by the emerging prompt learning techniques that embed
prompts into a model for adaptation to diverse downstream tasks our
contributions can be summarized as: (3) a domain mixup strategy is devised to
reduce the co-artifacts specific to dermoscopic images; (4) extensive
experiments on four out-of-distribution skin datasets and six biased isic
datasets demonstrate the outperforming generalization ability and robustness of
epvt under heterogeneous distribution shifts.",
514,Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,real-world pnens dataset.,
515,Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,we validated our method on a real-world pnens dataset from two centers.,
516,Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"the dataset contained 264 and 28 patients in center 1 and center 2, and a senior
radiologist annotated the bounding boxes for all 408 and 28 lesions.",
517,Developing Large Pre-trained Model for Breast Tumor Segmentation from Ultrasound Images,"five-fold cross validation is performed on the dataset in all experiments to
verify our proposed network.",
518,Developing Large Pre-trained Model for Breast Tumor Segmentation from Ultrasound Images,"for external validation, we further test our model on two independent
publicly-available datasets collected by stu-hospital (dataset 1) to verify the
advantages of our proposed model for breast tumor segmentation in ultrasound
images, we compare our deep-supervised convolutional network with the
state-ofthe-art tumor segmentation methods, including deepres representative
segmentation results using different methods are provided in fig.",
519,Developing Large Pre-trained Model for Breast Tumor Segmentation from Ultrasound Images,"using a large clinical dataset, our proposed model demonstrates not only
state-of-the-art segmentation performance, but also the outstanding
generalizability to new ultrasound data from different sites.",
520,3D Mitochondria Instance Segmentation with Spatio-Temporal Transformers,segmentation performance on all three datasets.,
521,Physics-Informed Conditional Autoencoder Approach for Robust Metabolic CEST MRI at 7T,data measurements.,
522,Deep Unsupervised Clustering for Conditional Identification of Subgroups Within a Digital Pathology Image Set,her2 dataset.,
523,Deep Unsupervised Clustering for Conditional Identification of Subgroups Within a Digital Pathology Image Set,"human epidermal growth factor receptor 2 (her2 or her2/neu) is a protein
involved in normal cell growth, which plays an important role in the diagnosis
and treatment of breast cancer deep clustering models applied to the her2
dataset.",
524,Deep Unsupervised Clustering for Conditional Identification of Subgroups Within a Digital Pathology Image Set,"we evaluate the performance and behavior of the dec, vade, and cdvade models on
the her2 dataset.",
525,Deep Unsupervised Clustering for Conditional Identification of Subgroups Within a Digital Pathology Image Set,"we investigate whether the models will learn to distinguish the her2 class
labels, the scanner labels, or other potentially meaningful data subgroups in a
fully unsupervised fashion.",
526,Deep Unsupervised Clustering for Conditional Identification of Subgroups Within a Digital Pathology Image Set,"to investigate the clustering abilities of cdvade on the her2 dataset, we inject
the her2 class labels into the latent embedding space.",
527,A Texture Neural Network to Predict the Abnormal Brachial Plexus from Routine Magnetic Resonance Imaging,"this paper constructed a bp dataset with the most commonly used bp mris in our
clinical practice.",
528,A Texture Neural Network to Predict the Abnormal Brachial Plexus from Routine Magnetic Resonance Imaging,"the major contributions of this study include 1) directed triangle construction
idea for tpp, 2) huge number of tpp matrices as the heterogeneity
representations of bp, 3) tppnet with 15 layers and huge number of channels, 4)
the bp dataset containing mr images and their corresponding roi masks.",
529,A Texture Neural Network to Predict the Abnormal Brachial Plexus from Routine Magnetic Resonance Imaging,"to testify our proposed tppnet, a bp dataset is constructed with 452 series
including three most commonly used mr sequences in clinical practice, i.e.",
530,CircleFormer: Circular Nuclei Detection in Whole Slide Images with Circle Queries and Attention,"we evaluate our circleformer on the public monuseg dataset for nuclei detection
in whole slide images.",
531,Self-supervised Dense Representation Learning for Live-Cell Microscopy with Time Arrow Prediction,"to demonstrate the utility of tap for a diverse set of specimen and microscopy
modalities we use the following four different datasets: hela.",
532,Self-supervised Dense Representation Learning for Live-Cell Microscopy with Time Arrow Prediction,"for each dataset we heuristically choose δt to roughly correspond to the time
scale of observable biological processes (i.e.",
533,Prompt-MIL: Boosting Multi-instance Learning Schemes via Task-Specific Prompt Tuning,"compared to the full fine-tuning method, our method achieved a relative
improvement of 1.29% to 13.61% in accuracy and 3.22% to 27.18% in auroc on the
three datasets.",
534,Prompt-MIL: Boosting Multi-instance Learning Schemes via Task-Specific Prompt Tuning,"we evaluated the training speed and memory consumption of our method and
compared to the full fine-tuning baseline on four different sized wsis in the
bright dataset.",
535,Prompt-MIL: Boosting Multi-instance Learning Schemes via Task-Specific Prompt Tuning,"foundational models refer to those trained on large-scale pathology datasets
(e.g.",
536,Prompt-MIL: Boosting Multi-instance Learning Schemes via Task-Specific Prompt Tuning,the entire tcga pan-cancer dataset,
537,Prompt-Based Grouping Transformer for Nucleus Detection and Classification,"however, the transformer framework has a relatively large number of parameters,
which could cause high costs in fine-tuning the whole model on large datasets.",
538,Prompt-Based Grouping Transformer for Nucleus Detection and Classification,"inspired by the prompt tuning methods consep 1 [10] is a colorectal nuclear
dataset with three types, consisting of 41 h&e stained image tiles from 16
colorectal adenocarcinoma whole-slide images (wsis).",
539,Prompt-Based Grouping Transformer for Nucleus Detection and Classification,"we split them following the official partition is a breast cancer dataset with
three types and consists of 120 image tiles from 113 patients.",
540,Relaxation-Diffusion Spectrum Imaging for Probing Tissue Microarchitecture,"recent advances in diffusion mri (dmri) and diffusion signal modeling equip
brain researchers with an in vivo probe into microscopic tissue compositions
multi-compartment models are typically used to characterize signals from, for
example, intra-and extra-neurite compartments here, we propose a unified
strategy to estimate using mte diffusion data (i) compartment specific t 2
relaxation times; (ii) non-t 2 -weighted (non-t 2 w) parameters of multi-scale
microstructure; and (iii) non-t 2 w multi-scale fodfs.",
541,Relaxation-Diffusion Spectrum Imaging for Probing Tissue Microarchitecture,"we evaluate rdsi using both ex vivo monkey and in vivo human brain mte data,
acquired with fixed diffusion times across multiple b-values.",
542,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning,"the proposed technique was tested on a healthy-subject dataset and on a dataset
containing tumor cases.",
543,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning,"the first comprises 21 subjects of the human connectome project (hcp) that were
used for testing the automated methods tractseg and classifyber to test the
proposed method on pathological data, we used an in-house dataset containing ten
presurgical scans of patients with brain tumors.",
544,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning,"manual segmentation experiments using an interactive prototype of attractive
were initiated on the tumor data (holistic evaluation).",
545,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning,"additionally, reproducible simulations on the freely available hcp and the
internal tumor dataset were created (algorithmic evaluation).",
546,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning,"the code used for these experiments is publicly available for the algorithmic
evaluation, the initial training dataset was created with 20 randomly selected
streamlines from the whole-brain tractogram, which have been shown to be a
decent number to start training.",
547,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning,"since some tracts contain only a fraction of streamlines from the entire
tractogram, it might be unlikely that the training dataset will contain any
streamline belonging to the target tract.",
548,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning,"therefore, two streamlines of the specific tract were further added to the
training dataset, and class weights were used to compensate for the class
unbalance.",
549,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning,"to ensure that the initial dataset s rand contained streamlines from the target
tract, the expert initiated the active learning workflow by defining a small roi
that included fibers of the tract.",
550,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning,"to allow comparison between the proposed and traditional roi-based techniques,
the or of subjects from the tumor dataset were segmented using both approaches
by an expert familiar with the respective tool, and the time required was
reported to measure efficiency.",
551,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning,"note, in all experiments, the classifier is trained from scratch every
iteration, prototypes are generated for each subject individually, and the
classifier predicts on data from the same subject it is trained with, as it
performs subject-individual tract segmentation and is not used as a fully
automated method.",
552,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning,"to ensure a stable active learning setup that generalizes across different
datasets, the whole method was developed on the hcp and applied with fixed
settings to the tumor data active learning-based white matter tract segmentation
enables the identification of arbitrary pathways and can be applied to cases
where fully automated methods are unfeasible.",
553,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning,"the algorithmic evaluation yielded consistent results from the fifth to the
tenth iterations on both the hcp and tumor datasets.",
554,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning,"as expected, outcomes obtained from the tumor dataset were not quite as good as
those of the hcp dataset.",
555,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning,"this trend is generally observed in clinical datasets, which tend to exhibit
lower performance levels compared to high-quality datasets, which could be
responsible for the decline in the results.",
556,atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning,"for selected scenarios, the ability of the classifier to generalize by learning
from previously annotated subjects will be investigated, which may even allow to
train a fully automatic classifier for new tracts once enough data is annotated.",
557,B-Cos Aligned Transformers Learn Human-Interpretable Features,"we classify image patches from the public colorectal cancer dataset
nct-crc-he-100k domain-expert evaluation: our primary objective is to develop an
extension of the vision transformer that is more transparent and trusted by
medical professionals.",
558,Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"second, resting-state fmri data are not routinely collected for gbm clinical
practices, which restricts the size of annotated datasets such that it is
infeasible to train a reliable prediction model based on deep learning for
survival prediction.",
559,Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"similar to data augmentation schemes, we can artificially boost data volume
(i.e., fln maps) up to m times through producing m fln maps for each patient in
the a-lnm, which helps to mitigate the risk of over-fitting and improve the
performance of overall survival time prediction when learning a deep neural
network from a small sized dataset.",
560,Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"to evaluate the predictive power of the fln maps generated by our a-lnm, we
conduct extensive experiments on 235 gbm patients in the training dataset of
brats 2020 2.1 materials gsp1000 processed connectome.",
561,Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"it publicly released preprocessed restingstate fmri data of 1000 healthy
right-handed subjects with an average age 21.5 ± 2.9 years and approximately
equal numbers of males and females from the brain genomics superstruct project
(gsp) brats 2020.",
562,Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"it provided an open-access pre-operative imaging training dataset to segment
brain tumors of glioblastoma (gbm, belonging to high grade glioma) and low grade
glioma (lgg) patients, as well as to predict overall survival time of gbm
patients the union of all the three tumor sub-regions was considered as the
whole tumor, which is regarded as the lesion in this paper.",
563,Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"in this paper, we propose to investigate the feasibility of the novel
neuroimaging features, i.e., fln maps, for overall survival time prediction of
gbm patients in the training dataset of the brats 2020, in which one patient
alive was excluded, and the remaining 235 patients consisted of 89 short-term
survivors (less than 10 months), 59 mid-term survivors (between 10 and 15
months), and 87 long-term survivors (more than 15 months).",
564,Intraoperative CT Augmentation for Needle-Based Liver Interventions,"image fusion typically relies on the estimation of rigid or non-rigid
transformations between 2 images, to bring into the intraoperative image
structures of interest only visible in the preoperative data.",
565,Intraoperative CT Augmentation for Needle-Based Liver Interventions,"our future steps will essentially involve applying this method to patient data
and perform a small user study to evaluate the usefulness and limitations of our
approach.",
566,Optical Coherence Elastography Needle for Biomechanical Characterization of Deep Tissue,"1, using force and position sensor data (see supplementary material).",
567,Pelvic Fracture Segmentation Using a Multi-scale Distance-Weighted Neural Network,none,
568,Towards Multi-modal Anatomical Landmark Detection for Ultrasound-Guided Brain Tumor Resection with Contrastive Learning,"gliomas are the most common central nervous system (cns) tumors in adults,
accounting for 80% of primary malignant brain tumors as the true underlying
deformation from brain shift is impossible to obtain and the differences of
image features between mri and us are large, quantitative validation of
automatic mri-us registration algorithms often rely on homologous anatomical
landmarks that are manually labeled between corresponding mri and
intra-operative us scans previously, many groups have proposed algorithms to
label landmarks in anatomical scans we employed the publicly available
easy-resect (retrospective evaluation of cerebral tumors) dataset",
569,Deep Reinforcement Learning Based System for Intraoperative Hyperspectral Video Autofocusing,none,
570,Surgical Video Captioning with Mutual-Modal Concept Alignment,neurosurgery video captioning dataset.,
571,Surgical Video Captioning with Mutual-Modal Concept Alignment,"to evaluate the effectiveness of surgical video captioning, we collect a
large-scale dataset with 41 surgical videos of endonasal skull base
neurosurgery.",
572,Surgical Video Captioning with Mutual-Modal Concept Alignment,"after necessary data cleaning, we divide these surgical videos with resolution
of 1, 920× 1, 080 into 11, 004 thirty-second video clips with clear surgical
purposes.",
573,Surgical Video Captioning with Mutual-Modal Concept Alignment,"these video clips are annotated under tool-tissue interaction (tti) principle
endovis image captioning dataset.",
574,Surgical Video Captioning with Mutual-Modal Concept Alignment,"we further compare our method with state-of-the-arts on the public endovis-2018
image captioning dataset implementation details.",
575,Regularized Kelvinlet Functions to Model Linear Elasticity for Image-to-Physical Registration of the Breast,"the first explores sensitivity to regularized kelvinlet function hyperparameters
k grab , k twist , ε grab , and ε twist and establishes optimal hyperparameters
in a training dataset of 11 breast deformations.",
576,Regularized Kelvinlet Functions to Model Linear Elasticity for Image-to-Physical Registration of the Breast,"this dataset consists of supine breast mr images simulating surgical
deformations from one breast cancer patient.",
577,Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"we address the important problem of intraoperative patient-to-image registration
in a new way by relying on preoperative data to synthesize plausible
transformations and appearances that are expected to be found intraoperatively.",
578,Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"our experiments using clinical data showed that our method provides accurate
registration without manual intervention, that it is computationally efficient,
and it is invariant to the visual appearance of the cortex.",
579,Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"we present results on a clinical dataset comprising fifty post-operative
glioblastoma (gbm) patients.",
580,FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"the study further compared gods with two other novelty detection models: robust
covariance and, one-class support vector machine (oc-svm) results of a binary
classification model using svm are also shown in the supplementary section table
table the gods uses two separating hyperplanes to minimize the distance between
the two classifiers by learning a low-dimensional subspace containing flim data
properties of healthy labels.",
581,FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"residual tumor labels are detected by calculating the distance between the
projected data points and the learned subspace.",
582,FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"this is mainly due to the robustness of the model, the ability to handle
high-dimensional data, and the contrast in the flim decay curves.",
583,FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"the novelty detection model generalizes to the healthy labels and considers data
falling off the healthy distribution as residual cancer.",
584,FocalErrorNet: Uncertainty-Aware Focal Modulation Network for Inter-modal Registration Error Estimation in Ultrasound-Guided Neurosurgery,"in contrast, intra-operative ultrasound (ius) has gained popularity for
real-time imaging during surgery to monitor tissue deformation and surgical
tools because of its lower cost, portability, and flexibility recently,
automatic quality assessment for medical image registration has attracted
increasing attention for methodological development and assessment, we used the
resect (retro-spective evaluation of cerebral tumors) dataset",
585,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"however, it is not trivial to determine this using traditional methods due to
poor textural definition of tissues and lack of per-pixel ground truth depth
data.",
586,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"to validate our proposed solution for the newly formulated problem, we acquired
and publicly released two new datasets.",
587,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"all data acquisition and devices were controlled by python and labview programs,
and complete data sets of the above images were collected on visually realistic
phantoms for multiple probe and laparoscope positions.",
588,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"therefore, our first newly acquired dataset, named jerry, contains 1200 sets of
images.",
589,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"since it is important to report errors in 3d and in millimeters, we recorded
another dataset similar to jerry but also including ground truth depth map for
all frames by using structured-lighting system these datasets have multiple uses
such as: -intersection point detection: detecting intersection points is an
important problem that can bring accurate surgical cancer visualization.",
590,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"both the hardware and software design of the proposed solution were illustrated
and two newly acquired datasets were publicly released.",
591,Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"we believe that our problem reformulation and dataset release, together with the
initial experimental results, will establish a new benchmark for the surgical
vision community.",
592,A Novel Video-CTU Registration Method with Structural Point Similarity for FURS Navigation,"to the best of our knowledge, this work shows the first study to continuously
track the flexible ureteroscope in preoperative data using a vision-based
method.",
593,Cascade Transformer Encoded Boundary-Aware Multibranch Fusion Networks for Real-Time and Accurate Colonoscopic Lesion Segmentation,none,
594,Unified Brain MR-Ultrasound Synthesis Using Multi-modal Hierarchical Representations,none,
595,StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,dataset and preprocessing.,
596,StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"our clinical dataset consists of 108 patients for whom were acquired both a
pre-operative h&n ct scan and 4 to 11 wsis after laryngectomy (with a total
amount of 849 wsis).",
597,StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"we split the dataset patient-wise into three groups for training (64),
validation hyperparameters.",
598,StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"we drew our code from cyclegan and voxelmorph implementations with modifications
explained above, and we thank the authors of msv-regsynnet for making their code
and data available to us evaluation.",
599,StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"according to the mr/ct application in rt, we compared our model against the
state-of-the-art results of msv-regsynnet which were computed on the same
dataset.",
600,StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"we also compared against msv-regsynnet on its own validation dataset for
generalization assessment: we yielded comparable results for the first cohort
and significantly better ones for the second, which proves that structuregnet
behaves well on other modalities and that the structure awareness is an
essential asset for better registration, as pelvis is a location where organs
are moving.",
601,X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"we trained our model with a large dataset of 3500 cts of patients with
head-and-neck cancer, more exactly 2297 patients from the publicly available the
cancer imaging archive (tcia) 3d reconstruction.",
602,Structure-Preserving Synthesis: MaskGAN for Unpaired MR-CT Translation,none,
603,FreeSeed: Frequency-Band-Aware and Self-guided Network for Sparse-View CT Reconstruction,"freeseed achieves promising results with only image data and can be further
enhanced once the sinogram is available.",
604,Co-learning Semantic-Aware Unsupervised Segmentation for Pathological Image Registration,"to create such a mapping, we created a pseudo dataset by utilizing images from
the oasis-1 and brats2020.",
605,Co-learning Semantic-Aware Unsupervised Segmentation for Pathological Image Registration,"from the resulting t1 sequences, a pseudo dataset of 300 images was randomly
selected for further analysis.",
606,Co-learning Semantic-Aware Unsupervised Segmentation for Pathological Image Registration,appendix b provides a detailed process for creating the pseudo dataset.,
607,Co-learning Semantic-Aware Unsupervised Segmentation for Pathological Image Registration,real data with landmarks.,
608,Co-learning Semantic-Aware Unsupervised Segmentation for Pathological Image Registration,"after creating the pseudo dataset, we warped brain mr images without tumors to
the atlas and used the resulting deformation field as the gold standard for
evaluation.",
609,Revealing Anatomical Structures in PET to Generate CT for Attenuation Correction,"the data used in our experiments are collected from the cancer image archive
(tcia) each sample contains co-registered (acquired with pet-ct scans) ct, pet,
and nac-pet whole-body scans.",
610,An Explainable Deep Framework: Towards Task-Specific Fusion for Multi-to-One MRI Synthesis,none,
611,Geometric Ultrasound Localization Microscopy,none,
612,Reflectance Mode Fluorescence Optical Tomography with Consumer-Grade Cameras,none,
613,DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"in this experiment, we evaluate the performance of different methods for
estimating affine registration of the retrospective evaluation of cerebral
tumors (resect) miccai challenge dataset as the most challenging experiment, we
finally use our method to achieve deformable registration of abdominal 3d
freehand us to a ct or mr volume.",
614,DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"we are using a heterogeneous dataset of 27 cases, comprising liver cancer
patients and healthy volunteers, different ultrasound machines, as well as
optical vs.",
615,DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"all 3d ultrasound data sets are accurately calibrated, with overall system
errors in the range of commercial ultrasound fusion options.",
616,Solving Low-Dose CT Reconstruction via GAN with Local Coherence,datasets.,
617,Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"first, our proposed approaches are evaluated on the ""mayo-clinic low-dose ct
grand challenge"" (mayo-clinic) dataset of lung ct images the dataset contains
2250 two dimensional slices from 9 patients for training, and the remaining 128
slices from 1 patient are reserved for testing.",
618,Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"to evaluate the generalization of our model, we also consider another dataset
rider with nonsmall cell lung cancer under two ct scans baselines and evaluation
metrics.",
619,Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"to evaluate the stability and generalization of our model and the baselines
trained on mayo-clinic dataset, we also test them on the rider dataset.",
620,Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,training deep learning models for medical applications often needs new data.,
621,Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"this was not the case for noise2aliasing, and historical clinical data sufficed
for training.",
622,Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"we validated our method on publicly available data first, we used the spare
varian dataset to study whether noise2aliasing can match the performance of the
supervised baseline and if it can outperform it when adding noise to the
projections.",
623,Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"then, we use the internal dataset to explore the requirements for the method to
be applied to an existing clinical dataset.",
624,Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"the projections obtained during a scan are sub-sampled according to the
pseudo-average subset selection method described in the datasets used in this
study are two: 1.",
625,Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"the spare varian dataset was used to provide performance results on publicly
available patient data.",
626,Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"to more closely resemble normal respiratory motion per projection image, the 8
min scan has been used from each patient (five such scans are available in the
dataset).",
627,Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,the hyperparameters are optimized over the training dataset.,
628,Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"an internal dataset (irb approved) of 30 lung cancer patients' 4dcbcts from 2020
to 2022, originally used for igrt, with 25 patients for training and 5 patients
for testing.",
629,Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,the data were anonymized prior to analysis.,
630,Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"projection noise was added using the poisson distribution to the spare varian
dataset to evaluate the ability of the unsupervised method to reduce it.",
631,Trackerless Volume Reconstruction from Intraoperative Ultrasound Images,"3 presents our current results on ex vivo porcine data, and finally, we conclude
in sect.",
632,CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,"magnetic resonance imaging (mri) is critical to the diagnosis, treatment, and
follow-up of brain tumour patients management despite the success, gan-based
models are challenged by the limited capability of adversarial learning in
modelling complex multi-modal data distributions diffusion model (dm) has
achieved state-of-the-art performance in synthesizing natural images, promising
to improve mri synthesis models.",
633,LightNeuS: Neural Surface Reconstruction in Endoscopy Using Illumination Decline,none,
