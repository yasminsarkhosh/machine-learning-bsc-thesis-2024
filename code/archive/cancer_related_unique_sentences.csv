Paper Title,Extracted Sentence
Anatomy-Driven Pathology Detection on Chest X-rays,none
Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET,none
AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor,"however, most deep learning approaches for segmentation require fully or partially labeled training datasets, which can be time-consuming and expensive to annotate."
AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor,"to address this issue, recent research has focused on developing segmentation frameworks that require little or no segmentation labels."
AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor,"to meet this need, many researchers have devoted their efforts to weakly-supervised semantic segmentation (wsss)  the literature has not adequately addressed the issue of low-resolution class-activation maps (cams), especially for medical images."
AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor,the model learns the pixel-wise weighted sum of the activation maps by a novel contrastive learning method.
AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor,"our proposed method has the following contributions: -to tackle the issues in existing cams, we propose to use multiple-exit classification networks to accurately capture all the internal activation maps of different resolutions."
AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor,-we propose an attentive feature aggregation to learn the pixel-wise weighted sum of the internal activation maps.
AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor,"-we demonstrate the superiority of ame-cam over state-of-the-art cam methods in extracting segmentation results from classification networks on the 2021 brain tumor segmentation challenge (brats 2021)  we evaluate our method on the brain tumor segmentation challenge (brats) dataset  in this section, we compare the segmentation performance of the proposed ame-cam with five state-of-the-art weakly-supervised segmentation methods, namely grad-cam  compared to the unsupervised baseline (ul), c&f is unable to separate the tumor and the surrounding tissue due to low contrast, resulting in low dice scores in all experiments."
AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor,"with pixel-wise labels, the dice of supervised c&f improves significantly."
Unsupervised Discovery of 3D Hierarchical Structure with Generative Diffusion Features,"we train segmentation models with k = 3 parts (background, brain, tumor)."
Unsupervised Discovery of 3D Hierarchical Structure with Generative Diffusion Features,"the evaluation metric, as in the brats'19 challenge  we perform ablation studies on the brats'19 dataset (table  this might be due to the fact that predictive modeling involves learning from a distribution of images and a model may therefore extract useful knowledge from a collection of images."
Unsupervised Discovery of 3D Hierarchical Structure with Generative Diffusion Features,"to evaluate the significance of the diffusion features, we replaced our diffusion feature extractor with a 3d resnet from med3d  in this work, we showed that features from 3d generative diffusion models using a ladder-like u-net-based architecture can discover intrinsic 3d structures in biomedical images."
S 2 ME: Spatial-Spectral Mutual Teaching and Ensemble Learning for Scribble-Supervised Polyp Segmentation,none
Tracking Adaptation to Improve SuperPoint for 3D Reconstruction in Endoscopy,"3d reconstruction strategies have been studied for long, and one crucial step in these strategies is feature detection and matching which serves as input for structure from motion (sfm) pipelines."
Tracking Adaptation to Improve SuperPoint for 3D Reconstruction in Endoscopy,"endoscopic images are a challenging case for feature detection and matching, due to several well known challenges for these tasks, such as lack of texture, or the presence of frequent artifacts, like specular reflections."
Tracking Adaptation to Improve SuperPoint for 3D Reconstruction in Endoscopy,"these problems are accentuated when all the elements in the scene are deformable, as it is the case in most endoscopy scenarios, and in particular in the real use case studied in our work, the lower gastrointestinal tract explored with colonoscopies."
Black-box Domain Adaptative Cell Segmentation via Multi-source Distillation,none
Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning,"in recent years, deep learning (dl) methods have demonstrated remarkable performance in detecting and localizing tumors on ultrasound images  domain adaptation (da) has been extensively studied to alleviate the aforementioned limitations, the goal of which is to reduce the domain gap caused by the diversity of datasets from different domains  to alleviate the problem of pseudo-label-based uda, in this work, we propose an advanced uda framework based on self-supervised da with a test-time finetuning network."
Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning,"test-time adaptation methods have been developed  to summarize, our contributions are three-fold: • we design a self-supervised da framework that includes a parameter search method and provide a mathematical justification for it."
Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning,"due to the low resolution of ultrasound images, manual segmentation of breast cancer is challenging even for expert clinicians, resulting in a sparse number of labeled data."
Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning,"to address this issue, we introduced a novel self-supervised da network for breast cancer segmentation in ultrasound images."
Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning,"in particular, we proposed a test-time finetuning network to learn domain-specific knowledge via knowledge distillation by self-supervised learning."
PET-Diffusion: Unsupervised PET Enhancement Based on the Latent Diffusion Model,none
Cross-Adversarial Local Distribution Regularization for Semi-supervised Medical Image Segmentation,none
Infusing Physically Inspired Known Operators in Deep Models of Ultrasound Elastography,the young's modulus of the experimental phantom was 20 kpa and contains several inclusions with young's modulus of higher than 40 kpa.
Infusing Physically Inspired Known Operators in Deep Models of Ultrasound Elastography,this data is available online at http://code.sonography.ai in  in vivo data was collected at johns hopkins hospital from patients with liver cancer during open-surgical rf thermal ablation by a research antares siemens system using a vf 10-5 linear array with the sampling frequency of 40 mhz and the center frequency of 6.67 mhz.
Infusing Physically Inspired Known Operators in Deep Models of Ultrasound Elastography,the institutional review board approved the study with the consent of the patients.
SLPD: Slide-Level Prototypical Distillation for WSIs,"in computational histopathology, visual representation extraction is a fundamental problem  more recently, some works propose to close the gap via directly learning slidelevel representations in pre-training."
SLPD: Slide-Level Prototypical Distillation for WSIs,"for instance, hipt  in this paper, we propose to encode the intra-and inter-slide semantic structures by modeling the mutual-region/slide relations, which is called slpd: slide-level prototypical distillation for wsis."
PROnet: Point Refinement Using Shape-Guided Offset Map for Nuclei Instance Segmentation,nuclei segmentation in histopathology images is an important task for cancer diagnosis and immune response prediction  thousands of instances are tedious and the ambiguous nature of nuclei boundaries requires high-level expert annotators.
PROnet: Point Refinement Using Shape-Guided Offset Map for Nuclei Instance Segmentation,"to address this, weakly-supervised nuclei segmentation methods  to overcome these challenges, we propose a novel weakly supervised instance segmentation method that effectively distinguishes adjacent nuclei and is robust to point shifts."
PROnet: Point Refinement Using Shape-Guided Offset Map for Nuclei Instance Segmentation,"the proposed model consists of three modules responsible for binary segmentation, boundary delineation, and instance separation."
TPRO: Text-Prompting-Based Weakly Supervised Histopathology Tissue Segmentation,none
MetaLR: Meta-tuning of Learning Rates for Transfer Learning in Medical Imaging,none
DAS-MIL: Distilling Across Scales for MIL Classification of Histological WSIs,overall objective.
DAS-MIL: Distilling Across Scales for MIL Classification of Histological WSIs,"to sum up, the overall optimization problem is formulated as a mixture of two objectives: the one requiring higher conditional likelihood w.r.t."
DAS-MIL: Distilling Across Scales for MIL Classification of Histological WSIs,"ground truth labels y and carried out through the cross-entropy loss l ce (•; y); the other one based on knowledge distillation: where λ is a hyperparameter weighting the tradeoff between the teaching signals provided by labels and the higher resolution, while β balances the contributions of the consistency regularization introduced in eq."
vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images,"on top of that, we observe that in non-linear probing regime, it performs (within the standard deviation) as well as the fpn trained from scratch while having x50 times fewer trainable parameters (see fig."
vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images,"we reproduce the key results on msd challenge ct datasets, which contain tumor and organ segmentation tasks."
vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images,"table  in this work, we present vox2vec -a self-supervised framework for voxel-wise representation learning in medical imaging."
vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images,we plan to investigate further how the performance of vox2vec scales with the increasing size of the pre-training dataset and the pre-trained architecture size.
vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images,another interesting research direction is exploring the effectiveness of vox2vec with regard to domain adaptation to address the challenges of domain shift between different medical imaging datasets obtained from different sources.
vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images,a particular interest is a lowshot scenario when only a few examples from the target domain are available.
Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"deep learning has brought medical image segmentation into the era of datadriven approaches, and has made significant progress in this field  domain adaptation (da) has been proposed and investigated to combat distribution shift in medical image segmentation."
Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"many researchers proposed using adversarial learning to tackle distribution shift problems  to tackle the aforementioned issues, we propose utilizing prompt learning to take full advantage of domain information."
Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"prompt learning  in this paper, we introduce a domain prompt learning method (prompt-da) to tackle distribution shift in multi-target domains."
Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,we evaluate our proposed method on two multi-domain datasets: 1).
Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,the infant brain mri dataset for cross-age segmentation; 2).
Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,the brats2018 dataset for cross-grade tumor segmentation.
Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,our proposed method was evaluated using two medical image segmentation da datasets.
Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"the first dataset, i.e., cross-age infant segmentation  the first dataset is for infant brain segmentation (white matter, gray matter and cerebrospinal fluid)."
Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"to build the cross-age dataset, we take advantage 10 brain mris of 6-month-old from iseg2019  the 2nd dataset is for brain tumor segmentation (enhancing tumor, peritumoral edema and necrotic and non-enhancing tumor core), which has 285 mri samples (210 hgg and 75 lgg)."
Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,we take hgg as the source domain and lgg as the target domain.
Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"we compared our method with four sota methods: adda  for fair comparison, we have replaced the backbone of these models with the same we used in our approach."
Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,"the quantitative comparison results of cross-age infant brain segmentation is presented in table  when transferring to a single target domain in the brain tumor segmentation task, our proposed da solution improves about 3.09 dice in the target lgg domain."
Gall Bladder Cancer Detection from US Images with only Image Level Labels,none
Structured State Space Models for Multiple Instance Learning in Digital Pathology,"the resulting images are of gigapixel size, rendering their computational analysis challenging."
Structured State Space Models for Multiple Instance Learning in Digital Pathology,"to deal with this issue, multiple instance learning (mil) schemes based on weakly supervised training are used for wsi classification tasks."
Structured State Space Models for Multiple Instance Learning in Digital Pathology,"in such schemes, the wsi is typically divided into a grid of patches, with general purpose features derived from pretrained imagenet  state space models are designed to efficiently model long sequences, such as the sequences of patches that arise in wsi mil."
Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision,"based on longitudinal imaging for a given patient it requires establishing which lesions are corresponding (i.e., same lesion, observed at different timepoints), which lesions have disappeared and which are new compared to prior scanning."
Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision,"this information can be leveraged to assess treatment response, e.g., by analyzing the evolution of size and morphology for a given tumor  in practice, the development of automatic and reliable lesion tracking solutions is hindered by the complexity of the data (over different modalities), the absence of large, annotated datasets, and the difficulties associated with lesion identification (i.e., varying sizes, poses, shapes, and sparsely distributed locations)."
Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision,"in this work, we present a multi-scale self-supervised learning solution for lesion tracking in longitudinal studies using the capabilities of contrastive learning  our proposed method brings two elements of novelty from a technical point of view: (1) the multi-scale approach for the anatomical embedding learning and (2) a positive sampling approach that incorporates anatomically significant landmarks across different subjects."
Geometry-Invariant Abnormality Detection,none
Interpretable Medical Image Classification Using Prototype Learning and Privileged Information,none
ArSDM: Colonoscopy Images Synthesis with Adaptive Refinement Semantic Diffusion Models,none
Synthetic Augmentation with Large-Scale Unconditional Pre-training,"it is worth noting that the labels for these samples have been kept, which allows the fine-tuning process to be guided by labeled data, leading to better predictions on the specific task or domain being trained."
Synthetic Augmentation with Large-Scale Unconditional Pre-training,"by ensuring that the fine-tuning process is representative of the entire dataset through even sampling from each tissue type, we can eliminate bias towards any particular tissue type."
Synthetic Augmentation with Large-Scale Unconditional Pre-training,we evaluate the fine-tuned model on the official test set.
Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation,a must-have ingredient for training a deep neural network (dnn) is a large number of labelled data that is not always available in real-world applications.
Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation,this challenge of data annotation becomes even worse for medical image segmentation tasks that require pixel-level annotation by experts.
Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation,data augmentation (da) is a recognized approach to tackle this challenge.
Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation,"in other words, the deformation-based transformations are learned globally for the image."
Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation,this assumption is restrictive and associated with several challenges.
Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation,"first, the learning of a global image-level transformation requires image alignment that may be non-trivial in many scenarios, such as the alignment of tumours that can appear at different locations of an image, or alignment of images from different modalities."
Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation,"the learning of transformations itself is also complicated by the presence of other objects in the image and is best suited when the object of interest is always in the same (and often centre) location in all the images, i.e., images are globally aligned a priori  intuitively, object-centric transformations and augmentations have the potential to overcome the challenges associated with global image-level transformations."
Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation,"recently, an object-centric augmentation method termed as tumorcp  similarly, other existing works on object-level augmentation of lesions have mostly focused on position, orientation, and random transformations of the lesion on different backgrounds  in this paper, we present a novel approach for learning and transferring object-centric deformations for da in medical image segmentation tasks."
Centroid-Aware Feature Recalibration for Cancer Grading in Pathology Images,none
Explaining Massive-Training Artificial Neural Networks in Medical Image Analysis Task Through Visualizing Functions Within the Models,"figure  in this study, we proposed a novel xai approach to explain the functions and behavior of an mtann model for semantic segmentation of liver tumors in ct."
Explaining Massive-Training Artificial Neural Networks in Medical Image Analysis Task Through Visualizing Functions Within the Models,"our structure optimization algorithm refined the structure and made every hidden unit in the model have a clear, meaningful function by removing redundant hidden units and ""condensing"" the functions into fewer hidden units, which solved the issue of unstable xai results with conventional xai methods."
Explaining Massive-Training Artificial Neural Networks in Medical Image Analysis Task Through Visualizing Functions Within the Models,the unsupervised hierarchical clustering algorithm in our xai approach grouped the hidden units with a similar function into one group so as to explain their functions by group.
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,liver cancer is one of the most deadly cancers and has the second highest fatality rate  a single-phase lesion annotation means the annotation of both lesion position and its class.
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"in hospitals, collected multi-phase cts are normally grouped by patients rather than lesions, which makes single-phase lesion annotation insufficient for feature fusion learning."
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"however, the number of lesions inside a single patient can vary from one to dozens and they can be of different types in realistic cases."
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"we use additional cross phase tokens at the last stage to complete a multi-phase fusion, which can focus on cross-phase communication and improve the fusion effectiveness as compared with conventional modes."
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"while most multi-phase liver lesion classification studies use datasets with no more than three phases (without dl phase for its difficulty of collection) or no more than six lesion classes, we validate the whole framework on an in-house dataset with four phases of abdominal ct and seven classes of liver lesions."
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"considering the disproportion of axial lesion slice number and the relatively small scale of the dataset, we adopt a 2-d network in classification part instead of 3-d in pre-processing part and achieve a 90.9% accuracy."
Adaptive Region Selection for Active Learning in Whole Slide Image Semantic Segmentation,"to validate our segmentation framework, we first train on the fully-annotated data (average performance of five repetitions reported)."
Adaptive Region Selection for Active Learning in Whole Slide Image Semantic Segmentation,"with a patch extraction stride s = 256 pixels, our framework yields an froc score of 0.760 that is equivalent to the challenge top 2, and an miou (tumor) of 0.749, which is higher than the most comparable method in "
Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation,none
Continual Learning for Abdominal Multi-organ and Tumor Segmentation,"humans inherently learn in an incremental manner, acquiring new concepts over time without forgetting previous ones."
Continual Learning for Abdominal Multi-organ and Tumor Segmentation,"in contrast, deep learning models suffer from catastrophic forgetting  the medical domain faces a similar problem: the ability to dynamically extend a model to new classes is critical for multiple organ and tumor segmentation, wherein the key obstacle lies in mitigating 'forgetting.' a typical strategy involves retaining some previous data."
Continual Learning for Abdominal Multi-organ and Tumor Segmentation,"for instance, liu et al."
Continual Learning for Abdominal Multi-organ and Tumor Segmentation,"therefore, we identify two main open questions that must be addressed when designing a multi-organ and tumor segmentation framework."
Continual Learning for Abdominal Multi-organ and Tumor Segmentation,q1: can we relieve the forgetting problem without needing previous data and annotations?
Continual Learning for Abdominal Multi-organ and Tumor Segmentation,q2: can we design a new model architecture that allows us to share more parameters among different continual learning steps?
Continual Learning for Abdominal Multi-organ and Tumor Segmentation,"to tackle the above questions, in this paper, we propose a novel continual multi-organ and tumor segmentation method that overcomes the forgetting problem with little memory and computation overhead."
Continual Learning for Abdominal Multi-organ and Tumor Segmentation,"first, inspired by knowledge distillation methods in continual learning  we focus on organ/tumor segmentation because it is one of the most critical tasks in medical imaging  segment liver tumors in the lits dataset."
Efficient Subclass Segmentation in Medical Images,problem definition.
Efficient Subclass Segmentation in Medical Images,"we start by considering a set of r coarse classes, denoted by y c = {y 1 , ..., y r }, such as background and brain tumor, and a set of n training images, annotated with y c , denoted by d c = {(x l , y l )|y l i ∈ y c } n l=1 ."
Efficient Subclass Segmentation in Medical Images,"intuitively, given sufficient superclass labels in supervised learning, the superclassification head tends to reduce feature distance among samples within the same superclass, which conflicts with the goal of increasing the distance between subclasses within the same superclass."
Efficient Subclass Segmentation in Medical Images,"to alleviate this issue, we aim to enhance the internal diversity of the distribution within the same superclass while preserving the discriminative features among superclasses."
Efficient Subclass Segmentation in Medical Images,"to achieve this, we propose separate normalization(sn) to separately process feature maps belonging to hierarchical foreground and background divided by superclass labels."
Efficient Subclass Segmentation in Medical Images,"this segmentation result is supervised by the superposition of the pseudo label map z pse and subclass labels z, with weighting factor α: the intuition behind this framework is to simultaneously leverage the information from both unlabeled and labeled data by incorporating a more robust supervision from transform-invariant pseudo labels."
Efficient Subclass Segmentation in Medical Images,while mixing up only the semantic foreground provides a way of exchanging knowledge between similar foreground objects while lifting the confirmation bias in pseudo labeling 
Towards AI-Driven Radiology Education: A Self-supervised Segmentation-Based Framework for High-Precision Medical Image Editing,trainee physicians require several years of experience with a diverse range of clinical cases to develop sufficient skills and expertise.
Towards AI-Driven Radiology Education: A Self-supervised Segmentation-Based Framework for High-Precision Medical Image Editing,"however, designing educational materials solely based on real-world data poses several challenges."
Towards AI-Driven Radiology Education: A Self-supervised Segmentation-Based Framework for High-Precision Medical Image Editing,"for example, although small but significant disease characteristics (e.g., depth of cancer invasion) can sometimes alter diagnosis and treatment, collecting pairs with and without these characteristics is cumbersome."
Towards AI-Driven Radiology Education: A Self-supervised Segmentation-Based Framework for High-Precision Medical Image Editing,"another major challenge is longitudinal tracking of pathological progression over time (e.g., from the early stage of cancer to the advanced stage), which is difficult to understand because medical images are often snapshots."
Towards AI-Driven Radiology Education: A Self-supervised Segmentation-Based Framework for High-Precision Medical Image Editing,privacy is also a concern since images of educational materials are widely distributed.
Towards AI-Driven Radiology Education: A Self-supervised Segmentation-Based Framework for High-Precision Medical Image Editing,"our medical image editing method can be applied to medical education, which has been overlooked as an application of ai."
Towards AI-Driven Radiology Education: A Self-supervised Segmentation-Based Framework for High-Precision Medical Image Editing,"future challenges include improving scalability with fewer manual operations, validating segmentation maps from a more objective perspective, and comparing our proposed algorithm with existing methods, such as those based on superpixels  data use declaration and acknowledgment: the pelvic mri and chest ct datasets were collected from the national cancer center hospital."
Towards AI-Driven Radiology Education: A Self-supervised Segmentation-Based Framework for High-Precision Medical Image Editing,"the study, data use, and data protection procedures were approved by the ethics committee of the national cancer center, tokyo, japan (protocol number 2016-496)."
Medical Image Computing and Computer Assisted Intervention – MICCAI 2023,"multi-modal learning has become a popular research area in computer vision and medical image analysis, with modalities spanning across various media types, including texts, audio, images, videos and multiple sensor data."
Medical Image Computing and Computer Assisted Intervention – MICCAI 2023,"this approach has been utilised in robot control  the missing modality issue is a significant challenge in the multi-modal domain, and it has motivated the community to develop approaches that attempt to address this problem."
Medical Image Computing and Computer Assisted Intervention – MICCAI 2023,havaei et al.
Medical Image Computing and Computer Assisted Intervention – MICCAI 2023,"aiming at this issue, we propose the non-dedicated training model -we propose the learnable cross-modal knowledge distillation (lckd) model to address missing modality problem in multi-modal learning."
Medical Image Computing and Computer Assisted Intervention – MICCAI 2023,"it is a simple yet effective model designed from the viewpoint of distilling crossmodal knowledge to maximise the performance for all tasks; -the lckd approach is designed to automatically identify the important modalities per task, which helps the cross-modal knowledge distillation process."
FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation,training data.
FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation,"the real-world dataset used in experiments is provided by the fets challenge organizer, which is the training set of the whole dataset about brain tumor segmentation."
FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation,"in order to evaluate the performance of fedgrav, we partition the dataset composed of 341 data samples  experiment results on the cifar-10."
FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation,it can adaptively adjust the aggregation weights and explore the internal correlations of local models more effectively.
FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation,"we evaluated our method on cifar-10 and real-world miccai federated tumor segmentation challenge (fets) datasets, and the superior results demonstrated the effectiveness and robustness of our fedgrav."
Faithful Synthesis of Low-Dose Contrast-Enhanced Brain MRI Scans Using Noise-Preserving Conditional GANs,none
A Spatial-Temporal Deformable Attention Based Framework for Breast Lesion Detection in Videos,"ultrasound imaging is a very effective technique for breast lesion diagnosis, which has high sensitivity."
A Spatial-Temporal Deformable Attention Based Framework for Breast Lesion Detection in Videos,"automatically detecting breast lesions is a challenging problem with a potential to aid in improving the efficiency of radiologists in ultrasound-based breast cancer diagnosis  most existing breast lesion detection methods can be categorized into imagebased  to address the aforementioned issues, we propose a spatial-temporal deformable attention based network, named stnet, for detecting the breast lesions in ultrasound videos."
A Spatial-Temporal Deformable Attention Based Framework for Breast Lesion Detection in Videos,"within our stnet, we introduce a spatial-temporal deformable attention module to fuse multi-scale spatial-temporal information among different frames, and further integrate it into each layer of the encoder and decoder."
DeDA: Deep Directed Accumulator,none
OpenAL: An Efficient Deep Active Learning Framework for Open-Set Pathology Image Classification,"deep learning techniques have achieved unprecedented success in the field of medical image classification, but this is largely due to large amount of annotated data  active learning (al) is an effective approach to address this issue from a data selection perspective, which selects the most informative samples from an unlabeled sample pool for experts to label and improves the performance of the trained model with reduced labeling cost  recently, ning et al."
OpenAL: An Efficient Deep Active Learning Framework for Open-Set Pathology Image Classification,"in this paper, we propose a novel al framework under an open-set scenario, and denote it as openal, which cannot only query as many target class samples as possible but also query the most informative samples from the target classes."
SFusion: Self-attention Based N-to-One Multimodal Fusion Block,sfusion without ce denotes that feature representations are directly fed into the ma module (fig.
SFusion: Self-attention Based N-to-One Multimodal Fusion Block,"in this paper, we propose a self-attention based n-to-one fusion block sfusion to tackle the problem of multimodal missing modalities fusion."
SFusion: Self-attention Based N-to-One Multimodal Fusion Block,"as a data-dependent fusion strategy, sfusion can automatically learn the latent correlations between different modalities and builds a shared feature representation."
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"serious skin diseases such as melanoma can be life-threatening, making early detection and treatment essential  accuracy and robustness requirements in applications, which is hard to suffice due to the long-tailed occurrence of diseases in the real-world."
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,long-tailed problem is usually caused by differences in incidence rate and difficulties in data collection.
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,"some diseases are common while others are rare, making it difficult to collect balanced data  to tackle the challenge of learning unbiased classifiers with imbalanced data, many previous works focus on three main ideas, including re-sampling data  recently, contrastive learning (cl) methods pose great potential for representation learning when trained on imbalanced data  to address the above issues, we propose a class-enhancement contrastive learning (ecl) method for skin lesion classification, differences between scl and ecl are illustrated in fig."
SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation,datasets and pre-trained model.
SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation,"we conducted experiments on automating liver tumor segmentation in contrast-enhanced ct scans, a crucial task in liver cancer diagnosis and surgical planning  collecting large-scale data from our hospital and training a new model will be expensive."
SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation,"therefore, we can use the model trained from them as a starting point and use slpt to adapt it to our hospital with minimum cost."
SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation,"we collected a dataset from our in-house hospital comprising 941 ct scans with eight categories: hepatocellular carcinoma, cholangioma, metastasis, hepatoblastoma, hemangioma, focal nodular hyperplasia, cyst, and others."
SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation,it covers both major and rare tumor types.
UniSeg: A Prompt-Driven Universal Segmentation Model as Well as A Strong Representation Learner,recent years have witnessed the remarkable success of deep learning in medical image segmentation.
UniSeg: A Prompt-Driven Universal Segmentation Model as Well as A Strong Representation Learner,"however, although the performance of deep learning models even surpasses the accuracy of human exports on some segmentation tasks, two challenges still persist."
UniSeg: A Prompt-Driven Universal Segmentation Model as Well as A Strong Representation Learner,(1) different segmentation tasks are usually tackled separately by specialized networks (see fig.
UniSeg: A Prompt-Driven Universal Segmentation Model as Well as A Strong Representation Learner,several strategies have been attempted to address both challenges.
UniSeg: A Prompt-Driven Universal Segmentation Model as Well as A Strong Representation Learner,"first, multi-head networks (see fig."
Cross-Modulated Few-Shot Image Generation for Colorectal Tissue Classification,"therefore, developing automatic and accurate histopathological image analysis methods that leverage recent progress in deep learning has received significant attention in recent years."
Cross-Modulated Few-Shot Image Generation for Colorectal Tissue Classification,"in this work, we investigate the problem of diagnosing colorectal cancer, which is one of the most common reason for cancer deaths around the world and particularly in europe and america  existing deep learning-based colorectal tissue classification methods  while generative adversarial networks (gans)  the ability of generative models  our approach: while the aforementioned works explore fs generation in natural images, to the best of our knowledge, we are the first to investigate fs generation in colorectal tissue images."
Cross-Modulated Few-Shot Image Generation for Colorectal Tissue Classification,"in this work, we look into multi-class colorectal tissue analysis problem, with low and high-grade tumors included in the set."
Structure-Preserving Instance Segmentation via Skeleton-Aware Distance Transform,dataset and evaluation metric.
Structure-Preserving Instance Segmentation via Skeleton-Aware Distance Transform,we use the gland segmentation challenge dataset 
DAST: Differentiable Architecture Search with Transformer for 3D Medical Image Segmentation,none
Pre-trained Diffusion Models for Plug-and-Play Medical Image Enhancement,none
Evidence Reconciled Neural Network for Out-of-Distribution Detection in Medical Images,none
Scale-Aware Test-Time Click Adaptation for Pulmonary Nodule and Mass Segmentation,computer aided diagnosis (cad) systems can significantly reduce such heavy workloads.
Scale-Aware Test-Time Click Adaptation for Pulmonary Nodule and Mass Segmentation,the accuracy of the existing nodule detection model reaches 96.1%  several studies have proposed solutions to tackle the large scale span challenges at both the input and feature level.
Scale-Aware Test-Time Click Adaptation for Pulmonary Nodule and Mass Segmentation,"for instance, some approaches adopt multi-scale inputs  recently, some click-based lesion segmentation methods  in this paper, we propose a scale-aware test-time click adaptation (sattca) method, which simply utilizes easily obtainable lesion click (i.e., the center detected nodule) to adjust the parameters of the network normalization layers "
WeakPolyp: You only Look Bounding Box for Polyp Segmentation,"then, this transformed mask is supervised by the bounding box annotation."
WeakPolyp: You only Look Bounding Box for Polyp Segmentation,this indirect supervision avoids the misleading of box-shape bias of annotations.
WeakPolyp: You only Look Bounding Box for Polyp Segmentation,"however, many regions in the predicted mask are lost in the projection and therefore get no supervision."
Shifting More Attention to Breast Lesion Segmentation in Ultrasound Videos,none
FocalUNETR: A Focal Transformer for Boundary-Aware Prostate Segmentation Using CT Images,none
Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,"the results reported before reveal that approaching the problem of segmentation uncertainty prediction via a regression task, where the uncertainty is expressed in terms of landmark location, is globally better than via pixel-based segmentation methods."
Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,"it also shows that our method (n 1 , n 2 and sn 2 ) is better than the commonly-used mc-dropout."
Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,"this is why on very noisy and poorly contrasted data, the univariate or the bivariate model might be preferable to using the asymmetric model."
Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,"while our method works well on the tasks presented, it is worth noting that it may not be applicable to all segmentation problems like tumour segmentation."
Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,"nevertheless, our approach is broad enough to cover many applications, especially related to segmentation that is later used for downstream tasks such as clinical metric estimation."
Anatomical-Aware Point-Voxel Network for Couinaud Segmentation in Liver CT,"since it is defined based on the anatomical structure of live vessels, even no intensity contrast (fig."
Anatomical-Aware Point-Voxel Network for Couinaud Segmentation in Liver CT,"in this paper, to tackle the aforementioned challenges, we propose a pointvoxel fusion framework that represents the liver ct in continuous points to better learn the spatial structure, while performing the convolutions in voxels to obtain the complementary semantic information of the couinaud segments."
Anatomical-Aware Point-Voxel Network for Couinaud Segmentation in Liver CT,"specifically, the liver mask and vessel attention maps are first extracted from the ct images, which allows us to randomly sample points embedded with vessel structure prior in the liver space and voxelize them into a voxel grid."
HENet: Hierarchical Enhancement Network for Pulmonary Vessel Segmentation in Non-contrast CT Images,"segmentation of the pulmonary vessels is the foundation for the clinical diagnosis of pulmonary vascular diseases such as pulmonary embolism (pe), pulmonary hypertension (ph) and lung cancer  in the literature, several conventional methods  to summarize, there exist several challenges for pulmonary vessel segmentation in non-contrast ct images:  to address the above challenges, we propose a h ierarchical e nhancement n etwork (henet) for pulmonary vessel segmentation in non-contrast ct images by enhancing the representation of vessels at both image-and feature-level."
HENet: Hierarchical Enhancement Network for Pulmonary Vessel Segmentation in Non-contrast CT Images,"for the input ct images, we propose an auto contrast enhancement (ace) module to automatically adjust the range of hu values in different areas of ct images."
Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels,none
Anti-adversarial Consistency Regularization for Data Augmentation: Applications to Robust Medical Image Segmentation,none
Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk,none
Learning Reliability of Multi-modality Medical Images for Tumor Segmentation via Evidence-Identified Denoising Diffusion Probabilistic Models,integrating multi-modality medical images for tumor segmentation is crucial for comprehensive diagnosis and surgical planning.
Learning Reliability of Multi-modality Medical Images for Tumor Segmentation via Evidence-Identified Denoising Diffusion Probabilistic Models,"in the clinic, the consistent information and complementary information in multi-modality medical images provide the basis for tumor diagnosis."
Learning Reliability of Multi-modality Medical Images for Tumor Segmentation via Evidence-Identified Denoising Diffusion Probabilistic Models,"for instance, the consistent anatomical structure information offers the location feature for tumor tracking  existing methods for multi-modality medical image integration can be categorized into three groups:  dempster-shafer theory (dst)  in this paper, we propose an evidence-identified ddpm (ei-ddpm) with contextual discounting for tumor segmentation via integrating multi-modality medical images."
Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network,breast cancer is the leading cause of cancer-related fatalities among women.
Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network,"currently, it holds the highest incidence rate of cancer among women in the u.s., and in 2022 it accounted for 31% of all newly diagnosed cancer cases  in the past decade, deep learning-based approaches achieved remarkable advancements in bus tumor classification  vision transformer (vit)  accordingly, numerous prior studies introduced modifications to the original vit network specifically designed for bus image classification  multitask learning leverages shared information across related tasks by jointly training the model."
Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network,it constrains models to learn representations that are relevant to all tasks rather than learning task-specific details.
Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network,"moreover, multitask learning acts as a regularizer by introducing inductive bias and prevents overfitting  in this study, we introduce a hybrid multitask approach, hybrid-mt-estan, which encompasses tumor classification as a primary task and tumor segmentation as a secondary task."
Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network,hybrid-mt-estan combines the advantages of cnns and transformers in a framework incorporating anatomical tissue information in bus images.
Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network,"since in medical image diagnosis achieving high sensitivity places emphasis on the detection of malignant lesions, we employed the focal loss for the classification task to trade off between sensitivity and specificity."
Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network,"because malignant tumors are more challenging to detect due to greater differences in margin, shape, and appearance in bus images, focal loss forces the model to focus more on difficult predictions."
Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network,"specifically, focal loss adds a factor (1 -p i ) γ to the cross-entropy loss where γ is a focusing parameter, resulting in in the formulation, α is a weighting coefficient, n denotes the number of image samples, t i is the target label of the i th training sample, and p i denotes the prediction."
SimPLe: Similarity-Aware Propagation Learning for Weakly-Supervised Breast Cancer Segmentation in DCE-MRI,"breast cancer is the most common cause of cancer-related deaths among women all around the world  to better support the radiologists with breast cancer diagnosis, various segmentation algorithms have been developed  although  in this study, we propose a simple yet effective weakly-supervised strategy, by using extreme points as annotations (see fig."
SimPLe: Similarity-Aware Propagation Learning for Weakly-Supervised Breast Cancer Segmentation in DCE-MRI,dataset.
SimPLe: Similarity-Aware Propagation Learning for Weakly-Supervised Breast Cancer Segmentation in DCE-MRI,"the batch size was 2, consisting of a random foreground patch and a random background patch located via initial segmentation y init ."
SimPLe: Similarity-Aware Propagation Learning for Weakly-Supervised Breast Cancer Segmentation in DCE-MRI,such setting can help alleviate class imbalance issue.
SimPLe: Similarity-Aware Propagation Learning for Weakly-Supervised Breast Cancer Segmentation in DCE-MRI,the patch size was 128 × 128 × 96.
Conditional Diffusion Models for Weakly Supervised Medical Image Segmentation,"in this field, previous wsss works  meanwhile, denoising diffusion models  brain tumor segmentation."
Conditional Diffusion Models for Weakly Supervised Medical Image Segmentation,"brats (brain tumor segmentation challenge)  only classification labels are used during training the diffusion models, and segmentation masks are used for evaluation in the test stage."
Conditional Diffusion Models for Weakly Supervised Medical Image Segmentation,"for both datasets, we repeat the evaluation protocols for four times and report the average metrics and their standard deviation on test set."
DBTrans: A Dual-Branch Vision Transformer for Multi-Modal Brain Tumor Segmentation,"glioma is one of the most common malignant brain tumors with varying degrees of invasiveness  with the rise of deep learning, researchers have begun to study deep learning-based image analysis methods  in recent years, models based on the self-attention mechanism, such as transformer, have received widespread attention due to their excellent performance in natural language processing (nlp)  while transformer-based models have shown effectiveness in capturing long-range dependencies, designing a transformer architecture that performs well on the samm-bts task remains challenging."
DBTrans: A Dual-Branch Vision Transformer for Multi-Modal Brain Tumor Segmentation,"first, modeling relationships between 3d voxel sequences is much more difficult than 2d pixel sequences."
DBTrans: A Dual-Branch Vision Transformer for Multi-Modal Brain Tumor Segmentation,"when applying 2d models, 3d images need to be sliced along one dimension."
DBTrans: A Dual-Branch Vision Transformer for Multi-Modal Brain Tumor Segmentation,datasets.
DBTrans: A Dual-Branch Vision Transformer for Multi-Modal Brain Tumor Segmentation,we use the multimodal brain tumor segmentation challenge (brats 2021  comparative experiments.
DBTrans: A Dual-Branch Vision Transformer for Multi-Modal Brain Tumor Segmentation,"to evaluate the effectiveness of the proposed dbtrans, we compare it with the state-of-the-art brain tumor segmentation methods including six transformer-based networks swin-unet "
M-GenSeg: Domain Adaptation for Target Modality Tumor Segmentation with Annotation-Efficient Supervision,none
Edge-Aware Multi-task Network for Integrating Quantification Segmentation and Uncertainty Prediction of Liver Tumor on Multi-modality Non-contrast MRI,"in this paper, we have proposed an eamtnet for the simultaneous segmentation and multi-index quantification of liver tumors on multi-modality ncmri."
Edge-Aware Multi-task Network for Integrating Quantification Segmentation and Uncertainty Prediction of Liver Tumor on Multi-modality Non-contrast MRI,the new eafa enhances edge awareness by utilizing boundary information as prior knowledge while capturing the long-range dependency of features to improve feature selection and fusion.
Edge-Aware Multi-task Network for Integrating Quantification Segmentation and Uncertainty Prediction of Liver Tumor on Multi-modality Non-contrast MRI,"additionally, multi-task leverages the prediction discrepancy to estimate uncertainty, thereby improving segmentation and quantification performance."
RCS-YOLO: A Fast and High-Accuracy Object Detector for Brain Tumor Detection,none
Category-Level Regularized Unlabeled-to-Labeled Learning for Semi-supervised Prostate Segmentation with Multi-site Unlabeled Data,none
A Sheaf Theoretic Perspective for Robust Prostate Segmentation,none
MedNeXt: Transformer-Driven Scaling of ConvNets for Medical Image Segmentation,"transformers  the convnext architecture marries the scalability and long-range spatial representation learning capabilities of vision  in this work, we maximize the potential of a convnext design while uniquely addressing challenges of limited datasets in medical image segmentation."
MedNeXt: Transformer-Driven Scaling of ConvNets for Medical Image Segmentation,"we present the first fully convnext 3d segmentation network, mednext, which is a scalable encoder-decoder network, and make the following contributions: mednext achieves state-of-the-art performance against baselines consisting of transformer-based, convolutional and large kernel networks."
Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,"however, as illustrated in  beyond tumour delineation, another important use of functional images, such as pet images is their use for designing imrt dose painting (dp)."
Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,"in particular, dose painting uses functional images to paint optimised dose prescriptions based on the spatially varying radiation sensitivities of tumours, thus enhancing the efficacy of tumour control  to address both tumour delineation and corresponding dose painting challenges, we propose to combine the expressiveness of deep cnns with the versa-tility of kspc in a unified framework, which we call kspc-net."
Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,"in the proposed kspc-net, a cnn is employed to learn directly from the data to produce the pixel-wise bandwidth feature map and initial segmentation map, which are used to define the tuning parameters in the kspc module."
Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,our framework is completely automatic and differentiable.
Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,"more specifically, we use the classic unet  the dataset is from the hecktor challenge in miccai 2021 (head and neck tumor segmentation challenge)."
Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,"the hecktor training dataset consists of 224 patients diagnosed with oropharyngeal cancer  in this paper, we present a novel network, kspc-net, for the segmentation in 2d pet images, which integrates kspc into the unet architecture in an end-toend differential manner."
Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,"the kspc-net utilizes the benefits of kspc to deliver both contour-based and grid-based segmentation outcomes, leading to improved precision in the segmentation of contours."
Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,promising performance was achieved by our proposed kspc-net compared to the state-of-the-art approaches on the miccai 2021 challenge dataset (hecktor).
Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,it is worth mentioning that the architecture of our kspc-net is not limited to head & neck cancer type and can be broadcast to different cancer types.
A2FSeg: Adaptive Multi-modal Fusion Network for Medical Image Segmentation,"due to the possibility of missing modalities, we will have different numbers of feature maps for fusion."
A2FSeg: Adaptive Multi-modal Fusion Network for Medical Image Segmentation,"to address this issue, we normalize the different attention weights by using a softmax function: that is, we only consider feature maps from those available modalities but normalize their contribution to the final fusion result, so that, the fused one has a consistent value range, no matter how many modalities are missing."
A2FSeg: Adaptive Multi-modal Fusion Network for Medical Image Segmentation,"then, we perform voxel-wise multiplication of the attention weight with the corresponding modal feature maps."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"despite the promising results of existing pre-operative survival prediction methods, they often overlook clinical knowledge that could aid in improving the prediction accuracy."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"notably, tumor types have been found to be strongly correlated with the prognosis of diffuse glioma  our method is evaluated using pre-operative multimodal mr brain images of 1726 diffuse glioma patients collected from cooperation hospitals and a public dataset brats2019  diffuse glioma can be classified into three histological types: the oligodendroglioma, the astrocytoma, and the glioblastoma  the tumor subtyping network is trained independently before being integrated into the backbone."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"to solve the inherent issue of imbalanced tumor type in the training data collected in clinic, a novel ordinal manifold mixup based feature augmentation is applied in the training of the tumor subtyping network."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"as f type i has strong correlation with prognosis, the performance of the backbone can be improved."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"in addition, information of patient age and tumor position is also used."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"to encode the tumor position, the brain is divided into 3 × 3 × 3 blocks, and the tumor position is represented by 27 binary values (0 or 1) with each value for one block."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"in the in-house dataset, the proportions of the three tumor types are 20.9% (oligodendroglioma), 28.7% (astrocytoma), and 50.4% (glioblastoma), which is consistent with the statistical report in  in the original manifold mixup  where y k i and y k j stand for the labels of the k-th tumor type of the i-th and j-th patients, respectively, and λ ∈ [0, 1] is a weighting factor."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"for binary classification, the original manifold mixup can effectively enhance the network performance, however, for the classification of more than two classes, e.g., tumor types, there exists a big issue."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,as shown in fig.
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"in our experiment, both in-house and public datasets are used to evaluate our method."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"specifically, the in-house dataset collected in cooperation hospitals contains pre-operative multimodal mr images, including t1, t1 contrast enhanced (t1c), t2, and flair, of 1726 patients (age 49.7 ± 13.1) with confirmed diffuse glioma types."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"the patient number of each tumor type is 361 (oligodendroglioma), 495 (astrocytoma), and 870 (glioblastoma), respectively."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"in the 1726 patients, 743 have the corresponding overall survival time (dead, non-censored), and 983 patients have the last visiting time (alive, censored)."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"besides the inhouse dataset, a public dataset brats2019, including pre-operative multimodal mr images of 210 non-censored patients (age 61.4 ± 12.2), is adopted as the external independent testing dataset."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"all images of the in-house and brats2019 datasets go through the same pre-processing stage, including image normalization and affine transformation to mni152  besides our method, four state-of-the-art methods, including random forest based method (rf)  where d = {x 1 , ..., x n } is the dataset containing all patients, t i and t j are ground truth of survival times of the i-th and j-th patients, r i and r j are the days predicted by rf, mcsp, and pgsp or risks predicted by the deep cox proportional hazard models (i.e., deepconvsurv and our method), 1 x<y = 1 if x < y, else 0, and δ i = 0 or 1 when the i-th patient is censored or non-censored."
Medical Boundary Diffusion Model for Skin Lesion Segmentation,none
H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation,"with the emergence of multimodal datasets (e.g., brats  in addition to the progress on the fusion of multimodal features, improving the model representation ability is also an effective way to boost segmentation performance."
H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation,"in the past few years, transformer structure  although remarkable performance has been accomplished with these efforts, there still exist several challenges to be resolved."
H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation,most existing methods are either limited to specific modality numbers due to the design of asymmetric connections or suffer from large computational complexity because of the huge amount of model parameters.
H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation,", where i ∈ [0, 1, 2, 3], and c = 2 (tumor and background) represents the number of segmentation classes."
H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation,"to mitigate the pixel imbalance problem, we use a combined loss of focal loss  where n refers to the total number of pixels, p t and q t denote the predicted probability and ground truth of the t-th pixel, respectively, and r = 2 is the modulation factor."
H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation,"thus, ds loss can be calculated as follows: where g i represents the ground truth after resizing and has the same size as o i ."
H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation,"in this paper, we proposed an efficient hybrid model (h-denseformer) that combines transformer and cnn for multimodal tumor segmentation."
H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation,"concretely, a multi-path parallel embedding module and a densely connected transformer block were developed and integrated to balance accuracy and computational complexity."
H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation,extensive experimental results demonstrated the effectiveness and superiority of our proposed h-denseformer.
TransNuSeg: A Lightweight Multi-task Transformer for Nuclei Segmentation,none
QCResUNet: Joint Subject-Level and Voxel-Level Prediction of Segmentation Quality,"furthermore, most of the existing methods do not localize segmentation errors, which is meaningful for both auditing purposes and guiding manual refinement."
QCResUNet: Joint Subject-Level and Voxel-Level Prediction of Segmentation Quality,"to address these challenges, we propose a novel framework for joint subject-level and voxel-level prediction of segmentation quality from multimodal mri."
QCResUNet: Joint Subject-Level and Voxel-Level Prediction of Segmentation Quality,the contribution of this work is four-fold.
QCResUNet: Joint Subject-Level and Voxel-Level Prediction of Segmentation Quality,the dice loss and cross-entropy loss were averaged across the number of pixels i in a batch.
QCResUNet: Joint Subject-Level and Voxel-Level Prediction of Segmentation Quality,"the two parts are combined using a weight parameter λ to balance the different loss components: 3 experiments for this study, pre-operative multimodal mri scans of varying grades of glioma were obtained from the 2021 brain tumor segmentation (brats) challenge  in this work, we proposed a novel cnn architecture called qcresunet to perform automatic brain tumor segmentation qc in multimodal mri scans."
QCResUNet: Joint Subject-Level and Voxel-Level Prediction of Segmentation Quality,qcre-sunet simultaneously provides subject-level segmentation-quality prediction and localizes segmentation failures at the voxel level.
EGE-UNet: An Efficient Group Enhanced UNet for Skin Lesion Segmentation,malignant melanoma is one of the most rapidly growing cancers in the world.
EGE-UNet: An Efficient Group Enhanced UNet for Skin Lesion Segmentation,"as estimated by the american cancer society, there were approximately 100,350 new cases and over 6,500 deaths in 2020  transunet  prior works have enhanced performance by introducing intricate modules, but neglected the constraint of computational resources in real medical settings."
EGE-UNet: An Efficient Group Enhanced UNet for Skin Lesion Segmentation,"hence, there is an urgent need to design a low-parameter and low-computational load model for segmentation tasks in mobile healthcare."
Diffusion Kinetic Model for Breast Cancer Segmentation in Incomplete DCE-MRI,"for a second step, we train the sm that integrates the previously learned latent kinetic code to provide tumor hemodynamic information for voxel-level prediction."
Diffusion Kinetic Model for Breast Cancer Segmentation in Incomplete DCE-MRI,"considering the varying sizes, shapes and appearances of tumors that results from intratumor heterogeneity and results in difficulties of accurate cancer annotation, we design the segmentation loss as follows: where l ssim is used to evaluate tumor structural characteristics, s and g represents segmentation map and ground truth, respectively; μ s is the mean of s and μ g is the mean of g; ϕ s represents the variance of s and ϕ g represents the variance of g; c 1 and c 2 denote the constant to hold training stable  where k 1 is set as 0.01, k 2 is set as 0.03 and l is set as the range of voxel values."
Diffusion Kinetic Model for Breast Cancer Segmentation in Incomplete DCE-MRI,"dataset: to demonstrate the effectiveness of our proposed dkm, we evaluate our method on 4d dce-mri breast cancer segmentation using the breast-mri-nact-pilot dataset  we propose a diffusion kinetic model by exploiting hemodynamic priors in dce-mri to effectively generate high-quality segmentation results only requiring precontrast images."
Morphology-Inspired Unsupervised Gland Segmentation via Selective Semantic Grouping,"accurate gland segmentation from whole slide images (wsis) plays a crucial role in the diagnosis and prognosis of cancer, as the morphological features of glands can provide valuable information regarding tumor aggressiveness  to reduce the annotation cost, developing annotation-efficient methods for semantic-level gland segmentation has attracted much attention  one potential solution is to adopt unsupervised semantic segmentation (uss) methods which have been successfully applied to medical image research and natural image research."
Morphology-Inspired Unsupervised Gland Segmentation via Selective Semantic Grouping,"on the one hand, existing uss methods have shown promising results in various medical modalities, e.g., magnetic resonance images  x-ray images  to tackle the above challenges, our solution is to incorporate an empirical cue about gland morphology as additional knowledge to guide gland segmentation."
Morphology-Inspired Unsupervised Gland Segmentation via Selective Semantic Grouping,the cue can be described as: each gland is comprised of a border region with high gray levels that surrounds the interior epithelial tissues.
Morphology-Inspired Unsupervised Gland Segmentation via Selective Semantic Grouping,"ultimately, our method produces well-delineated and complete predictions; see fig."
Morphology-Inspired Unsupervised Gland Segmentation via Selective Semantic Grouping,"our contributions are as follows: (1) we identify the major challenge encountered by prior unsupervised semantic segmentation (uss) methods when dealing with gland images, and propose a novel mssg for unsupervised gland segmentation."
Morphology-Inspired Unsupervised Gland Segmentation via Selective Semantic Grouping,
EoFormer: Edge-Oriented Transformer for Brain Tumor Segmentation,our method comprises the efficient hybrid encoder and the edgeoriented transformer decoder.
EoFormer: Edge-Oriented Transformer for Brain Tumor Segmentation,the encoder effectively extracts features from images by striking a balance between cnn and transformer architectures.
EoFormer: Edge-Oriented Transformer for Brain Tumor Segmentation,the decoder integrates the sobel and laplacian edge detection filters into our edgeoriented modules that enhance the extraction capability of edge and texture information.
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"specifically, a typical lyme lesion exhibits a bull's eye pattern with one central redness and one outer circle, which is different from darkness lesion in cancer-related skin disease like melanoma."
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"furthermore, clinical data collected for training is usually imbalanced in some properties, e.g., more samples with light skins compared with dark skins."
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"therefore, existing skin disease segmentation  in this paper, we present the first lyme disease dataset that contains labeled segmentation and skin tones."
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"dark), and lesionconducted under clinician supervision and institutional review boards (irb) approval."
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"our dataset with manual labels is available at this url  secondly, we design a simple yet novel data preprocessing and alternation method, called edgemixup, to improve lyme disease segmentation and diagnosis fairness on samples with different skin-tones."
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,the key insight is to alter a skin image with a linear combination of the source image and a detected lesion boundary so that the lesion structure is preserved while minimizing skin tone information.
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,such an improvement is an iterative process that gradually improves lesion edge detection and segmentation fairness until convergence.
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"then, the detected, converged edge in the first step also helps classification of lyme diseases via mixup with improved fairness."
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,our source code is available at this url  we evaluate edgemixup for skin disease segmentation and classification tasks.
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,our results show that edgemixup is able to increase segmentation utility and improve fairness.
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"we also show that the improved segmentation further improves classification fairness as well as joint fairness-utility metrics compared to existing debiasing methods, e.g., ad "
Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"head and neck (h&n) cancer refers to malignant tumors in h&n regions, which is among the most common cancers worldwide  traditional survival prediction methods are usually based on radiomics  firstly, existing deep survival models are underdeveloped in utilizing complementary multi-modality information, such as the metabolic and anatomical information in pet and ct images."
Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"for survival prediction in h&n cancer, existing methods usually use single imaging modality  secondly, although deep survival models have advantages in performing end-to-end survival prediction without requiring tumor masks, this also incurs difficulties in extracting region-specific information, such as the prognostic information in primary tumor (pt) and metastatic lymph node (mln) regions."
Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"to address this limitation, recent deep survival models adopted multi-task learning for joint tumor segmentation and survival prediction, to implicitly guide the model to extract features related to tumor regions  in this study, we design an x-shape merging-diverging hybrid transformer network (named xsurv, fig."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,histological features allow visual readout of cancer biology as they represent the overall impact of genetic changes on cells  the great rise of deep learning in the past decade and our ability to digitize histopathology slides using high-throughput slide scanners have fueled interests in the applications of deep learning in histopathology image analysis.
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"the majority of the efforts, so far, focus on the deployment of these models for diagnosis and classification  in the machine learning domain, patient prognostication can be treated as a weakly supervised problem, which a model would predict the outcome (e.g., time to cancer recurrence) based on the histopathology images."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"their majority have utilized multiple instance learning (mil)  to address this issue, graph neural networks (gnn) have recently received more attention in histology."
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,this study is not human subjects research because it was a secondary analysis of results from biological specimens that were not collected for the purpose of the current study and for which the samples were fully anonymized.
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,this work was supported by msk cancer center support grant/core grant (p30 ca008748) and by james and esther king biomedical research grant (7jk02) and moffitt merit society award to c.
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,h.
Detection of Basal Cell Carcinoma in Whole Slide Images,"to improve the efficiency and accuracy of the search, we developed a new framework named sc-net, which focuses on identifying highly valuable architectures."
Detection of Basal Cell Carcinoma in Whole Slide Images,"we observed that conventional nas methods often overlook fairness ranking during the search, hindering the search for optimal solutions."
Detection of Basal Cell Carcinoma in Whole Slide Images,our sc-net framework addresses this by ensuring fair training and precise ranking.
Detection of Basal Cell Carcinoma in Whole Slide Images,comparison with related methods.
Detection of Basal Cell Carcinoma in Whole Slide Images,"to ensure a fair comparison on our dataset, we selected several papers in the field of pathological image analysis, such as  evaluation metrics."
Detection of Basal Cell Carcinoma in Whole Slide Images,"our model was evaluated on: as shown in table  in this paper, we introduce sc-net, a novel nas framework for skin cancer detection in pathology images."
Detection of Basal Cell Carcinoma in Whole Slide Images,"by formulating sc-net as a balanced supernet, we ensure fair ranking and treatment of all potential architectures."
Detection of Basal Cell Carcinoma in Whole Slide Images,"with scnet and evolutionary search, we obtained optimal architectures, achieving 96.2% top-1 and 96.5% accuracy on a skin cancer dataset, improvements of 4.8% and 4.7% over baselines."
IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis,none
Multi-scale Prototypical Transformer for Whole Slide Image Classification,histopathological images are regarded as the 'gold standard' in the diagnosis of cancers.
Multi-scale Prototypical Transformer for Whole Slide Image Classification,"with the advent of the whole slide image (wsi) scanner, deep learning has gained its reputation in the field of computational pathology  to address this issue, multiple instance learning (mil) has been successfully applied to the wsi classification task as a weakly supervised learning problem  recently, prototypical learning is applied in wsi analysis to identify representative instances in the bag  on the other hand, when pathologists analysis the wsis, they always observe the tissues at various resolutions  in this work, we propose a multi-scale prototypical transformer (mspt) for wsi classification."
Multi-scale Prototypical Transformer for Whole Slide Image Classification,the mspt includes two key components: a prototypical transformer (pt) and a multi-scale feature fusion module (mffm).
Thyroid Nodule Diagnosis in Dynamic Contrast-Enhanced Ultrasound via Microvessel Infiltration Awareness,none
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"specimens were analyzed with a multiplexed quantitative immunofluorescence (qif) panel using the method described in  the two top predictive triangil features were found to be the number of edges between stroma and cd4+ cells, and the number of edges between stroma and tumor cells with more interactions between stromal cells and both cd4+ and tumor cells being associated with response to io."
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"this finding is concordant with other studies  result: figure  we presented a new approach, triangular analysis of geographical interplay of lymphocytes (triangil), to quantitatively chartacterize the spatial arrangement and relative geographical interplay of multiple cell families across pathological images."
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"compared to previous spatial graph-based methods, triangil quantifies the spatial interplay between multiple cell families, providing a more comprehensive portrait of the tumor microenvironment."
NASDM: Nuclei-Aware Semantic Histopathology Image Generation Using Diffusion Models,none
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"for promising curative effect, a high-quality radiotherapy plan is demanded to distribute sufficient dose of radiation to the planning target volume (ptv) while minimizing the radiation hazard to organs at risk (oars)."
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"to achieve this, radiotherapy plans need to be manually adjusted by the dosimetrists in a trial-and-error manner, which is extremely labor-intensive and time-consuming  recently, the blossom of deep learning (dl) has promoted the automatic medical image processing tasks  although the above methods have achieved good performance in predicting dose distribution, they suffer from the over-smoothing problem."
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"these dl-based dose prediction methods always apply the l 1 or l 2 loss to guide the model optimization which calculates a posterior mean of the joint distribution between the predictions and the ground truth  in this paper, we investigate the feasibility of applying a diffusion model to the dose prediction task and propose a diffusion-based model, called diffdp, to automatically predict the clinically acceptable dose distribution for rectum cancer patients."
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"overall, the contributions of this paper can be concluded as follows:  dataset and evaluations."
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,we measure the performance of our model on an in-house rectum cancer dataset which contains 130 patients who underwent volumetric modulated arc therapy (vmat) treatment at west china hospital.
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"concretely, for every patient, the ct images, ptv segmentation, oars segmentations, and the clinically planned dose distribution are included."
Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning,"in the past few years, the development of histopathological whole slide image (wsi) analysis methods has dramatically contributed to the intelligent cancer diagnosis  generally, multiple instance learning (mil) is one of the most popular solutions for wsi analysis  however, hipt is a hierarchical learning framework based on a greedy training strategy."
Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning,the bias and error generated in each level of the representation model will accumulate in the final decision model.
Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning,"moreover, the vit  in this paper, we propose a novel whole slide image representation learning framework named position-aware masked autoencoder (pama), which achieves slide-level representation learning by reconstructing the local representations of the wsi in the patch feature space."
Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,"cervical cancer is a common and severe disease that affects millions of women globally, particularly in developing countries  several computer-aided cervical cancer screening methods have been proposed for whole slide images (wsis) in the literature."
Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,"most of them are detectionbased methods, which typically contain a detection model as well as some postprocessing modules in their frameworks."
Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,cervical cancer cell detection datasets involve labeling individual and small bounding boxes in a large number of cells.
Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,"it often requires multiple experienced pathologists to annotate  to address the aforementioned issues, we propose a detection-free pipeline in this paper, which does not rely on any detection model."
Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,"instead, our pipeline requires only sample-level diagnosis labels, which are naturally available in clinical scenarios and thus get rid of additional image labeling."
Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,dataset and experimental setup.
Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,"in this study, we have collected 5384 cervical cytopathological wsi by 20x lens, each with 20000 × 20000 pixels, from our collaborating hospitals."
Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,"among them, there 2853 negative samples, and 2531 positive samples (962 ascus, and 1569 high-level positive samples)."
Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,"in this section, we experiment to demonstrate the effectiveness of all the proposed parts in our pipeline."
Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,"we divide all 5384 samples into five independent parts for five-fold cross-validation, and the results are shown in table  cervical cancer is a common and severe disease that affects millions of women globally, particularly in developing countries  several computer-aided cervical cancer screening methods have been proposed for whole slide images (wsis) in the literature."
Instance-Aware Diffusion Model for Gland Segmentation in Colon Histology Images,"this method effectively integrates the abundant information from the original image, thereby enhancing the distinction between the objects and the surrounding background."
Instance-Aware Diffusion Model for Gland Segmentation in Colon Histology Images,"our proposed method was trained and tested on the 2015 mic-cai gland segmentation (glas) challenge dataset  colorectal cancer is a prevalent form of cancer characterized by colorectal adenocarcinoma, which develops in the colon or rectum's inner lining and exhibits glandular structures  recently, diffusion model  in this paper, we propose a new method for gland instance segmentation based on the diffusion model."
Instance-Aware Diffusion Model for Gland Segmentation in Colon Histology Images,(1) our method utilizes a diffusion model to perform denoising and tackle the task of gland instance segmentation in histology images.
Instance-Aware Diffusion Model for Gland Segmentation in Colon Histology Images,our proposed method was trained and tested on the 2015 mic-cai gland segmentation (glas) challenge dataset 
Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs,"to that end, researchers have recently proposed to use gan-based image-to-image translation (i2it) algorithms for transforming h&e-stained slides into ihc."
Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs,"despite the progress, the outstanding challenge in training such i2it frameworks is the lack of aligned h&e-ihc image pairs, or in other words, the inconsistencies in the h&e-ihc groundtruth pairs."
Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs,"to explain, since re-staining a slice is physically infeasible, a matching pair of h&e-ihc slices are taken from two depth-wise consecutive cuts of the same tissue then stained and scanned separately."
Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs,datasets.
Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs,the following datasets are used in our experiments: the breast cancer immunohistochemical (bci) challenge dataset  implementation details.
Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs,"for all of our models, we used resnet-6blocks as the generator and a 5-layer patchgan as the discriminator."
HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis,none
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"colorectal cancer is the third most common malignant tumor, and nearly half of all patients with colorectal cancer develop liver metastasis during the course of the disease  extensive existing works have demonstrated the power of deep learning on various spatial-temporal data, and can potentially be applied towards the problem of crlm."
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"for example, originally designed for natural data, several mainstream models such as e3d-lstm  however, all these methods have only demonstrated their effectiveness towards 3d/4d data (i.e., time-series 2d/3d images), and it is not clear how to best extend them to work with the 5d cect data."
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,-no other malignant tumors.
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,our retrospective dataset includes two cohorts from two hospitals.
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,the first cohort consists of 201 patients and the second cohort includes 68 patients.
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,all images underwent manual quality control to exclude any scans with noticeable artifacts or blurriness and to verify the completeness of all slices.
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"additional statistics on our dataset are presented in table  colorectal cancer is the third most common malignant tumor, and nearly half of all patients with colorectal cancer develop liver metastasis during the course of the disease  extensive existing works have demonstrated the power of deep learning on various spatial-temporal data, and can potentially be applied towards the problem of crlm."
Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology,for these two tasks we used artifact-free tiles from tumor regions detected with an in-house tumor detection model.
Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology,"for breast cancer metastasis detection in lymph node tissue, we used wsis of h&estained healthy lymph node tissue and lymph node tissue with breast cancer metastases from the publicly available camelyon16 challenge data set  for cell of origin (coo) prediction of activated b-cell like (abc) or germinal center b-cell like (gcb) tumors in diffuse large b-cell lymphoma (dlbcl), we used data from the phase 3 goya (nct01287741) and phase 2 cavalli (nct02055820) clinical trials, hereafter referred to as ct1 and ct2, respectively."
Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology,all slides were h&e-stained and scanned using ventana dp200 scanners at 40× magnification.
Progressive Attention Guidance for Whole Slide Vulvovaginal Candidiasis Screening,none
CellGAN: Conditional Cervical Cell Synthesis for Augmenting Cytopathological Image Classification,none
An Anti-biased TBSRTC-Category Aware Nuclei Segmentation Framework with a Multi-label Thyroid Cytology Benchmark,none
Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,"breast cancer (bc) is one of the most common malignant tumors in women worldwide and it causes nearly 0.7 million deaths in 2020  recently, with the development of transformer, multi-modal pre-training has achieved great success in the fields of computer vision (cv) and natural language processing (nlp)."
Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,"according to the data format, there are two main multi-modal pre-training approaches, as shown in fig."
Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,"to our best knowledge, this is the first pre-training work based on multi-modal pathological data."
Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,"we evaluate the proposed method on two public datasets as herohe challenge and bci challenge, which shows that our method achieves state-of-theart performance."
Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,i=1 and {yi} λ 2 n i=1 into the modal-fusion encoder to extract the patch tokens {fi} λ 1 n i=1 and {gi} λ 2 n i=1 .
Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,x and y are reconstructed by modal-specific decoders respectively.
Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,acrobat challenge.
Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,the automatic registration of breast cancer tissue (acrobat) challenge  bci challenge.
Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,"breast cancer immunohistochemical image generation challenge  breast cancer (bc) is one of the most common malignant tumors in women worldwide and it causes nearly 0.7 million deaths in 2020  recently, with the development of transformer, multi-modal pre-training has achieved great success in the fields of computer vision (cv) and natural language processing (nlp)."
Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,breast cancer immunohistochemical image generation challenge 
Semi-supervised Pathological Image Segmentation via Cross Distillation of Multiple Attentions,none
Towards Novel Class Discovery: A Study in Novel Skin Lesions Clustering,"automatic identification of lesions from dermoscopic images is of great importance for the diagnosis of skin cancer  one approach to address the above problem is novel class discovery (ncd)  in this paper, we propose a new novel class discovery framework to automatically discover novel disease categories."
Towards Novel Class Discovery: A Study in Novel Skin Lesions Clustering,"specifically, we first use contrastive learning to pretrain the model based on all data from known and unknown categories to learn a robust and general semantic feature representation."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"cancers are a group of heterogeneous diseases reflecting deep interactions between pathological and genomics variants in tumor tissue environments  the major goal of multimodal data learning is to extract complementary contextual information across modalities  to tackle above challenges, we propose a pathology-and-genomics multimodal framework (i.e., pathomics) for survival prediction (fig."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,datasets.
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"importantly, our approach opens up perspectives for exploring the key insights of intrinsic genotypephenotype interactions in complex cancer data across modalities."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"our finetuning cancers are a group of heterogeneous diseases reflecting deep interactions between pathological and genomics variants in tumor tissue environments  the major goal of multimodal data learning is to extract complementary contextual information across modalities  to tackle above challenges, we propose a pathology-and-genomics multimodal framework (i.e., pathomics) for survival prediction (fig."
Robust Cervical Abnormal Cell Detection via Distillation from Local-Scale Consistency Refinement,cervical cancer is the second most common cancer among adult women.
Robust Cervical Abnormal Cell Detection via Distillation from Local-Scale Consistency Refinement,"if diagnosed early, it can be effectively treated and cured  with the development of deep learning  although the above-mentioned attempts can improve the screening performance significantly, there are several issues that need to be addressed: 1) object detection methods often require accurate annotated data to guarantee performance with robustness and generalization."
Robust Cervical Abnormal Cell Detection via Distillation from Local-Scale Consistency Refinement,"however, due to legal limitations, the scarcity of positive samples, and especially the subjectivity differences between cytopathologists for manual annotations  to address these issues, we propose a novel method for cervical abnormal cell detection using distillation from local-scale consistency refinement."
Robust Cervical Abnormal Cell Detection via Distillation from Local-Scale Consistency Refinement,"inspired by knowledge distillation, we construct a pre-trained patch correction network (pcn), which is designed to exploit the supervised information from the pcn to reduce the impact of noisy labels and utilize the contextual relationships between cells."
Robust Cervical Abnormal Cell Detection via Distillation from Local-Scale Consistency Refinement,"in our approach, we begin by utilizing retinanet  cervical cancer is the second most common cancer among adult women."
MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"the considered dual-stream approach, including an embedding and instance-based stream, exhibited slightly improved average scores, compared to embedding-based mil only."
MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"in our analysis, we focused on the embedding-based configuration and on the balanced combined approach (referred to as 2/2)."
MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"with the baseline data augmentation approaches, the maximum improvements were 0.03, and 0.02 for the frozen, and 0.01, and 0.05 for the paraffin data set."
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"breast cancer (bc) is the most common cancer diagnosed among females and the second leading cause of cancer death among women after lung cancer  among different types of imaging biomarkers, histopathological images are generally considered the golden standard for bc prognosis since they can confer important cell-level information that can reflect the aggressiveness of bc  to deal with the above challenges, several researchers began to design domain adaption algorithms, which utilize the labeled data from a related cancer subtype to help predict the patients' survival in the target domain."
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"specifically, alirezazadeh et al  although much progress has been achieved, most of the existing studies applied the feature alignment strategy to reduce the distribution difference between source and target domains."
Gene-Induced Multimodal Pre-training for Image-Omic Classification,none
Histopathology Image Classification Using Deep Manifold Contrastive Learning,we tested our proposed method on two different tasks: (1) intrahepatic cholangiocarcinomas(ihccs) subtype classification and (2) liver cancer type classification.
Histopathology Image Classification Using Deep Manifold Contrastive Learning,the dataset for the former task was collected from 168 patients with 332 wsis from seoul national university hospital.
Histopathology Image Classification Using Deep Manifold Contrastive Learning,ihccs can be further categorized into small duct type (sdt) and large duct type (ldt).
Histopathology Image Classification Using Deep Manifold Contrastive Learning,"in the deep manifold embedding learning model, the learning rates were set to 1e-4 with a decay rate of 1e-6 for the ihccs subtype classification and to 1e-5 with a decay rate of 1e-8 for the liver cancer type classification."
Histopathology Image Classification Using Deep Manifold Contrastive Learning,"the k-nearest neighbors graph and the geodesic distance matrix are updated once every five training epochs, which is empirically chosen to balance running time and accuracy."
Histopathology Image Classification Using Deep Manifold Contrastive Learning,"to train the mil classifier, we set the learning rate to 1e-3 and the decay rate to 1e-6."
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"additionally, the presence of tumor heterogeneity and the varied distribution of tumor foci can further complicate the labeling process."
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"to address this issue, we propose applying neighbor consistency regularization (ncr)  where d kl is the kl-divergence loss to quantify the discrepancy between two probability distributions, t represents the temperature and nn k (v i ) is the set of k nearest neighbors of v i in the feature space."
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"biopsy and whole-mount slides provide complementary multi-modal information on the tumor microenvironment, and combining them can provide a more comprehensive understanding of tumor-associated stroma."
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"for instance, a model trained on whole-mount slides only may not generalize well to biopsy slides due to systematic shifts, hindering model performance in the clinical application scenario."
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"to address the above issues, we propose an adversarial multi-modal learning (aml) module to force the feature extractor to produce multimodal-invariant representations on multiple source images."
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"specifically, we incorporate a source discriminator adversarial neural network as auxiliary classifier."
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"the stroma classifier and source discriminator are trained simultaneously, aiming to effectively classify tumor-associated stroma while impeding accurate source prediction by the discriminator."
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"the optimization process aims to achieve a balance between these two goals, resulting in an embedding space that encodes as much information as possible about tumor-associated stroma identification while not encoding any information on the data source."
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"by adopting the adversarial learning strategy, our model can maintain the correlated information and shared characteristics between two modalities, which will enhance the model's generalization and robustness."
Multi-scope Analysis Driven Hierarchical Graph Transformer for Whole Slide Image Based Cancer Survival Prediction,none
Mining Negative Temporal Contexts for False Positive Suppression in Real-Time Ultrasound Lesion Detection,deep learning has recently emerged as a promising approach for ultrasound lesion detection.
Mining Negative Temporal Contexts for False Positive Suppression in Real-Time Ultrasound Lesion Detection,"while previous works focused on lesion detection in still images  previous general-purpose detectors  to address this issue, we propose a novel ultradet model to leverage ntc."
Mining Negative Temporal Contexts for False Positive Suppression in Real-Time Ultrasound Lesion Detection,"for each region of interest (roi) r proposed by a basic detector, we extract temporal contexts from previous frames."
Mining Negative Temporal Contexts for False Positive Suppression in Real-Time Ultrasound Lesion Detection,our contributions are four-fold.
Mining Negative Temporal Contexts for False Positive Suppression in Real-Time Ultrasound Lesion Detection,"in this paper, we address the clinical challenge of real-time ultrasound lesion detection."
Mining Negative Temporal Contexts for False Positive Suppression in Real-Time Ultrasound Lesion Detection,"we propose a novel negative temporal context aggregation (ntca) module, imitating radiologists' diagnosis processes to suppress fps."
Iteratively Coupled Multiple Instance Learning from Instance to Bag Classifier for Whole Slide Image Classification,"our experiments utilized two datasets, with the first being the publicly available breast cancer dataset, camelyon16  the second dataset is a private hepatocellular carcinoma (hcc) dataset collected from sir run run shaw hospital, hangzhou, china."
Iteratively Coupled Multiple Instance Learning from Instance to Bag Classifier for Whole Slide Image Classification,"this dataset comprises a total of 1140 valid tumor wsis scanned at 40× magnification, and the objective is to identify the severity of each case based on the edmondson-steiner (es) grading."
Artifact Restoration in Histology Images with Diffusion Probabilistic Models,histology is critical for accurately diagnosing all cancers in modern medical imaging analysis.
Artifact Restoration in Histology Images with Diffusion Probabilistic Models,"however, the complex scanning procedure for histological wholeslide images (wsis) digitization may result in the alteration of tissue structures, due to improper removal, fixation, tissue processing, embedding, and storage  in real clinical practice, rescanning the wsis that contain artifacts can partially address this issue."
Artifact Restoration in Histology Images with Diffusion Probabilistic Models,"however, it may require multiple attempts before obtaining a satisfactory wsi, which can lead to a waste of time, medical resources, and deplete tissue samples."
Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,breast cancer is the most prevalent form of cancer among women and can have serious physical and mental health consequences if left unchecked  deep neural networks have been widely adopted for breast cancer diagnosis to alleviate the workload of radiologists.
Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"however, these models often require a large number of manual annotations and lack interpretability, which can prevent their broader applications in breast cancer diagnosis."
Probabilistic Modeling Ensemble Vision Transformer Improves Complex Polyp Segmentation,"colorectal cancer (crc) remains a major health burden with elevated mortality worldwide  traditional machine learning approaches in polyp segmentation primarily focus on learning low-level features, such as texture, shape, or color distribution  despite significant progress made by these binary mask supervised models, challenges remain in accurately locating polyps, particularly in complex clinical scenarios, due to their insensitivity to complex lesions and high false-positive rates."
Probabilistic Modeling Ensemble Vision Transformer Improves Complex Polyp Segmentation,"more specifically, most polyps have an elliptical shape with well-defined boundaries."
Probabilistic Modeling Ensemble Vision Transformer Improves Complex Polyp Segmentation,"to address these limitations, qadir et al."
Probabilistic Modeling Ensemble Vision Transformer Improves Complex Polyp Segmentation,"therefore, the primary challenge lies in enhancing polyp segmentation performance in complex scenarios by precisely preserving the polyp segmentation boundaries, while simultaneously maximizing the decoder's attention on the overall pattern of the polyps."
Probabilistic Modeling Ensemble Vision Transformer Improves Complex Polyp Segmentation,"in this paper, we propose a novel transformer-based polyp segmentation framework, petnet, which addresses the aforementioned challenges and achieves sota performance in locating polyps with high precision."
DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,"breast cancer (bc) is the most common cancer in women and incidence is increasing  authenticated by the bi-rads lexicon  the question of ""what the bi-mg would look like if they were symmetric?"" is often considered when radiologists determine the symmetry of bi-mg."
DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,it can provide valuable diagnostic information and guide the model in learning the diagnostic process akin to that of a human radiologist.
DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,"to  to alleviate the lack of annotation pixel-wise asymmetry annotations, in this study, we propose a random synthesis method to supervise disentanglement."
DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,"training with synthetic artifacts is a low-cost but efficient way to supervise the model to better reconstruct images  the alpha weights α k is a 2d gaussian distribution map, in which the co-variance is determined by the size of k-th tumor t, representing the transparency of the pixels of the tumor."
DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,some examples are shown in fig.
Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,"over 430,000 new cases of renal cancer were reported in 2020 in the world  segmentation of kidney tumors on ncct images adds challenges compared to contrast-enhanced ct (cect) images, due to low contrast and lack of multiphase images."
Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,"on cect images, the kidney tumors have different intensity values compared to the normal tissues."
Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,verify that the proposed framework achieves a higher dice score compared to the standard 3d u-net using a publicly available dataset.
Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,"the release of two public ct image datasets with kidney and tumor masks from the 2019/2021 kidney and kidney tumor segmentation challenge  looking at the top 3 teams from each challenge  in terms of focusing on protruded regions in kidneys, our work is close to  the second protuberance detection network is the same as the base network except it starts from 8 channels instead of 16."
Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,we train this network using synthetic datasets.
Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,"thus, when the output of the protuberance detection network is concatenated with the output of the base network, the fusion network can easily reduce the loss by ignoring the protuberance detection network's output, which is suboptimal."
Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,"to avoid this issue, we perform summation not concatenation to avoid the model from ignoring all output from the protuberance detection network."
Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,we then clip the value of the mask to the range of 0 and 1.
Skin Lesion Correspondence Localization in Total Body Photography,none
Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,"then, the expected probability for the c-th class p c and the total uncertainty u for each sample (x i ) can be calculated as p c = αc s , and u = c s , respectively, where s = c c=1 α c ."
Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,"to fit the dirichlet distribution to the output layer of our network, we use a loss function consisting of the prediction error l p i and the evidence adjustment where λ is the annealing coefficient to balance the two terms."
Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,"l p i can be crossentropy, negative log-likelihood, or mean square error , while l e i (θ) is kl divergence to the uniform dirichlet distribution  the performance of the proposed network is compared with 3 baseline models including gtn, graph convolution network  clinical relevance: hormone receptor status plays an important role in determining breast cancer prognosis and tailoring treatment plans for patients  intra-operative deployment of deep learning solutions requires a measure of interpretability as well as predictive confidence."
Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-Based Hierarchical Fusion Network with Attention Mechanism,"breast cancer is the most common cancer and the leading cause of cancer death in women  with the development of computer technology, artificial intelligence-based methods have shown potential in image generation and have received extensive attention."
Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-Based Hierarchical Fusion Network with Attention Mechanism,"some studies have shown that some generative models can effectively perform mutual synthesis between mr, ct, and pet  diffusion-weighted imaging (dwi) is emerging as a key imaging technique to complement breast ce-mri  i from the perspective of method, we innovatively proposed a multi-sequence fusion model, designed for combining t1-weighted imaging and multi-b-value dwi to synthesize ce-mri for the first time."
Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-Based Hierarchical Fusion Network with Attention Mechanism,"the mris were acquired with philips ingenia all mris were resampled to 1 mm isotropic voxels and uniformly sized, resulting in volumes of 352 × 352 pixel images with 176 slices per mri, and subsequent registration was performed based on advanced normalization tools (ants)  we have developed a multi-sequence fusion network based on multi-b-value dwi to synthesize ce-mri, using source data including dwis and t1-weighted fatsuppressed mri."
Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-Based Hierarchical Fusion Network with Attention Mechanism,"compared to existing methods, we avoid the challenges of using full-sequence mri and aim to be selective on valuable source data dwi."
Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-Based Hierarchical Fusion Network with Attention Mechanism,"hierarchical fusion generation module, weighted difference module, and multisequence attention module have all been shown to improve the performance of synthesizing target images by addressing the problems of synthesis at different scales, leveraging differentiable information within and across sequences."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,none
Automated CT Lung Cancer Screening Workflow Using 3D Camera,none
Multi-task Learning of Histology and Molecular Markers for Classifying Diffuse Glioma,none
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"to achieve this, we efficiently exploit knowledge from multi-center datasets that are not tailored for second-course gtv segmentation."
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"our training strategy does not specific to any tasks but challenges the network to retrieve information from another encoder with augmented inputs, which enables the network to learn from the above three aspects."
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,extensive quantitative and qualitative experiments validate our designs.
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"s v lacks its counterpart for the second course, in which i v /g v are the ct image and the corresponding annotation for gtv."
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"to address this, we apply two distinct randomized augmentations, p 1 , p 2 , to mimic the unregistered issue of the first and second course ct."
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"the transformed data is feed into the encoders e 1/2 as shown in the following equations: , p 1 (g e ), p 2 (i e ), p 2 (g e ), when i e , g e ∈ s e ."
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,region-preserving attention module.
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"although introducing the esophageal structural prior knowledge using s e can improve the performance in dsc and asd (table  however, there is no performance gain with mha as shown in table  to tackle the aforementioned problem, we propose ram which involves the concatenation of the original features with attention outputs, allowing for the preservation of convolution-generated regional tumor patterns while effectively comprehending long-range prior knowledge specific to the esophagus."
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"finally, our proposed artseg with ram achieves the best dsc/hsd of 75.26%/19.75 mm, and outperforms its ablations as well as other baselines, as shown in table  limitations."
CLIP-Lung: Textual Knowledge-Guided Lung Nodule Malignancy Prediction,"lung cancer is one of the most fatal diseases worldwide, and early diagnosis of the pulmonary nodule has been identified as an effective measure to prevent lung cancer."
CLIP-Lung: Textual Knowledge-Guided Lung Nodule Malignancy Prediction,"deep learning-based methods for lung nodule classification have been widely studied in recent years  however, the aforementioned methods still face challenges in distinguishing visually similar samples with adjacent rank labels."
CLIP-Lung: Textual Knowledge-Guided Lung Nodule Malignancy Prediction,"for example, in fig."
EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,computer-aided diagnosis systems (cad) using deep learning models have shown promise in accurate and efficient skin lesion diagnosis.
EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"however, recent research has revealed that the success of these models may be a result of overly relying on ""spurious cues"" in dermoscopic images, such as rulers, gel bubbles, dark corners, and hairs  to alleviate the artifact bias and enhance the model's generalization ability, we rethink the problem from the domain generalization (dg) perspective, where a model trained within multiple different but related domains are expected to perform well in unseen test domains."
EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,as illustrated in fig.
EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"previous dg algorithms learning domain-invariant features from source domains have succeeded in natural image tasks  to overcome the above problems, we propose an environment-aware prompt vision transformer (epvt) for domain generalization of skin lesion recognition."
EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,"on the one hand, inspired by the emerging prompt learning techniques that embed prompts into a model for adaptation to diverse downstream tasks  our contributions can be summarized as:  (3) a domain mixup strategy is devised to reduce the co-artifacts specific to dermoscopic images; (4) extensive experiments on four out-of-distribution skin datasets and six biased isic datasets demonstrate the outperforming generalization ability and robustness of epvt under heterogeneous distribution shifts."
Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,none
Developing Large Pre-trained Model for Breast Tumor Segmentation from Ultrasound Images,"breast cancer is a serious health problem with high incidence and wide prevalence for women throughout the world  therefore, there is a high demand for automatic and robust methods to achieve accurate breast tumor segmentation."
Developing Large Pre-trained Model for Breast Tumor Segmentation from Ultrasound Images,"however, due to speckle noise and shadows in ultrasound images, breast tumor boundaries tend to be blurry and are difficult to be distinguished from background."
Developing Large Pre-trained Model for Breast Tumor Segmentation from Ultrasound Images,"furthermore, the boundary and size of breast tumors are always variable and irregular  various approaches based on deep learning have been developed for tumor segmentation with promising results  to address these challenges, we present, to the best of our knowledge, the first work to adopt multi-scale features collected from large set of clinical ultrasound images for breast tumor segmentation."
Developing Large Pre-trained Model for Breast Tumor Segmentation from Ultrasound Images,the main contributions of our work are as follows:  we collected 10927 cases for this research from yunnan cancer hospital.
Developing Large Pre-trained Model for Breast Tumor Segmentation from Ultrasound Images,five-fold cross validation is performed on the dataset in all experiments to verify our proposed network.
Developing Large Pre-trained Model for Breast Tumor Segmentation from Ultrasound Images,"for external validation, we further test our model on two independent publicly-available datasets collected by stu-hospital (dataset 1)  to verify the advantages of our proposed model for breast tumor segmentation in ultrasound images, we compare our deep-supervised convolutional network with the state-ofthe-art tumor segmentation methods, including deepres  representative segmentation results using different methods are provided in fig."
Developing Large Pre-trained Model for Breast Tumor Segmentation from Ultrasound Images,"in this paper, we have developed a large pre-trained model for breast tumor segmentation from ultrasound images."
3D Mitochondria Instance Segmentation with Spatio-Temporal Transformers,none
Physics-Informed Conditional Autoencoder Approach for Robust Metabolic CEST MRI at 7T,conditional autoencoder.
Physics-Informed Conditional Autoencoder Approach for Robust Metabolic CEST MRI at 7T,"we developed a conditional autoencoder (cae) to solve the b 1 inhomogeneity problem, which is essential for the generation of metabolic cest contrast maps at 7t."
Physics-Informed Conditional Autoencoder Approach for Robust Metabolic CEST MRI at 7T,the left part of fig.
Deep Unsupervised Clustering for Conditional Identification of Subgroups Within a Digital Pathology Image Set,none
A Texture Neural Network to Predict the Abnormal Brachial Plexus from Routine Magnetic Resonance Imaging,"the major contributions of this study include 1) directed triangle construction idea for tpp, 2) huge number of tpp matrices as the heterogeneity representations of bp, 3) tppnet with 15 layers and huge number of channels, 4) the bp dataset containing mr images and their corresponding roi masks."
A Texture Neural Network to Predict the Abnormal Brachial Plexus from Routine Magnetic Resonance Imaging,"following irb approval for this study, we search for patients with metastatic breast cancer who had a breast cancer mri performed between 2010 and 2020 and had morphologically positive bp on the mri report from our electronic medical records (emr) in * hospital."
A Texture Neural Network to Predict the Abnormal Brachial Plexus from Routine Magnetic Resonance Imaging,"totally, we collect approximate 807 series which include 274 t2, 254 t1 and 279 post-gadolinium."
CircleFormer: Circular Nuclei Detection in Whole Slide Images with Circle Queries and Attention,none
Self-supervised Dense Representation Learning for Live-Cell Microscopy with Time Arrow Prediction,none
Prompt-MIL: Boosting Multi-instance Learning Schemes via Task-Specific Prompt Tuning,none
Prompt-Based Grouping Transformer for Nucleus Detection and Classification,none
Relaxation-Diffusion Spectrum Imaging for Probing Tissue Microarchitecture,none
atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning,none
B-Cos Aligned Transformers Learn Human-Interpretable Features,task-based evaluation: cancer classification and segmentation is an important first step for many downstream tasks such as grading or staging.
B-Cos Aligned Transformers Learn Human-Interpretable Features,"therefore, we choose this problem as our target."
B-Cos Aligned Transformers Learn Human-Interpretable Features,we classify image patches from the public colorectal cancer dataset nct-crc-he-100k  domain-expert evaluation: our primary objective is to develop an extension of the vision transformer that is more transparent and trusted by medical professionals.
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"second, resting-state fmri data are not routinely collected for gbm clinical practices, which restricts the size of annotated datasets such that it is infeasible to train a reliable prediction model based on deep learning for survival prediction."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"in order to circumvent these issues, in this paper we introduce a novel neuroimaging feature family, namely functional lesion network (fln) maps that are generated by our augmented lesion network mapping (a-lnm), for overall survival time prediction of gbm patients."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,our a-lnm is motivated by lesion network mapping (lnm)  the details of our workflow are described as follows.
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"to evaluate the predictive power of the fln maps generated by our a-lnm, we conduct extensive experiments on 235 gbm patients in the training dataset of brats 2020  2.1 materials gsp1000 processed connectome."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,it publicly released preprocessed restingstate fmri data of 1000 healthy right-handed subjects with an average age 21.5 ± 2.9 years and approximately equal numbers of males and females from the brain genomics superstruct project (gsp)  brats 2020.
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"it provided an open-access pre-operative imaging training dataset to segment brain tumors of glioblastoma (gbm, belonging to high grade glioma) and low grade glioma (lgg) patients, as well as to predict overall survival time of gbm patients  the union of all the three tumor sub-regions was considered as the whole tumor, which is regarded as the lesion in this paper."
Intraoperative CT Augmentation for Needle-Based Liver Interventions,"needle-based liver tumor ablation techniques (e.g., radiofrequency, microwave, laser, cryoablation) have a great potential for local curative tumor control  in standard clinical settings, the insertion of each needle requires multiple check points during its progression, fine-tune maneuvers, and eventual repositioning."
Intraoperative CT Augmentation for Needle-Based Liver Interventions,"this leads to multiple ct acquisitions to control the progression of the needle with respect to the vessels, the target, and other sensible structures  to address this challenge, two main strategies could be considered: image fusion and image processing techniques."
Intraoperative CT Augmentation for Needle-Based Liver Interventions,"image fusion typically relies on the estimation of rigid or non-rigid transformations between 2 images, to bring into the intraoperative image structures of interest only visible in the preoperative data."
Intraoperative CT Augmentation for Needle-Based Liver Interventions,"this process is often described as an optimization problem  on the other hand, deep learning techniques have proven to be very efficient at solving image processing challenges  in this paper we propose an alternative approach, where a neural network learns local image features in a ncct image by leveraging the known preoperative vessel tree geometry and topology extracted from a matching (undeformed) cct."
Intraoperative CT Augmentation for Needle-Based Liver Interventions,"then, the augmented ct is generated by fusing the deformed vascular tree with the non-contrasted intraoperative ct."
Optical Coherence Elastography Needle for Biomechanical Characterization of Deep Tissue,none
Pelvic Fracture Segmentation Using a Multi-scale Distance-Weighted Neural Network,"pelvic fracture is a severe type of high-energy injury, with a fatality rate greater than 50%, ranking the first among all complex fractures  several studies have been proposed to provide more efficient tools for operators."
Pelvic Fracture Segmentation Using a Multi-scale Distance-Weighted Neural Network,"a semi-automatic graph-cut method based on continuous max-flow has been proposed for pelvic fracture segmentation, but it still requires the manual selection of seed points and trail-and-error  fracture segmentation is still a challenging task for the learning-based method because (1) compared to the more common organ/tumor segmentation tasks where the model can implicitly learn the shape prior of an object, it is difficult to learn the shape information of a bone fragment due to the large variations in fracture types and shapes  this paper proposes a deep learning-based method to segment pelvic fracture fragments from preoperative ct images automatically."
Pelvic Fracture Segmentation Using a Multi-scale Distance-Weighted Neural Network,our major contribution includes three aspects.
Towards Multi-modal Anatomical Landmark Detection for Ultrasound-Guided Brain Tumor Resection with Contrastive Learning,none
Deep Reinforcement Learning Based System for Intraoperative Hyperspectral Video Autofocusing,"this information is potentially valuable for making intraoperative decisions, particularly in cases where tissue differentiation is critical but challenging to perform using traditional visualisation techniques."
Deep Reinforcement Learning Based System for Intraoperative Hyperspectral Video Autofocusing,"in the case of brain tumour excision, fluorescence-guided resection is commonly used to minimize damage to healthy tissue  while hsi has been integrated into surgical microscope systems  the issue of reduced focal depth in real-time hsi systems could be mitigated by the introduction of a video autofocus system."
Deep Reinforcement Learning Based System for Intraoperative Hyperspectral Video Autofocusing,"autofocus methods are divided into active methods, which use transmission to probe the scene, and passive methods, which rely only on incoming light."
Surgical Video Captioning with Mutual-Modal Concept Alignment,"to evaluate the effectiveness of surgical video captioning, we collect a large-scale dataset with 41 surgical videos of endonasal skull base neurosurgery."
Surgical Video Captioning with Mutual-Modal Concept Alignment,"these surgical videos are recorded at the prince of wales hospital, chinese university of hong kong, where surgeons remove pituitary tumors through the endonasal corridor to the skull base."
Surgical Video Captioning with Mutual-Modal Concept Alignment,"after necessary data cleaning, we divide these surgical videos with resolution of 1, 920× 1, 080 into 11, 004 thirty-second video clips with clear surgical purposes."
Regularized Kelvinlet Functions to Model Linear Elasticity for Image-to-Physical Registration of the Breast,none
Learning Expected Appearances for Intraoperative Registration During Neurosurgery,we address the important problem of intraoperative patient-to-image registration in a new way by relying on preoperative data to synthesize plausible transformations and appearances that are expected to be found intraoperatively.
Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"in particular, we tackle intraoperative 3d/2d registration during neurosurgery, where preoperative mri scans need to be registered with intraoperative surgical views of the brain surface to guide neurosurgeons towards achieving a maximal safe tumor resection  most existing techniques perform patient-to-image registration using intraoperative mri  the main limitation of existing intraoperative registration methods is that they rely heavily on processing intraoperative images to extract image features (eg., 3d surfaces, vessels centerlines, contours, or other landmarks) to drive registration, making them subject to noise and low-resolution images that can occur in the operating room  clinical feasibility."
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,none
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"residual tumor in the cavity after head and neck cancer (hnc) surgery is a significant concern as it increases the risk of cancer recurrence and can negatively impact the patient's prognosis  during transoral robotic surgery (tors), surgeons may assess the surgical margin via visual inspection, palpation of the excised specimen and intraoperative frozen sections analysis (ifsa)  label-free mesoscopic fluorescence lifetime imaging (flim) has been demonstrated as an intraoperative imaging guidance technique with high classification performance (auc = 0.94) in identifying in vivo tumor margins at the epithelial surface prior to tumor excision  however, ability of label-free flim to identify residual tumors in vivo in the surgical cavity (deep margins) has not been reported."
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,one significant challenge in developing a flim-based classifier to detect tumor in the surgical cavity is the presence of highly imbalanced labels.
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"surgeons aim to perform an en bloc resection, removing the entire tumor and a margin of healthy tissue around it to ensure complete excision."
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"therefore, in most cases, only healthy tissue in left in the cavity."
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"to address the technical challenge of highly imbalanced label distribution and the need for intraoperative real-time cavity imaging, we developed an intraoperative flim guidance model to identify residual tumors by classifying residual cancer as anomalies."
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,our proposed approach identified all patients with psm.
FocalErrorNet: Uncertainty-Aware Focal Modulation Network for Inter-modal Registration Error Estimation in Ultrasound-Guided Neurosurgery,none
Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"cancer remains a significant public health challenge worldwide, with a new diagnosis occurring every two minutes in the uk (cancer research uk  it is crucial to accurately determine the sensing area, with positive signal potentially indicating cancer or affected lymph nodes."
Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"geometrically, the sensing area is defined as the intersection point between the gamma probe axis and the tissue surface in 3d space, but projected onto the 2d laparoscopic image."
Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"similarly, it is also challenging to acquire the probe pose during the surgery."
Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,problem redefinition.
Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"in this study, in order to provide sensing area visualization ground truth, we modified a non-functional 'sensei' probe by adding a miniaturized laser module to clearly optically indicate the sensing area on the laparoscopic images -i.e."
Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"our system consists of four main components: a customized stereo laparoscope system for capturing stereo images, a rotation stage for automatic phantom movement, a shutter for illumination control, and a daq-controlled switchable laser module (see fig."
Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"to validate our proposed solution for the newly formulated problem, we acquired and publicly released two new datasets."
Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"in this section, we introduce the hardware and software design that was used to achieve our final goal, while fig."
Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"therefore, our first newly acquired dataset, named jerry, contains 1200 sets of images."
Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"since it is important to report errors in 3d and in millimeters, we recorded another dataset similar to jerry but also including ground truth depth map for all frames by using structured-lighting system  these datasets have multiple uses such as: -intersection point detection: detecting intersection points is an important problem that can bring accurate surgical cancer visualization."
Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,we believe this is an under-investigated problem in surgical vision.
Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,-tool segmentation: corresponding ground truth will be released.
Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"in this work, a new framework for using a laparoscopic drop-in gamma detector in manual or robotic-assisted minimally invasive cancer surgery was presented, where a laser module mock probe was utilized to provide training guidance and the problem of detecting the probe axis-tissue intersection point was transformed to laser point position inference."
Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,both the hardware and software design of the proposed solution were illustrated and two newly acquired datasets were publicly released.
Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"extensive experiments were conducted on various backbones and the best results were achieved using a simple network design, enabling real time inference of the sensing area."
Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"we believe that our problem reformulation and dataset release, together with the initial experimental results, will establish a new benchmark for the surgical vision community."
A Novel Video-CTU Registration Method with Structural Point Similarity for FURS Navigation,"on the other hand, surgeons may miss stones and tumors and unsuccessfully orientate the ureteroscope inside the kidneys due to limited field of views, just 2d images without depth information, and the complex anatomical structure of the kidneys."
A Novel Video-CTU Registration Method with Structural Point Similarity for FURS Navigation,"to this end, ureteroscope tracking and navigation is increasingly developed as a promising tool to solve these issues."
A Novel Video-CTU Registration Method with Structural Point Similarity for FURS Navigation,many researchers have developed various methods to boost endoscopic navigation.
A Novel Video-CTU Registration Method with Structural Point Similarity for FURS Navigation,han et al.
A Novel Video-CTU Registration Method with Structural Point Similarity for FURS Navigation,"although these methods mentioned above work well, ureteroscopic navigation is still a challenging problem."
A Novel Video-CTU Registration Method with Structural Point Similarity for FURS Navigation,"compared to other endoscopes such as colonoscope and bronchoscope, the diameter of the ureteroscope is smaller, resulting in more limited lighting source and field of view."
A Novel Video-CTU Registration Method with Structural Point Similarity for FURS Navigation,"particularly, ureteroscopy involves much solids (impurities) and fluids (liquids), making ureteroscopic video images low-quality, as well as these solids and fluids inside the kidneys cannot be regularly observed in computed tomography (ct) images."
A Novel Video-CTU Registration Method with Structural Point Similarity for FURS Navigation,"on the other hand, the complex internal structures such as calyx, papilla, and pyramids of the kidneys are difficult to be observed in ct images."
A Novel Video-CTU Registration Method with Structural Point Similarity for FURS Navigation,"these issues introduce a difficulty in directly aligning ureteroscopic video sequences to ct images, leading to a challenge of image-based continuous ureteroscopic navigation."
Cascade Transformer Encoded Boundary-Aware Multibranch Fusion Networks for Real-Time and Accurate Colonoscopic Lesion Segmentation,"on the other hand, various polyps and adenomas with different pathological features have similar visual characteristics to intestinal folds."
Cascade Transformer Encoded Boundary-Aware Multibranch Fusion Networks for Real-Time and Accurate Colonoscopic Lesion Segmentation,"to address these issues mentioned above, we explore a new deep learning architecture called cascade transformer encoded boundary-aware multibranch fusion (ctbmf) networks with cascade transformers and multibranch fusion for polyp and adenoma segmentation in colonoscopic white-light and narrow-band video images."
Cascade Transformer Encoded Boundary-Aware Multibranch Fusion Networks for Real-Time and Accurate Colonoscopic Lesion Segmentation,several technical highlights of this work are summarized as follows.
Unified Brain MR-Ultrasound Synthesis Using Multi-modal Hierarchical Representations,"however, as noted in  medical image synthesis aims to predict missing images given available images."
Unified Brain MR-Ultrasound Synthesis Using Multi-modal Hierarchical Representations,"deep-learning based methods have reached the highest level of performance  to tackle this challenge, unified approaches have been proposed."
Unified Brain MR-Ultrasound Synthesis Using Multi-modal Hierarchical Representations,"these approaches are designed to have the flexibility to handle incomplete image sets as input, improving practicality as only one network is used for generating missing images."
Unified Brain MR-Ultrasound Synthesis Using Multi-modal Hierarchical Representations,"third, adversarial learning is employed to generate realistic image synthesis."
Unified Brain MR-Ultrasound Synthesis Using Multi-modal Hierarchical Representations,"finally, experiments on the challenging problem of ius and mr synthesis demonstrate the effectiveness of the proposed approach, enabling the synthesis of high-quality images while establishing a mathematically grounded formulation for unified image synthesis and outperforming non-unified gan-based approaches and the state-of-the-art method for unified multi-modal medical image synthesis."
StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"the theoretical spacing between each slice is 5 mm, and the typical pixel size before downsampling is 100k × 100k."
StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"two expert radiation oncologists on ct delineated both the thyroid and cricoid cartilages for structure awareness and the gross tumor volume (gtv) for clinical validation, while two expert pathologists did the same on wsis."
StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,they then meet and agreed to place 6 landmarks for each slice at important locations (not used for training).
StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"concerning the gpu runtime, with a 3-step cascade for initialization, the inference remains in a similar time scale to baseline methods and performs mapping in less than 3s."
StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"we also compared against msv-regsynnet on its own validation dataset for generalization assessment: we yielded comparable results for the first cohort and significantly better ones for the second, which proves that structuregnet behaves well on other modalities and that the structure awareness is an essential asset for better registration, as pelvis is a location where organs are moving."
StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,visuals of registration results are displayed in the supplementary material.
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"this can improve image-guided therapies and preoperative planning, especially for radiotherapy, which requires precise patient positioning with minimal radiation exposure."
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"however, this task is an ill-posed inverse problem: x-ray measurements are the result of attenuation integration across the body, which makes them very fig."
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,ambiguous.
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,traditional reconstruction methods require hundreds of projections to get sufficient constraints on the internal structures.
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"with very few projections, it is very difficult to disentangle the structures for even coarse 3d estimation."
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"in other words, many 3d volumes may have generated such projections a priori."
Structure-Preserving Synthesis: MaskGAN for Unpaired MR-CT Translation,none
FreeSeed: Frequency-Band-Aware and Self-guided Network for Sparse-View CT Reconstruction,"for the former, few work has investigated the fact that the artifacts exhibit similar pattern across different sparseview scenarios, which is evident in fourier domain as shown in fig."
FreeSeed: Frequency-Band-Aware and Self-guided Network for Sparse-View CT Reconstruction,"while fourier domain band-pass maps help capture the pattern of the artifacts, restoring the image detail contaminated by strong artifacts may still be difficult due to the entanglement of artifacts and details in the residues."
FreeSeed: Frequency-Band-Aware and Self-guided Network for Sparse-View CT Reconstruction,"consequently, we propose a self-guided artifact refinement network (seednet) that provides supervision signals to aid freenet in refining the image details contaminated by the artifacts."
Co-learning Semantic-Aware Unsupervised Segmentation for Pathological Image Registration,none
Revealing Anatomical Structures in PET to Generate CT for Attenuation Correction,none
An Explainable Deep Framework: Towards Task-Specific Fusion for Multi-to-One MRI Synthesis,none
Geometric Ultrasound Localization Microscopy,"however, the necessity of beamforming for ulm remains questionable."
Geometric Ultrasound Localization Microscopy,our work challenges the conventional assumption that beamforming is the ideal processing step for ulm and presents an alternative approach based on geometric reconstruction from time-of-arrival (toa) information.
Geometric Ultrasound Localization Microscopy,"the discovery of ulm has recently surpassed the diffraction-limited spatial resolution and enabled highly detailed visualization of the vascularity  while contrast-enhanced ultra-sound (ceus) is used in the identification of musculoskeletal soft tissue tumours  for ulm to investigate its potential to refine mb localization  to this end, we propose an alternative approach for ulm, outlined in fig."
Reflectance Mode Fluorescence Optical Tomography with Consumer-Grade Cameras,none
DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"in this experiment, we evaluate the performance of different methods for estimating affine registration of the retrospective evaluation of cerebral tumors (resect) miccai challenge dataset  as the most challenging experiment, we finally use our method to achieve deformable registration of abdominal 3d freehand us to a ct or mr volume."
DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"we are using a heterogeneous dataset of 27 cases, comprising liver cancer patients and healthy volunteers, different ultrasound machines, as well as optical vs."
DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"in order to measure the capture range, we start the registration from 50 random rigid poses around the ground truth and calculate the fiducial registration error (fre) after optimization."
DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"for local optimization, lc 2 is used in conjunction with bobyqa  from the results shown in table  note that this registration problem is much more challenging than the prior two due to difficult ultrasonic visibility in the abdomen, strong deformations, and ambiguous matches of liver vasculature."
DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"therefore, to the best of our knowledge, these results present a significant leap towards reliable and fully automatic fusion, doing away with cumbersome manual landmark placements."
Solving Low-Dose CT Reconstruction via GAN with Local Coherence,datasets.
Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"first, our proposed approaches are evaluated on the ""mayo-clinic low-dose ct grand challenge"" (mayo-clinic) dataset of lung ct images  the dataset contains 2250 two dimensional slices from 9 patients for training, and the remaining 128 slices from 1 patient are reserved for testing."
Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"the lowdose measurements are simulated by parallel-beam x-ray with 200 (or 150) uniform views, i.e., n v = 200 (or n v = 150), and 400 (or 300) detectors, i.e., n d = 400 (or n d = 300)."
Solving Low-Dose CT Reconstruction via GAN with Local Coherence,a similar increasing trend with our approach across different settings but has worse reconstruction quality.
Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"to evaluate the stability and generalization of our model and the baselines trained on mayo-clinic dataset, we also test them on the rider dataset."
Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"the results are shown in table  to illustrate the reconstruction performances more clearly, we also show the reconstruction results for testing images in fig."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"as the surrounding normal tissue is also sensitive to radiation, highly accurate delivery is vital."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"image guided rt (igrt) is a technique to capture the anatomy of the day using in room imaging in order to align the treatment beam with the tumor location  a major challenge especially for cbct imaging of the thorax and upperabdomen is the respiratory motion that introduces blurring of the anatomy, reducing the localization accuracy and the sharpness of the image."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"a technique used to alleviate motion artifacts is respiratory correlated cbct (4dcbct)  several traditional methods based on iterative reconstruction algorithms and motion compensation techniques are used to reduce view-aliasing in 4dcbcts  deep learning has been proposed as a way to address view-aliasing with accelerated reconstruction  a different method, called noise2inverse, uses an unsupervised approach to reduce measurement noise in the traditional ct setting  we propose noise2aliasing to address these limitations."
Trackerless Volume Reconstruction from Intraoperative Ultrasound Images,"liver cancer is the most prevalent indication for liver surgery, and although there have been notable advancements in oncologic therapies, surgery remains as the only curative approach overall  liver laparoscopic resection has demonstrated fewer complications compared to open surgery  performing ious during laparoscopic liver surgery poses significant challenges, as laparoscopy has poor ergonomics and narrow fields of view, and on the other hand, ious demands skills to manipulate the probe and analyze images."
Trackerless Volume Reconstruction from Intraoperative Ultrasound Images,"at the end, and despite its real-time capabilities, ious images are intermittent and asynchronous to the surgery, requiring multiple iterations and repetitive steps (probe-in -→ instruments-out -→ probe-out -→ instruments-in)."
Trackerless Volume Reconstruction from Intraoperative Ultrasound Images,"physics-based methods have exploited speckle correlation models between different adjacent frames  our method improves upon previous solutions in terms of robustness and accuracy, particularly in the presence of rotational motion."
Trackerless Volume Reconstruction from Intraoperative Ultrasound Images,such motion is predominant in the context highlighted above and is the source of additional nonlinearity in the pose estimation problem.
Trackerless Volume Reconstruction from Intraoperative Ultrasound Images,"to the best of our knowledge, this is the first work that provides a clinically sound and efficient 3d us volume reconstruction during minimally invasive procedures."
CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,"magnetic resonance imaging (mri) is critical to the diagnosis, treatment, and follow-up of brain tumour patients  management  despite the success, gan-based models are challenged by the limited capability of adversarial learning in modelling complex multi-modal data distributions  diffusion model (dm) has achieved state-of-the-art performance in synthesizing natural images, promising to improve mri synthesis models."
CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,"it shows superiority in model training  however, current dm-based methods focus on one-to-one mri translation, promising to be improved by many-to-one methods, which requires dedicated design to balance the multiple conditions introduced by multi-modal mri."
CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,"moreover, as most dms operate in original image domain, all markov states are kept in memory  we propose a dm-based multi-modal mri synthesis model, cola-diff, which facilitates many-to-one mri translation in latent space, and preserve anatomical structure with accelerated sampling."
CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,"-introduce structural guidance of brain regions in each step of the diffusion process, preserving anatomical structure and enhancing synthesis quality."
CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,-propose an auto-weight adaptation to balance multi-conditions and maximise the chance of leveraging relevant multi-modal information.
LightNeuS: Neural Surface Reconstruction in Endoscopy Using Illumination Decline,"colorectal cancer (crc) is the third most commonly diagnosed cancer and is the second most common cause of cancer death  to overcome these difficulties, we rely on two properties of endoscopic images: -endoluminal cavities such as the gastrointestinal tract, and in particular the human colon, are watertight surfaces."
LightNeuS: Neural Surface Reconstruction in Endoscopy Using Illumination Decline,"to account for this, we represent its surface in terms of a signed distance function (sdf), which by its very nature presents continuous watertight surfaces."
