title,extracted_keyword_sent
Anatomy-Driven Pathology Detection on Chest X-rays,"it is
derived from the mimic-cxr dataset [9,10], which is based on imaging studies
from 65 079 patients performed at beth israel deaconess medical center in
boston, us."
Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET,the dataset is composed of 23 oncological patients with different tumor types.
Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET,"the dataset included the label maps of 7 organs
(bones, lungs, heart, liver, kidneys, spleen, aorta) and one image-derived input
function a(t) [bq/ml] from the descending aorta per patient."
Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET,"then, the dataset was split
patient-wise into training, validation, and test set, with 10, 4, and 9 patients
respectively."
Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET,"in both cases, 75 axial slices per patient were extracted in a
pre-defined patient-specific range from the lungs to the bladder (included) and
were cropped to size 112 × 112 pixels."
Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET,"4.1 (see table 1).figure 2 shows the kps for four selected organs
as computed with the proposed dnn (kp dnn ), as computed with curve fit using
only the 9 patients of the test set (kp cf ) and using all 23 patients (kp ref
cf ) [16]."
Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET,"this is likely due to breathing and heartbeat motion artifacts, which
cannot be modeled properly with a 2tc km that assumes no motion between
frames.figure 3b-e shows the central coronal slice of the four kpis in an
exemplary patient."
AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor,"specifically, ame-cam achieves
the highest dice score for all patients in all datasets and modalities."
Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"similarly to the metavir score in d 1 histo
, we also binarize the ishak score, as proposed in [16,20], which results in two
cohorts of 34 healthy and 15 pathological patients.in all datasets, we select
the slices based on the liver segmentation of the patients."
Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"we first sample n patients, where n is the batch size, in a
balanced way with respect to the radiological/histological classes; namely, we
roughly have the same number of subjects per class."
Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"for d 2 histo , which has fewer patients than the batch size, we use
a balanced sampling strategy with respect to the radiological/histological
classes with no obligation of one slice per patient in the batch."
Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"as we work
with 2d slices rather than 3d volumes, we compute the average probability per
patient of having the pathology."
Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"the evaluation results presented later are
based on the patient-level aggregated prediction.finally, we run our experiments
on a tesla v100 with 16gb of ram and a 6 cpu cores, and we used the
pytorch-lightning library to implement our models."
Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification,"first, we can
notice that our method outperforms all other pretraining methods in d 1 histo
and d 1+2 histo , which are the two datasets with more patients."
Unsupervised Discovery of 3D Hierarchical Structure with Generative Diffusion Features,none
S 2 ME: Spatial-Spectral Mutual Teaching and Ensemble Learning for Scribble-Supervised Polyp Segmentation,"these datasets are
collected from diversified patients in multiple medical centers with various
data acquisition systems."
Tracking Adaptation to Improve SuperPoint for 3D Reconstruction in Endoscopy,"obtaining 3d models from the intracorporeal scenes captured in
endoscopies is an essential step to enable these novel tasks and build
applications, for example, for improved monitoring of existing patients or
augmented reality during training or real explorations.3d reconstruction
strategies have been studied for long, and one crucial step in these strategies
is feature detection and matching which serves as input for structure from
motion (sfm) pipelines."
Black-box Domain Adaptative Cell Segmentation via Multi-source Distillation,"firstly, we acquire 50 images from a cohort of patients with
triple negative breast cancer (tnbc), which is released by naylor et al [18]."
Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning,"yet, acquiring large training datasets and
their corresponding labels, especially from a cohort of patients, can be costly
or even infeasible, which poses a significant challenge in developing a dl model
with high performance [7]."
Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning,"this is due to
sensitive privacy issues in patients' data, particularly in collaborative
research, which restricts access to labels from different domains."
Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning,"• our framework is effective at preserving privacy, since it carries out da
using only pre-trained network parameters, without transferring any patient
data."
PET-Diffusion: Unsupervised PET Enhancement Based on the Latent Diffusion Model,none
3D Arterial Segmentation via Single 2D Projections and Depth Supervision in Contrast-Enhanced CT Images,"the cohort consists of 141 patients with pancreatic ductal
adenocarcinoma, of an equal ratio of male to female patients."
Mesh2SSM: From Surface Meshes to Statistical Shape Models of Anatomy,"dataset: we use the publicly available decath-pancreas dataset of 273
segmentations from patients who underwent pancreatic mass resection [24]."
Cross-Adversarial Local Distribution Regularization for Semi-supervised Medical Image Segmentation,none
Infusing Physically Inspired Known Operators in Deep Models of Ultrasound Elastography,"this data is available online at http://code.sonography.ai
in [16].in vivo data was collected at johns hopkins hospital from patients with
liver cancer during open-surgical rf thermal ablation by a research antares
siemens system using a vf 10-5 linear array with the sampling frequency of 40
mhz and the center frequency of 6.67 mhz."
Infusing Physically Inspired Known Operators in Deep Models of Ultrasound Elastography,"the institutional review board
approved the study with the consent of the patients."
SLPD: Slide-Level Prototypical Distillation for WSIs,"many histopathologic features have been established based on the morphologic
phenotypes of the tumor, such as tumor invasion, anaplasia, necrosis and
mitoses, which are then used for cancer diagnosis, prognosis and the estimation
of response-to-treatment in patients [3,9]."
SLPD: Slide-Level Prototypical Distillation for WSIs,"tumors of different patients can exhibit morphological similarities in some
respects [17,21], so the correspondences across slides should be characterized
during learning."
PROnet: Point Refinement Using Shape-Guided Offset Map for Nuclei Instance Segmentation,none
Many Tasks Make Light Work: Learning to Localise Medical Anomalies from Multiple Synthetic Tasks,"this huge increase in pressure has led
to long patient-waiting times and fatigued radiologists who make more mistakes
[3]."
TPRO: Text-Prompting-Based Weakly Supervised Histopathology Tissue Segmentation,none
VesselVAE: Recursive Variational Autoencoders for 3D Blood Vessel Synthesis,"this subset consisted of 1694
healthy vessel segments reconstructed from 2d mra images of patients."
MetaLR: Meta-tuning of Learning Rates for Transfer Learning in Medical Imaging,none
DAS-MIL: Distilling Across Scales for MIL Classification of Histological WSIs,"on the one hand, annotating wsis requires strong medical expertise,
is expensive, time-consuming, and labels are usually provided at the slide or
patient level."
Pick the Best Pre-trained Model: Towards Transferability Estimation for Medical Image Segmentation,none
vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images,none
Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation,none
Spectral Adversarial MixUp for Few-Shot Unsupervised Domain Adaptation,"however, most uda methods
require sufficient target samples, which are scarce in medical imaging due to
the limited accessibility to patient data."
Gall Bladder Cancer Detection from US Images with only Image Level Labels,"non-ionizing
radiation, low cost, and accessibility make us a popular non-invasive diagnostic
modality for patients with suspected gall bladder (gb) afflictions."
Gall Bladder Cancer Detection from US Images with only Image Level Labels,"on the
other hand, the image-level malignancy label is usually available at a low cost,
as it can be obtained readily from the diagnostic report of a patient without
additional effort from clinicians.instead of training a classification pipeline,
we propose to solve an object detection problem, which involves predicting a
bounding box for the malignancy."
Gall Bladder Cancer Detection from US Images with only Image Level Labels,"gallbladder cancer detection in ultrasound images: we use the public gbc us
dataset [3] consisting of 1255 image samples from 218 patients."
Gall Bladder Cancer Detection from US Images with only Image Level Labels,"the dataset
contains 990 non-malignant (171 patients) and 265 malignant (47 patients) gb
images (see fig."
Gall Bladder Cancer Detection from US Images with only Image Level Labels,"we did the cross-validation splits at the patient level, and
all images of any patient appeared either in the train or validation split."
Gall Bladder Cancer Detection from US Images with only Image Level Labels,"since kvasir-seg does not contain any control images, we add 600
non-polyp images randomly sampled from the polypgen [1] dataset.since the
patient information is not available with the data, we use random stratified
splitting for 5-fold cross-validation."
Structured State Space Models for Multiple Instance Learning in Digital Pathology,"patient selection for such
treatment regimes is based principally on the assessment of tissue biopsies and
the characterisation of the tumor microenvironment."
Structured State Space Models for Multiple Instance Learning in Digital Pathology,"in our experiments, the average patch sequence length
arising from camelyon16 is 6129 (ranging from 127 to 27444).tcga-luad is a tcga
lung adenocarcinoma dataset that contains 541 wsis along with genetic
information about each patient."
Structured State Space Models for Multiple Instance Learning in Digital Pathology,"as a mil task, we chose the task of predicting the
patient mutation status of tp53, a tumor suppressor gene that is highly relevant
in oncology studies."
Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision,"based on longitudinal imaging for a given patient it requires establishing which
lesions are corresponding (i.e., same lesion, observed at different timepoints),
which lesions have disappeared and which are new compared to prior scanning."
Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision,"for nlst, we randomly selected a subset of 1045 test images coming from
420 patients with up to 3 studies."
Geometry-Invariant Abnormality Detection,"this can include variances in scanner quality and
resolution, in addition to the fov selected during patient scans."
Geometry-Invariant Abnormality Detection,"detection and segmentation of anomalous regions, particularly for cancer
patients, is essential for staging, treatment and intervention planning."
Interpretable Medical Image Classification Using Prototype Learning and Privileged Information,"the proposed approach is evaluated using the publicly available lidc-idri
dataset consisting of 1018 clinical thoracic ct scans from patients with
non-small cell lung cancer (nsclc) [2,3]."
Incremental Learning for Heterogeneous Structure Segmentation in Brain Tumor MRI,none
ArSDM: Colonoscopy Images Synthesis with Adaptive Refinement Semantic Diffusion Models,none
Synthetic Augmentation with Large-Scale Unconditional Pre-training,none
Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation,none
Longitudinal Multimodal Transformer Integrating Imaging and Latent Clinical Signatures from Routine EHRs for Pulmonary Nodule Classification,"we searched all records in our ehr archives for patients who had billing codes
from a broad set of pulmonary conditions, intending to capture pulmonary
conditions beyond just malignancy."
Longitudinal Multimodal Transformer Integrating Imaging and Latent Clinical Signatures from Routine EHRs for Pulmonary Nodule Classification,"we searched our institution's imaging archive for
patients with three chest cts within five years."
Partially Supervised Multi-organ Segmentation via Affinity-Aware Consistency Learning and Cross Site Feature Alignment,none
Centroid-Aware Feature Recalibration for Cancer Grading in Pathology Images,"however, the current pathology workflow is sub-optimal and
low-throughput since it is, by and large, manually conducted, and the large
volume of workloads can result in dysfunction or errors in cancer grading, which
have an adversarial effect on patient care and safety [2]."
Explaining Massive-Training Artificial Neural Networks in Medical Image Analysis Task Through Visualizing Functions Within the Models,"dynamic contrast-enhanced liver ct scans
consisting of 42 patients with 194 liver tumors in the portal venous phase from
the lits database [21] were used in this study."
FeSViBS: Federated Split Learning of Vision Transformer with Block Sampling,none
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"in
hospitals, collected multi-phase cts are normally grouped by patients rather
than lesions, which makes single-phase lesion annotation insufficient for
feature fusion learning."
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"however, the number of lesions inside a single patient
can vary from one to dozens and they can be of different types in realistic
cases."
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"the single-phase annotated lesion has the position and class labels in all
phases but they are not aligned, so we could have difficulty finding out which
lesions in different phases are the same with 2 or more lesions in one patient."
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"to reduce errors caused by unregistered data and address the situation that one
patient has multiple lesions of different types, we pre-process the multi-phase
liver cts registered and grouped by lesions.the registration network is based on
voxelmorph [1], with a u-net learning registration field and moving data
transformed by the field."
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"we choose an atlas phase art as
suggested by clinicians and other phases of cts are registered to the art phase
of every patient.after registration, a lesion matcher finds the same lesions in
different phases."
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"after the pre-processing unit with window
dice threshold of 0.3, we screen 761 lesions from 444 patients with four phases
of cts, seven types of lesions (13.2% of hcc, 5.3% of hm, 11.3% of icc, 22.6% of
hh, 31.1% of hc, 8.7% of fnh, and 7.8% of ha), and totally 4820 slices."
TransLiver: A Hybrid Transformer Model for Multi-phase Liver Lesion Classification,"lesions from the same patient are
either assigned to the training and validation set or the test set, but not
both.implementations."
Adaptive Region Selection for Active Learning in Whole Slide Image Semantic Segmentation,none
COLosSAL: A Benchmark for Cold-Start Active Learning for 3D Medical Image Segmentation,none
Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation,"each pcle video represents one tumour type
and corresponds to a different patient."
Explainable Image Classification with Improved Trustworthiness for Tissue Characterisation,"the dataset is split into a training and testing subset, with the division done
on the patient level.implementation."
Continual Learning for Abdominal Multi-organ and Tumor Segmentation,none
Efficient Subclass Segmentation in Medical Images,none
Towards AI-Driven Radiology Education: A Self-supervised Segmentation-Based Framework for High-Precision Medical Image Editing,none
Localized Region Contrast for Enhancing Self-supervised Learning in Medical Image Segmentation,"abd-110 is an abdomen
dataset from [25] that contains 110 ct images from patients with various
abdominal tumors and these ct images were taken during the treatment planning
stage."
FedGrav: An Adaptive Federated Aggregation Algorithm for Multi-institutional Medical Image Segmentation,none
Faithful Synthesis of Low-Dose Contrast-Enhanced Brain MRI Scans Using Noise-Preserving Conditional GANs,"however, these contrast agents are expensive and may cause nephrogenic systemic
fibrosis in patients with severely reduced kidney function [31]."
Faithful Synthesis of Low-Dose Contrast-Enhanced Brain MRI Scans Using Noise-Preserving Conditional GANs,"moreover, [17]
reported that gadolinium accumulates inside patients with unclear health
consequences, especially after repeated application."
A Spatial-Temporal Deformable Attention Based Framework for Breast Lesion Detection in Videos,none
DeDA: Deep Directed Accumulator,none
OpenAL: An Efficient Deep Active Learning Framework for Open-Set Pathology Image Classification,none
SFusion: Self-attention Based N-to-One Multimodal Fusion Block,"medical
images may be missing due to artifacts and diverse patient conditions [11]."
SFusion: Self-attention Based N-to-One Multimodal Fusion Block,"during training, to simulate real missing modalities scenarios, each training
patient's data is fixed to one of 15 possible missing cases."
SFusion: Self-attention Based N-to-One Multimodal Fusion Block,"for a comprehensive
evaluation, we test the performance of all 15 cases for each test patient.our
implementations are on an nvidia rtx 3090(24g) with pytorch 1.8.1."
VISA-FSS: A Volume-Informed Self Supervised Approach for Few-Shot 3D Segmentation,none
ECL: Class-Enhancement Contrastive Learning for Long-Tailed Skin Lesion Classification,none
SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation,none
UniSeg: A Prompt-Driven Universal Segmentation Model as Well as A Strong Representation Learner,none
Cross-Modulated Few-Shot Image Generation for Colorectal Tissue Classification,none
Unpaired Cross-Modal Interaction Learning for COVID-19 Segmentation on Limited CT Images,"it is difficult to directly learn cross-modal
dependencies using the features obtained by the encoder because ct and x-ray
data were collected from different patients."
Unpaired Cross-Modal Interaction Learning for COVID-19 Segmentation on Limited CT Images,"all ct images were acquired
without intravenous contrast enhancement from patients with positive reverse
transcription polymerase chain reaction (rt-pcr) for sars-cov-2."
Unpaired Cross-Modal Interaction Learning for COVID-19 Segmentation on Limited CT Images,"the chestx-ray14 dataset comprises
112,120 x-ray images showing positive cases from 30,805 patients, encompassing
14 disease image labels pertaining to thoracic and lung ailments."
Structure-Preserving Instance Segmentation via Skeleton-Aware Distance Transform,none
DAST: Differentiable Architecture Search with Transformer for 3D Medical Image Segmentation,none
MultiTalent: A Multi-dataset Approach to Medical Image Segmentation,none
Co-assistant Networks for Label Correction,none
Pre-trained Diffusion Models for Plug-and-Play Medical Image Enhancement,"however,
ct imaging has relatively high radiation doses that can pose a risk of radiation
exposure to patients."
Pre-trained Diffusion Models for Plug-and-Play Medical Image Enhancement,"this makes mr imaging safer for patients, particularly for those who require
frequent or repeated scans."
Robust T-Loss for Medical Image Segmentation,none
Multi-Head Multi-Loss Model Calibration,none
Guiding the Guidance: A Comparative Analysis of User Guidance Signals for Interactive Segmentation of Volumetric Images,"we discard the
513 tumor-free patients, leaving us with 501 volumes."
Laplacian-Former: Overcoming the Limitations of Vision Transformers in Local Texture Detection,none
Understanding Silent Failures in Medical Image Classification,none
Evidence Reconciled Neural Network for Out-of-Distribution Detection in Medical Images,none
Scale-Aware Test-Time Click Adaptation for Pulmonary Nodule and Mass Segmentation,"the main reason is that the lesion scale in the
two public datasets are relatively small, which matches the fact few patients
have very large nodule or mass."
WeakPolyp: You only Look Bounding Box for Polyp Segmentation,none
Shifting More Attention to Breast Lesion Segmentation in Ultrasound Videos,"note that the breast lesion locations of neighboring ultrasound video frames are
close, while the breast lesion location distance is large for different
ultrasound videos, which are often obtained from different patients."
ACC-UNet: A Completely Convolutional UNet Model for the 2020s,none
FocalUNETR: A Focal Transformer for Boundary-Aware Prostate Segmentation Using CT Images,none
Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,"the camus dataset [20] contains cardiac ultrasounds from 500 patients,
for which two-chamber and four-chamber sequences were acquired.manual
annotations for the endocardium and epicardium borders of the left ventricle
(lv) and the left atrium were obtained from a cardiologist for the end-diastolic
(ed) and end-systolic (es) frames."
Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,"the dataset is split into 400 training
patients, 50 validation patients, and 50 testing patients."
Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,"this is a proprietary multi-site multi-vendor dataset
containing 2d echocardiograms of apical two and four chambers from 890 patients."
Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,"data comes from patients diagnosed with coronary artery disease, covid, or
healthy volunteers."
Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation,"the dataset is split into a training/validation set (80/20)
and an independent test set from different sites, comprised of 994
echocardiograms from 684 patients and 368 echocardiograms from 206 patients,
respectively."
DHC: Dual-Debiased Heterogeneous Co-training Framework for Class-Imbalanced Semi-supervised Medical Image Segmentation,none
Anatomical-Aware Point-Voxel Network for Couinaud Segmentation in Liver CT,none
HENet: Hierarchical Enhancement Network for Pulmonary Vessel Segmentation in Non-contrast CT Images,"although contrast-enhanced ct images have better
contrast for pulmonary vessels compared to non-contrast ct images, the
acquisition of contrast-enhanced ct images needs to inject a certain amount of
contrast agent to the patients."
HENet: Hierarchical Enhancement Network for Pulmonary Vessel Segmentation in Non-contrast CT Images,"some patients have concerns about the possible
risk of contrast media [2]."
Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels,"kits includes 210 annotated ct scans of kidney tumors from different
patients."
Semi-supervised Domain Adaptive Medical Image Segmentation Through Consistency Regularized Disentangled Contrastive Learning,"brats consists of brain mris from 285 patients with t1, t2, t1ce, and flair
scans."
BerDiff: Conditional Bernoulli Diffusion Model for Medical Image Segmentation,"brats 2021 consists of four different
sequence (t1, t2, flair, t1ce) mri images for each patient."
BerDiff: Conditional Bernoulli Diffusion Model for Medical Image Segmentation,"our training set includes 55,174 2d images scanned from 1,126 patients,
and the test set comprises 3,991 2d images scanned from 125 patients."
Annotator Consensus Prediction for Medical Image Segmentation with Diffusion Models,none
Anti-adversarial Consistency Regularization for Data Augmentation: Applications to Robust Medical Image Segmentation,none
Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk,"relevant to the field of multimodal segmentation are also
developments on unpaired multimodal segmentation, where cross-modality learning
is employed to take advantage of different image modalities covering the same
anatomy, but without the constraint to collect images from the same patients
[5,10,19]."
Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk,"although the methodologies comprising cyclegans and/or multiple
segmentation networks [10,19] seem promising, they can be excessively complex
for the task of han oar segmentation where both ct and mr image modalities from
the same patient are often available."
Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk,"when segmenting oars in the han region for the purpose of
rt planning, a multimodal segmentation model that can leverage the information
from ct and mr images of the same patient might be beneficial compared to
separate single-modal models."
Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk,"this can be mitigated with
image registration, but not completely, mainly due to different patient
positioning that especially affects the deformation of soft tissues, and various
modality-specific artifacts (e.g."
Multimodal CT and MR Segmentation of Head and Neck Organs-at-Risk,"the han-seg dataset comprises ct and t1-weighted mr images of 56 patients, which
were deformably registered with the simpleelastix registration tool, and
corresponding curated manual delineations of 30 oars (for details, please refer
to [14])."
Learning Reliability of Multi modality Medical Images for Tumor Segmentation via Evidence Identified Denoising Diffusion Probabilistic Models,none
Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network,"to avoid data
leakage and bias, we selected the train, test, and validation sets based on the
cases, i.e., the images from one case (patient) were assigned to only one of the
training, validation, and test sets."
SwinUNETR-V2: Stronger Swin Transformers with Stagewise Convolutions for 3D Medical Image Segmentation,none
SimPLe: Similarity-Aware Propagation Learning for Weakly-Supervised Breast Cancer Segmentation in DCE-MRI,"early diagnosis and treatment is beneficial to improve the
survival rate and prognosis of breast cancer patients."
SimPLe: Similarity-Aware Propagation Learning for Weakly-Supervised Breast Cancer Segmentation in DCE-MRI,"the method obtained a dice value
of 83% using the interval-slice annotation, on a testing dataset containing only
28 patients.in this study, we propose a simple yet effective weakly-supervised
strategy, by using extreme points as annotations (see fig."
Uncertainty-Informed Mutual Learning for Joint Medical Image Classification and Segmentation,"a total of 157 patients who suffer
the breast cancer are considered -43 achieve pcr and 114 non-pcr.for each case,
we cut out the slices in the 3d image and totally got 1,570 2d images, which are
randomly divided into the train, validation, and test datasets with 1,230, 170,
and 170 slices, respectively."
Conditional Diffusion Models for Weakly Supervised Medical Image Segmentation,none
DBTrans: A Dual-Branch Vision Transformer for Multi-Modal Brain Tumor Segmentation,"compared with natural images,
medical image segmentation often requires higher accuracy to make subsequent
treatment plans for patients."
HartleyMHA: Self-attention in Frequency Domain for Resolution-Robust and Parameter-Efficient 3D Image Segmentation,none
MDViT: Multi-domain Vision Transformer for Small Medical Image Segmentation Datasets,none
M-GenSeg: Domain Adaptation for Target Modality Tumor Segmentation with Annotation-Efficient Supervision,none
Edge-Aware Multi-task Network for Integrating Quantification Segmentation and Uncertainty Prediction of Liver Tumor on Multi-modality Non-contrast MRI,"simultaneous multi-index quantification (i.e., max diameter (md), center point
coordinates (x o , y o ), and area), segmentation, and uncertainty prediction of
liver tumor have essential significance for the prognosis and treatment of
patients [6,16]."
RCS-YOLO: A Fast and High-Accuracy Object Detector for Brain Tumor Detection,none
Certification of Deep Learning Models for Medical Image Segmentation,"indeed, segmentation techniques and variations of 2d
and 3d u-nets are currently the state-of-the-art to identify and isolate tumors,
blood vessels, organs, or other structures within an image and provide crucial
help to physicians for medical diagnosis, screening, and prognosis
[32].nowadays, segmentation models are gaining widespread adoption in modern
clinical practice and are being used with increasing frequency, making the
results of these models critical for many patients."
Category-Level Regularized Unlabeled-to-Labeled Learning for Semi-supervised Prostate Segmentation with Multi-site Unlabeled Data,"unfortunately, such ""abundance"" may be unobtainable in practice, i.e., the
local unlabeled pool is also limited due to restricted image collection
capabilities or scarce patient samples."
Category-Level Regularized Unlabeled-to-Labeled Learning for Semi-supervised Prostate Segmentation with Multi-site Unlabeled Data,"yet, due to differences
in imaging protocols and variations in patient demographics, this solution
usually introduces data heterogeneity, lead-ing to a quality problem."
Category-Level Regularized Unlabeled-to-Labeled Learning for Semi-supervised Prostate Segmentation with Multi-site Unlabeled Data,"inherently, the challenge of ms-ssl stems from
intra-class variation, which results from different imaging protocols, disease
progress and patient demographics."
Category-Level Regularized Unlabeled-to-Labeled Learning for Semi-supervised Prostate Segmentation with Multi-site Unlabeled Data,"compared
to c1 and c2, scans from c3 to c6 are taken from patients with prostate cancer,
either for detection or staging purposes, which can cause inherent semantic
differences in the prostate region to further aggravate heterogeneity."
A Sheaf Theoretic Perspective for Robust Prostate Segmentation,none
MedNeXt: Transformer-Driven Scaling of ConvNets for Medical Image Segmentation,none
Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,"it enables the
extraction of semi-quantitative metrics such as standardized uptake values
(suvs), which normalize pixel intensities based on patient weight and
radiotracer dose [20]."
Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,"however, the performance of kspc depends heavily on the
tuning parameters of bandwidth and threshold in the model, and it lacks
information from other patients.beyond tumour delineation, another important use
of functional images, such as pet images is their use for designing imrt dose
painting (dp)."
Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,"the hecktor training dataset consists of 224 patients
diagnosed with oropharyngeal cancer [1]."
Deep Probability Contour Framework for Tumour Segmentation and Dose Painting in PET Images,"for each patient, fdg-pet input images
and corresponding labels in binary description (0 s and 1 s) for the primary
gross tumour volume are provided and co-registered to a size of 144 × 144 × 144
using bounding box information encompassing the tumour."
A2FSeg: Adaptive Multi-modal Fusion Network for Medical Image Segmentation,none
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"[1] proposed a random forest model [2], which adopts the radiomics features [3]
of the brain tumor images, to predict the overall survival (os) time of diffuse
glioma patients."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"in this way, inconsistency between the augmented features and the corresponding
labels can be effectively reduced.our method is evaluated using pre-operative
multimodal mr brain images of 1726 diffuse glioma patients collected from
cooperation hospitals and a public dataset brats2019 [12] containing multimodal
mr brain images of 210 patients."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"the survival prediction backbone is a deep cox proportional hazard model [14]
which takes the multimodal mr brain images of diffuse glioma patients as inputs
and predicts the corresponding risks."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"the tumor subtyping network is a
classification network, which classifies the patient tumor types and feeds the
learned tumor-type-related features to the backbone to enhance the survival
prediction performance.the tumor subtyping network is trained independently
before being integrated into the backbone."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"assume that d = {x 1 , ...,
x n } is the dataset containing pre-operative multimodal mr brain images of
diffuse glioma patients, and n is the number of patients."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"the backbone is
responsible for deriving features from x i to predict the risk of the patient."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"in addition, information of patient age and tumor
position is also used."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"the backbone is based on the
deep cox proportional hazard model, and the loss function is defined as:where h
θ (x i ) represents the risk of the i-th patient predicted by the backbone, θ
stands for the parameters of the backbone, x i is the input multimodal mr brain
images of the i-th patient, r(t i ) is the risk group at time t i , which
contains all patients who are still alive before time t i , t i is the observed
time (time of death happened) of x i , and δ i = 0/1 for censored/non-censored
patient."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"the cross entropy is adopted as
the loss function of the tumor subtyping network, which is defined as:where y k
i and p k i are the ground truth (0 or 1) and the prediction (probability) of
the k-th tumor type (k = 1, 2, 3) of the i-th patient, respectively."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"specifically, the augmented feature fi∼j and label ȳi∼j is defined
as:where y k i and y k j stand for the labels of the k-th tumor type of the i-th
and j-th patients, respectively, and λ ∈ [0, 1] is a weighting factor."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"as aforementioned, the survival time
of patients with different tumor types varies largely (oligodendroglioma >
astrocytoma > glioblastoma), so the tumor types can be regarded as risk grade,
which are ordered rather than categorical."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"finally, the ordinal loss, which is in the form of kl
divergence, is defined as:in our method, μ k and σ 2 k are calculated bywhere φ
θ and g are the encoder and gap of the tumor subtyping network, respectively, θ
is the parameter set of the encoder,stands for the subset containing the
pre-operative multimodal mr brain images of the patients with the k-th tumor
type, n k is the patient number in d k ."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"in the training stage of the
tumor subtyping network, each input batch contains pre-operative multimodal mr
brain images of n patients and can be divided into k = 3 subsets according to
their corresponding tumor types, i.e., d k , k = 1, 2, 3."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"specifically, the in-house dataset collected in cooperation hospitals
contains pre-operative multimodal mr images, including t1, t1 contrast enhanced
(t1c), t2, and flair, of 1726 patients (age 49.7 ± 13.1) with confirmed diffuse
glioma types."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"the patient number of each tumor type is 361 (oligodendroglioma),
495 (astrocytoma), and 870 (glioblastoma), respectively."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"in the 1726 patients,
743 have the corresponding overall survival time (dead, non-censored), and 983
patients have the last visiting time (alive, censored)."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"besides the inhouse
dataset, a public dataset brats2019, including pre-operative multimodal mr
images of 210 non-censored patients (age 61.4 ± 12.2), is adopted as the
external independent testing dataset."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"according to the bounding boxes of all
1936 patients, the size of input 3d image patch is set to 96 × 96 × 64 voxels,
which can cover the entire tumor of every patient.besides our method, four
state-of-the-art methods, including random forest based method (rf) [18], deep
convolutional survival model (deepconvsurv) [19], multi-channel survival
prediction method (mcsp) [20], and imaging phenotype and genotype based survival
prediction method (pgsp) [9], are evaluated."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"concordance index (c-index) is adopted to quantify the
prediction accuracy:where d = {x 1 , ..., x n } is the dataset containing all
patients, t i and t j are ground truth of survival times of the i-th and j-th
patients, r i and r j are the days predicted by rf, mcsp, and pgsp or risks
predicted by the deep cox proportional hazard models (i.e., deepconvsurv and our
method), 1 x<y = 1 if x < y, else 0, and δ i = 0 or 1 when the i-th patient is
censored or non-censored."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"as rf, mcsp, and pgsp cannot use the censored data in
the in-house dataset, 80% of the non-censored data (594 patients) are randomly
selected as the training data, and the rest 20% non-censored data (149 patients)
are for testing."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"while deepconvsurv and our method are deep cox models, both
censored and non-censored patients can be utilized."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"so besides the 80%
non-censored patients, all censored data (983 patients) are also included in the
training data.table 1 shows the evaluation results of the in-house and the
external independent (brats2019) testing datasets using all methods under
evaluation."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"we proposed a new method for pre-operative survival prediction of diffuse glioma
patients, where a tumor subtyping network is integrated into the prediction
backbone."
Pre-operative Survival Prediction of Diffuse Glioma Patients with Joint Tumor Subtyping,"both in-house and public
datasets containing 1936 patients were used in the experiment."
Medical Boundary Diffusion Model for Skin Lesion Segmentation,none
H-DenseFormer: An Efficient Hybrid Densely Connected Transformer for Multimodal Tumor Segmentation,"pi-cai22
provides multimodal mr images of 220 patients with prostate cancer, including
t2-weighted imaging (t2w), high b-value diffusion-weighted imaging (dwi), and
apparent diffusion coefficient (adc) maps."
TransNuSeg: A Lightweight Multi-task Transformer for Nuclei Segmentation,"for both datasets, we randomly split
80% of the samples on the patient level as the training set and the remaining
20% as the test set."
Learnable Cross-modal Knowledge Distillation for Multi-modal Learning with Missing Modality,none
QCResUNet: Joint Subject-Level and Voxel-Level Prediction of Segmentation Quality,none
EGE-UNet: An Efficient Group Enhanced UNet for Skin Lesion Segmentation,none
Diffusion Kinetic Model for Breast Cancer Segmentation in Incomplete DCE-MRI,"however, the
aforementioned methods require the complete dce-mri sequences and overlook the
difficulty in assessing complete temporal sequences and the missing time point
problem, especially post-contrast phase, due to the privacy protection and
patient conditions."
Diffusion Kinetic Model for Breast Cancer Segmentation in Incomplete DCE-MRI,"dataset: to demonstrate the effectiveness of our proposed dkm, we evaluate our
method on 4d dce-mri breast cancer segmentation using the breast-mri-nact-pilot
dataset [13], which contains a total of 64 patients with the contrastenhanced
mri protocol: a pre-contrast scan, followed by 2 consecutive postcontrast time
points (as shown in fig."
Morphology-Inspired Unsupervised Gland Segmentation via Selective Semantic Grouping,none
EoFormer: Edge-Oriented Transformer for Brain Tumor Segmentation,"the brats 2020 dataset [14]
consists of mri image data from 369 patients, with each patient having four
modalities (t1, t1ce, t2 and t2-flair) of skull-striped mri, which are aligned
to a standard brain template."
EoFormer: Edge-Oriented Transformer for Brain Tumor Segmentation,"the training/validation/test split follows
315/16/37 according to recent works [10,23].the medseg dataset includes mri
images of t1, t1ce, t2, and t2 flair modalities from 255 patients with
medulloblastoma."
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"while the em pattern may appear simple to recognize,
its diagnosis can be challenging for those with or without a medical background
alike, as only 20% of united states patients have the stereotypical bull's eye
lesion [6]."
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"such dl-assisted segmentation not only helps clinicians in pre-screening
patients but also improves downstream tasks such as lesion classification."
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"our lyme
disease dataset contains two parts: (i) a classification dataset, composed of
more than 3,000 diseased skin images that are either obtained from public
resources or clinicians with patient-informed consent, and (ii) a segmentation
dataset containing 185 samples that are manually annotated for three
regions-i.e., background, skin (light vs."
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"all skin images are either collected from publicly
available sources or from clinicians with patient informed consent."
EdgeMixup: Embarrassingly Simple Data Alteration to Improve Lyme Disease Lesion Segmentation and Diagnosis Fairness,"one
prominent observation is that ls images are more abundant than ds images due to
a disparity in the availability of ds imagery found from either public sources
or from clinicians with patient consent."
Factor Space and Spectrum for Medical Hyperspectral Image Segmentation,"following [23,27], we partition the datasets into training, validation, and
test sets using a patient-centric hard split approach with a ratio of 3:1:1."
Factor Space and Spectrum for Medical Hyperspectral Image Segmentation,"specifically, each patient's data is allocated entirely to one of the three
sets, ensuring that the same patient's data do not appear in multiple sets.we
use data augmentation techniques such as rotation and flipping, and train with
an adam optimizer using a combination of dice loss and cross-entropy loss for 8
batch size and 100 epochs."
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,"the periodic acquisition and analysis of volumetric ct and mri scans of oncology
patients is essential for the evaluation of the disease status, the selection of
the treatment, and the response to treatment."
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,"currently, scans are acquired
every 2-12 months according to the patient's characteristics, disease stage, and
treatment regime."
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,"as
treatments improve and patients live longer, the number of scans in longitudinal
studies increases and their interpretation is more challenging and
time-consuming.radiological follow-up requires the quantitative analysis of
lesions and patterns of lesion changes in subsequent scans."
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,"experimental results on lung (83 cts, 19 patients) and liver (77 cects, 18
patients) datasets show that our method yields high classification accuracy.to
the best of our knowledge, ours is the first method to perform longitudinal
lesion matching and lesion changes pattern detection."
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,", s n be a series of n ≥ 2 consecutive patient scans
acquired at timesis a set of vertices v i j corresponding to the lesions
associated with the lesion segmentation masks l i = l i 1 , l i 2 , ."
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,"we evaluated our method with two studies on retrospectively collected patient
datasets that were manually annotated by an expert radiologist.dataset: lung and
liver ct studies were retrospectively obtained from two medical centers
(hadassah univ hosp jerusalem israel) during the routine clinical examination of
patients with metastatic disease."
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,"each patient study consists of at least 3
scans.dlung consists of 83 chest ct scans from 19 patients with a mean 4.4 ± 2.0
scans/patient, a mean time interval between consecutive scans of 125.9 ± 81.3
days, and voxel sizes of 0.6-1.0 × 0.6-1.0 × 1.0-3.0 mm 3 ."
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,"dliver consists of
77 abdominal cect scans from 18 patients with a mean 4.3 ± 2.0 scans/patient, a
mean time interval between consecutive scans of 109.7 ± 93.5 days, and voxel
sizes of 0.6-1.0 × 0.6-1.0 × 0.8-5.0 mm 3 .lesions in both datasets were
annotated by an expert radiologist, yielding a total of 1,178 lung and 800 liver
lesions, with a mean of 14.2 ± 19.1 and 10.4 ± 7.9 lesions/scan (lesions with
<20 voxels were excluded)."
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,"the use of graph-based methods for lesion tracking and detection of patterns of
lesion changes was shown to achieve high accuracy in classifying changes in
individual lesion and identifying patterns of lesion changes in liver and lung
longitudinal ct studies of patients with metastatic disease."
Graph-Theoretic Automatic Lesion Tracking and Detection of Patterns of Lesion Changes in Longitudinal CT Studies,"this approach has
proven to be useful in detecting missed, faint, and surmised to be present
lesions, otherwise hardly detectable by examining the scans separately or in
pairs, leveraging the added information provided by evaluating all patient's
scans simultaneously using the labels from the lesion changes graph and
non-consecutive edges."
Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"neuropsychiatric systemic lupus erythematosus (npsle) refers to a complex
autoimmune disease that damages the brain nervous system of patients."
Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"the
clinical symptoms of npsle include cognitive disorder, epilepsy, mental illness,
etc., and patients with npsle have a nine-fold increased mortality compared to
the general population [11]."
Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"however, the high overlap of clinical symptoms with other
psychiatric disorders and the absence of early non-invasive biomarkers make
accurate diagnosis difficult and time-consuming [3].although conventional
magnetic resonance imaging (mri) tools are widely used to detect brain injuries
and neuronal lesions, around 50% of patients with npsle present no brain
abnormalities in structural mri [17]."
Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"figure 1
shows spectra images of four participants including healthy controls (hc) and
patients with npsle."
Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"it can be seen that the visual differences between patients
with npsle and hcs in the spectra of the volumes are subtle."
Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"dataset and preprocessing: the t2-weighted mr images of 39 participants
including 23 patients with npsle and 16 hcs were gathered from our affiliated
hospital."
Robust Exclusive Adaptive Sparse Feature Selection for Biomarker Discovery and Early Diagnosis of Neuropsychiatric Systemic Lupus Erythematosus,"we also found
that glu+gln/cr+pcr in ri decreased, which indicates that the excitatory
neurotransmitter glu in the brain of patients with npsle may have lower
activity."
CARL: Cross-Aligned Representation Learning for Multi-view Lung Cancer Histology Classification,"exclusion criteria involves
patients diagnosed with large cell carcinoma or not otherwise specified, along
with cases that have contouring inaccuracies or lacked tumor delineation [9,13]."
CARL: Cross-Aligned Representation Learning for Multi-view Lung Cancer Histology Classification,"in summary, we propose a novel multi-view method called cross-aligned
representation learning (carl) for accurately distinguishing between adc and scc
using multi-view ct images of nsclc patients."
Self- and Semi-supervised Learning for Gastroscopic Lesion Detection,"some appearances of lesions are quite
rare and can only be observed in a few patients."
Self- and Semi-supervised Learning for Gastroscopic Lesion Detection,"collection : lgmdd collects about 1m+ gastroscopic
images from 2 hospitals of about 500 patients and their diagnosis reports."
Revisiting Feature Propagation and Aggregation in Polyp Segmentation,none
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","in the uk, approximately 11,500 patients are diagnosed with rectal cancer each
year [19]."
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","a common form of treatment for such patients is neoadjuvant therapy,
including chemotherapy and radiotherapy, which can be given to patients with
locally advanced rectal cancer to shrink the tumour prior to surgery."
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","recent
evidence suggests that 10-20% of patients will have a complete pathological
response to neoadjuvant therapy and can therefore avoid surgery altogether
[2,5]."
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","however, one third of patients do not benefit from radiotherapy treatment
prior to surgery [8], hence it is important to determine how a patient will
respond to radiotherapy with a personalized approach in order to avoid
overtreatment.histology-based digital biomarkers enable the possibility to
predict a patient's response to therapy."
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","various studies have investigated the link between cms and patient outcomes,
suggesting that patients with tumour classified as cms4, which features stromal
invasion [9] and shows significantly higher stroma content [15], have worse
survival rates compared to the other cms classes [5]."
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","other work has looked at predicting
chemoradiotherapy response in rectal cancer patients from h&e images using
different approaches, but without providing contextual interpretations
[19,22].as opposed to predicting response to radiotherapy alone, we aim to
analyse this prediction in the context of the overall tissue architecture and
the tumour biology as captured by cms."
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","pathologists and oncologists can use this information to inspect the validity of
the prediction result and interrogate key aspects of the spatial biology that is
critical for patient management."
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","we achieve 0.82 auc predicting
complete response to radiotherapy using deep learning on wsis for crc patients,
whilst providing novel interpretability of the results."
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","these epithelial segmentation masks were generated at 10x
magnification (1 µm 2 /pixel) with a u-net [17] which was trained and validated
on 666 full tissue sections belonging to 362 patients from the focus cohort
[18]."
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","grampian and aristotle are used in both
training and validation, with a 70/30% training-validation split, keeping any
wsis from a single patient in the same dataset."
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","there are 365 slides total in our dataset, from 249
patients."
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","for example, the model demonstrates that
cms4 patients are less likely to respond to radiotherapy."
"Joint Prediction of Response to Therapy, Molecular Traits, and Spatial Organisation in Colorectal Cancer Biopsies","importantly, this level of visualisation is not
only accessible to pathologists, this joint prediction model also enhances the
communication between pathologists and oncologists which is critical for patient
management."
Automatic Bleeding Risk Rating System of Gastric Varices,"esophagogastric varices are one of the common manifestations in patients with
liver cirrhosis and portal hypertension and occur in about 50 percent of
patients with liver cirrhosis [3,6]."
Automatic Bleeding Risk Rating System of Gastric Varices,"the occurrence of esophagogastric variceal
bleeding is the most serious adverse event in patients with cirrhosis, with a
6-week acute bleeding mortality rate as high as 15%-20% percent [14]."
Automatic Bleeding Risk Rating System of Gastric Varices,"it is
crucial to identify high-risk patients and offer prophylactic treatment at the
appropriate time."
Automatic Bleeding Risk Rating System of Gastric Varices,"in this work, we collect a gv bleeding risks rating dataset
(gvbleed) that contains 1678 gastroscopy images from 411 patients with different
levels of gv bleeding risks."
Automatic Bleeding Risk Rating System of Gastric Varices,"all of these cases are collected
from 411 patients in a grade-iii class-a hospital during the period from 2017 to
2022."
Automatic Bleeding Risk Rating System of Gastric Varices,"in the current version, images from patients with ages elder than 18 are
retained 1 ."
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"implicit biases can negatively affect patient
care, particularly for marginalized populations with lower socioeconomic status
[30]."
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"in an algorithm used to predict healthcare costs, black patients who received
the same health risk scores as white patients were consistently sicker [21]."
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"black patients exhibit a 50% higher
age-standardized pe fatality rate and a twofold risk for pe hospitalization than
white patients [18,24]."
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"hospitalized black patients with pe were younger than
whites."
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"racial disparities exist
in pe and demonstrate the inequities that affect black patients."
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the pulmonary embolism dataset used in this study from 918
patients (163 deceased, median age 64 years, range 13-99 years, 52% female),
including 3978 ctpa images and 918 clinical reports, which were identified via
retrospective review across three institutions."
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"for each patient, the race labels, survival time-to-event labels and
pesi variables are collected from clinical data, and the 11 pesi variables are
used to calculate the pesi scores, which include age, sex, comorbid illnesses
(cancer, heart failure, chronic lung disease), pulse, systolic blood pressure,
respiratory rate, temperature, altered mental status, and arterial oxygen
saturation at the time of diagnosis [2].diverse bias of multimodal survival
prediction model."
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the feature with the highest pe
probability from a patient's multiple ctpas is considered as the most pe-related
visual representation."
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"next, the gatortron [29] model is employed to recognize
clinical concepts and identify medical relations for getting accurate patient
information from pe clinical reports."
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the framework also consists of a cox proportional hazard (coxph) model [7] that
is trained to predict patient ranking using a multimodal combination of risk
predictions from the above three sp modules."
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"these coxph models calculate the
corresponding time-to-event evaluation and predict the fusion of patients' risk
as the survival outcome."
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"besides, clinical data in the form of text
reports and pesi variables objectively reflect the patient's physiological
information and the physician's diagnosis, exhibiting smaller race biases in
correlation with survival across different races."
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the outputs from each patient's medical history, clinical
diagnosis, observations, and radiologist impression are separately generated and
concatenated to form the 1024 × 4 features.we build the encoders of the baseline
sp modules and de-biased sp modules with multi-layer perceptron (mlp) neural
networks and relu activation."
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"3, is used to compare
the survival prediction between high-risk and lowrisk patient groups."
Improving Outcome Prediction of Pulmonary Embolism by De-biased Multi-modality Model,"the proposed de-biased method has already shown the
capacity to relieve them, which is vital when serving patients with an accurate
analysis."
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"however, these imaging
techniques are expensive and add additional burdens for the patient."
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"recently, deep
neural network based models that predict a patient's risk score directly from
mammograms have shown promising results [3,8,9,20,33]."
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"these models do not
require additional patient information and have been shown to outperform
traditional statistical models.when prior mammograms are available, radiologists
compare prior exams to the current mammogram to aid in the detection of breast
cancer."
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"integrating prior mammograms into deep learning
models for breast cancer risk prediction can provide a more comprehensive
evaluation of a patient's breast health.in this paper, we introduce a deep
neural network that makes use of prior mammograms, to assess a patient's risk of
developing breast cancer, dubbed prime+ (prior mammogram enabled risk
prediction)."
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"we hypothesize that mammographic parenchymal pattern changes
between current and prior allow the model to better assess a patient's risk."
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"our
method is based on a transformer model that uses attention [30], similar to how
radiologists would compare current and prior mammograms.the method is trained
and evaluated on a large and diverse dataset of over 9,000 patients and shown to
outperform a model based on state-of-the art risk prediction techniques for
mammography [33]."
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"for medical applications, x typically
represents patient information like age, family history, genetic makeup, and
diagnostic test results (e.g., a mammogram)."
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"1).we typically want to estimate the hazard function h(t),
which measures the rate at which patients experience the event of interest at
time t, given that they have survived up to that point."
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"specifically, h(t) is 1 if the
patient is diagnosed with cancer within t years and 0 otherwise."
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"we compiled an in-house mammography dataset comprising 16,113 exams (64,452
images) from 9,113 patients across institutions from the united states, gathered
between 2010 and 2021."
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"we partitioned the dataset by patient to create
training, validation, and test sets."
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"the validation set contains 800 exams (198
cancer, 210 benign, 392 normal) from 400 patients, and the test set contains
1,200 exams (302 cancer, 290 benign, 608 normal) from 600 patients."
Enhancing Breast Cancer Risk Prediction by Incorporating Prior Images,"our results suggest that
incorporating changes in patients using prior mammograms and a transformer
decoder improves the performance of breast cancer risk prediction
models.analysis based on density."
Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"for the ldct, we annotate more than 12,852 nodules from 8,271 patients
from the nlst dataset [14]."
Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"for the ncct, we annotate over 4,029 nodules from
over 2,565 patients from our collaborating hospital."
Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"there are 8,271 patients
enrolled in this study."
Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"1 j ← seg loss(m, s) + 3 i=1 cls loss(y, p i ) update loss18: end for patient,
and
localized and labeled the nodules in the scan as benign or malignant based on
the rough candidate nodule location and whether the patient develops lung cancer
provided by nlst metadata."
Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"the in-house cohort was retrospectively collected from 2,565 patients
at our collaborating hospital between 2019 and 2022."
Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"the training set contains 9,910 (9,413 benign and 497 malignant) nodules from
6,366 patients at nlst, and 2,592 (843 benign and 1,749 malignant) nodules from
2,113 patients at the in-house cohort."
Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"the validation set contains 1,499 (1,426
benign and 73 malignant) nodules from 964 patients at nlst."
Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"the nlst test set
has 1,443 (1,370 benign and 73 malignant) nodules from 941 patients."
Parse and Recall: Towards Accurate Lung Nodule Malignancy Prediction Like Radiologists,"the
in-house test set has 1,437 (1,298 benign and 139 malignant) nodules from 452
patients."
M&M: Tackling False Positives in Mammography with a Multi-view and Multi-instance Learning Sparse Detector,"we split the
data into train/val/test with an 80:10:10 ratio at the patient level; (2)
inhouse-a: an evaluation dataset collected from a u.s."
Reversing the Abnormal: Pseudo-Healthy Generative Networks for Anomaly Detection,"stroke is
a leading cause of death and disability, where early detection and treatment can
significantly improve patient outcomes."
Reversing the Abnormal: Pseudo-Healthy Generative Networks for Anomaly Detection,"we believe that our proposed method will open new avenues
for interpretable, fast, and accurate anomaly segmentation and support various
clinical-oriented downstream tasks, such as investigating progression of
disease, patient stratification and treatment planning."
SHISRCNet: Super-Resolution and Classification Network for Low-Resolution Breast Cancer Histopathology Image,"accurate identification of cancer
types will make a correct assessment of the patient's risk and improve the
chances of survival."
SHISRCNet: Super-Resolution and Classification Network for Low-Resolution Breast Cancer Histopathology Image,"considering the improvement of
histopathological images' acquisition equipment will cost lots of money while
significantly increasing patients' expense of detection."
Text-Guided Foundation Model Adaptation for Pathological Image Classification,"to extend our
evaluation into the real-world setting with insufficient data, we additionally
choose 1, 2, 4, 8, or 16 wsis with the largest numbers of patches from each
class as the training set.the evaluation metric is patient-wise accuracy, where
the prediction of a wsi is obtained by a soft vote over the patches, and
accuracy is averaged class-wise.implementation."
Distributionally Robust Image Classifiers for Stroke Diagnosis in Accelerated MRI,"nevertheless, the long acquisition time for a
brain mri (20 to 30 min) imposes challenges, especially in cases of acute stroke
where rapid diagnosis is essential and patient movement during this distressing
period of time commonly limits evaluation."
Distributionally Robust Image Classifiers for Stroke Diagnosis in Accelerated MRI,"our dataset included mri brain scans from 226 patients performed at an urban
tertiary referral academic medical center that is a comprehensive stroke center."
Distributionally Robust Image Classifiers for Stroke Diagnosis in Accelerated MRI,"clinical scans of adult patients aged 18-89 years with recent (acute or
subacute) strokes were identified between 1/1/2013 and 1/1/2021 for inclusion in
this study via a search of the philips performance bridge."
Distributionally Robust Image Classifiers for Stroke Diagnosis in Accelerated MRI,"scans meeting this
criteria were downloaded and simultaneously anonymized to preserve patient
anonymity and prevent disclosure of protected health information as part of this
irb exempt study."
Distributionally Robust Image Classifiers for Stroke Diagnosis in Accelerated MRI,"no patient demographic information was retained for the scans,
as it was considered to represent an unnecessary risk for accidental release of
protected health information."
Contrastive Feature Decoupling for Weakly-Supervised Disease Detection,none
Multiple Prompt Fusion for Zero-Shot Lesion Detection Using Vision-Language Models,none
Fast Non-Markovian Diffusion Model for Weakly Supervised Anomaly Detection in Brain MR Images,none
MUVF-YOLOX: A Multi-modal Ultrasound Video Fusion Network for Renal Tumor Diagnosis,"compared with ct and mri, ceus is radiation-free,
cost-effective, and safe in patients with renal dysfunction."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"despite this, the clinical
pathological analysis presents certain challenges and complexities, with the
ultimate diagnosis relying on patients rather than slides.specifically, in
clinical problems of pathological image analysis, doctors usually summarize
patient-level labels based on slide labels as the diagnostic results [1,6]."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"for
example, for the pathological discrimination diagnosis task of intestinal
tuberculosis(itb) and crohn's desease(cd), the categories of postoperative
slides are divided into three types (normal, cd, itb), and doctors will
summarize the binary results of patients (itb or cd) based on slide-level labels
[6]."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"similar situations exist in other tasks, such as the classification of
breast cancer metastases in lymph nodes, where slide categories may have
different classifications, and the corresponding diagnosis of the same patient
is whether the cancer has spread to the regional lymph nodes (n-stage) [1]."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"1, actual pathological image analysis involves the
relationships of patches, slides, and patients, which is called a multi-level
multi-instance learning (ml-mil) problem."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"among them, for patients and slides,
patients are bags while slides are instances, and for slides and patches, slides
are bags while patches are instances.there are generally two methods to solve
the ml-mil problem."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"the second method is
to treat slide-patient as a new mil problem according to the traditional mil
thinking, where slides are regarded as instances and patient labels as bags."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"although this method seems reasonable, the number of patients is usually
relatively small, and deep learning models usually require a large amount of
data for training."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"therefore, the insufficient number of samples at the
slide-patient level may make it difficult for the model to learn enough
information.to address the multi-level multi-instance learning (ml-mil) problem
in medical field, we propose a novel framework called patients and slides are
equal (p&sre)."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"inspired by the iterative labeling process in medical diagnosis,
this framework treats patients and slides as instances at the same level and
uses transformers and attention mechanisms to build connections between them."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"this simple yet effective method allows for interaction between patient-level
and slidelevel information to correct their respective features and improve
classification performance."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"our framework consists of two steps: first, at the
patch-slide level, a common mil framework is used to train a mil neural network
and obtain slide-level feature vectors; then, at the slide-patient level, we use
self-attention mechanisms to combine the slides of the same patient into
patient-level feature vectors, and treat these patient-level feature vectors
together with all slide-level feature vectors of the same patient as instances
at the same level, which are inputted into transformers for feature interaction
and prediction of patient-and slide-level labels."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"before this, no other
framework had directly tackled this specific problem, making our proposal a
ground-breaking step in the application of ml-mil in healthcare; 2) proposing a
simple yet highly effective method that leverages self-attention mechanisms and
transformer models to enhance the interaction between slide and patient
information."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"this innovative approach not only improves the classification
performance at the patient level but also at the slide level, showcasing its
effectiveness and versatility; 3) conducting extensive experiments on two
separate datasets."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"the second part is the patient-slide level mil,
which generates patient-level features using attention mechanism and interacts
the features with transformer."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"to enhance readability, we first provide the
following symbolization for ml-mil: for a patient x i , it has a patient-level
classification label y i ."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"for patient x i , there may exist n i slides s i ={s
j |j=1 to n i }, where the classification label for each slide s j is denoted as
z j ."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"here, i,j, and k are indices for patient, slide, and patch levels,
respectively."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"after performing patch-slide level mil, we move on to patient-slide level mil."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"in general mil algorithms, the patient is regarded as the bag and the slide as
the instance."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"however, considering the diagnostic process in clinical practice,
we propose to treat both patients and slides as instances at the same level."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"specifically, our p&sre framework for patient-slide level consists of two parts:
patient-level feature generation based on self-attention and patient-slide
feature interaction based on transformer [11].patient-level feature generation
based on self-attention."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"therefore, we directly use a fully connected (fc)
layer to integrate the feature-level features into patient-level features v i
through attention mechanism, serving as patient instances."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"then, we perform a weighted average of the vectors
based on this weight to obtain the patient feature v i :patient-slide feature
interaction based on transformer."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"after doctors summarize the patient-level results, they typically review the
slides to double-check the diagnosis results."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"this patient-slide feature
interaction (psfi) naturally lends itself to the construction of a transformer,
and information exchange and integration between slides and patient level are
bidirectional."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"by using the
self-attention-based transformer structure, each input token is treated equally
(i.e., viewed as the same instance level), and tokens can interact extensively
with each other, enabling mutual correction between patients and slides and even
between slides."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"specifically, we merge the slide feature set {h j } and the
patient feature v i into the input tokensand then input them into a multi-layer
transformer through self-attention and feed-forward neural network layers to
obtain the interaction information between slides and output tokens t out i
:where d is the dimension of the token, and t k and t l come from t in i ."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"finally, we obtain
the output tokensthen, all output tokens are input into a shared fc layer, and
the patient's predicted logits y i and the predicted classification logits {z j
|j = 1 to n i } for each slide are output.training progress and loss function."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"during training, we sampled one patient at a time and pre-extracted their
batch-level features for all slides, in order to save gpu memory."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"due to the
issue of class imbalance in both slide level and patient level, we use the lade
[7] loss function."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"cd-itb is a private dataset consisting of 853 slides from 163
patients, with binary patient-level labels of cd or itb in a ratio of 103:60 and
tri-class slide-level labels of cd, itb, and normal slides in a ratio of
436:121:296, respectively."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"on average, there were 5 slides per patient."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"we adopted a patient-level stratification
approach for 5-fold cross-validation, with 20% of the training set randomly
assigned as the validation set for each fold."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"camelyon17 [1] is a publicly dataset, and its
training set comprises 500 slides from 100 breast cancer patients with lymph
node metastases."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,there were 5 slides per patient on average.
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"the patients are divided into two
groups based on their pn stage, namely lymph node positive and lymph node
negative, in proportions of 24:76, respectively."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"following the reference [4], we employed a transformer with 8 heads and 8
layers in the patient-slide feature interactions."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"at
the patient level, we used two approaches for prediction: maxs, where the
feature of the instance that achieves the maximum positive probability from the
slide-level mil model is selected to patient-level model, and maxmins, where the
mean value of features of the maximum and minimum positive probability from the
slide-level mil model is selected to patient-level model.the results of 5-fold
cv at the slide and patient levels are reported in table 1 and table 2,
respectively."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"abmil with p&sre improves the f1 score from 0.565 to 0.579 for the
cd-itb dataset and from 0.529 to 0.571 for the camelyon17 dataset at the
slide-level, and improves the f1 score from 0.522 to 0.599 for the cd-itb
dataset and from 0.842 to 0.861 for the camelyon17 dataset at the patient-level."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"therefore, the ablation experiments demonstrate the effectiveness of p&sre in
enhancing the classification performance at both the slide and patient levels."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"for instance, we did
not explore the possibility of treating patches as an equivalent level to slides
and patients."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"the primary reason is that the vast number of patches required for
analysis is significantly larger than that of slides and patients, which
presents a computational challenge for training."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"we first classify the process from patch to slide to the patient in
medical pathology diagnosis as a multi-level mil problem."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"based on existing
state-of-the-art mil methods, we then extend the framework to p&sre, which
conducts feature extraction and interaction at the slide-patient level."
Patients and Slides are Equal: A Multi-level Multi-instance Learning Framework for Pathological Image Analysis,"by
introducing a transformer, the framework enables iterative interaction and
correction of information between patients and slides, resulting in better
performance at both the patient level and slide level compared to existing
state-of-the-art algorithms on two validation datasets."
Learning with Synthesized Data for Generalizable Lesion Detection in Real PET Images,none
What Do AEs Learn? Challenging Common Assumptions in Unsupervised Anomaly Detection,"finding anomalies in medical images is especially hard due to large
inter-patient variance of normality, the irregular appearance-, and often rare
occurrence of diseases."
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"neoadjuvant chemotherapy
can increase the likelihood of achieving a margin-negative resection and avoid
unnecessary surgery in patients with aggressive tumor types [23]."
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"providing
accurate and objective preoperative biomarkers is crucial for triaging patients
who are most likely to benefit from neoadjuvant chemotherapy."
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"however, current
clinical markers such as larger tumor size and high carbohydrate antigen (ca)
19-9 level may not be sufficient to accurately tailor neoadjuvant treatment for
patients [19]."
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"therefore, multi-phase contrast-enhanced ct has a great potential
to enable personalized prognostic prediction for pdac, leveraging its ability to
provide a wealth of texture information that can aid in the development of
accurate and effective prognostic models [2,10].previous studies have utilized
image texture analysis with hand-crafted features to predict the survival of
patients with pdacs [1], but the representational fig."
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"our proposed model has the
potential to be used in combination with clinical factors for risk
stratification and treatment decisions for patients with pdac."
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"between pdac and vesselsthe vascular involvement in patients with pdac affects
the resectability and treatment planning [5]."
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"in this study, we used data from shengjing hospital to train our method
with 892 patients, and data from three other centers, including guangdong
provincial people's hospital, tianjin medical university and sun yatsen
university cancer center for independent testing with 178 patients."
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"pdac masks for 340 patients were manually labeled by a
radiologist from shengjing hospital with 18 years of experience in pancreatic
cancer, while the rest were predicted using self-learning models [11,24] and
checked by the same annotator."
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"combining the texture-aware transformer and
regular structure information improved the results from 0.630 to 0.648, as tumor
invasion strongly affects the survival of pdac patients."
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"to demonstrate the added value of our signature as a tool to select
patients for neoadjuvant treatment before surgery, we plotted kaplan-meier
survival curves in fig."
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"we further stratify patients by our signature after
grouping them by tumor size and ca19-9, two clinically used preoperative
criteria for selection, and also age."
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"our signature could significantly stratify
patients in all cases and those in the high-risk group had worse outcomes and
might be considered as potential neoadjuvant treatment candidates (e.g."
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"33
high-risk patients with larger tumor size and high ca19-9)."
Improved Prognostic Prediction of Pancreatic Cancer Using Multi-phase CT by Integrating Neural Distance and Texture-Aware Transformer,"furthermore, our model can be combined with
established high-risk features to aid in the patient selections who might
benefit from neoadjuvant therapy before surgery."
DCAug: Domain-Aware and Content-Consistent Cross-Cycle Framework for Tumor Augmentation,none
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"the five-year survival rate for gc is approximately 33% [16],
which is mainly attributed to patients being diagnosed with advanced-stage
disease harboring unresectable tumors."
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"however, patients with
early-stage disease have a substantially higher five-year survival rate of
around 72% [16]."
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"it is a non-invasive, relatively
low-cost, and safe procedure that exposes patients to less radiation dose and
does not require the use of contrast injection that may cause serious side
effects (compared to multi-phase contrastenhanced ct)."
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"these results demonstrate the potential
of our approach for opportunistic screening of gastric cancer in asymptomatic
patients using non-contrast ct scans."
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"however, our framework is specifically designed
for noncontrast ct scans, which is beneficial for asymptomatic patients."
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"inspired by this, we
further develop a deep classification model on top of learnable cluster
representations.specifically, given image x ∈ r h×w ×d , annotation y ∈ r k×hw d
, and patient class p ∈ l, our model consists of three components: 1) a cnn
backbone to extract its pixel-wise features f ∈ r c×hw d (fig."
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"our study analyzed a dataset of ct scans collected
from guangdong province people's hospital between years 2018 and 2020, with
2,139 patients consisting of 787 gastric cancer and 1,352 normal cases."
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"we used
the latest patients in the second half of 2020 as a hold-out test set, resulting
in a training set of 687 gastric cancer and 1,204 normal cases, and a test set
of 100 gastric cancer and 148 normal cases."
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"all patients underwent multi-phase cts with a median spacing
of 0.75 × 0.75 × 5.0 mm and an average size of (512, 512, 108) voxel."
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"no
patient information or records were provided to the readers."
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"in table 2, we report the performance of patient-level detection and tumor-level
localization stratified by tumor (t) stage."
Cluster-Induced Mask Transformers for Effective Opportunistic Gastric Cancer Screening on Non-contrast CT Scans,"our method surpasses or performs on par with
established screening tools [4,7,10] in terms of sensitivity for gastric cancer
detection at a similar specificity level with a relatively large testing patient
size (n = 1151 by integrating the internal and external test sets), as shown in
table 3."
Self-supervised Polyp Re-identification in Colonoscopy,none
YONA: You Only Need One Adjacent Reference-Frame for Accurate and Fast Video Polyp Detection,none
Boosting Breast Ultrasound Video Classification by the Guidance of Keyframe Feature Centers,none
Text-Guided Cross-Position Attention for Segmentation: Case of Medical Image,"monuseg [8] contains
30 digital microscopic tissue images of several patients and qata-cov19 are
covid-19 chest x-ray images."
Text-Guided Cross-Position Attention for Segmentation: Case of Medical Image,"sij is the dataset privately prepared for this study
which consists of 804 mri slices of nineteen healthy subjects and sixty patients
diagnosed with axial spondyloarthritis."
Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fréchet Domain Distance,"the model is trained to perform binary classification of
wsis from lymph nodes of breast cancer patients."
Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fréchet Domain Distance,"showing how fdd can help to identify subsets of patient
cases for which mil performance is worse than reported on the in-domain test
data; 3."
Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fréchet Domain Distance,"grand challenge camelyon data [16] potentially large shift as some patients have
already started neoadjuvant treatment as well as the tissue may be affected from
the procedure of sentinel lymph node removal."
Detecting Domain Shift in Multiple Instance Learning for Digital Pathology Using Fréchet Domain Distance,"we deem that the information needed to do this type of subset
divisions would be available without labelling since the patient cases in a
clinical setting would already contain such information."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"early detection and accurate diagnosis of liver tumors may improve overall
patient outcomes, in which imaging plays a key role [11]."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"dynamic
contrast-enhanced (dce) ct is widely used for diagnostics, but it requires
iodine contrast injection which can cause reaction and potential risks in
patients."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"after an incidental tumor is
found, the patient may undergo further imaging examination such as a multi-phase
dce ct for differential diagnosis [11], which can provide useful discriminative
information such as the vascularity of lesions and the pattern of contrast agent
enhancement [19]."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"(1) tumor screening involves
finding tumor patients in a large pool of healthy subjects and patients."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"most
existing works in tumor segmentation and detection did not explicitly consider
it since their training and testing images are all tumor patients."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"we collect a large-scale dataset with both tumor and
non-tumor subjects, where the non-tumor subjects includes not only healthy ones,
but also patients with various diffuse liver diseases such as steatosis and
hepatitis to improve the robustness of the algorithm."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"such metrics cannot reflect the
lesion-level accuracy (how many lesion instances are correctly detected and
classified) and may bias to large lesions when a patient has multiple tumors."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,patient-level metrics (e.g.
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"therefore, we assess our algorithm thoroughly with pixel, lesion, and
patient-level metrics.algorithms for liver tumor segmentation have focused on
improving the feature extraction backbone of a fully-convolutional cnn
[9,13,15,23]."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"the pixelwise segmentation architectures may not be optimal for
lesion and patient-level evaluation metrics since they cannot consider a lesion
or an image holistically."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"inspired by them, we
propose a novel end-to-end framework named pixel-lesion-patient network (plan)
for lesion segmentation and classification, as well as patient classification."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"it contains three branches with bottomup cooperation: the segmentation map from
the pixel branch helps to initialize the lesion branch, which is an improved
mask transformer aiming to segment and classify each lesion; the patient branch
aggregates information from the whole image and predicts image-level labels of
each lesion type, with regularization terms to encourage consistency with the
lesion branch.we collected a large-scale multi-phase dataset containing 810
non-tumor subjects and 939 tumor patients."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"on the non-contrast
tumor screening and diagnosis task, plan achieves 95.0%, 96.4%, and 0.965 in
patient-level sensitivity, specificity, and average auc for malignant and benign
patients, in contrast to 94.4%, 93.7%, and 0.889 for the widely-used nnu-net
[8]."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,we also hope to make patient-level diagnoses for each ct scan.
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"(3) a patient branch is
attached to make dedicated image-level predictions with a proposed
lesion-patient consistency loss."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"we propose a simple approach
to remedy this issue by sampling an extra n foreground pixels for each
lesion.patient branch."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,a patient-level diagnosis is useful for triage.
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"intuitively, we can also infer
patient-level labels from segmentation results by checking if there is any
lesion in the predicted mask."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"we equip plan with a dedicated
patient branch to aggregate such global information to make better patient-level
prediction."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"since one patient can have multiple liver tumors of different types,
in our problem, we give each image several hierarchical binary labels."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"we employ the dual-path transformer block [17] to
fuse multi-scale features from the pixel encoder and decoder to generate a
feature map, followed by global average pooling and a linear classification
layer to predict the c + 3 labels.a lesion-patient consistency loss is further
proposed to encourage coherence of the lesion and patient-level predictions."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"inspired by multi-instance learning [6], we compute a pseudo patient-level
prediction c ∈ r c from the lesion-level predictions by max-pooling the class
probability of each class across all lesion queries (discarding the no-object
class)."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"we also have the probability vector from the patient branch p ∈ r c
corresponding to the c fine-grained classes."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"1, where l pixel is the
combined crossentropy (ce) and dice loss for the pixel branch as in nnu-net [8];
l lesion-class is the ce loss [3] for lesion classification in the lesion
branch; l lesion-mask is the combined ce and dice loss [3] for binary lesion
segmentation in the lesion branch with the foreground-enhanced sampling
strategy; l patient is the binary ce loss for the multi-label classification
task in the patient branch."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"our dataset contains 810 normal subjects and 939 patients with liver
tumors."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"each normal subject has a non-contrast (nc) ct, while each patient has a
dynamic contrast-enhanced (dce) ct scan with nc, arterial, and venous phases."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"in the former setting, both
normal and patient data are used and randomly split into 1149 training, 100
validation, and 500 testing."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"in the latter one, only patient data are used with
641 training, 100 validation, and 200 testing."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"another hold-out set of 150
patients and 100 normal cts are used for reader study to compare our accuracy
with two radiologists."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"extensive data
augmentation is applied including random cropping, scaling, flipping, elastic
deformation, and brightness adjustment [8].during training, we first pretrain
the backbone and the pixel branch for 500 epochs, and then train the whole
network for another 500 epochs.patient-level results."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"for the
baselines, patient-level labels are inferred from their predicted masks by
counting lesion pixels."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"as displayed in table 1, plan achieves the best accuracy
on all tasks, especially in nc preliminary diagnosis tasks, which demonstrates
the effectiveness of its dedicated patient branch that can explicitly aggregate
features from the whole image.lesion and pixel-level results."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"in this work, we focus more on patient and lesion-level metrics."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,we consider patients with only one tumor type in this study.
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"the
efficacy of the lesion and patient branches has been analyzed above based on the
lesion and patient-level results."
Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient Network,"in the patient level,
[5] achieved auc=0.75 in nc ct tumor screening, while our auc is 0.985."
Self-supervised Learning for Endoscopic Video Analysis,"furthermore, the ability to recognize phases allows
real-time monitoring and decision-making assistance during surgery, thus
improving patient safety and outcomes."
Self-supervised Learning for Endoscopic Video Analysis,"we compiled a dataset of laparoscopic procedures videos exclusively
performed on patients aged 18 years or older."
Self-supervised Learning for Endoscopic Video Analysis,"we
have curated a dataset comprising 13,979 colonoscopy videos of patients aged 18
years or older."
Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"survival prediction, a regression
task that models the survival outcomes of patients, is crucial for h&n cancer
patients: it provides early prognostic information to guide treatment planning
and potentially improves the overall survival outcomes of patients [2]."
Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"[22] attempted to address
this limitation by proposing a multi-scale non-local attention fusion (mnaf)
block for survival prediction of glioma patients, in which multi-modality
features were fused via non-local attention mechanism [23] at multiple scales."
Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"we adopted the training dataset of hecktor 2022 (refer to
https://hecktor.grand-cha llenge.org/), including 488 h&n cancer patients
acquired from seven medical centers [7], while the testing dataset was excluded
as its ground-truth labels are not released."
Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"each patient underwent pretreatment
pet/ct and has clinical indicators."
Merging-Diverging Hybrid Transformer Networks for Survival Prediction in Head and Neck Cancer,"the patients from two centers (chum and chuv) were used for
testing and other patients for training, which split the data into 386/102
patients in training/testing sets."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"as such, there is a paucity of efforts that
embark on utilizing machine learning models for patient prognostication and
survival analysis (for example, predicting risk of cancer recurrence or expected
patient survival)."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"while prognostication and survival analysis offer invaluable
insights for patient management, biological studies and drug development
efforts, they require careful tracking of patients for a lengthy period of time;
rendering this as a task that requires a significant amount of effort and
funding.in the machine learning domain, patient prognostication can be treated
as a weakly supervised problem, which a model would predict the outcome (e.g.,
time to cancer recurrence) based on the histopathology images."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"hence, locally focused methods are
unable to benefit from the coarse properties of slides due to their high
dimensions which may lead to poor performance.this paper aims to investigate the
potential of extracting fine and coarse features from histopathology slides and
integrating them for risk stratification in cancer patients."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"therefore, the
contributions of this work can be summarized as: 1) a novel graph-based model
for predicting survival that extracts both local and global properties by
identifying morphological super-nodes; 2) introducing a fine-coarse feature
distillation module with 3 various strategies to aggregate interactions at
different scales; 3) outperforming sota approaches in both risk prediction and
patient stratification scenarios on two datasets; 4) publishing two large and
rare prostate cancer datasets containing more than 220 graphs for active
surveillance and 240 graphs for brachytherapy cases."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"for p n , which is the n-th patient, a set of patches {patch j } m j=1 is
extracted from the related whole slide images."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"finally, a specific
graph (g n ) for the n-th patient (p n ) can be constructed by assuming patches
as nodes."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"therefore, for each
patient such as p n , we have a graph defined by adjacency matrix a n with size
m × m and features matrix z n (g n = graph(z n , a n ))."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"the final model ( θ )
with parameters θ utilizes g n and s n to predict the risk associated with this
patient: due to computational limits and large number of patches available for
each
patient, we utilize a self-supervised approach to train an encoder to reduce the
inputs' feature space size."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"this term is motivated by
the original mincut problem and intends to solve it for the the patients' graph."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"the first set (pca-as) includes 179 pca patients who were
managed with active surveillance (as)."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"radical therapy is considered
overtreatment in these patients, so they are instead monitored with regular
serum prostate-specific antigen (psa) measurements, physical examinations,
sequential biopsies, and magnetic resonance imaging [23]."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"although majority of patients in our cohort are classified as low-risk based on
nccn guidelines [21], a significant subset of them experienced disease upgrade
that triggered definitive therapy (range: 6.2 to 224 months after diagnosis).the
second dataset (pca-bt) includes 105 pca patients with low to high risk disease
who went through brachytherapy."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"we utilize concordance-index (c-index) that measures the
relative ordering of patients with observed events and un-censored cases
relative to censored instances [2]."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"superior performance of our mca policy implies that balanced
exploitation of fine and coarse features with shared weights may provide more
robust contextual information compared to using mixed guided information or
utilizing them independently.patient stratification."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"the capacity of stratifying
patients into risk groups (e.g., low and high risk) is another criterion that we
employ to assess the utility of models in clinical practice."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"we evaluate model
performances via kaplan-meier curve [15] (cut-off set as the ratio of patients
with recurrence within 3 years of therapy initiation for pca-bt and the ratio of
upgraded cases for pca-as), logrank test [6] (with 0.05 as significance level),
and median outcome associated with risk groups (table 1 and fig."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"our model
stratified pca-as patients into high-and low-risk groups with median time to
progression of 36.5 and 131.7 months, respectively."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"while none of the baselines are capable of assigning patients into
risk groups with statistical significance, our distillation policies achieve
significant separation in both pca-as and pca-bt datasets; suggesting that
global histo-morphological properties improve patient stratification
performance."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"furthermore, our findings have significant clinical implications as
they identify, for the first time, highrisk prostate cancer patients who are
otherwise known to be low-risk based on clinico-pathological parameters."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"this
group should be managed differently from the rest of the low-risk prostate
cancer patients in the clinic."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"while a
prognostic biomarker provides information about a patient's outcome (without
specific recommendation on the next course of action), a predictive biomarker
gives insights about the effect of a therapeutic intervention and potential
actions that can be taken.ablation study."
ALL-IN: A Local GLobal Graph-Based DIstillatioN Model for Representation Learning of Gigapixel Histopathology Images With Application In Cancer Risk Assessment,"achieving higher c-indices in our all model versions indicates the
important role of coarse features and global context in patient risk estimation
in addition to local patterns."
DARC: Distribution-Aware Re-Coloring Model for Generalizable Nucleus Segmentation,"the images are extracted from 16
colorectal adenocarcinoma wsis, each of which belongs to an individual patient,
and scanned with an omnyx vl120 scanner within the department of pathology at
university hospitals coventry and warwickshire, uk."
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"accurate spatial characterization of tumor immune microenvironment is critical
for precise therapeutic stratification of cancer patients (e.g."
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"the demographics and other relevant information for all eight
head-and-neck squamous cell carcinoma patients is given in table 1."
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"after that, hematoxylin-and dapi-stained rois were used as
references to align mihc and mif rois again using fiji and subdivided into
512×512 patches, resulting in total of 268 co-registered mihc and mif patches
(∼33 co-registered mif/mihc images per patient)."
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"lyon19 ihc cd3/cd8 images are taken from breast, colon, and
prostate cancer patients."
An AI-Ready Multiplex Staining Dataset for Reproducible and Accurate Characterization of Tumor Immune Microenvironment,"we have released the first ai-ready restained and co-registered mif and mihc
dataset for head-and-neck squamous cell carcinoma patients."
Detection of Basal Cell Carcinoma in Whole Slide Images,the patient data were separated between training and testing to prevent overlap.
IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis,"(1) luad-gm dataset: the objective is
to predict the epidermal growth factor receptor (egfr) gene mutations in
patients with lung adenocarcinoma (luad) using 723 whole slide image (wsi)
slices, where 47% of cases have egfr mutations."
Multi-scale Prototypical Transformer for Whole Slide Image Classification,"a wsi dataset t can be defined as:where x i denotes a
patient, y i the label of x i , i j i is the j-th instance of x i , n is the
number of patients and n is the number of instances."
Thyroid Nodule Diagnosis in Dynamic Contrast-Enhanced Ultrasound via Microvessel Infiltration Awareness,"our dataset contained 282 consecutive patients who underwent thyroid
nodule examination at nanjing drum tower hospital."
Thyroid Nodule Diagnosis in Dynamic Contrast-Enhanced Ultrasound via Microvessel Infiltration Awareness,"all patients performed
dynamic ceus examination by an experienced sonographer using an iu22 scanner
(philips healthcare, bothell, wa) equipped with a linear transducer l9-3 probe."
Thyroid Nodule Diagnosis in Dynamic Contrast-Enhanced Ultrasound via Microvessel Infiltration Awareness,"all data were approved by the institutional review board of
nanjing drum tower hospital, and all patients signed the informed consent before
enrollment into the study.implementation details."
Label-Free Nuclei Segmentation Using Intra-Image Self Similarity,none
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"immunotherapy (io) is the standard treatment for patients with advanced
non-small cell lung cancer (nsclc) [19] but only 27-45% of patients respond to
this treatment [21]."
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"therefore, better algorithms and improved biomarkers are
essential for identifying which cancer patients are most likely to respond to io
in advance of treatment."
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"we demonstrate the efficacy of triaangil for
characterizing tme in the context of predicting 1) response to io with immune
checkpoint inhibitors (ici), 2) overall survival (os), in patients with nsclc,
and 3) providing novel insights into the spatial interplay between different
immune cell subtype."
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"tils),
to show that a high density of tils is associated with improved patient survival
and treatment response in nsclc [3,24]."
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"these approaches include methods that connect cells
regardless of their type (1) using global graphs (gg) such as voronoi that
connect all nuclei [2,14], or (2) using cell cluster graphs (ccg) [16] to create
multiple nuclear subgraphs based on cell-to-cell proximity to predict tumor
aggressiveness and patient outcome [16]."
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"the cohort employed in this study was composed of pre-treatment tumor biopsy
specimens from patients with nsclc from five centers (two centers for training
(s t ) and three centers for independent validation (s v ))."
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"the entire analysis
was carried out using 122 patients in experiment 1 (73 in s t , and 49 in s v )
and 135 patients in experiment 2 (81 in s t , and 54 in s v )."
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"for every patient, multiple density measures including the number of different
cells types and their ratios are calculated [3,24] (supplemental table 2)."
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"architectural features (e.g., perimeter, triangle area, edge length) were then
calculated on these global graphs for each patient."
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"for every patient, subgraphs are built on nuclei regardless of their type and
only based on their euclidean distance."
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"spatil: for each
patient, first, subgraphs are built on individual cell types based on a distance
parameter."
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"design: triangil was also trained to differentiate between patients who
responded to io and those who did not."
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"for our study, the responders to io were
identified as those patients with complete response, partial response, and
stable disease, and non-responders were patients with progressive disease."
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"a
linear discriminant analysis (lda) classifier was trained on s t to predict
which patients would respond to io."
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"design: s t
was used to construct a least absolute shrinkage and selection operator (lasso)
[28] regularized cox proportional hazards model [6] using the triangil features,
to obtain risk score for each patient."
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"the median risk score in s t was used as a threshold in both s t and s
v to dichotomize patients into low-risk/high-risk categories."
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"the c-index
evaluates the correlation between risk predictions and survival times, aiming to
maximize the discrimination between high-risk and low-risk patients [11]."
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"os is
the time between the initiation of io to the death of the patient."
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"the patients
were censored if the date of death was unknown.result: figure 2 presents some
triangil features in a field of view for a patient with long-term survival and
another with short-term survival."
Triangular Analysis of Geographical Interplay of Lymphocytes (TriAnGIL): Predicting Immunotherapy Response in Lung Cancer,"triangil was
predictive of response after io (n = 122) and also demonstrated a strong
correlation with os in nsclc patients treated with io (n = 135)."
NASDM: Nuclei-Aware Semantic Histopathology Image Generation Using Diffusion Models,none
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"radiotherapy, one of the mainstream treatments for cancer patients, has gained
notable advancements in past decades."
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"consequently, it is essential to develop a robust
methodology to automatically predict the dose distribution for cancer patients,
relieving the burden on dosimetrists and accelerating the radiotherapy
procedure.recently, the blossom of deep learning (dl) has promoted the automatic
medical image processing tasks [4][5][6], especially for dose prediction
[7][8][9][10][11][12][13][14]."
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"[7] modified the
traditional 2d unet [15] to predict the dose of prostate cancer patients."
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"therefore, introducing a diffusion model to the dose prediction task is a
worthwhile endeavor.in this paper, we investigate the feasibility of applying a
diffusion model to the dose prediction task and propose a diffusion-based model,
called diffdp, to automatically predict the clinically acceptable dose
distribution for rectum cancer patients."
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"(3) the
proposed diffdp is extensively evaluated on a clinical dataset consisting of 130
rectum cancer patients, and the results demonstrate that our approach
outperforms other state-of-the-art methods."
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"an image
set of cancer patient is defined as {x, y}, where x ∈ r h ×w ×(2+o) represents
the structure images, ""2"" signifies the ct image and the segmentation mask of
the ptv, and o denotes the total number of segmentation mask of oars."
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"we measure the performance of our model on an in-house
rectum cancer dataset which contains 130 patients who underwent volumetric
modulated arc therapy (vmat) treatment at west china hospital."
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"concretely, for
every patient, the ct images, ptv segmentation, oars segmentations, and the
clinically planned dose distribution are included."
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"we randomly select 98 patients for model training, 10
patients for validation, and the remaining 22 patients for test."
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"in this paper, we introduce a novel diffusion-based dose prediction (diffdp)
model for predicting the radiotherapy dose distribution of cancer patients."
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"moreover, we propose a structure encoder to extract anatomical
information from patient anatomy images and enable the model to concentrate on
the dose constraints within several essential organs."
DiffDP: Radiotherapy Dose Prediction via a Diffusion Model,"extensive experiments on
an in-house dataset with 130 rectum cancer patients demonstrate the superiority
of our method."
Position-Aware Masked Autoencoder for Histopathology WSI Representation Learning,"however, these methods still rely on at least patient-level annotations."
Detection-Free Pipeline for Cervical Cancer Screening of Whole Slide Images,none
Instance-Aware Diffusion Model for Gland Segmentation in Colon Histology Images,none
Adaptive Supervised PatchNCE Loss for Learning H&E-to-IHC Stain Translation with Inconsistent Groundtruth Image Pairs,none
HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis,none
Learning Robust Classifier for Imbalanced Medical Image Dataset with Noisy Labels by Minimizing Invariant Risk,none
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"colorectal cancer is the third most common malignant tumor, and nearly half of
all patients with colorectal cancer develop liver metastasis during the course
of the disease [6,16]."
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"patients with colorectal cancer typically undergo contrast-enhanced computed
tomography (cect) scans multiple times during follow-up visits after surgery for
early detection of crlm, generating a 5d dataset."
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"when patients undergo cect
scans to detect crlm, typically three phases are captured: the unenhanced plain
scan phase (p), the portal venous phase (v), and the arterial phase (a)."
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"that means patients have not been diagnosed as crlm when they took the
scans.-patients were previously diagnosed with colorectal cancer tnm stage i to
stage iii, and recovered from colorectal radical surgery."
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"-patients have two or
more times of cect scans.-we already determined whether or not the patients had
liver metastases within 2 years after the surgery, and manually labeled the
dataset based on this."
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"the first cohort consists of 201 patients and the
second cohort includes 68 patients."
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"patients may have different numbers
of ct scans, ranging from 2 to 6, depending on the number of follow-up visits."
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"we selected 170 patients who underwent three or more cect scans from our
original dataset, and cropped the images to only include the liver area, as
shown in fig."
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"we applied the same augmentation
technique consistently to all phases and timestamps of each patient's data."
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"1, patients b and c are diagnosed with positive crlm
later."
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"mpbd-lstm correctly yields a positive prediction for patient b with a
confidence of 0.82, but incorrectly yields a negative prediction for patient c
with a confidence of 0.77."
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"with similar confidence in the two cases, the error
is likely due to the relatively smaller liver size of patient c."
MPBD-LSTM: A Predictive Model for Colorectal Liver Metastases Using Time Series Multi-phase Contrast-Enhanced CT Scans,"how to effectively address
inter-patient variability in the dataset, perhaps by better fusing the 5d
features, requires further research from the community in the future."
Deep Cellular Embeddings: An Explainable Plug and Play Improvement for Feature Representation in Histopathology,none
Progressive Attention Guidance for Whole Slide Vulvovaginal Candidiasis Screening,none
CellGAN: Conditional Cervical Cell Synthesis for Augmenting Cytopathological Image Classification,none
An Anti-biased TBSRTC-Category Aware Nuclei Segmentation Framework with a Multi-label Thyroid Cytology Benchmark,"patient-level
images were partitioned first for training and test images, and patch-level
curation was performed."
Multi-modal Pathological Pre-training via Masked Autoencoders for Breast Cancer Diagnosis,none
Semi-supervised Pathological Image Segmentation via Cross Distillation of Multiple Attentions,none
Towards Novel Class Discovery: A Study in Novel Skin Lesions Clustering,none
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"therefore, synergizing multimodal data could
deepen a crossscale understanding towards improved patient prognostication.the
major goal of multimodal data learning is to extract complementary contextual
information across modalities [4]."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"overall, we formulate the objective of multimodal feature learning by
converting image patches and tabular genomics data into groupwise embeddings,
and then extracting multimodal patient-wise embeddings."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"the abr and the
group-wise embedding i n ∈ r 1×256 are defined as:where w,v1 and v2 are the
learnable parameters.patient-wise multimodal feature embedding."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"to aggregate
patient-wise multimodal feature embedding from the group-wise representations,
as shown in fig."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"in the pathological image
stream, the patient-wise image representation is aggregated by n group
representations as, where p ∈ p and p is the number of patients."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"similarly, the
patient-wise genomics representation is aggregated as g p ∈ r n ×256 ."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"after
generating patient-wise representation, we utilize two transformer layers [27]
to extract feature embeddings for each modality as follows:where msa denotes
multi-head self-attention [27] (see appendix 1), l denotes the layer index of
the transformer, and h p could either be i p or g p ."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"ideally, the image
and genomics embeddings belonging to the same patient should have a higher
relevance between each other."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"we collected wsis
from the cancer genome atlas colon adenocarcinoma (tcga-coad) dataset
(cc-by-3.0) [8,21] and rectum adenocarcinoma (tcga-read) dataset (cc-by-3.0)
[8,20], which contain 440 and 153 patients."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"finally, we included 426 patients of tcga-coad and 145 patients of
tcga-read.experimental settings and implementations."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"we followed the previous studies [5][6][7] to partition the overall
survival (os) months into four non-overlapping intervals by using the quartiles
of event times of uncensored patients for discretized-survival c-index
calculation (see appendix 2)."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"in addition, our model reflects
its efficiency on the limited finetuning data (e.g., 75 patients are used for
finetuning on tcga-read, which are only 22% of tcga-coad finetuning data)."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"for the
tcga-read dataset, as the number of uncensored patients is limited, we use 75%,
50%, and 25% of the finetuning data to allow at least one uncensored patient to
be included for finetuning."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"developing data-efficient multimodal learning is crucial to advance the survival
assessment of cancer patients in a variety of clinical data scenarios."
Pathology-and-Genomics Multimodal Transformer for Survival Outcome Prediction,"we
demonstrated that the proposed pathomics framework is useful for improving the
survival prediction of colon and rectum cancer patients."
Robust Cervical Abnormal Cell Detection via Distillation from Local-Scale Consistency Refinement,"nevertheless, delayed
diagnosis of cervical cancer until an advanced stage will have a negative impact
on patient prognosis and consume medical resources."
StainDiff: Transfer Stain Styles of Histology Images with Denoising Diffusion Probabilistic Models and Self-ensemble,none
MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"the mean and median
age of patients at the date of dissection was 47 and 50 years, respectively."
MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis,"the
data set comprised 13 male and 27 female patients, corresponding to a slight
gender imbalance."
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"thus, effective and accurate prognosis of
bc as well as stratifying cancer patients into different subgroups for
personalized cancer management has attracted more attention than ever
before.among different types of imaging biomarkers, histopathological images are
generally considered the golden standard for bc prognosis since they can confer
important cell-level information that can reflect the aggressiveness of bc [4]."
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"for instance, lu et al [5] presented a
novel approach for predicting the prognosis of er-positive bc patients by
quantifying nuclear shape and orientation from histopathological images."
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"however, due to the high-cost of
collecting survival information from the patients, it is still a challenge to
build effective machine learning models for specific bc subtypes with limited
annotation data.to deal with the above challenges, several researchers began to
design domain adaption algorithms, which utilize the labeled data from a related
cancer subtype to help predict the patients' survival in the target domain."
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"specifically, alirezazadeh et al [7] presented a new representation
learning-based unsupervised domain adaption method to predict the clinical
outcome of cancer patients on the target domain."
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"it can be expected that better
prognosis performance can be achieved if we leveraged the tils-tumor interaction
information to resolve the survival analysis task on the target domain.based on
the above considerations, in this paper, we proposed a tils-tumor interactions
guided unsupervised domain adaptation (t2uda) algorithm to predict the patients'
survival on the target bc subtype."
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"we evaluated the performance of
our method on the breast invasive carcinoma (brca) cohort derived from the
cancer genome atlas (tcga), and the experimental results indicated that t2uda
outperforms other domain adaption methods for predicting patients' clinical
outcomes."
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"the cox proportional hazard model was applied to predict the patients' clinical
outcome [16], and its negative log partial likelihood function can be formulated
as:where x i represents the output of the last layer for the prognosis task and
r (t i ) is the risk set at time t i , which represents the set of patients that
are still under risk before time t."
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,sample i refers to censored patient ifoverall objective.
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"specifically, the brca dataset
includes 661 patients with hematoxylin and eosin (he)-stained pathological
imaging and corresponding survival information."
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"among the collected brca
patients in tcga, the number of er positive(er+) and er negative(er-) patients
are 515 and 146, respectively."
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"instead of directly aligning regions, our proposed method
focused on similar tils-tumor interactions and aligning patches of the same
tissue.we also evaluated the contributions of the key components of our
framework and found that t2uda performed better than source only and t2uda-v1,
which shows the advantage of minimizing differences in tils-tumor interaction
weights.in addition, we also evaluated the patient stratification performance of
different methods."
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"3, our proposed t2uda outperformed feature
alignment-based methods (such as ddc and deepjdot), adversarial-based methods
(such as dann and mdd), and t2uda-v1 in stratification performance, proving that
considering the interaction between tils and tumors as migration knowledge leads
to better prognostic results.we also examined the consistency of important edges
in each group of stratified patients based on the tils-tumor interaction weights
calculated by the gat-based framework in the source and target domains."
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"4(b), the weights of the edges connecting tumor
and tils regions were higher for patients in the low survival risk group in both
source and target domains."
Transfer Learning-Assisted Survival Analysis of Breast Cancer Relying on the Spatial Interaction Between Tumor-Infiltrating Lymphocytes and Tumors,"in this paper, we presented an unsupervised domain adaptation algorithm that
leverages tils-tumor interactions to predict patients' survival in a target bc
subtype(t2uda)."
Gene-Induced Multimodal Pre-training for Image-Omic Classification,"furthermore, to model the high-order relevance of the two modalities, we combine
cls tokens of paired image and genomic data to form unified representations and
propose a triplet learning module to differentiate patient-level positive and
negative samples in a mini-batch."
Gene-Induced Multimodal Pre-training for Image-Omic Classification,"it is worth mentioning that although our
unified representation fuses features from the whole gene expression cohort and
partial wsis in a mini-batch, we can still learn high-order relevance and
discriminative patient-level information between these two modalities in
pre-training thanks to the triplet learning module."
Gene-Induced Multimodal Pre-training for Image-Omic Classification,"after extracting the input patch embeddings and gene
sequence separately, we concatenate cls img and cls ge as cls pat ∈ r 2d to
represent patient-level characteristics.suppose we obtain a triplet list {x, x +
, x -} during current iteration, where x, x + , x -are concatenated tokens of
anchor cls pat , positive cls pat , and negative cls pat , respectively."
Gene-Induced Multimodal Pre-training for Image-Omic Classification,"to
enhance the global modeling capability, i.e., extracting more precise
patient-level features, we expect that the distance between the anchor and the
positive sample gets closer, while the negative sample is farther away."
Gene-Induced Multimodal Pre-training for Image-Omic Classification,"applying the pre-trained backbone to image-omic classification task
is straightforward, since gimp pre-training allows it to learn representative
patient-level features."
Gene-Induced Multimodal Pre-training for Image-Omic Classification,"we collect corresponding rna-seq fpkm
data for each patient and the length of the input genomic sequence is 60,480."
Gene-Induced Multimodal Pre-training for Image-Omic Classification,"2 (c) and (d), cls pat with gimp pre-trained are well separated between
luad and lusc, i.e., gimp pays more attention to the categoryrelated feature
distribution and could extract more discriminative patient-level features during
triplet learning."
Histopathology Image Classification Using Deep Manifold Contrastive Learning,"the dataset for the former task was collected from 168 patients
with 332 wsis from seoul national university hospital."
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"if significant pca is detected on
biopsies and the patient has organ-confined cancer with no contraindications,
radical prostatectomy (rp) is the standard of care [3,4]."
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"machine learning algorithms have been used to
quantify the percentage of tumor to stroma in bladder cancer patients, but
required dichotomizing patients based on a threshold [14]."
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"software has been
used to segment tumor and stroma tissue in breast cancer patient samples, but
the method required constant supervision by a pathologist [15]."
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"in our study, we utilized three datasets for tumor-associated stroma
analysis.(1) dataset a comprises 513 tiles extracted from the whole mount slides
of 40 patients, sourced from the archives of the pathology department at
cedars-sinai medical center (irb# pro00029960)."
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"it combines two sets of tiles:
224 images from 20 patients featuring stroma, normal glands, low-grade and
highgrade cancer [22], along with 289 images from 20 patients with dense
high-grade cancer (gleason grades 4 and 5) and cribriform/non-cribriform glands
[23]."
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"(3) dataset c comprised 6134 negative biopsy slides obtained from 262
patients' biopsy procedures, where all samples were diagnosed as negative."
Deep Learning for Tumor-Associated Stroma Identification in Prostate Histopathology Slides,"future research can focus on validating our
approach on larger and more diverse datasets and expanding the method to a
patient-level prediction system, ultimately improving prostate cancer diagnosis
and treatment."
Multi-scope Analysis Driven Hierarchical Graph Transformer for Whole Slide Image Based Cancer Survival Prediction,"the ability to predict the future risk of patients with cancer can significantly
assist clinical management decisions, such as treatment and monitoring [21]."
Multi-scope Analysis Driven Hierarchical Graph Transformer for Whole Slide Image Based Cancer Survival Prediction,"deepattnmisl [26] extracted the phenotype patterns of the patient via a
clustering algorithm, which provides meaningful medical prior to guide the
aggregation of patch features."
Multi-scope Analysis Driven Hierarchical Graph Transformer for Whole Slide Image Based Cancer Survival Prediction,"for the network training, cox loss [26] is adopted for the survival prediction
task, which is defined as:where δ i denote the censorship of i-th patient, o(i)
and o(j) denote the survival output of i-th and j-th patient in a batch,
respectively."
Multi-scope Analysis Driven Hierarchical Graph Transformer for Whole Slide Image Based Cancer Survival Prediction,"the concordance index (ci) [23] is used to measure the
fraction of all pairs of patients whose survival risks are correctly ordered."
Multi-scope Analysis Driven Hierarchical Graph Transformer for Whole Slide Image Based Cancer Survival Prediction,"moreover, to
evaluate the ability of patients stratification, the kaplan-meier (km) analysis
is used [23]."
Mining Negative Temporal Contexts for False Positive Suppression in Real-Time Ultrasound Lesion Detection,none
Iteratively Coupled Multiple Instance Learning from Instance to Bag Classifier for Whole Slide Image Classification,none
Artifact Restoration in Histology Images with Diffusion Probabilistic Models,none
Thinking Like Sonographers: A Deep CNN Model for Diagnosing Gout from Musculoskeletal Ultrasound,"however, misdiagnosis of gout can occur frequently when a patient's clinical
characteristics are atypical."
Scribble-Based 3D Multiple Abdominal Organ Segmentation via Triple-Branch Multi-Dilated Network with Pixel- and Class-Wise Consistency,"we used the publicly available abdomen ct dataset word [17] for experiments,
which consists of 150 abdominal ct volumes from patients with rectal cancer,
prostate cancer or cervical cancer before radiotherapy."
Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"by identifying breast cancer early, patients can receive targeted treatment
before the disease progresses.deep neural networks have been widely adopted for
breast cancer diagnosis to alleviate the workload of radiologists."
Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"furthermore, there are differences between
multi-view mammograms of the same patient, arising from variations in breast
shape and density."
Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"we employ the noise-contrastive
estimation framework [6] to maximize the mutual information, which is a
contrastive learning framework:where s(i, p v ) evaluates the correlation
between multi-view fused representations and single-view representations
[17]:where n (i) is a reconstruction of p v generated by a fully connected
network n from i and the euclidean norm || • || 2 is applied to obtain
unit-length vectors.in contrastive learning, we consider the same patient
mammograms as positive samples and those from different patient mammograms in
the same batch p i v = p v \{p i v } as negative samples [17]."
Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"minimizing the
similarity between the same patient mammograms enables the model to learn shared
features."
Mammo-Net: Integrating Gaze Supervision and Interactive Information in Multi-view Mammogram Classification,"maximizing the dissimilarity between different patient mammograms
enhances the model's robustness.in short, we require the fusion representation i
to reversely reconstruct multiview representations p v so that more
view-invariant information can be passed to i."
CTFlow: Mitigating Effects of Computed Tomography Acquisition and Reconstruction with Normalizing Flows,"(2) aapm-mayo clinic low-dose ct ""grand challenge"" dataset,
a publicly available grand challenge dataset consisting of 5,936 abdominal ct
images from 10 patient cases reconstructed at 1.0 mm slice thickness."
CTFlow: Mitigating Effects of Computed Tomography Acquisition and Reconstruction with Normalizing Flows,"images from eight patient cases were used for training, and two cases were
reserved for validation."
Probabilistic Modeling Ensemble Vision Transformer Improves Complex Polyp Segmentation,none
DisAsymNet: Disentanglement of Asymmetrical Abnormality on Bilateral Mammograms Using Self-adversarial Learning,"each dataset is randomly
split into training, validation, and testing sets at the patient level in an
8:1:1 ratio, respectively (except for that inbreast which is split with a ratio
of 6:2:2, to keep enough normal samples for the test).table 1."
Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,"thus, early detection of kidney tumors can
help to improve patient's prognosis."
Segmentation of Kidney Tumors on Non-Contrast CT Images Using Protuberance Detection Network,"while this method demonstrated high sensitivity (95%), its false
positives per patient remained high (15 false positives per patient)."
Skin Lesion Correspondence Localization in Total Body Photography,"however, establishing skin
lesion correspondences across multiple scans from different patient visits has
not been well investigated in the context of full-body imaging.several
techniques have been proposed to match skin lesions across pairs of 2d images
[9][10][11][12][13][14]16,17,25]."
Anatomy-Informed Data Augmentation for Enhanced Prostate Cancer Detection,"inducing this kind of
soft tissue deformation ultimately led to improved model performance in
patient-and lesion-level pca detection on an independent test set."
Anatomy-Informed Data Augmentation for Enhanced Prostate Cancer Detection,"we apply
either our proposed transformation to the rectum or the bladder, random
deformable or no transformation in randomly selected exams and conduct a strict
turing test with clinicians having different levels of radiology expertise (a
freshly graduated clinician (c.e.) and resident radiologists (c.m., k.s.z.), 1.5
-3 years of experience in prostate mri) to determine if they can notice the
artificial deformation.finally, we quantify the effect of our proposed
transformation on the clinical task of patient-level pca diagnosis and
lesion-level pca detection."
Anatomy-Informed Data Augmentation for Enhanced Prostate Cancer Detection,"to consider clinically informative results, we
use the partial area under the receiver operating characteristic (pauroc) for
patient-level evaluation with the sensitivity threshold of 78.75%, which is 90%
of the sensitivity of radiologists for pi-rads ≥ 4."
Anatomy-Informed Data Augmentation for Enhanced Prostate Cancer Detection,"every patient
underwent extended systematic and targeted mri trans-rectal ultrasound-fusion
transperineal biopsy."
Anatomy-Informed Data Augmentation for Enhanced Prostate Cancer Detection,"in table 1 we summarize the patient-level pauroc and f 1 -scores; and
lesion-level froc results on the independent test set showing the advantage of
using anatomy-informed da."
Anatomy-Informed Data Augmentation for Enhanced Prostate Cancer Detection,"extending the basic da scheme with the proposed anatomy-informed deformation not
only increased the sensitivity closely matching the radiologists' patient-level
diagnostic performance but also improved the detection of pca on a lesion level."
Anatomy-Informed Data Augmentation for Enhanced Prostate Cancer Detection,"interestingly, while the use of random deformable transformation also improved
lesion-level performance, it did not approach the diagnostic performance of the
radiologists, unlike the anatomy-informed da.at the selected patient-and
object-level working points, the model with the proposed rectum-and
bladder-informed da scheme reached the best results with significant
improvements (p < 0.05) compared to the model with the basic da setting by
increasing the f 1 -score with 5.11% and identifying 4 more lesions (5.3%) from
the 76 lesions in our test set.the time overhead introduced by anatomy-informed
augmentation caused no increase in the training time, the gpu remained the main
bottleneck."
Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,"ex-vivo: data is collected from fresh breast tissue samples from the patients
referred to bcs at kingston health sciences center over two years."
Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,"the study is
approved by the institutional research ethics board and patients consent to be
included."
Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,"in total 51 cancer and 149 normal spectra are collected and
stratified into five folds (4 for cross validation and 1 prospectively) with
each patient restricted to one fold only."
Bridging Ex-Vivo Training and Intra-operative Deployment for Surgical Margin Assessment with Evidential Graph Transformer,"to demonstrate the robustness of the model and ensure it is not
overfitting, we also report the performance of the ensemble model from the
4-fold cross validation study on the 5th unseen prospective test fold.clinical
relevance: hormone receptor status plays an important role in determining breast
cancer prognosis and tailoring treatment plans for patients [6]."
Radiomics-Informed Deep Learning for Classification of Atrial Fibrillation Sub-Types from Left-Atrium CT Volumes,"recent works have shown that automatic classification of af sub-types can be
done using ct volumes of the left atrium and surrounding eat, which can be used
to screen for patients with high risk of peaf."
Radiomics-Informed Deep Learning for Classification of Atrial Fibrillation Sub-Types from Left-Atrium CT Volumes,"to
summarize our key contributions: -we propose a novel radiomics-informed deep
learning (ridl) method for af sub-type classification from ct volumes, which
achieves state-of-the-art results and can be used to screen for patients with
high risk of peaf."
Radiomics-Informed Deep Learning for Classification of Atrial Fibrillation Sub-Types from Left-Atrium CT Volumes,"we use a dataset of 172 patients containing 94 paaf and 78 peaf cases
collected from the sun yat-sen memorial hospital in china."
Radiomics-Informed Deep Learning for Classification of Atrial Fibrillation Sub-Types from Left-Atrium CT Volumes,"overall, our method is a novel
way of combining radiomic and deep learning approaches, and can be used to
improve accuracy of peaf screening from ct volumes for better preventive care of
high-risk patients."
Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-Based Hierarchical Fusion Network with Attention Mechanism,"early detection of breast cancer allows patients to receive timely
treatment, which may have less burden and a higher probability of survival [6]."
Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-Based Hierarchical Fusion Network with Attention Mechanism,"however, the use
of gadolinium-based contrast agents (gbca) requires iv-cannulation, which is a
burden to patients, time consuming and cumbersome in a screening situation."
Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-Based Hierarchical Fusion Network with Attention Mechanism,"studies have shown that dwi could be used to detect
lesions, distinguish malignant from benign breast lesions, predict patient
prognosis, etc [1,3,7,8,17]."
Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-Based Hierarchical Fusion Network with Attention Mechanism,"dwi may be a valuable alternative in breast cancer detection in patients with
contraindications to gbca [3]."
Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-Based Hierarchical Fusion Network with Attention Mechanism,"we retrospectively collected 765 patients
with breast cancer presenting at our cancer institute from january 2015 to
november 2020, all patients had biopsy-proven breast cancers (all cancers
included in this study were invasive breast cancers, and ductal carcinoma in
situ had been excluded)."
Synthesis of Contrast-Enhanced Breast MRI Using T1- and Multi-b-Value DWI-Based Hierarchical Fusion Network with Attention Mechanism,"our proposed model can potentially be used to synthesize ce-mri,
which is expected to reduce or avoid the use of gbca, thereby optimizing
logistics and minimizing potential risks to patients."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"despite the
superior tumor-to-normal tissue contrast of ce-mri, the use of gbcas during mri
scanning can result in a fatal systemic disease known as nephrogenic systemic
fibrosis (nsf) in patients with renal insufficiency [4]."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"it was reported that the
incidence rate of nsf is around 4% after gbca administration in patients with
severe renal insufficiency, and the mortality rate can reach 31% [6]."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"currently,
there is no effective treatment for nsf, making it crucial to find a ce-mri
alternative for patients at risk of nsf.in recent years, artificial intelligence
(ai), especially deep learning, plays a gamechanging role in medical imaging
[7,8], which showed great potential to eliminate the use of the toxic gbcas
through synthesizing virtual contrast-enhanced mri (vce-mri) from
gadolinium-free sequences, such as t1-weighted (t1w) and t2-weighted (t2w) mri
[9][10][11][12]."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"in addition to the advantage of eliminating the
use of gbca, vce-mri synthesis can also speed up the clinical workflow by
eliminating the need for acquiring ce-mri scan, which saves time for both
clinical staff and patients."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"patient data was retrospectively collected from three oncology centers in hong
kong."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"this dataset included 303 biopsy-proven (stage i-ivb) npc patients who
received radiation treatment during 2012-2016."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"the three hospitals were labelled
as institution-1 (110 patients), institution-2 (58 patients), and institution-3
(135 patients), respectively."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"for each patient, t1w mri, t2w mri,
gadolinium-based ce-mri, and planning ct were retrieved."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"mri images were
automatically registered as mri images for each patient were scanned in the same
position."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"due to
the retrospective nature of this study, patient consent was waived."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"for model
development, 288 patients were used for model development and 15 patients were
used to synthesize vce-mri for clinical evaluation."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"the details of patient
characteristics and the number split for training and testing of each dataset
were illustrated in table 1."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"the effectiveness of this network in vce-mri synthesis for npc patients
has been demonstrated by li et al."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"different from the original
study, which used single institutional data for model development and utilized
min-max value of the whole dataset for data normalization, in this work, we used
mean and standard deviation of each individual patient to normalize mri
intensities due to the heterogeneity of the mri intensities across institutions
[15]."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"considering the clinical burden of oncologists, 15 patients
were included for clinical evaluations."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"to evaluate the reality of
vce-mri, oncologists were invited to differentiate the synthetic patients (i.e.,
image volumes that generated from synthetic vce-mri) from real patients (i.e.,
image volumes that generated from real ce-mri)."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"paired two-tailed t-test (with a significance
level of p = 0.05) was applied to analyses if the scores obtained from real
patients and synthetic patients are significantly different."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"an accurate tumor delineation improves local control and reduce toxicity
to surrounding normal tissues, thus potentially improving patient survival [20]."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"for comparison, ce-mri was also imported to
eclipse for tumor delineation but assigned as a different patient, which were
shown to oncologists in a random and blind manner.to mimic the real clinical
setting, contrast-free t1w, t2w mri and corresponding ct of each patient were
imported into the eclipse system since sometimes t1w and t2w mri will also be
referenced during tumor delineation."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"due to both real patients and synthetic
patients were involved in delineation, to erase the delineation memory of the
same patient, we separated the patients to two datasets, each with the same
number of patients, both two datasets with mixed real patients and synthetic
patients without overlaps (i.e., the ce-mri and vce-mri from the same patient
are not in the same dataset).when finished the first dataset delineation, there
was a one-month interval before the delineation of the second dataset."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"after the
delineation of all patients, the dice similarity coefficient (dsc) [21] and
hausdorff distance (hd) [22] of the gtvs delineated from real patients and
corresponding synthetic patients were calculated to evaluate the accuracy of
delineated contours.dice similarity coefficient (dsc)."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"the dsc can be expressed as:where c ce and c
vce represent the contours delineated from real patients and synthetic patients,
respectively."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"for institution-1, 2 real patients were judged as
synthetic and 1 synthetic patient was considered as real."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"for institution-2, 2
real patients were determined as synthetic and 4 synthetic patients were
determined as real."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"for institution-3, 2 real patients were judged as synthetic
and 3 synthetic patients were considered as real."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"in total, 6 real patients were
judged as synthetic and 8 synthetic patients were judged as real."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"the overall clarity scores of
tumorto-normal tissue interface for real and synthetic patients were 3.67 with a
median of 4 and 3.47 with a median of 4, respectively."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"the average scores for real
and synthetic patients were 3.6 and 3, 3.6 and 3.8, 3.8 and 3.6 for
institution-1, institution-2, and institution-3, respectively."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"5 real patients
got a higher score than synthetic patients and 3 synthetic patients obtained a
higher score than real patients."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"the scores of the other 7 patient pairs were
the same."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"in total, 126 risk areas were recorded from the
ce-mri for all of the evaluation patients, while 10 (7.94%) false positive high
risk invasion areas and 9 (7.14%) false negative high risk invasion areas were
recorded from vce-mri."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"13 patient pairs obtained the
same staging results."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"for the institution-2 data, all synthetic patients
observed the same stages as real patients."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"for the two t-stage disagreement patients, one synthetic patient was staged as
phase iv while the corresponding real patient was staged as phase iii, the other
synthetic patient was staged as i while corresponding real patient was staged as
phase iii."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"figure 2 illustrated the delineated
primary gtv contours from an average patient with the dsc of 0.765 and hd of
1.938 mm."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"the green contour shows the primary gtv that delineated form the
synthetic patient, while the red contour was delineated from corresponding real
gbca-based patient."
Clinical Evaluation of AI-Assisted Virtual Contrast Enhanced MRI in Primary Gross Tumor Volume Delineation for Radiotherapy of Nasopharyngeal Carcinoma,"in this study, we conducted a series of clinical evaluations to validate the
clinical efficacy of vce-mri in rt of npc patients."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"while recent advances in human body modeling [4,5,12,13,15] have
allowed for automation of patient positioning, scout scans are still required as
they are used by automatic exposure control system in the ct scanners to compute
the dose to be delivered in order to maintain constant image quality [3].since
ldct scans are obtained in a single breath-hold and do not require any contrast
medium to be injected, the scout scan consumes a significant portion of the
scanning workflow time."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"furthermore, any
patient movement during the time between the two scans may cause misalignment
and incorrect dose profile, which could ultimately result in a repeat of the
entire process."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"finally, while minimal, the radiation dose administered to the
patient is further increased by a scout scan.we introduce a novel method for
estimating patient scanning parameters from non-ionizing 3d camera images to
eliminate the need for scout scans during pre-scanning."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"for ldct lung cancer
screening, our framework automatically estimates the patient's lung position
(which serves as a reference point to start the scan), the patient's isocenter
(which is used to determine the table height for scanning), and an estimate of
patient's water equivalent diameter (wed) profiles along the craniocaudal
direction which is a well established method for defining size specific dose
estimate (ssde) in ct imaging [8,9,11,18]."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"we trained our
models on a large collection of ct scans acquired from over 60, 000 patients
from over 15 sites across north america, europe and asia."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"-a generative model of
patient wed trained on over 60, 000 patients.-a novel method for real-time
refinement of wed, which can be used for dose modulation water equivalent
diameter (wed) is a robust patient-size descriptor [17] used
for ct dose planning."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"the wed of a patient is thus a function
taking as input a craniocaudal coordinate and outputting the wed of the patient
at that given position."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"we then train an
encoder network to map the patient depth image to the wed manifold."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"in this approach, our latent vector represents the encoding of a
patient in the latent space."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"this way, a single autodecoder can learn
patient-specific continuous wed functions."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"while the depth image provides critical information on the patient anatomy, it
may not always be sufficient to accurately predict the wed profiles."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"for
example, some patients may have implants or other medical devices that cannot be
guessed solely from the depth image."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"first, we use our encoder network to initialize
the latent vector to a point in the manifold that is close to the current
patient."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"as the
table moves and the patient gets scanned, ct data is being acquired and ground
truth wed can be computed for portion of the body that has been scanned, along
with the corresponding craniocaudal coordinate."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"our ct scan dataset consists of 62, 420 patients from 16 different sites across
north america, asia and europe."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"our 3d camera dataset consists of 2, 742 pairs
of depth image and ct scan from 2, 742 patients from 6 different sites across
north america and europe acquired using a ceiling-mounted kinect 2 camera."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"our
evaluation set consists of 110 pairs of depth image and ct scan from 110
patients from a separate site in europe."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,patient positioning is the first step in lung cancer screening workflow.
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"we
propose to estimate the table position by regressing the patient isocenter and
the starting point of the scan by estimating the location of the patient's lung
top.starting position."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"we define the starting position of the scan as the
location of the patient's lung top."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"we trained a denseunet [7] taking the camera
depth image as input and outputting a gaussian heatmap centered at the patient's
lung top location."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"we trained our model on 2, 742 patients using
adaloss [14] and the adam [6] optimizer with a learning rate of 0.001 and a
batch size of 32 for 400 epochs."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"we report an accuracy of 100% on our
evaluation set of 110 patients."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"the patient isocenter is
defined as the centerline of the patient's body."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"we trained a densenet [1]
taking the camera depth image as input and outputting the patient isocenter."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"we trained our model on 2, 742 patients using adadelta [16]
with a batch size of 64 for 300 epochs."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"we trained our autodecoder model on our unpaired ct scan dataset of 62, 420
patients with a latent vector of size 32."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"the encoder was trained on our paired
ct scan and depth image dataset of 2, 742 patients."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"we trained this baseline model on 2, 742 patients using the adadelta
[6] optimizer with a learning rate of 0.001 and a batch size of 32."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"figure 4 presents a
qualitative evaluation on patients with different body morphology.finally, we
evaluated the clinical relevancy of our approach by computing the relative error
as described in the international electrotechnical commission (iec) standard iec
62985:2019 on methods for calculating size specific dose estimates (ssde) for
computed tomography [2]."
Automated CT Lung Cancer Screening Workflow Using 3D Camera,"the δ rel metric is defined as:where:-ŵ ed(z) is the
predicted water equivalent diameter -w ed(z) is the ground truth water
equivalent diameter z is the position along the craniocaudal axis of the
patient."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"patients with early
stages of the disease exhibit few symptoms until suddenly converting to the late
stage, at which point their central vision rapidly deteriorates [12]."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"clinicians
currently diagnose amd, and stratify patients, using biomarkers derived from
optical coherence tomography (oct), which provides high-resolution images of
fig."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"however, the widely adopted amd grading system
[7,13], which coarsely groups patients into broad categories for early and
intermediate amd, only has limited prognostic value for late amd."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"clinicians
suspect that this is due to the grading system's reliance on static biomarkers
that are unable to capture temporal dynamics which contain critical information
for assessing progression risk.in their search for new biomarkers, clinicians
have annotated known biomarkers in longitudinal datasets that monitor patients
over time and mapped them against disease progression [2,16,19]."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"at the core of our method is the novel
strategy to represent patient time series as trajectories in a latent feature
space."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"after strict quality control, the development
dataset consists of 46,496 scans of 6,236 eyes from 3,456 patients."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"the
unseen dataset is larger, containing 114,062 scans of 7,253 eyes from 3,819
patients."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"visual acuity scores, which measured the patient's functional quality of vision
using a logmar chart, are available at 83,964 time points."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"naively clustering whole time series of patients ignores two characteristics of
longitudinal data."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"firstly, individual time series are not directly comparable
as patients enter and leave the study at different stages of their overall
progression.secondly, longer time series can record multiple successive
transitions in disease stage."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"2, matches two sub-trajectories, u and v , of
patients who progress between the same start and end states:since all
sub-trajectories cover a similar temporal duration, d transition also
differentiates between fast and slow progressors and stable periods of no
progression."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"however, by ignoring intermediary images, this metric does not
respect the disease pathway along which patients progress."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"two teams of two ophthalmologists then
review 20 sub-trajectories from distinct patients in each cluster, interpreting
and summarising any consistently observed temporal dynamics."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"each experiment uses 10-fold cross
validation on random 80/20 partitions, while ensuring a patient-wise split."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"in all tasks the
standard biomarkers are only marginally more indicative of risk than the
patient's age and sex."
Clustering Disease Trajectories in Contrastive Feature Space for Biomarker Proposal in Age-Related Macular Degeneration,"as late stage patients were overrepresented in our datasets, we
also intend to apply our method to datasets with greater numbers of patients
progressing from earlier disease stages."
Multi-task Learning of Histology and Molecular Markers for Classifying Diffuse Glioma,none
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"gross tumor volume (gtv)
represents the area of the tumor that can be identified with a high degree of
certainty and is of paramount importance in clinical practice.in the clinical
setting, patients may undergo a second round of rt treatment to achieve complete
tumor control when initial treatment fails to completely eradicate cancer [16]."
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"during the second course of rt, a ct image i
2 of the same patient is acquired."
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"the paired first-second course dataset, s p , is collected from sun
yat-sen university cancer center (ethics approval number: b2023-107-01),
comprising paired ct scans of 69 distinct patients from south china."
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"we
collected the gtv dataset s v from medmind technology co., ltd., which has ct
scans from 179 patients."
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"additionally, we collect s e from segthor [12],
consisting of ct scans and esophagus annotations from 40 patients who did not
implementation details."
Second-Course Esophageal Gross Tumor Volume Segmentation in CT with Prior Anatomical and Radiotherapy Information,"notably, the paired first-second course dataset s test p pertains
to the same group of patients, thereby ensuring that any performance drop can be
attributed solely to differences in courses of rt, rather than variations across
different patients.figure 2 illustrates the reduction in the gtv area after the
initial course of rt, where the transverse plane is taken from the same location
relative to the vertebrae (yellow lines)."
CLIP-Lung: Textual Knowledge-Guided Lung Nodule Malignancy Prediction,"lidc-idri [1] is a dataset for pulmonary nodule classification or
detection based on low-dose ct, which involves 1,010 patients."
EPVT: Environment-Aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition,none
Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"this phenomenon is especially common in rare tumors like
pancreatic neuroendocrine neoplasms (pnens).in order to overcome above
challenges, some studies [3,9,13,18] used multilabel method because of the
following advantages: 1) the input of the model is only a single modality such
as images, which is easy to apply clinically; 2) the model learns multi-label
and multi-disciplinary knowledge, which is consistent with clinical logic; 3)
multi-label simultaneous prediction, which meets the need of clinical
multi-dimensional description of patients."
Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"all patients with arterial phase computed tomography (ct)
images were included."
Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"the dataset contained 264 and 28 patients in center 1 and
center 2, and a senior radiologist annotated the bounding boxes for all 408 and
28 lesions."
Self-feedback Transformer: A Multi-label Diagnostic Model for Real-World Pancreatic Neuroendocrine Neoplasms Data,"taking a
patient as a sample, we chose the dataset from center 1 as the internal dataset,
of which the samples with most of the main labels were used as dataset 1 (219
lesions) and was split into 5 folds, and the remaining samples are randomly
divided into the training set dataset 2 (138 lesions) and the validation set
dataset 3 (51 lesions), the training set and the validation set of the
corresponding folds were added during cross-validation, respectively."
Developing Large Pre-trained Model for Breast Tumor Segmentation from Ultrasound Images,none
3D Mitochondria Instance Segmentation with Spatio-Temporal Transformers,none
Physics-Informed Conditional Autoencoder Approach for Robust Metabolic CEST MRI at 7T,"cest imaging was performed in seven subjects, including two
glioblastoma patients, after written informed consent was obtained to
investigate the dependence of cest effects on b 1 in brain tissue."
Physics-Informed Conditional Autoencoder Approach for Robust Metabolic CEST MRI at 7T,"the
test set consisted of the two tumor patients and one healthy subject."
Physics-Informed Conditional Autoencoder Approach for Robust Metabolic CEST MRI at 7T,"quantified maps of amide, rnoe and amine for another tumor patient is
shown in supplementary fig."
Diffusion-Based Data Augmentation for Nuclei Image Segmentation,none
Deep Unsupervised Clustering for Conditional Identification of Subgroups Within a Digital Pathology Image Set,"due to model complexity and limited training data, ml
performance often varies across data subgroups or domains, such as different
patient subpopulations or varied data acquisition scenarios."
Deep Unsupervised Clustering for Conditional Identification of Subgroups Within a Digital Pathology Image Set,"deep unsupervised clustering
algorithms could map the medical imaging data back to their causal factors or
underlying domains, such as image acquisition equipment, patient subpopulations,
or other meaningful data subgroups."
A Texture Neural Network to Predict the Abnormal Brachial Plexus from Routine Magnetic Resonance Imaging,"brachial plexus syndrome occurs not infrequently in patients with malignant
disease."
A Texture Neural Network to Predict the Abnormal Brachial Plexus from Routine Magnetic Resonance Imaging,"following irb approval for this study, we search for patients with metastatic
breast cancer who had a breast cancer mri performed between 2010 and 2020 and
had morphologically positive bp on the mri report from our electronic medical
records (emr) in * hospital."
A Texture Neural Network to Predict the Abnormal Brachial Plexus from Routine Magnetic Resonance Imaging,"only patients that
had all three sequences segmented (t2, t1 and post-gadolinium) were included in
the dataset."
CircleFormer: Circular Nuclei Detection in Whole Slide Images with Circle Queries and Attention,none
Self-supervised Dense Representation Learning for Live-Cell Microscopy with Time Arrow Prediction,none
Prompt-MIL: Boosting Multi-instance Learning Schemes via Task-Specific Prompt Tuning,none
Prompt-Based Grouping Transformer for Nucleus Detection and Classification,"we split them following the official partition [1,10].is a breast cancer
dataset with three types and consists of 120 image tiles from 113 patients."
Maximum-Entropy Estimation of Joint Relaxation-Diffusion Distribution Using Multi-TE Diffusion MRI,none
Simulation of Arbitrary Level Contrast Dose in MRI Using an Iterative Global Transformer Model,"however,
gbcas have several disadvantages like contraindications in patients with reduced
renal function [2], patient inconvenience, high operation costs and
environmental side effects [3]."
Simulation of Arbitrary Level Contrast Dose in MRI Using an Iterative Global Transformer Model,"for downstream task assessment we
used 159 patient studies from another site (site b) using gadobenate
dimeglumine."
Simulation of Arbitrary Level Contrast Dose in MRI Using an Iterative Global Transformer Model,"for each patient, 3d t1w mprage scans were acquired for the
pre-contrast, low-dose, and post-contrast images."
TractCloud: Registration-Free Tractography Parcellation with a Novel Local-Global Streamline Point Cloud Representation,"in the challenging btp (tumor patients) dataset, tractcloud reg-free
obtains significantly lower tda values than sota methods and comparable
performance to tractcloud regist ."
Relaxation-Diffusion Spectrum Imaging for Probing Tissue Microarchitecture,"our studies suggest that rdsi provides useful information on
microvascularity and necrosis helpful for facilitating early stratification of
patients with gliomas (fig."
Exploring Unsupervised Cell Recognition with Prior Self-activation Maps,none
Brain Anatomy-Guided MRI Analysis for Assessing Clinical Progression of Cognitive Impairment with Structural MRI,"the dm contains 1) 45 health control (hc)
subjects and 2) 37 diabetes mellitus patients with mild ci (mci)."
atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning,"consequently, they are
unsuitable for tasks such as preoperative planning of neurosurgical patients, as
they may produce incomplete or false segmentations, which could have harmful
consequences during surgery [19]."
atTRACTive: Semi-automatic White Matter Tract Segmentation Using Active Learning,"we focused on the left optic radiation (or), the left
cortico-spinal tract (cst), and the left arcuate-fasciculus (af), representing a
variety of established tracts.to test the proposed method on pathological data,
we used an in-house dataset containing ten presurgical scans of patients with
brain tumors."
B-Cos Aligned Transformers Learn Human-Interpretable Features,none
Single-subject Multi-contrast MRI Super-resolution via Implicit Neural Representations,"in clinical practice, magnetic resonance imaging (mri) provides important
information for diagnosing and monitoring patient conditions [4,16]."
Single-subject Multi-contrast MRI Super-resolution via Implicit Neural Representations,"as multi-parametric
isotropic 3d scans are not always feasible to acquire due to time-constraints
[19], motion [9], and patient's condition [10], super-resolution offers a
convenient alternative to obtain the same from anisotropic 2d scans."
Single-subject Multi-contrast MRI Super-resolution via Implicit Neural Representations,"in this work, we mitigate these gaps by proposing a novel
multi-contrast super-resolution framework that only requires the
patient-specific low-resolution mr scans of different sequences (and views) as
supervision."
Single-subject Multi-contrast MRI Super-resolution via Implicit Neural Representations,"in this section, we first formally introduce the problem of joint
super-resolution of multi-contrast mri from only one image per contrast per
patient."
Single-subject Multi-contrast MRI Super-resolution via Implicit Neural Representations,"in each dataset, we select 25 patients that
fulfill the isotropic acquisition criteria for both ground truth hr scans."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"patients with gbm generally have a very poor survival rate;
the median overall survival time is about 14 months [17]; and the overall
survival time is affected by many factors, including patient characteristics
(e.g., age and physical status), tissue histopathology (e.g., cellular density
and nuclear atypia), and molecular pathology (e.g., mutations and gene
expression levels) [1,14,15]."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"although these factors, particularly molecular
information, have usually proved to be strong predictors of survival in gbm,
there remain substantial challenges and unmet clinical needs to exploit easily
accessible, noninvasive neuroimaging data acquired preoperatively to predict
overall survival time of gbm patients, which can benefit treatment planning.to
do so, magnetic resonance imaging (mri) and its derived radiomics have been
widely used to study gbm preoperative prognosis over the last few decades."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"[2] first applied a forest of trees to assign an
importance value to each of the 1022 radiomic features extracted from t1 mri,
and then the 32 most important features were fed to the random forest regressor
for predicting overall survival time of a gbm patient."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"first, due to mass effect and physical infiltration of gbm in the
brain, fcs estimated directly from gbm patients' resting-state fmri might be
inaccurate, especially when the tumors are near or in the regions of interest."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"in order to circumvent these issues, in this paper we
introduce a novel neuroimaging feature family, namely functional lesion network
(fln) maps that are generated by our augmented lesion network mapping (a-lnm),
for overall survival time prediction of gbm patients."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"by
embedding the lesion into a normative functional connectome and computing
functional connectivity between the lesion and the rest of the brain using fmri
of all healthy subjects in the normative cohort, lnm has been successfully
employed to the identification of the brain network underlying particular
symptoms or behavioral deficits in stoke [4,13].the details of our workflow are
described as follows.1) we first manually segment the whole tumor (regarded as
lesion in this paper) on structural mri for all gbm patients, and the resulting
lesion masks are mapped onto a reference brain template, e.g., the mni152 2mm 3
template.2) the proposed a-lnm is next used to generate fln maps for each gbm
patient by using resting-state fmri from a large cohort of healthy subjects."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"specifically, for each patient, we correlate the mean bold time series of all
voxels within the lesion with the bold time series of every voxel in the whole
brain for all n subjects in the normative cohort, producing n functional
disconnection (fdc) maps of voxel-wise correlation values (transformed to
zscores)."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"similar to data augmentation schemes, we can artificially
boost data volume (i.e., fln maps) up to m times through producing m fln maps
for each patient in the a-lnm, which helps to mitigate the risk of over-fitting
and improve the performance of overall survival time prediction when learning a
deep neural network from a small sized dataset.for this reason, we propose the
name ""augmented lnm (a-lnm)"", compared to the traditional lnm where only one fln
map is generated per patient by averaging all the n fdc maps."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"to evaluate the predictive
power of the fln maps generated by our a-lnm, we conduct extensive experiments
on 235 gbm patients in the training dataset of brats 2020 [18] to classify the
patients into three overall survival time groups viz."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"it provided an open-access pre-operative imaging training dataset to
segment brain tumors of glioblastoma (gbm, belonging to high grade glioma) and
low grade glioma (lgg) patients, as well as to predict overall survival time of
gbm patients [18]."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"this training dataset contained 133 lgg and 236 gbm patients,
and each patient had four mri modalities, including t1, post-contrast
t1-weighted, t2-weighted, and t2 fluid attenuated inversion recovery."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"in this paper, we propose to investigate the feasibility of the novel
neuroimaging features, i.e., fln maps, for overall survival time prediction of
gbm patients in the training dataset of the brats 2020, in which one patient
alive was excluded, and the remaining 235 patients consisted of 89 short-term
survivors (less than 10 months), 59 mid-term survivors (between 10 and 15
months), and 87 long-term survivors (more than 15 months)."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"as stated above,
the whole tumor is referred to as a lesion for each gbm patient."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"from the manual
expert segmentation labels of lesions in the 235 gbm patients of the brats 2020,
we co-register the lesion masks to the mni152 2mm 3 template by employing a
symmetric normalization algorithm in antspy [3]."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"after lesion mapping, we introduce a modified lnm (called augmented lnm (a-lnm)
in this paper) to generate fln maps for each gbm patient by using resting-state
fmri of all 1000 gsp healthy subjects, as described below."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"i) for each patient,
the lesion is viewed as a seed region to calculate fdc in the healthy subjects
with restingstate fmri."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"ii) different from the commonly used lnm where
the resulting 1000 fdc maps are thresholded or averaged to obtain a single fln
map for each patient, the a-lnm generates many fln maps for each patient in a
manner that partitions all the 1000 fdc maps into disjoint subsets of equal size
and averages each subset to produce one fln map."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"3 of this paper, according to experimental
results, we divided the 1000 fdc maps into 100 subsets, and randomly chose 10
out of the resulting 100 fln maps for each patient as input to the downstream
prediction model.deep neural network for overall survival time prediction."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"the features are then combined using the average pooling
operation and fed to a fully-connected layer with kernel size (1, 1, 1) to
classify each gbm patient into one of the three overall survival time groups
(i.e., short-term survival, mid-term survival, and long-term survival)."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"we evaluated
the classification performance of our proposed method using 235 gbm patients in
the brats 2020 training dataset, because only these 235 patients had both
overall survival time and manual expert segmentation labels of lesions."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"patients whose
frontal lobe is affected by tumors showed more executive dysfunction, apathy,
and disinhibition [11]."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"on the dominant left hemisphere, the cams of long-term
survivors and mid-term survivors overlapped at the superior temporal gyrus and
wernicke's area which are involved in the sensation of sound and language
comprehension respectively, and have been associated with decreased survival in
patients with high-grade glioma [26]."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"in this paper, we introduce a novel neuroimaging feature family, called a-lnm
derived fln maps, for overall survival time prediction of gbm patients."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"a-lnm
was presented to generate plenty of fln maps for each gbm patient by
partitioning the fdc maps obtained from resting-state fmri of 1000 gsp healthy
subjects into disjoint subsets of equal size and averaging each subset."
Overall Survival Time Prediction of Glioblastoma on Preoperative MRI Using Lesion Network Mapping,"we
applied a 3d resnet-based backbone network to extract features from the
generated fln maps and classify gbm patients into three overall survival time
groups."
A Multi-task Network for Anatomy Identification in Endoscopic Pituitary Surgery,"failure to appreciate these critical
parasellar neurovascular structures can lead to their injury, and adverse
outcomes for the patient [9,11]."
A Multi-task Network for Anatomy Identification in Endoscopic Pituitary Surgery,"all
patients have provided informed consent, and the study was registered with the
local governance committee."
Intraoperative CT Augmentation for Needle-Based Liver Interventions,"ct-guidance is a widely used imaging modality for placing
the needles, monitoring the treatment, and following up patients."
Intraoperative CT Augmentation for Needle-Based Liver Interventions,"once the network has been trained on the patient-specific preoperative data, the
next step is to augment and visualize the intraoperative ncct."
Intraoperative CT Augmentation for Needle-Based Liver Interventions,"our future steps will essentially involve applying this method to
patient data and perform a small user study to evaluate the usefulness and
limitations of our approach.aknowledgments."
Optical Coherence Elastography Needle for Biomechanical Characterization of Deep Tissue,"furthermore, the prostate is
known to display large bulk displacement caused by patient movement and needle
insertions [20,24] in addition to actual sample compression (fig."
Pelvic Fracture Segmentation Using a Multi-scale Distance-Weighted Neural Network,"these data is collected from 100 patients (aged 18-74 years,
41 females) who were to undergo pelvic reduction surgery at beijing jishuitan
hospital between 2018 and 2022, under irb approval (202009-04)."
Towards Multi-modal Anatomical Landmark Detection for Ultrasound-Guided Brain Tumor Resection with Contrastive Learning,"early surgical
treatment to remove the maximum amount of cancerous tissues while preserving the
eloquent brain regions can improve the patient's survival rate and functional
outcomes of the procedure [2]."
Towards Multi-modal Anatomical Landmark Detection for Ultrasound-Guided Brain Tumor Resection with Contrastive Learning,"table 1 lists the mean and standard deviation of landmark identification errors
(in mm) between the predicted position and the ground truth in intra-operative
us for each patient of the resect dataset."
Towards Multi-modal Anatomical Landmark Detection for Ultrasound-Guided Brain Tumor Resection with Contrastive Learning,"in the table, we also provide the
severity of brain shift for each patient."
Deep Reinforcement Learning Based System for Intraoperative Hyperspectral Video Autofocusing,none
Surgical Video Captioning with Mutual-Modal Concept Alignment,"we split these video
clips at patientlevel, where the video clips of 31 patients are used for
training and the rest of 10 patients are utilized for test.endovis image
captioning dataset."
Imitation Learning from Expert Video Data for Dissection Trajectory Prediction in Endoscopic Surgical Procedure,none
Regularized Kelvinlet Functions to Model Linear Elasticity for Image-to-Physical Registration of the Breast,"image-to-physical registration is a necessary process for computer-assisted
surgery to align preoperative imaging to the intraoperative physical space of
the patient to in-form surgical decision making."
Regularized Kelvinlet Functions to Model Linear Elasticity for Image-to-Physical Registration of the Breast,"the second validates the registration method in a breast
cancer patient and compares registration accuracy and computation time to
previously proposed methods."
Regularized Kelvinlet Functions to Model Linear Elasticity for Image-to-Physical Registration of the Breast,"three
hyperparameter sweeps were used: this dataset consists of supine breast mr
images simulating surgical
deformations from one breast cancer patient."
Regularized Kelvinlet Functions to Model Linear Elasticity for Image-to-Physical Registration of the Breast,"a 71-year-old patient with invasive
mammary carcinoma in the left breast was enrolled in a study approved by the
institutional review board at vanderbilt university."
Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"we address the important problem of intraoperative patient-to-image registration
in a new way by relying on preoperative data to synthesize plausible
transformations and appearances that are expected to be found intraoperatively."
Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"indeed, the extent of tumor removal is highly
correlated with patients' chances of survival and complete resection must be
balanced against the risk of causing new neurological deficits [5] making
accurate intraoperative registration a critical component of
neuronavigation.most existing techniques perform patient-to-image registration
using intraoperative mri [11], cbct [19] or ultrasound [9,17,20]."
Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"we propose a novel approach for patient-to-image registration that registers the
intraoperative 2d view through the surgical microscope to preoperative mri 3d
images by learning expected appearances."
Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"this set is used to train
a patient-specific pose regressor network to obtain a model that is
texture-invariant and is cross-modality to bridge the mri and rgb camera
modalities."
Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"in addition, our
method is patient-specific, centered around m, since each model is trained
specifically for a given patient."
Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"patient's head during neurosurgery.we use the l-bfgs optimizer and 5
convolutional layers of vgg-19 to generate each image following [1] to find the
resulting parameters θ."
Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"the model is trained for each case (patient)
for 200 epochs using mini-batches of size 8 with adam optimizer and a learning
rate of 0.001 and decays exponentially to 0.0001 over the course of the
optimization."
Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"we tested our method retrospectively on 6 clinical datasets from 6
patients (cases) (see fig."
Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"training
patient-specific models from preoperative imaging transfers computational tasks
to the preoperative stage so that patient-to-image registration can be performed
in near real-time from live images acquired from a surgical
microscope.limitations."
Learning Expected Appearances for Intraoperative Registration During Neurosurgery,"we introduced expected appearances, a novel learning-based method for
intraoperative patient-to-image registration that uses synthesized expected
images of the operative field to register preoperative scans with intraoperative
views through the surgical microscope."
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"radiotherapy (rt) has proven effective and efficient in treating cancer
patients."
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"hence, this manual segmentation step is very time-consuming and
must be performed accurately and, more importantly, must be patient-safe."
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"in the field of rt
planning for brain tumor patients, the recent study of [17] shows that current
dl-based segmentation algorithms for target structures carry a significant
chance of producing false positive outliers, which can have a considerable
negative effect on applied radiation dose, and ultimately, they may impact
treatment effectiveness."
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"we present results on a clinical
dataset comprising fifty post-operative glioblastoma (gbm) patients."
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"a segmentation model
(u-net [20]) is trained to output target segmentation predictions for the gross
tumor volume (gtv) based on patient mri sequences."
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"a
pixel-wise mean squared error between both dose predictions is then a
segmentation model (u-net [20]) is trained to output target segmentation
predictions ( st ) for the gross tumor volume (gtv) based on patient mri
sequences imr."
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"originally proposed for head and neck cancer [12], this approach has been
recently extended for brain tumor patients [9] with levels of prediction error
below 2.5 gy, which is less than 5% of the prescribed dose."
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"we refer the reader to [9] for further details.segmentation models:
to develop and test the proposed approach, we employed a separate in-house
dataset (i.e., different cases than those used to train the dose predictor
model) of 50 cases from post-operative gmb patients receiving standard rt
treatment."
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"4, the standard bce+softdice
model would yield a centrally located radiation dose, with strong negative
clinical impact to the patient."
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"the ultimate goal of dl-based segmentation for rt planning is to provide
reliable and patient-safe segmentations for dosimetric planning and optimally
targeting tumor lesions and sparing of healthy tissues."
Dose Guidance for Radiotherapy-Oriented Deep Learning Segmentation,"these first results on a dataset of post-operative gbm
patients show the ability of the proposed doselo to deliver improved
dosimetric-compliant segmentation results."
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"residual tumor in the cavity after head and neck cancer (hnc) surgery is a
significant concern as it increases the risk of cancer recurrence and can
negatively impact the patient's prognosis [1]."
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"our proposed approach identified all patients with
psm."
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"finally, the
patient's surgical cavity was scanned to check for residual tumor."
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"the research was performed under the approval of the uc davis institutional
review board (irb) and with the patient's informed consent."
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"all patients were
anesthetized, intubated, and prepared for surgery as part of the standard of
care."
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"n = 22 patients are represented in this study, comprising hnc in the
palatine tonsil (n = 15) and the base of the tongue (n = 7)."
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"for each patient,
the operating surgeon conducted an en bloc surgical tumor resection procedure
(achieved by tors-electrocautery instruments), and the resulting excised
specimen was sent to a surgical pathology room for grossing."
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"1).after the
surgical excision of the tumor, an in vivo flim scan of approximately 90 s was
conducted within the patient's surgical cavity, where the tumor was excised."
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"the evaluation followed a leave-one-patient-out
cross-validation approach."
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"three novelty detection models were evaluated, and all three models
could identify the presence of residual tumors in the cavity for the three
patients."
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"the oc-svm and
robust covariance reported a high standard deviation, indicating that the
performance of the classification model is inconsistent across different
patients."
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"moreover, the current approach
correctly identified all patients with psms (see fig."
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"the flimbased
classification model could help guide the surgical team in real-time, providing
information on the location and extent of cancerous tissue.in context to the
standard of care, the proposed residual tumor detection model exhibits high
patient-level sensitivity (sensitivity = 1) in detecting patients with psms."
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"in
contrast, defect-driven ifsa reports a patient-level sensitivity of 0.5 [6,7]."
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,our approach exhibits a low patient-level specificity compared to ifsa.
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"therefore, completely resecting
cancerous tissue and improving patient outcomes.the false positive predictions
from the classification model presented two trends: false positives in an
isolated region and false positives spreading across a larger region."
FLIm-Based in Vivo Classification of Residual Cancer in the Surgical Cavity During Transoral Robotic Surgery,"the model will be validated on a larger patient cohort in future work and
address the limitations of the point-level false positive and negative
predictions."
FocalErrorNet: Uncertainty-Aware Focal Modulation Network for Inter-modal Registration Error Estimation in Ultrasound-Guided Neurosurgery,"resection of early-stage brain tumors can greatly reduce the mortality rate of
patients."
FocalErrorNet: Uncertainty-Aware Focal Modulation Network for Inter-modal Registration Error Estimation in Ultrasound-Guided Neurosurgery,"an example of
an mri-ius pair from a patient is shown in fig."
FocalErrorNet: Uncertainty-Aware Focal Modulation Network for Inter-modal Registration Error Estimation in Ultrasound-Guided Neurosurgery,"for registration error regression in surgical applications, knowledge regarding
the reliability of the automated results is instrumental for the safety and
wellbeing of the patients."
FocalErrorNet: Uncertainty-Aware Focal Modulation Network for Inter-modal Registration Error Estimation in Ultrasound-Guided Neurosurgery,"to prevent information leakage, we ensured that each patient was
included in only one of the split sets."
FocalErrorNet: Uncertainty-Aware Focal Modulation Network for Inter-modal Registration Error Estimation in Ultrasound-Guided Neurosurgery,"one limitation of our work
lies in the limited patient data, as public ius datasets are scarce, while the
settings and properties of us scanners can vary, potentially affecting the dl
model designs."
Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"in practice, imprecise
intraoperative cancer tissue detection and visualization results in missed
cancer or the unnecessary removal of healthy tissues, which leads to increased
costs and potential harm to the patient."
Detecting the Sensing Area of a Laparoscopic Probe in Minimally Invasive Cancer Surgery,"there is a pressing need for more
reliable and accurate intraoperative visualization tools for minimally invasive
surgery (mis) to improve surgical outcomes and enhance patient care."
A Novel Video-CTU Registration Method with Structural Point Similarity for FURS Navigation,none
Cascade Transformer Encoded Boundary-Aware Multibranch Fusion Networks for Real-Time and Accurate Colonoscopic Lesion Segmentation,none
Unified Brain MR-Ultrasound Synthesis Using Multi-modal Hierarchical Representations,"we evaluated our method on a dataset of 66
consecutive adult patients with brain gliomas who were surgically treated at the
brigham and women's hospital, boston usa, where both pre-operative 3d t2-space
and pre-dural opening intraoperative us (ius) reconstructed from a tracked
handheld 2d probe were acquired."
StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"it has
received growing attention in medical imaging due to the various contexts where
it applies, like image fusion between 2d real-time acquisitions and either
pre-operative 3d images for guided interventions or reference planning volumes
for patient positioning in radiation therapy (rt)."
StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"our clinical dataset consists of 108 patients for
whom were acquired both a pre-operative h&n ct scan and 4 to 11 wsis after
laryngectomy (with a total amount of 849 wsis)."
StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"we split the dataset patient-wise into three
groups for training (64), validation (20), and testing (24)."
StructuRegNet: Structure-Guided Multimodal 2D-3D Registration,"we implemented our
model with pytorch1.13 framework and trained for 600 (800 for mr/ct) epochs with
a batch size of 8 (4 for mr/ct) patients parallelized over 4 nvidia gtx 1080
tis.evaluation."
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"tomographic imaging estimates body density using hundreds of x-ray projections,
but it's slow and harmful to patients."
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"acquisition time may be too high for
certain applications, and each projection adds dose to the patient."
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"this can improve image-guided therapies and preoperative planning,
especially for radiotherapy, which requires precise patient positioning with
minimal radiation exposure.however, this task is an ill-posed inverse problem:
x-ray measurements are the result of attenuation integration across the body,
which makes them very fig."
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"compared to nerf-based methods, our method exploits prior
knowledge from many patients to require only two projections."
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"we evaluate our
method on reconstructing cancer patients' head-and-neck cts, which involves
intricate and complicated structures."
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"in practice, we take operator a as a 3d cone beam
projection that simulates x-ray attenuation across the patient, adapted from
[21,27]."
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"we trained our model with a large dataset of 3500 cts of
patients with head-and-neck cancer, more exactly 2297 patients from the publicly
available the cancer imaging archive (tcia) [1,6,16,17,28,32] and 1203 from
private internal data, after obtention of ethical approbations."
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"to
evaluate our approach, we used an external private cohort of 80 patients who had
undergone radiotherapy for head-and-neck cancer, with their consent."
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"our method
achieves better fitting of the patient structure, including bones, tissues, and
air separations, almost matching the real ct volume."
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"in some clinical procedures, an
earlier ct volume of the patient may be available and can be used as an
additional input for nerp [23]."
X2Vision: 3D CT Reconstruction from Biplanar X-Rays with Deep Structure Prior,"this approach may provide coarse
reconstructions for patients with rare abnormalities, as most learning methods,
but a larger dataset or developing a prior including tissue abnormalities could
improve robustness."
Structure-Preserving Synthesis: MaskGAN for Unpaired MR-CT Translation,"unfortunately, ct imaging exposes patients
to ionizing radiation, which can damage dna and increase cancer risk [9],
especially in children and adolescents."
Structure-Preserving Synthesis: MaskGAN for Unpaired MR-CT Translation,"we collected 270 volumetric t1-weighted mri and 267 thinslice
ct head scans with bony reconstruction performed in pediatric patients under
routine scanning protocols1 ."
Structure-Preserving Synthesis: MaskGAN for Unpaired MR-CT Translation,"we targeted the age group from 6-24 months since
pediatric patients are more susceptible to ionizing radiation and experience a
greater cancer risk (up to 24% increase) from radiation exposure [7]."
Structure-Preserving Synthesis: MaskGAN for Unpaired MR-CT Translation,"13 mri-ct
volumes from the same patients that were captured less than three months apart
are registered using rigid registration algorithms."
FreeSeed: Frequency-Band-Aware and Self-guided Network for Sparse-View CT Reconstruction,"we conduct experiments on the dataset of ""the 2016 nih-aapm mayo clinic low dose
ct grand challenge"" [8], which contains 5,936 ct slices in 1 mm image thickness
from 10 anonymous patients, where a total of 5,410 slices from 9 patients,
resized to 256 × 256 resolution, are randomly selected for training and the 526
slices from the remaining one patient for testing without patient overlap."
Co-learning Semantic-Aware Unsupervised Segmentation for Pathological Image Registration,"to perform the longitudinal registration task, we registered each
pre-operative scan to the corresponding follow-up scan of the same patient and
measured the mean target registration error (tre) of the paired landmarks using
the resulting deformation field."
Fast Reconstruction for Deep Learning PET Head Motion Correction,"marker-based hmt such as polaris vicra (ndi, canada) use
light-reflecting markers on the patient's head and track the markers for motion
correction [6]."
Fast Reconstruction for Deep Learning PET Head Motion Correction,"however, vicra is not routinely used in the clinic, as setup and
calibration of the tracking device can be complicated and attaching markers to
each patient increases the logistical burden of the scan."
Revealing Anatomical Structures in PET to Generate CT for Attenuation Correction,"the data used in our experiments are collected from the cancer image archive
(tcia) [4] (https://www.cancerimagingarchive.net/collections/), where a series
of public datasets with different types of lesions, patients, and scanners are
open-access."
An Explainable Deep Framework: Towards Task-Specific Fusion for Multi-to-One MRI Synthesis,none
Geometric Ultrasound Localization Microscopy,none
Reflectance Mode Fluorescence Optical Tomography with Consumer-Grade Cameras,none
DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"our neural network is
trained using patches from the ""gold atlas -male pelvis -gentle radiotherapy""
[14] dataset, which is comprised of 18 patients each with a ct, mr t1, and mr t2
volumes."
DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"the dataset comprises 8 sets of mr and ct volumes, both depicting the
abdominal region of a single patient and exhibiting notable deformations."
DISA: DIfferentiable Similarity Approximation for Universal Multimodal Registration,"as the most challenging experiment, we finally use our method to achieve
deformable registration of abdominal 3d freehand us to a ct or mr volume.we are
using a heterogeneous dataset of 27 cases, comprising liver cancer patients and
healthy volunteers, different ultrasound machines, as well as optical vs."
Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"when a patient is located in a ct equipment, a set of consecutive
cross-sectional images are generated."
Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"first, our proposed approaches are evaluated on the ""mayo-clinic
low-dose ct grand challenge"" (mayo-clinic) dataset of lung ct images [19].the
dataset contains 2250 two dimensional slices from 9 patients for training, and
the remaining 128 slices from 1 patient are reserved for testing."
Solving Low-Dose CT Reconstruction via GAN with Local Coherence,"we randomly
select 4 patients with 1827 slices from the dataset."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,radiotherapy (rt) is one of the cornerstones of cancer patients.
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"from the projections, it is possible to extract a respiratory signal [12], which
indicates the position of the organs within the patient during breathing."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"this was not the case for noise2aliasing, and
historical clinical data sufficed for training.we validated our method on
publicly available data [15] against a supervised approach [6] and applied it to
an internal clinical dataset of 30 lung cancer patients."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"the spare varian dataset was used to provide performance
results on publicly available patient data."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"to more closely resemble normal
respiratory motion per projection image, the 8 min scan has been used from each
patient (five such scans are available in the dataset)."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"training is performed
over 4 patients while 1 patient is used as a test set."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"an internal dataset (irb approved) of 30
lung cancer patients' 4dcbcts from 2020 to 2022, originally used for igrt, with
25 patients for training and 5 patients for testing."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"the metrics in table 1 show
mean and standard deviation across all phases for a single patient."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"noise2alisting trained
on 25 patients and tested on 5 achieved mean psnr of 35.24 and ssim of 0.91,
while the clinical method achieved mean psnr of 29.97 and 0.74 ssim with p-value
of 0.048 for the psnr and 0.0015 for the ssim, so noise2aliasing was
significantly better according to both metrics."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"overall, using more patients results in better noise reduction and
sharper reconstructions (see fig."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"with fewer patients, the model is
more conservative and tends to keep more noise, but also smudges the interface
between tissues and bones."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"with more patients, more of the view-aliasing is
addressed, and the reconstruction is sharper, however, a few small anatomical
structures tend to be suppressed by the model.especially between fat tissue and
skin and around the bones."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"however, the model also tends to remove small
anatomical structures as high-frequency objects that cannot be distinguished
from the noise.when applied to a clinical dataset, noise2aliasing benefits from
more patients being included in the dataset, however, qualitatively good
performance is already achieved with 5 patients."
Noise2Aliasing: Unsupervised Deep Learning for View Aliasing and Noise Reduction in 4DCBCT,"as future work, we plan to study noise2aliasing
in the presence of changes in the breathing frequency and amplitude between
patients and during a scan."
DULDA: Dual-Domain Unsupervised Learned Descent Algorithm for PET Image Reconstruction,"forty 128 × 128 × 40 3d zubal brain phantoms [24] were used in the simulation
study as ground truth, and one clinical patient brain images with different dose
level were used for the robust analysis."
DULDA: Dual-Domain Unsupervised Learned Descent Algorithm for PET Image Reconstruction,"to test the robustness of proposed dulda, we forward-project one patient brain
image data with different dose level and reconstructed it with the trained dulda
model."
DULDA: Dual-Domain Unsupervised Learned Descent Algorithm for PET Image Reconstruction,"the patient is
scanned with a ge discovery mi 5-ring pet/ct system."
Low-Dose CT Image Super-Resolution Network with Dual-Guidance Feature Distillation and Dual-Path Content Communication,avg ct is the average image among adjacent ct slices of each patient.
Low-Dose CT Image Super-Resolution Network with Dual-Guidance Feature Distillation and Dual-Path Content Communication,"we first calculate
the average ct image of adjacent ct slices of each patient to provide the 3d
spatial structure information of ct volume."
Non-iterative Coarse-to-Fine Transformer Networks for Joint Affine and Deformable Image Registration,"these nice registration methods show advantages in both registration accuracy
and runtime on the benchmark task of intra-patient brain mri registration."
Non-iterative Coarse-to-Fine Transformer Networks for Joint Affine and Deformable Image Registration,"we evaluated the proposed nice-trans on the task of inter-patient brain mri
registration, which is a common benchmark task in medical image registration
studies [7][8][9][12][13][14][15][16][17][18]."
Non-iterative Coarse-to-Fine Transformer Networks for Joint Affine and Deformable Image Registration,"first, the experiment (table 1)
demonstrated that our nice-trans can well address the inherent misalignments
among inter-patient brain mri images, but the sensitivity of affine registration
to different degrees of misalignments is still awaiting further exploration."
Non-iterative Coarse-to-Fine Transformer Networks for Joint Affine and Deformable Image Registration,"second, in this study, we evaluated the nice-trans on the benchmark task of
inter-patient brain mri registration, while we believe that our nice-trans also
could apply to other image registration applications (e.g., brain tumor
registration [37])."
Trackerless Volume Reconstruction from Intraoperative Ultrasound Images,"this information is then used to register the 3d ultrasound image with
the patient's anatomy."
Trackerless Volume Reconstruction from Intraoperative Ultrasound Images,"frames were cropped to remove the patient and probe
characteristics, then down-sampled to a size of 128 × 128 with an image spacing
of 0.22 mm per pixel."
CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,"magnetic resonance imaging (mri) is critical to the diagnosis, treatment, and
follow-up of brain tumour patients [26]."
CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,"multiple mri modalities offer
complementary information for characterizing brain tumours and enhancing patient
l."
CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,"the brats 2018 contains mri scans from
285 glioma patients."
CoLa-Diff: Conditional Latent Diffusion Model for Multi-modal MRI Synthesis,"therefore, cola-diff could serve as a useful tool for generating mri to reduce
the burden of mri scanning and benefit patients and healthcare providers."
InverseSR: 3D Brain MRI Super-Resolution Using a Latent Diffusion Model,none
Topology-Preserving Computed Tomography Super-Resolution Based on Dual-Stream Diffusion Model,none
LightNeuS: Neural Surface Reconstruction in Endoscopy Using Illumination Decline,none
