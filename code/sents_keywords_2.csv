paper_id,extracted_sents_keywords
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_14.pdf,"[13], obtaining results comparable to full 3d supervision. compared to
centerline segmentation, where the vessel diameter is disregarded, training a 3d
vessel segmentation model from 2d annotations poses additional segmentation-
speciﬁc challenges, as 2d projections only capture the outline of the vessels,
providing no information about their interior. furthermore, the axes of projec-
tion are crucial for the model’s success, given the sparsity of information in 2d
annotations.
to achieve 3d vessel segmentation with only 2d supervision from projec-
tions, we ﬁrst investigate which viewpoints to annotate in order to maximize
segmentation performance."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_14.pdf,"4
experimental design
dataset. the cohort consists of 141 patients with pancreatic ductal adeno-
carcinoma, of an equal ratio of male to female patients. [15,18] and
semi-automatically extract the ribs, which have similar intensities as arteries in
arterial cts and would otherwise occlude the vessels."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_14.pdf,"we implement [13] as a baseline on our dataset, training on up to 3
ﬁxed orthogonal projections. we distinguish between models selected according
to the 2d performance on the validation set (2d) which is a fair baseline, and
models selected according to the 3d performance on the validation set (3d),
which is an unfair baseline as it requires 3d annotations on the validation set. with the exception of the single ﬁxed viewpoint baselines where the models have
the tendency to diverge towards over- or segmentation, we perform binary hole-
ﬁlling on the output of all of our other models, as producing hollow objects is a
common under-segmentation issue."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_59.pdf,"3d mitochondria instance segmentation
with spatio-temporal transformers
omkar thawakar1(b), rao muhammad anwer1,2, jorma laaksonen2,
orly reiner3, mubarak shah4, and fahad shahbaz khan1,5
1 mbzuai, masdar city, uae
omkar.thawakar@mbzuai.ac.ae
2 aalto university, espoo, finland
3 weizmann institute of science, rehovot, israel
4 university of central florida, orlando, usa
5 linköping university, linköping, sweden
abstract. accurate 3d mitochondria instance segmentation in electron
microscopy (em) is a challenging problem and serves as a prerequisite
to empirically analyze their distributions and morphology."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_59.pdf,"however, automatic 3d mito-
chondria instance segmentation is a challenging task, since complete shape of
mitochondria can be sophisticated and multiple instances can also experience
entanglement with each other resulting in unclear boundaries. here, we look
into the problem of accurate 3d mitochondria instance segmentation. earlier works on mitochondria segmentation employ standard image process-
ing and machine learning methods
[20,21,33]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_59.pdf,"although such a cnn-based designs [11,16,34] has achieved
promising segmentation results compared to traditional methods, they struggle
to eﬀectively capture long-range dependencies due to their limited local recep-
tive ﬁeld. [6,13,19,30,31] have been successfully utilized in dif-
ferent computer vision problems due to their capabilities at modelling long-range
dependencies and enabling the model to attend to all the elements in the input
616
o. thawakar et al.
sequence. the core component in vits is the self-attention mechanism that that
learns the relationships between sequence elements by performing relevance esti-
mation of one item to other items."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_59.pdf,"in this way, self-attention mechanism goes
much beyond the receptive ﬁeld of the conventional convolutional ﬁlters. while
self-attention has been shown to be beneﬁcial when combined with convolutional
layers for diﬀerent medical imaging tasks, to the best of our knowledge, no pre-
vious attempt to design spatio-temporal self-attention as an exclusive building
block for the problem of 3d mitochondria instance segmentation exists in liter-
ature. next, we present our approach that eﬀectively utilizes an eﬃcient spatio-
temporal attention mechanism for 3d mitochondria instance segmentation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_59.pdf,"best results are in bold. [36] is a dense mitochondria instance seg-
mentation dataset from isbi 2021 challenge. the dataset consists of 2 em image
volumes (30 μm3) of resolution of 8 × 8 × 30 nm, from rat tissues (mitoem-r)
and human tissue (mitoem-h) samples, respectively."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_59.pdf,"[27]
(rcom env) and models are trained using 2 amd mi250x gpus. during training
of mitoem, for the fair comparison, we adopt same data augmentation technique
from [36]. the 3d patch of size (32×320×320) is input to the model and trained
using batch size of 2."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_59.pdf,"for lucchi, we follow training
details of [16,36] for semantic segmentation. for fair comparison with previous
works, we use the same evaluation metrics as in the literature for both datasets. we use 3d ap-75 metric [36] for mitoem-r and mitoem-h datasets."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_46.pdf,"we argue that such a
strategy struggles to eﬀectively perform deep feature aggregation and
ignores the useful local information. to tackle these issues, we propose a
spatial-temporal deformable attention based framework, named stnet. our stnet introduces a spatial-temporal deformable attention module
to perform local spatial-temporal feature fusion."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_46.pdf,"keywords: breast lesion detection · ultrasound videos ·
spatial-temporal deformable attention · multi-frame prediction
1
introduction
ultrasound imaging is a very eﬀective technique for breast lesion diagnosis,
which has high sensitivity. automatically detecting breast lesions is a challeng-
ing problem with a potential to aid in improving the eﬃciency of radiologists in
ultrasound-based breast cancer diagnosis [18,21]. some of the challenges asso-
ciated with automatic breast lesion detection include blurry boundaries and
changeable sizes of breast lesions."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_46.pdf,"[9] proposed a feature aggregation network, termed as cva-net, that
executes intra-video and inter-video fusions at both video and clip levels based
on attention blocks. although the recent cva-net aggregates clip and video
level features, we distinguish two key issues that hamper its performance. first,
the self-attention based cross-frame feature fusion is a global-level operation and
it operates once before the encoder-decoder, thereby ignoring the useful local
information and in turn missing an eﬀective deep feature fusion."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_46.pdf,"we show the best results in bold. video
resnet-50 40.0 70.3
43.3
the previous work cva-net [9], to guarantee a fair comparison. speciﬁcally, the
testing set comprises 38 videos randomly selected from all 186 videos, while the
rest of the videos are used as the training set."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_46.pdf,"a texture neural network to predict
the abnormal brachial plexus from routine
magnetic resonance imaging
weiguo cao, benjamin howe, nicholas rhodes, sumana ramanathan,
panagiotis korﬁatis, kimberly amrami, robert spinner, and timothy kline(b)
mayo clinic, rochester, minnesota 55905, usa
kline.timothy@mayo.edu
abstract. brachial plexopathy is a form of peripheral neuropathy, which occurs
when there is damage to the brachial plexus (bp)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_46.pdf,"one prior approach, termed
glcm-cnn, was proposed to carry out a polyp differentiation task [13]. however, how
to arrange these glcms to form the 3d volume to optimize the performance is a major
challenge. with the goal of classifying normal from abnormal bp, we explored the approach
of deep texture learning."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_46.pdf,"the major
contributions of this study include 1) directed triangle construction idea for tpp, 2) huge
number of tpp matrices as the heterogeneity representations of bp, 3) tppnet with 15
layers and huge number of channels, 4) the bp dataset containing mr images and their
corresponding roi masks. 2
materials and method
2.1
dataset preparation and preprocessing
following irb approval for this study, we search for patients with metastatic breast
cancer who had a breast cancer mri performed between 2010 and 2020 and had mor-
phologically positive bp on the mri report from our electronic medical records (emr)
in * hospital. totally, 189 patients including 141 normal patients and 41 abnormal ones
are obtained."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_46.pdf,"the range of the age are varying from 15 to 85 years old. the female patient
number and male patient number are almost even. their weights by kg are in the range
of [40.8 kg, 145 kg]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_46.pdf,"then, the manual segmentations were utilized to train a 3d
nnunet model which was utilized to train the model which was used to predict rois
for the rest series [16]. the predicted segmentations were manually divided into three
groups, i.e. good, fair and poor. good cases were added to the training set."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_46.pdf,"we integrate the k-fold cross-validation, tpp gener-
ation and model training into one framework. since the tpp matrix is always small,
there are only 15 layers in tpp which could reduce the risk of overﬁtting issue met
in deeper neural networks. 4) free from the interference of multi-texture-pattern arrangements."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_74.pdf,"while prognostication and survival analysis oﬀer invaluable insights
for patient management, biological studies and drug development eﬀorts, they
require careful tracking of patients for a lengthy period of time; rendering this
as a task that requires a signiﬁcant amount of eﬀort and funding. in the machine learning domain, patient prognostication can be treated as a
weakly supervised problem, which a model would predict the outcome (e.g., time
to cancer recurrence) based on the histopathology images. [8] that is a two-step learning method."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_74.pdf,"diﬀerent mil variations have shown supe-
rior performances in grading or subtype classiﬁcation in comparison to outcome
prediction [10]. this is perhaps due to the fact that mil-based technique do
not incorporate patch locations and interactions as well as tissue heterogeneity
which can potentially have a vital role in deﬁning clinical outcomes [4,26].
to address this issue, graph neural networks (gnn) have recently received
more attention in histology. [17] by utilizing mes-
sage passing mechanism via edges connecting the nodes (i.e., small patches in our
case)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_74.pdf,"3
method
figure 1 summarizes our proposed end-to-end solution. below, we have provided
details of each module.
3.1
problem formulation
for pn, which is the n-th patient, a set of patches {patchj}m
j=1 is extracted
from the related whole slide images. in addition, a latent vector zj ∈ r1×d is
extracted from patchj using our encoder network (described in sect."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_74.pdf,"we exploit the mincut [5] idea to extract super-nodes in a diﬀerentiable
process after an auxiliary ginconv to focus more on large-scale interactions and
to ﬁnally learn the most global correlated super-nodes. inspired by the relaxation
form of the known k-way mincut problem, we create a continuous cluster
matrix cn ∈ rm×k using mlp layers and can ﬁnally estimate the super-nodes
features (sn ∈ rm×d) as:
sn = ct
n .x′
n,
cn = softmax (relu(x′
n.w1).w2) ,
(3)
where w1, w2 are mlps’ weights. hence, the extracted nodes are directly depen-
dent on the ﬁnal survival-speciﬁc loss."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_74.pdf,"in addition, two additional unsupervised
weighted regularization terms are optimized to improve the process:
mincut regularizer. this term is motivated by the original mincut problem
and intends to solve it for the the patients’ graph. it is deﬁned as:
rmincut = −tr(ct
n .an,norm.cn)
tr(ctn .dn.cn)
,
(4)
where dn is the diagonal degree matrix for an."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_74.pdf,"sigm(wk,gst
n ˆhl,n)

(8)
– mixed co-attention (mca): while the ﬁrst strategy allows the extreme
separation of two paths, the second one has the highest level of mixing infor-
mation. here, we take a balanced policy between the independence and knowl-
edge mixture of the two routes by only sharing the weights without using any
guidance. 4
experiments and results
4.1
dataset
we utilize two prostate cancer (pca) datasets to evaluate the performance of
our proposed model."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_74.pdf,"the recorded endpoint for this set is biochemical recurrence with
time to recurrence ranging from 11.7 to 56.1 months. we also utilized the prostate cancer grade assessment (panda) challenge
dataset [7] that includes more than 10,000 pca needle biopsy slides (no outcome
data) as an external dataset for training the encoder of our model.
4.2
experiments
we evaluate the models’ performance in two scenarios utilizing several objective
metrics. implementation details are available in supplementary material."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_74.pdf,"statistical tests
(paired t-test) on c-indices also show that our model is statistically better than
all baselines in pca-as and also superior to all models, except dgc, in pca-bt. superior performance of our mca policy implies that balanced exploitation of
ﬁne and coarse features with shared weights may provide more robust contex-
tual information compared to using mixed guided information or utilizing them
independently. the capacity of stratifying patients into risk groups
(e.g., low and high risk) is another criterion that we employ to assess the util-
ity of models in clinical practice."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_74.pdf,"furthermore, our ﬁndings
have signiﬁcant clinical implications as they identify, for the ﬁrst time, high-
risk prostate cancer patients who are otherwise known to be low-risk based on
clinico-pathological parameters. this group should be managed diﬀerently from
the rest of the low-risk prostate cancer patients in the clinic. therefore, pro-
viding evidence of the predictive (as opposed to prognostic) clinical information
that our model provides."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_9.pdf,"[18]. identifying potentially informative image regions (i.e., providing
useful information for model training) allows requesting the minimum amount
of annotations for model optimization, and a decrease in annotated area reduces
both localization and delineation workloads. the challenge is to eﬀectively select
annotation regions in order to achieve full annotation performance with the least
annotated area, resulting in high sampling eﬃciency. we use region-based active learning (al) [13] to progressively identify anno-
tation regions, based on iteratively updated segmentation models."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_9.pdf,"to validate our segmentation framework, we
ﬁrst train on the fully-annotated data (average performance of ﬁve repetitions
reported). with a patch extraction stride s = 256 pixels, our framework yields
an froc score of 0.760 that is equivalent to the challenge top 2, and an miou
(tumor) of 0.749, which is higher than the most comparable method in [3] that
achieved 0.741 with s = 128 pixels. with our framework, reducing s to 128 pixels
improves both metastases identiﬁcation and segmentation (froc score: 0.779,
miou (tumor): 0.758)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_9.pdf,"4(e–i)) shows that adaptive eﬀectively prevents the rapid expansion of
annotated tissue area as al step size increases, demonstrating greater robustness
to al step size choices than standard. this is advantageous because extensive
al step size tuning to balance the annotation and computation costs can be
avoided. this behavior can also be desirable in cases where frequent interac-
tion with annotators is not possible or to reduce computation costs, because the
proposed method is more tolerant to a large al step size."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_9.pdf,"4(h) that the full annotation performance is not achieved
with adaptive within 15 al cycles; in fig. s1 in the supplementary materials
we show that allowing for oversampling of previously selected regions can be a
solution to this problem. additionally, we visualize examples of selected regions
in fig. 5 and show that adaptive avoids two region selection issues of standard:
small, isolated informative areas are missed, and irrelevant pixels are selected
due to the region shape and size restrictions."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_61.pdf,"to that end, researchers have recently proposed to use gan-based image-to-
image translation (i2it) algorithms for transforming h&e-stained slides into
ihc. despite the progress, the outstanding challenge in training such i2it frame-
works is the lack of aligned h&e-ihc image pairs, or in other words, the incon-
sistencies in the h&e-ihc groundtruth pairs. to explain, since re-staining a
slice is physically infeasible, a matching pair of h&e-ihc slices are taken from
two depth-wise consecutive cuts of the same tissue then stained and scanned
separately."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_61.pdf,"to that end, we further augment the weight so that it is also a function of the
training iterations. such scheduling of the weights is done so that in the beginning
of the training, the weights are uniform in order not to wrongly bias the network
when the embeddings are still indiscriminative. and as training progresses, the
selective weighting scheme is gradually enforced so that the inconsistent patch
locations are treated with reduced weights."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_68.pdf,"this is also a big cause of con-
cern for publicly available h&e/ihc cell segmentation datasets with immune
cell annotations from single pathologists. multiplex staining resolves this issue
by allowing diﬀerent tumor and immune cell markers to be stained on the same
tissue section, avoiding any phenotyping guesswork from pathologists. 1. dataset overview."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_68.pdf,"demographics and other relevant details of the eight anonymized head-and-
neck squamous cell carcinoma patients, including ecog performance score, pack-year,
and surgical pathology stage (ajcc8). 2
oral cavity lateral tongue
case7 73
male
white 1
former
100
3
larynx
glottis
case8 56
male
white 0
never
0
2
oral cavity tongue
2
dataset
the complete staining protocols for this dataset are given in the accompany-
ing supplementary material. images were acquired at 20× magniﬁcation at
moﬃtt cancer center."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_68.pdf,"3. examples of synthesized ihc images and corresponding input images. style ihc
images were taken from the public lyon19 challenge dataset [14]. we used grayscale
hematoxylin images because they performed better with style transfer.
fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_68.pdf,"3.3
virtual cellular phenotyping on standard hematoxylin images
there are several public h&e/ihc cell segmentation datasets with manual
immune cell annotations from single pathologists. these are highly problem-
atic given the large (> 50%) disagreement among pathologists on immune cell
phenotyping [10]. in this last use case, we infer immune and tumor markers
from the standard hematoxylin images using again the public deepliif vir-
tual translation module [2,3]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_68.pdf,"data use declaration and acknowledgment: this study is not human sub-
jects research because it was a secondary analysis of results from biological spec-
imens that were not collected for the purpose of the current study and for which
the samples were fully anonymized. this work was supported by msk cancer
center support grant/core grant (p30 ca008748) and by james and esther
king biomedical research grant (7jk02) and moﬃtt merit society award to c.
h. chung. it is also supported in part by the moﬃtt’s total cancer care initia-
tive, collaborative data services, biostatistics and bioinformatics, and tissue
core facilities at the h. lee moﬃtt cancer center and research institute, an
nci-designated comprehensive cancer center (p30-ca076292)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_56.pdf,"the bethesda system for reporting thyroid cytopathol-
ogy (tbsrtc) has been widely accepted as a reliable criterion for
thyroid cytology diagnosis, where extensive diagnostic information can
be deduced from the allocation and boundary of cell nuclei. however,
two major challenges hinder accurate nuclei segmentation from thyroid
cytology. firstly, unbalanced distribution of nuclei morphology across
diﬀerent tbsrtc categories can lead to a biased model."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_56.pdf,"such distinct morphological diﬀerences can
be characterized by the tbsrtc category, which thus inspires us to utilize
the handy image-wise grading labels to guide the nuclei segmentation model
learning from unbalanced datasets. we also noticed that another challenge for
accurate nuclei identiﬁcation is the heavy reliance on large-scale high-quality
annotations [11]. moreover, amongst multiple annotation paradigms [12], pixel-
level labeling is the most time-consuming and laborious, whereas the image-wise
diagnostic labels, i.e. tbsrtc categories, are comparatively simpler."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_56.pdf,"(1) we pro-
pose a cytopathology nuclei segmentation network named tcsegnet, to pro-
vide supplementary guidance to facilitate the learning of nuclei boundaries. 582
j. zhu et al.
innovatively, our approach can help reduce bias in the learning process of the
segmentation model with the routine unbalanced training set. (2) we expand
tcsegnet to semi-tcsegnet to leverage image-wise labels in a semi-supervised
learning manner, which signiﬁcantly reduces the reliance on annotation-intensive
pixel-wise labels."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_56.pdf,"tbsrtc-category label guidance block. in tcsegnet, we introduce
a tbsrtc-category label guidance block to address the learning issue from
unbalanced routine datasets. this block consists of two learnable fully connected
layers that process the feature extracted by the cnn and transformer branches
separately, which obtains image-wise tbsrtc-category prediction denoted as
ˆycnn
cls and ˆytrans
cls
."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_56.pdf,"the balancing
coeﬃcient λss changes for every epoch e, namely
λe
ss = exp(−5 (1 − e/emax)2),
(5)
where emax is the maximum epoch number. the traditional method of integrating gaussian noise
in the mean teacher [18] may be problematic when working with cytopathology
images that have an imbalanced color distribution. to address this issue, we
generate a novel intensity-based noise, which can adaptively behave stronger in
the dark nuclei areas and weaker in bright cytoplasm or background regions."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_56.pdf,"3, together with the line charts in fig. our approach is capable
to address the current issue in the recognition and segmentation of small iso-
lated cells graded in the i category, which is always ignored by the unbalanced
pixel-wise cell morphology with other approaches. also, it yields that the incor-
poration of tbsrtc-category can contribute to a partial alleviation of a biased
model, resulting in more satisfying segmentation performance experimentally."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_56.pdf,"classiﬁcation
learning
hsv-intensity
noise
dice
iou
0.867
0.771

0.876
0.785

0.884
0.797


0.889 0.805
w. image-wise data
+1k data
0.879
0.790
+2k data
0.882
0.795
4
conclusion
in this paper, we propose a tbsrtc-category aware nuclei segmentation frame-
work tcsegnet, that leverages easy-to-obtain image-wise diagnostic category to
facilitate nuclei segmentation. importantly, it addresses the challenge of dis-
tinguishing nuclei across diﬀerent cell scales in an unbalanced dataset. we also
extend the framework to a semi-supervised learning fashion to overcome the issue
of lacking annotated training samples."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_5.pdf,"multi-sequence mri is valuable in clinical settings for reli-
able diagnosis and treatment prognosis, but some sequences may be unus-
able or missing for various reasons. to address this issue, mri synthesis is
a potential solution. recent deep learning-based methods have achieved
good performance in combining multiple available sequences for missing
sequence synthesis."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_5.pdf,"most of these works introduce an autoencoder-like architecture
for image-to-image translation and employ adversarial loss to generate more
realistic images. unlike these one-to-one approaches, mri synthesis faces the
challenge of fusing complementary information from multiple input sequences. recent studies about multi-sequence fusion can speciﬁcally be divided into two
groups: (1) image fusion and (2) feature fusion."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_5.pdf,"the weighted average is an intuitive fusion
strategy that can quantify the contribution of diﬀerent sequences directly. + ϵ
(1)
where w and b are weights and bias for the fc layer, ϵ = 10−5 to avoid dividing
0 in the following equation. ∈ rn to sum to 1."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_45.pdf,"xiaoying wang5(b), and lihua zhang1(b)
1 academy for engineering and technology, fudan university, shanghai, china
lihuazhang@fudan.edu.cn
2 school of computing, university of leeds, leeds, uk
3 school of biomedical engineering, shanghaitech university, shanghai, china
cuizhm@shanghaitech.edu.cn
4 changchun boli technologies co., ltd., jilin, china
5 department of liver surgery, key laboratory of carcinogenesis and cancer
invasion of ministry of education, liver cancer institute, zhongshan hospital,
fudan university, shanghai, china
xiaoyingwang@fudan.edu.cn
abstract. accurately segmenting the liver into anatomical segments
is crucial for surgical planning and lesion monitoring in ct imaging."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_45.pdf,"however, this is a challenging task as it is deﬁned based on vessel
structures, and there is no intensity contrast between adjacent seg-
ments in ct images. in this paper, we propose a novel point-voxel
fusion framework to address this challenge. speciﬁcally, we ﬁrst seg-
ment the liver and vessels from the ct image, and generate 3d
liver point clouds and voxel grids embedded with vessel structure
prior."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_45.pdf,"the
couinaud segmentation [7] based on ct images divides the liver into eight func-
tionally independent regions, which intuitively display the positional relation-
ship between couinaud segments and intrahepatic lesions, and helps surgeons
for make surgical planning [3,13]. in clinics, couinaud segments obtained from
manual annotation are tedious and time-consuming, based on the vasculature
used as rough guide (fig. 1). thus, designing an automatic method to accu-
rately segment couinaud segments from ct images is greatly demanded and
has attracted tremendous research attention."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_45.pdf,"it can supplement the cnn-based method and improve the segmentation per-
formance in regions without intensity contrast. in this paper, to tackle the aforementioned challenges, we propose a point-
voxel fusion framework that represents the liver ct in continuous points to
better learn the spatial structure, while performing the convolutions in voxels
to obtain the complementary semantic information of the couinaud segments.
fig. 1. couinaud segments (denoted as roman numbers) in relation to the liver vessel
structure."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_45.pdf,"however,
directly feeding the transformed point data as input into the point-based branch
undoubtedly ignores the vessel structure, which is crucial for couinaud segmen-
tation. to solve this issue, we propose a strategy of continuous spatial sampling
point data based on the m ′. speciﬁcally, the model randomly samples t points
in each training epoch, of which t/2 points fall in the smaller space covered by
the m ′, which enables the model to increase access to important data in the
region during training. in addition, we apply a random perturbation oﬀset =
(δx, δy, δz) in the range of [−1, 1] to each point pt = (xt, yt, zt) ∈ m ′ in this
region to obtain a new point pt = (xt + δx, yt + δy, zt + δz), and the intensity
in this coordinate obtained by trilinear interpolation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_45.pdf,"experimental results demon-
strate the eﬀectiveness of our proposed method against other cutting-edge meth-
ods, showing its potential to be applied in the preoperative application of liver
surgery.
acknowledgement. this project was funded by the national natural science foun-
dation of china (82090052, 82090054, 82001917 and 81930053), clinical research plan
of shanghai hospital development center (no. 2020cr3004a), and national key
research and development program of china under grant (2021yfc2500402)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_6.pdf,"https://doi.org/10.1007/978-3-031-43907-0_6
58
p. müller et al.
however, while image classiﬁcation labels can be automatically extracted
from electronic health records or radiology reports [7,20], this is typically not
possible for bounding boxes, thus limiting the availability of large datasets
for pathology detection. additionally, manually annotating pathology bound-
ing boxes is a time-consuming task, further exacerbating the issue. the result-
ing scarcity of large, publicly available datasets with pathology bounding boxes
limits the use of supervised methods for pathology detection, such that cur-
rent approaches typically follow weakly supervised object detection approaches,
where only classiﬁcation labels are required for training."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_50.pdf,"anatomy-informed data augmentation
for enhanced prostate cancer detection
balint kovacs1,2,3(b)
, nils netzer2,3
, michael baumgartner1,4,5
,
carolin eith2,3, dimitrios bounias1,3, clara meinzer2, paul f. jäger5,6
,
kevin s. zhang2, ralf floca1, adrian schrader2,3
, fabian isensee1,5
,
regula gnirs2, magdalena görtz7,8, viktoria schütz7, albrecht stenzinger9,
markus hohenfellner7, heinz-peter schlemmer2, ivo wolf10
,
david bonekamp2
, and klaus h. maier-hein1,5,11
1 division of medical image computing, german cancer research center (dkfz),
heidelberg, germany
balint.kovacs@dkfz-heidelberg.de
2 division of radiology, german cancer research center (dkfz),
heidelberg, germany
3 medical faculty heidelberg, heidelberg university, heidelberg, germany
4 faculty of mathematics and computer science, heidelberg university,
heidelberg, germany
5 helmholtz imaging, german cancer research center (dkfz),
heidelberg, germany
6 interactive machine learning group, german cancer research center (dkfz),
heidelberg, germany
7 department of urology, university of heidelberg medical center,
heidelberg, germany
8 junior clinical cooperation unit ‘multiparametric methods for early detection
of prostate cancer’, german cancer research center (dkfz), heidelberg, germany
9 institute of pathology, university of heidelberg medical center,
heidelberg, germany
10 mannheim university of applied sciences, mannheim, germany
11 pattern analysis and learning group, department of radiation oncology,
heidelberg university hospital, heidelberg, germany
abstract. data augmentation (da) is a key factor in medical image
analysis, such as in prostate cancer (pca) detection on magnetic reso-
nance images."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_50.pdf,"dnns
have already successfully supported radiologists in the interpretation of mag-
netic resonance images (mri) for prostate cancer (pca) diagnosis [3]. however,
the da scheme received less attention, despite its potential to leverage the data
characteristic and address overﬁtting as the root of generalization problems. state-of-the-art approaches still rely on simplistic spatial transformations,
like translation, rotation, cropping, and scaling by globally augmenting the mri
sequences [12,20]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_50.pdf,"malignancy of the segmented lesions was determined from
a systematic-enhanced lesion ground-truth histopathological assessment, which
has demonstrated reliable ground-truth assessment with sensitivity comparable
to radical prostatectomy [17]. the samples were evaluated according to the inter-
national society of urological pathology (isup) standards under the supervision
of a dedicated uropathologist. clinically signiﬁcant prostate cancer (cspca) was
deﬁned as isup grade 2 or higher."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_50.pdf,"crectum = 1200 and cbladder = 600 were selected for the ﬁnal models. compared
to the standard nnu-net settings, we implemented balanced sampling regard-
ing the prevalence of cspca and reduced the number of epochs to 350 to avoid
overﬁtting. we used mish activation function, ranger optimizer, cosine anneal
learning rate scheduler, and initial learning rate of 0.001 following [12]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_53.pdf,"modern deep learning methods for semantic segmentation
require labor-intensive labeling for large-scale datasets with dense pixel-
level annotations. recent data augmentation methods such as dropping,
mixing image patches, and adding random noises suggest eﬀective ways to
address the labeling issues for natural images. however, they can only be
restrictively applied to medical image segmentation as they carry risks of
distorting or ignoring the underlying clinical information of local regions
of interest in an image."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_53.pdf,"training a deep neural network (dnn) for such a task
is known to be data-hungry, as labeling dense pixel-level annotations requires
laborious and expensive human eﬀorts in practice [23,32]. furthermore, semantic
segmentation in medical imaging suﬀers from privacy and data sharing issues [13,
35] and a lack of experts to secure accurate and clinically meaningful regions of
interest (rois). this data shortage problem causes overﬁtting for training dnns,
resulting in the networks being biased by outliers and ignorant of unseen data.
to alleviate the sample size and overﬁtting issues, diverse data augmentations
have been recently developed."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_53.pdf,"also, cut-and-paste and crop-based methods carry risks
of dropping or distorting key objects such that expensive pixel-level annotations
could not be properly used. considering the rois are usually small and under-
represented compared to the backgrounds, the loss of information may cause a
fatal class imbalance problem in semantic segmentation tasks. in these regards, we tackle these issues with a novel augmentation method
without distorting the semantics of objects in image space."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_53.pdf,"the basic augmentation was used in
all methods including ours by default. for the training, we used k augmented
images with the given images for all baselines as in ours for a fair comparison.
evaluation. as the evaluation metric, mean intersection
over union (miou) and mean dice coeﬃcient (mdice) are used for all experi-
ments on test sets."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_33.pdf,"however, as medical image annotation is labour- and resource-
intensive, the scarcity of annotated data limits the eﬀectiveness and gen-
eralization of existing methods. although recent research has focused on
data generation and augmentation to address this issue, the quality of the
generated data remains a challenge, which limits the contribution to the
performance of subsequent tasks. inspired by the superiority of diﬀusion
models in ﬁtting data distributions and generating high-quality data,
in this paper, we propose an adaptive reﬁnement semantic diﬀusion
model (arsdm) to generate colonoscopy images that beneﬁt the down-
stream tasks."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_33.pdf,"[9,25]
or data augmentation methods [3,13,28] to enhance learning features, but
these methods yielded limited improvements in downstream tasks. recently,
diﬀusion models [6,15] have emerged as promising solutions to this problem,
demonstrating remarkable progress in generating multiple modalities of medical
data [4,10,12,21]. gt masks
original images
synthesis images
combine
segmentation
detection
downstream tasks
… …
arsdm
e.g.
e.g.
diffusion sampler
fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_33.pdf,"1. overview of the pipeline of our proposed approach, where details of arsdm
are described in sect. 2.
despite recent progress in these methods for medical image analysis, existing
models face two major challenges when applied to colonoscopy image analysis. firstly, the foreground (polyp) of colonoscopy images contains rich pathological
information yet is often tiny compared with the background (intestine wall) and
can be easily overwhelmed during training."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_33.pdf,"in addition, in order to generate high-quality annotated samples, it is
crucial to maintain the consistency between the polyp morphologies in synthe-
sized images and the original masks, which current generative models struggle
to achieve. to tackle these issues and inspired by the remarkable success achieved by dif-
fusion models in generating high-quality ct or mri data [8,11,23], we creatively
propose an eﬀective adaptive reﬁnement semantic diﬀusion model (arsdm) to
generate polyp-contained colonoscopy images while preserving the original anno-
tations. the pipeline of the data generation and downstream task training is
shown in fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_33.pdf,"speciﬁcally, we use the original segmentation masks as condi-
tions to train a conditional diﬀusion model, which makes the generated sam-
ples share the same masks with the input images. moreover, during diﬀusion
model training, we employ an adaptive loss re-weighting method to assign loss
arsdm
341
weights for each input according to the size ratio of polyps and background,
which addresses the overﬁtting problem for the large background. in addition,
we ﬁne-tune the diﬀusion model by minimizing the distance between the original
ground truth masks and the prediction masks from synthesis images via a pre-
trained segmentation network."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_33.pdf,"to the best of our
knowledge, this is the ﬁrst work for adapting diﬀusion models to colonoscopy
image synthesis. (2) large-scale colonoscopy generation: the proposed
approach can be used to generate large-scale datasets with no/arbitrary anno-
tations, which signiﬁcantly beneﬁts the medical image society, laying the foun-
dation for large-scale pre-training models in automatic colonoscopy analysis. (3)
qualitative and quantitative evaluation: we conduct extensive experi-
ments to evaluate our method on ﬁve public benchmarks for polyp segmentation
and detection."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_33.pdf,"this would lead to the model
generating more background-like polyps since the large background region will
easily overwhelm the small foreground polyp regions during training. a simple
way to alleviate this problem is to apply a weighted loss function that assigns
the polyp and background regions with diﬀerent weights. however, most polyps
vary a lot in size and shape."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_33.pdf,"thus assigning constant weights for all polyps
exacerbated the imbalance problem. in this case, to tackle this problem, we
propose an adaptive loss function that vests diﬀerent weights according to the
size ratio of the polyp over the background. h × w ,
(7)
where p = 1 means the pixel p at (h, w) belongs to the polyp region and p = 0
means it belongs to the background region."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_33.pdf,"(8)
2.3
prediction-guided sample reﬁnement
the downstream tasks of polyp segmentation and detection require rich semantic
information on polyp regions to train a good model. through extensive exper-
iments, we found inaccurate sample images with coarse polyp boundary that
is not aligned properly with the original masks may introduce large biases and
noises to the datasets. the model can be confused by several conﬂicting training
images with the same annotation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_50.pdf,"1. learning-based artifact restoration approaches. (a) cyclegan [19] formulates
the artifact restoration as an image-to-image transfer problem. it leverages two pairs of
the generator and discriminator to learn the transfer between the artifact and artifact-
free image domains."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_50.pdf,"therefore, learning-based artifact restoration approaches
have gained increasing attention. for example, cyclegan [19] formulates the
artifact restoration as an image-to-image transfer problem by learning the trans-
fer between the artifact and artifact-free image domains from unpaired images,
as depicted in fig. [2], which are diﬃcult to train
due to the mode collapse and are prone to suﬀer from unexpected stain style
mistransfer."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_50.pdf,"to evaluate the performance of artifact restoration, a training set is
curated from a subset of camelyon17 [8]1. it comprises a total number of 2445
artifact-free images and another 2547 images with artifacts, where all histological
images are scaled to the resolution of 256 × 256 pixels at the magnitude of 20×.
the test set uses another public histology image dataset [6] with 462 artifact-free
1 available at https://camelyon17.grand-challenge.org.
artifact restoration in histology images with diﬀusion probabilistic models
523
images2, where we obtain the paired artifact images by the manually-synthesized
artifacts [18].
fig. 4. artifact restoration on ﬁve real-world artifact images."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_50.pdf,"unlike cyclegan which requires both artifact-free images
and artifact images, artifusion only relies on artifact-free images, leading to
a size of the training set that is half that of cyclegan. for a fair compai-
son, we train the cyclegan with two conﬁgurations, namely (#1) using the
entire dataset, and (#2) using only half the dataset, where the latter uses the
same number of the training samples as artifusion. [5] (denoted as ‘u-net’), and the time token scheme with the
direct summation scheme (denoted as ‘add’)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_40.pdf,
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_1.pdf,"automatic bleeding risk rating system
of gastric varices
yicheng jiang1, luyue shi1, wei qi2, lei chen2, guanbin li5,
xiaoguang han3,4, xiang wan1, and siqi liu1(b)
1 shenzhen research institute of big data, shenzhen, china
siqiliu@sribd.cn
2 department of gastroenterology, the second hospital of hebei medical university,
hebei key laboratory of gastroenterology, hebei institute of gastroenterology,
hebei clinical research center for digestive diseases, shijiazhuang, china
3 fnii, the chinese university of hong kong, shenzhen, shenzhen, china
4 school of science and engineering, the chinese university of hong kong,
shenzhen, shenzhen, china
5 school of computer science and engineering, sun yat-sen university, guangzhou,
china
abstract. an automated bleeding risk rating system of gastric varices
(gv) aims to predict the bleeding risk and severity of gv, in order
to assist endoscopists in diagnosis and decrease the mortality rate of
patients with liver cirrhosis and portal hypertension."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_1.pdf,"due to the
complexity of gv structures with large intra-class variation and small
inter-class variations, we found that existing models perform poorly on
this task and tend to lose focus on the important varices regions. to solve
this issue, we constructively introduce the segmentation of gv into the
classiﬁcation framework and propose the region-constraint module and
cross-region attention module for better feature localization and to learn
the correlation of context information. we also collect a gv bleeding
risks rating dataset (gvbleed) with 1678 gastroscopy images from 411
patients that are jointly annotated in three levels of risks by senior clin-
ical endoscopists."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_1.pdf,"although the existing rating systems tried to identify
the risk from diﬀerent perspectives, they still lack clear quantiﬁcation standard
and heavily rely on the endoscopists’ subjective judgment. this may cause incon-
sistency or even misdiagnosis due to the variant experience of endoscopists in
diﬀerent hospitals. therefore, we aim to build an automatic gv bleeding risk
rating method that can learn a stable and robust standard from multiple expe-
rienced endoscopists."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_1.pdf,"while most works and public datasets focus on colonoscopy
[13,15] and esophagus [5,9], with a lack of study on gastroscopy images. in the
public dataset of endocv challenge [2], the majority are colonoscopies while only
few are gastroscopy images. in this work, we collect a gv bleeding risks rating
dataset (gvbleed) that contains 1678 gastroscopy images from 411 patients
with diﬀerent levels of gv bleeding risks."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_1.pdf,"finally, a simple classiﬁer is used to predict
the bleeding risk using the extracted feature map.
2.1
segmentation module
due to the large intra-class variation between gv with the same bleeding risk
and small inter-class variation between gv and normal tissue or gv with diﬀer-
ent bleeding risks, existing classiﬁcation models exhibit poor perform and tend
to lose focus on the gv areas. to solve this issue, we ﬁrst embed a segmentation
network into the classiﬁcation framework. the predict the varices mask is then
used to assist the gv feature to obtain the ﬁnal bleeding risk rate."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_1.pdf,"the gvbleed dataset contains 1678 endo-
scopic images with gastric varices from 527 cases. all of these cases are collected
from 411 patients in a grade-iii class-a hospital during the period from 2017
to 2022. in the current version, images from patients with ages elder than 18 are
retained1."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_1.pdf,"due to the large intra-class variation between gv with the same bleed-
ing risk and small inter-class variation between gv and normal tissue or gv with
diﬀerent bleeding risks, existing classiﬁcation models cannot correctly focus on
the varices regions and always raise poor performance. to solve this issue, we
constructively introduce segmentation to enhance the robustness of representa-
tion learning. besides, we further design a region-constraint module for better
feature localization and a cross-region attention module to learn the correlation
of target gv with its context."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_50.pdf,"b-cos aligned transformers learn
human-interpretable features
manuel tran1,2,3, amal lahiani1, yashin dicente cid1, melanie boxberg3,5,
peter lienemann2,4, christian matek2,6, sophia j. wagner2,3,
fabian j. theis2,3, eldad klaiman1, and tingying peng2(b)
1 roche diagnostics, penzberg, germany
2 helmholtz ai, helmholtz munich, neuherberg, germany
tying84ster@gmail.com
3 technical university of munich, munich, germany
4 ludwig maximilian university of munich, munich, germany
5 pathology munich-north, munich, germany
6 university hospital erlangen, erlangen, germany
abstract. vision transformers (vits) and swin transformers (swin)
are currently state-of-the-art in computational pathology."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_50.pdf,"compared to the swin transformer, it even improves the
f1-score by up to 4.7% on two public datasets. keywords: transformer · self-attention · explainability ·
interpretability
1
introduction
making artiﬁcial neural networks more interpretable, transparent, and trustwor-
thy remains one of the biggest challenges in deep learning. they are often still
considered black boxes, limiting their application in safety-critical domains such
e. klaiman—equal contribution."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_50.pdf,"in addition, there is an ongoing controversy about
their trustworthiness [5]. to address these issues, we propose a novel family of
transformer architectures based on the b-cos transform originally developed for
cnns [7]. by aligning the inputs and weights during training, the models are
implicitly forced to learn more biomedically relevant and meaningful features
(fig. 1)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_50.pdf,"4
implementation and evaluation details
task-based evaluation: cancer classiﬁcation and segmentation is an
important ﬁrst step for many downstream tasks such as grading or staging. therefore, we choose this problem as our target. [19], which consists of 38 annotated slides
from the tcga colorectal cancer cohort, to evaluate the eﬀectiveness of transfer
learning."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_50.pdf,"this is consistent with the observations made in
sect. 5: when bvt is trained from scratch, the model faces a trade-oﬀ between
522
m. tran et al.
learning the weight and input alignment and ﬁnding the appropriate inductive
bias to solve the classiﬁcation task. by reintroducing many of the inductive biases
of cnns through the window attention in the case of swin or transfer learning
in the case of bvt, the model likely overcomes this initial problem."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_71.pdf,"black-box domain adaptative cell
segmentation via multi-source
distillation
xingguang wang1, zhongyu li1(b), xiangde luo2, jing wan1, jianwei zhu1,
ziqi yang1, meng yang3, and cunbao xu4(b)
1 school of software engineering, xian jiaotong university, xi’an, china
zhongyuli@xjtu.edu.cn
2 school of mechanical and electrical engineering, university of electronic science
and technology of china, chengdu, china
3 hunan frontline medical technology co., ltd., changsha, china
4 department of pathology, quanzhou first hospital aﬃliated to fujian medical
university, quanzhou, china
937340447@qq.com
abstract. cell segmentation plays a critical role in diagnosing various
cancers."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_71.pdf,"although deep learning techniques have been widely investi-
gated, the enormous types and diverse appearances of histopathological
cells still pose signiﬁcant challenges for clinical applications. moreover,
data protection policies in diﬀerent clinical centers and hospitals limit
the training of data-dependent deep models. in this paper, we present
a novel framework for cross-tissue domain adaptative cell segmentation
without access both source domain data and model parameters, namely
multi-source black-box domain adaptation (mbda)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_71.pdf,"considering the domain shift cross diﬀer-
ent pathological tissues, predictions from the source models may not be
reliable, where the noise labels can limit the training of the target model. to address this issue, we propose two practical approaches for weight-
ing knowledge from the multi-source model predictions and ﬁltering out
noisy predictions. first, we assign pixel-level weights to the outputs of
source models to reduce uncertainty during knowledge distillation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_71.pdf,"it can
help people conduct cell counting, cell morphology analysis, and tissue analysis,
which reduces human labor [19]. however, data acquisition for medical images
poses unique challenges due to privacy concerns and the high cost of manual
annotation. moreover, pathological images from diﬀerent tissues or cancer types
often show signiﬁcant domain shifts, which hamper the generalization of mod-
els trained on one dataset to others."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_71.pdf,"nonetheless, several recent investigations have demonstrated that the domain
adaptation methods for source-free white-box models still present a privacy risk
due to the potential leakage of model parameters [4]. such privacy breaches
may detrimental to the privacy protection policies of hospitals. moreover, the
target domain uses the same neural network as the source domain, which is
not desirable for low-resource target users like hospitals [15]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_71.pdf,"while black-box models are proﬁcient
in speciﬁc domains, their performances greatly degrade when the target domain
is updated with new pathology slices. therefore, how to leverage the existing
knowledge of black-box models to eﬀectively train new models for the target
domain without accessing the source domain data remains a critical challenge. in this paper, we present a novel source-free domain adaptation framework
for cross-tissue cell segmentation without accessing both source domain data
and model parameters, which can seamlessly integrate heterogeneous models
from diﬀerent source domains into any cell segmentation network with high gen-
erality."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_71.pdf,"1. overview of our purposed framework, where logits maps denote the raw pre-
dictions from source models and ω denotes pixel-level weight for each prediction. the
semi-supervised loss, denoted as lssl, encompasses the supervised loss, consistency loss,
and maximize mutual information loss.
strategies within this new framework to address this issue. firstly, we propose a
pixel-level multi-source domain weighting method, which reduces source domain
noise by knowledge weighting."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_71.pdf,"thus, our ultimate objective is to derive a
novel student model ft : xt → yt that is relevant to the source domain task. accordingly, direct knowledge transfer using the output of the source domain
predictor may lead to feature bias in the student model due to the unavoid-
able covariance [20] between the target and source domains. inspired by [21],
we incorporate prediction uncertainty and cell boundary impurity to establish
pixel-level weights for multi-source outputs."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_71.pdf,"a point worth noting is that most of the
methods we compared with are white-box methods, which means they can obtain
more information from the source domain than us. for single-source domain
adaptation approach, cellsegssda and sfda-dpl, we employ two strategies
to ensure the fairness of the experiments: (1) single-source, i.e. performing adap-
tation on each single source, where we select the best results to display in the
table 1; (2) source-combined, i.e. all source domains are combined into a tra-
ditional single source. the table 1 and fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_43.pdf,"we release the code and model weights in
https://github.com/playersal/kga-net. keywords: breast ultrasound classiﬁcation · ultrasound video ·
coherence loss
1
introduction
breast cancer is a life-threatening disease that has surpassed lung cancer as lead-
ing cancer in some countries and regions [20]. breast ultrasound is the primary
screening method for diagnosing breast cancer, and accurately distinguishing
between malignant and benign breast lesions is crucial."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_43.pdf,"we use a 2d resnet trained on ultrasound images to get the features. while ultrasound videos oﬀer more information, prior studies have primarily
focused on static image classiﬁcation [2,11,27]. obtaining ultrasound video data
with pathology gold standard results poses a major challenge. sonographers typ-
ically record keyframe images during general ultrasound examinations, not entire
videos."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_43.pdf,"therefore, we compare our method with strong
video baselines on natural images. for fairness comparison, we train these models using both video
and image data, treating images as static videos. evaluation metrics are reported
on the busv test set for performance assessment."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_43.pdf,"it can be seen that both of these two modules
contribute to the overall performance according to auc and acc. it is worth
noting that these two models without coherence loss obtain very low sensitiv-
ity and high speciﬁcity, which means the model predictions are imbalanced and
intend to make benign predictions. it is because that clear malignant appear-
ances usually only exist in limited frames in a malignant video."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_33.pdf,"the results indicate that hybrid-mt-
estan achieved the highest accuracy, sensitivity, and f1 score of 82.7%,
86.4%, and 86.0%, respectively. multitask learning ·
hybrid cnn-transformer
1
introduction
breast cancer is the leading cause of cancer-related fatalities among women. currently, it holds the highest incidence rate of cancer among women in the u.s.,
and in 2022 it accounted for 31% of all newly diagnosed cancer cases [1]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_33.pdf,"however, the eﬀectiveness of vit-based approaches heavily relies on
access to large datasets for learning meaningful representations of input images. this is primarily because the architectural design of vits does not rely on the
same inductive biases in feature extraction which allow cnns to learn spatially
invariant features. accordingly, numerous prior studies introduced modiﬁcations to the origi-
nal vit network speciﬁcally designed for bus image classiﬁcation [13,14,23]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_33.pdf,"it constrains models to learn representations that
are relevant to all tasks rather than learning task-speciﬁc details. moreover,
multitask learning acts as a regularizer by introducing inductive bias and pre-
vents overﬁtting [25] (particularly with vits), and with that, can mitigate the
challenges posed by small bus dataset sizes. in [3], the authors demonstrated
that multitask learning outperforms single-task learning approaches for bus
classiﬁcation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_33.pdf,"all bus images in the dataset were zero-padded and reshaped to form square
images. to avoid data leakage and bias, we selected the train, test, and vali-
dation sets based on the cases, i.e., the images from one case (patient) were
350
b. shareef et al.
table 2. performance metrics of the compared methods for bus image classiﬁcation
and segmentation. furthermore,
we employed horizontal ﬂip, height shift (20%), width shift (20%), and rota-
tion (20◦c) for data augmentation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_53.pdf,"the model was further validated for a prospective
ex-vivo data, as well as a breast conserving surgery intra-operative data. results: the purposed model outperformed all baselines, statistically
signiﬁcantly, with average balanced accuracy of 91.6%. when applied to
intra-operative data, the purposed model improved the false positive rate
of the baselines."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_53.pdf,"the current standard of care for evaluating surgical suc-
cess is to investigate the resection margins, which refers to the area surrounding
the excised tumor. the intelligent knife (iknife) is a mass
spectrometry device that can address this challenge by analyzing the biochem-
ical signatures of resected tissue using the smoke that is released during tissue
incineration [3]. each spectrum contains the distribution of sampled ions with
respect to their mass to charge ratio (m/z)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_53.pdf,"it has also been shown that graph neural networks
can accurately capture the biochemical signatures of iknife and determine the
tissue type. particularly, graph transformer networks (gtn) has have shown
to further enhance the transparency of underlying relation between the graph
nodes and decision making via attention mechanism [11].
biological data, specially those acquired intra-opertively, are heterogeneous
by nature. while the use of ex-vivo data collected under speciﬁc protocols are
beneﬁcial to develop baseline models, intra-operative deployment of these models
is challenging."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_53.pdf,"then, the expected
probability for the c-th class pc and the total uncertainty u for each sample (xi)
can be calculated as pc = αc
s , and u = c
s , respectively, where s = 	c
c=1 αc. to
ﬁt the dirichlet distribution to the output layer of our network, we use a loss
function consisting of the prediction error lp
i and the evidence adjustment le
i
li(θ) = lp
i (θ) + λle
i(θ)
(2)
where λ is the annealing coeﬃcient to balance the two terms. is kl diver-
gence to the uniform dirichlet distribution [18].
2.3
experiments
network/graph ablation: we explore the hyper-parameters of the proposed
model in an extensive ablation study."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_53.pdf,"the performance of egt in comparison with the mentioned baselines are
summarized in table 1. as can be seen, the proposed egt model with aver-
age accuracy of 94.1% outperformed all the baselines statistically signiﬁcantly
(maximum p-values of 0.02 in one-tail paired wilcoxon signed-rank test). the
lower standard deviation of parameters shows the robustness of egt compared
to other baselines."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_53.pdf,"to demonstrate this,
568
a. jamzad et al.
table 1. average(standard deviation) of accuracy (acc), balanced accuracy (bac)
sensitivity (sen), speciﬁcity (spc), and the area under the curve (auc) for the
proposed evidential graph transformer in comparison with graph transformer (gtn),
graph convolution (gcn), and non-graph convolution (cnn) baselines. 3. left estimated probabilities and uncertainty scores for data samples in test set."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_35.pdf,"carl: cross-aligned representation learning
for multi-view lung cancer histology
classiﬁcation
yin luo1, wei liu1, tao fang1, qilong song2, xuhong min2, minghui wang1(b),
and ao li1(b)
1 school of information science and technology, university of science and
technology of china, hefei 230026, china
{mhwang,aoli}@ustc.edu.cn
2 department of radiology, anhui chest hospital, hefei 230039, anhui, china
abstract. accurately classifying the histological subtype of non-small cell lung
cancer (nsclc) using computed tomography (ct) images is critical for clinicians
in determining the best treatment options for patients."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_35.pdf,"although recent advances
in multi-view approaches have shown promising results, discrepancies between
ct images from different views introduce various representations in the feature
space, hindering the effective integration of multiple views and thus impeding
classiﬁcation performance. to solve this problem, we propose a novel method
called cross-aligned representation learning (carl) to learn both view-invariant
and view-speciﬁc representations for more accurate nsclc histological subtype
classiﬁcation. speciﬁcally, we introduce a cross-view representation alignment
learning network which learns effective view-invariant representations in a com-
mon subspace to reduce multi-view discrepancies in a discriminability-enforcing
way."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_35.pdf,"[13] both employ a convolutional neural network
(cnn) model with axial view ct images to classify the tumor histology into scc and
adc. multi-view deep learning, a 2.5d method, represents a
promising solution to this issue, as it focuses on obtaining a uniﬁed joint representation
from different views of lung nodules to capture abundant spatial information [16, 20]. for example, wu et al."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_35.pdf,"[11] also extract patches
from three orthogonal views of a lung nodule and present a multi-view resnet for fea-
ture fusion and classiﬁcation. [9, 20, 23].
despite the promising results of previous multi-view methods, they still confront a
severe challenge for accurate nsclc histological subtype prediction. in fact, due to the
limitation of scan time and hardware capacity in clinical practice, different views of ct
volumes are anisotropic in terms of in-plane and inter-plane resolution [21]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_35.pdf,"consequently, the discrepancies
of distinct views will hamper the fusion of multi-view information, limiting further
improvements in the classiﬁcation performance. to overcome the challenge mentioned above, we propose a novel cross-aligned repre-
sentation learning (carl) method for the multi-view histologic subtype classiﬁcation of
nsclc. carl offers a holistic and disentangled perspective of multi-view ct images
by generating both view-invariant and -speciﬁc representations."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_35.pdf,"in the common subspace, we hope that through optimizing
the shared encoder ec(·), the view-invariant representations can be matched to some
extent. however, the distributions of hc
av, hc
cv and hc
sv are very complex due to the signif-
icant variations between different views, which puts a burden on obtaining well-aligned
view-invariant representations with merely an encoder.
to address this issue, we design a discriminability-enforcing similarity loss ldsim to
further enhance the alignment of cross-view representations in the common subspace. importantly, considering that the axial view has a higher resolution than other views and
are commonly used in clinical diagnosis, we choose axial view as the main view and
force the sub-views (e.g., the coronal and sagittal views) to seek distributional similarity
with the main view."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_35.pdf,"n is the
number of sub-views. despite the fact that minimizing the lsim can efﬁciently mitigate
the issue of distributional disparities, it may not guarantee that the alignment network
will learn informative and discriminative representations. inspired by recent work on
362
y. luo et al.
multimodal feature extraction [12, 14], we impose a direct supervision by inputting hmain
into a classiﬁer f (·) to obtain the prediction of histological subtype, and use a cross-
entropy loss to enforce the discriminability of the main-view representations."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_35.pdf,"finally,
the discriminability-enforcing similarity loss ldsim is as follows:
ldsim = lsim + λ · lce

f

hmain
, y

(3)
where y denotes the ground-truth subtype labels, λ controls the weight of lce. = 110 to balance the magnitude of two terms. by minimizing ldsim, the
cross-view representation alignment learning network pushes the representations of each
sub-view to align with those of the main view in a discriminability-enforcing manner."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_38.pdf,"indeed, the ordinal regression-
based methods are able to learn ordered manifolds and to further enhance the
prediction accuracy. however, the aforementioned methods still face challenges in distinguishing
visually similar samples with adjacent rank labels. for example, in fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_38.pdf,", since
we conduct unimodal contrastive learning and map the samples onto a spherical
space, the false positive nodule with a malignancy score of 2.75 has a closer dis-
tance to that with a score of 4.75, and the false negative one should not be closer to
that of score 2.5. to address this issue, we found that the text attributes, such as
“subtlety”, “sphericity”, “margin”, and “lobulation”, annotated by radiologists,
can exhibit the diﬀerences between these hard samples. therefore, we propose
leveraging text annotations to guide the learning of visual features."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_38.pdf,"1) we propose clip-lung for lung nodule malignancy prediction, which lever-
ages clinical textual knowledge to enhance the image encoder and classiﬁer.
2) we design a channel-wise conditional prompt module to establish consistent
relationships among the correlated text tokens and feature maps.
3) we simultaneously align the image features with class and attribute fea-
tures through contrastive learning while generating more explainable atten-
tion maps. 2
methodology
2.1
overview
problem formulation. in this paper, we arrange the lung nodule classiﬁcation
dataset as {i, y, c, a}, where i = {ii}n
i=1 is an image set containing n lung nod-
ule images."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_38.pdf,"this disparity is likely attributed to the similarity in
appearances and subtle variations in text attributes among the benign nodules. consequently, aligning these distinct feature types becomes challenging, resulting
in a bias towards the text features associated with malignant nodules.
410
y. lei et al.
fig. the t-sne (left) and grad-cam (right) results."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_69.pdf,"cascade transformer encoded
boundary-aware multibranch fusion
networks for real-time and accurate
colonoscopic lesion segmentation
ao wang1(b), ming wu1(b), hao qi1, wenkang fan1, hong shi3(b),
jianhua chen3, sunkui ke4, yinran chen1, and xiongbiao luo1,2(b)
1 department of computer science and technology,
xiamen university, xiamen, china
awang.xmu@gmail.com, xiongbiao.luo@gmail.com, wuming@stu.xmu.edu.cn
2 national institute for data science in health and medicine,
xiamen university, xiamen, china
3 fujian cancer hospital, fujian medical university cancer hospital, fuzhou, china
endoshihong@hotmail.com
4 zhongshan hospital, xiamen university, xiamen 361004, china
abstract. automatic segmentation of colonoscopic intestinal lesions is
essential for early diagnosis and treatment of colorectal cancers."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_69.pdf,"such a newly designed encoder-decoder archi-
tecture can preserve lesion appearance feature details while aggregating
the semantic global cues at several diﬀerent feature levels. addition-
ally, a hybrid spatial-frequency loss function is explored to adaptively
concentrate on the loss of important frequency components due to the
inherent bias of neural networks. we evaluated our method not only on
an in-house database with four types of colorectal lesions with diﬀerent
pathological features, but also on four public databases, with the exper-
imental results showing that our method outperforms state-of-the-art
network models."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_69.pdf,"on the other hand, various polyps and adenomas with diﬀerent
pathological features have similar visual characteristics to intestinal folds. to
address these issues mentioned above, we explore a new deep learning archi-
tecture called cascade transformer encoded boundary-aware multibranch fusion
(ctbmf) networks with cascade transformers and multibranch fusion for polyp
and adenoma segmentation in colonoscopic white-light and narrow-band video
images. several technical highlights of this work are summarized as follows."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_1.pdf,"however, if the local center has limited image collection capability,
there may also not be enough unlabeled data for semi-supervised learn-
ing to be eﬀective. to overcome this issue, other partner centers can be
consulted to help enrich the pool of unlabeled images, but this can result
in data heterogeneity, which could hinder ssl that functions under the
assumption of consistent data distribution. tailoring for this important
yet under-explored scenario, this work presents a novel category-level
regularized unlabeled-to-labeled (cu2l) learning framework for semi-
supervised prostate segmentation with multi-site unlabeled mri data."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_1.pdf,"to eﬃciently enrich
the unlabeled pool, seeking support from other centers is a viable solution, as
illustrated in fig. yet, due to diﬀerences in imaging protocols and variations in
patient demographics, this solution usually introduces data heterogeneity, lead-
category-level regularized unlabeled-to-labeled learning
5
ing to a quality problem. thus, proper
mechanisms are called for this practical but challenging ssl scenario."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_1.pdf,"our method is evaluated on prostate mri data
from six diﬀerent clinical centers and shows promising performance on tackling
ms-ssl compared to other semi-supervised methods. 2
methods
2.1
problem formulation and basic architecture
in our scenario of ms-ssl, we have access to a local target dataset dlocal
(consisted of a labeled sub-set dl
local and an unlabeled sub-set du
local) and
the external unlabeled support datasets du
e
= m
j=1 du,j
e , where m is the
number of support centers. i=nl+1 with nu unlabeled scans."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_1.pdf,"λ is a trade-oﬀ weight scheduled by
the time-dependent ramp-up gaussian function [15] λ(t) = wmax·e−5(1−t/tmax)2,
where wmax and tmax are the maximal weight and iteration, respectively. the key
challenge of ms-ssl is the proper design of lu for robustly exploiting multi-site
unlabeled data {du
local, du
e } to support the local center. category-level regularized unlabeled-to-labeled learning
7
2.2
pseudo labeling for local distribution fitting
as mentioned above, supervised-like learning is advocated for local unlabeled
data to help the model ﬁt local distribution better."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_1.pdf,"2.3
category-level regularized unlabeled-to-labeled learning
unlabeled-to-labeled learning. inherently, the challenge of ms-ssl stems
from intra-class variation, which results from diﬀerent imaging protocols, disease
progress and patient demographics. inspired by prototypical networks [13,19,25]
that compare class prototypes with pixel features to perform segmentation,
here, we introduce a non-parametric unlabeled-to-labeled (u2l) learning scheme
that utilizes expert labels to explicitly constrain the prototype-propagated pre-
dictions. such design is based on two considerations: (i) a good prototype-
propagated prediction requires both compact feature and discriminative pro-
totypes, thus enhancing this prediction can encourage the model to learn in a
variation-insensitive manner and focus on the most informative clues; (ii) using
expert labels as ﬁnal guidance can prevent error propagation from pseudo labels."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_1.pdf,"table 2 presents the quantitative results with either c1
or c2 as the local target center, wherein only 6 or 8 local scans are anno-
tated. all methods are imple-
mented with the same backbone and training protocols to ensure fairness. as
observed, compared to the supervised-only baselines, our cu2l with {6, 8} local
labeled scans achieves {19.15%, 17.42%} and {9.1%, 6.44%} dsc improvements
in {c1, c2}, showing its eﬀectiveness in leveraging multi-site unlabeled data."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_47.pdf,"therefore, the task to synthesize
realistic cytopathological images becomes very challenging.
aiming at augmenting the performance of cervical abnormality screening, we
develop a novel conditional generative adversarial network in this paper, namely
cellgan, to synthesize cytopathological images for various cell types. we lever-
age fastgan [16] as the backbone for the sake of training stability and compu-
tational eﬃciency. to inject cell type for ﬁne-grained conditioning, a non-linear
mapping network embeds the class labels to perform layer-wise feature modu-
lation in the generator."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_20.pdf,"the recent develop-
ments of artiﬁcial neural networks in computational pathology have shown that
these methods hold great potential for improving the accuracy and quality of
cancer diagnosis. however, the issues with the robustness and reliability of such
methods have not been fully resolved yet. herein, we propose a centroid-aware
feature recalibration network that can conduct cancer grading in an accurate and
robust manner."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_48.pdf,"but it also suﬀers poor detection accuracy
for overlapping objects and requires additional post-processing steps to obtain
the ﬁnal detection results. [1], a transformer-based object detection method refor-
mulates object detection as a set-to-set prediction problem, and it removes
both the hand-crafted anchors and the non-maximum suppression (nms) post-
processing. [10]
introduces an analytic study of how query design aﬀects rectangle object detec-
tion."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_48.pdf,"mi is the ground truth obtained by roi align [5]
corresponding to ˆmi.
498
h. zhang et al.
3
experiment
3.1
dataset and evaluation
monuseg dataset. monuseg dataset is a public dataset from the 2018 multi-
organ nuclei segmentation challenge [6]. it contains 30 training/validataion
tissue images sampled from a separate whole slide image of h&e stained tissue
and 14 testing images of lung and brain tissue images."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_51.pdf,"clinical evaluation of ai-assisted virtual
contrast enhanced mri in primary gross
tumor volume delineation for radiotherapy
of nasopharyngeal carcinoma
wen li1, dan zhao2, zhi chen1, zhou huang2, saikit lam1, yaoqin xie3,
wenjian qin3, andy lai-yin cheung4, haonan xiao1, chenyang liu1,
francis kar-ho lee5, kwok-hung au5, victor ho-fun lee4, jing cai1,6(b),
and tian li1(b)
1 the hong kong polytechnic university, hong kong sar, china
jing.cai@polyu.eud.hk, litian.li@polyu.edu.hk
2 department of radiation oncology, beijing cancer hospital & institute, beijing, china
3 shenzhen institute of advanced technology, chinese academy of science, shenzhen, china
4 department of clinical oncology, the university of hong kong, hong kong sar, china
5 department of clinical oncology, queen elizabeth hospital, hong kong sar, china
6 research institute for smart ageing, the hong kong polytechnic university,
hong kong sar, china
abstract. ai generated vir-
tual contrast-enhanced mri (vce-mri) in primary gross-tumor-volume (gtv)
delineation for patients with nasopharyngeal carcinoma (npc)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_51.pdf,"the clinical evaluation of ai-based techniques is of paramount importance in health-
care. rigorous clinical evaluations can establish the safety and efﬁcacy of ai-based tech-
niques, identify potential biases and limitations, and facilitate the integration of clinical
expertise to ensure accurate and meaningful results [13]. furthermore, the clinical evalu-
ation of ai-based techniques can help identify areas for improvement and optimization,
leading to development of more effective algorithms.
clinical evaluation of ai-assisted virtual contrast enhanced mri
543
to bridge this bench-to-bedside research gap, in this study, we conducted a series of
clinicalevaluationstoassesstheeffectivenessofsyntheticvce-mriinnpcdelineation,
with a particular focus on assessment in vce-mri image quality and primary gtv
delineation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_51.pdf,"this dataset included 303 biopsy-proven (stage i-ivb) npc patients who received radi-
ation treatment during 2012–2016. the three hospitals were labelled as institution-1
(110 patients), institution-2 (58 patients), and institution-3 (135 patients), respectively. for each patient, t1w mri, t2w mri, gadolinium-based ce-mri, and planning ct
were retrieved."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_51.pdf,"mri images were automatically registered as mri images for each
patient were scanned in the same position. the use of this dataset was approved by the
institutional review board of the university of hong kong/hospital authority hong
kong west cluster (hku/ha hkw irb) with reference number uw21-412, and the
research ethics committee (kowloon central/kowloon east) with reference number
kc/ke-18-0085/er-1. due to the retrospective nature of this study, patient consent was
waived."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_51.pdf,"data use declaration:. the use of this dataset was approved by the institutional review board of
university of hong kong/hospital authority hong kong west cluster (hku/ha hkw irb) with
reference number uw21-412, and the research ethics committee (kowloon central/kowloon
east) with reference number kc/ke-18-0085/er-1. due to the retrospective nature of this study,
patient consent was waived."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_15.pdf,"cluster-induced mask transformers
for eﬀective opportunistic gastric
cancer screening on non-contrast ct
scans
mingze yuan1,2,3, yingda xia1(b), xin chen4(b), jiawen yao1,3, junli wang5,
mingyan qiu1,3, hexin dong1,2,3, jingren zhou1, bin dong2,6, le lu1,
li zhang2, zaiyi liu4(b), and ling zhang1
1 damo academy, alibaba group, hangzhou, china
yingda.xia@alibaba-inc.com
2 peking university, beijing, china
3 hupan lab, 310023 hangzhou, china
4 guangdong province people’s hospital, guangzhou, china
wolfchenxin@163.com, zyliu@163.com
5 the first aﬃliated hospital of zhejiang university, hangzhou, china
6 peking university changsha institute for computing and digital economy,
changsha, china
abstract. gastric cancer is the third leading cause of cancer-related
mortality worldwide, but no guideline-recommended screening test
exists."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_15.pdf,"this is because early-stage gastric tumors may only invade
the mucosal and muscularis layers, which are diﬃcult to identify without the
help of stomach preparation and contrast injection. additionally, the poor con-
trast between the tumor and normal stomach wall/tissues on non-contrast ct
scans and various shape alterations of gastric cancer, further exacerbates this
challenge. in this paper, we propose a novel approach for detecting gastric cancer on
non-contrast ct scans."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_15.pdf,"however, our framework is speciﬁcally designed for non-
contrast ct scans, which is beneﬁcial for asymptomatic patients. while previous
studies have successfully detected pancreatic [25] and esophageal [26] cancers on
non-contrast ct, identifying gastric cancer presents a unique challenge due to
its subtle texture changes, various shape alterations, and complex background,
e.g., irregular gastric wall; liquid and contents in the stomach. recent studies have used transformers for natural and
medical image segmentation [21]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_15.pdf,"mask transformers are locally sen-
sitive to image textures for precise segmentation and globally aware of organ-
tumor morphology for recognition. their cluster representations demonstrate a
remarkable balance of intra-cluster similarity and inter-class discrepancy. there-
fore, mask transformers are an ideal choice for an end-to-end joint segmentation
and classiﬁcation system for detecting gastric cancer."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_15.pdf,"this unet considers local information and can only extract stom-
ach rois well during testing. however, local textures are inadequate for accurate
gastric tumor detection on non-contrast cts, so we need a network of both local
sensitivity to textures and global awareness of the organ-tumor morphology. mask transformer [3,24] is a well-suited approach to boost the cnn backbone
with stand-alone transformer blocks."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_15.pdf,"4
experiments
4.1
experimental setup
dataset and ground truth. our study analyzed a dataset of ct scans col-
lected from guangdong province people’s hospital between years 2018 and 2020,
with 2,139 patients consisting of 787 gastric cancer and 1,352 normal cases. we
used the latest patients in the second half of 2020 as a hold-out test set, result-
ing in a training set of 687 gastric cancer and 1,204 normal cases, and a test
set of 100 gastric cancer and 148 normal cases."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_15.pdf,"we randomly selected 20% of
the training data as an internal validation set. to further evaluate speciﬁcity
in a larger population, we collected an external test set of 903 normal cases
from shengjing hospital. cancer cases were conﬁrmed through endoscopy (and
pathology) reports, while normal cases were conﬁrmed by radiology reports and a
two-year follow-up."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_15.pdf,"miss-t:
missing of t stage information. a reader
study was conducted with two experienced radiologists, one from guangdong
province people’s hospital with 20 years of experience and the other from the
first aﬃliated hospital of zhejiang university with 9 years of experience in
gastric imaging. the readers were given 248 non-contrast ct scans from the
test set and asked to provide a binary decision for each scan, indicating whether
the scan showed gastric cancer."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_68.pdf,"clustering disease trajectories
in contrastive feature space
for biomarker proposal in age-related
macular degeneration
robbie holland1(b), oliver leingang2, christopher holmes3, philipp anders4,
rebecca kaye6, sophie riedl2, johannes c. paetzold1, ivan ezhov7,
hrvoje bogunović2, ursula schmidt-erfurth2, hendrik p. n. scholl4,5,
sobha sivaprasad3, andrew j. lotery6, daniel rueckert1,7,
and martin j. menten1,7
1 biomedia, imperial college london, london, uk
robert.holland15@imperial.ac.uk
2 laboratory for ophthalmic image analysis, medical university of vienna,
vienna, austria
3 moorﬁelds eye hospital nhs foundation trust, london, uk
4 institute of molecular and clinical ophthalmology basel, basel, switzerland
5 department of ophthalmology, universitat basel, basel, switzerland
6 clinical and experimental sciences, university of southampton, southampton, uk
7 technical university of munich, munich, germany
abstract."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_68.pdf,"supplementary information the online version contains supplementary material
available at https://doi.org/10.1007/978-3-031-43990-2_68.
c
⃝ the author(s), under exclusive license to springer nature switzerland ag 2023
h. greenspan et al. https://doi.org/10.1007/978-3-031-43990-2_68
clustering disease trajectories for temporal biomarker proposal in amd
725
keywords: contrastive learning · biomarker discovery · clustering ·
disease trajectories · age-related macular degeneration
1
introduction
age-related macular degeneration (amd) is the leading cause of blindness in the
elderly, aﬀecting nearly 200 million people worldwide [24]. [12]. clinicians
currently diagnose amd, and stratify patients, using biomarkers derived from
optical coherence tomography (oct), which provides high-resolution images of
fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_68.pdf,"the established
amd grading system stratiﬁes early and intermediate stages solely by the size
of drusen in a single oct image [1,6,7,10]. late amd is classiﬁed into either
choroidal neovascularisation (cnv), identiﬁed by subretinal ﬂuid, or geographic
atrophy, signalled by progressive loss of photoreceptors and retinal thinning. grading systems derived from these biomarkers oﬀer lim-
ited diagnostic value and little to no prognostic capability."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_68.pdf,"we ﬁrst design and test our method on a development dataset, which was
collected from the southampton eye unit. afterwards, we test our method on
a second independent unseen dataset, which was obtained from moorﬁelds eye
hospital. all images were acquired using topcon 3d oct devices (topcon cor-
poration, tokyo, japan)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_68.pdf,"similarly, we ﬁt an equivalent linear regression model to the static
biomarkers from the established grading system detailed in sect. we also
include a demographic baseline using age and sex. we also add a temporally
agnostic baseline that clusters only single time points."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_68.pdf,"our sub-
trajectory clusters were comparable to, and in some cases outperformed, the cur-
rent widely adopted grading system in predicting risk of conversion (see table 1). in all tasks the standard biomarkers are only marginally more indicative of risk
than the patient’s age and sex. this experiment conﬁrms that our clusters are
related to disease progression."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_16.pdf,"co-assistant networks for label
correction
xuan chen, weiheng fu, tian li, xiaoshuang shi(b), hengtao shen,
and xiaofeng zhu
school of computer science and engineering,
university of electronic science and technology of china, chengdu 611731, china
xsshi2013@gmail.com
abstract. the presence of corrupted labels is a common problem in the
medical image datasets due to the diﬃculty of annotation. meanwhile,
corrupted labels might signiﬁcantly deteriorate the performance of deep
neural networks (dnns), which have been widely applied to medical
image analysis."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_16.pdf,"moreover, sample annota-
tion needs expensive cost. hence, correcting corrupted labels might be one of
eﬀective solutions to solve the issues of high-quality labels. numerous works have been proposed to tackle the issue of corrupted labels."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_16.pdf,"second, existing label correction methods often ignore to take into
account the relationship among the samples so that inﬂuencing the eﬀectiveness
of label correction. to address the aforementioned issues, in this paper, we propose a new
co-assistant framework, namely co-assistant networks for label correction
(cnlc) (shown in fig. 1), which consists of two modules, i.e., noise detector
and noise cleaner."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_16.pdf,"speciﬁcally, the noise detector ﬁrst adopts a convolutional
neural network (cnn [6,20]) to predict the class probability of samples, and
then the loss is used to partition all the training samples for each class into
three subgroups, i.e., clean samples, uncertain samples and corrupted samples. moreover, we design a robust loss (i.e., a resistance loss) into the cnn frame-
work to avoid model overﬁtting on corrupted labels and thus exploring the ﬁrst
issue in previous label correction methods. the noise cleaner constructs a graph
convolutional network (gcn [18,19]) model for each class to correct the cor-
rupted labels."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_16.pdf,"during the process of noise cleaner, we consider the relationship
co-assistant networks for label correction
161
among samples (i.e., the local topology structure preservation by gcn) to touch
the second issue in previous methods. in particular, our proposed cnlc itera-
tively updates the noise detector and the noise cleaner, which results in a bi-level
optimization problem [4,10]
compared to previous methods, the contributions of our method is two-fold. first, we propose a new label correction method (i.e., a co-assistant framework)
to boost the model robustness for medical image analysis by two sequential
modules."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_16.pdf,"either of them adaptively adjusts the other, and thus guaranteeing to
output a robust label correction model. second, two sequential modules in our
framework results in a bi-level optimization problem. we thus design a bi-level
optimization algorithm to solve our proposed objective function."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_16.pdf,"limited number of samples cannot guarantee to build robust noise
cleaner. in this paper, we address the above issues by employing semi-supervised
learning, i.e., a gcn for each class, which keeps the local topology structure of
samples on both labeled samples and unlabeled samples. speciﬁcally, our noise
cleaner includes three components, i.e., noise rate estimation, class-based gcns,
and corrupted label correction."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_16.pdf,"similarly, the embedding of all samples
e is an essential input of the noise cleaner, which is generated by the noise
detector. as the optimizations of two modules are nested, the objective function
of our proposed method is the following bi-level optimization problem:
⎧
⎨
⎩
minθ lr

f t (x; θ) , f t−1 (x; θ) , ˜y

,
minωc lbce (gt
c (ac, ec; ωc) , zc) + lmse

gt
c (ac, ec; ωc) , gt−1
c
(ac, ec; ωc)

,
(7)
where f t(x; θ) denotes the output of the upper-level (i.e., the noise detector)
in the t-th epoch, ac and ec represent the adjacency matrix and the feature
matrix of class c, zc are labels of labeled samples in class c, gt
c(ac, ec; ωc) and
gt−1
c
(ac, ec; ωc) denote the output of gcn model for class c at the t-th and
t-1-th epochs, respectively. in this paper, we construct a bi-level optimization algorithm to search optimal
network parameters of the above objective function."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_16.pdf,"= {0, 0.2, 0.4} into these
datasests, where ϵ = 0 means that all labels in the training set are clean. for fair-
ness, in our experiments, we adopt the same neural network for all comparison
methods based on their public codes and default parameter settings. we evaluate
the eﬀectiveness of all methods in terms of four evaluation metrics, i.e., classiﬁ-
cation accuracy (acc), speciﬁcity (spe), sensitivity (sen) and area under the
roc curve (auc)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_16.pdf,"= 0.2 and
ϵ = 0.4, respectively, on isic. the reason is that the cross-entropy loss easily
results in the overﬁtting issue on corrupted labels. 3.3
ablation study
to verify the eﬀectiveness of the noise cleaner, we compare our method with
the following comparison methods: 1) w/o nc: without noise cleaner, and 2)
mlp: replace gcn with multi-layer perceptron, i.e., without considering the
relationship among samples."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_25.pdf,"a complete objec-
tive should consider the symmetric form by switching d1 and d0 in (8).
4
experiments
4.1
dataset and metric
we evaluate our model against sotas on the existing polyp [14] dataset and
the panda-mil dataset introduced in this work. we employ the same eval-
uation criteria as the previous work for a fair comparison. please refer to the
supplementary material for the statistics of the two datasets."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_25.pdf,"its training split contains 163 videos of video-level anno-
tations, and the testing split includes 90 videos of frame-level annotations. the prostate cancer grade assessment (panda) challenge
[2] comprises over 10k whole-slide images (wsis) of digitized hematoxylin
and eosin-stained biopsies originating from radboud university medical cen-
ter and karolinska institute. panda-mil collects the eosin-stained biopsies
with region-based masks indicating the benign (normal) and cancerous (abnor-
mal) tissue, combined by stroma and epithelium."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_25.pdf,"in sum, panda-mil’s training
split contains 3,925 bags of bag-level annotations, and the testing split includes
975 bags of instance-level annotations.
metric. we follow the previous methods [4,13,14] to employ the instant-level
area under curve (auc) and the average precision (ap) for a fair comparison. the larger values of both metrics mean better disease detection performance."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_25.pdf,"wu et al.
table 1. comparison with auc and ap metrics on polyp and panda-mil datasets. [5], for a fair comparison. our method
is trained using adam optimizer with the learning rate of 0.001, batch size 32,
and 200 epochs."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_13.pdf,"cross-modulated few-shot image
generation for colorectal tissue
classiﬁcation
amandeep kumar1(b), ankan kumar bhunia1, sanath narayan3,
hisham cholakkal1, rao muhammad anwer1,2, jorma laaksonen2,
and fahad shahbaz khan1,4
1 mbzuai, masdar city, united arab emirates
amandeep.kumar@mbzuai.ac.ae
2 aalto university, espoo, finland
3 technology innovation institute, masdar city, united arab emirates
4 linköping university, linköping, sweden
abstract. in this work, we propose a few-shot colorectal tissue image
generation method for addressing the scarcity of histopathological train-
ing data for rare cancer tissues."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_13.pdf,"there-
fore, developing automatic and accurate histopathological image analysis meth-
ods that leverage recent progress in deep learning has received signiﬁcant atten-
tion in recent years. in this work, we investigate the problem of diagnosing
supplementary information the online version contains supplementary material
available at https://doi.org/10.1007/978-3-031-43898-1_13.
c
⃝ the author(s), under exclusive license to springer nature switzerland ag 2023
h. greenspan et al. https://doi.org/10.1007/978-3-031-43898-1_13
few-shot image generation for colorectal tissue classiﬁcation
129
colorectal cancer, which is one of the most common reason for cancer deaths
around the world and particularly in europe and america [23].
existing deep learning-based colorectal tissue classiﬁcation methods [18,21,22]
typically require large amounts of annotated histopathological training data for all
tissue types to be categorized."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_13.pdf,"therefore, we propose a few-shot (fs) image generation approach for
generating high-quality and diverse colorectal tissue images of novel classes using
limited exemplars. moreover, we demonstrate the applicability of these generated
images for the challenging problem of fs colorectal tissue classiﬁcation. contributions: we propose a few-shot colorectal tissue image generation
framework, named xm-gan, which simultaneously focuses on generating high-
quality yet diverse images."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_13.pdf,"our approach: while the aforementioned works explore fs generation in nat-
ural images, to the best of our knowledge, we are the ﬁrst to investigate fs gener-
ation in colorectal tissue images. in this work, we look into multi-class colorectal
tissue analysis problem, with low and high-grade tumors included in the set. the
corresponding dataset [14] used in this study is widely employed for multi-class
texture classiﬁcation in colorectal cancer histology and comprises eight types of
tissue: tumor epithelium, simple stroma, complex stroma, immune cells, debris,
normal mucosal glands, adipose tissue and background (no tissue)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_13.pdf,"as a result, this leads to high-quality
yet diverse colorectal tissue image generation in fs setting. 3
method
problem formulation: in our few-shot colorectal tissue image generation
framework, the goal is to generate diverse set of images from k input exam-
ples x of a unseen (novel) tissue classes. let ds and du be the set of seen and
unseen classes, respectively, where ds ∩du = ∅. in the training stage, we sample
images from ds and train the model to learn transferable generation ability to
produce new tissue images for unseen classes."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_13.pdf,"next, we introduce a controllable fea-
ture modulation mechanism in our cross-
transformer to further enhance the diversity
and quality of generated images. controllable feature modulation: the
standard cross-attention mechanism, described
above, computes locally consistent features
that generate images with reduced artifacts.
however, given the deterministic nature of the
cross-attention and the limited set of reference
images, simultaneously generating diverse and
high-quality images in the few-shot setting is
still a challenge. to this end, we introduce
a controllable feature modulation mechanism
within our cfb that aims at improving the
diversity and quality of generated images."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_13.pdf,"each pathologist is shown a random set of 20 images
136
a. kumar et al.
(10 real and 10 xm-gan generated) and asked to identify whether they are
real or generated. the study shows that pathologists could diﬀerentiate between
the ai-generated and real images only 55% time, which is comparable with a
random prediction in a binary classiﬁcation problem, indicating the ability of
our proposed generative framework to generate realistic colorectal images.
5
conclusions
we proposed a few-shot colorectal tissue image generation approach that com-
prises a controllable fusion block (cfb) which generates locally consistent fea-
tures by performing a dense aggregation of local regions from reference tissue
images based on their similarity to those in the base tissue image. we intro-
duced a mapping network together with a cross-modulated layer normalization,
within our cfb, to enhance the quality and diversity of generated images."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_13.pdf,"we extend our heartfelt appreciation to the pathologists who
made signiﬁcant contributions to our project. we are immensely grateful to dr. hima
abdurahiman from government medical college-kozhikode, india; dr. sajna pv from
mvr cancer center and research institute, kozhikode, india; dr. binit kumar khan-
delia from north devon district hospital, uk; dr. nishath pv from aster mother
hospital kozhikode, india; dr. mithila mohan from dr. girija’s diagnostic labora-
tory and scans, trivandrum, india; dr. kavitha from aster mims, kozhikode, india;
and several other unnamed pathologists who provided their expert advice, valuable
suggestions, and insightful feedback throughout various stages of our research work. this work was partially supported by the mbzuai-wis research program via project
grant wis p008."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_57.pdf,"nucleus segmentation is usually the ﬁrst step in pathologi-
cal image analysis tasks. generalizable nucleus segmentation refers to the
problem of training a segmentation model that is robust to domain gaps
between the source and target domains. the domain gaps are usually
believed to be caused by the varied image acquisition conditions, e.g.,
diﬀerent scanners, tissues, or staining protocols."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_57.pdf,"in this paper, we argue
that domain gaps can also be caused by diﬀerent foreground (nucleus)-
background ratios, as this ratio signiﬁcantly aﬀects feature statistics that
are critical to normalization layers. we propose a distribution-aware
re-coloring (darc) model that handles the above challenges from two
perspectives. first, we introduce a re-coloring method that relieves dra-
matic image color variations between diﬀerent domains."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_57.pdf,"therefore, existing dg works
usually replace bn with in for feature normalization [12,19]. however, for
dense-prediction tasks like semantic segmentation or contour detection, adopt-
ing in alone cannot fully address the feature statistics variation problem. this is
because feature statistics are also relevant to the ratio between foreground and
background pixel numbers."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_57.pdf,"it is shown that the value of b aﬀects the model
performance signiﬁcantly. the above problem is common in nucleus segmentation because pathologi-
cal images from diﬀerent organs or tissues tend to have signiﬁcantly diﬀerent
foreground-background ratios. however, this phenomenon is often ignored in
existing research."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_57.pdf,"moreover, we ﬁnd that the performance of instance nor-
malization is sensitive to the varied ratios in foreground and background pixel
numbers. this problem is well addressed by our proposed dain. compared
with existing works, darc achieves signiﬁcantly better performance on average
across four benchmarks.
acknowledgement."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_24.pdf,"the
contextualized features are then passed to distinct attention-based mil modules that
extract bag labels. furthermore, a knowledge distillation mechanism encourages the
agreement between the predictions delivered by diﬀerent scales.
retrieval, but also introducing multiple challenges. on the one hand, annotat-
ing wsis requires strong medical expertise, is expensive, time-consuming, and
labels are usually provided at the slide or patient level."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_24.pdf,"1. distinct gnns provide
contextualized features, which are fed to distinct attention-based mil modules
that compute bag-level predictions. through knowledge distillation, we encour-
250
g. bontempo et al.
age agreement across the predictions delivered at diﬀerent resolutions, while indi-
vidual scale features are learned in isolation to preserve the diversity in terms
of information content. by transferring knowledge across scales, we observe that
the classiﬁer self-improves as information ﬂows during training."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_24.pdf,"we encourage such a constraint
by minimizing the euclidean distance between the low-resolution criticality grid
map z1 and its subsampled counterpart computed by the high-resolution branch:
lcrit = ∥z1 − graphpooling(z2)∥2
2.
(2)
in the equation above, graphpooling identiﬁes a pooling layer applied over the
higher scale: to do so, it considers the relation “part of” between scales and then
averages the child nodes, hence allowing the comparison at the instance level. to sum up, the overall optimization problem is formulated
as a mixture of two objectives: the one requiring higher conditional likelihood
w.r.t. ground truth labels y and carried out through the cross-entropy loss
lce(·; y); the other one based on knowledge distillation:
min
θ
(1 − λ)lce(ybag
2
) + lce(ybag
1
) + λlkd + βlcrit,
(3)
where λ is a hyperparameter weighting the tradeoﬀ between the teaching signals
provided by labels and the higher resolution, while β balances the contributions
of the consistency regularization introduced in eq. das-mil: distilling across scales for mil classiﬁcation of wsis
253
4
experiments
wsis pre-processing."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_72.pdf,"historically,
a breakthrough in ct-mri registration was achieved by viola and wells, who
proposed mutual information [19]. essentially, it abstracts the problem to the
statistical concept of information theory and optimizes image-wide alignment
statistics. broken down to patch level and inspired by ultrasound physics, the
linear correlation of linear combination (lc2) measure has shown to work well
for us to mri or ct registration [2,22]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_72.pdf,"as an alternative to directly assessing similarity on the original images, var-
ious groups have proposed to ﬁrst compute intermediate representations, and
then align these with conventional l1 or l2 metrics [5,20]. [5], which is
based on image self-similarity and has with minor adaptations (denoted mind-
ssc for self-similarity context) also been applied to us problems [7]. yet, such
feature descriptors are not expressive enough to cope with complex us artifacts
and exhibit many local optima, therefore requiring closer initialization."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_72.pdf,"however, these methods are not generalizable to diﬀer-
ent anatomies or modalities. moreover, the paucity of precise and unambiguous
ground truth registration, particularly in abdominal mr-us registration, exac-
erbates the overﬁtting problem, restricting generalization even within the same
modality and anatomy. it has furthermore been proposed in the past to utilize
cnns as a replacement for a similarly metric."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_72.pdf,"when
φ is a fully convolutional neural network (cnn), we can simply feed it the entire
volume in order to pre-compute the feature vectors of every voxel with a single
forward pass. tα[p]⟩,
(2)
thus converting the original problem into a registration of pre-computed feature
maps using a simple and diﬀerentiable dot product similarity. this approxima-
tion is based on the assumption that the cnn is approximately equivariant to
the transformation, i.e. φ(m ◦tα)[p] ≈ φ(m)◦tα[p]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_72.pdf,"note that the network will be trained only once, on a
ﬁxed dataset that is fully independent of the datasets that will be used in the
evaluation (see sect. 4).
dataset. our neural network is trained using patches from the “gold atlas
- male pelvis - gentle radiotherapy” [14] dataset, which is comprised of 18
patients each with a ct, mr t1, and mr t2 volumes. we resample each volume
disa: universal multimodal registration
765
to a spacing of 2 mm and normalize the voxel intensities to have zero mean and
standard variation of one."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_72.pdf,"to assess the eﬀectiveness of our method,
1 https://github.com/imfusiongmbh/disa-universal-multimodal-registration. 766
m. ronchetti et al.
table 1. results on registration of brain us-mr data from the resect challenge. fre is the average of ﬁducial errors in millimeters across all cases, while fre25,
fre50, and fre75 refer to the 25th, 50th, and 75th percentiles.
method
mode
avg."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_72.pdf,"fur-
thermore, the evaluation speed of our objective function allows us to exhaustively
search the solution space, escaping local minima and converging to the correct
solution with pose and deformation parameters at once, in less than two seconds. note that this registration problem is much more challenging than the prior
two due to diﬃcult ultrasonic visibility in the abdomen, strong deformations,
and ambiguous matches of liver vasculature. therefore, to the best of our knowl-
edge, these results present a signiﬁcant leap towards reliable and fully automatic
fusion, doing away with cumbersome manual landmark placements."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_75.pdf,"for all tasks,
the new method outperformed embedding extraction methods that did not include
cell-level representations. using the publicly available herohe challenge data
set, the method achieved a state-of-the-art performance of 90% area under the
receiver operating characteristic curve. additionally, we present a novel model
explainability method that could identify cells associated with different classiﬁca-
tion groups, thus providing supplementary validation of the classiﬁcation model."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_75.pdf,"although cell-level analysis has the potential to
produce more detailed and explainable data, it can be limited by the unavailability
of sufﬁciently annotated training data. to overcome this problem, weakly supervised
and multiple instance learning (mil) based approaches have been applied to numer-
ous wsi classiﬁcation tasks [6–10]. however, many of these models use embeddings
derived from tiles extracted using pretrained networks, and these often fail to capture
useful information from individual cells."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_75.pdf,"our
new method achieved better performance on wsi classiﬁcation tasks and had a greater
level of explainability than models that used only tile-level embeddings. 2
embedding extraction scheme
transfer learning using backbones pretrained on natural images is a common method
that addresses the challenge of using data sets that largely lack annotation. however,
using backbones pretrained on natural images is not optimal for classiﬁcation of clinical
images [11]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_75.pdf,"numbers in the bars
represent the number of wsis by classiﬁcation for each task. for breast cancer human epidermal growth factor receptor 2 (her2) prediction,
we used data from the herohe challenge data set [26]. to enable comparison with
previous results we used the same test data set that was used in the challenge [27]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_75.pdf,"for
prediction of estrogen receptor (er) status, we used images from the tcga-breast
invasive carcinoma (tcga-brca) data set [28] for which the er status was known. deep cellular embeddings: an explainable plug and play improvement
781
for these two tasks we used artifact-free tiles from tumor regions detected with an
in-house tumor detection model.
for breast cancer metastasis detection in lymph node tissue, we used wsis of h&e-
stained healthy lymph node tissue and lymph node tissue with breast cancer metastases
from the publicly available camelyon16 challenge data set [16, 29]. all artifact-free
tissue tiles were used."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_75.pdf,"4. model performance using the xformer and a-mil architectures for the breast cancer
her2 status, breast cancer er status, and breast cancer metastasis detection in lymph node tissue
classiﬁcation tasks. error bars represent 95% conﬁdence intervals computed by a 5000-sample
bias-corrected and accelerated bootstrap. in fact, for the her2 classiﬁcation task, combined embeddings obtained using the
xformer architecture achieved, to our knowledge, the best performance yet reported on
the herohe challenge data set (area under the receiver operating characteristic curve
[auc], 90%; f1 score, 82%)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_75.pdf,"5. model performance using the xformer and a-mil architectures for the coo in dlbcl
classiﬁcation task. error bars represent 95% conﬁdence intervals computed by a 5000-sample
bias-corrected and accelerated bootstrap.
4.1
model explainability
tile-based approaches in dp often use explainability methods such as gradient-weighted
classactivationmapping[30]tohighlightpartsoftheimagethatcorrespondwithcertain
category outputs. while the backbone of our model was able to highlight individual cells,
there was no guaranteed correspondence between the model activations and the cells."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_62.pdf,"for instance, a model
trained on whole-mount slides only may not generalize well to biopsy slides due
to systematic shifts, hindering model performance in the clinical application
scenario. to address the above issues, we propose an adversarial multi-modal learning
(aml) module to force the feature extractor to produce multimodal-invariant
representations on multiple source images. speciﬁcally, we incorporate a source
discriminator adversarial neural network as auxiliary classiﬁer."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_62.pdf,"the stroma classi-
ﬁer and source discriminator are trained simultaneously, aiming to eﬀectively
classify tumor-associated stroma while impeding accurate source prediction by
the discriminator. the optimization process aims to achieve a balance between
these two goals, resulting in an embedding space that encodes as much informa-
tion as possible about tumor-associated stroma identiﬁcation while not encod-
ing any information on the data source. by adopting the adversarial learning
648
z. wang et al.
strategy, our model can maintain the correlated information and shared charac-
teristics between two modalities, which will enhance the model’s generalization
and robustness."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_51.pdf,"in addition, for the dose painting
strategy, there is a need to develop image segmentation approaches that
reproducibly and accurately identify the high recurrent-risk contours. to
address these issues, we propose a novel hybrid-cnn that integrates a
kernel smoothing-based probability contour approach (kspc) to produce
contour-based segmentation maps, which mimic expert behaviours and
provide accurate probability contours designed to optimise dose paint-
ing/imrt strategies. instead of user-supplied tuning parameters, our
ﬁnal model, named kspc-net, applies a cnn backbone to automatically
learn the parameters and leverages the advantage of kspc to simultane-
ously identify object boundaries and provide probability contour accord-
ingly."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_51.pdf,"our framework is com-
pletely automatic and diﬀerentiable. more speciﬁcally, we use the classic unet
[17] as the cnn backbone and evaluate our kspc-net on the publicly avail-
able miccai hecktor (head and neck tumor segmentation) challenge
2021 dataset. our proposed kspc-net yields superior results in terms of both
dice similarity scores and hausdorﬀ distance compared to state-of-art models."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_51.pdf,"in addition, α is a balancing parameter
and is set to be 0.01 in this work. 3
experiments
3.1
dataset
the dataset is from the hecktor challenge in miccai 2021 (head and neck
tumor segmentation challenge). for each patient, fdg-
pet input images and corresponding labels in binary description (0 s and 1 s)
for the primary gross tumour volume are provided and co-registered to a size
of 144 × 144 × 144 using bounding box information encompassing the tumour."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_51.pdf,"4
results
4.1
results on hecktor 2021 dataset
to evaluate the performance of our kspc-net, we compared it with the results
of 5-fold cross-validation against three widely-used models namely, the standard
2d unet, the 2d residual unet and the 3d unet. [7] and ccut-net
[21] which were reported in the hecktor 2021 challenges [1]. to quantify the
performance, we report several metrics including dice similarity scores, preci-
sion, recall, and hausdorﬀ distance."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_51.pdf,"the kspc-net utilizes the beneﬁts of kspc to deliver
both contour-based and grid-based segmentation outcomes, leading to improved
precision in the segmentation of contours. promising performance was achieved
by our proposed kspc-net compared to the state-of-the-art approaches on the
miccai 2021 challenge dataset (hecktor). it is worth mentioning that the
542
w. zhang and s. ray
architecture of our kspc-net is not limited to head & neck cancer type and can
be broadcast to diﬀerent cancer types."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_64.pdf,"consideration of subgroups or domains within medical image
datasets is crucial for the development and evaluation of robust and gen-
eralizable machine learning systems. to tackle the domain identiﬁcation
problem, we examine deep unsupervised generative clustering approaches
for representation learning and clustering. the variational deep embed-
ding (vade) model is trained to learn lower-dimensional representations
of images based on a mixture-of-gaussians latent space prior distribu-
tion while optimizing cluster assignments."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_64.pdf,"thus, achieving (through training) and demonstrating (as part of testing)
satisfactory ml model performance across relevant subgroups is crucial before
the real-world clinical deployment of a medical ml system [13].
however, a challenging situation arises when relevant subgroups are unrec-
ognized. one solution to this issue is to apply a clustering algorithm to the data,
with the goal of identifying the unannotated subgroups. the main objective of
unsupervised clustering is to group data points into distinct classes of similar
traits."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_16.pdf,"detecting domain shift in multiple
instance learning for digital pathology
using fr´echet domain distance
milda poceviˇci¯ut˙e1,2(b)
, gabriel eilertsen1,2
, stina garvin3,
and claes lundstr¨om1,2,4
1 center for medical imaging science and visualization, link¨oping university,
university hospital, link¨oping, sweden
{milda.poceviciute,gabriel.eilertsen,claes.lundstrom}@liu.se
2 department of science and technology, link¨oping university, link¨oping, sweden
3 department of clinical pathology, department of biomedical and clinical sciences,
link¨oping university, link¨oping, sweden
garvin.stina@regionostergotland.se
4 sectra ab, link¨oping, sweden
abstract. multiple-instance learning (mil) is an attractive approach
for digital pathology applications as it reduces the costs related to data
collection and labelling."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_16.pdf,"we trained an
attention-based mil algorithm to classify whether a whole-slide image
of a lymph node contains breast tumour metastases. the algorithm was
evaluated on data from a hospital in a diﬀerent country and various sub-
sets of this data that correspond to diﬀerent levels of domain shift. our
contributions include showing that mil for digital pathology is aﬀected
by clinically realistic diﬀerences in data, evaluating which features from
a mil model are most suitable for detecting changes in performance,
and proposing an unsupervised metric named fr´echet domain distance
(fdd) for quantiﬁcation of domain shifts."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_16.pdf,"[32], or
domain generalisation when the target data is unavailable [34]. however, it may not
be feasible to perform an explicit domain adaptation, and an already adapted
model could still experience problems with domain shifts. hence, it is important
to provide indications of the expected performance on a target dataset without
requiring annotations [5,25]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_16.pdf,"hence, it is not clear how well they will work
in such a scenario. in this work, we evaluate an attention-based mil model on unseen data
from a new hospital and propose a way to quantify the domain shift severity. the model is trained to perform binary classiﬁcation of wsis from lymph nodes
of breast cancer patients."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_16.pdf,"to evaluate
clinically realistic domain shifts, we divided the dataset in two diﬀerent ways,
creating four subsets:
1a. 161 wsis from sentinel node biopsy cases (54 wsis with metastases): a
small shift as it is the same type of lymph nodes as in grand challenge
camelyon data [16].
1b. 141 wsis from axillary nodes dissection cases (57 wsis with metastases):
potentially large shift as some patients have already started neoadjuvant
treatment as well as the tissue may be aﬀected from the procedure of sentinel
lymph node removal.
2a."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_16.pdf,"however, it may require more eﬀort to determine what type of
changes in data distribution are critical. our results show that domain shift is
present between the wsis from the same hospital (camelyon data) and another
medical centre (brln data). however, as clinically relevant subsets of brln
data are analysed, stark diﬀerences in performance and reliability (indicated
by the standard deviation) are revealed."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_16.pdf,"an interesting
aspect is that the performance was better for the out-of-domain ductal subset
compared to in-domain camelyon wsis. in practical applications, it may be a
problem when the domain shift quantiﬁcation cannot separate between shifts
having positive or negative eﬀect on performance. such diﬀerentiation could be
the topic of future work."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_16.pdf,"we carried out a study on how clinically realistic domain shifts
aﬀect attention-based mil for digital pathology. the results show that domain
shift may raise challenges in mil algorithms. furthermore, there is a clear beneﬁt
of using attention for feature selection and our proposed fddk metric for quan-
tiﬁcation of expected performance drop."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_25.pdf,"initial failed attempts used segmentation or geometric meth-
ods, but led to the discovery that it could be resolved by leveraging high-
dimensional image features and probe position information. to demon-
strate the eﬀectiveness of this solution, we designed and implemented a
simple regression network that successfully addressed the problem. to
further validate the proposed solution, we acquired and publicly released
two datasets captured using a custom-designed, portable stereo laparo-
scope system."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_25.pdf,"keywords: laparoscopic image-guided intervention · minimally
invasive surgery · detection of sensing area
supplementary information the online version contains supplementary material
available at https://doi.org/10.1007/978-3-031-43996-4 25.
c
⃝ the author(s), under exclusive license to springer nature switzerland ag 2023
h. greenspan et al. https://doi.org/10.1007/978-3-031-43996-4_25
detecting the sensing area of a laparoscopic probe in cancer surgery
261
1
introduction
cancer remains a signiﬁcant public health challenge worldwide, with a new diag-
nosis occurring every two minutes in the uk (cancer research uk1). surgery is
one of the main curative treatment options for cancer."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_25.pdf,"leverages the cancer-targeting ability of nuclear
agents typically used in nuclear imaging to more accurately identify cancer intra-
operatively from the emitted gamma signal (see fig. however, the use of
this probe presents a visualization challenge as the probe is non-imaging and is
air-gapped from the tissue, making it challenging for the surgeon to locate the
probe-sensing area on the tissue surface. it is crucial to accurately determine the sensing area, with positive signal
potentially indicating cancer or aﬀected lymph nodes."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_25.pdf,"our system
consists of four main components: a customized stereo laparoscope system for
capturing stereo images, a rotation stage for automatic phantom movement, a
shutter for illumination control, and a daq-controlled switchable laser module
(see fig. with this setup, we aim to transform the sensing area localization
problem from a geometrical issue to a high-level content inference problem in
2d. it is noteworthy that this remains a challenging task, as ultimately we need
to infer the probe axis-surface intersection without the aid of the laser module
to realistically simulate the use of the ‘sensei’ probe."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_25.pdf,"hence, stereo image data was also adopted in
this paper. if the problem of inferring the intersection point is treated as a geometric
problem, both data collection and intra-operative registration would be diﬃcult,
which inspired us to approach this problem diﬀerently. in practice, we utilize the
laser module to collect the ground truth of the intersection points when the laser
is on."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_25.pdf,"hence, we input these axes to the network as another
branch and randomly sampled points along them to represent the probe. 3
dataset
to validate our proposed solution for the newly formulated problem, we acquired
and publicly released two new datasets. in this section, we introduce the hard-
ware and software design that was used to achieve our ﬁnal goal, while fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_25.pdf,"since it is important to report errors in 3d and in millimeters, we
recorded another dataset similar to jerry but also including ground truth depth
map for all frames by using structured-lighting system [8]—namely the coﬀbee
dataset. these datasets have multiple uses such as:
– intersection point detection: detecting intersection points is an important
problem that can bring accurate surgical cancer visualization. we believe
this is an under-investigated problem in surgical vision."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_25.pdf,"– depth estimation: corresponding ground truth will be released.
– tool segmentation: corresponding ground truth will be released. 4
probe axis-surface intersection detection
4.1
overview
the problem of detecting the intersection point is trivial when the laser is on and
can be solved by training a deep segmentation network. however, segmentation
requires images with a laser spot as input, while the real gamma probe produces
no visible mark and therefore this approach produces inferior results."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_25.pdf,"however, marker-based tracking and pose
estimation methods have sterilization implications for the instrument, and the
sfm method requires the surgeon to constantly move the laparoscope, reducing
the practicality of these methods for surgery. in this work, we propose a simple, yet eﬀective regression approach to address
this problem. our approach relies solely on the 2d information and works well
without the need for the laser module after training."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_25.pdf,"images
resblock1
....
resblock4
fc
concatenation
mlp1
mlp2
loss
feature1
point
feature
visual
feature
feature2
principal points
fig. 4. an overview of our approach using resnet and mlp.
4.2
intersection detection as segmentation
we utilized diﬀerent deep segmentation networks as a ﬁrst attempt to address
our problem [10,18]. please refer to the supplementary material for the imple-
mentation details of the networks."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_25.pdf,"therefore the network does not have any visual information to make
predictions from images of the gamma probe. we note that to enable real-world
applications, we need to estimate the intersection point using the images when
the laser module is turned oﬀ.
4.3
intersection detection as regression
problem formulation. formally, given a pair of stereo images il, ir, n points
{pl
1, pl
2, ..., pl
n} were sampled along the principal axis of the probe, pl
i ∈ r2
from the left image."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_25.pdf,"this ﬁgure illustrates that our proposed method successfully detected the inter-
section point using solely standard rgb laparoscopic images as the input. fur-
thermore, based on the simple design, our method achieved the inference time
of 50 frames per second, making it well-suitable for intraoperative surgery.
6
conclusion
in this work, a new framework for using a laparoscopic drop-in gamma detector
in manual or robotic-assisted minimally invasive cancer surgery was presented,
where a laser module mock probe was utilized to provide training guidance and
the problem of detecting the probe axis-tissue intersection point was transformed
to laser point position inference. both the hardware and software design of the
proposed solution were illustrated and two newly acquired datasets were publicly
released."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_25.pdf,"extensive experiments were conducted on various backbones and the
best results were achieved using a simple network design, enabling real time
inference of the sensing area. we believe that our problem reformulation and
dataset release, together with the initial experimental results, will establish a
new benchmark for the surgical vision community."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_26.pdf,"compared
with traditional methods, our network is more applicable to the task of
skin cancer detection. furthermore, unlike traditional unilaterally aug-
mented (ua) methods, the proposed supernet skin-cancer net (sc-net)
considers the fairness of training and alleviates the eﬀects of evalua-
tion bias. we use the sc-net to fairly treat all the architectures in the
search space and leveraged evolutionary search to obtain the optimal
architecture for a skin cancer dataset."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_26.pdf,"the signiﬁcant variance in pathology and natural images can compro-
mise these models’ accuracy. neural architecture search (nas) addresses this
issue by auto-designing superior models [10–13], exploring a vast architecture
space. however, current nas methods often overlook fairness in architecture
ranking, impeding the discovery of top-performing models."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_26.pdf,"to improve the eﬃciency and accuracy of the
search, we developed a new framework named sc-net, which focuses on identify-
ing highly valuable architectures. we observed that conventional nas methods
often overlook fairness ranking during the search, hindering the search for opti-
mal solutions. our sc-net framework addresses this by ensuring fair training
and precise ranking."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_26.pdf,"[14]. section 2.2
provides further details about the supernet. a balanced evolutionary algorithm
is then used to select the optimal structure from the search space, with the
candidate structures’ performance evaluated using mini-batch patch data. we
evaluate the searched architectures on the skin cancer dataset."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_26.pdf,"3. schematic diagram comparing (a) the ua method and (b) our method. in the
ua principle, some channels are trained twice while others are trained only once or
not at all, leading to channel training unfairness and evaluation bias. in contrast, our
proposed method ensures that all channels are trained evenly (twice) by training both
the width d and its complementary width."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_26.pdf,"[1 : d] , d ≤ n
(3)
where γa (d) means the selected d channels from the left (smaller-index) side. however, the ua principle leads to channel training imbalance in the super-
net due to its constraints, as illustrated in fig. channels with smaller
indices are used for various sizes, resulting in over-training of the left chan-
nel kernels since widths are uniformly sampled."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_26.pdf,"therefore, channels closer to the left will get more
attempts during training, which leads the degree of training to vary widely
between channels. this introduces evaluation bias and leads to sub-optimal
results.
to mitigate evaluation bias on width, we propose a new sc-net that pro-
motes the fairness of channels during training. as shown in fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_26.pdf,"since the channels are counted from the right within sr,
the training degree of the d-th channel on the left corresponds to the training
degree of the (n−d+1)-th channel on the right in eq. + 1
(8)
therefore, the training degree t for each channel will always be equal to the
same constant value of the width, independent of the channel index, ensuring
fairness in terms of channel (ﬁlter) levels. thus the network width can be fairly
ranked using our network."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_26.pdf,"comparison with related methods. to ensure a fair comparison on our
dataset, we selected several papers in the ﬁeld of pathological image analysis,
such as [9,22,23], as well as others using the ua principle, such as [18,24].
evaluation metrics. our model was evaluated on: (1) accuracy (acc): per-
centage of correct classiﬁcations."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_26.pdf,"as shown in table 4, our s resnet50 surpassed the original
resnet50 on all datasets, gaining 2.3% and 1.8% more auc on chestmnist
and dermamnist respectively, proving the model’s robust generalization.
detection of basal cell carcinoma in whole slide images
271
table 4. performance comparison on chestmnist and dermamnist datasets
model
chestmnist dermamnist
auc acc
auc acc
resnet18
76.8
94.7
91.7
73.5
resnet50
76.9
94.7
91.3
73.5
auto-sklearn
64.9
77.9
90.2
71.9
autokeras
74.2
93.7
91.5
74.9
google automl 77.8
94.8
91.4
76.8
s resnet50
79.2
95.5
93.1
77.8
4
conclusion and future work
in this paper, we introduce sc-net, a novel nas framework for skin cancer
detection in pathology images. by formulating sc-net as a balanced supernet,
we ensure fair ranking and treatment of all potential architectures. with sc-
net and evolutionary search, we obtained optimal architectures, achieving 96.2%
top-1 and 96.5% accuracy on a skin cancer dataset, improvements of 4.8% and
4.7% over baselines."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_24.pdf,"they also have a clear performance limit and low data uti-
lization eﬃciency. to address these issues, we introduce a two-stage
detection-free pipeline, incorporating pooling transformer and moco pre-
training strategies, that optimizes data utilization for whole slide images
(wsis) while relying solely on sample-level diagnosis labels for training. the experimental results demonstrate the eﬀectiveness of our approach,
with performance scaling up as the amount of data increases."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_24.pdf,"our code and model is avail-
able at https://github.com/thebestannie/detection-free-miccai2023. keywords: detection-free · contrastive learning · pathology image
classiﬁcation · cervical cancer
1
introduction
cervical cancer is a common and severe disease that aﬀects millions of women
globally, particularly in developing countries [9]. early diagnosis is vital for suc-
cessful treatment, which can signiﬁcantly increase the cure rate [17]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_24.pdf,"finally, many existing methods focus on detecting
and classifying individual cells. the tendency to neglect eﬀective integration of
the overall information across the entire wsi results in poor performance in
sample-level classiﬁcation.
to address the aforementioned issues, we propose a detection-free pipeline
in this paper, which does not rely on any detection model. instead, our pipeline
requires only sample-level diagnosis labels, which are naturally available in clin-
ical scenarios and thus get rid of additional image labeling."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_24.pdf,"248
m. cao et al.
3
experiment and results
dataset and experimental setup. in this study, we have collected 5384
cervical cytopathological wsi by 20x lens, each with 20000 × 20000 pixels, from
our collaborating hospitals. among them, there 2853 negative samples, and 2531
positive samples (962 ascus, and 1569 high-level positive samples)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_24.pdf,"for inference time consuming, as shown
in right of fig. 3, our method has shorter inference time and a good balance
between accuracy and inference time. 4
conclusion and discussion
in this paper, we propose a novel two-stage detection-free pipeline for wsi clas-
siﬁcation of cervical abnormality."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_9.pdf,"developing large pre-trained model for breast
tumor segmentation from ultrasound images
meiyu li1, kaicong sun1, yuning gu1, kai zhang1, yiqun sun1, zhenhui li2,
and dinggang shen1,3(b)
1 school of biomedical engineering, shanghaitech university, shanghai, china
dgshen@shanghaitech.edu.cn
2 department of radiology, yunnan cancer hospital, kunming, china
3 shanghai united imaging intelligence co., ltd., shanghai, china
abstract. early detection and diagnosis of breast cancer using ultrasound images
are crucial for timely diagnostic decision and treatment in clinical application."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_9.pdf,"however, due to speckle noise and shadows in ultrasound
images, breast tumor boundaries tend to be blurry and are difﬁcult to be distinguished
from background. these issues pose challenges and difﬁculties for accurate
breast tumor segmentation in ultrasound images. various approaches based on deep learning have been developed for tumor seg-
mentation with promising results [13–19]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_9.pdf,"however, although these proposed models have
achieved satisfactory results in different medical segmentation tasks, their performances
are limited for breast tumor segmentation in ultrasound images due to the low image
contrast and blurry tissue boundary. to address these challenges, we present, to the best of our knowledge, the ﬁrst
work to adopt multi-scale features collected from large set of clinical ultrasound images
for breast tumor segmentation. the main contributions of our work are as follows: (1)
we propose a well-pruned simple but effective network for breast tumor segmentation,
which shows remarkable and solid performance on large clinical dataset; (2) our large
pretrained model is evaluated on two additional public datasets without ﬁne-tuning and
shows extremely stabilized improvement, indicating that our model has outstanding
generalizability and good robustness against multi-site data data."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_9.pdf,"cnθcn(g) represents the
probability for the input of cn coming from the original dataset.
intheimplementation,weupdatethesegmentationnetworkandallthediscriminators
alternatingly in each iteration until both the generator and discriminators are converged. 92
m. li et al.
3
experiments
3.1
dataset and implementation details
we collected 10927 cases for this research from yunnan cancer hospital. each scan is
with resolution of 1 × 1 mm2 and size of 512 × 480."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_19.pdf,"currently, deep learning (dl) has achieved the automatic prediction
of dose distribution in radiotherapy planning, enhancing its efﬁciency and qual-
ity. however, existing methods suffer from the over-smoothing problem for their
commonly used l1 or l2 loss with posterior average calculations. to alleviate this
limitation, we innovatively introduce a diffusion-based dose prediction (diffdp)
model for predicting the radiotherapy dose distribution of cancer patients."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_19.pdf,"[17] constructed an additional segmentation task
to provide the dose prediction task with essential anatomical knowledge. although the above methods have achieved good performance in predicting dose
distribution, they suffer from the over-smoothing problem. [17, 18], leading to the over-smoothed predicted images without important
high-frequency details [19]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_19.pdf,"[20] has veriﬁed its remarkable potential in modeling
complex image distributions in some vision tasks [21–23]. unlike other dl models, the
diffusion model is trained without any extra assumption about target data distribution,
thus evading the average effect and alleviating the over-smoothing problem [24]. figure 1
(4) provides an example in which the diffusion-based model predicts a dose map with
shaper and clearer boundaries of ray-penetrated areas. therefore, introducing a diffusion
model to the dose prediction task is a worthwhile endeavor."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_19.pdf,"by incorporating the anatomical information, the noise predictor can be aware
of the dose constraints among ptv and oars, thus distributing more appropriate dose
to them and generating more accurate dose distribution maps. overall, the contributions of this paper can be concluded as follows: (1) we propose
a novel diffusion-based model for dose prediction in cancer radiotherapy to address
the over-smoothing issue commonly encountered in existing dl-based dose prediction
methods. to the best of our knowledge, we are the ﬁrst to introduce the diffusion model
for this task."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_19.pdf,"additionally,
the noise intensity is initialized to 1e−2 and decayed to 1e−4 linearly along with the
increase of steps.
3
experiments and results
dataset and evaluations. we measure the performance of our model on an in-house
rectum cancer dataset which contains 130 patients who underwent volumetric modulated
arc therapy (vmat) treatment at west china hospital. concretely, for every patient, the
ct images, ptv segmentation, oars segmentations, and the clinically planned dose
distribution are included."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_6.pdf,"the code will be accessible to the public. keywords: bilateral mammogram · asymmetric transformer ·
disentanglement · self-adversarial learning · synthesis
1
introduction
breast cancer (bc) is the most common cancer in women and incidence is
increasing [14]. with the wide adoption of population-based mammography
c
⃝ the author(s), under exclusive license to springer nature switzerland ag 2023
h. greenspan et al."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_6.pdf,"to mimic the process of radiologists, previous studies
only extracted simple features from the two breasts and used fusion techniques
to perform the classiﬁcation [6,20,22,24,25]. however, most of these studies formulate
the diagnosis as an mv analysis problem without dedicated comparisons between
the two breasts. the question of “what the bi-mg would look like if they were symmetric?”
is often considered when radiologists determine the symmetry of bi-mg."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_6.pdf,"however, it is
disentanglement of asymmetrical abnormality on bilateral mammograms
61
diﬃcult to train the generator in a supervised manner due to the lack of annota-
tions of the location for asymmetrical pairs. [10], we introduce a frozen discriminator ψd to impose constraints
on the generator to address this challenge. the frozen discriminator comprises
the same components as asyc."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_6.pdf,"the tumors and
symmetrical mammograms are combined by an alpha blending-based method
[17], which can be denoted by x|fake = x n
k=1(1 − αk) + n
k=1 tkαk, t ∈ t . the alpha weights αk is a 2d gaussian distribution map, in which the co-variance
is determined by the size of k-th tumor t, representing the transparency of the
pixels of the tumor. some examples are shown in fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_6.pdf,"the vindr-mammo dataset [8]
includes 5,000 cases with bi-rads assessments and bounding box annotations,
consisting of 13,404 normal (bi-rads = 1) and 6,580 abnormal (bi-rads
̸= 1) images. the in-house dataset comprises 43,258 mammography exams from
10,670 women between 2004–2020, collected from a hospital with irb approvals. in this study, we randomly select 20% women of the full dataset, comprising 6,000
normal (bi-rads = 1) and 28,732 abnormal (bi-rads ̸= 1) images."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_10.pdf,"for the sake of promoting
segmentation performance, recent methods utilize the dynamic mr sequence and
exploit its temporal correlations to acquire powerful representations [2–4]. [5,6]. how-
ever, the aforementioned methods require the complete dce-mri sequences and
overlook the diﬃculty in assessing complete temporal sequences and the missing
time point problem, especially post-contrast phase, due to the privacy protection
and patient conditions. hence, these breast cancer segmentation models cannot
be deployed directly in clinical practice."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_10.pdf,"ground truth segmentations of the data are provided in the dataset for tumor
annotation. no data augmentation techniques are used to ensure fairness. all approaches are evaluated using 1) dice
similarity coeﬃcient (dsc) and 2) jaccard index (ji)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_10.pdf,"the model is trained for 500 epochs with the
batch size to 1. no data augmentation techniques are used to ensure fairness. imental results demonstrate that the proposed method comprehensively other
models with less scans (i.e., pre-contrast) in testing."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_57.pdf,"clearly, the nuclei struc-
ture is a 3-channel map with the same size as the image. therefore, the problem of synthesizing instance map
transfers to synthesizing nuclei structures. we deploy an unconditional diﬀusion
model to learn the distribution of nuclei structures."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_50.pdf,"dose guidance for radiotherapy-oriented
deep learning segmentation
elias r¨ufenacht1(b)
, robert poel2, amith kamath1
, ekin ermis2,
stefan scheib3, michael k. fix2, and mauricio reyes1,2
1 artorg center for biomedical engineering research,
university of bern, bern, switzerland
elias.ruefenacht@unibe.ch
2 department of radiation oncology, inselspital, bern university hospital
and university of bern, bern, switzerland
3 varian medical systems imaging laboratory gmbh, baden, switzerland
abstract. deep learning-based image segmentation for radiotherapy is
intended to speed up the planning process and yield consistent results."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_50.pdf,"nonetheless, recent studies have reported general pitfalls of these metrics
[4,19] as well as a low correlation with end-clinical objectives [11,18,22,23]. fur-
thermore, from a robustness point of view, models trained with these loss func-
tions have been shown to be more prone to generalization issues. these studies have also reported results
favoring distribution-matching losses, such as the cross-entropy being a strictly
proper scoring rule [6], providing better-calibrated predictions and uncertainty
estimates."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_50.pdf,"hence, only the parameters of the
segmentation model are updated. [20]
architecture for all trained segmentation models, with the same training param-
eters but two diﬀerent loss functions, to allow for a fair comparison. as a strong
comparison baseline, we used a combo-loss formed by bce plus softdice, which
is also used by nnunet and recommended by its authors [8]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_50.pdf,"as pointed out by [17], segmentation outliers can have a
detrimental eﬀect on rt planning. we also remark that the range of hd values is
in range with values reported by models trained using much more training data
(see [1]), alluding to the possibility that the problem of robustness might not be
directly solvable with more data. dice coeﬃcients did not deviate signiﬁcantly
between the baseline and the doselo models (dsc: 0.713 ± 0.203 (baseline)
vs. 0.697 ± 0.216 (doselo))."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_72.pdf,"keywords: medical image classiﬁcation · curriculum learning ·
uncertainty estimation
1
introduction
curriculum learning methods in deep learning are inspired by human educa-
tion and involve structuring the training data from easy to hard to teach net-
works progressively. however, developing a good diﬃculty metric or measurer
for curriculum learning is a challenge. recently, there are two main categories of
approaches to designing the diﬃculty metrics."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_72.pdf,"however, this type of approach suﬀers from the
uncertainty of quantifying the diﬃculty of data due to insuﬃcient training in
the early stages. in addition, while deep learning models have achieved impres-
sive performance in the medical image analysis ﬁeld, there remain challenges in
measuring and developing a model with low in-domain uncertainty. recently,
uncertainty estimation has emerged as an eﬀective tool for measuring the in-
domain uncertainty of models."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_72.pdf,"this process ensures
that the network is trained on easier samples at the beginning when it is less mature
and gradually moves towards harder samples as the network improves. we propose a new approach to address the challenges of curriculum learn-
ing, which we call dynamic curriculum learning via in-domain uncertainty
(dclu). our approach is motivated by two key observations: 1) sample diﬃ-
culty is inﬂuenced by both the complexity of the data and the model’s inability
dclu for medical image classiﬁcation
749
to explain data, related to in-domain uncertainty, and 2) reducing in-domain
uncertainty by improving the learning process can boost model performance."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_72.pdf,"however, some existing pacing functions attempt to partition the
dataset into multiple subsets and gradually feed them into the network during
training - this fails to satisfy the requirement of our diﬃculty measurer. to address
this problem, we propose the uncertainty-aware sampling pacing function (uas)
consisting of two modules: the reorder and sampling modules. within the reorder
module, uas sorts all training data from easy to hard according to ascending
uncertainties from ddm at the last epoch and sends them into the network to
yield predictions and new uncertainty estimates."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_72.pdf,"our method with uas (exponential) performs better than other
methods on chest-xray 8 (covid-19) and has the second best performance
on isic 2018 task 3. [12]
83.17
37.64
72.77
64.13
ours (exponential) 82.93
39.26
81.7
73.69
ours (full)
85.1
40.58
83.04
82.03
754
c. li et al.
due to the fact that our objective function is constructed based on the dirichlet
distribution and the presence of class imbalance within both datasets. when the
samples are selected by uas (exponential) at the early training stage, samples
from smaller numbered classes may not be chosen which leads to the optimiza-
tion may tend to fall into local extrema."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_23.pdf,"ecl: class-enhancement contrastive
learning for long-tailed skin lesion
classiﬁcation
yilan zhang, jianqi chen, ke wang, and fengying xie(b)
image processing center, school of astronautics, beihang university, beijing 100191,
china
xfy 73@buaa.edu.cn
abstract. skin image datasets often suﬀer from imbalanced data distri-
bution, exacerbating the diﬃculty of computer-aided skin disease diag-
nosis. some recent works exploit supervised contrastive learning (scl)
for this long-tailed challenge."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_23.pdf,"for infor-
mation enhancement, we design a hybrid-proxy model to generate class-
dependent proxies and propose a cycle update strategy for parameters
optimization. a balanced-hybrid-proxy loss is designed to exploit rela-
tions between samples and proxies with diﬀerent classes treated equally. taking both “imbalanced data” and “imbalanced diagnosis diﬃculty”
into account, we further present a balanced-weighted cross-entropy loss
following curriculum learning schedule."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_23.pdf,"as computer-aided diagnosis matures, recent advances
with deep learning techniques such as cnns have signiﬁcantly improved the per-
formance of skin lesion classiﬁcation [7,8]. however, as data-hungry approaches,
deep learning models require large balanced and high-quality datasets to meet the
supplementary information the online version contains supplementary material
available at https://doi.org/10.1007/978-3-031-43895-0 23.
c
⃝ the author(s), under exclusive license to springer nature switzerland ag 2023
h. greenspan et al. https://doi.org/10.1007/978-3-031-43895-0_23
ecl: class-enhancement contrastive learning
245
sample
enhanced proxy
anchor sample
anchor proxy
many class
medium class
few class
aggregation
separation
(a) supervised contrastive learning  
(b) class-enhancement contrastive learning
over-treatment 
equal-treatment 
fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_23.pdf,"in scl, head classes are over-
treated leading to optimization concentrating on head classes. by contrast, ecl utilizes
the proxies to enhance the learning of tail classes and treats all classes equally according
to balanced contrastive theory [24]. moreover, the enriched relations in samples and
proxies are helped for better representations."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_23.pdf,"accuracy and robustness requirements in applications, which is hard to suﬃce due
to the long-tailed occurrence of diseases in the real-world. long-tailed problem is
usually caused by diﬀerences in incidence rate and diﬃculties in data collection. some diseases are common while others are rare, making it diﬃcult to collect bal-
anced data [13]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_23.pdf,"this will cause the head classes to account for the majority of the
samples and the tail classes only have small portions. thus, existing public skin
datasets usually suﬀer from imbalanced problems which then results in class bias
of classiﬁer, for example, poor model performance especially on tail lesion types.
to tackle the challenge of learning unbiased classiﬁers with imbalanced data,
many previous works focus on three main ideas, including re-sampling data [1,
18], re-weighting loss [2,15,22] and re-balancing training strategies [10,23]. despite the great results achieved, these methods either
manually interfere with the original data distribution or improve the accuracy
of minority classes at the cost of reducing that of majority classes [12,13]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_23.pdf,"(2) scl loss focuses more on
optimizing the head classes with much larger gradients than tail classes, which
means tail classes are all pushed farther away from heads [24]. (3) most methods
246
y. zhang et al.
only consider the impact of sample size (“imbalanced data”) on the classiﬁcation
accuracy of skin diseases, while ignoring the diagnostic diﬃculty of the diseases
themselves (“imbalanced diagnosis diﬃculty”). to address the above issues, we propose a class-enhancement contrastive
learning (ecl) method for skin lesion classiﬁcation, diﬀerences between scl
and ecl are illustrated in fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_23.pdf,"a proxy
can be regarded as the representative of a speciﬁc class set as learnable param-
eters. we propose a novel hybrid-proxy model to generate proxies for enhancing
diﬀerent classes with a reversed imbalanced strategy, i.e., the fewer samples in
a class, the more proxies the class has. these learnable proxies are optimized
with a cycle update strategy that captures original data distribution to mitigate
the quality degradation caused by the lack of minority samples in a mini-batch."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_23.pdf,"the new loss treats all classes equally
and utilizes sample-to-sample, proxy-to-sample and proxy-to-proxy relations to
improve representation learning. moreover, we design a balanced-weighted cross-
entropy loss which follows a curriculum learning schedule by considering both
imbalanced data and diagnosis diﬃculty. our contributions can be summarized as follows: (1) we propose an ecl
framework for long-tailed skin lesion classiﬁcation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_23.pdf,"information of classes are
enhanced by the designed hybrid-proxy model with a cycle update strategy. (2)
we present a balanced-hybrid-proxy loss to balance the optimization of each
class and leverage relations among samples and proxies. (3) a new balanced-
weighted cross-entropy loss is designed for an unbiased classiﬁer, which considers
both “imbalanced data” and “imbalanced diagnosis diﬃculty”."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_23.pdf,"l2-normalization is applied to z by using inner product as distance
measurement in cl. both the class-dependent proxies generated by hybrid-proxy
model and the embeddings of samples are used to calculate balanced-weighted
cross-entropy loss, thus capturing the rich relations of samples and proxies. for
better representation, we design a cycle update strategy to optimize the proxies’
parameters in hybrid-proxy model, together with a curriculum learning schedule
for achieving unbiased classiﬁers."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_23.pdf,"2. overall framework of the proposed ecl. ecl has two branches for classi-
ﬁer learning (guided by balanced-weighted cross-entropy loss lbw ce) and contrastive
learning (guided by balanced-hybrid-proxy loss lbhp ). proxies in hybrid-proxy model
are generated by a reserve imbalanced way (see sect."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_23.pdf,"∈ {1, 2, ..., n p
c }, c ∈ {1, 2, ..., c}}, c is the class number, pc
k ∈ rd is
the k-th proxy vector of class c, and n p
c is the proxy number in this class. since
samples in a mini-batch follow imbalanced data distribution, these proxies are
designed to be generated in a reversed imbalanced way by giving more represen-
tative proxies of tail classes for enhancing the information of minority samples. let us denote the sample number of class c as nc and the maximum in all classes
as nmax."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_23.pdf,"as we know, a gradient descent algorithm will generally be executed to
update the parameters after training a mini-batch of samples. however, when
dealing with an imbalanced dataset, tail samples in a batch contribute little to
the update of their corresponding proxies due to the low probability of being
sampled. so how to get better representative proxies?"
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_23.pdf,"algorithm 1 presents
the details of the training process. 2.2
balanced-hybrid-proxy loss
to tackle the problem that scl loss pays more attention on head classes,
we introduce bcl and propose balanced-hybrid-proxy loss to treat classes
equally. i
, yi)

b, let z =

z(1,2)
i

b =

z1
1, z2
2, ..., z1
b, z2
b

be the feature embeddings in a batch and b denotes the
batch size."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_23.pdf,"in addition, we further deﬁne zc and pc as a subset with the label c
of z and p respectively. the average operation in the denominator of balanced-
hybrid-proxy loss can eﬀectively reduce the gradients of the head classes, making
an equal contribution to optimizing each class. note that our loss diﬀers from
bcl as we enrich the learning of relations between samples and proxies."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_23.pdf,"sample-
to-sample, proxy-to-sample and proxy-to-proxy relations in the proposed loss
have the potential to promote network’s representation learning. moreover, as
the skin datasets are often small, richer relations can eﬀectively help form a
high-quality distribution in the embedding space and improve the separation of
features.
2.3
balanced-weighted cross-entropy loss
taking both “imbalanced data” and “imbalanced diagnosis diﬃculty” into con-
sideration, we design a curriculum schedule and propose balanced-weighted
cross-entropy loss to train an unbiased classiﬁer. the training phase are divided
into three stages."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_23.pdf,"we ﬁrst train a general classiﬁer, then in the second stage we
assign larger weight to tail classes for “imbalanced data”. in the last stage, we
utilize the results on the validation set as the diagnosis diﬃculty indicator of
skin disease types to update the weights for “imbalanced diagnosis diﬃculty”. we assume
f e
c is the evaluation result of class c on validation set after epoch e and we use
f1-score in our experiments."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_23.pdf,"dataset consists of 10015 images in 7 classes while a larger 2019 dataset provides
25331 images in 8 classes. the imbalanced factors α = nmax
nmin of the two datasets
are all > 50 (isic2018 58.30 and isic2019 53.87), which means that skin lesion
classiﬁcation suﬀers a serious imbalanced problem. we randomly divide the sam-
ples into the training, validation and test sets as 3:1:1."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_23.pdf,"moreover, mwnl and scl have been veriﬁed to perform well in the skin disease
classiﬁcation task. to ensure fairness, we re-train all methods by rerun their
released codes on our divided datasets with the same experimental settings. ecl: class-enhancement contrastive learning
251
table 1. comparison results on isic2018 and isic2019 datasets."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_23.pdf,"it can be seen that ecl has
a signiﬁcant advantage with the highest level in most metrics on two datasets. noticeably, our ecl outperforms other imbalanced methods by great gains, e.g.,
2.56% in pre on isic2018 compared with scl and 4.33% in f1 on isic2019
dataset compared with tsc. furthermore, we draw the confusion matrixes after
normalization in fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_23.pdf,"to further verify the eﬀectiveness of the designs in ecl, we
conduct a detailed ablation study shown in table 2 (the results on isic2018 are
shown in supplementary material table s2). first, we directly move the con-
trastive learning (cl) branch and replaced the balanced-weighted cross-entropy
252
y. zhang et al.
(bwce) loss with cross-entropy (ce) loss. we can see from the results that
adding cl branch can signiﬁcantly improve the network’s data representation
ability with better performance than only adopting a classiﬁer branch."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_23.pdf,"with more proxies, metrics ﬂuctuate and do not increase sig-
niﬁcantly. however, the result of using proxies generated by reversed balanced
way in hybrid-proxy model (hpm) outperforms equal proxies in nearly all met-
rics, which proves that giving more proxies to tail classes can eﬀectively enhance
and enrich the information. 4
conclusion
in this work, we present a class-enhancement contrastive learning framework,
named ecl, for long-tailed skin lesion classiﬁcation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_23.pdf,"class-dependent proxies
are generated in hybrid-proxy model to enhance information of tail classes, where
rich relations between samples and proxies are utilized to improve representation
learning of the network. furthermore, balanced-weighted cross-entropy loss is
designed to help train an unbiased classiﬁer by considering both “imbalanced
data” and “imbalanced diagnosis diﬃculty”. extensive experiments on isic2018
and isic2019 datasets have demonstrated the eﬀectiveness and superiority of
ecl over other compared methods."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_46.pdf,"however, the large number of parame-
ter and computational load of these models make them unsuitable for
mobile health applications. to address this issue, we propose a more
eﬃcient approach, the eﬃcient group enhanced unet (ege-unet). we incorporate a group multi-axis hadamard product attention module
(ghpa) and a group aggregation bridge module (gab) in a lightweight
manner."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_46.pdf,"group multi-axis hadamard product attention module. to overcome
the quadratic complexity issue posed by mhsa, we propose hpa with linear
complexity. [10,20] on p, followed by a
hadamard product operation between x and p to obtain the output."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_24.pdf,"however, recent research has revealed that deep
neural networks for skin lesion recognition may overly depend on disease-
irrelevant image artifacts (i.e. dark corners, dense hairs), leading to poor
generalization in unseen environments. to address this issue, we pro-
pose a novel domain generalization method called epvt, which involves
embedding prompts into the vision transformer to collaboratively learn
knowledge from diverse domains. concretely, epvt leverages a set of
domain prompts, each of which plays as a domain expert, to capture
domain-speciﬁc knowledge; and a shared prompt for general knowledge
over the entire dataset."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_24.pdf,"to facilitate knowledge sharing and the interac-
tion of diﬀerent prompts, we introduce a domain prompt generator that
enables low-rank multiplicative updates between domain prompts and
the shared prompt. a domain mixup strategy is additionally devised to
reduce the co-occurring artifacts in each domain, which allows for more
ﬂexible decision margins and mitigates the issue of incorrectly assigned
domain labels. experiments on four out-of-distribution datasets and six
diﬀerent biased isic datasets demonstrate the superior generalization
ability of epvt in skin lesion recognition across various environments."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_24.pdf,"[3–5,29], which leads to unreli-
able diagnoses. when a deep learning model overﬁts speciﬁc artifacts instead of
learning the correct dermoscopic patterns, it may fail to identify skin lesions in
real-world environments where the artifacts are absent or inconsistent.
to alleviate the artifact bias and enhance the model’s generalization ability,
we rethink the problem from the domain generalization (dg) perspective, where
a model trained within multiple diﬀerent but related domains are expected to
perform well in unseen test domains. as illustrated in fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_24.pdf,"[7,24,32],
exploiting multiple learnable domain experts (e.g., batch norm statistic, auxil-
iary classiﬁers, etc.) to capture domain-speciﬁc knowledge from diﬀerent source
domains individually. still, two signiﬁcant challenges remain. first, previous
work only exploits some weak experts, like the batch norm, to capture knowledge,
which naturally hampers the capability of capturing essential domain-speciﬁc
knowledge."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_24.pdf,"second, previous methods such as [30] focused on learning domain
knowledge independently while overlooking the rich cross-domain information
that all domain experts can contribute collectively for the target domain predic-
tion. to overcome the above problems, we propose an environment-aware prompt
vision transformer (epvt) for domain generalization of skin lesion recognition. epvt: environment-aware prompt vision transformer
251
fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_24.pdf,"the prompt generator enables multiple domain
prompts to work collaboratively and beneﬁt from each other for generalization to
unknown domains. additionally, we devise a domain mixup strategy to resolve
the problem of co-occurring artifacts in dermoscopic images and mitigate the
resulting noisy domain label assignments. our contributions can be summarized as: (1) we resolve an artifacts-derived
biasing problem in skin cancer diagnosis using a novel environment-aware prompt
learning-based dg algorithm, epvt; (2) epvt takes advantage of a vit-
based domain-aware prompt learning and a novel domain prompt generator to
improve domain-speciﬁc and cross-domain knowledge learning simultaneously;
(3) a domain mixup strategy is devised to reduce the co-artifacts speciﬁc to
dermoscopic images; (4) extensive experiments on four out-of-distribution skin
datasets and six biased isic datasets demonstrate the outperforming general-
ization ability and robustness of epvt under heterogeneous distribution shifts."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_24.pdf,"by using the hadamard product, the model can eﬃciently leverage cross-domain
knowledge for target domain prediction. 2.3
mitigating the co-artifacts issue
the artifacts-based domain labels can provide domain information for der-
moscopic images. however, a non-trivial issue arises due to the possible co-
occurrence of diﬀerent artifacts from other domains within each domain."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_24.pdf,"= λxk
i +(1−λ)xq
j; xk
i and xq
j are samples from two diﬀerent domains
k and q, and yk
i and yq
j are the corresponding labels. this strategy can overcome
the challenge of ambiguous domain labels in dermoscopic images and improve
the performance of our model.
2.4
optimization
so far, we have introduced lmixup in eq. 3 for optimizing our model. however,
since our goal is to generalize the model to unseen environments, we also need
to take advantage of each domain prompt."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_24.pdf,"it’s worth noting that isic2019, derm7pt-
dermoscopic, and ph2 are dermoscopic images, while derm7pt-clinical and
pad are clinical images. (2) trap set debiasing: we train and test our epvt
with its baseline on six trap sets [3] with increasing bias levels, ranging from 0
(randomly split training and testing sets from the isic2019 dataset) to 1 (the
highest bias level where the correlation between artifacts and class label is in
the opposite direction in the dataset splits). more details about these datasets
and splits are provided in the complementary material."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_24.pdf,"3a, we present the performance of the erm base-
line and our epvt on six biased isic2019 datasets. each point on the graph
represents an algorithm that is trained and tested on a speciﬁc bias degree split. the graph shows that the erm baseline performs better than our epvt when
the bias is low (0 and 0.3)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_24.pdf,"however, this is because erm relies heavily on spu-
rious correlations between artifacts and class labels, leading to overﬁtting on the
training set. as the bias degree increases, the correlation between artifacts and
class labels decreases, and overﬁtting the train set causes the performance of
erm to drop dramatically on the test set with a signiﬁcant distribution diﬀer-
ence. in contrast, our epvt exhibits greater robustness to diﬀerent bias levels."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_24.pdf,"4
conclusion
in this paper, we propose a novel dg algorithm called epvt for robust skin
lesion recognition. our approach addresses the co-artifacts problem using a
domain mixup strategy and cross-domain learning problems using a domain
prompt generator. compared to other competitive domain generalization algo-
rithms, our method achieves outstanding results on three out of four ood
datasets and the second-best on the remaining one."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_36.pdf,"embarrassingly simple data
alteration to improve lyme disease
lesion segmentation and diagnosis
fairness
haolin yuan1, john aucott3, armin hadzic2, william paul2,
marcia villegas de flores1, philip mathew1,2, philippe burlina2,
and yinzhi cao1(b)
1 johns hopkins university, baltimore, usa
{hyuan4,mvilleg5,yinzhi.cao}@jhu.edu
2 johns hopkins applied physics laboratory, laurel, usa
{william.paul,philip.mathew,philippe.burlina}@jhuapl.edu
3 johns hopkins university school of medicine, baltimore, usa
jaucott2@jhmi.edu
abstract. lyme disease is a severe skin disease caused by tick bites,
which aﬀects hundreds of thousands of people."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_36.pdf,"however, it is
challenging to segment lyme disease lesions due to the lack of well-
segmented, labeled lyme datasets and the nature of lyme, e.g., the
typical bull’s eye lesion and its closeness to normal skin. in this paper,
we design a simple yet novel data preprocessing and alteration method,
called edgemixup, to help segment lyme lesions on imbalanced training
datasets. the key insight is to deploy a linear combination of lesion edge,
either detected or computed, and the source image highlights the aﬀected
lesion area so that a learning model focuses more on the preserved lesion
structure instead of skin tone, thus iteratively improving segmentation
performance."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_36.pdf,"additionally, the improved edge from lesion segmentation
can be further used for lyme disease classiﬁcation—e.g., in diﬀerentiat-
ing lyme from other similar lesions including tinea corporis and herpes
zoster—with improved model fairness on diﬀerent subpopulations. [1] yet some
improvements still remain to be addressed, importantly in areas that allow both
algorithmic performance and fairness [2], and in certain medical applications that
promise to signiﬁcantly lessen morbidity and mortality. early detection of skin
lesions is such an endeavor as it can aid in identifying infectious diseases with
supplementary information the online version contains supplementary material
available at https://doi.org/10.1007/978-3-031-43901-8_36.
c
⃝ the author(s), under exclusive license to springer nature switzerland ag 2023
h. greenspan et al."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_36.pdf,"first, there lacks
of a well-segmented dataset with manual labels on lyme disease. on one hand,
some datasets—such as ham10000 [10] and isbi challenges [11]—have manual
annotated segmentations for diseases like melanoma, but they do not have lyme
disease lesions. on the other hand, some datasets—such as groh et al."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_36.pdf,"speciﬁcally, a typical lyme lesion exhibits a bull’s eye pattern
with one central redness and one outer circle, which is diﬀerent from darkness
lesion in cancer-related skin disease like melanoma. furthermore, clinical data
collected for training is usually imbalanced in some properties, e.g., more sam-
ples with light skins compared with dark skins. [17], usually suﬀer
from relatively low performance and reduced fairness [2,18,19]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_36.pdf,"our lyme disease dataset contains two parts: (i)
a classiﬁcation dataset, composed of more than 3,000 diseased skin images that
are either obtained from public resources or clinicians with patient-informed con-
sent, and (ii) a segmentation dataset containing 185 samples that are manually
annotated for three regions—i.e., background, skin (light vs. dark), and lesion—
conducted under clinician supervision and institutional review boards (irb)
approval. secondly, we design a simple yet novel data preprocessing and alternation
method, called edgemixup, to improve lyme disease segmentation and diagno-
sis fairness on samples with diﬀerent skin-tones. the key insight is to alter a skin
image with a linear combination of the source image and a detected lesion bound-
ary so that the lesion structure is preserved while minimizing skin tone informa-
tion."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_36.pdf,"then, the detected,
376
h. yuan et al.
fig. a motivating example to illustrate why edgemixup improves model perfor-
mance and reduces biases via mixing up lesion boundary with original image (heatmap
is generated via grad-cam). (color ﬁgure online)
converged edge in the ﬁrst step also helps classiﬁcation of lyme diseases via mixup
with improved fairness."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_36.pdf,"we evaluate edgemixup for skin disease segmentation and classiﬁcation
tasks. our results show that edgemixup is able to increase segmentation utility
and improve fairness. [22].
2
motivation
in this section, we motivate the design of edgemixup by showing that added
lesion boundary helps a dl model focus more on the lesion part instead of other
features such as skin or background."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_36.pdf,"1b and 1c. the reason is that a legacy
diagnosis has no information about lesion and does not know where to locate its
focus, thus easily gets distracted by ﬁngers instead of the lesion pattern.
3
method
in this section, we ﬁrst give the deﬁnition for model fairness, and we then
describe the design of edgemixup for the purpose of de-biasing in fig. 2 and
edgemixup
377
fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_36.pdf,"we consider any model f, either a classiﬁcation model fclass or
a segmentation model fseg, to be biased against certain skin-tone st2 if given
metrics m and samples xst1 and xst2 from class y, where st1 and st2 are diﬀer-
ent skin-tones according to their ita scores, m(f(xst1), y) > m(f(xst2), y). if
there exists a model f such that m(f(xst1), y) = m(f(xst2, y)), we consider it
perfectly fair for st1 and st2 skin-tone samples. edgemixup improves model fairness on light and dark skin samples in both
segmentation and classiﬁcation tasks, and it has two major components: (i) edge
detection using mixup, and (ii) data preprocessing and alteration for downstream
tasks."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_36.pdf,"lastly, edgemixup selects an
edge candidate with the highest conﬁdence score output by the learning model
(line 11) and returns it as the edge for this given sample. note that the initial
edge detection is irrelevant to the sample size of a particular subpopulation, thus
improving the fairness. that is, even if the original dataset is imbalanced, as long
as one sample from a subpopulation exists, the color range of the sample’s lesion
is considered in the initial detection."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_36.pdf,"we follow the default setting from
each paper for evaluation. our evaluation metrics include (i) jaccard index (iou
score), which measures the similarity between a predicted mask and the manu-
ally annotated ground truth, and (ii) the gap between jaccard values (jgap) to
measure fairness.
table 2 shows the performance and fairness of edgemixup and diﬀerent
baselines. we compare predicted masks with the manually-annotated ground
truth by calculating the jaccard index, and computing the gap for subpopula-
tions with ls and ds (based on ita)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_36.pdf,"our evaluation metrics include accuracy gap, the (rawlsian) minimum accuracy
across subpopulations, area under the receiver operating characteristic curve
(auc), and joint metrics (caiα and cauciα). table 3 shows utility performance (acc and auc) and fairness results (gaps
of acc and auc between ls and ds subpopulations). we here list two variants
of edgemixup, and one of which, “unet”, uses the lesion edge generated by
edgemixup
381
table 3."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_36.pdf,"samples contain skin tones as
a protected factor. 3. by adding the “unet” variant, we
demonstrate here that simply applying lesion edge predicetd by the baseline unet
model, while not optimal, eﬃciently reduces model bias on diﬀerent skin-tone
samples. [27] and skin lesion [28]
classiﬁcation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_36.pdf,"[11] to encourage researches studying lesion seg-
mentation, feature detection, and image classiﬁcation. [10] only contains melanoma samples and all of the
samples are with light skins according to our inspection using ita scores.
382
h. yuan et al.
bias mitigation: researchers have addressed bias and heterogeneity in deep
learning models [18,29]. second,
adversarial debiasing operates on the principle of simultaneously training two
networks with diﬀerent objectives [31]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_36.pdf,"7
conclusion
we present a simple yet novel approach to segment lyme disease lesion, which
can be further used for disease classiﬁcation. the key insight is a novel data pre-
processing method that utilizes edge detection and mixup to isolate and highlight
skin lesions and reduce bias. edgemixup outperforms sotas in terms of jac-
cord index for segmentation and caiα and cauciα for disease classiﬁcation.
acknowledgement."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_38.pdf,"2
method
2.1
risk prediction
survival analysis is done to predict whether events will occur sometime in the
future. for medical applications, x typically
represents patient information like age, family history, genetic makeup, and diag-
nostic test results (e.g., a mammogram). if the event has not yet occurred by the
end of the study or observation period, the data is referred to as right-censored
(fig. 1)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_32.pdf,"eoformer: edge-oriented transformer
for brain tumor segmentation
dong she1,2, yueyi zhang1,2(b), zheyu zhang1, hebei li1, zihan yan3,
and xiaoyan sun1,2(b)
1 university of science and technology of china, hefei 230026, china
{zhyuey,sunxiaoyan}@ustc.edu.cn
2 hefei comprehensive national science center, institute of artiﬁcial intelligence,
hefei 230088, china
3 beijing tiantan hospital, capital medical university, beijing 100050, china
abstract. accurate segmentation of brain tumors in mri images
requires precise detection of the edges."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_32.pdf,"our approach combines the strengths of cnn and trans-
former to create a more powerful encoder that can extract both local and global
information from input data. we address the computational and memory complexity issues that arise from
3d input by replacing the vanilla attention with our extended 3d eﬃcient atten-
tion. assuming the size of the input feature is n and the dimensionality is d, the
input feature x ∈ rn×d pass through three linear layers to generate the queries
q ∈ rn×dk, keys k ∈ rn×dk and values v ∈ rn×dv."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_32.pdf,"our method comprises the eﬃcient hybrid encoder and the edge-
oriented transformer decoder. the encoder eﬀectively extracts features from
images by striking a balance between cnn and transformer architectures. the
decoder integrates the sobel and laplacian edge detection ﬁlters into our edge-
oriented modules that enhance the extraction capability of edge and texture
information."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_56.pdf,"here, we demonstrate the ﬁrst label-free flim-based classiﬁcation using a
novelty detection model to identify residual cancer in the surgical cavity of the
oropharynx. due to highly imbalanced label representation in the surgical cav-
ity, the model employed solely flim data from healthy surgical cavity tissue for
training and classiﬁed the residual tumors as an anomaly. flim data from n = 22
patients undergoing upper aerodigestive oncologic surgery were used to train and
validate the classiﬁcation model using leave-one-patient-out cross-validation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_56.pdf,"[13].
however, ability of label-free flim to identify residual tumors in vivo in the surgical
cavity (deep margins) has not been reported. one signiﬁcant challenge in developing
a flim-based classiﬁer to detect tumor in the surgical cavity is the presence of highly
imbalanced labels. surgeons aim to perform an en bloc resection, removing the entire tumor and a
margin of healthy tissue around it to ensure complete excision."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_56.pdf,"therefore, in most cases,
only healthy tissue in left in the cavity. to address the technical challenge of highly
imbalanced label distribution and the need for intraoperative real-time cavity imaging,
we developed an intraoperative flim guidance model to identify residual tumors by
classifying residual cancer as anomalies. our proposed approach identiﬁed all patients
with psm."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_56.pdf,"η − max

w t
2 xi + b2
2
∔
(1)
where w1, w2 are the orthonormal frames,
min
w∈sk
d ,b
is the stiefel manifold, η is the
sensitivity margin, and was set η = 0.4 for our experiments. ν denote a penalty factor on
these soft constraints, and b is the biases. xi denotes the training set containing cdt of
the concatenated flim decay curve across channels 1–3 along the time axis."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_15.pdf,"factor space and spectrum for medical
hyperspectral image segmentation
boxiang yun1, qingli li1, lubov mitrofanova2, chunhua zhou3,
and yan wang1(b)
1 shanghai key laboratory of multidimensional information processing, east china
normal university, shanghai, china
52265904012@stu.ecnu.edu.cn, qlli@cs.ecnu.edu.cn, ywang@cee.ecnu.edu.cn
2 almazov national medical research centre, st. petersburg, russia
3 rui jin hospital, school of medicine, shanghai jiao tong university, shanghai,
china
abstract. medical hyperspectral imaging (mhsi) brings opportuni-
ties for computational pathology and precision medicine."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_15.pdf,"one sample contains highly correlated spectral bands, so
that the spatial stream can focus on spatial feature extraction. for the spectral
stream, to deal with problems of spatiospectral redundancy and the ineﬃciency
of global spectral feature representation, we propose a novel and concise hier-
archical structure shown in fig. 2. we employ a basic transformer paradigm
[21] but design it tailored for capturing global low-rank spectral features."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_15.pdf,"we introduce depth-wise conv (dwconv) for
dynamically integrating redundant spatial information into spectral features to
reduce spatial redundant noises, achieved by setting diﬀerent strides of the con-
volutional kernel. then, we represent long-distance dependencies among spectral
inter-bands as a low-rank completion problem. smd(·) indicates the spectral
matrix decomposition operation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_15.pdf,"where ⊗ denote kronecker product, aci ∈ rc′×1×1,
ahi ∈ rc′×1×1, awi ∈ rc′×1×1, r is the tensor rank and λi is a scaling factor. recent research [3,32] has proposed new methods based on dnns to address this
problem of representing mhsis as low-rank tensors. as shown in fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_37.pdf,"fine-tuning network in federated
learning for personalized skin diagnosis
kyungsu lee1, haeyun lee2, thiago coutinho cavalcanti1, sewoong kim1,
georges el fakhri3, dong hun lee4, jonghye woo3, and jae youn hwang1(b)
1 department of electrical engineering and computer science, daegu gyeongbuk
institute of science and technology, daegu 42988, south korea
{ks_lee,jyhwang}@dgist.ac.kr
2 production engineering research team, samsung sdi, yongin 17084, south korea
3 gordon center for medical imaging, department of radiology, massachusetts
general hospital and harvard medical school, boston, ma 02114, usa
4 department of dermatology, seoul national university college of medicine,
institute of human-environment interface biology, seoul national university, seoul
03080, south korea
abstract. federated learning (fl) has emerged as a promising tech-
nique in the ﬁeld of medical diagnosis."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_37.pdf,"by distributing the same task
through deep networks on mobile devices, fl has proven eﬀective in
diagnosing dermatitis, a common and easily recognizable skin disease. however, in skin disease diagnosis, fl poses challenges related to (1)
prioritizing generalization over personalization and (2) limited utiliza-
tion of mobile devices. despite its improved comprehensive diagnostic
performance, skin disease diagnosis should aim for personalized diag-
nosis rather than centralized and generalized diagnosis, due to personal
diversities and variability, such as skin color, wrinkles, and aging."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_37.pdf,"let crossover(p (i), p (j)) be a crossover function by jointly using
two chromosomes, and then the kth genes of p (i)|k and p (j)|k are changed in the
50% probability when the constraint of |p (i)|k − p (j)|k| ≤ lk is satisﬁed. here,
since the convolution parameters in a deep depth are rarely ﬁne-tuned due to a
gradient vanishing problem, lk exhibits a relatively larger value when k becomes
larger. in addition, since we experimentally demonstrated that lk ≥ 0.15 provides
a much longer time to ﬁne-tune apd-net, we constrained lk ≤ 0.15, and the
ﬁxed values of lk are randomly determined for each experiment."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_37.pdf,"to evaluate the performance and feasibility of apd-net, we used
three public datasets, including 7pt, isic, and ham, and detailed descriptions
for datasets are illustrated in table 1. furthermore, in this work, we collected
skin images through the tertiary referral hospital under the approval of the
institutional review board (irb no. 1908-161-1059) and obtained images with
the consent of the subjects according to the principles of the declaration of
helsinki from 51 patients and subjects. the dataset included four categories,
384
k. lee et al.
fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_66.pdf,"intra-operative ultrasound (ius) has been adopted
to provide real-time images to track brain shift, and inter-modal (i.e.,
mri-ius) registration is often required to update the pre-surgical plan. quality control for the registration results during surgery is important
to avoid adverse outcomes, but manual veriﬁcation faces great challenges
due to diﬃcult 3d visualization and the low contrast of ius. automatic
algorithms are urgently needed to address this issue, but the problem was
rarely attempted."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_66.pdf,"in this test, patches can contain large areas of zeros (image con-
tent out of the scanning fov of the ius). the main reason for the observed
performance decline is due to the reduction in suﬃcient image features in ius.
however, despite these challenges, we saw an acceptable outcome from focaler-
rornet (absolute error = 1.28 mm or ∼1 voxel in clinical mris). 696
s. salari et al.
4
discussion
in image-guided interventions, there is an urgent need for automatic assessment
of image registration quality."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_66.pdf,"finally, compared with classiﬁcation,
regression tasks tend to be more error-prone for deep learning algorithms. to
tackle these challenges, we employed 3d focal modulation with depth-wise con-
volution to encode contextual information for the image pair. compared with the
vit and its variants, focal modulation allows a more lightweight setup, which
could be desirable for 3d data."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_57.pdf,"here we propose a novel focal transformer-based
image segmentation architecture to eﬀectively and eﬃciently extract local
visual features and global context from ct images. additionally, we design
an auxiliary boundary-induced label regression task coupled with the main
prostate segmentation task to address the unclear boundary issue in ct
images. we demonstrate that this design signiﬁcantly improves the quality
of the ct-based prostate segmentation task over other competing meth-
ods, resulting in substantially improved performance, i.e., higher dice sim-
ilarity coeﬃcient, lower hausdorﬀ distance, and average symmetric sur-
face distance, on both private and public ct image datasets."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_57.pdf,"https://doi.org/10.1007/978-3-031-43898-1_57
focalunetr
593
can be time-consuming and may result in signiﬁcant variations between operators
[10]. despite good progress,
these methods often have limitations in capturing long-range relationships and
global context information [2] due to the inherent bias of convolutional opera-
tions. [2] adapts vit to medical image segmentation
tasks by connecting several layers of the transformer module (multi-head sa)
to the fcn-based encoder for better capturing the global context information
from the high-level feature maps."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_57.pdf,"this serves as a regularization term for the main
task of generating the segmentation mask. and the auxiliary task enhances the
model’s generalizability by addressing the challenge of unclear boundaries in
low-contrast ct images. the architecture of focalunetr as (a) the main task for prostate segmenta-
tion and (b) a boundary-aware regression auxiliary task."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_57.pdf,"first, we develop a novel
focal transformer model (focalunetr) for ct-based prostate segmentation,
which makes use of focal sa to hierarchically learn the feature maps accounting
for both short- and long-range visual dependencies eﬃciently and eﬀectively. second, we also address the challenge of unclear boundaries speciﬁc to ct images
by incorporating an auxiliary task of contour regression. third, our methodology
advances state-of-the-art performance via extensive experiments on both real-
world and benchmark datasets."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_57.pdf,"for the queries inside the i-th window qi ∈ rd×sw×sw, we extract the sl
r × sl
r
keys and values from kl and v l around the window where the query lies in and
then gather the keys and values from all l to obtain ki = {k1, . . finally, a relative position
bias is added to compute the focal sa for qi by
attention(qi, ki, vi) = softmax(qikt
i
√
d
+ b)vi,
where b = {bl}l
1 is the learnable relative position bias [24]. the encoder utilizes a patch size of 2×2 with a feature dimension of 2×2×1 =
4 (i.e., a single input channel ct) and a d-dimensional embedding space."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_57.pdf,"the objective function
for the segmentation head is given by: lseg = ldice(ˆpi, g) + lce(ˆpi, g), where ˆpi
represents the predicted probabilities from the main task and g represents the
ground truth mask, both given an input image i. the predicted probabilities,
ˆpi, are derived from the main task through the application of the focalunetr
model to the input ct image. to address the challenge of unclear boundaries in ct-based prostate segmen-
tation, an auxiliary task is introduced for the purpose of predicting boundary-
aware contours to assist the main prostate segmentation task. this auxiliary
task is achieved by attaching another convolution head after the extracted fea-
ture maps at the ﬁnal stage (see fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_57.pdf,"the
resulting contour is a heatmap in the form of a heatsum function [11]. we pre-
dict this heatmap with a regression task trained by minimizing mean-squared
error instead of treating it as a single-pixel boundary segmentation problem. given the ground truth of contour gc
i , induced from the segmentation mask
for input image i, and the reconstructed output probability ˆpc
i , we use the fol-
lowing loss function: lreg =
1
n

i ||ˆpc
i − gc
i ||2 where n is the total number of
images for each batch."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_57.pdf,"sequently, the models may struggle to provide accurate predictions for this spe-
ciﬁc portion of the uterus. thus, the overall performance of focalunetr is
overshadowed by this challenge, resulting in only moderate improvement over
the baselines on the amos dataset. however, the performance margin signiﬁ-
cantly improves when using the real-world (private) dataset."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_57.pdf,"thus, it can be inferred that the optimal setting
for these parameters is when both λ1 and λ2 are set to 0.5.
4
conclusion
in summary, the proposed focalunetr architecture has demonstrated the abil-
ity to eﬀectively capture local visual features and global contexts in ct images
by utilizing the focal self-attention mechanism. the auxiliary contour regres-
sion task has also been shown to improve the segmentation performance for
unclear boundary issues in low-contrast ct images. extensive experiments on
two large ct datasets have shown that the focalunetr outperforms state-of-
the-art methods for the prostate segmentation task."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_10.pdf,"second, we pre-train our
transformer model using global and local views via a self-supervised
manner, aiming to make it robust to spatial-temporal variations and
discriminative across diﬀerent scenes. to develop the foundation model,
we construct a large-scale endoscopy video dataset by combining 9 pub-
licly available datasets and a privately collected dataset from baoshan
branch of renji hospital in shanghai, china. our dataset overall consists
of over 33k video clips with up to 5 million frames, encompassing var-
ious protocols, target organs, and disease types."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_10.pdf,"we build a video transformer model and
design a self-supervised pre-training approach. combining 9 public and a new private collected dataset from baoshan branch of
renji hospital in shanghai, china, with over 33k video clips with up to 5 million
frames. our pre-trained endo-fm can be easily applied to various downstream
tasks by serving as the backbone."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_10.pdf,"by
adopting this strategy, our model learns high-level context information from two
perspectives: 1) spatial context in terms of the possible neighboring tissue and
lesions within a local spatial crop, and 2) temporal context in terms of the possi-
ble presence of lesions in the previous or future frames of a local temporal crop. thus, our method eﬀectively addresses the proportion and existence issues that
may be encountered. we minimize the following loss for cross-view matching:
lcv =
g

i=1
l

j=1
−pt
v ig · log ps
v j
l ."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_10.pdf,"(2)
dynamic motion matching. in addition to the proportion and existence
issues of lesions, a further challenge arises from the inherent dynamic nature
of the scenes captured in endoscopy videos. the speeds and ranges of motion
can vary greatly across diﬀerent videos, making it diﬃcult to train a model
that is eﬀective across a wide range of dynamic scenarios."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_10.pdf,"the previous model
[27] learned from clips with ﬁxed frame rate can not tackle this issue, as clips
sampled with various frame rates contain diﬀerent motion context information
(e.g., fast v.s. slow scene changing) and diﬀer in nuanced tissue and lesions. to address this challenge, our approach involves motion modeling during pre-
training under dynamic endoscope scenes by predicting a target global view (pt
v ig)
processed by the teacher from another online global view (ps
v kg) processed by the
student. moreover, by predicting the nuanced diﬀerences of tissue and lesions in
a view with a high frame rate from another with a low frame rate, the model is
encouraged to learn more comprehensive motion-related contextual information."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_10.pdf,"centering
and sharpening schemes [6] are incorporated to the teacher outputs. to prevent
the problem of the teacher and student models constantly outputting the same
value during pre-training, we update the student model θ through backpropaga-
tion, while the teacher model φ is updated through exponential moving average
(ema) using the student’s weights. this is achieved by updating the teacher’s
weights as φt ← αφt−1 + (1 − α)θt at each training iteration t. here, α is a
momentum hyper-parameter that determines the updating rate."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_10.pdf,"the training batch size
is 12 with adamw [17] optimizer (learning rate 2e−5, weight decay 4e−2). the
pre-training is ﬁnished with 30 epochs with a cosine schedule [16].
3
experiment
3.1
datasets and downstream setup
we collect all possible public endoscope video datasets and a new one from
baoshan branch of renji hospital for pre-training. as shown in table 1, these
public datasets are provided by world-wide research groups [5,13,18,19,30] and
previous endovis challenge [23], covering 3 endoscopy protocols and 10+ types
of diseases."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_10.pdf,"we also train our model from scratch to serve as a baseline. the same
experimental setup is applied to all the experiments for fair comparisons. quantitative comparison results are shown in table 2."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_24.pdf,"however, exist-
ing methods usually produce over-smoothed images with loss of details
due to i) the diﬃculty in accurately modeling the artifact patterns in
the image domain, and ii) the equal treatment of each pixel in the loss
function. to address these issues, we concentrate on the image post-
processing and propose a simple yet eﬀective frequency-band-aware
and self-guided network, termed freeseed, which can eﬀectively remove
artifacts and recover missing details from the contaminated sparse-view
ct images. speciﬁcally, we ﬁrst propose a frequency-band-aware arti-
fact modeling network (freenet), which learns artifact-related frequency-
band attention in the fourier domain for better modeling the globally
distributed streak artifact on the sparse-view ct images."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_24.pdf,"https://doi.org/10.1007/978-3-031-43999-5_24
frequency-band-aware and self-guided network for sparse-view ct
251
keywords: sparse-view ct · ct reconstruction · fourier convolution
1
introduction
x-ray computed tomography (ct) is an established diagnostic tool in clinical
practice; however, there is growing concern regarding the increased risk of cancer
induction associated with x-ray radiation exposure [14]. lowering the dose of ct
scans has been widely adopted in clinical practice to address this issue, following
the “as low as reasonably achievable” (alara) principle in the medical com-
munity [9]. sparse-view ct is one of the eﬀective solutions, which reduces the
radiation by only sampling part of the projection data for image reconstruction."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_20.pdf,"gall bladder cancer detection from us
images with only image level labels
soumen basu1(b), ashish papanai1, mayank gupta1, pankaj gupta1,2,
and chetan arora1
1 indian institute of technology, delhi, india
soumen.basu@cse.iitd.ac.in
2 postgraduate institute of medical education and research, chandigarh, india
abstract. automated detection of gallbladder cancer (gbc) from
ultrasound (us) images is an important problem, which has drawn
increased interest from researchers. however, most of these works use
diﬃcult-to-acquire information such as bounding box annotations or
additional us videos."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_20.pdf,"we posit that
even when we have only the image level label, still formulating the prob-
lem as object detection (with bounding box output) helps a deep neural
network (dnn) model focus on the relevant region of interest. since no
bounding box annotations is available for training, we pose the problem
as weakly supervised object detection (wsod). motivated by the recent
success of transformer models in object detection, we train one such
model, detr, using multi-instance-learning (mil) with self-supervised
instance selection to suit the wsod task."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_20.pdf,"in recent
years, automated gbc detection from us images has drawn increased interest
[3,5] due to its potential for improving diagnosis and treatment outcomes. many
of these works formulate the problem as an object detection, since training a
image classiﬁcation model for gbc detection seems challenging due to the reasons
outlined in the abstract (also see fig. 1).
fig. 1. (a) low inter-class variability."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_20.pdf,"on the other hand, the image-level
malignancy label is usually available at a low cost, as it can be obtained readily
from the diagnostic report of a patient without additional eﬀort from clinicians. instead of training a classiﬁcation pipeline, we propose to solve an object
detection problem, which involves predicting a bounding box for the malignancy. the motivation is that, running a classiﬁer on a focused attention/ proposal
region in an object detection pipeline would help tackle the low inter-class and
high intra-class variations."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_20.pdf,"at inference, we
use the predicted instance labels to predict the bag labels. our experiments val-
idate the utility of this approach in circumventing the challenges in us images
and detecting gbc accurately from us images using only image-level labels. contributions: the key contributions of this work are:
– we design a novel detr variant based on mil with self-supervised instance
learning towards the weakly supervised disease detection and localization task
in medical images."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_20.pdf,"although mil and self-supervised instance learning has
been used for cnns [24], such a pipeline has not been used for transformer-
based detection models. – we formulate the gbc classiﬁcation problem as a weakly supervised object
detection problem to mitigate the eﬀect of low inter-class and large intra-class
variances, and solve the diﬃcult gbc detection problem on us images without
using the costly and diﬃcult to obtain additional annotation (bounding box)
or video data. – our method provides a strong baseline for weakly supervised gbc detection
and localization in us images, which has not been tackled earlier."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_20.pdf,"current sota models for gbc detection require costly bound-
ing box annotation of the pathological regions, or additional us video data,
which limit their applicability. we proposed to formulate gbc detection as a
weakly supervised object detection/ localization problem using a detr with self-
supervised instance learning in a mil framework. our experiments show that the
approach achieves competitive performance without requiring additional anno-
tation or data."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_49.pdf,"this paper proposes a gene-induced multimodal pre-
training (gimp) framework, which jointly incorporates genomics and
whole slide images (wsis) for classiﬁcation tasks. our work aims at
dealing with the main challenges of multi-modality image-omic classi-
ﬁcation w.r.t. (1) the patient-level feature extraction diﬃculties from
gigapixel wsis and tens of thousands of genes, and (2) eﬀective fusion
considering high-order relevance modeling."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_49.pdf,"[22] via global feature, local feature
or multi-granularity alignment. but, none of these works considers the challenges
in wsis and genes processing. [8], is not aﬀordable for
gigapixel wsis analysis."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_49.pdf,"[·] is the indicator function.
gene-induced triplet learning. the transformer-based backbones in the
classiﬁcation task require the cls token to be able to extract accurate global
information, which is even more important yet diﬃcult in wsis due to the long
sequence challenge. in addition, in order to construct the mini-batch, the sub-
sequences we intercept in the mpm pre-training phase may not be suﬃciently
representative of the image-level characteristics."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_49.pdf,"at last, we measure the performance on the test set. training conﬁgurations
are consistent throughout the ﬁne-tuning process to ensure fair comparisons. all
experiments are conducted on a single nvidia geforce rtx 3090.
3.2
comparison between gimp and other methods
we conduct comparisons between gimp and three competitors under diﬀer-
ent settings."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_21.pdf,"however, the necessity of beam-
forming for ulm remains questionable. our work challenges the conventional
assumption that beamforming is the ideal processing step for ulm and presents
an alternative approach based on geometric reconstruction from time-of-arrival
(toa) information. the discovery of ulm has recently surpassed the diﬀraction-limited spatial
resolution and enabled highly detailed visualization of the vascularity [8]. ulm
borrows concepts from super-resolution ﬂuorescence microscopy techniques to
supplementary information the online version contains supplementary material
available at https://doi.org/10.1007/978-3-031-43999-5_21."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_21.pdf,"this approach provides a ﬁner
distinction between overlapping and clustered spots, improving localization pre-
cision, reliability, and computation eﬃciency. in conclusion, we challenge the
conventional wisdom that beamforming is necessary for ulm and propose a
novel approach that entirely relies on tdoa information for mb localization. our proposed approach demonstrates promising results and indicates a consid-
erable trade-oﬀ between precision, computation, and memory."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_21.pdf,"our proposed geometric inference indicates the best localization
performance represented by an average rmse of around one-tenth of a wave-
length. also, the jaccard index reﬂects an outperforming balance of true positive
table 1. summary of localization results using 15k frames of the pala dataset [11]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_29.pdf,"until recently, the variational autoencoder (vae) and its variants held
the state-of-the-art for the unsupervised approach. however, novel unsupervised
anomaly detectors based on autoregressive transformers coupled with vector-
quantized variational autoencoders (vq-vae) have overcome issues associated
with autoencoder-only methods [21,22]. in [22], the authors explore the advan-
tage of tractably maximizing the likelihood of the normal data to model the
long-range dependencies of the training data."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_29.pdf,"although fully convolutional models can
304
a. patel et al.
ingest images of varying dimensions, we have found that using training data with
varying resolutions resulted in poor auto-encoder reconstructions. [19] as a mechanism to account for some
level of spatial awareness, an approach which has been applied to various tasks
in medical imaging scenarios with ranging levels of success [1,18]. a coordconv layer is a concatenation of channels to the input image refer-
encing a predeﬁned coordinate system."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_29.pdf,"for example, two whole-
body images with large diﬀerences in voxel-size will have coordconv channels
from 0–1 along each axis, thus conveying the notion of spatial resolution to the
network. we found when training the vq-vae model on data with varying reso-
lutions and dimensions that reconstructions showcased unwanted and signiﬁcant
artifacts, while by adding the coordconv channels this issue was not present
(see appendix c for examples). [0, 1] where 0 is the upper leg, and 1 is the neck."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_11.pdf,"this paper describes a graph-based
lesion tracking method for the comprehensive analysis of lesion changes and their pat-
terns at the lesion level. the tasks are formalized as graph-theoretic problems (fig. 1). complex lesion changes include merged lesions, which occurs when at least two lesions
grow and merge into one (possible disease progression), split lesions, which occurs
when a lesion shrinks and cleaves into several parts (possible response to treatment) and
conglomeration of lesions, which occurs when clusters of lesions coalesce."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_11.pdf,"its outputs are the lesion matchings, the labels of the changes in individual lesions, and
the patterns of the lesion changes. the method is a pipeline of four steps: 1) pairwise
deformable registration of each prior scan, organ and lesion segmentations, with the
most recent (current) scan as in [3]; 2) overlap-based lesion matching; 3) construction of
the lesion change graph from the individual lesion segmentations and lesion matches; 4)
detection of changes in individual lesions and patterns of lesion changes from the graph
properties and from analysis of its connected components.
2.1
problem formalization
let s =

s1, . . . , vi
ni

is a set of vertices vi
j corresponding to the lesions associated
with the lesion segmentation masks li =

li
1, li
2, . ."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_61.pdf,"guiding the guidance: a comparative
analysis of user guidance signals
for interactive segmentation
of volumetric images
zdravko marinov1,2(b), rainer stiefelhagen1, and jens kleesiek3,4
1 karlsruhe institute of technology, karlsruhe, germany
{zdravko.marinov,rainer.stiefelhagen}@kit.edu
2 hidss4health - helmholtz information and data science school for health,
karlsruhe, heidelberg, germany
3 institute for ai in medicine, university hospital essen, essen, germany
jens.kleesiek@uk-essen.de
4 cancer research center cologne essen (ccce), university medicine essen, essen,
germany
abstract. interactive segmentation reduces the annotation time of
medical images and allows annotators to iteratively reﬁne labels with
corrective interactions, such as clicks."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_61.pdf,"this is challenging when working with volumetric medical data
as voxelwise labeling requires a lot of time and expertise. interactive segmen-
tation models address this issue by utilizing weak labels, such as clicks, instead
of voxelwise annotations [5–7]. the clicks are transformed into guidance sig-
nals, e.g., gaussian heatmaps or euclidean/geodesic distance maps, and used
together with the image as a joint input for the interactive model."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_61.pdf,"there is
also no systematic framework for comparing guidance signals, which includes not
only accuracy but also eﬃciency and the ability to iteratively improve predic-
tions with new clicks, which are all important aspects of interactive models [7]. we address these challenges with the following contributions:
1. [2] datasets and vary various hyperparameters."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_66.pdf,"h-denseformer: an eﬃcient hybrid
densely connected transformer for
multimodal tumor segmentation
jun shi1, hongyu kan1, shulan ruan1, ziqi zhu1, minfan zhao1, liang qiao1,
zhaohui wang1, hong an1(b), and xudong xue2
1 university of science and technology of china, hefei, china
shijun18@mail.ustc.edu.cn, han@ustc.edu.cn
2 hubei cancer hospital, tongji medical college, huazhong university of science
and technology, wuhan, china
abstract. recently, deep learning methods have been widely used
for tumor segmentation of multimodal medical images with promising
results."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_66.pdf,"[33], which combine the transformer
with the multimodal feature fusion approaches mentioned above, further demon-
strate the potential of this idea for multimodal tumor segmentation. 694
j. shi et al.
although remarkable performance has been accomplished with these eﬀorts,
there still exist several challenges to be resolved. most existing methods are
either limited to speciﬁc modality numbers due to the design of asymmetric
connections or suﬀer from large computational complexity because of the huge
amount of model parameters."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_66.pdf,"shortening the feature length can eﬀectively reduce
computation, but it also weakens the representation capability meanwhile. [17] to balance computational cost and repre-
sentation capability. figure 1 details the dct module, which consists of four
transformer layers and a feedforward layer."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_66.pdf,"we
also conduct holistic t-tests of the overall performance for our method and all
baseline models with the two-tailed p < 0.05.
3.2
implementation details
we use pytorch to implement our proposed method and the baselines. for a
fair comparison, all models are trained from scratch using two nvidia a100
gpus and all comparison methods are implemented with open-source codes,
following their original conﬁgurations. in particular, we evaluate the 3d and
2d h-denseformer on hecktor21 and pi-cai22, respectively."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_66.pdf,"we also use an early stopping
strategy with a tolerance of 30 epochs to ﬁnd the best model within 100 epochs. online data augmentation, including random rotation and ﬂipping, is performed
to alleviate the overﬁtting problem. 1 https://pi-cai.grand-challenge.org/.
698
j. shi et al.
3.3
overall performance
table 2. comparison with existing methods on independent test set."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_66.pdf,"for pi-cai22, the 2d
variant of h-denseformer also outperforms existing methods (p < 0.05), achiev-
ing a dsc of 49.9%, hd95 of 35.9 mm, and ji of 37.1%. overall, h-denseformer
reaches an eﬀective balance of performance and computational cost compared to
existing cnns and hybrid structures. for qualitative analysis, we show a visual
comparison of the diﬀerent methods."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_66.pdf,"4
conclusion
in this paper, we proposed an eﬃcient hybrid model (h-denseformer) that com-
bines transformer and cnn for multimodal tumor segmentation. concretely, a
multi-path parallel embedding module and a densely connected transformer
block were developed and integrated to balance accuracy and computational
complexity. extensive experimental results demonstrated the eﬀectiveness and
superiority of our proposed h-denseformer."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_53.pdf,"henet: hierarchical enhancement
network for pulmonary vessel
segmentation in non-contrast ct images
wenqi zhou1,2, xiao zhang1,3, dongdong gu2, sheng wang1,2, jiayu huo5,
rui zhang4, zhihao jiang1, feng shi2, zhong xue2, yiqiang zhan2,
xi ouyang2(b), and dinggang shen1,2(b)
1 shanghaitech university, shanghai, china
dgshen@shanghaitech.edu.cn
2 shanghai united imaging intelligence co., ltd., shanghai, china
xi.ouyang@uii-ai.com
3 school of information science and technology, northwest university, xi’an, china
4 department of pulmonary and critical care medicine, west china hospital,
sichuan university, chengdu, china
5 school of biomedical engineering and imaging sciences (bmeis),
king’s college london, london, uk
abstract. pulmonary vessel segmentation in computerized tomogra-
phy (ct) images is essential for pulmonary vascular disease and surgical
navigation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_53.pdf,"however, the existing methods were generally designed for
contrast-enhanced images, their performance is limited by the low con-
trast and the non-uniformity of hounsﬁeld unit (hu) in non-contrast
ct images, meanwhile, the varying size of the vessel structures are
not well considered in current pulmonary vessel segmentation meth-
ods. to address this issue, we propose a hierarchical enhancement net-
work (henet) for better image- and feature-level vascular representa-
tion learning in the pulmonary vessel segmentation task. speciﬁcally, we
ﬁrst design an auto contrast enhancement (ace) module to adjust
the vessel contrast dynamically."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_53.pdf,"[1] also proposed an orthogonal
fused u-net++ for pulmonary peripheral vessel segmentation. however, all these
methods ignored the signiﬁcant variability in hu values of pulmonary vessels at
diﬀerent regions.
to summarize, there exist several challenges for pulmonary vessel segmen-
tation in non-contrast ct images: (1) the contrast between pulmonary vessels
and background voxels is extremely low (fig. 1(c)); (2) pulmonary vessels have
a complex structure and signiﬁcant variability in vessel appearance, with diﬀer-
ent scales in diﬀerent areas. the central extrapulmonary vessels near the heart
have a large irregular ball-like shape, while the shape of the intrapulmonary
vessels is delicate and tubular-like (fig. 1(a) and (b))."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_53.pdf,"thus, we set diﬀerent ranges of hu values to better visualize the vessels
in fig. 1(d) and (e). to address the above challenges, we propose a h ierarchical enhancement
n etwork (henet) for pulmonary vessel segmentation in non-contrast ct images
by enhancing the representation of vessels at both image- and feature-level. for
the input ct images, we propose an auto contrast enhancement (ace) module
to automatically adjust the range of hu values in diﬀerent areas of ct images."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_53.pdf,"it mimics the radiologist in setting the window level (wl) and window width
hierarchical enhancement network
553
fig. the challenges of accurate pulmonary vessel segmentation. (a–b) the central
extrapulmonary vessels (pointed by blue arrows) are large compared to tubular-like
intrapulmonary vessels (pointed by green arrows), which become thinner as they get
closer to the peripheral lung."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_53.pdf,"the annotations of pulmonary
vessels are semi-automatically segmented in 3d by two radiologists using the
3d slicer software. this study is approved by the ethical committee of west
china hospital of sichuan university, china. these cases are randomly split
into a training set (120 scans) and a testing set (40 scans)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_53.pdf,"in the testing phase, we perform the sliding window average prediction with
strides of (64, 64, 32) to cover the entire ct images. for a fair comparison,
we use the same hyper-parameter settings and dice similarity coeﬃcient loss
across all experiments. in particular, we use the same data augmentation, no
post-processing scheme, adam optimizer with an initial learning rate of 10−4,
and train for 800 epochs with a batch size of 4."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_73.pdf,"unlike natural images,
wsis typically contain billions of pixels and also have a pyramid structure, as
shown in fig. such gigapixel resolution and expensive pixel-wise annotation
eﬀorts pose unique challenges to constructing eﬀective and accurate models for
wsi analysis. to overcome these challenges, multiple instance learning (mil)
has become a popular paradigm for wsi analysis."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_66.pdf,"gong et al. [4]
employed the geodesic distance computed using the dijkstra algorithm on the k-
nearest neighbor graph to measure the correlation between the original samples
deep manifold contrastive learning
685
and then further divided each class into sub-classes to deal with the problems of
high spectral dimension and channel redundancy in the hyperspectral images. however, this method captured the nonlinear data manifold structure on the
original data (not on the feature vectors) only once at the beginning stage,
which is not updated in the further training process."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_66.pdf,"jeong
3
result
3.1
datasets
we tested our proposed method on two diﬀerent tasks: (1) intrahepatic cholan-
giocarcinomas(ihccs) subtype classiﬁcation and (2) liver cancer type classiﬁca-
tion. the dataset for the former task was collected from 168 patients with 332
wsis from seoul national university hospital. ihccs can be further categorized
into small duct type (sdt) and large duct type (ldt)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_66.pdf,"in the deep manifold
embedding learning model, the learning rates were set to 1e-4 with a decay rate
of 1e-6 for the ihccs subtype classiﬁcation and to 1e-5 with a decay rate of
1e-8 for the liver cancer type classiﬁcation. the k-nearest neighbors graph and
the geodesic distance matrix are updated once every ﬁve training epochs, which
is empirically chosen to balance running time and accuracy. to train the mil
classiﬁer, we set the learning rate to 1e-3 and the decay rate to 1e-6."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_66.pdf,"one limitation of
the proposed method is the extra computation time for graph generation and
pairwise distance computation using the dijkstra algorithm. in the future, we
plan to optimize the algorithm and apply our method to other datasets and
tasks, such as multi-class classiﬁcation problems and natural image datasets.
acknowledgements. this study was approved by the institutional review board
of
seoul
national
university
hospital
(irb
no.h-1011-046-339)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_54.pdf,"digital pathology plays a pivotal role in the diagnosis and
interpretation of diseases and has drawn increasing attention in mod-
ern healthcare. due to the huge gigapixel-level size and diverse nature
of whole-slide images (wsis), analyzing them through multiple instance
learning (mil) has become a widely-used scheme, which, however, faces
the challenges that come with the weakly supervised nature of mil. con-
ventional mil methods mostly either utilized instance-level or bag-level
supervision to learn informative representations from wsis for down-
stream tasks. in this work, we propose a novel mil method for patholog-
ical image analysis with integrated instance-level and bag-level supervi-
sion (termed iib-mil)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_54.pdf,"as the demand for intelligently pathological image analysis continues to grow,
an increasing number of researchers have paid attention to this ﬁeld [12,14,
25]. [1] is usually applied to formulate pathological image
analysis tasks into weakly supervised learning problems. in the mil setting, the
entire wsi is regarded as a bag and tiled patches are instances."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_54.pdf,"[2,8,24], on the other hand,
focuses its learning process at the instance level, and then obtains the bag-level
prediction by simply aggregating instance predictions. bag-level mil incorpo-
rates instance embeddings to create a bag representation, converting the mil
into a supervised learning problem. furthermore, it can extract contextual infor-
mation and correlations between instances."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_54.pdf,"nonetheless, bag-level mil needs to
learn informative embeddings of instances and adjust the contributions of these
instance embeddings to generate the bag representation simultaneously, which
faces the risk of obtaining a suboptimal model given the limited training samples
in practice. the instance-level mil, however, faces the problem of noisy labels,
which is caused by the common strategy of assigning the wsi labels to patches
and the fact that there are lots of patches irrelevant to the wsi labels [3,6].
considering these conventional mil methods usually utilize either bag-level
or instance-level supervision, leading to suboptimal performance. then we propose to combine bag-level and instance-level supervision
to improve the performance of mil."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_54.pdf,"after that, iib-mil utilizes both
a transformer-based bag-level and a label-disambiguation-based instance-level
supervision to cooperatively optimize the model, where the bag-level loss is cal-
culated referring to the wsi labels, while the instance loss is calculated referring
to pseudo patch labels calibrated by the label-disambiguation module. since
bag-level supervision channel is trained to globally summarise information of all
patches for prediction, the bag-level outputs are used as the ﬁnal predictions
during the test stage.
2.2
problem formulation
assume there is a set of n wsis denoted by s = {s1, s2, ..., sn}. each wsi si
has a wsi-level label yi ∈ {1, ..., c}, where c represents category number."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_47.pdf,"imitation learning from expert video
data for dissection trajectory prediction
in endoscopic surgical procedure
jianan li1, yueming jin2, yueyao chen1, hon-chi yip3, markus scheppach4,
philip wai-yan chiu5, yeung yam6, helen mei-ling meng7, and qi dou1(b)
1 department of computer science and engineering,
the chinese university of hong kong, hong kong, china
qidou@cuhk.edu.hk
2 department of biomedical engineering and department of electrical and
computer engineering, national university of singapore, singapore, singapore
3 department of surgery, the chinese university of hong kong, hong kong, china
4 internal medicine iii - gastroenterology,
university hospital of augsburg, augsburg, germany
5 multi-scale medical robotics center and the chinese university of hong kong,
hong kong, china
6 department of mechanical and automation engineering,
the chinese university of hong kong, hong kong, china
7 centre for perceptual and interactive intelligence and the chinese university of
hong kong, hong kong, china
abstract. high-level cognitive assistance, such as predicting dissection
trajectories in endoscopic submucosal dissection (esd), can potentially
support and facilitate surgical skills training."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_47.pdf,"however, it has rarely been
explored in existing studies. imitation learning has shown its eﬃcacy in
learning skills from expert demonstrations, but it faces challenges in pre-
dicting uncertain future movements and generalizing to various surgical
scenes. in this paper, we introduce imitation learning to the formulated
task of learning how to suggest dissection trajectories from expert video
demonstrations."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_47.pdf,"imitation learning has been widely studied in various domains [11,16,18]
with its good ability to learn complex skills, but it still needs adaptation and
improvement when being applied to learn dissection trajectory from surgical
data. one challenge arises from the inherent uncertainty of future trajectories. supervised learning such as behavior cloning (bc) [3] tends to average all pos-
sible prediction paths, which leads to inaccurate predictions."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_47.pdf,"finally, we show the action inference strategy with
forward-diﬀusion guidance which produces accurate trajectory predictions with
our implicit diﬀusion policy. 2.1
implicit modeling for surgical dissection decision-making
in our approach, we formulate the dissection trajectory prediction to an imitation
learning from expert demonstrations problem, which deﬁnes a markov decision
process (mdp) m = (s, a, t , d), comprising of state space s, action set a,
state transition distribution t , and expert demonstrations d. the goal is to
learn a prediction policy π∗(a|s) from a set of expert demonstrations d. the
input state of the policy is a clip of video frames s = {it−l+1, it−l+2, . . , it},
it ∈ rh×w ×3 and the output is an action distribution of a sequence of 2d
coordinates a = {yt+1, yt+2, ..., yt+n}, yt ∈ r2 indicating the future dissection
trajectory projected to the image space."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_47.pdf,"the optimal action is derived from the policy distribution conditioned on the
state s, and pθ(s, a) represents the joint state-action distribution. = max
θ
e(s,a)∼d[log pθ(s, a)].
(1)
in this regard, the imitation of surgical dissection decision-making is converted
to a distribution approximation problem. 2.2
training implicit policy as diﬀusion models
approximating the joint state-action distribution in eq. 1 from the video demon-
stration data is challenging for previous ebm-based methods."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_47.pdf,"the trainable reverse transition is a gaussian distribution as well,
whose posterior is pθ(xt−1|xt) = n

xt−1; μθ(xt, t), σθ(xt, t)

, in which μθ(xt, t)
and σθ(xt, t) are the means and the variances parameterized by a neural network.
to train the implicit diﬀusion policy, we maximize the log-likelihood of the
state-action distribution in eq. 1. using the evidence lower bound (elbo) as
the proxy, the likelihood maximization can be simpliﬁed to a noise prediction
problem, more details can be referred to [10]. ϵa∥ + γ∥ϵs
θ(xt, t) − ϵs∥],
(3)
where ϵs and ϵa are sampled from n(0, i s), n(0, i a) respectively."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_47.pdf,"3
experiments
3.1
experimental dataset and evaluation metrics
dataset. we evaluated the proposed approach on a dataset assembled from 22
videos of esd surgery cases, which are collected from the endoscopy centre of
the prince of wales hospital in hong kong. all videos were recorded via olym-
pus microscopes operated by an expert surgeon with over 15 years of experience
in esd."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_24.pdf,"improved prognostic prediction
of pancreatic cancer using multi-phase
ct by integrating neural distance
and texture-aware transformer
hexin dong1,2,3, jiawen yao1,3(b), yuxing tang1, mingze yuan1,2,3,
yingda xia1, jian zhou4,5, hong lu6, jingren zhou1,3, bin dong2,7, le lu1,
zaiyi liu8, li zhang2(b), yu shi9(b), and ling zhang1
1 damo academy, alibaba group, hangzhou, china
yaojiawen.yjw@alibaba-inc.com
2 peking university, beijing, china
zhangli pku@pku.edu.cn
3 hupan lab, hangzhou 310023, china
4 sun yat-sen university cancer center, guangzhou, china
5 south china hospital, shenzhen university, shenzhen, china
6 tianjin medical university cancer institute and hospital, tianjin, china
7 peking university changsha institute for computing and digital economy,
changsha, china
8 guangdong provincial people’s hospital, guangzhou, china
9 shengjing hospital, shenyang, china
18940259980@163.com
abstract. pancreatic ductal adenocarcinoma (pdac) is a highly lethal
cancer in which the tumor-vascular involvement greatly aﬀects the
resectability and, thus, overall survival of patients."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_24.pdf,"we propose a novel approach for measuring the relative position relation-
ship between the tumor and the vessel by explicitly using the distance between
them. [8], or other surface-
awareness metrics are used. however, as shown in fig. 1, these point-to-point dis-
tances cannot diﬀerentiate the degree of tumor-vascular invasion [18]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_24.pdf,"finally, we concatenate the features extracted from the two components and
apply a fully-connected layer to predict the survival outcome, denoted as oos,
which is a value between 0 and 1. to optimize the proposed model, we use the
negative log partial likelihood as the survival loss [9].
3
experiments
dataset. in this study, we used data from shengjing hospital to train our
method with 892 patients, and data from three other centers, including guang-
dong provincial people’s hospital, tianjin medical university and sun yat-
sen university cancer center for independent testing with 178 patients. the
improved prognostic prediction of pancreatic cancer
247
contrast-enhanced ct protocol included non-contrast, pancreatic, and portal
venous phases."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_24.pdf,"to demonstrate the added value of our
signature as a tool to select patients for neoadjuvant treatment before surgery,
we plotted kaplan-meier survival curves in fig. 3. we further stratify patients by
our signature after grouping them by tumor size and ca19-9, two clinically used
preoperative criteria for selection, and also age. our signature could signiﬁcantly
stratify patients in all cases and those in the high-risk group had worse outcomes
and might be considered as potential neoadjuvant treatment candidates (e.g. 33
high-risk patients with larger tumor size and high ca19-9)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf,"ahn2,3, harrison bai5, xinbo gao1,
michael k. atalay2,3, and zhicheng jiao2,3(b)
1 school of electronic engineering, xidian university, xi’an, china
2 warren alpert medical school, brown university, providence, usa
zhicheng_jiao@brown.edu
3 department of diagnostic imaging, rhode island hospital, providence, usa
4 school of computer science and engineering, central south university,
changsha, china
5 department of radiology and radiological sciences, johns hopkins university
school of medicine, baltimore, usa
abstract. bias in healthcare negatively impacts marginalized popula-
tionswithlowersocioeconomicstatusandcontributestohealthcareinequal-
ities."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf,"eliminating bias in ai models is crucial for fair and precise medical
implementation. the development of a holistic approach to reducing bias
aggregationinmultimodalmedicaldataandpromotingequityinhealthcare
ishighlydemanded.racialdisparitiesexistinthepresentationanddevelop-
mentofalgorithmsforpulmonaryembolism(pe),anddeepsurvivalpredic-
tionmodelcanbede-biasedwithmultimodaldata.inthispaper,wepresent
a novel survival prediction (sp) framework with demographic bias disen-
tanglement for pe. the ctpa images and clinical reports are encoded by
the state-of-the-art backbones pretrained with large-scale medical-related
tasks."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf,"the proposed de-biased sp modules eﬀectively disentangle latent
race-intrinsic attributes from the survival features, which provides a fair
survival outcome through the survival prediction head. we evaluate our
method using a multimodal pe dataset with time-to-event labels and race
identiﬁcations. the comprehensive results show an eﬀective de-biased per-
formance of our framework on outcome predictions."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf,"keywords: pulmonary embolism · deep survival prediction ·
de-bias learning · multi-modal learning
1
introduction
bias in medicine has demonstrated a notable challenge for providing comprehen-
sive and equitable care. implicit biases can negatively aﬀect patient care, particu-
larly for marginalized populations with lower socioeconomic status [30]. evidence
supplementary information the online version contains supplementary material
available at https://doi.org/10.1007/978-3-031-43904-9_50. c
⃝ the author(s), under exclusive license to springer nature switzerland ag 2023
h. greenspan et al. (eds.): miccai 2023, lncs 14224, pp."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf,"using biased data for ai models
reinforces racial inequities, worsening disparities among minorities in healthcare
decision-making [22].
within the radiology arm of ai research, there have been signiﬁcant advances
in diagnostics and decision making [19]. along these advancements, bias in
healthcare and ai are exposing poignant gaps in the ﬁeld’s understanding of
model implementation and their utility [25,26]. ai model quality relies on input
data and addressing bias is a crucial research area."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf,"[22].
pulmonary embolism (pe) is an example of health disparities related to race. black patients exhibit a 50% higher age-standardized pe fatality rate and a
twofold risk for pe hospitalization than white patients [18,24]. hospitalized black
patients with pe were younger than whites."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf,"the pulmonary embolism severity index (pesi) is a
well-validated clinical tool based on 11 clinical variables and used for outcome pre-
diction measurement [2]. [7,12,14].
however, one issue with traditional survival analysis is bias from single modal
data that gets compounded when curating multimodal datasets, as diﬀerent
combinations of modes and datasets create with a uniﬁed structure. multimodal
data sets are useful for fair ai model development as the bias complementary
from diﬀerent sources can make de-biased decisions and assessments."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf,"in that
process, the biases of each individual data set will get pooled together, creating
a multimodal data set that inherits multiple biases, such as racial bias [1,15,23]. in addition, it has been found that creating multimodal datasets without any de-
biasing techniques does not improve performance signiﬁcantly and does increase
bias and reduce fairness [5]. overall, a holistic approach to model development
would be beneﬁcial in reducing bias aggregation in multimodal datasets. [4] for bias disentanglement
improves model generalization for fairness [3,6,27].
we developed a pe outcome model that predicted mortality and detected
bias in the output."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf,"we then implemented methods to remove racial bias in our
dataset and model and output unbiased pe outcomes as a result. our contri-
butions are as follows: (1) we identiﬁed bias diversity in multimodal informa-
tion using a survival prediction fusion framework. (2) we proposed a de-biased
survival prediction framework with demographic bias disentanglement."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf,"1. overview of the survival prediction (sp) framework and the proposed de-
biased sp module (lower right). id branch (ei;ci) and survival branch (ec;cc) are
trained to disentangle race-intrinsic attributes and survival attributes with the feature
swapping augmentation, respectively. the survival head predicts the outcomes based
on the de-biased survival attributes."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf,"2
bias in survival prediction
this section describes the detail of how we identify the varying degrees of bias
in multimodal information and illustrates bias using the relative diﬀerence in
survival outcomes. we will ﬁrst introduce our pulmonary embolism multimodal
datasets, including survival and race labels. then, we evaluate the baseline sur-
vival learning framework without de-biasing in the various racial groups.
dataset."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf,"the clinical reports from physicians
that provided crucial information are anonymized and divided into four parts:
medical history, clinical diagnosis, observations and radiologist’s opinion. [2].
diverse bias of multimodal survival prediction model. we designed a
deep survival prediction (sp) baseline framework for multimodal data as shown
518
z. zhong et al.
in fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf,"the biased performance of the imaging-based module is likely caused by the rich-
ness of redundant information in images, which includes implicit features such as
body structure and posture that reﬂect the distribution of diﬀerent races. this
redundancy leads to model overﬁtting on race, compromising the fairness of risk
prediction across diﬀerent races. besides, clinical data in the form of text reports
and pesi variables objectively reﬂect the patient’s physiological information and
the physician’s diagnosis, exhibiting smaller race biases in correlation with sur-
vival across diﬀerent races."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf,"3
de-biased survival prediction model
based on our sp baseline framework and multimodal ﬁndings from sect. 2, we
present a feature-level de-biased sp module that enhances fairness in survival
de-biased outcome prediction model
519
outcomes by decoupling race attributes, as shown in the lower right of fig. 1.
in the de-biased sp module, ﬁrstly, two separate encoders em
i
and em
c are for-
mulated to embed features f m into disentangled latent vectors for race-intrinsic
attributes zid or race-conﬂicting attributes zsur implied survival information [16]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf,"[31] to
train em
c and cm
c to overﬁt to race label while training em
i
and cm
i
with cross-
entropy (ce) loss. the relative diﬃculty scores w as deﬁned in eq. 1 reweight
and enhance the learning of the race-intrinsic attributes [20]. + gce (cc(z), yid)
(2)
to promote race-intrinsic learning in em
i
and cm
i , we apply diversify with
latent vectors swapping."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf,"the two neural networks are trained
to predict yid or ˜yid with ce loss or gce loss. as the random combination are
generated from diﬀerent samples, the swapping decreases the correlation of these
feature vectors, thereby enhancing the race-intrinsic attributes. + gce (cc(zsw), ˜yid)
(3)
the survival prediction head cm
sur predicts the risk on the survival feature
zsur."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf,"− log

j:yj
t >yi
t
ecsur(zj
sur)
⎞
⎠
(4)
loverall = ldis + λswlsw + λsurlcoxph
(5)
where yt and ye are survival labels including the survival time and the event,
respectively. the weights λsw and λsur are assigned as 0.5 and 0.8, respectively,
to balance the feature disentanglement and survival prediction. 4
experiment
we validate the proposed de-biased survival prediction frameworks on the col-
lected multi-modality pe data."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf,"performance comparison of the proposed de-biased sp framework and base-
line using c-index values on multiple modal outcomes. the larger c-index value is
better and the lower bias is fairer. 0.816
0.124 0.759
0.756
0.768
0.012
into training, validation, and testing sets, with a ratio of 7:1:2, the same ratio of
survival events is maintained in each institution."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf,"2. tsne visualizations of the features from multimodal data. based on the com-
parison between the id features and others, it is observed that the clusters containing
race obtained from the same class are more compact. 3. kaplan-meier survival curves of our 3 de-biased sp modules and the multi-
modal coxph model."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf,"(color ﬁgure online)
4.1
results
table 1 shows the quantitative comparisons of the baseline and de-biased frame-
works with the c-indexes of the multimodal survival predictions. in general, our
framework including de-biased sp modules shows signiﬁcantly better predictions
in testing set than the pesi-based outcome estimation with c-indexes of 0.669,
0.654, 0.697, 0.043 for the overall testset, white testset, color testset and race
bias. the de-biased results outperform the baseline in overall survival c-index
and show a lower race bias, especially in imaging- and fusion-based predictions."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf,"the results indicate the eﬀectiveness of the proposed de-biasing in mitigating
race inequity. the results also prove the observations for the diﬀerent biases
present in diﬀerent modalities, especially in the ctpa images containing more
abundant race-related information. it also explains the limited eﬀectiveness of
de-biasing the clinical results, which contain less racial identiﬁcation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf,"the pre-
522
z. zhong et al.
table 2. results of ablation studies. every 2 columns (overall performance of testing
and bias) represent a training setting. the disentangled representations, transformed
from latent space to a 2d plane via tsne and color-coded by race [9], are shown
in fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf,"2. we observe the disentanglement in the visualization of the id features
zid, while the survival features zsur eliminate the race bias. the lack of appar-
ent race bias observed in both the original features and those encoded in the
baseline can be attributed to the subordinate role that id features play in the
multimodal information. the kaplan-meier (k-m) survival curve [14], as shown
in fig. 3, is used to compare the survival prediction between high-risk and low-
risk patient groups."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf,"in addition,
the predictions of the de-biased framework show favorable performance, and our
multimodal fusion demonstrates a more pronounced discriminative ability in the
k-m survival analysis compared to the single-modal results. we conducted ablation studies to examine the eﬀect of the two key compo-
nents, including swapping feature augmentation and race-balance resampling. as shown in table 2, the diﬀerent training settings show signiﬁcant diﬀerences
in survival prediction performance across modalities."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf,"overall, multimodal fusion approaches are eﬀective in all training settings, and
the coxph model can actively learn the optimal combination of multimodal
features to predict survival outcomes. 5
discussions and conclusions
in this work, we developed a de-biased survival prediction framework based
on the race-disentangled representation. the proposed de-biased sp framework,
based on the sota pe detection backbone and large-scale clinical language
model, can predict the pe outcome with a higher survival correlation ahead
of the clinical evaluation index."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf,"we detected indications of racial bias in our
dataset and conducted an analysis of the multimodal diversity. experimental
de-biased outcome prediction model
523
results illustrate that our approach is eﬀective for eliminating racial bias while
resulting in an overall improved model performance. the proposed technique
is clinically relevant as it can address the pervasive presence of racial bias in
healthcare systems and oﬀer a solution for minimizing or eliminating bias with-
out pausing to evaluate their aﬀection for the models and tools."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf,"the proposed de-biased method has already shown the
capacity to relieve them, which is vital when serving patients with an accurate
analysis. the research in our paper demonstrates and proves that eliminating
racial biases from data improves performance, and yields a more precise and
robust survival prediction tool. in the future, these de-biased sp modules can
be plugged into other models, oﬀering a fairer method to predict survival out-
comes."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_45.pdf,"the displacement estimation step of ultrasound elastogra-
phy (use) can be done by optical ﬂow convolutional neural networks
(cnn). even though displacement estimation in use and computer
vision share some challenges, use displacement estimation has two dis-
tinct characteristics that set it apart from the computer vision coun-
terpart: high-frequency nature of rf data, and the physical rules that
govern the motion pattern. the high-frequency nature of rf data has
been well addressed in recent works by modifying the architecture of
the available optical ﬂow cnns."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_45.pdf,"the core idea is that some known operations (for example
inversion of a matrix) are embedded inside the networks to simplify the training
and improving the generalization ability of the network. the known operator can
be viewed as the prior knowledge related to the physics of the problem. [7].
in this paper, we aim to embed two lateral displacement reﬁnement algo-
rithms in the cnns to improve the lateral strains."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_45.pdf,"the
operator s denotes stop gradient operation, which is employed to avoid the
axial strain being aﬀected by this regularization. it should be noted in con-
trast to [5] in which only out-of-range samples were contributing to the loss,
in this work, all samples contribute to lvd to reduce the estimation bias. lvs, where λvs is the weight
of the smoothness loss."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_45.pdf,"this data is available online at
http://code.sonography.ai in [16]. in vivo data was collected at johns hopkins hospital from patients with liver
cancer during open-surgical rf thermal ablation by a research antares siemens
system using a vf 10-5 linear array with the sampling frequency of 40 mhz and
the center frequency of 6.67 mhz. the institutional review board approved the
study with the consent of the patients."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_45.pdf,"4
conclusions
in this paper, we proposed to incorporate two known operators inside a use
network. the network is trained by physically inspired constraints speciﬁcally
designed to tackle the long-standing illusive problem of lateral strain imaging. the proposed operators provide a reﬁnement in each pyramid level of the archi-
tecture and substantially improve the lateral strain image quality."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_64.pdf,"thirdly, to improve
the distinction between the object and the background, we apply con-
ditional encoding to enhance the intermediate features with the original
image encoding. to objectively validate the proposed method, we com-
pared state-of-the-art deep learning model on the 2015 miccai gland
segmentation challenge (glas) dataset and the colorectal adenocarci-
noma gland (crag) dataset. the experimental results show that our
method improves the accuracy of segmentation and proves the eﬃcacy
of the method."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_64.pdf,"the mask fcn
head, denoted by mfh, is comprised of three 1 × 1 convolutional layers. we enhance our loss function by incorporating two components, ld and ls,
and utilize the γ parameter to optimize the balance between these two losses. [14], and the ld is the loss of
diﬀusiondet."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_64.pdf,"the optimal value for the parameter γ is usually determined based
on achieving the best overall performance on the validation set. in this work, we
chose γ = 5 to balance these two losses. 3
experiments and results
we presented the segmentation results of our model compared to the ground
truth in fig. 3, and provided both qualitative and quantitative evaluations that
validate the eﬀectiveness of our proposed network for gland instance segmenta-
tion.
data and evaluation metrics: we evaluated the eﬀectiveness of the pro-
posed model on two datasets: the glas dataset and the crag dataset."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_64.pdf,"conditional
encoding is employed to establish a connection between input image features
table 1. the experimental results on glas challenge dataset. the s represents the
score, r represents the rank and rank sum refers to the sum of rank for each evaluation
metric."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_64.pdf,"experimental results on the glas dataset and crag
dataset show that our method surpasses state-of-the-art approach, demonstrat-
ing its eﬀectiveness. although our method demonstrates excellent performance in gland instance
segmentation, challenges arise in certain scenarios characterized by irregular
shapes, ﬂattening, and overlapping. in such cases, our network tends to clas-
sify multiple small targets with unclear boundaries as a single object, indicating
limitations in segmentation accuracy when dealing with high aggregation or over-
lap."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_42.pdf,"interpretable medical image classiﬁcation
using prototype learning and privileged
information
luisa gallée1
, meinrad beer2
, and michael götz1,3(b)
1 experimental radiology, university hospital ulm, ulm, germany
{luisa.gallee,michael.goetz}@uni-ulm.de
2 department of diagnostic and interventional radiology,
university hospital ulm, ulm, germany
3 i2soui - innovative imaging in surgical oncology ulm,
university hospital ulm, ulm, germany
abstract. interpretability is often an essential requirement in medical
imaging."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_28.pdf,"in this work, we propose a method for visualizing intrahepatic structures
after organ motion and needle-induced deformations, in non-injected images, by
exploiting image features that are generally not perceivable by the human eye
in common clinical workﬂows. to address this challenge, two main strategies could be considered: image
fusion and image processing techniques. image fusion typically relies on the
estimation of rigid or non-rigid transformations between 2 images, to bring into
the intraoperative image structures of interest only visible in the preoperative
data."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_28.pdf,"when ground-truth
displacement ﬁelds are not known, state-of-the-art methods use unsupervised
techniques, usually an encoder-decoder architecture [7,13], to learn the unknown
displacement ﬁeld between the 2 images. however, such unsupervised methods
fail at solving our problem due to lack of similar image features between the
contrasted (cct) and non-contrasted (ncct) image in the vascular tree region
(see sect. 3.3). on the other hand, deep learning techniques have proven to be very eﬃcient
at solving image processing challenges [15]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_28.pdf,"[17], or contrast-enhancement to cite a few. however, applying such methods
to generate a contrasted intraoperative ct is not a suﬃciently accurate solution
for the problem that we address. contrast-enhancement methods could be an
alternative."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_28.pdf,"finally, we extract the vm from each mpcect
sample and apply 3 dilation operations, which demonstrated the best perfor-
mance in terms of prediction accuracy and robustness on our data. [25] and others do not ﬁt
our problem since they do not include the ncct images. aiming at a patient-
speciﬁc prediction, we only train on a “subject” at a time."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_28.pdf,"the
training process converges in about 1,000 epochs with a batch size of 1 and 200
steps per epoch.
3.2
results
to assess our method, we use a dice score to measure the overlap between our
predicted segmentation and the ground truth. being a commonly used metric
for segmentation problems, dice aligns the nature of our problem as well as the
clinical impact of our solution. we ha performed tests on 4 diﬀerent (porcine)
data sets."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_28.pdf,"we also studied the inﬂuence of the diﬀusion kernel applied to
the initial segmentation. we have seen, on our experimental data, that 3 dilation
operations were suﬃcient to compensate for the possible motion between ncct
and cct acquisitions.
comparison with voxelmorph: the problem that we address can be seen
from diﬀerent angles. in particular, we could attempt to solve it by register-
ing the preoperative ncct to the intraoperative one and then applying the
intraoperative ct augmentation for needle-based liver interventions
299
resulting displacement ﬁeld to the known preoperative segmentation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_45.pdf,"iteratively coupled multiple instance
learning from instance to bag classiﬁer
for whole slide image classiﬁcation
hongyi wang1, luyang luo2, fang wang3, ruofeng tong1,4, yen-wei chen1,5,
hongjie hu3, lanfen lin1(b), and hao chen2,6(b)
1 college of computer science and technology, zhejiang university,
hangzhou, china
llf@zju.edu.cn
2 department of computer science and engineering,
the hong kong university of science and technology, hong kong, china
jhc@cse.ust.hk
3 department of radiology, sir run run shaw hospital, hangzhou, china
4 research center for healthcare data science, zhejiang lab, hangzhou, china
5 college of information science and engineering, ritsumeikan university,
kusatsu, japan
6 department of chemical and biological engineering,
the hong kong university of science and technology, hong kong, china
abstract. whole slide image (wsi) classiﬁcation remains a challenge
due to their extremely high resolution and the absence of ﬁne-grained
labels."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_45.pdf,"such schemes
hinder the patch embedder’s access to slide-level semantic labels, result-
ing in inconsistency within the entire mil pipeline. to overcome this issue,
we propose a novel framework called iteratively coupled mil (icmil),
which bridges the loss back-propagation process from the bag-level classi-
ﬁer to the patch embedder. in icmil, we use category information in the
bag-level classiﬁer to guide the patch-level ﬁne-tuning of the patch feature
extractor."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_45.pdf,"however, the high resolu-
tion of wsis also makes their automated classiﬁcation challenging [15]. patch-
based classiﬁcation is a common solution to this problem [3,8,24]. it predicts the
slide-level label by ﬁrst predicting the labels of small, tiled patches in a wsi."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_45.pdf,"therefore,
many weakly-supervised [8,24] and semi-supervised [3,5] methods have been pro-
posed to generate patch-level pseudo labels at a lower cost. however, the lack
of reliable supervision directly hinders the performance of these methods, and
serious class-imbalance problems could arise, as tumor patches may only account
for a small portion of the entire wsi [12]. in contrast, mil-based methods have become increasingly preferred due to
their only demand for slide-level labels [18]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_45.pdf,"(c) mil methods that introduce extra self-supervised ﬁne-tuning of g(·). (d) our pro-
posed icmil which can bridge the loss back-propagation process from f(·) to g(·) by
iteratively coupling them during training.
to address the challenges mentioned above, we propose a novel mil frame-
work called icmil, which can iteratively couple the patch feature embedding pro-
cess with the bag-level classiﬁcation process to enhance the eﬀectiveness of mil
training (as illustrated in fig. 2(d)). [9,16,25], we aim to bridge the loss back-propagation process from f(·) to g(·) to
improve g(·)’s ability to perceive slide-level labels."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_45.pdf,"in this regard, we further propose a teacher-student [7]
approach to eﬀectively generate pseudo labels and simultaneously ﬁne-tune g(·). after ﬁne-tuning, the domain shift problem is alleviated in g(·), leading to bet-
ter patch representations. the new representations can be used to train a better
bag-level classiﬁer in return for the next round of iteration."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_45.pdf,"previous works [13,17,22], but it was only treated as an assisting tool for aiding
the training of either g(·) or f(·) in the traditional mil pipelines. in contrast,
we are the ﬁrst to consider the optimization of the entire mil pipeline as an em
alike problem, utilizing em for coupling g(·) and f(·) together iteratively. [6] pre-trained on imagenet [19] (step 1⃝ in fig. 3)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_45.pdf,"although patch-level labels are oﬃcially provided in
camelyon16, they were not used in our experiments. the second dataset is a private hepatocellular carcinoma (hcc) dataset col-
lected from sir run run shaw hospital, hangzhou, china. this dataset com-
prises a total of 1140 valid tumor wsis scanned at 40× magniﬁcation, and the
objective is to identify the severity of each case based on the edmondson-steiner
(es) grading."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_45.pdf,"from
table 1(a), we can learn that as the number of icmil iteration increases, the
performance will also go up until reaching a stable point. since the number of
instances is very large in wsi datasets, we empirically recommend to choose
to run icmil one iteration for ﬁne-tuning g(·) to achieve the balance between
performance gain and time consumption. from table 1(b), it is shown that our
474
h. wang et al.
fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_73.pdf,"joint prediction of response to therapy,
molecular traits, and spatial organisation
in colorectal cancer biopsies
ruby wood1,3
, enric domingo4
, korsuk sirinukunwattana1,3
,
maxime w. lafarge5, viktor h. koelzer5
, timothy s. maughan4
,
and jens rittscher1,2,3(b)
1 department of engineering science, university of oxford, oxford, uk
{ruby.wood,jens.rittscher}@eng.ox.ac.uk
2 nuﬃeld department of medicine, university of oxford, oxford, uk
3 big data institute, university of oxford, li ka shing centre for health
information and discovery, oxford, uk
4 department of oncology, university of oxford, oxford, uk
5 computational and translational pathology group, department of pathology
and molecular pathology, university hospital and university of zürich,
zürich 8091, switzerland
abstract. existing methods for interpretability of model predictions
are largely based on technical insights and are not linked to clinical
context."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_73.pdf,"they are
even more unbalanced for cms4, since only 28/244 slides in grampian and
17/121 slides in aristotle are labelled with cms4. we address this imbalance
in the supplementary materials. there are 365 slides total in our dataset, from
249 patients."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_73.pdf,"each prediction uses an optimised threshold value determined
from the validation set in order to round the output probabilities to a binary prediction. we use weighted metrics due to the class imbalance in our dataset. despite the noise in our reference data used for training, our model
achieves good performance in terms of mean auc scores on all three prediction
branches of our model, predicting complete response to radiotherapy (rt) with
0.819 auc, cms4 with 0.819 auc and epithelial tissue at the node level with
0.760 auc across folds."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_65.pdf,"methods to relieve the high depen-
dency on the accurate annotations of nuclei are highly needed. unsupervised learning (ul) methods achieved great success in the data
dependency problem for nuclei segmentation, which learns from the structural
properties in the data without any manual annotations. based on the character
of these methods, we can group them into two categories: the traditional ul
methods and the deep learning ul methods."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_65.pdf,"this phenomenon oﬀers valuable information
for networks to use but the current clustering models do not take this into
account. to address the above issues and motivated by the iiss property, we hereby
propose a novel self-similarity-driven segmentation network (ssimnet) for
unsupervised nuclei segmentation. as shown in fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_65.pdf,"[15] (termed as dcgn). for the methods without public codes, we report the results from the original
publications for a fair comparison. the results are shown in table 1.
as table 1 shows, ﬁrstly, our ssimnet outperforms all other unsupervised
model and performs even close to fully supervised u-net under the metrics
of dice coeﬃcient and aggregated jaccard index (aji)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_70.pdf,"the frequency attention mechanism is modeled using a laplacian pyra-
mid to emphasize each frequency information’s contribution selectively. then,
a parametric frequency attention fusion strategy to balance the importance of
shape and texture features by recalibrating the frequency features. these two
attention mechanisms work in parallel."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_70.pdf,"➋ we also introduce a novel eﬃcient
enhancement multi-scale bridge that eﬀectively transfers spatial information
from the encoder to the decoder while preserving the fundamental features. ➌ our method not only alleviates the problem of the traditional self-attention
mechanism mentioned above, but also it surpasses all its counterparts in terms
of diﬀerent evaluation metrics for the tasks of medical image segmentation. 2
methods
in our proposed network, illustrated in fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_70.pdf,"our eﬃcient enhancement transformer block ﬁrst takes a layernorm (ln)
from the input x. then it applies the ef-att mechanism to capture contextual
information and selectively include various types of frequency information while
using the laplacian pyramid to balance the importance of shape and texture
features. next, x and diversity-enhanced shortcuts are added to the output of
the attention mechanism to increase the diversity of features."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_70.pdf,"it is proved in [19]
that as transformers become deeper, their features become less varied, which
restrains their representation capacity and prevents them from attaining optimal
performance. to address this issue, we have implemented an augmented short-
740
r. azad et al.
fig. the structure of our frequency enhancement transformer block.
cut method from [9], a diversity-enhanced shortcut (des), employing a kro-
necker decomposition-based projection."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_70.pdf,"they demonstrate that eﬃcient attention
e can provide an equivalent representation of self-attention while being com-
putationally eﬃcient. by adopting this approach, we can alleviate the issues of
feature redundancy and computational complexity associated with self-attention. wang et al."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_70.pdf,"the laplacian pyramid is composed of
multiple levels, each level containing distinct types of information. to ensure
a balanced distribution of low and high-frequency information in the model, it
is necessary to eﬃciently aggregate the features from all levels of the frequency
domain. hence, we present frequency attention that involves multiplying the key
and value of each level (xl) to calculate the attention score and then fuses the
resulting attention scores of all levels using a fusion module, which performs
summation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_30.pdf,"learning robust classiﬁer for imbalanced
medical image dataset with noisy labels
by minimizing invariant risk
jinpeng li1, hanqun cao1, jiaze wang1, furui liu3, qi dou1,2,
guangyong chen3(b), and pheng-ann heng1,2
1 department of computer science and engineering, the chinese university of hong
kong, shatin, hong kong
2 institute of medical intelligence and xr, the chinese university of hong kong,
shatin, hong kong
3 zhejiang lab, hangzhou, china
gychen@zhejianglab.com
abstract. in medical image analysis, imbalanced noisy dataset classiﬁ-
cation poses a long-standing and critical problem since clinical large-
scale datasets often attain noisy labels and imbalanced distributions
through annotation and collection."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_30.pdf,"current approaches addressing noisy
labels and long-tailed distributions separately may negatively impact
real-world practices. additionally, the factor of class hardness hinder-
ing label noise removal remains undiscovered, causing a critical neces-
sity for an approach to enhance the classiﬁcation performance of noisy
imbalanced medical datasets with various class hardness. to address this
paradox, we propose a robust classiﬁer that trains on a multi-stage noise
removal framework, which jointly rectiﬁes the adverse eﬀects of label
noise, imbalanced distribution, and class hardness."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_30.pdf,"multi-environment risk
minimization (mer) strategy captures data-to-label causal features for
noise identiﬁcation, and the rescaling class-aware gaussian mixture
modeling (rcgm) learns class-invariant detection mappings for noise
removal. extensive experiments on two imbalanced noisy clinical datasets
demonstrate the capability and potential of our method for boosting the
performance of medical image classiﬁcation. keywords: imbalanced data · noisy labels · medical image analysis
1
introduction
image classiﬁcation is a signiﬁcant challenge in medical image analysis."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_30.pdf,"time-consuming and expensive. besides, pruning clean and balanced datasets
require a large amount of crucial clinical data, which is insuﬃcient for large-scale
deep learning. therefore, we focus on a more practical yet unexplored setting for
handling imbalanced medical data with noisy labels, utilizing all available low-
cost data with possible noisy annotations."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_30.pdf,"noisy imbalanced datasets arise due
to the lack of high-quality annotations [11] and skewed data distributions [18]
where the number of instances largely varies across diﬀerent classes. besides,
the class hardness problem where classiﬁcation diﬃculties vary for diﬀerent cat-
egories presents another challenge in removing label noise. due to diﬀerences
in disease epidemicity and collection diﬃculty, rare anomalies or anatomical
features render diseases with low epidemicity easier to detect."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_30.pdf,"[12,23,24] fail to jointly address these scenarios, leading to inadequate
classiﬁcation outcomes. therefore, noisy-labeled, imbalanced datasets with var-
ious class hardness remain a persistent challenge in medical classiﬁcation. existing approaches for non-ideal medical image classiﬁcation can be sum-
marized into noisy classiﬁcation, imbalanced recognition, and noisy imbalanced
identiﬁcation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_30.pdf,"noisy classiﬁcation approaches [3,7,23] conduct noise-invariant
learning depending on the big-loss hypothesis, where classiﬁers trained with
clean data with lower empirical loss aid with de-noising identiﬁcation. however,
imbalanced data creates diﬀerent conﬁdence distributions of clean and noisy data
in the majority class and minority class as shown in fig. 1, which invalidates the
big-loss assumption [3,4]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_30.pdf,"imbalanced recognition approaches [9,15,21] utilize
augmented embeddings and imbalance-invariant training loss to re-balance the
long-tailed medical data artiﬁcially, but the disturbance from noisy labels leads
to uncasual feature learning, impeding the recognition of tail classes. noisy long-
tailed identiﬁcation technique [25] has achieved promising results by addressing
noise and imbalance concerns sequentially. however, the class hardness problem
leads to vague decision boundaries that hinders accurate‘ noise identiﬁcation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_30.pdf,"the invariant risk to tackle noise identiﬁcation inﬂuenced by multiple factors,
enabling the classiﬁer to learn causal features and be distribution-invariant, 3)
a re-scaling class-aware gaussian mixture modeling (cgmm) approach is pro-
posed to distinguish noise labels under various class hardness, 4) we evaluate our
method on two medical image datasets, and conduct thorough ablation studies
to demonstrate our approach’s eﬀectiveness. 2
method
2.1
problem formulation
in the noisy imbalanced classiﬁcation setting, we denote a medical dataset as
{(xi, yi)}n
i=1 where yi is the corresponding label of data xi and n is the total
amount of instances. here yi may be noisy."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_30.pdf,"= c, ei, em)
(2)
the induction derives from the assumption that the incorrect mapping pg(y =
c|z, e) conditions on both pure latent to logits mapping pg(y = c|z) and adverse
eﬀects pg(y = c|e). by bayes theorem, we decompose the eﬀect into imbalance,
learning robust medical image classiﬁer by minimizing invariant risk
309
fig. 2. protocol for noisy long-tailed recognition: (a) shows warm-up and
mer schemes."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_30.pdf,"(b) represents rcgm scheme for class-aware noise detection and score
re-scaling. (c) displays ﬁnal ﬁne-tuning procedures including noise removal ﬁnetune
and re-balanced ﬁnetune.
noise, and mode (hardness), where the noise eﬀect depends on skew distribution
and hardness eﬀect; and the hardness eﬀect is noise-invariant. currently, noise removal methods only address pure noise eﬀects (pg(en|y =
c)), while imbalance recognition methods can only resolve imbalanced distri-
bution, which hinders the co-removal of adverse inﬂuences."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_30.pdf,"in essence, the fundamental idea
of noisy classiﬁcation involves utilizing clean data for classiﬁer training, which
determines the importance of noise identiﬁcation and removal. to address these
issues, we propose a mapping correction approach that combines independent
noise detection and removal techniques to identify and remove noise eﬀectively. 2.3
minimizing invariant risk across multi-distributions
traditional learning with noisy label methods mainly minimize empirical risk on
training data."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_30.pdf,"(4)
ideally, the noise removal process is distribution-invariant if data is uniformly
distributed w.r.t. classes. by the law of large numbers, all constructed distribu-
tions should be symmetric according to the balanced distribution to obtain a
uniform expectation. [25] composed of one uniform distribution and two symmetric
skewed distributions instead of theoretical settings."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_30.pdf,"this results in ineﬀectiveness of
global cluster methods in detecting label noises across all categories. to resolve
the challenge, we propose a novel method called rescaling class-aware gaussian
mixture modeling (rcgm) which clusters each category data independently
by ﬁtting conﬁdence scores qij from ith class into two gaussian distributions
as pn
i (xn|μn, σn) and pc
i(xc|μc, σc). =

k∈{c,n}
αikpk
i

qij | μk
i , σk
i

,
(5)
which produces more accurate and independent measurements of label quality."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_30.pdf,"let xij be the jth in class i, then its
probability of having a clean label is:
γij = αikpc
i (qij | μc
i, σc
i )
pm
i (qij)
,
(6)
which is then multiplied by a hyperparameter s if the instance is predicted as
noise to reduce its weight in the ﬁnetuning. τ
(7)
2.5
overall learning framework for imbalanced and noisy data
in contrast to two-stage noise removal and imbalance classiﬁcation techniques,
our approach applies a multi-stage protocol: warm-up phases, noise removal
phases, and ﬁne-tuning phases as shown in fig. a few epochs by assuming that g only remembers
clean images with less empirical loss."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_30.pdf,"in the noise removal phases, we learn class-
invariant probability distributions of noisy-label eﬀect with mer and remove
class hardness impact with rcgm. finally, in the ﬁne-tuning phases, we apply
mixup technique [13,25,26] to rebuild a hybrid distribution from noisy pairs
and clean pairs by:
ˆxkl := αklxk + (1 − αkl)xl,
∀xk, xl ∈ d
ˆykl := αklyk + (1 − αkl)yl,
∀yk, yl ∈ d
(8)
where αkl := v(xk)
v(xl) denotes the balanced scale; and {(ˆxkl, ˆykl)} are the mixed
clean data for classiﬁer ﬁne-tuning. [12] and ce loss are the ﬁne-tuning loss functions."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_30.pdf,"the second-best performances are underlined. to emulate imbalanced scenarios, we prune the class sizes of the training
set into an imbalanced distribution as [5]. consequently, chaoyang dataset
consists of a training set with 2,181 images, a validation set with 713 images,
and a testing set with 1,426 images, where the validation and testing sets have
clean labels."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_30.pdf,"table 1 exhibits the overall comparison of all
approaches. we ﬁrst conclude that noisy imbalanced setting does negatively
aﬀect learning with noise methods and imbalanced methods. in imbalanced
methods, cece only obtains 40.92 in macro-f1 on ham10000 and 47.12%
macro-f1 on chaoyang."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_30.pdf,"similar increases happen in gce & gce+focal and
nl & nl+sqrt-rs. then, we compare our approach to state-of-the-art meth-
ods of the noisy (dividemix), imbalanced (fcd), and noisy long-tailed (h2e)
methods. our framework achieves improvements in all metrics on both datasets,
demonstrating the rationality of the assumption and the eﬀectiveness of our
framework.
fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_30.pdf,"for example, mer achieves 5.37% and 1.15% improvements on ham10000 and
chaoyang, respectively, demonstrating the eﬀectiveness of our noise removal
314
j. li et al.
techniques. further, our multi-stage noise removal technique outperforms single
mer and rcgm, revealing that the decomposition for noise eﬀect and hard-
ness eﬀect works on noisy imbalanced datasets. we ﬁnd that the combination
of mer and rcgm improves more on chaoyang dataset."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_30.pdf,"it indicates the re-scaling pro-
cess for noise weight deduction contributes to balancing the feature learning and
classiﬁcation boundary disturbance from the mixture of noisy and clean data. furthermore, similar performance trends reveal the robustness of scale s.
4
conclusion and discussion
we propose a multi-step framework for noisy long-imbalanced medical image
classiﬁcation. we address three practical adverse eﬀects including data noise,
imbalanced distribution, and class hardness."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_30.pdf,"to solve these diﬃculties, we con-
duct multi-environment risk minimization (mer) and rescaling class-aware
gaussian mixture modeling (rcgm) together for robust feature learning. extensive results on two public medical image datasets have veriﬁed that our
framework works on the noisy imbalanced classiﬁcation problem. the main lim-
itation of our work is the manually designed multi-stage training protocol which
lacks simplicity compared to end-to-end training and warrants future simpliﬁca-
tion.
acknowlegdement."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_48.pdf,"this would usher exciting new developments, such as post-intervention
diagnosis, measuring polyps and stenosis, and automatically evaluating explo-
ration thoroughness in terms of the surface percentage that has been observed. this is the problem we address here. however, to model large sections of it while increasing the recon-
struction accuracy, multiple images must be used."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_48.pdf,"an impor-
tant ﬁrst step in that direction is to register the images from the sequences. [8].
unfortunately, this solves only half the problem because these techniques pro-
vide very sparse reconstructions and going from there to dense ones remains an
open problem. and occlusions, specularities, varying albedos, and speciﬁcities of
endoscopic lighting make it a challenging one.
to overcome these diﬃculties, we rely on two properties of endoscopic images:
– endoluminal cavities such as the gastrointestinal tract, and in particular the
human colon, are watertight surfaces."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_48.pdf,"(color ﬁgure
online)
square law discussed above actually holds. together, these two changes make the
minimization problem better posed and the automatic depth estimation more
reliable. our results show that exploiting the illumination is key to unlocking implicit
neural surface reconstruction in endoscopy."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_8.pdf,"liver tumor screening and diagnosis
in ct with pixel-lesion-patient network
ke yan1,2(b), xiaoli yin3, yingda xia1, fakai wang1, shu wang3,
yuan gao1,2, jiawen yao1,2, chunli li1,2,3, xiaoyu bai1,2, jingren zhou1,2,
ling zhang1, le lu1, and yu shi3
1 damo academy, alibaba group, hangzhou, china
yanke.yan@alibaba-inc.com
2 hupan lab, 310023 hangzhou, china
3 department of radiology, shengjing hospital of china medical university,
shenyang 110004, china
abstract. liver tumor segmentation and classiﬁcation are important
tasks in computer aided diagnosis."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_8.pdf,"(3) for evaluation,
previous segmentation works typically use pixel-level metrics such as dice coef-
ﬁcient. such metrics cannot reﬂect the lesion-level accuracy (how many lesion
instances are correctly detected and classiﬁed) and may bias to large lesions when
a patient has multiple tumors. patient-level metrics (e.g. classifying whether a
subject has malignant tumors) are also useful for treatment recommendation
in clinical practice [18,20]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_8.pdf,"the importance
sampling strategy [3] can hardly select any foreground pixels in such cases, so
the loss only contains background pixels, degrading the segmentation recall of
small lesions. we propose a simple approach to remedy this issue by sampling
an extra n foreground pixels for each lesion. a patient-level diagnosis is useful for triage."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_8.pdf,"we equip plan with a dedicated patient branch to aggregate such global
information to make better patient-level prediction. since one patient can have
multiple liver tumors of diﬀerent types, in our problem, we give each image
several hierarchical binary labels. labels suggest the existence of c ﬁne-grained types of tumors."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_62.pdf,"longitudinal multimodal transformer
integrating imaging and latent clinical
signatures from routine ehrs
for pulmonary nodule classiﬁcation
thomas z. li1(b), john m. still2, kaiwen xu3, ho hin lee3, leon y. cai1,
aravind r. krishnan4, riqiang gao5, mirza s. khan6, sanja antic7,
michael kammer7, kim l. sandler8, fabien maldonado7,
bennett a. landman1,3,4,8, and thomas a. lasko2,3
1 biomedical engineering, vanderbilt university, nashville, tn 37212, usa
thomas.z.li@vanderbilt.edu
2 biomedical informatics, vanderbilt university, nashville, tn 37212, usa
3 computer science, vanderbilt university, nashville, tn 37212, usa
4 electrical and computer engineering, vanderbilt university,
nashville, tn 37212, usa
5 digital technology and innovation, siemens healthineers,
princeton, nj 08540, usa
6 saint luke’s mid america heart institute, kansas city, mo 64111, usa
7 medicine, vanderbilt university medical center, nashville, tn 37235, usa
8 radiology, vanderbilt university medical center, nashville, tn 37235, usa
abstract. the accuracy of predictive models for solitary pulmonary
nodule (spn) diagnosis can be greatly increased by incorporating repeat
imaging and medical context, such as electronic health records (ehrs)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_10.pdf,"low-dose computer tomography (ldct) has been widely
used in medical diagnosis yet suﬀered from spatial resolution loss and
artifacts. numerous methods have been proposed to deal with those
issues, but there still exists drawbacks: (1) convolution without guid-
ance causes essential information not highlighted; (2) features with
ﬁxed-resolution lose the attention to multi-scale information; (3) sin-
gle super-resolution module fails to balance details reconstruction and
noise removal. therefore, we propose an ldct image super-resolution
network consisting of a dual-guidance feature distillation backbone for
elaborate visual feature extraction, and a dual-path content communica-
tion head for artifacts-free and details-clear ct reconstruction."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_10.pdf,"keywords: low-dose computed tomography · image denoising ·
image super-resolution · deep learning
c
⃝ the author(s), under exclusive license to springer nature switzerland ag 2023
h. greenspan et al. (eds.): miccai 2023, lncs 14229, pp. [18] and cancer screening [28]. to
balance the high image quality and low radiation damage compared to normal-
dose ct (ndct), numerous algorithms have been proposed for ldct super-
resolution [3,4]. image post-processing super-resolution (sr) methods
could be divided into 3 categories: interpolated-based methods [16,25], model-
based methods [13,14,24,26] and learning-based methods [7–9,17]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_10.pdf,"the aforementioned methods still have drawbacks: (1) they treated the
regions of interest (roi) and regions of uninterest equally, resulting in the extra
cost in computing source and ineﬃcient use for hierarchical features. (2) most of
them extracted the features with a ﬁxed resolution, failing to eﬀectively lever-
age multi-scale features which are essential to image restoration task [27,32]. (3) they connected the sr task and the ldct denoising task stiﬄy, leading to
smooth texture, residual artifacts and unclear edges.
to deal with those issues, as shown in fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_10.pdf,"singly using the sr head that consists of pixel
shuﬄe layer and convolution layer fails to suppress the residual artifacts because
of its poor noise removal ability. to deal with this problem, we develop a dual-
path architecture by introducing the shared denoising head into sr task where
the parameters of sr heads and denoising heads in diﬀerent paths are shared
respectively. two paths are designed to process the deep features extracted from
our backbone: (1) the sr path transfers the deep features to those with high-
frequency information and reconstructs the sr result, and (2) the denoising
102
j. chi et al.
path migrates the deep features to those without noise and recovers the clean
result secondly."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_10.pdf,"2. qualitative results on the 3d-ircadb dataset with the scale factor of 2. (a)
is the hr image and its red rectangle region displays the liver and its lateral issues. (b) to (h) are the reconstruction results by diﬀerent methods."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_10.pdf,"the results of dan, spsr and aid-srgan suﬀers from
the artifacts. jdnsr blurs the issue structural information, e.g. the edges of
liver and bone. for the inferior vena cava, portal vein, and gallbladder within
the kidney, realsr restores blurred details and textures though it could recover
clear edges of calciﬁcations."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_10.pdf,"figure 3 shows the qualitative comparison results on
the pancreas dataset with the scale factor of 4. figure 3 has similar obser-
vation as fig. 2, that is, our method could suppress more artifacts than other
methods, especially at the edges of the pancreas and the texture and structure of
the issues with in the kidney. therefore, our method reconstructs more detailed
results than other methods."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_75.pdf,"deep-learning-based object detection methods show promise
for improving screening mammography, but high rates of false positives
can hinder their eﬀectiveness in clinical practice. to reduce false posi-
tives, we identify three challenges: (1) unlike natural images, a malignant
mammogram typically contains only one malignant ﬁnding; (2) mam-
mography exams contain two views of each breast, and both views ought
to be considered to make a correct assessment; (3) most mammograms
are negative and do not contain any ﬁndings. in this work, we tackle the
three aforementioned challenges by: (1) leveraging sparse r-cnn and
showing that sparse detectors are more appropriate than dense detectors
for mammography; (2) including a multi-view cross-attention module
to synthesize information from diﬀerent views; (3) incorporating multi-
instance learning (mil) to train with unannotated images and perform
breast-level classiﬁcation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_75.pdf,"as shown in fig. 1a, most works focus on reporting
recalls outside the clinically relevant region of less than 1 fp/image.
to tackle the high rate of false positives in mammography, we identify three
challenges: (1) a malignant mammogram typically contains only one malignant
ﬁnding. this is diﬀerent from natural images: for example, an image in coco
contains on average 7.7 objects [11]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_75.pdf,"concretely, the false positive rate is
low for a typical evaluation data distribution but much higher for a clinically-
representative data distribution, as shown in fig. in this work, we tackle these challenges and propose a multi-view and multi-
instance learning system, m&m. m&m is an end-to-end system that detects
malignant ﬁndings and provides breast-level classiﬁcation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_43.pdf,"this enables
a vit to achieve improved segmentation performance compared to traditional
convolutional neural networks (cnns) on plenty of segmentation tasks [16]. how-
ever, due to the lack of inductive biases, such as weight sharing and locality, vits
are more data-hungry than cnns, i.e., require more data to train [31]. [17] in brain mri."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_43.pdf,": we conduct
experiments on sota data-eﬃcient mis vits and multi-domain learning meth-
ods. we implement resnet-34 as the backbone of bat for fair
comparison (similar model size). as illustrated in table 2-a,b,c, these sota
models are superior to base in st."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_37.pdf,"mpbd-lstm: a predictive model
for colorectal liver metastases using
time series multi-phase
contrast-enhanced ct scans
xueyang li1, han xiao2, weixiang weng2, xiaowei xu3, and yiyu shi1(b)
1 university of notre dame, notre dame, usa
{xli34,yshi4}@nd.edu
2 the first aﬃliated hospital of sun yat-sen university, guangzhou, china
xiaoh69@mail.sysu.edu.cn, wengwx3@mail2.sysu.edu.cn
3 guangdong provincial people’s hospital, guangzhou, china
abstract. colorectal cancer is a prevalent form of cancer, and many
patients develop colorectal cancer liver metastasis (crlm) as a result."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_37.pdf,"– we already determined whether or not the patients had liver metastases
within 2 years after the surgery, and manually labeled the dataset based
on this.
– no potential focal infection in the liver before the colorectal radical surgery.
– no metastases in other organs before the liver metastases.
– no other malignant tumors. our retrospective dataset includes two cohorts from two hospitals. the ﬁrst
cohort consists of 201 patients and the second cohort includes 68 patients."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_37.pdf,"however, we found that such design actually resulted in a
worse performance. this issue will be demonstrated and discussed later in the
ablation study. in summary, the mpbd-lstm model comprises two planes, each of which
contains three 3d-lstm stacks with two modules in each stack."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_37.pdf,"notably, simvp [4] is the only cnn-based model we tested, while
all other models are lstm-based. our results suggest that lstm networks are
more eﬀective in handling temporal features for our problem compared with
cnn-based models. although the architecture of predrnn-v2 is
diﬀerent from mpbd-lstm, it potentially supports the eﬃcacy of jointly com-
puting spatiotemporal relations in diﬀerent timestamps.
386
x. li et al.
table 3. ablation study on bi-directional connection and multi-planes
model
auc score
mpbd-lstm w/o multi-plane
0.774
mpbd-lstm w/o bi-directional connection 0.768
mpbd-lstm w/inter-plane connections
0.786
mpbd-lstm
0.790
ablation study on model structures."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_47.pdf,"[9–11] are often used. however, dxa and ct
require special equipment that is much less accessible in a small clinic. further-
more, ct requires high radiation exposure, and dxa allows the measurement
of only overall body composition, which lacks details in individual muscles such
as the iliacus muscle, which overlays with the gluteus maximus muscle in dxa
images."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_47.pdf,"in this study, we propose mskdex: musculoskeletal (msk) decomposition
from a plain x-ray image for the ﬁne-grained estimation of lean muscle mass
and volume of each individual muscle, which are useful metrics for evaluating
muscle diseases including sarcopenia. figure 1 illustrates the meaning of our
ﬁne-grained muscle analysis and its challenges. the contribution of this paper
is three-fold: 1) proposal of the object-wise intensity-sum (owis) loss, a simple
yet eﬀective metric invariant to muscle deformation and projection direction, for
quantitative learning of the absolute volume and lean mass of the muscles, 2)
proposal of partially aligned training utilizing the aligned (paired) dataset for
the rigid object for the pixel-wise supervision in an unpaired image translation
task, 3) extensive evaluation of the performance using a 539-patient dataset."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_47.pdf,"(b) visualization of two
representative cases. patient #1 (young, male) and patient #2 (old, female) had similar
bmi and almost the same gluteus maximus volume, while the lean muscle mass was
signiﬁcantly diﬀerent, likely due to the fatty degeneration in patient #2, which was
clearly observable in the projections of the lean muscle mass volume.
fig. 2. overview of the proposed mskdex."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_47.pdf,"= e(ix,idrr)
1
nb

i∈k

λl1
g(ix)drr
i
− idrr
i

1
−gc(g(ix)drr
i
, idrr
i
)

,
(4)
where the k is a set of indexes containing aligned bone indexes. the nb is the
size of the set k. the λl1 tries to balance structural faithfulness and quantita-
tive accuracy. the full objective, aiming for realistic decomposition while
maintaining structural faithfulness and quantitative accuracy, is deﬁned as
l = min
g,f
max
dx,ddrrs

lup
gan + lgc + λislall
is + lall
b
	
,
(5)
where the λis re-weights the penalty on the proposed owis loss.
fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_47.pdf,"the average pcc for the muscles was improved from 0.457 to 0.826 by adding
the owis loss (λis = 100) and to 0.796 by adding the bone loss, while their
combination achieved the best average pcc of 0.855, demonstrating the supe-
rior ability of quantitative learning of the proposed mskdex. the results also
suggested that the weight balance for loss terms needs to be made to achieve the
best performance. more detailed results are shown in supplemental materials."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_62.pdf,"muvf-yolox: a multi-modal
ultrasound video fusion network for
renal tumor diagnosis
junyu li1,2,3, han huang1,2,3, dong ni1,2,3, wufeng xue1,2,3,
dongmei zhu4(b), and jun cheng1,2,3(b)
1 national-regional key technology engineering laboratory for medical
ultrasound, school of biomedical engineering, shenzhen university medical school,
shenzhen university, shenzhen, china
chengjun583@qq.com
2 medical ultrasound image computing (music) lab, shenzhen university,
shenzhen, china
3 marshall laboratory of biomedical engineering, shenzhen university, shenzhen,
china
4 department of ultrasound, the aﬃliated nanchong central hospital of north
sichuan medical college, nanchong, china
zdm596987@gmail.com
abstract. early diagnosis of renal cancer can greatly improve the sur-
vival rate of patients."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_62.pdf,"3
experimental results
3.1
materials and implementations
we collect a renal tumor us dataset of 179 cases from two medical centers,
which is split into the training and validation sets. we further collect 36 cases
from the two medical centers mentioned above (14 benign cases) and another
center (fujian provincial hospital, 22 malignant cases) to form the test set. each
case has a video with simultaneous imaging of b-mode and ceus-mode."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_62.pdf,"some
examples of the images are shown in fig. 2. there is an obvious visual diﬀerence
between the images from the fujian provincial hospital (last column in fig. 2)
and the other two centers, which raises the complexity of the task but can better
verify our method’s generalization ability."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_62.pdf,"this proves that complementary informa-
tion exists among diﬀerent modalities. for a fair comparison with other fusion
methods, we embed their fusion modules into our framework so that diﬀerent
approaches can be validated in the same environment. [17]
merge the multi-modal features or pick one of them by automatically generating
channel-wise weights for each modality."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_62.pdf,"the experimental results show that
the proposed method outperforms single-modal, single-frame, and other state-
of-the-art multi-modal approaches.
acknowledgment. our dataset was collected from the aﬃliated nanchong cen-
tral hospital of north sichuan medical college, shenzhen people’s hospital, and
fujian provincial hospital hospitals. this study was approved by local institu-
tional review boards."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_7.pdf,"mammo-net: integrating gaze
supervision and interactive information
in multi-view mammogram classiﬁcation
changkai ji1,2, changde du2, qing zhang3, sheng wang1,4,5, chong ma6,
jiaming xie7, yan zhou3, huiguang he1,2(b), and dinggang shen1,5,8(b)
1 school of biomedical engineering, shanghaitech university, shanghai, china
{jichk,dgshen}@shanghaitech.edu.cn, huiguang.he@ia.ac.cn
2 state key laboratory of multimodal artiﬁcial intelligence systems, institute of
automation, chinese academy of sciences, beijing, china
3 department of radiology, renji hospital shanghai jiao tong university school of
medicine, shanghai, china
4 institute for medical imaging technology, school of biomedical engineering,
shanghai jiao tong university, shanghai, china
5 shanghai united imaging intelligence co., ltd., shanghai, china
6 school of automation, northwestern polytechnical university, xi’an, china
7 department of computer science,
the university of hong kong, hong kong, china
8 shanghai clinical research and trial center, shanghai, china
abstract. breast cancer diagnosis is a challenging task."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_7.pdf,"however, the eﬀectiveness of deep neural net-
works is often limited by the lack of interpretability and the need for
signiﬁcant amount of manual annotations. to address these issues, we
present a novel approach by leveraging both gaze data and multi-view
data for mammogram classiﬁcation. the gaze data of the radiologist
serves as a low-cost and simple form of coarse annotation, which can pro-
vide rough localizations of lesions."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_7.pdf,"keywords: mammogram classiﬁcation · gaze · multi-view
interaction · bidirectional fusion learning
supplementary information the online version contains supplementary material
available at https://doi.org/10.1007/978-3-031-43990-2 7.
c
⃝ the author(s), under exclusive license to springer nature switzerland ag 2023
h. greenspan et al. https://doi.org/10.1007/978-3-031-43990-2_7
mammo-net for multi-view mammogram classiﬁcation
69
1
introduction
breast cancer is the most prevalent form of cancer among women and can have
serious physical and mental health consequences if left unchecked [5]. [19].
mammograms provide images of breast tissue, which are taken from two views:
the cranio-caudal (cc) view, and the medio-lateral oblique (mlo) view [4]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_7.pdf,"furthermore, there are diﬀerences
70
c. ji et al.
between multi-view mammograms of the same patient, arising from variations
in breast shape and density. capturing these multi-view shared features can be
a challenge for models. to address this issue, we develop a novel method called
bidirectional fusion learning (bfl) to extract shared features from multi-view
mammograms."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_7.pdf,"moreover, the pyramid representation enables the model to learn from the
important pathological regions on which radiologists are focusing, without the
need for precise pixel-level information. layernorm is also employed to address
the issue of imprecise gaze data. this reduces noise in the consistency process
by performing consistency loss only in the regions where radiologist spent most
time."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_7.pdf,"74
c. ji et al.
3.2
implementation details
we trained our model using the adam optimizer [10] with a learning rate of
10−4 (partly implemented by mindspore). to overcome the problem of limited
data, we employed various data augmentation techniques, including translation,
rotation, and ﬂipping. to address the problem of imbalanced classes, we utilized
a weighted loss function that assigns higher weights to malign cases in order
to balance the number of benign and malign cases."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_7.pdf,"[23] proposed a resnet-based
model with class activation mapping guided by eye gaze data. we developed a
multi-view model using this approach for a fair comparison, and found that our
method performed better. we believe that one possible reason for the inferior
performance of ga-net compared to mammo-net might be the use of a simple
mse loss by ga-net, which neglects the coarse nature of the gaze data."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_7.pdf,"however, this model did not consider the gap between research
and clinical workﬂow. this model requires gaze input during both the training
and inference stages, which limits its practical use in hospitals without eye-
trackers. in contrast, our method does not rely on gaze input during inference
stage."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_41.pdf,"[2,18,19], resulting in signiﬁcant improvements in skin lesion segmenta-
tion performance. despite these advances, the segmentation of skin lesions with
ambiguous boundaries, particularly at extremely challenging scales, remains a
bottleneck issue that needs to be addressed. in such cases, even state-of-the-art
segmentation models struggle to achieve accurate and consistent results."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_41.pdf,"the small one covers
1.03% in the image space and the large one covers 72.96%. as studied prior,
solving the segmentation problems of such two types of lesions have diﬀerent
strategies. [18] can capture the long-range dependencies to improve the
boundary decision."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_41.pdf,"feeding more boundary-aware supervision
can reduce these negative eﬀects to some degree [2,19]. the latest transformer,
xbound-former, comprehensively addresses the multi-scale boundary problem
through cross-scale boundary learning and exactly reaches higher performance
on whatever small or large lesions. , current models for skin lesion segmentation are still struggling with
extremely challenging cases, which are often encountered in clinical practice."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_41.pdf,"evaluation metrics: to comprehensively compare the segmentation results,
particularly the boundary delineations, we employ four commonly used metrics
to quantitatively evaluate the performance of our segmentation methods. these
metrics include the dice score, the iou score, average symmetric surface dis-
tance (assd), and hausdorﬀ distance of boundaries (95−th percentile; hd95).
to ensure fair comparison, all labels and predictions are resized to (512×512)
before computing these scores, following the approach of a previous study [18].
3.2
implementation details
for the diﬀusion model hyper-parameters, we use the default settings of the plain
diﬀusion model, which can be found in the supplementary materials. regarding
medical boundary diﬀusion model
433
false negatives
true positves
false postives
image
u-net++
ca-net
transunet
mb-diff
(ours)
gt
transfuse
xbound-
former
medseg
diff
uncertainty
(ours)
fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_41.pdf,"[3], and especially the boundary-enhanced
method, x-boundformer [18]. [22], a recently released diﬀusion-based model, which we re-trained
for 200,000 steps to ensure a fair comparison. the quantitative results are shown in table 1, which reports four evaluation
scores for two datasets."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_41.pdf,"3(a),
where “w/o evo” refers to using image features to directly train a segmentation
model with fpn [11] architecture and “w/o fusion” means no evolution fusion is
used. to ensure a fair comparison, we average the scores of multiple evolutions
to represent the performance of “w/o fusion”. the results demonstrate that our
evolutionary approach can signiﬁcantly improve performance, and the evolution
uncertainty-based fusion strategy further enhances performance."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_39.pdf,"merging-diverging hybrid transformer
networks for survival prediction in head
and neck cancer
mingyuan meng1,2
, lei bi2(b)
, michael fulham1,3
, dagan feng1,4
,
and jinman kim1
1 school of computer science, the university of sydney, sydney, australia
2 institute of translational medicine, shanghai jiao tong university, shanghai, china
lei.bi@sjtu.edu.cn
3 department of molecular imaging, royal prince alfred hospital, sydney, australia
4 med-x research institute, shanghai jiao tong university, shanghai, china
abstract. survival prediction is crucial for cancer patients as it provides early
prognostic information for treatment planning."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_39.pdf,"our xsurv combines the complementary information
in pet and ct images and extracts the region-speciﬁc prognostic information
in pt and mln regions. extensive experiments on the public dataset of head
and neck tumor segmentation and outcome prediction challenge (hecktor
2022) demonstrate that our xsurv outperforms state-of-the-art survival prediction
methods. keywords: survival prediction · transformer · head and neck cancer
supplementary information the online version contains supplementary material available at
https://doi.org/10.1007/978-3-031-43987-2_39."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_39.pdf,"the process of radiomics feature extraction is
providedinthesupplementarymaterials.then,acoxphmodel[9]isadoptedtointegrate
the selected radiomics features and the xsurv-predicted survival score to make the ﬁnal
prediction. in addition, clinical indicators (e.g., age, gender) also can be integrated by
the coxph model. [7], while the testing dataset was excluded as its ground-truth labels are not released."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_39.pdf,"deepmtlr-coxph, icare, and radio-deepmts achieved top performance in
hecktor 2021 and 2022. for a fair comparison, all methods took the same pre-
processed images and clinical indicators as inputs. survival prediction and segmenta-
tion were evaluated using concordance index (c-index) and dice similarity coefﬁcient
(dsc), which are the standard evaluation metrics in the challenges [6, 7, 35]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_59.pdf,"mesh2ssm: from surface meshes
to statistical shape models of anatomy
krithika iyer1,2(b) and shireen y. elhabian1,2
1 scientiﬁc computing and imaging institute,
university of utah, salt lake city, ut, usa
krithika.iyer@utah.edu, shireen@sci.utah.edu
2 kahlert school of computing, university of utah, salt lake city, ut, usa
abstract. statistical shape modeling is the computational process of
discovering signiﬁcant shape parameters from segmented anatomies cap-
tured by medical images (such as mri and ct scans), which can fully
describe subject-speciﬁc anatomy in the context of a population."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_59.pdf,"we propose mesh2ssm, a new approach that leverages
unsupervised, permutation-invariant representation learning to estimate
how to deform a template point cloud to subject-speciﬁc meshes, form-
ing a correspondence-based shape model. mesh2ssm can also learn a
population-speciﬁc template, reducing any bias due to template selec-
tion. the proposed method operates directly on meshes and is computa-
tionally eﬃcient, making it an attractive alternative to traditional and
deep learning-based ssm approaches."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_59.pdf,"mesh2ssm leverages unsupervised, permutation-invariant representation learn-
ing to learn the low dimensional nonlinear shape descriptor directly from mesh
data and uses the learned features to generate a correspondence model of the
population. mesh2ssm also includes an analysis network that operates on the
learned correspondences to obtain a data-driven template point cloud (i.e., tem-
plate point cloud), which can replace the initial template, and hence reducing
the bias that could arise from template selection. furthermore, the learned rep-
resentation of meshes can be used for predicting related quantities that rely on
shape."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_59.pdf,"the
use of an autoencoder for meaningful feature extraction of meshes to learn the
pdm provides a versatile and scalable framework for ssm. [13,21] analysis module helps in mitigating bias and
capturing non-linear characteristics of the data. the method is demonstrated to
have superior performance in identifying shape variations using fewer parameters
on synthetic and clinical datasets."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_1.pdf,"general-purpose
real-time object detection models can mistakenly report obvious false
positives (fps) when applied to ultrasound videos, potentially mislead-
ing junior radiologists. [15]. to address this issue, we propose to extract contexts from
previous frames, including ntc, with the guidance of inverse optical
ﬂow. by aggregating extracted contexts, we endow the model with the
ability to suppress fps by leveraging ntc."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_1.pdf,"as shown in sect. 4.4, the inability to utilize ntc is
a key issue leading to the fps reported by general-purpose detectors.
to address this issue, we propose a novel ultradet model to leverage ntc. for each region of interest (roi) r proposed by a basic detector, we extract
temporal contexts from previous frames."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_1.pdf,"we provide a new version of high-quality labels
that are re-annotated by experienced radiologists. we reproduce all baselines
using our high-quality labels to ensure a fair comparison. visual comparisons
of two versions of labels are available in supplementary materials."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_1.pdf,"this conclusion agrees with
radiologists’ skills to focus more on local regions instead of global information. mining negative temporal contexts to suppress fps
11
5
conclusion
in this paper, we address the clinical challenge of real-time ultrasound lesion
detection. we propose a novel negative temporal context aggregation (ntca)
module, imitating radiologists’ diagnosis processes to suppress fps."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_46.pdf,"while the majority
of methods rely on separate learning stages, also end-to-end approaches have been pro-
posed [3,14]. in spite of the large amount of data, the number of labeled samples in mil
(represented by the number of individual, globally labelled wsis) is often small and/or
imbalanced [6]. general data augmentation strategies, such as rotations, ﬂipping, stain
augmentation and normalization and afﬁne transformations, are applicable to increase
the amount of data [15]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_46.pdf,"this method was originally proposed as data agnostic approach
which also shows good results if applied to image data [2,4,16]. variations were pro-
posed, to be applied to latent representations [17] as well as to balance data sets [6]. due to the structure of mil training data, we identiﬁed several options to perform
interpolation-based data augmentation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_46.pdf,"we actively decided not to use a self-supervised contrastive learning app-
roach [10] as feature extraction stage since invariant features could interfere with the
effect of data augmentation. we investigated various settings consisting of instance-
based only (inst), embedding-based only (emb) and the dual-stream approach with
weightings 3/1, 2/2 (balanced) and 1/3 for the instance and the embedding-based path-
ways. as comparison, several other augmentation methods on feature level are investi-
gated including random sampling, selective random sampling and random noise."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_46.pdf,"one half (40) of the data set consists of
frozen and the other half (40) of parafﬁn sections [5]), representing the different modal-
ities. all images were acquired during clinical routine at the kardinal schwarzenberg
hospital. procedures were approved by the ethics committee of the county of salzburg
(no. 1088/2021)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_46.pdf,"the mean and median age of patients at the date of dissection was
47 and 50 years, respectively. the data set comprised 13 male and 27 female patients,
corresponding to a slight gender imbalance. they were labeled by an expert pathologist
with over 20 years experience."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_46.pdf,"the
whole pipeline, including the separation, was repeated 32 times to achieve representa-
tive scores. due to the almost balanced setting, the overall classiﬁcation accuracy (mean
and standard deviation) is ﬁnally reported. adam was used as optimizer."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_46.pdf,"the considered dual-stream approach, including an embedding
and instance-based stream, exhibited slightly improved average scores, compared to
embedding-based mil only. in our analysis, we focused on the embedding-based con-
ﬁguration and on the balanced combined approach (referred to as 2/2). with the baseline
data augmentation approaches, the maximum improvements were 0.03, and 0.02 for the
frozen, and 0.01, and 0.05 for the parafﬁn data set."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_12.pdf,"imaging patients with inﬂammatory bowel disease (ibd) can
be especially problematic, owing to involuntary bowel movements and
diﬃculties with long breath-holds during acquisition. therefore, this
paper proposes a deep adversarial super-resolution (sr) reconstruction
approach to address the problem of multi-task degradation by utilizing
cycle consistency in a staged reconstruction model. we leverage a low-
resolution (lr) latent space for motion correction, followed by super-
resolution reconstruction, compensating for imaging artefacts caused by
respiratory motion and spontaneous bowel movements."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_12.pdf,"learned image reconstruction approaches are believed to
occasionally hide disease signs. we investigate this hypothesis by evalu-
ating a downstream task, automatically scoring ibd in the area of the
terminal ileum on the reconstructed images and show evidence that our
method does not suﬀer a synthetic domain bias. keywords: abdominal mr · motion correction · super-resolution ·
deep learning
supplementary information the online version contains supplementary material
available at https://doi.org/10.1007/978-3-031-43999-5 12.
c
⃝ the author(s), under exclusive license to springer nature switzerland ag 2023
h. greenspan et al."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_12.pdf,"this limits the assessment
of the complete volume in 3d. given these problems, we aim to develop a novel
method that can perform both motion correction (mc) and super-resolution
(sr) to improve the quality of 3d ibd mri and to support accurate interpre-
tation and diagnosis. motion can cause multiple issues for mr acquisition."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_12.pdf,"[18]
utilizes cyclic consistency structures to address unpaired degradation adaptation
in brain sr, however abdominal data would be more complicated and suﬀer
from motion corruption. joint optimization of mc and sr remains challenging
because of the high-dimensionality of hr image space, and lr latent space has
been introduced in order to alleviate this issue. recent studies on sr joint with
other tasks (e.g., reconstruction, denoising) have demonstrated improvements in
the lr space [11,19,20]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_12.pdf,"in this case, quality reconstruction
data is extremely important for the detection of relevant structures. 2
method
problem formulation and preliminaries: in 3d sr, the degradation pro-
cess is modeled with: ilr = d(ihr; ki, ↓s)+n, d() represents the downsampling
with the blur kernel ki, scaling factor s, and noise n. in this work, we propose
the motion corruption term m, which operates on lr latent space. and our
mc-sr model can be reﬁned to
ilr = m(d(ihr; ki, ↓s); z) + n
(1)
mocosr concept: as shown in fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_27.pdf,"in this paper, we make a ﬁrst attempt to explore a deep
learning method for unsupervised gland segmentation, where no man-
ual annotations are required. existing unsupervised semantic segmenta-
tion methods encounter a huge challenge on gland images. they either
over-segment a gland into many fractions or under-segment the
gland regions by confusing many of them with the background.
to overcome this challenge, our key insight is to introduce an empirical
cue about gland morphology as extra knowledge to guide the segmen-
tation process."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_27.pdf,"gland borders typically consist of dark-colored cells, whereas the interior epithe-
lial tissues contain cells with various color distributions that may closely resem-
ble those non-glandular tissues in the background. as such, the e2e clustering
methods tend to blindly cluster pixels with similar properties and confuse many
gland regions with the background, leading to under-segment results.
to tackle the above challenges, our solution is to incorporate an empir-
ical cue about gland morphology as additional knowledge to guide
gland segmentation. the cue can be described as: each gland is comprised
of a border region with high gray levels that surrounds the interior epithelial tis-
sues."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_27.pdf,"ultimately,
our method produces well-delineated and complete predictions; see fig. 1(b). our contributions are as follows: (1) we identify the major challenge encoun-
tered by prior unsupervised semantic segmentation (uss) methods when dealing
with gland images, and propose a novel mssg for unsupervised gland segmen-
tation. (2) we propose to leverage an empirical cue to select gland sub-regions
and explicitly group their semantics into a complete gland region, thus avoid-
ing over-segmentation and under-segmentation in the segmentation results."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_27.pdf,"consequently,
applying pixel-level cross-entropy loss between the gland image and the merged
proposal map could introduce undesired noise into the segmentation network,
thus leading to under-segment predictions with confusion between the glands and
the background. as such, we propose two types of morphology-aware semantic
grouping (msg) modules (i.e., msg for variation and msg for omission) to
respectively reduce the confusion caused by the two challenges mentioned above
and improve the overall accuracy and comprehensiveness of the segmentation
results. the details of the two msg modules are described as follows."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_27.pdf,"then,
we use the average of the pixel embeddings in gland border set g as the align-
ment anchor and pull all pixels of i towards the anchor:
lmsgv = 1
i

i∈i

i − 1
g

g∈g
g
2
. (3)
msg for omission is designed to overcome the problem of partial omis-
sion in the proposals. it identiﬁes and relabels the overlooked gland regions in
the proposal map and groups them back into the gland semantic category."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_27.pdf,"the network is trained for 20 epochs with an sgd optimizer, a learning
rate of 5e−3, and a batch size of 16. for a fair comparison, the results of all
288
q. zhang et al.
fig. 4. ablation study on msg modules."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_27.pdf,"more ablation tests on the spm (tab. 1 & 2) and
hyper-parameters (tab. 3) are in the supplementary material. 4
conclusion
this paper explores a dl method for unsupervised gland segmentation, which
aims to address the issues of over/under segmentation commonly observed in
previous uss methods. the proposed method, termed mssg, takes advantage
of an empirical cue to select gland sub-region proposals with varying appear-
ances."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_11.pdf,"in the context of machine learning, we often distinguish two types of uncer-
tainties: epistemic and aleatoric [13]. brieﬂy speaking, epistemic uncertainty
arises from imperfect knowledge of the model about the problem it is trained
to solve, whereas aleatoric uncertainty describes ignorance regarding the data
used for learning and making predictions. for example, if a classiﬁer has learned
to predict the presence of cancerous tissue on a colon histopathology, and it is
tasked with making a prediction on a breast biopsy it may display epistemic
uncertainty, as it was never trained for this problem [21]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_11.pdf,"in this work,
we design a weighting scheme to enforce the specialization of each head into a
particular subset of the categories {c1, ..., ck} in the training set. we ﬁrst assume that the multi-head model has less branches than the num-
ber of classes in our problem, i.e. m ≤ k, as otherwise we would need to have
diﬀerent branches specializing in the same category. if n is not divisible by k, the reminder categories are
assigned for specialization to random branches."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_11.pdf,"this
can be quantiﬁed by the expected calibration error (ece), given by:
ece =
n

s=1
|bs|
n |acc(bs) − conf(bs)|,
(5)
where 
s bs form a uniform partition of the unit interval, and acc(bs), conf(bs)
are accuracy and average conﬁdence (maximum softmax value) for test samples
predicted with conﬁdence in bs.
in practice, the ece alone is not a good measure in terms of practical usabil-
ity, as one can have a perfectly ece-calibrated model with no predictive power
[29]. a binary classiﬁer in a balanced dataset, randomly predicting always one
class with c = 0.5 + ϵ conﬁdence, has a perfect calibration and 50% accuracy. [9] that capture both discrimination abil-
ity and calibration: a model must be both accurate and calibrated to achieve a
low psr value."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_11.pdf,"2) kvasir2, a dataset for the task of endoscopic image
classiﬁcation. the annotated part of this dataset contains 10,662 images, and it
represents a challenging classiﬁcation problem due a high amount of classes (23)
and highly imbalanced class frequencies [2]. for the sake of readability we do not
show measures of dispersion, but we add them to the supplementary material
(appendix b), together with further experiments on other datasets."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_11.pdf,"inter-
estingly, methods that smooth labels (ls, mbls, mixup) show a strong
degradation in calibration and their ece is often twice the ece of the
baseline sl1h model. we attribute this to class imbalance and the large
number of categories: smoothing labels might be ineﬀective in this sce-
nario. note that models minimizing the dca loss do manage to bring
the ece down, although by giving up accuracy."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_44.pdf,"multi-modal pathological pre-training
via masked autoencoders for breast
cancer diagnosis
mengkang lu, tianyi wang, and yong xia(b)
national engineering laboratory for integrated aero-space-ground-ocean big data
application technology, school of computer science and engineering,
northwestern polytechnical university, xi’an 710072, china
yxia@nwpu.edu.cn
abstract. breast cancer (bc) is one of the most common cancers iden-
tiﬁed globally among women, which has become the leading cause of
death. multi-modal pathological images contain diﬀerent information for
bc diagnosis."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_44.pdf,"the pre-trained model
could be performed on multiple relevant tasks (ihc reconstruction and
ihc classiﬁcation). the experiments on two datasets (herohe chal-
lenge and bci challenge) show state-of-the-art results. the patholog-
ical process is usually the golden standard approach for bc diagnosis, which
relies on leveraging diverse complementary information from multi-modal data."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_44.pdf,"to our best knowledge, this is the ﬁrst pre-training
work based on multi-modal pathological data.  we evaluate the proposed method on two public datasets as herohe chal-
lenge and bci challenge, which shows that our method achieves state-of-the-
art performance. multi-modal pathological pre-training via masked autoencoders
459
fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_44.pdf,"after the process
of the mixed attention module, h&e and her2 patch tokens are fed into the
modal-speciﬁc decoders respectively to reconstruct the original h&e image x′
and her2 image y ′. the reconstruction loss is computed by the mean squared
error between the original images x, y and the generative images x′, y ′, which
is computed as
lh&e = 1
t1
t1

i=1
| pi − p′
i |2, lher2 = 1
t2
t2

i=1
| qi − q′
i |2 . (3)
462
m. lu et al.
we use an adjustable hyperparameter θ to balance the losses of two modalities. the ﬁnal loss l is deﬁned as
l = θlh&e + (1 − θ)lher2
(4)
2.3
downstream tasks
the pre-trained encoder could be used for downstream tasks, as shown in fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_44.pdf,"[19] as the aggregator
in our training process. 3
experimental results
3.1
datasets
acrobat challenge. [27] provides h&e wsis and matched ihc wsis
(er, pr, her2, and ki67), which consists of 750 training cases, 100 valida-
tion cases, and 300 testing cases."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_44.pdf,"multi-modal pathological pre-training via masked autoencoders
463
table 1. performance comparison on bci challenge. her2 on h&e (herohe) challenge [9] is developed
to predict the her2 status in invasive bc cases via the analysis of he slides."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_44.pdf,"5.
her2 status prediction. we compare our method with the top ﬁve methods
reported in herohe challenge review [9]. most of these methods use the multi-
network ensemble strategy and extra datasets."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_58.pdf,"whole slide image (wsi) classiﬁcation is an essential task in com-
putational pathology. despite the recent advances in multiple instance learning
(mil) for wsi classiﬁcation, accurate classiﬁcation of wsis remains challeng-
ing due to the extreme imbalance between the positive and negative instances in
bags, and the complicated pre-processing to fuse multi-scale information of wsi.
to this end, we propose a novel multi-scale prototypical transformer (mspt)
for wsi classiﬁcation, which includes a prototypical transformer (pt) module
and a multi-scale feature fusion module (mffm). the pt is developed to reduce
redundant instances in bags by integrating prototypical learning into the trans-
former architecture."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_58.pdf,"with the advent of the whole slide image (wsi) scanner, deep learning has gained its
reputation in the ﬁeld of computational pathology [1–3]. however, wsis are extremely
large in the size and lack of pixel-level annotations, making it difﬁcult to adopt the
traditional supervised learning methods for wsi classiﬁcation [4].
to address this issue, multiple instance learning (mil) has been successfully applied
to the wsi classiﬁcation task as a weakly supervised learning problem [5–7]. in this
context, a wsi is considered as a bag, and the cropped patches within the slide are the
supplementary information the online version contains supplementary material available at
https://doi.org/10.1007/978-3-031-43987-2_58."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_58.pdf,"however, the lesion regions usually only account for a small por-
tion of the wsi, resulting in a large number of negative patches. when the positive and
negative instances in the bag are highly imbalanced, the mil models are prone to incor-
rectly discriminate these positive instances when using simple aggregation operations. [9],
apply variants of the attention mechanism to re-weight instance features."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_58.pdf,"it can effec-
tively capture multi-scale information in wsi to improve the performance of wsi
classiﬁcation. 2
method
2.1
mil problem formulation
mil is a typical weakly supervised learning method, where the training data consists
of a set of bags, and each bag contains multiple instances. the goal of mil is to learn
a classiﬁer that can predict the label of a bag based on the instances in it."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_58.pdf,"however,
the wsi dataset generally has a long sequence of instances, which makes the clustering
algorithms computationally expensive and slow down as the size of the bag increases. to solve the issue above, we propose to apply the self-attention (sa) mechanism in
transformer to re-calibrate these cluster prototypes. as shown in fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_55.pdf,"during inference, the extracted
embeddings are used to generate a cascade of cosine similarity maps that initially locate
the corresponding location in a follow-up image within a larger area and subsequently
improve the matching accuracy through gradual reﬁnement.
time points. classical methods to solve this problem rely on image registration,
where tracking is performed via image alignment and rule-based correspondence
matching [15,16,21]. these approaches are diﬃcult to optimize, especially when
scaling across diﬀerent body regions and ﬁelds of view."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_55.pdf,"to overcome this, we propose
to train a pixel-wise multi-scale embedding model that accounts for anatomical
similarity among diﬀerent subjects, making the embeddings more eﬀective. 3
method
3.1
problem deﬁnition
let i1 (i.e., template or baseline image) and i2 (i.e., query or follow-up image)
be two 3d-ct scans acquired at time t1 and t2, respectively, additionally, let p1
576
a. vizitiu et al.
and p2 denote the point of interest (i.e., the lesion center) in both images. the
problem of lesion tracking can be formulated as ﬁnding the optimal transforma-
tion that maps p1 to its corresponding location, p2, in i2.
3.2
training stage
let d = {x1, x2, ..., xn} be a set of n unpaired and unlabeled 3d-ct volumes."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_72.pdf,"multi-scope analysis driven hierarchical
graph transformer for whole slide
image based cancer survival prediction
wentai hou1, yan he2, bingjian yao2, lequan yu3, rongshan yu2,
feng gao4, and liansheng wang2(b)
1 department of information and communication engineering at school of
informatics, xiamen university, xiamen, china
houwt@stu.xmu.edu.cn
2 department of computer science at school of informatics,
xiamen university, xiamen, china
{yanhe56,yaobingjian}@stu.xmu.edu.cn, {rsyu,lswang}@xmu.edu.cn
3 department of statistics and actuarial science,
the university of hong kong, hong kong sar, china
lqyu@hku.hk
4 the sixth aﬃliated hospital, sun yat-sen university, guangzhou, china
gaof57@mail.sysu.edu.cn
abstract. cancer survival prediction requires considering not only the
biological morphology but also the contextual interactions of tumor and
surrounding tissues."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_72.pdf,"⎞
⎠ ,
(6)
where δi denote the censorship of i-th patient, o(i) and o(j) denote the survival
output of i-th and j-th patient in a batch, respectively.
3
experiments
3.1
experimental settings
dataset. in this study, we used a colorectal cancer (crc)(385 cases)
cohort collected from co-operated hospital to evaluate the proposed method. moreover, two public cancer cohorts from tcga project, i.e., liver hepato-
cellular carcinoma (lihc)(371 cases) and kidney clear cell carci-
noma (kirc)(398 cases) are also included as the censorship of these two
data sets are relatively balanced."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_72.pdf,"“-” denotes that the algorithm cannot be executed in
this cohort due to memory overﬂow. w/o transformer
0.592 ± 0.010
0.647 ± 0.002
0.616 ± 0.005
ours
hgt
0.607 ± 0.004 0.657 ± 0.003 0.646 ± 0.003
752
w. hou et al.
3.3
interpretability of the proposed framework
we selected the crc dataset for further interpretable analysis, as it is one of the
leading causes of mortality in industrialized countries, and its prognosis-related
factors have been widely studied [3,8]. background (back); debris (deb); lymphocytes (lym); mucus
(muc); muscle (mus); normal colon mucosa (norm); stroma (str); tumor
(tum)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_52.pdf,
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_62.pdf,"multitalent: a multi-dataset approach to
medical image segmentation
constantin ulrich1,4,5(b), fabian isensee1,2, tassilo wald1,2,
maximilian zenk1,5, michael baumgartner1,2,6, and klaus h. maier-hein1,3
1 division of medical image computing, german cancer research center (dkfz),
heidelberg, germany
constantin.ulrich@dkfz-heidelberg.de
2 helmholtz imaging, dkfz, heidelberg, germany
3 pattern analysis and learning group, department of radiation oncology,
heidelberg university hospital, heidelberg, germany
4 national center for tumor diseases (nct), nct heidelberg, a partnership
between dkfz and university medical center heidelberg, heidelberg, germany
5 medical faculty heidelberg, university of heidelberg, heidelberg, germany
6 faculty of mathematics and computer science, heidelberg university,
heidelberg, germany
abstract. the medical imaging community generates a wealth of data-
sets, many of which are openly accessible and annotated for speciﬁc
diseases and tasks such as multi-organ or lesion segmentation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_62.pdf,"we employ three diﬀerent network architectures,
which are further described below, to demonstrate that our approach is applica-
ble to any network topology. to solve the label contradiction problem we decou-
ple the segmentation outputs for each class by applying a sigmoid activation
function instead of the commonly used softmax activation function across the
dataset. but it has indepen-
dent segmentation head parameters θc for each class."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_62.pdf,"to demonstrate the general applicability of this app-
roach, we applied it to three segmentation networks. we employed a 3d u-net
[24], an extension with additional residual blocks in the encoder (resenc u-net),
that demonstrated highly competitive results in previous medical image segmen-
tation challenges [14,15] and a recently proposed transformer based architecture
(swinunetr [29]). we implemented our approach in the nnu-net framework
[13]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_62.pdf,"this should serve as additional
external validation of our model. to ensure fair comparability, we did not scale
up any models. despite using gradient checkpointing, the swinunetr models
requires roughly 30 gb of gpu memory, compared to less than 17 gb for the
cnns.
3
results
multi-dataset training results are presented in fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_71.pdf,"[4]
that employs dense connections between two convolutional paths, and achieves
multimodal ct and mr segmentation of han oars
747
improvements compared to other fusion strategies and single modality variants. however, other studies have shown that the best fusion strategy depends on
the speciﬁc nature of the problem, e.g. yan et al. [22] demonstrated that the
late fusion outperforms the other two approaches for the longitudinal detection
of diabetic retinopathy."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_71.pdf,"although the methodologies comprising cyclegans and/or
multiple segmentation networks [10,19] seem promising, they can be excessively
complex for the task of han oar segmentation where both ct and mr image
modalities from the same patient are often available. consequently, our primary
focus is the paired multimodal segmentation problem, including the missing
modality scenario.
motivation. when segmenting oars in the han region for the purpose of rt
planning, a multimodal segmentation model that can leverage the information
from ct and mr images of the same patient might be beneﬁcial compared to
separate single-modal models."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_71.pdf,"an important repercus-
sion is that image registration errors propagate into oar delineations, which
is particularly salient in the han region. to address these challenges, we pro-
pose an upgraded nnu-net network with two separate encoders, one for each
modality, and a common decoder that fuses fms using the proposed mfm that
learns to infer aﬃne transformation parameters in a single forward pass. this
approach eﬃciently pseudo-registers fms from the mr encoder with those from
the ct encoder, mitigating the eﬀects of registration errors caused by non-rigid
deformation of oars and imaging artifacts.
modality fusion module."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_71.pdf,"although only a subset of images is publicly available1 due
to the ongoing han-seg challenge2, both the publicly available training as well
as the privately withheld test images were used in our 4-fold cross-validation
experiments. on the other hand, to evaluate the generalization ability of our
method, we also conducted experiments on the ct-only pddca dataset (for
details, please refer to [15]), from which we collected 15 images from the oﬀ-
and on-site test sets of the corresponding challenge for our evaluation. as this
dataset is widely used for evaluating the performance of automatic han oar
segmentation methods, it serves as a valuable benchmark for comparison with
other state-of-the-art methods."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_71.pdf,"the same modiﬁcation was also
used with the maml model. to ensure a fair model comparison, we set the
number of ﬁlters in the encoder of the single modality baseline model to match
the number of ﬁlters of the entry-level concatenation encoder. we also halved
the number of ﬁlters in networks that have separate encoders so that the overall
number of parameters in the proposed model and the baselines remains approx-
imately the same (excluding the parameters in the localization part of mfm
1 https://doi.org/10.5281/zenodo.7442914."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_71.pdf,"note that the maml model, which is composed of two u-nets, had a
considerably higher number of parameters. to address the challenge of a rela-
tively small dataset, we adopted a 4-fold cross-validation strategy without using
any external training images. all models were trained until convergence, i.e.
when the validation loss plateaued, and we selected the model with the best
validation loss for inference.
results."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_28.pdf,"multiple prompt fusion for zero-shot
lesion detection using vision-language
models
miaotian guo1, huahui yi2, ziyuan qin2, haiying wang1, aidong men1,
and qicheng lao1,3(b)
1 school of artiﬁcial intelligence, beijing university of posts
and telecommunications, beijing, china
qicheng.lao@bupt.edu.cn
2 west china biomedical big data center, west china hospital, sichuan university,
sichuan, china
3 shanghai artiﬁcial intelligence laboratory, shanghai, china
abstract. the success of large-scale pre-trained vision-language models
(vlm) has provided a promising direction of transferring natural image
representations to the medical domain by providing a well-designed
prompt with medical expert-level knowledge."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_28.pdf,"besides, the models pre-trained with natu-
ral images fail to detect lesions precisely. to solve this problem, fusing
multiple prompts is vital to assist the vlm in learning a more compre-
hensive alignment between textual and visual modalities. in this paper,
we propose an ensemble guided fusion approach to leverage multiple
statements when tackling the phrase grounding task for zero-shot lesion
detection."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_28.pdf,"in addition, each
keyword in a single lengthy prompt cannot take eﬀect equally as we expect,
where the essential information can be ignored. this problem motivates us to
study alternative approaches with multiple prompt fusion. in this work, instead of striving to design a single satisfying prompt, we
aim to take advantage of pre-trained vlms in a more ﬂexible way with the
form of multiple prompts, where each prompt can elicit respective knowledge
from the model which can then be fused for better lesion detection performance."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_28.pdf,"here we present part of the single prompts used in the experiments
for illustration. the misclassiﬁcation problem in some of the single prompts is corrected
(i.e., malignant to benign) on the ﬁrst dataset. for all datasets, the candidate boxes
are more precise and associated with higher conﬁdence scores."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_76.pdf,"a correct diagnosis,
therefore, is dependent on the pathologist’s training and prior exposure to a
wide variety of disease subtypes [30]. this presents a challenge, as some dis-
ease variants are extremely rare, making visual identiﬁcation diﬃcult. in recent
years, deep learning methods have aimed to alleviate this problem by designing
discriminative frameworks that aid diagnosis [15,28]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_76.pdf,"https://doi.org/10.1007/978-3-031-43987-2_76
nasdm: nuclei-aware histopathology image generation
787
be used to generate histopathology images with speciﬁc characteristics, such as
visual patterns identifying rare cancer subtypes [4]. as such, generative models
can be sampled to emphasize each disease subtype equally and generate more
balanced datasets, thus preventing dataset biases getting ampliﬁed by the mod-
els [7]. generative models have the potential to improve the pedagogy, trustwor-
thiness, generalization, and coverage of disease diagnosis in the ﬁeld of histology
by aiding both deep learning models and human pathologists."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_76.pdf,"several gan-based generative
models have been proposed to generate histology patches [16,31,33]. however,
gans suﬀer from problems of frequent mode collapse and overﬁtting their dis-
criminator [29]. it is also challenging to capture long-tailed distributions and
synthesize rare samples from imbalanced datasets using gans."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_76.pdf,"to use
the data exhaustively, patching is performed with a 50% overlap in neighboring
patches. as such, at (1) 20× we extract a total of 54,735 patches for training
and 4,991 patches as a held-out set, while at (2) 20× magniﬁcation we generate
12,409 training patches and 655 patches are held out.
3.2
stain normalization
a common issue in deep learning with h&e stained histopathology slides is the
visual bias introduced by variations in the staining protocol and the raw mate-
rials of chemicals leading to diﬀerent colors across slides prepared at diﬀerent
labs [1]. as such, several stain-normalization methods have been proposed to
tackle this issue by normalizing all the tissue samples to mimic the stain dis-
tribution of a given target slide [17,23,26]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_46.pdf,"this technique results in the emergence of
aliasing artifacts caused by the low number of projection images per bin,
which severely impacts the image quality and limits downstream use. previous attempts to address this problem relied on traditional algo-
rithms, while only recently deep learning techniques are being employed. in this work, we propose noise2aliasing, which reduces both view-
aliasing and statistical noise present in 4dcbct scans."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_46.pdf,"cone beam ct (cbct) is the most widely used imaging modality for igrt.
supplementary information the online version contains supplementary material
available at https://doi.org/10.1007/978-3-031-43999-5 46.
c
⃝ the author(s), under exclusive license to springer nature switzerland ag 2023
h. greenspan et al. https://doi.org/10.1007/978-3-031-43999-5_46
482
s. papa et al.
a major challenge especially for cbct imaging of the thorax and upper-
abdomen is the respiratory motion that introduces blurring of the anatomy,
reducing the localization accuracy and the sharpness of the image. a technique used to alleviate motion artifacts is respiratory correlated
cbct (4dcbct) [16]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_46.pdf,"in 4dcbcts this is not the case, as separate respira-
tory phases are being reconstructed, where the organs are in diﬀerent positions. we can address this problem by carefully choosing subsets of projections that
result in respiratory-uncorrelated reconstructions. the reconstructions will dis-
play organs in their average position and, therefore, have the same underlying
structure."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_46.pdf,"the ﬁrst is the traditional fdk
obtained using rtk [13]. the second is the supervised approach proposed by
[6], where we replace the model with the msd, for a fair comparison. in the
supervised approach, the model is trained by using as input reconstructions
obtained from subsets deﬁned with pseudo-average subset selection while the
targets use all of the projections available."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_46.pdf,"we thank celia juan de la cruz, nikita
moriakov, xander staal, and jonathan mason for helping during the development
of this work. this work was funded by rov with grant number pps2102 and elekta oncology
ab and was supported by an institutional grant of the dutch cancer society and the
dutch ministry of health."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_1.pdf,"existing al methods cannot work well in
this scenario because they tend to select a large number of non-target
samples. in this paper, we formulate this scenario as an open-set al
problem and propose an eﬃcient framework, openal, to address the
challenge of querying samples from an unlabeled pool with both target
class and non-target class samples. experiments on ﬁne-grained classiﬁ-
cation of pathology images show that openal can signiﬁcantly improve
the query quality of target class samples and achieve higher performance
than current state-of-the-art al methods."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_1.pdf,"however, obtaining large amounts of high-quality annotated data
is usually expensive and time-consuming, especially in the ﬁeld of pathology
image processing [5,12–14,18]. therefore, a very important issue is how to obtain
the highest model performance with a limited annotation budget. l. qu and y. ma—contributed equally."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_1.pdf,"existing al methods cannot accurately
distinguish whether the samples are from the target classes or not, thus querying a
large number of non-target samples and wasting the annotation budget, while our
method can accurately query samples from the target categories. (color ﬁgure online)
active learning (al) is an eﬀective approach to address this issue from a
data selection perspective, which selects the most informative samples from an
unlabeled sample pool for experts to label and improves the performance of the
trained model with reduced labeling cost [1,2,9,10,16,17,19]. [11]. figure 1 shows an al
scenario for pathology image classiﬁcation in an open world, which is very com-
mon in clinical practice."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_1.pdf,"since the non-
target patches are not necessary for training the classiﬁer, labeling them would
waste a large amount of budget. we call this scenario in which the unlabeled pool
consists of both target class and non-target class samples open-set al problem. most existing al algorithms can only work in the closed-set setting."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_1.pdf,"in contrast, our method uses a novel feature-based
target sample selection strategy and achieves the best performance. upon analysis, our openal is capable of eﬀectively maintaining the balance
of sample numbers across diﬀerent classes during active learning. we visualize
the cumulative sampling ratios of openal for the target classes in each round
10
l. qu et al.
fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_1.pdf,"b. cumulative sampling ratios of lfosa on the original dataset (under 33%
matching ratio). c. cumulative sampling ratios of our openal on a newly-constructed
more imbalanced setting for the target classes lym (6000 samples), norm (3000
samples), and tum (9000 samples). on the original dataset with a 33% matching ratio, as shown in fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_1.pdf,"it can be observed that in the ﬁrst 4 rounds, lym
samples are either not selected or selected very few times. this severe sample
imbalance weakens the performance of lfosa compared to random selection
initially. conversely, our method selects target class samples with a more bal-
openal
11
anced distribution."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_1.pdf,"4
conclusion
in this paper, we present a new open-set scenario of active learning for pathology
image classiﬁcation, which is more practical in real-world applications. we pro-
pose a novel al framework for this open-set scenario, openal, which addresses
the challenge of accurately querying the most informative target class samples
in an unlabeled sample pool containing a large number of non-target samples. openal signiﬁcantly outperforms state-of-the-art al methods on real pathol-
ogy image classiﬁcation tasks."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_58.pdf,
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_1.pdf,"to address this dilemma, pet enhancement
methods have been developed by improving the quality of low-dose pet
(lpet) images to standard-dose pet (spet) images. however, previ-
ous pet enhancement methods rely heavily on the paired lpet and
spet data which are rare in clinic. thus, in this paper, we propose
an unsupervised pet enhancement (upete) framework based on the
latent diﬀusion model, which can be trained only on spet data."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_1.pdf,"subsequently, with the devel-
opment of deep learning, the end-to-end pet enhancement networks [9,14,21]
were proposed and achieved signiﬁcant performance improvement. but these
supervised methods relied heavily on the paired lpet and spet data that are
rare in actual clinic due to radiation exposure and involuntary motions (e.g., res-
piratory and muscle relaxation). [17]
were developed to overcome this limitation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_1.pdf,"therefore, when
a diﬀusion model (trained only on spet) can recover noisy samples to spet,
this model can also recover lpet to spet. however, extending the diﬀusion
model developed for 2d photographic images to pet enhancement still faces two
problems: a) three-dimensionsal (3d) pet images will dramatically increase the
computational cost of diﬀusion model; b) pet is the detail-sensitive images and
may be introduced/lost some details during the procedure of adding/removing
noise, which will aﬀect the downstream diagnosis. taking all into consideration, we propose the spet-only unsupervised pet
enhancement (upete) framework based on the latent diﬀusion model."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_1.pdf,"then zct is fed into a denoising attention u-net [16] at each step for
calculation of cross-attention, where the query q and key k are calculated from
zct while the value v is still calculated from the output of the previous layer
because our ﬁnal goal is spet estimation. denoting the output of previous layer
as zp et , the ct-guided cross-attention can be formulated as follows:
output = softmax(qct kt
ct
√
d
+ b) · vp et ,
qct = convq(zct ),
kct = convk(zct ),
vp et = convv (zp et ),
(2)
where d is the number of channels, b is the position bias, and conv(·) denotes
the 1 × 1 × 1 convolution with stride of 1.
2.3
implementation details
typically, the trained diﬀusion model generates target images from random
noise, requiring a large number of steps t to make the ﬁnal perturbed sam-
ple (zt ) close to pure noise. however, in our task, the target spet image is
generated from a given lpet image during testing, and making zt as close to
pure noise as possible is not necessary since the remaining pet-related informa-
tion can also beneﬁt the image recovery."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_51.pdf,"in real-world scenarios, point annotation locations may shift from nuclei centers
as a result of the expert labeling process, leading to a lower performance after
model training. to overcome these challenges, we propose a novel weakly supervised instance
segmentation method that eﬀectively distinguishes adjacent nuclei and is robust
to point shifts. the proposed model consists of three modules responsible for
binary segmentation, boundary delineation, and instance separation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_51.pdf,"w and h are the
width and height of the input image. to train the module we employ a focal
loss, commonly used in point detection problems. if c(x, y) = 1
(1 − c(x, y))β( ˆc(x, y))αlog(1 − ˆc(x, y))
otherwise,
(3)
where np denotes the number of point labels."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_51.pdf,"we used 16 images (4 images from the
breast, liver, kidney, and prostate) as training and 14 images (2 images from each
breast, liver, kidney, prostate, bladder, brain, and stomach) as testing. for a fair
comparison, images were pre-processed before training/testing i.e., normalized
and cropped to 250×250 patches following the setting used in [17].
534
s. nam et al.
to make point labels, we use the center point of full mask annotations. for
a realistic scenario, we generate shifted point label."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_20.pdf,"parse and recall: towards accurate lung
nodule malignancy prediction like
radiologists
jianpeng zhang1,4(b), xianghua ye2(b), jianfeng zhang1,4, yuxing tang5,
minfeng xu1,4, jianfei guo1,4, xin chen3, zaiyi liu3, jingren zhou1,4, le lu5,
and ling zhang5
1 damo academy, alibaba group, hangzhou, china
jianpeng.zhang0@gmail.com
2 the first aﬃliated hospital of college of medicine, zhejiang university,
hangzhou, china
hye1982@zju.edu.cn
3 guangdong provincial people’s hospital, guangzhou, china
4 hupan lab, hangzhou 310023, china
5 damo academy, alibaba group, new york, usa
abstract. lung cancer is a leading cause of death worldwide and early
screening is critical for improving survival outcomes."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_20.pdf,"1. in pare, a nodule is diagnosed
from two levels: ﬁrst parsing the contex-
tual information contained in the nodule
itself, and then recalling the previously
learned nodules to look for related clues. one of the major challenges of
lung nodule malignancy prediction is
the quality of datasets [6]. recent works have
focused on collecting pathologically
labeled data to develop reliable malig-
nancy prediction models [16,17,19]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_20.pdf,"[16] collated a
pathological gold standard dataset of
990 ct scans. another issue is most of
the studies focus on ldct for malig-
nancy prediction [10]. however, the
majority of lung nodules are incidentally detected by routine imaging other than
ldct [4,15], such as noncontrast chest ct (ncct, the most frequently per-
formed ct exam, nearly 40% [18])."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_20.pdf,"to fulﬁll both ldct and ncct screening needs, we curate a large-scale
lung nodule dataset with pathology- or follow-up-conﬁrmed benign/malignant
labels. for the ncct, we annotate over 4,029 nodules from
over 2,565 patients from our collaborating hospital. experimental results on sev-
eral datasets demonstrate that our method achieves outstanding performance on
both ldct and ncct screening scenarios."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_20.pdf,"the nodules with a diameter smaller
than 4mm were excluded. the in-house cohort was retrospectively collected
from 2,565 patients at our collaborating hospital between 2019 and 2022. unlike
nlst, this dataset is noncontrast chest ct, which is used for routine clinical
care."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_20.pdf,"the in-house test set has 1,437 (1,298 benign and 139
malignant) nodules from 452 patients. [2] challenge dataset, which is usually used for external validation
in previous work [6,11,24]. lungx contains 83 (42 benign and 41 malignant)
nodules, part of which (13 scans) were contrast-enhanced."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_60.pdf,"from these analyses, it is
increasingly recognized that the lack of ﬂexibility on model ﬁnetuning limits the
data utility of multimodal learning. meanwhile, the size of multimodal medical
datasets is not as large as natural vision-language datasets, which necessitates
the need for data-eﬃcient analytics to address the training diﬃculty.
to tackle above challenges, we propose a pathology-and-genomics multimodal
framework (i.e., pathomics) for survival prediction (fig. 1). we summarized
our contributions as follows."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_7.pdf,"patients and slides are equal: a
multi-level multi-instance learning
framework for pathological image
analysis
fei li1,2, mingyu wang1,2, bin huang1,2, xiaoyu duan4, zhuya zhang1,2,
ziyin ye3(b), and bingsheng huang1,2(b)
1 medical ai lab, school of biomedical engineering, shenzhen university medical
school, shenzhen university, shenzhen, china
huangb@szu.edu.cn
2 marshall laboratory of biomedical engineering, shenzhen university,
shenzhen, china
3 department of pathology, the first aﬃliated hospital, sun yat-sen university,
guangzhou, china
yeziyin@mail.sysu.edu.cn
4 department of pathology, the seventh aﬃliated hospital, sun yat-sen university,
shenzhen, china
abstract. in current pathology image classiﬁcation, methods mostly
rely on patch-based multi-instance learning (mil), which only consid-
ers the relationship between patches and slides."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_7.pdf,"however, in clinical
medicine, doctors use slide-level labels to summarize patient-level labels
as a diagnostic result, indicating the involvement of three levels of patch,
slide, and patient in actual pathology image analysis, which we refer to
as the multi-level multi-instance learning (ml-mil) problem. to address
this issue, we propose a novel and general framework called patients and
slides are equal (p&sre), inspired by the doctor’s diagnostic process of
repeatedly conﬁrming labels at the patient and slide level. in this frame-
work, we treat patients and slides as instances at the same level and use
transformers and attention mechanisms to build connections between
them."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_7.pdf,"the results show
that our method improves the performance of the baselines on both slide
and patient levels. our method provides a simple and eﬀective solution
to the common problem of ml-mil in medical clinical scenarios and has
broad potential applications. keywords: multiple instance learning · multi-level labels ·
pathology images · transformer
f. li, m. wang and b. huang—contribute equally to this work."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_7.pdf,"[2] is the primary analysis method used, which involves analyzing tasks
based on slide labels and patches. despite this, the clinical pathological analysis
presents certain challenges and complexities, with the ultimate diagnosis relying
on patients rather than slides. speciﬁcally, in clinical problems of pathological image analysis, doctors usu-
ally summarize patient-level labels based on slide labels as the diagnostic results
[1,6]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_7.pdf,"therefore, as shown in
fig. 1, actual pathological image analysis involves the relationships of patches,
slides, and patients, which is called a multi-level multi-instance learning (ml-
mil) problem. among them, for patients and slides, patients are bags while
slides are instances, and for slides and patches, slides are bags while patches are
instances."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_7.pdf,"this method is relatively simple, but the information
exchange between slides is not fully utilized, which may lead to errors in the sum-
mary result. the second method is to treat slide-patient as a new mil problem
according to the traditional mil thinking, where slides are regarded as instances
and patient labels as bags. although this method seems reasonable, the number
of patients is usually relatively small, and deep learning models usually require a
large amount of data for training."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_7.pdf,"our framework consists of two steps: ﬁrst, at the patch-slide level,
a common mil framework is used to train a mil neural network and obtain
p&sre: a ml-mil framework for pathological image analysis
65
fig. 1. description and solutions for the ml-mil problem. slide-level feature vectors; then, at the slide-patient level, we use self-attention
mechanisms to combine the slides of the same patient into patient-level feature
vectors, and treat these patient-level feature vectors together with all slide-level
feature vectors of the same patient as instances at the same level, which are
inputted into transformers for feature interaction and prediction of patient- and
slide-level labels."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_7.pdf,"we
conducted rigorous experiments on two datasets and demonstrated the eﬀective-
ness of our method. our contributions include:
1) proposing a novel general framework to address the unique “patch-slide-
patient” ml-mil problem in the medical ﬁeld. before this, no other frame-
work had directly tackled this speciﬁc problem, making our proposal a
ground-breaking step in the application of ml-mil in healthcare;
2) proposing a simple yet highly eﬀective method that leverages self-attention
mechanisms and transformer models to enhance the interaction between slide
and patient information."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_7.pdf,"w r and w o are transformation matrices. b1
and b2 are bias vectors. this update procedure is repeated for l layers, where
the t′
k are fed to the successive transformer layer."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_7.pdf,"for instance, we did
not explore the possibility of treating patches as an equivalent level to slides and
patients. the primary reason is that the vast number of patches required for
analysis is signiﬁcantly larger than that of slides and patients, which presents a
computational challenge for training. as a result, we have not yet explored this
avenue."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_7.pdf,"in the future, we plan to leverage clustering and active learning methods
to reduce the number of patches and enable the interaction of all three levels
with the transformer, which would further enhance the accuracy and eﬃciency
of our proposed method. 5
conclusion
this study proposes a highly scalable and versatile framework to address m-
mil problems. we ﬁrst classify the process from patch to slide to the patient
in medical pathology diagnosis as a multi-level mil problem."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_64.pdf,"however, the labeling process of medical images is tedious and time-
consuming. to address this problem, the common paradigm of transfer learning,
supplementary information the online version contains supplementary material
available at https://doi.org/10.1007/978-3-031-43907-0_64.
c
⃝ the author(s), under exclusive license to springer nature switzerland ag 2023
h. greenspan et al. [10,21,30].
compared with the distributed training across multiple centers, there are no
speciﬁc ethical issues or computational design of distributed/federated learning
frameworks with the “pre-train-then-ﬁne-tune” workﬂow."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_64.pdf,"this process is time-
consuming and laborious. however, most of these works
require source information available while medical images have more privacy and
ethical issues and fewer datasets are publicly available than natural images. considering the issues mentioned above, this work focused on source-free
pre-trained model selection for segmentation tasks in the medical image."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_64.pdf,"these methods have achieved
promising performance on classiﬁcation and regression tasks without fully con-
sidering the properties of medical image segmentation. first, unlike classiﬁcation
and regression problems that can use a single n-dimensional feature vector to rep-
resent each image, segmentation problems lack a global semantic representation,
which poses diﬃculties for direct transferability estimation. in addition, most
label-comparison-based methods [9,15,17,27] focus on the relationship between
the embeddings and downstream labels without exploring the eﬀectiveness of the
features themselves."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_64.pdf,"third, medical images face severe class imbalance problems,
with excessive diﬀerences between foreground and background. however, exist-
ing algorithms rarely give additional attention to the class imbalance problem. 676
y. yang et al.
fine-tune
performance
model bank 
dnn1
upstream data
downstream data
dnn2
dnn3
pre-train-then-fine-tune process
pre-train
match or not?"
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_64.pdf,"forward propagation
point sampling
class 1
class 2
class n
feature bank
framework of cc-fv method
feature unit sphere
feature analysis
estimation
estimation
transferability
estimation
source-free model selection problem
fine-tune
fig. 1. source-free model selection problem and the framework of our class
consistency with feature variety constraint(cc-fv) te method. our main goal is to
predict the performance of models in the model bank after ﬁne-tuning on downstream
tasks without actually ﬁne-tuning."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_64.pdf,"and σf k
j
and
σf k
j′ are covariance matrices of fk
j and fk
j′. compared to some commonly used
metrics like kl-divergence or bhattacharyya distance [17], wasserstein distance
is more stable during the computation of high-dimensional matrices because it is
unnecessary to compute the determinant or inverse of a high-dimensional matrix,
which can easily lead to an overﬂow in numerical computation. we calculate the
wasserstein distance of the distribution with voxels of the same class in a sample
pair comprised of every two samples in the dataset, and obtained the following
deﬁnition of class consistency ccons
ccons =
1
n(n − 1)
c

k=1

ij
w2(fk
i , fk
j )
(2)
given that 3d medical images are computationally intensive, and prone to
causing out-of-memory problems, in the sliding window inference process for
678
y. yang et al.
each case, we do not concatenate the output of each patch into the ﬁnal predic-
tion result, but directly sample from the patched output and concatenate them
into the ﬁnal sampled feature matrix. in the calculation of class consistency, we
only sample the foreground voxels with a pre-deﬁned sampling number which is
proportional to the voxel number of each class in the image because of the severe
class imbalance problem."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_64.pdf,"the feature vectors will be more
widely dispersed in the unit sphere if the hyperspherical energy (hse) is lower
[3]. as for semantic segmentation problems, the feature pyra-
mid structure is critical for segmentation results [14,29]. hence in our framework,
diﬀerent decoders’ outputs are upsampled to the size of the output and can be
used in the sliding window sampling process."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_64.pdf,"table 1 demonstrates that our method surpasses all the other methods. most
of the existing methods are inferior to ours because they are not designed for seg-
mentation tasks with a serious class imbalance problem. besides, these methods
rely only on single-layer features and do not make good use of the hierarchical
structure of the model."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_64.pdf,"we can easily ﬁnd that with models with a pre-training process
have a more compact intra-class distance and a higher ﬁne-tuning performance. 4
conclusion
in our work, we raise the problem of model selection for upstream and down-
stream transfer processes in the medical image segmentation task and analyze
682
y. yang et al. the practical implications of this problem."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_69.pdf,"generally, multiple instance learning (mil) is one of the most popular solu-
tions for wsi analysis [14,17,18]. mil methods regard wsi recognition as a
weakly supervised learning problem and focus on how to eﬀectively and eﬃciently
aggregate histopathological local features into a global representation. [8] to enhance the capacity of mil in structural informa-
tion mining."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_69.pdf,"typically, chen et al. [5] explored and posed a new challenge
referred to as slide-level self-learning and proposed hipt, which leveraged the
hierarchical structure inherent in wsis and constructed multiple levels of the
self-supervised learning framework to learn high-resolution image representa-
tions. this approach enables mil-based frameworks to take advantage of abun-
dant unlabeled wsis, further improving the accuracy and robustness of tumor
recognition."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_69.pdf,"however, hipt is a hierarchical learning framework based on a greedy train-
ing strategy. the bias and error generated in each level of the representation
model will accumulate in the ﬁnal decision model. moreover, the vit [6] back-
bone used in hipt is originally designed for nature sense images in ﬁxed sizes
whose positional information is consistent."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_69.pdf,"embedding the orientation information with a ﬁxed polar axis
will lead to ambiguities in various slides. to address this problem, we design a kernel reorientation (kro) strategy to
dynamically update the polar axis during the training. as shown in fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_1.pdf,"(6)
intuitively, idbp iteratively estimates the original image from the current
degraded image and makes a projection by constraining it with prior knowledge. although idbp oﬀers a ﬂexible way to solve image enhancement problems, it
still requires paired images to train the denoising operator [26].
pre-trained diﬀusion models
7
2.3
pre-trained diﬀusion models for plug-and-play medical image
enhancement
we introduce a plug-and-play framework by leveraging the beneﬁts of the diﬀu-
sion model and idbp algorithm. here we highlight two beneﬁts: (1) it removes
the need for paired images; and (2) it can simply apply the single pre-trained
diﬀusion model across multiple medical image enhancement tasks."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_1.pdf,"we fol-
lowed the degradation operator settings in ddnm. speciﬁcally, we used the
identity matrix i as the degradation operator for the denoising task and scaled
pre-trained diﬀusion models
9
the projection diﬀerence h†(hx0|t−y) with coeﬃcient σ to balance the informa-
tion from measurement y and denoising output x0|t. the downsampling opera-
tor implemented with torch.nn.adaptiveavgpool2d for the super-resolution task."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_54.pdf,"probabilistic modeling ensemble vision
transformer improves complex polyp
segmentation
tianyi ling1,2, chengyi wu2,3, huan yu2,4, tian cai5, da wang1,
yincong zhou2, ming chen2(b), and kefeng ding1(b)
1 department of colorectal surgery and oncology (key laboratory of cancer
prevention and intervention, china national ministry of education, key laboratory
of molecular biology in medical sciences, zhejiang province, china), the second
aﬃliated hospital, zhejiang university school of medicine, hangzhou, zhejiang,
china
dingkefeng@zju.edu.cn
2 department of bioinformatics, college of life sciences, zhejiang university,
hangzhou, zhejiang, china
mchen@zju.edu.cn
3 department of hepatobiliary and pancreatic surgery, the first aﬃliated hospital,
school of medicine, zhejiang university, hangzhou, zhejiang, china
4 department of thoracic surgery, the second aﬃliated hospital, school of
medicine, zhejiang university, hangzhou, zhejiang, china
5 department of hepatobiliary and pancreatic surgery, the second aﬃliated
hospital, zhejiang university school of medicine, hangzhou, zhejiang, china
abstract. colorectal polyps detected during colonoscopy are strongly
associated with colorectal cancer, making polyp segmentation a critical
clinical decision-making tool for diagnosis and treatment planning."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_54.pdf,"previous polyp segmentation net-
works based on supervised binary masks may have lacked global seman-
tic perception of polyps, resulting in a loss of capture and discrimination
capability for polyps in complex scenarios. to address this issue, we
propose a novel gaussian-probabilistic guided semantic fusion method
that progressively fuses the probability information of polyp positions
with the decoder supervised by binary masks. our probabilistic model-
ing ensemble vision transformer network(petnet) eﬀectively sup-
presses noise in features and signiﬁcantly improves expressive capabilities
at both pixel and instance levels, using just simple types of convolu-
tional decoders."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_54.pdf,"furthermore, transformer [3,17,19,20] models have also been proposed for
polyp segmentation, and achieve the state-of-the-art(sota) performance. despite signiﬁcant progress made by these binary mask supervised models,
challenges remain in accurately locating polyps, particularly in complex clinical
scenarios, due to their insensitivity to complex lesions and high false-positive
rates. more speciﬁcally, most polyps have an elliptical shape with well-deﬁned
boundaries."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_54.pdf,"however, this method has limitations in accurately segmenting
polyp boundaries, which are crucial for clinical decision-making. therefore, the primary challenge lies in enhancing polyp segmentation per-
formance in complex scenarios by precisely preserving the polyp segmentation
boundaries, while simultaneously maximizing the decoder’s attention on the
overall pattern of the polyps. in this paper, we propose a novel transformer-based polyp segmentation
framework, petnet, which addresses the aforementioned challenges and achieves
sota performance in locating polyps with high precision."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_54.pdf,"(7)
where n is the total number of binary decoders, lg represents the l1 loss
between the ground truth gaussian mask gg and gudb prediction mask pg. λ is a hyperparameter used to balance the binary and gaussian losses. further-
more, we employ intermediate decoder outputs to calculate auxiliary losses for
convergence acceleration.
578
t. ling et al.
3.3
evaluation metrics
conventional evaluation metrics for polyp segmentation are typically limited to
pixel-level calculations."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_23.pdf,"progressive attention guidance for whole
slide vulvovaginal candidiasis screening
jiangdong cai1, honglin xiong1, maosong cao1, luyan liu1, lichi zhang2,
and qian wang1(b)
1 school of biomedical engineering, shanghaitech university, shanghai, china
qianwang@shanghaitech.edu.cn
2 school of biomedical engineering, shanghai jiao tong university, shanghai, china
abstract. vulvovaginal candidiasis (vvc) is the most prevalent human
candidal infection, estimated to aﬄict approximately 75% of all women
at least once in their lifetime. it will lead to several symptoms includ-
ing pruritus, vaginal soreness, and so on."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_23.pdf,"keywords: whole slide image · vulvovaginal candidiasis ·
attention-guided
1
introduction
vulvovaginal candidiasis (vvc) is a type of fungal infection caused by candida,
which results in discomforting symptoms, including itching and burning in the
genital area [4,18]. it is the most prevalent human candidal infection, estimated
to aﬄict approximately 75% of all women at least once in their lifetime [1,20],
resulting in huge consumption of medical resources. [6] is one of the main tools for screening cervical abnormalities."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_23.pdf,"(2) in addition to occupying only
a small image space for each candida, the overall candida quantity in wsis is
also low compared to the number of other cells. the class imbalance makes it
diﬃcult to conduct discriminative learning and to ﬁnd candida. (3) the staining
of diﬀerent samples leads to the huge style gap between wsis."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_23.pdf,"while collecting
more candida data may contribute to a more robust network, such eﬀorts are
dwarfed by the inhomogeneity of wsis, which adds to the risk of overﬁtting. all
of the above issues make it diﬃcult for diagnostic models to focus on candida,
thus resulting in poor classiﬁcation performance and generalization capability. in this paper, we ﬁnd that the attention for a deep network to focus on can-
dida is the key to the high performance of the screening task."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_23.pdf,"that, the attention of the clas-
siﬁer may spread across the entire image, leading to overﬁtted training quickly. therefore, we argue that the detection and classiﬁcation tasks are comple-
mentary to solve our problem. particularly, we pre-train a detector and inherit
its advantages in the classiﬁer."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_23.pdf,"2.3
contrastive learning
as mentioned in sect. 1, the style gap is another problem, which makes over-
ﬁtting more severe. in this part, we adopt the strategy of contrastive learning
to alleviate such problems and further optimize the attention of the network."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_23.pdf,"(pt: pre-training; ssa: skip self-attention; cl: contrastive loss). dataset-small is balanced with 100
positive wsis and 100 negative wsis. we conduct a 5-fold cross-validation, and
the ratio of training, validation, and testing is 3:1:1."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_55.pdf,"supplementary information the online version contains supplementary material
available at https://doi.org/10.1007/978-3-031-43993-3_55.
c
⃝ the author(s), under exclusive license to springer nature switzerland ag 2023
h. greenspan et al. it is a challenge to infer
the nucleus types due to the diversity and unbalanced distribution of nuclei. thus, we aim to automatically classify cell nuclei in pathological images."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_60.pdf,", f(xn, p)]), y),
(7)
where only the parameters of the g(·) and the prompt p are optimized, while
the feature extractor model f(·) is frozen.
training the entire pipeline in an end-to-end fashion on gigapixel images is
infeasible using the current hardware. to address this issue, we utilize the patch
batching and gradient retaining techniques from [25]. as shown in fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_60.pdf,"table 1. comparison of accuracy and auroc on three datasets. reported metrics
(in %age) are the average across 3 runs. [7] for feature extraction."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_15.pdf,"radiomics-informed deep learning
for classiﬁcation of atrial fibrillation
sub-types from left-atrium ct volumes
weihang dai1
, xiaomeng li1(b)
, taihui yu2,3, di zhao4, jun shen2,3,
and kwang-ting cheng1
1 the hong kong university of science and technology, hong kong, china
eexmli@ust.hk
2 sun yat-sen university, guangzhou, china
3 sun yat-sen memorial hospital, guangzhou, china
4 chinese academy of sciences, beijing, china
abstract. atrial fibrillation (af) is characterized by rapid, irregu-
lar heartbeats, and can lead to fatal complications such as heart fail-
ure."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_15.pdf,"(6)
3
experiments
3.1
implementation details
dataset. we use a dataset of 172 patients containing 94 paaf and 78 peaf
cases collected from the sun yat-sen memorial hospital in china. ct volumes
are centered on the left atrium and normalized to between -1 and 1. roi masks
for eat are obtained through hounsﬁeld value thresholding between -250 and
0."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_15.pdf,"deep and hybrid volume-based
classiﬁcation methods [11,14,24] are adapted to our task since there are no
existing works for af sub-type classiﬁcation. we use the same encoder for all
deep architectures for fair comparison, except for methods that are architecture
speciﬁc. a na¨ıve feature concatenation method is used as our baseline for the
hybrid approach."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_15.pdf,"experiments on larger datasets or alternative tasks can also be
done to provide more empirical support, since current results show only slight
improvements over baseline. these issues may be addressed in future works. overall, our method is a novel way of combining radiomic and deep learning
approaches, and can be used to improve accuracy of peaf screening from ct
volumes for better preventive care of high-risk patients.
acknowledgement."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_33.pdf,"to demonstrate application, we perform
registration on a breast cancer patient case with a segmented tumor and compare
performance to other image-to-physical and image-to-image registration methods. we show comparable accuracy to a previously proposed image-to-physical reg-
istration method with improved computation time, making regularized kelvinlet
functions an attractive approach for image-to-physical registration problems. keywords: deformation · registration · elasticity · image-guidance · breast ·
ﬁnite element · kelvinlet
© the author(s), under exclusive license to springer nature switzerland ag 2023
h. greenspan et al. (eds.): miccai 2023, lncs 14228, pp."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_33.pdf,"image-to-physical registration methods that accurately model an elastic
soft-tissue environment while also complying with intraoperative data constraints is an
active ﬁeld of research. determining correspondences between imaging space and geo-
metric data is required for image-to-physical registration, but it is often an inexact and
ill-posed problem. deep learning image registra-
tion methods like voxelmorph have also been used for this purpose [10]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_33.pdf,"in this work, we propose an image-to-physical registration method that uses regu-
larized kelvinlet functions as a novel deformation basis for nonrigid registration. reg-
ularized kelvinlet functions are analytical solutions to the equations for linear elasticity
that we superpose to compute a nonrigid deformation ﬁeld nearly instantaneously [15].
346
m. ringel et al.
we utilize “grab” and “twist” regularized kelvinlet functions with a linearized iterative
reconstruction approach (adapted from [12]) that is well-suited for sparse data registra-
tion problems. sensitivity to regularized kelvinlet function hyperparameters is explored
on a supine mr breast imaging dataset."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_33.pdf,"however, practical use of eq. (3)
regularized kelvinlet functions to model linear elasticity
347
becomes numerically problematic in discretized problems because the displacement
and displacement gradient become indeﬁnite as x approaches x0. + b
r3 rrt
f = k(r)f
(3)
to address numerical singularity, regularization is incorporated with a new forcing
function eq."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_57.pdf,"reveal to revise: an explainable ai life
cycle for iterative bias correction
of deep models
frederik pahde1, maximilian dreyer1, wojciech samek1,2,3(b),
and sebastian lapuschkin1(b)
1 fraunhofer heinrich-hertz-institute, berlin, germany
{wojciech.samek,sebastian.lapuschkin}@hhi.fraunhofer.de
2 technische universit¨at berlin, berlin, germany
3 bifold – berlin institute for the foundations of learning and data,
berlin, germany
abstract. state-of-the-art machine learning models often learn spuri-
ous correlations embedded in the training data."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_57.pdf,"this poses risks when
deploying these models for high-stake decision-making, such as in medical
applications like skin cancer detection. to tackle this problem, we pro-
pose reveal to revise (r2r), a framework entailing the entire explain-
able artiﬁcial intelligence (xai) life cycle, enabling practitioners to iter-
atively identify, mitigate, and (re-)evaluate spurious model behavior with
a minimal amount of human interaction. in the ﬁrst step (1), r2r reveals
model weaknesses by ﬁnding outliers in attributions or through inspec-
tion of latent concepts learned by the model."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_57.pdf,"concretely, we apply
the methods of rrr, cdep and clarc for model correction, and (4)
(re-)evaluate the model’s performance and remaining sensitivity towards
the artifact. using two medical benchmark datasets for melanoma detec-
tion and bone age estimation, we apply our r2r framework to vgg,
resnet and eﬃcientnet architectures and thereby reveal and correct
real dataset-intrinsic artifacts, as well as synthetic variants in a con-
trolled setting. completing the xai life cycle, we demonstrate multiple
r2r iterations to mitigate diﬀerent biases."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_57.pdf,"code is available on https://
github.com/maxdreyer/reveal2revise. keywords: xai life cycle · bias identiﬁcation · model correction
1
introduction
deep neural networks (dnns) have successfully been applied in research
and industry for a multitude of complex tasks. this includes various medical
f. pahde and m. dreyer—contributed equally."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_57.pdf,"supplementary information the online version contains supplementary material
available at https://doi.org/10.1007/978-3-031-43895-0 56.
c
⃝ the author(s), under exclusive license to springer nature switzerland ag 2023
h. greenspan et al. https://doi.org/10.1007/978-3-031-43895-0_56
reveal to revise: an xai life cycle for iterative bias correction of dnns
597
fig. our r2r life cycle for revealing and revising spurious behavior of any pre-
trained dnn."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_57.pdf,"in contrast, global xai methods (e.g., [12,14]) reveal
general prediction strategies employed or features encoded by a model, which is
necessary for the identiﬁcation and understanding of systematic (mis-)behavior.
acting on the insights from explanations, various methods have been introduced
to correct for undesired model behavior [31]. while multiple approaches exist
for either revealing or revising model biases, only few combine both steps, to
be applicable as a framework. [13,25].
598
f. pahde et al.
to that end, we propose reveal to revise (r2r), an iterative xai life cycle
requiring low amounts of human interaction that consists of four phases, illus-
trated in fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_57.pdf,"[22], penalizing attention on
artifacts via ground truth masks automatically generated in step (2). the arti-
fact masks are further used for evaluation on a poisoned test set and to measure
the remaining attention on the bias. we demonstrate the applicability and high
automation of r2r on two medical tasks, including melanoma detection and bone
age estimation, using the vgg-16, resnet-18 and eﬃcientnet-b0 dnn architec-
tures."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_57.pdf,"dataset-intrinsic, as
well as synthetic artifacts in a controlled setting. lastly, we showcase the r2r life
cycle through multiple iterations, unveiling and unlearning diﬀerent biases. 2
related work
among other methods, e.g., leveraging auxiliary information [15,18,19,21],
or training on de-biased representations [4,16], shortcut unlearning is often
approached with xai."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_57.pdf,"most model correction methods require dense annotations, such as labels for
artifactual samples or artifact localization masks, which are either crafted heuris-
tically or by hand [13,20]. in our r2r framework, we automate the annotation
by following [2] for data labeling through spray outlier clusters, or by collecting
the most representative samples of bias concepts according to crp. the spatial
artifact localization is further automated by computing artifact heatmaps as out-
lined in sect."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_57.pdf,"3.1, thereby considerably easing the step from bias identiﬁcation
to correction. reveal to revise: an xai life cycle for iterative bias correction of dnns
599
existing works for model correction measure the performance on the original
or clean test set, with corrected models often showing an improved generaliza-
tion [13,20]. a more targeted approach for measuring the artifact’s inﬂuence is
the evaluation on poisoned data [25], for which r2r is well suited by using its
localization scheme to ﬁrst extract artifacts and to then poison clean test sam-
ples."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_57.pdf,"by precisely localizing artifacts, r2r further allows to measure the model’s
attention on an artifact through attribution heatmaps. 3
reveal to revise framework
our reveal to revise (r2r) framework comprises the entire xai life cycle, includ-
ing methods for (1) the identiﬁcation of model bias, (2) artifact labeling and local-
ization, (3) the correction of detected misbehavior, and (4) the evaluation of the
improved model. to that end, we now describe the methods used for r2r."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_57.pdf,"following [2,14],
we apply spray by clustering latent attributions computed through lrp. the
spray clusters then naturally allow us to label data containing the bias. we automate artifact localization by training a con-
cept activation vector (cav) hl to model the artifact in latent space of a layer
l, representing the direction from artifactual to non-artifactual samples obtained
from a linear classiﬁer."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_57.pdf,"1
(bottom center). 3.2
methods for model correction
in the following, we present the methods used for mitigating model biases.
clarc for latent space correction. methods from the clarc framework
correct model (mis-)behavior w.r.t."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_57.pdf,"
1
.
(4)
4
experiments
the experimental section is divided into the two parts of (1) identiﬁcation, miti-
gation and evaluation of spurious model behavior with various correction meth-
ods and (2) showcasing the whole r2r framework in an iterative fashion. reveal to revise: an xai life cycle for iterative bias correction of dnns
601
fig. 2. overview of artifacts with crp visualizations of corresponding concepts
zoomed-in using receptive ﬁeld information (top), input samples (middle), and cropped
out artifacts (bottom) using our artifact localization method."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_57.pdf,"see appendix a.1 for additional experiment details. 4.2
revealing and revising spurious model behavior
revealing bias: in the ﬁrst step of the r2r life cycle, we can reveal the use
of several artifacts by the examined models, including the well-known band-aid,
ruler and skin marker [6] and our synthetic clever hans for the isic dataset, as
shown in fig. 2 for vgg-16. here, we show concept visualizations and cropped
out artifacts based on our automatic artifact localization scheme described in
sect."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_57.pdf,"the “band-aid” use can be further identiﬁed via spray, as illustrated
in fig. besides the synthetic clever hans for bone age classiﬁcation, we
encountered the use of “l” markings, resulting from physical lead markers placed
by radiologist to specify the anatomical side. interestingly, the “l” markings are
larger for hands of younger children, as all hands are scaled to similar size [10],
oﬀering the model to learn a shortcut by estimating the bone age based on the
relative size of the “l” markings, instead of valid features."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_57.pdf,"note that artifacts might
overlap clinically informative features in poisoned samples, limiting the compa-
rability of poisoned and original test performance. as shown in tab. 1 (isic
2019) and appendix a.2 (bone age), we are generally able to improve model
behavior with all methods. the only exception is the synthetic artifact for vgg-
16, where only rrr mitigates the bias to a certain extent, indicating that
the artifact signal is too strong for the model."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_57.pdf,"interestingly,
despite successfully decreasing the models’ output sensitivity towards artifacts,
1 cdep is not applied to eﬃcientnets, as existing implementations are incompatible. reveal to revise: an xai life cycle for iterative bias correction of dnns
603
fig. the eﬀect of iterative model correction on relevances attributed to artifacts for
each iteration (left) and the band-aid artifact cluster from spray, which dissipates
after its correction step (right)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_57.pdf,"604
f. pahde et al.
5
conclusion
we present r2r, an xai life cycle to reveal and revise spurious model behavior
requiring minimal human interaction via high automation. to reveal model bias,
r2r relies on crp and spray. whereas spray automatically points out clever
hans behavior by analyzing large sets of attribution data, crp allows for a ﬁne-
grained investigation of spurious concepts learned by a model."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_57.pdf,"by automatically localizing artifacts, we successfully perform model revision,
thereby reducing attention on the artifact and leading to improved performance
on corrupted data. when applying r2r iteratively, we did not ﬁnd the emergence
of new biases, which, however, might happen if larger parts of the model are ﬁne-
tuned or retrained to correct strong biases. future research directions include the
application to non-localizable artifacts, and addressing fairness issues in dnns.
acknowledgements."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_3.pdf,"researchers have been motivated
to generate pseudo ct images from nac-pet images [2,7], or more directly,
26
y. pan et al.
to generate ac-pet images from nac-pet images [5,11]. since pseudo ct is
convenient to be integrated into conventional ac processes, generating pseudo
ct images is feasible in clinics for ac. the pseudo ct images should satisfy two-fold requests."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_3.pdf,"[3] that directly learns a mapping from nac-pet to
ct image with mae loss (denoted as u-net), (ii) a conventional gan-based
method [1,2] that uses the u-net as the backbone and employ the style-content
loss and adversarial loss as an extra constraint (denoted as cgan), and (iii)
an auxiliary gan-based method [10] that uses the ct-based segmentation (i.e.,
the simple thresholding s) as an auxiliary task for ct generation (denoted as
agan). for a fair comparison, we implemented these methods by ourselves in a
tensorflow platform with an nvidia 3090 gpu. all methods share the same
backbone structure as g∗ in fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_3.pdf,"secondly, agan achieves the worst
intensity similarity and anatomical consistency for some organs. such inconsis-
tent metrics suggest that the global intensity similarity may have a competing
relationship with anatomical consistency in the learning procedure, thus it is not
advisable to balance them in a single network. thirdly, cgan achieves better
anatomical consistency than u-net, but worse than aseg."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_61.pdf,"more importantly, this research
highlights the usage of fpe can eﬀectively replace skip connections by providing
more comprehensive multi-scale characteristics from full stages in encoder. to
further address the issue of high-level semantics being overwhelmed in the pro-
gressive feature fusion process, we also integrate a feature aggregation enhance-
ment (fae) module that aggregates the outputs of fpe from previous stages at
634
y. su et al.
decoder. moreover, we introduce gate mechanisms in both fpe and fae to ﬁlter
out redundant information, prioritizing informative features for eﬃcient feature
fusion."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_63.pdf,"the code is publicly available at https://
github.com/feimanman/cervical-abnormal-cell-detection. keywords: cervical abnormal cell detection · consistency learning ·
cervical cytologic images
1
introduction
cervical cancer is the second most common cancer among adult women. if diag-
nosed early, it can be eﬀectively treated and cured [19]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_63.pdf,"it is worth mentioning that all of the aforementioned
detection methods inevitably produce false positive results, which should be fur-
ther reﬁned by pathologists for manual checking or classiﬁcation models estab-
lished for automatic screening. to solve this problem, zhou et al. [23] proposed a
three-stage method including cell-level detection, image-level classiﬁcation, and
case-level diagnosis obtained by an svm classiﬁer."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_63.pdf,"[16]
for detection, xception, and patch-based models to boost classiﬁcation. although the above-mentioned attempts can improve the screening perfor-
mance signiﬁcantly, there are several issues that need to be addressed: 1) object
detection methods often require accurate annotated data to guarantee perfor-
mance with robustness and generalization. however, due to legal limitations, the
scarcity of positive samples, and especially the subjectivity diﬀerences between
cytopathologists for manual annotations [20], it is likely to generate noisy sam-
ples that aﬀect the performance of the detection model."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_63.pdf,"therefore, the visual
feature correlations between the target cells and their surroundings can provide
valuable information to aid the screening process, which also needs to be utilized
when designing the cervical abnormal cell detection network. to address these issues, we propose a novel method for cervical abnormal
cell detection using distillation from local-scale consistency reﬁnement. inspired
by knowledge distillation, we construct a pre-trained patch correction network
654
m. fei et al.
fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_63.pdf,"such a
656
m. fei et al.
design can enable retinanet to take the prediction score as references, and uti-
lize reﬁned scores from pcn to obtain more conﬁdent predictions. the ranking
loss optimizes the detection to generate higher conﬁdence scores than the pre-
vious prediction, thereby suppressing false positives and enabling the detection
network to better distinguish between positive and negative cells.
2.3
roi-correlation consistency (rcc) learning
in order to solve the problem of mismatched inputs to the detection and classiﬁ-
cation models, we add the roi align layer to the output of the fpn. however,
for cervical abnormal cell detection, normal and abnormal cells may have very
similar appearances, which might not be suﬃcient for conducting eﬀective dif-
ferentiation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_68.pdf,"https://doi.org/10.1007/978-3-031-43898-1_68
robust t-loss for medical image segmentation
715
knowledge that is often scarcely available [6]. in addition, medical image anno-
tations can be aﬀected by human bias and poor inter-annotator agreement [23],
further complicating the process. despite eﬀorts to obtain labels through auto-
mated mining [31] and crowd-sourcing methods [11], the quality of datasets
gathered using these methods remains challenging due to often high levels of
label noise."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_68.pdf,"in a random sample
of 504 images, 5.4% were labeled incorrectly or as other classes [10]. noisy labels are and will continue to be, a problem in medical datasets. this is a concern as label noise has been shown to decrease the accuracy of
supervised models [20,22,35], making it a key area of focus for both research
and practical applications."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_68.pdf,"in this work, we show that several traditional robust loss functions are vul-
nerable to memorizing noisy labels. to overcome this problem, we introduce a
novel robust loss function, the t-loss, which is inspired by the negative log-
likelihood of the student-t distribution. the t-loss, whose simplest formulation
features a single parameter, can adaptively learn an optimal tolerance level to
label noise directly during backpropagation, eliminating the need for additional
computations such as the expectation maximization (em) steps.
to evaluate the eﬀectiveness of the t-loss as a robust loss function for medi-
cal semantic segmentation, we conducted experiments on two widely-used bench-
mark datasets in the ﬁeld: one for skin lesion segmentation and the other for lung
segmentation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_4.pdf,"however, label-eﬃcient solutions from weak supervision
like scribbles are rarely explored yet primarily meaningful and demand-
ing in medical practice due to the expensiveness and scarcity of densely-
annotated polyp data. besides, various deployment issues, including data
shifts and corruption, put forward further requests for model generaliza-
tion and robustness. to address these concerns, we design a framework
of spatial-spectral dual-branch mutual teaching and entropy-guided
pseudo label ensemble learning (s2me)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_4.pdf,"these datasets are collected
from diversiﬁed patients in multiple medical centers with various data acquisi-
tion systems. varying data shifts and corruption like motion blur and specular
reﬂections2 pose signiﬁcant challenges to model generalization and robustness. [18] and
run the experiments on a single nvidia rtx3090 gpu."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_4.pdf,"[15] are employed as the compar-
ative baselines and implemented with unet [20] as the segmentation backbone
referring to the wsl4mis3 repository. for a fair comparison, the output from
the spatial branch is taken as the ﬁnal prediction and utilized in evaluation
without post-processing. in addition, statistical evaluations are conducted with
multiple seeds, and the mean and standard deviations of the results are reported.
3.2
results and analysis
table 1."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_4.pdf,"results are from
outputs of model-1 on the sun-seg [10] dataset. to ensure the reliability of the mixed
pseudo labels for ensemble learning, we present the pixel-level adaptive fusion
strategy according to entropy maps of dual predictions to balance the strengths
and weaknesses of spatial and spectral branches. as demonstrated in table 4,
our method achieves improved performance compared to two image-level fusion
strategies, i.e., random [15] and equal mixing."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_4.pdf,"moreover, we optimize the segmentation model with the
hybrid mode of loss supervision from scribbles and pseudo labels in a holistic
manner and witness improved outcomes. with extensive in-domain and out-of-
domain evaluation on four public datasets, our method shows superior accu-
racy, generalization, and robustness, indicating its clinical signiﬁcance in allevi-
ating data-related issues such as data shift and corruption which are commonly
encountered in the medical ﬁeld. future eﬀorts can be paid to apply our app-
roach to other annotation-eﬃcient learning contexts like semi-supervised learn-
ing, other sparse annotations like points, and more medical applications."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_3.pdf,"shisrcnet: super-resolution
and classiﬁcation network
for low-resolution breast cancer
histopathology image
luyuan xie1,3, cong li1,3, zirui wang2,3, xin zhang1,3, boyan chen1,3,
qingni shen1,3(b), and zhonghai wu1,3(b)
1 school of software and microelectronics, peking university, beijing, china
qingnishen@ss.pku.edu.cn, wuzh@pku.edu.cn
2 national engineering research center for software engineering, peking university,
beijing 100871, china
3 tencent cloud media, shenzhen, china
https://github.com/xiely-123/shisrcnet
abstract. the rapid identiﬁcation and accurate diagnosis of breast can-
cer, known as the killer of women, have become greatly signiﬁcant for
those patients. numerous breast cancer histopathological image classiﬁ-
cation methods have been proposed."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_3.pdf,"the experimental results demonstrate that the eﬀects of our
method are close to the sota methods with taking hr images as inputs. keywords: breast cancer · histopathological image · super-resolution ·
classiﬁcation · joint training
1
introduction
breast cancer is one of the high-mortality cancers among women in the 21st
century. accurate identiﬁcation of cancer types
c
⃝ the author(s), under exclusive license to springer nature switzerland ag 2023
h. greenspan et al."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_3.pdf,"at present, most single super-resolution methods only have ﬁxed receptive
ﬁelds [7,10,11,18]. these models cannot capture multi-scale features and do not
solve the problems caused by lr in various magniﬁcation factors well. [9] and multi-scale reﬁned context to improve the eﬀect of
reconstructing histopathological images."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_3.pdf,"therefore, designing an appropriate feature
extraction block for sr of the histopathological images is still a challenging task. in recent years, a series of deep learning methods have been proposed to
solve the breast cancer histopathological image classiﬁcation issue by the high-
resolution (hr) histopathological images. [12,21,22] improved the speciﬁc model
structure to classify breast histopathology images, which showed a signiﬁcant
improvement in recognition accuracy compared with the previous works [1,20]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_3.pdf,"[15] and attention mechanism to extract
discriminative features from complex backgrounds. however, it only concate-
nates multi-scale features and does not consider the problem of feature fusion. so it is still worth to explore the potential of extraction and fusion of multi-scale
features for breast images classiﬁcation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_3.pdf,"in the cf module,
we introduce hr images to cf module in the training stage for improving the
performance of cf module and reducing the error caused by the reconstructed
sr images. [16] to alleviate the class imbalanced data problem
of the hr and sr images’ classiﬁcation. [5], the hr and sr of the same images are similar to two
diﬀerent views."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_25.pdf,"code will be available
at https://github.com/carboxy/slpd. keywords: computational pathology · whole slide images(wsis) ·
self-supervised learning
1
introduction
in computational histopathology, visual representation extraction is a fundamen-
tal problem [14], serving as a cornerstone of the (downstream) task-speciﬁc learn-
ing on whole slide pathological images (wsis). numerous
z. yu and t. lin—equal contribution."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_25.pdf,"in order to learn this intra-slide semantic structure, we
encourage the region representations to be closer to the assigned prototypes. by
representing each slide with its prototypes, we further select semantically simi-
1 by formulating wsi tasks as a multi-instance learning problem, the wsi is treated
as a bag with corresponding patches as instances. slpd
261
(e) intra-slide disllaon 
(f) inter-slide disllaon 
(d) global (le) vs. slide-level clustering (right)
(a) hierarchical structure of wsi
(b) two-stage pretraining
probability 
distribuon 
prototype 
within slide 
prototypes 
across slides 
(c) slide-level prototypical disllaon 
wsi
region
patch
image
fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_25.pdf,"clustering can reveal the representative patterns in the data and has
achieved success in the area of unsupervised representation learning [4,5,24,26].
to characterize the histopathologic features underlying the slides, a straight-
forward practice is the global clustering, i.e., clustering the region embeddings
from all the wsis, as shown in the left of fig. however, the obtained
clustering centers, i.e., the prototypes, are inclined to represent the visual bias
slpd
263
related to staining or scanning procedure rather than medically relevant fea-
tures [33]. meanwhile, this clustering strategy ignores the hierarchical structure
“region→wsi→whole dataset” underlying the data, where the id of the wsi
can be served as an extra learning signal."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_25.pdf,"previous self-supervised learning methods applied to histopatho-
logic images only capture such correspondences with positive pairs at the patch-
level [22,23], which overlooks the semantic structure of the wsi. we rethink this
problem from the perspective how to measure the similarity between two slides
accurately. due to the heterogeneity of the slides, comparing them with the local
crops or the averaged global features are both susceptible to being one-sided."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_25.pdf,"2.3, we can alternatively
use the global clustering to obtain prototypes and then optimize the network
with a similar distillation objective as eq. 2. for a fair comparison, the total
number of prototypes of the two clustering methods is approximately the same. table 2(#1,2) reports the comparative results, where the slide-level clustering
surpasses the global clustering by 0.6% and 1.8% of auc on nsclc and brca,
which veriﬁes the eﬀectiveness of the former."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_2.pdf,"slpt: selective labeling meets prompt
tuning on label-limited lesion
segmentation
fan bai1,2,3, ke yan2,3, xiaoyu bai2,3, xinyu mao1, xiaoli yin4,
jingren zhou2,3, yu shi4, le lu2, and max q.-h. meng1,5(b)
1 department of electronic engineering, the chinese university of hong kong,
shatin, hong kong, china
2 damo academy, alibaba group, hangzhou, china
3 hupan lab, hangzhou 310023, china
4 department of radiology, shengjing hospital of china medical university,
shenyang 110004, china
5 department of electronic and electrical engineering,
southern university of science and technology, shenzhen, china
mengqh@sustech.edu.cn
abstract. medical image analysis using deep learning is often challenged
by limited labeled data and high annotation costs."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_2.pdf,"https://doi.org/10.1007/978-3-031-43895-0_2
slpt: selective labeling meets prompt tuning
15
1
introduction
deep learning has achieved promising performance in computer-aided diagnosis
[1,12,14,24], but it relies on large-scale labeled data to train, which is challenging
in medical imaging due to label scarcity and high annotation cost [3,25]. specif-
ically, expert annotations are required for medical data, which can be costly and
time-consuming, especially in tasks such as 3d image segmentation. transferring pre-trained models to downstream tasks is an eﬀective solution
for addressing the label-limited problem [8], but ﬁne-tuning the full network
with small downstream data is prone to overﬁtting [16]. [5,18] is emerging from natural language processing (nlp), which introduces
additional tunable prompt parameters to the pre-trained model and updates only
prompt parameters using supervision signals obtained from a few downstream
training samples while keeping the entire pre-trained unchanged."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_2.pdf,"in al, given the initial labeled
data, the model actively selects a subset of valuable samples for labeling and
improves performance with minimum annotation eﬀort. nevertheless, directly
combining prompt tuning with al presents several problems. first, unlike the
task-speciﬁc models trained with initial data in al, the task-agnostic pre-trained
model (e.g., trained by related but not identical supervised or self-supervised
task) is employed for data selection with prompt tuning."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_2.pdf,"fine-
tuning a large pre-trained model with limited data may be suboptimal and prone
to overﬁtting [16]. to overcome this issue, we draw inspiration from nlp [18]
and explore prompt tuning on visual models. in order to facilitate prompt tun-
ing on the model’s deep layers, we introduce the feature-aware prompt updater
(fpu)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_2.pdf,"however, initializing and
optimizing k prompts directly can signiﬁcantly increase parameters and may not
ensure prompt diversity. to address these challenges, we propose a diversiﬁed
visual prompt tuning approach. as shown in fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_2.pdf,"y represents
the ground truth and l is the total loss. 2.3
tandem selective labeling
previous studies overlook the critical issue of data selection for downstream
tasks, especially when available labels are limited. to address this challenge, we
propose a novel strategy called tesla."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_2.pdf,"we conducted experiments on automating
liver tumor segmentation in contrast-enhanced ct scans, a crucial task in liver
cancer diagnosis and surgical planning [1]. although there are publicly available
liver tumor datasets [1,24], they only contain major tumor types and diﬀer in
image characteristics and label distribution from our hospital’s data. deploying
a model trained from public data to our hospital directly will be problematic."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_2.pdf,"collecting large-scale data from our hospital and training a new model will be
expensive. therefore, we can use the model trained from them as a starting
point and use slpt to adapt it to our hospital with minimum cost. we col-
lected a dataset from our in-house hospital comprising 941 ct scans with eight
categories: hepatocellular carcinoma, cholangioma, metastasis, hepatoblastoma,
hemangioma, focal nodular hyperplasia, cyst, and others."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_2.pdf,"20
f. bai et al.
table 1. evaluation of diﬀerent tunings on the lesion segmentation with limited data
(40 class-balanced patients). denote precision and recall."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_2.pdf,"during training, we set
k = 3 and employed diverse data augmentation techniques such as scale, elas-
tic, rotation, and mirror. to ensure fairness and eliminate model ensemble eﬀects, we
only used the model’s prediction with k = 1 during testing. we used ﬁxed ran-
dom seeds and 5-fold cross-validation for all segmentation experiments.
3.2
results
evaluation of prompt tuning."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_2.pdf,"since we aim to evaluate the eﬃcacy of
prompt tuning on limited labeled data in table 1, we create a sub-dataset of
approximately 5% (40/752) from the original dataset. speciﬁcally, we calculate
the class probability distribution vector for each sample based on the pixel class
in the mask and use coreset with these vectors to select 40 class-balanced sam-
ples. using this sub-dataset, we evaluated various tuning methods for limited
slpt: selective labeling meets prompt tuning
21
table 2. comparison of data selection methods for label-limited lesion segmentation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_65.pdf,"despite the success of deep learning-based medical image segmen-
tation, the robust performance on various sizes of lesions of nodule and
mass is still challenging. in this paper, we propose a multi-scale neural
network with scale-aware test-time adaptation to address this challenge. speciﬁcally, we introduce an adaptive scale-aware test-time click adap-
tation method based on eﬀortlessly obtainable lesion clicks as test-time
cues to enhance segmentation performance, particularly for large lesions."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_65.pdf,"the main
reason is that the lesion scale in the two public datasets are relatively small,
which matches the fact few patients have very large nodule or mass. this makes
the pulmonary nodule and mass segmentation task resemble a long-tail problem
rather than a mere large scale span problem. this leads to unsatisfactory results
when segmenting large lesions that require more accurate delineation [26]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_65.pdf,"furthermore, the attention mechanisms [23]
has also been utilized to emphasize the features that are more relevant for seg-
mentation. though these methods have achieved impressive performance, they
still struggle to accurately segment the extremely imbalanced multi-scale lesions. recently, some click-based lesion segmentation methods [19–21] introduce the
click at the input or feature level and modify the network accordingly, result-
ing in higher accuracy results."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_65.pdf,"this helps to improve the segmentation
performance of large-scale nodules and masses. additionally, we also propose a
multi-scale input encoder to further address the problem of imbalanced lesion
scales. experimental results on two public datasets and one in-house dataset
demonstrate that the proposed method outperforms existing methods with dif-
ferent backbones."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_65.pdf,"this can
be achieved either through an artiﬁcial or automatic approach, for instance, by
adding click channels directly to the input or by adding a prior encoder to the
network as demonstrated by the methods [19,20]. however, incorporating clicks
in this way does not focus on addressing the extremely imbalanced lesion scales.
2.2
network architecture
the network structure of the proposed method, as shown in fig. 2, is enhanced
with a multi-scale (ms) input encoder to address the issue of multi-scale lesions."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_65.pdf,"the subsequent modules can be
based on either cnn or transformer structures. the multi-scale input encoder
allows the network to capture more scale information of the nodules and masses,
thus mitigating the problem of large lesion scale span. 2.3
scale-aware test-time click adaptation
in clinical scenarios, the neural network for assisted diagnosis is generally a pre-
training model."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_65.pdf,"this is mainly due to the fact that large receptive ﬁelds may involve background
features that are not conducive to segmentation inference for micro or small
nodules. in datasets such as lidc and in-house, where the number imbalance
of multi-scale lesion phenomena is more notable, the multi-input method consis-
tently outperforms the other two baselines. we also implemented comparative experiments with other click methods [20]
and [19]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_65.pdf,"3(b) shows the
mean recall rate for lesions at every scale. the diﬀerence between the two scatter
diagrams indicates that the proposed sattca eﬀectively alleviates the issue of
test-time click adaptation for pulmonary lesion segmentation
689
extremely imbalanced lesion scales, and improves the segmentation performance
for large lesions. in addition, for ten epochs of tta, the inference time of each
sample will increase approximately one second comparing with baseline."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_4.pdf,"scribble-based 3d multiple abdominal
organ segmentation via triple-branch
multi-dilated network with pixel- and
class-wise consistency
meng han1, xiangde luo1, wenjun liao2, shichuan zhang2,
shaoting zhang1,3, and guotai wang1,3(b)
1 school of mechanical and electrical engineering, university of electronic science
and technology of china, chengdu, china
guotai.wang@uestc.edu.cn
2 department of radiation oncology, sichuan cancer hospital and institute,
university of electronic science and technology of china, chengdu, china
3 shanghai artiﬁcial intelligence laboratory, shanghai, china
abstract. multi-organ segmentation in abdominal computed tomog-
raphy (ct) images is of great importance for diagnosis of abdominal
lesions and subsequent treatment planning."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_4.pdf,"the ﬁnal segmentation
results were obtained by using a sliding window strategy. for a fair comparison,
we used the primary decoder’s outputs as the ﬁnal results during the inference
stage and did not use any post-processing methods. note that all experiments
were conducted in the same experimental setting."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_48.pdf,"gross tumor volume (gtv)
represents the area of the tumor that can be identiﬁed with a high degree of cer-
tainty and is of paramount importance in clinical practice. however, the precise delineation of the gtv is labor-
intensive, and is restricted to specialized hospitals with highly skilled rt experts. the automatic identiﬁcation of the esophagus presents inherent challenges due to
its elongated soft structure and ambiguous boundaries between it and adjacent
organs [12]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_48.pdf,"meanwhile, an ideal method for automatic esophageal gtv segmenta-
tion in the second course of rt should consider three key aspects: 1) changes in
tumor volume after the ﬁrst course of rt, 2) the proliferation of cancerous cells
from a tumor to neighboring healthy cells, and 3) the anatomical-dependent
second-course esophageal gtv segmentation
513
fig. our training approach leverages multi-center datasets containing relevant anno-
tations, that challenges the network to retrieve information from e1 using the features
from e2. the decoder d utilizes the prior knowledge obtained from i1 and g1 to gener-
ate the mask prediction."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_48.pdf,"to achieve this, we eﬃciently exploit
knowledge from multi-center datasets that are not tailored for second-course
gtv segmentation. our training strategy does not speciﬁc to any tasks but
challenges the network to retrieve information from another encoder with aug-
mented inputs, which enables the network to learn from the above three aspects. extensive quantitative and qualitative experiments validate our designs."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_48.pdf,"as shown
in fig. 1, our strategy is to challenge the network to retrieve information from
augmented inputs in e1 using the features from e2, which can incorporate a wide
range of datasets that are not tailored for second-course gtv segmentation. 3.1
tumor volume variation
the diﬀerences in tumor volume between the ﬁrst and second courses following
an rt treatment can have a negative impact on the state-of-the-art (sota)
learning-based techniques, which will be discussed in sect."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_48.pdf,"second-course esophageal gtv segmentation
515
3.2
cancer cell proliferation
the paired dataset sp for the ﬁrst and second courses is limited, whereas an
unpaired gtv dataset sv = {iv; gv} can be easily obtained in a standard clini-
cal workﬂow with a substantial amount. sv lacks its counterpart for the second
course, in which iv/gv are the ct image and the corresponding annotation for
gtv. to address this, we apply two distinct randomized augmentations, p1, p2,
to mimic the unregistered issue of the ﬁrst and second course ct. the trans-
formed data is feed into the encoders e1/2 as shown in the following equations:
i1, g1, i2, g2 =
⎧
⎨
⎩
p1(i1
p), p1(g1
p), p2(i2
p), p2(g2
p),
when i1
p, i2
p, g1
p, g2
p ∈ sp,
p1(iv), p1(gv), p2(iv), p2(gv),
when iv, gv ∈ sv,
p1(ie), p1(ge), p2(ie), p2(ge),
when ie, ge ∈ se."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_48.pdf,"by aug-
menting the data as described in eq. (4), se challenges the network to extract
information from the entire esophagus, which enhances the network’s embedding
space with anatomical prior knowledge of the esophagus. similarly, data from
the paired sp is also augmented by p1/2 to increase the network’s robustness."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_48.pdf,"we attribute the drawback is due to the
location-agnostic nature of the operations in mha, where the local regional
correlations are perturbed. to tackle the aforementioned problem, we propose ram which involves the
concatenation of the original features with attention outputs, allowing for the
preservation of convolution-generated regional tumor patterns while eﬀectively
comprehending long-range prior knowledge speciﬁc to the esophagus. finally,
our proposed artseg with ram achieves the best dsc/hsd of 75.26%/19.75
mm, and outperforms its ablations as well as other baselines, as shown in table 2.
limitations."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_52.pdf,"although several fully-supervised deep learning methods for membrane seg-
mentation from ihc images have been proposed recently, the high demand for
pixel-level annotations makes this process time-consuming and labor-intensive. to overcome this issue, we propose a novel deep framework for membrane seg-
mentation that utilizes nuclei point-level supervision. our framework consists of
two networks: a seg-net that generates segmentation results for membranes and
nuclei, and a tran-net that transforms the segmentation into semantic points."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_52.pdf,"although these methods can perform weakly supervised segmenta-
tion of cell nuclei from ihc membrane-stained images, they are usually ineffective in
segmenting messy cell membranes. therefore, this paper proposes a novel point-supervised cell membrane segmenta-
tion method, addressing a major challenge in the ﬁeld. the paper also explores the
feasibility of point supervision for the segmentation of two types of objects (cell nuclei
and cell membranes) for the ﬁrst time."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_52.pdf,"during infer-
ence, we only adopt the seg-net for segmentation. 3.1
formulation of the point-level supervised segmentation problem
given an input cell image set {ii}n
i=1, where n is the number of images in this
set, ii ∈ rh×w ×3 with h, w representating the height and width of the image,
respectively, and 3 being the number of channels of the image. our goal is to obtain
the mask of membranes (
mi ∈ rh×w ×1) and nuclei (si ∈ rh×w ×1), that is

mi, si

= σ(fθ (ii)), where fθ is a segmentation network (seg-net) and with train-
able parameters θ, and σ is the sigmoid activation function."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_52.pdf,"however, the two seg-net
channels are interdependent, which can result in nuclei and membranes being insepa-
rably segmented. to overcome this issue, we enforce one channel to output the nuclei
segmentation using a supervised mask si ∈ rh×w ×1. in this study, we create si by
expanding each point annotation to a circle with a radius of 20."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_52.pdf,"this over-
segmentation can take two forms: (1) segmentation of stained impurities, which can
restrict the network’s generalization performance by learning simple color features, and
(2) segmentation of nuclei. to address these issues, we propose a normalization loss
term, ℓnorm
i
, which is an l1 normalization and is deﬁned in eq. the purpose of this
544
h. li et al.
loss term is to encourage the network to learn a smoother membrane segmentation that
does not capture small stained regions or nuclei."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_52.pdf,"(3)
however, relying solely on the ℓnorm
i
normalization term might lead to a trivial solu-
tion, as it only minimizes the average value of the prediction result, potentially resulting
in a minimal maximum conﬁdence for the cell membrane segmentation (e.g., 0.03). to
prevent this issue, we introduce a hinge-loss-like loss function, presented in eq. (4), to
constrain the distribution of membrane segmentation results."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_2.pdf,"however, early-stage renal cancers are
usually asymptomatic, therefore they are often incidentally found during other
examinations [19], which includes non-contrast ct (ncct) scans. segmentation of kidney tumors on ncct images adds challenges compared
to contrast-enhanced ct (cect) images, due to low contrast and lack of multi-
phase images. on cect images, the kidney tumors have diﬀerent intensity val-
ues compared to the normal tissues."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_2.pdf,"in our work, we also make use of 3d u-net, but using this
network alone fails to learn some isodensity tumors. to overcome this issue, we
developed a framework that speciﬁcally incorporates protuberances in kidneys,
allowing for an eﬀective segmentation of tumors on ncct images. in terms of focusing on protruded regions in kidneys, our work is close to
[14,15]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_2.pdf,"thus,
when the output of the protuberance detection network is concatenated with
the output of the base network, the fusion network can easily reduce the loss by
ignoring the protuberance detection network’s output, which is suboptimal. to
avoid this issue, we perform summation not concatenation to avoid the model
from ignoring all output from the protuberance detection network. we then clip
the value of the mask to the range of 0 and 1."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_2.pdf,"composite dice is an average dice between kidney and
tumor dice. the results were obtained by submitting our predicted masks to the grand
challenge page. [13] 0.9123
0.9737
0.8509
our baseline model
0.8832
0.9728
0.7935
4.2
training details and evaluation metrics
our model was trained using sgd with a 0.9 momentum and a weight decay of
1e−7."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_2.pdf,"5
results
5.1
performance on cect images
to show that our model is properly tuned, we compare our baseline model with
an existing method using cect images. as can be seen from table 1, our model
showed comparable scores to the winner of kits19 challenge. we used this
baseline model as our base network for the experiments on ncct images.
5.2
performance on ncct images
table 2 shows our experimental results and ablation studies on ncct images."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_9.pdf,"self- and semi-supervised learning
for gastroscopic lesion detection
xuanye zhang1, kaige yin2, siqi liu1, zhijie feng2, xiaoguang han3,4,
guanbin li5(b), and xiang wan1(b)
1 shenzhen research institute of big data, cuhk-shenzhen, shenzhen, china
wanxiang@sribd.cn
2 department of gastroenterology, hebei key laboratory of gastroenterology, hebei
institute of gastroenterology, hebei clinical research center for digestive diseases,
the second hospital of hebei medical university, shijiazhuang, hebei, china
3 fnii, cuhk-shenzhen, shenzhen, china
4 school of science and engineering, cuhk-shenzhen, shenzhen, china
5 school of computer science and engineering, research institute of sun yat-sen
university in shenzhen, sun yat-sen university, guangzhou, china
liguanbin@mail.sysu.edu.cn
abstract. gastroscopic lesion detection (gld) plays a key role in
computer-assisted diagnostic procedures."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_9.pdf,"2) gastro-
scopic images exhibit distinct diﬀerences from natural images, which are
usually of high similarity in global but high diversity in local. such char-
acteristic of gastroscopic images also degrades the performance of using
generic self-supervised or semi-supervised methods to solve the labeled
data shortage problem using massive unlabeled data. in this paper, we
propose self- and semi-supervised learning (ssl) for gld tailored for
using massive unlabeled gastroscopic images to enhance gld tasks per-
formance, which consists of a hybrid self-supervised learning (hsl)
method for backbone pre-training and a prototype-based pseudo-label
generation (ppg) method for semi-supervised detector training."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_9.pdf,"some appearances of lesions are quite rare and can only be observed in a
few patients. generic self-supervised backbone pre-training or semi-supervised
detector training methods can solve the ﬁrst challenge for natural images but its
eﬀectiveness is undermined for gastroscopic images due to the second challenge.
self-supervised backbone pre-training methods enhance object detection
performance by learning high-quality feature representations from massive unla-
belled data for the backbone. the mainstream self-supervised backbone pre-
training methods adopt self-supervised contrast learning [3,4,7,9,10] or masked
fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_9.pdf,"current pseudo-
label generation methods rely on the objectiveness score threshold to generate
pseudo-labels, which makes them perform below expectations on gld, because
the characteristic of gastroscopic lesions makes it diﬃcult to set a suitable thresh-
old to discover potential lesions meanwhile avoiding introducing much noise. the motivation of this paper is to explore how to enhance gld perfor-
mance using massive unlabeled gastroscopic images to overcome the labeled
data shortage problem. the main challenge for this goal is the characteristic
of gastroscopic lesions."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_9.pdf,"intuitively, such a challenge requires local feature rep-
resentations to contain enough detailed information, meanwhile preserving dis-
criminability. enlightened by this, we propose the self- and semi-supervised
learning (ssl) framework tailored to address challenges in daily clinical prac-
tice and use massive unlabeled data to enhance gld performance. ssl over-
comes the challenges of gld by leveraging a large volume of unlabeled gastro-
scopic images using self-supervised learning for improved feature representations
and semi-supervised learning to discover and utilize potential lesions to enhance
performance."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_9.pdf,"to preserve the representativeness of the memory and
further the prototype feature vectors, ppg designs a novel memory update
strategy. in semi-supervised learning, ppg generates pseudo-labels for unlabeled
data relying on the similarity to the prototype feature vectors, which achieves a
better balance between lesion discovery and noise avoidance. memory module stores a set of lesion feature vectors as
memory."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_9.pdf,"ppg can bring extra 0.9ap and 0.9ap
enhancement for centernet and fasterrcnn respectively. we conduct extra experiments based on faster rcnn
to further analyze the eﬀect of diﬀerent parameter settings on lgldd.
1) reconstruction loss weight λr is designed to balance the losses of con-
trastive learning and the reconstruction, which is to balance the discriminability
and the detailed information volume of local feature representations. as illus-
trated in table 2.a, only suitable λr can fully boost the detection performance.
2) objectiveness score threshold τu: we compare ppg with objective-
ness score-based pseudo-label generation methods with diﬀerent τu (table 2.b)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_9.pdf,"we compare our memory update strategy
with a queue-like (‘q-like’) memory update strategy (ﬁrst in & ﬁrst out). (endo21 challenge consists of 4 sub-tasks and
only the sub-task 2 train/test split is available according to the [2]). experi-
mental results in table 2.d show that ssl can bring signiﬁcant improvements to
publicly available datasets."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_52.pdf,"self-supervised domain adaptive
segmentation of breast cancer
via test-time fine-tuning
kyungsu lee1, haeyun lee2, georges el fakhri3, jonghye woo3,
and jae youn hwang1(b)
1 department of electrical engineering and computer science, daegu gyeongbuk
institute of science and technology, daegu 42988, south korea
{ks_lee,jyhwang}@dgist.ac.kr
2 production engineering research team, samsung sdi, yongin 17084, south korea
3 gordon center for medical imaging, department of radiology, massachusetts
general hospital and harvard medical school, boston, ma 02114, usa
abstract. unsupervised
domain
adaptation
(uda)
has
become
increasingly popular in imaging-based diagnosis due to the challenge of
labeling a large number of datasets in target domains."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_52.pdf,"the primary
limitation is that dl models require a large number of training samples to
achieve accurate predictions [8,24]. yet, acquiring large training datasets and
their corresponding labels, especially from a cohort of patients, can be costly
or even infeasible, which poses a signiﬁcant challenge in developing a dl model
with high performance [7]. second, even when large-scale datasets are available
through collaborative research from multiple sites, dl models trained on such
datasets may yield sub-optimal solutions due to domain gaps caused by diﬀer-
ences in images acquired from diﬀerent sites [20]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_52.pdf,"example solu-
tions include transfer learning- and style transfer-based methods. this is due to sensitive privacy issues in patients’ data,
particularly in collaborative research, which restricts access to labels from diﬀer-
ent domains. [16,33], aiming to generate semi-predictions (pseudo-labels)
in target domains ﬁrst, followed by producing accurate predictions using the
pseudo-labels."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_52.pdf,"one critical limitation of pseudo-label-based uda is the possi-
bility of error accumulation due to mispredicted pseudo-labels. this can lead to
signiﬁcant degradation of the performance of dl models, as errors can compound
and become more pronounced over time [17,25].
to alleviate the problem of pseudo-label-based uda, in this work, we propose
an advanced uda framework based on self-supervised da with a test-time ﬁne-
tuning network. test-time adaptation methods have been developed [4,11,13,23]
to improve the learning of knowledge in target domains."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_52.pdf,"due to the low resolution of
ultrasound images, manual segmentation of breast cancer is challenging even
for expert clinicians, resulting in a sparse number of labeled data. to address
this issue, we introduced a novel self-supervised da network for breast cancer
segmentation in ultrasound images. in particular, we proposed a test-time ﬁne-
tuning network to learn domain-speciﬁc knowledge via knowledge distillation by
self-supervised learning."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_52.pdf,"the
manual creation of these annotations, however, is laborious and often constitutes
a practical bottleneck in the analysis of microscopy experiments [6]. recently,
self-supervised representation learning (ssl) has emerged as a promising app-
roach to alleviate this problem [1,3]. in ssl one ﬁrst deﬁnes a pretext task
supplementary information the online version contains supplementary material
available at https://doi.org/10.1007/978-3-031-43993-3_52.
c
⃝ the author(s), under exclusive license to springer nature switzerland ag 2023
h. greenspan et al."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_52.pdf,"to permutations of the input. in contrast to common models (e.g.
resnet [9]) that lack this symmetry, we here directly incorporate this induc-
tive bias via a permutation-equivariant head h that is a generalization of the set
permutation-equivariant layer proposed in [32] to dense inputs. speciﬁcally, we
choose h = h1 ◦ . . ."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_52.pdf,"when we originally used a regular
self-supervised dense representation learning
543
cnn-based head, we consistently observed that the tap loss stagnated during
the initial training epochs and decreased only slowly thereafter (cf. fig. 2b). using the permutation-equivariant head alleviated this problem and enabled a
consistent loss decrease already from the beginning of training. 3.4
downstream tasks
we next investigate whether the learned tap representations are useful for com-
mon supervised downstream tasks, where we especially focus on their utility in
the low training data regime."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_55.pdf,"https://doi.org/10.1007/978-3-031-43904-9_55
570
r. hirsch et al.
procedures are performed each year globally and 80 million in the united states,
signifying the crucial role of endoscopy in clinical research and care. a cardinal challenge in performing endoscopy is the limited ﬁeld of view which
hinders navigation and proper visual assessment, potentially leading to high
detection miss-rate, incorrect diagnosis or insuﬃcient treatment. yet the success of such ai systems heavily
relies on acquiring annotated data which requires experts of speciﬁc knowledge,
leading to an expensive, prolonged process."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_57.pdf,"[5] to video input and object tracking scenario. as tracklet re-identiﬁcation is a sequence-to-sequence matching problem, the
standard solution is comparing sequences element-wise and then aggregating
the per-element comparisons, e.g. by averaging or max/min pooling [21] - the
so-called late fusion technique. we, on the other hand, follow an early fusion
approach by building a joint representation for the whole sequence."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_57.pdf,"one can see that the joint embedding multi-view model outperforms all other
techniques both on roc and prc. in addition, we evaluate the eﬀectiveness of reid by measuring the aver-
age polyp fragmentation rate (fr), deﬁned as the average number of tracklets
polyps are split into. obviously, lower fragmentation rate means better result
(with the best fragmentation of 1), but it may come at the expense of wrong
tracklet matching (false positive)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_55.pdf,"semi-supervised pathological image
segmentation via cross distillation
of multiple attentions
lanfeng zhong1, xin liao2, shaoting zhang1,3, and guotai wang1,3(b)
1 university of electronic science and technology of china, chengdu, china
guotai.wang@uestc.edu.cn
2 department of pathology, west china second university hospital, sichuan
university, chengdu, china
3 shanghai artiﬁcial intelligence laboratory, shanghai, china
abstract. segmentation of pathological images is a crucial step for
accurate cancer diagnosis."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_55.pdf,"however, acquiring dense annotations of such
images for training is labor-intensive and time-consuming. to address
this issue, semi-supervised learning (ssl) has the potential for reducing
the annotation cost, but it is challenged by a large number of unlabeled
training images. in this paper, we propose a novel ssl method based on
cross distillation of multiple attentions (cdma) to eﬀectively leverage
unlabeled images."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_55.pdf,"[7] proposed
to encourage the predictions of auxiliary decoders and a main decoder to be
consistent under perturbed hierarchical features. pseudo label-based methods
typically generate pseudo labels for labeled images to supervise the network [4].
since using a model’s prediction to supervise itself may over-ﬁt its bias, chen
et al. net+ [19] utilized multiple decoders with diﬀerent upsampling strategies
to obtain slightly diﬀerent outputs, and each decoder’s probability output was
sharpened to serve as pseudo labels to supervise the others."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_55.pdf,"for an input image, the logit predictions obtained by the three branches are
denoted as zca, zsa and zcsa, respectively. after using a standard softmax
operation, their corresponding probability prediction maps are denoted as pca,
psa and pcsa, respectively.
574
l. zhong et al.
2.2
cross decoder knowledge distillation (cdkd)
since the three branches have diﬀerent decision boundaries, using the predictions
from one branch as pseudo labels to supervise the others would avoid each branch
over-ﬁtting its bias. however, as the predictions for unlabeled training images
are noisy and inaccurate, using hard or sharpened pseudo labels [2,19] would
strengthen the conﬁdence on incorrect predictions, leading the model to overﬁt
the noise [10,22]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_55.pdf,"they were also compared with the lower bound
of supervised learning (sl) that only learns from the labeled images. [1] for a fair comparison. semi-supervised segmentation via cross distillation of multiple attentions
577
quantitative evaluation of these methods is shown in table 1."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_48.pdf,"breast lesion segmentation in ultrasound (us) videos is essen-
tial for diagnosing and treating axillary lymph node metastasis. however,
the lack of a well-established and large-scale ultrasound video dataset
with high-quality annotations has posed a persistent challenge for the
research community. to overcome this issue, we meticulously curated a
us video breast lesion segmentation dataset comprising 572 videos and
34,300 annotated frames, covering a wide range of realistic clinical sce-
narios."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_48.pdf,"location ground truth. instead of formulating it as a regression problem,
we adopt a likelihood heatmap-based approach to encode the location of breast
lesions, since it is more robust to occlusion and motion blur. to do so, we compute
a bounding box of the annotated breast lesion segmentation result, and then take
the center coordinates of the bounding box."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_48.pdf,"our method
✓
✓
✓
0.789
0.687
0.815
0.033
4.1
comparisons with state-of-the-arts
we conduct a comparative analysis between our network and nine state-of-the-
art methods, comprising four image-based methods and ﬁve video-based meth-
ods. to ensure a fair and equitable compar-
ison, we acquire the segmentation results of all nine compared methods by utiliz-
ing either their publicly available implementations or by implementing them our-
selves. additionally, we retrain these networks on our dataset and ﬁne-tune their
network parameters to attain their optimal segmentation performance, enabling
accurate and meaningful comparisons."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_54.pdf,"our code is publicly available at https://github.
com/abner228/smilecode. keywords: breast cancer · weakly-supervised learning · medical
image segmentation · contrastive learning · dce-mri
1
introduction
breast cancer is the most common cause of cancer-related deaths among women
all around the world [8]. early diagnosis and treatment is beneﬁcial to improve
the survival rate and prognosis of breast cancer patients."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_54.pdf,"early studies focused on image
processing based approaches by conducting graph-cut segmentation [29] or ana-
lyzing low-level hand-crafted features [1,11,19]. these methods may encounter
the issue of high computational complexity when analyzing volumetric data,
and most of them require manual interactions. recently, deep-learning-based
methods have been applied to analyze breast mri."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_54.pdf,"the batch size was 2,
consisting of a random foreground patch and a random background patch
located via initial segmentation yinit. such setting can help alleviate class
imbalance issue. = 0.1.
• fine-tune: we initialized the network with the trained weights."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_50.pdf,"however, current low-dose
ct reconstruction techniques mainly rely on model-based methods or
deep-learning-based techniques, which often ignore the coherence and
smoothness for sequential ct slices. to address this issue, we propose
a novel approach using generative adversarial networks (gans) with
enhanced local coherence. the proposed method can capture the local
coherence of adjacent images by optical ﬂow, which yields signiﬁcant
improvements in the precision and stability of the constructed images."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_50.pdf,"due to harmful radiation exposure of standard-dose ct, the low
dose ct is more preferable in clinical application [4,6,34]. however, when the
dose is low together with the issues like sparse-view or limited angles, it becomes
quite challenging to reconstruct high-quality ct images. the high-quality ct
images are important to improve the performance of diagnosis in clinic [27]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_50.pdf,"https://doi.org/10.1007/978-3-031-43999-5_50
solving low-dose ct reconstruction via gan with local coherence
525
where xr ∈ rd denotes the unknown ground-truth picture, y ∈ rm denotes
the received measurement, and δ is the noise. the problem of ct reconstruction is to recover
xr from the received y.
solving the inverse problem of (1) is often very challenging if there is no
any additional information. if the forward operator t is well-posed and δ is
neglectable, we know that an approximate xr can be easily obtained by directly
computing t −1(y)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_50.pdf,"if the vertical axial sampling space of transverse planes is small, the cor-
responding ct slices should be highly similar. so we apply optical ﬂow, though
there exist several technical issues waiting to solve for the design and imple-
mentation, to capture the local coherence of adjacent ct images for reducing
the artifacts in low-dose ct reconstruction. our contributions are summarized
below:
1."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_50.pdf,"530
w. liu and h. ding
4
experiment
datasets. first, our proposed approaches are evaluated on the “mayo-clinic
low-dose ct grand challenge” (mayo-clinic) dataset of lung ct images [19]. the dataset contains 2250 two dimensional slices from 9 patients for training,
and the remaining 128 slices from 1 patient are reserved for testing."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_50.pdf,"we randomly select 4
patients with 1827 slices from the dataset. the simulation process is identical to
that of mayo-clinic. the proposed networks were implemented in the pytorch
framework and trained on nvidia 3090 gpu with 100 epochs.
baselines and evaluation metrics."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_50.pdf,"for
both two measures, the higher the better.
results. table 1 presents the results on the mayo-clinic dataset, where the ﬁrst
row represents diﬀerent parameter settings (i.e., the number of uniform views nv,
the number of detectors nd and the standard deviation of gaussian noise σ) for
simulating low-dose sinograms. our proposed approach gan-lc consistently
outperforms the baselines under almost all the low-dose parameter settings."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_50.pdf,"fbpconvnet has
solving low-dose ct reconstruction via gan with local coherence
531
table 1. experimental results for mayo-clinic dataset. the value in ﬁrst row of the
table represents nv, nd and σ for simulating low-dose sinograms, respectively."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_50.pdf,"the value in ﬁrst row of the table
represents nv, nd and σ for simulating low-dose sinograms, respectively. to evaluate the stability and generalization of our
model and the baselines trained on mayo-clinic dataset, we also test them on
the rider dataset. the results are shown in table 2."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_50.pdf,"532
w. liu and h. ding
fig. 3. reconstruction results on mayo-clinic dataset. the sparse view setting of sino-
grams is nv = 200, nd = 400 and σ = 2.0."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_50.pdf,"the experimental results on real datasets demonstrate the advantages
of our proposed network over several popular approaches. in future, we will
evaluate our network on real-world ct images from local hospital and use the
reconstructed images to support doctors for the diagnosis and recognition of lung
nodules. our code is publicly available at https://github.com/lwjie595/ganlc.
acknowledgements."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_53.pdf,"many stain style transfer methods have been proposed to elimi-
nate the variance of stain styles across diﬀerent medical institutions or
even diﬀerent batches. however, existing solutions are conﬁned to gener-
ative adversarial networks (gans), autoencoders (aes), or their vari-
ants, and often fell into the shortcomings of mode collapses or posterior
mismatching issues. in this paper, we make the ﬁrst attempt at a dif-
fusion probabilistic model to cope with the indispensable stain style
transfer in histology image context, called staindiff."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_53.pdf,"moreover, given the stochastic nature of staindiff that multiple
transferred results can be generated from one input histology image,
we further boost and stabilize the performance by the proposal of a
novel self-ensemble scheme. our model can avoid the challenging issues
in mainstream networks, such as the mode collapses in gans or align-
ment between posterior distributions in aes. in conclusion, staindiff
suﬃces to increase the stain style transfer quality, where the training is
straightforward and the model is simpliﬁed for real-world clinical deploy-
ment."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_53.pdf,"moreover,
experiments have shown that stain variations can lead to a signiﬁcant decrease in
the accuracy and reproducibility of deep learning algorithms in histology analy-
sis. consequently, it is crucial to minimize staining variations to ensure reliable,
consistent, and accurate cad systems.
to address the issue of stain variations between diﬀerent domains, stain style
transfer has been proposed. while the conventional color matching [22] and stain
separation methods [19] used to be popular; learning-based approaches have
become increasingly dominant, because they eliminate the need for challenging
manual selection of the template images."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_53.pdf,"importantly, diﬀusion models oﬀer several advantages over gans and
aes, including tractable probabilistic parameterization, stable training proce-
dures, and theoretical guarantees [3]. additionally, they can avoid some of the
challenges encountered by gans and aes, such as the alignment of posterior
distributions or training extra discriminators, leading to a simpler model and
training process. however, the applicability of diﬀusion models to histology stain
style transfer remains unexplored."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_53.pdf,"(2); e denotes the expectation; ∥·∥ is
the l1-norm. finally, the overall loss function is l = ld + γlc, balanced by the
coeﬃcient γ.
fig. the directed graphical model for the inference stage with self-ensemble scheme
of the staindiff."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_53.pdf,"the stain transfer primarily addresses
the domain gap between two stain styles, which is mathematically formulated
as a one-to-one mapping. meanwhile, in some clinical settings, multiple institu-
tions or hospitals are involved, where stain normalization is usually employed for
multiple stain styles to one style alignment. the proposed symmetric staindiff
structure can be easily adapted to support stain normalization, with minimal
change to the loss in eq."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_53.pdf,"each slide is digitized by
two diﬀerent scanners, resulting in stain style variations. for a fair comparison,
we follow the settings in previous work [26] by using 10,000 unpaired patches
randomly cropped from the ﬁrst 184 slides of both scanners as the training set. [33] as the evaluation metrics."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_53.pdf,"(2) dataset-b: the cancer genome atlas
(tcga). all experiments are implemented in python 3.8.13 with
pytorch 1.12.1 on two nvidia geforce rtx 3090 gpu cards with 24gib of
1 https://mitos-atypia-14.grand-challenge.org. staindiﬀ: stain style transfer with diﬀusion
555
table 1. comparison of stain style transfer performance on dataset-a. to show the
statistical signiﬁcance, the p-values in terms of ssim and fsim are computed with
respect to staindiff (full setting)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_53.pdf,"while a slight performance gain
can be achieved with higher m values than 10, the ensemble becomes more time-
consuming, as the cost time is linear to m. it implies an optimal m should be
selected as a trade-oﬀ between the performance and computational time, such
as 10 in this work. staindiﬀ: stain style transfer with diﬀusion
557
4
conclusion
in this paper, we propose staindiff, a denoising diﬀusion model for histolog-
ical stain style transfer, hence a model can get rid of the challenging issues in
mainstream networks, such as the mode collapses in gans or alignment between
posterior distributions in aes. innovatively, by imposing a cycle-consistent con-
straint imposed on latent spaces, staindiff enables learning from unpaired his-
tology images, making it widely applicable to real clinical settings."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_73.pdf,"structuregnet: structure-guided
multimodal 2d-3d registration
amaury leroy1,2,3(b), alexandre cafaro1,2,3, gr´egoire gessain4,
anne champagnac5, vincent gr´egoire3, eric deutsch2, vincent lepetit6,
and nikos paragios1
1 therapanacea, paris, france
a.leroy@therapanacea.eu
2 gustave roussy, inserm 1030, paris-saclay university, villejuif, france
3 department of radiation oncology, centre l´eon b´erard, lyon, france
4 department of pathology, gustave roussy, villejuif, france
5 department of pathology, centre l´eon b´erard, lyon, france
6 ecole des ponts paristech, marne-la-vall´ee, france
abstract. multimodal 2d-3d co-registration is a challenging problem
with numerous clinical applications, including improved diagnosis, radia-
tion therapy, or interventional radiology. in this paper, we present struc-
turegnet, a deep-learning framework that addresses this problem with
three novel contributions."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_73.pdf,"first, we combine a 2d-3d deformable regis-
tration network with an adversarial modality translation module, allow-
ing each block to beneﬁt from the signal of the other. second, we solve the
initialization challenge for 2d-3d registration by leveraging tissue struc-
ture through cascaded rigid areas guidance and distance ﬁeld regulariza-
tion. third, structuregnet handles out-of-plane deformation without
requiring any 3d reconstruction thanks to a recursive plane selection."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_73.pdf,"onepromisingsolutionistorelyonrigidstructuresthataresupposedlymorerobust
duringthepreparation.structuralinformationtoguideimageregistrationhasbeen
studiedwiththehelpofsegmentationsintothetrainingloop[11],orbylearningnew
image representations for reﬁned mapping [12].
in this paper, we propose to leverage the structural features of tissue and
more particularly the rigid areas to guide the registration process with two dis-
tinct contributions: (1) a cascaded rigid alignment driven by stiﬀ regions and
coupled with recursive plane selection, and (2) an improved 2d/3d deformable
motion model with distance ﬁeld regularization to handle out-of-plane deforma-
tion. to our knowledge, no previous study proposed 2d/3d registration com-
bined with structure awareness. we also use the cyclegan for image translation
and direct monomodal signal comparison [25]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_73.pdf,"to any 2d/3d setting. the modality transfer is a 2d image-to-image translation
problem deﬁned as follows: given a sequence of n slices h = {h1, ..., hn} and a
volume considered as a full stack of m axial slices ct = {ct1, ..., ctm}, we build
a cyclegan with two generators and two discriminators gh→ct , gct →h, dh
and dct . with a symmetric situation for gct →h, gh→ct outputs a synthetic
ct image, which is then processed by dct along with randomly sampled orig-
inal input slices with an associated adversarial loss ladv."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_73.pdf,"(1)
additionally, r also warps ct without gradient backpropagation and is the
input with sct for plane selection. we then introduce a sequence alignment
problem, the objective being to update the slice sequence z of sct by mapping
it to a corresponding sequence j of 2d images from ct. + mi(sctzi, ctjj)
else
,
(2)
structuregnet: 2d-3d multimodal registration
775
which means that each row of s will be ﬁlled by computing the sum of the mi
for the corresponding column j and the maximum similarity from the last row."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_73.pdf,"[zi − 2, zi + 2]. based on
these rigid registration and plane selection blocks, we build a cascaded module
to iteratively reﬁne the alignment where the intermediate warping becomes the
new input. we deﬁned the number of iterations as a hyperparameter to reach
a good balance between computational time and similarity maximization. this
dual model is crucial for initialization but does not take into account out-of-
plane deformations and a perfect alignment is not accessible yet."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_73.pdf,"the theoretical spacing
between each slice is 5 mm, and the typical pixel size before downsampling is
100k × 100k. two expert radiation oncologists on ct delineated both the thy-
roid and cricoid cartilages for structure awareness and the gross tumor volume
(gtv) for clinical validation, while two expert pathologists did the same on
wsis. they then meet and agreed to place 6 landmarks for each slice at impor-
tant locations (not used for training)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_73.pdf,"concerning the gpu
runtime, with a 3-step cascade for initialization, the inference remains in a sim-
ilar time scale to baseline methods and performs mapping in less than 3s. we
also compared against msv-regsynnet on its own validation dataset for gener-
alization assessment: we yielded comparable results for the ﬁrst cohort and sig-
niﬁcantly better ones for the second, which proves that structuregnet behaves
well on other modalities and that the structure awareness is an essential asset for
better registration, as pelvis is a location where organs are moving. visuals of
registration results are displayed in the supplementary material."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_51.pdf,"structure-preserving instance
segmentation via skeleton-aware
distance transform
zudi lin1(b), donglai wei2, aarush gupta3, xingyu liu1, deqing sun4,
and hanspeter pﬁster1
1 harvard university, cambridge, usa
linzudi@gmail.com
2 boston college, chestnut hill, usa
3 cmu, pittsburgh, usa
4 google research, mountain view, usa
abstract. objects with complex structures pose signiﬁcant challenges
to existing instance segmentation methods that rely on boundary or aﬃn-
ity maps, which are vulnerable to small errors around contacting pixels
that cause noticeable connectivity change. while the distance transform
(dt) makes instance interiors and boundaries more distinguishable, it
tends to overlook the intra-object connectivity for instances with varying
width and result in over-segmentation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_51.pdf,"for example, the structure of gland
tissues in microscopy images is essential in accessing the pathological stages for
cancer diagnosis and treatment. these instances, however, are usually closely
in touch with each other and have non-convex structures with parts of varying
widths (fig. 1a), posing signiﬁcant challenges for existing segmentation methods. in the biomedical domain, most methods [3,4,13,14,22] ﬁrst learns interme-
diate representations and then convert them into masks with standard segmen-
tation algorithms like connected-component labeling and watershed transform."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_51.pdf,"target sdt generation. there is an inconsistency problem in object skeleton
generation: part of the complete instance skeleton can be diﬀerent from the
skeleton of the instance part (fig. 4). some objects may touch the image border
due to either a restricted ﬁeld of view (fov) of the imaging devices or spatial data
augmentation like the random crop."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_51.pdf,"there are 85 and
80 images in the training and test set, respectively, with ground truth annota-
tions provided by pathologists. according to the challenge protocol, the test set
is further divided into two splits with 60 images of normal and 20 images of
abnormal tissues for evaluation. three evaluation criteria used in the challenge
include instance-level f1 score, dice index, and hausdorﬀ distance, which mea-
sure the performance of object detection, segmentation, and shape similarity,
respectively."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_51.pdf,"[13], our model infers the sdt energy of instance masks from
a global structure perspective instead of boundary that relies on relatively local pre-
dictions, which produces high-quality masks.
training and inference. since the training data is relatively limited due to
the challenges in collecting medical images, we apply pixel-level and spatial-level
augmentations, including random brightness, contrast, rotation, crop, and elastic
transformation, to alleviate overﬁtting. we set α = 0.8 for our sdt in eq."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_51.pdf,"with the bet-
ter distinguishability of object interior and boundary, sdt can unambiguously
separate closely touching instances (fig. 5, ﬁrst two rows), performs better than
previous methods using object boundary representations [4,22]. besides, under
the hausdorﬀ distance for evaluating shape-similarity between ground-truth and
predicted masks, our sdt reports an average score of 44.82 across two test splits,
which improves the previous state-of-the-art approach (i.e., fullnet with an aver-
age score of 50.15) by 10.6%. we also notice the diﬀerent sensitivities of the three
evaluation metrics."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_51.pdf,"decreasing α to 0.6 introduces
more merges and make the results worse. 2.2 we show the inconsistency problem of
global and local skeletons. in this study, we set α = 0.8 and let the model
learn the pre-computed sdt energy for the training set."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_51.pdf,"4
conclusion
in this paper, we introduce the skeleton-aware distance transform (sdt) to
capture both the geometry and topological connectivity of instance masks with
complex shapes. for multi-class problems, we can use class-aware semantic seg-
mentation to mask the sdt energy trained for all objects that is agnostic to
their classes. we hope this work can inspire more research on not only better
representations of object masks but also novel models that can better predict
those representations with shape encoding."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_6.pdf,"medical image synthesis is a challenging task due to the
scarcity of paired data. several methods have applied cyclegan to lever-
age unpaired data, but they often generate inaccurate mappings that shift
theanatomy.thisproblemisfurtherexacerbatedwhentheimagesfromthe
sourceandtargetmodalitiesareheavilymisaligned.recently,currentmeth-
ods have aimed to address this issue by incorporating a supplementary seg-
mentation network. unfortunately, this strategy requires costly and time-
consuming pixel-level annotations."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_6.pdf,"unfortunately, ct imaging
exposes patients to ionizing radiation, which can damage dna and increase
cancer risk [9], especially in children and adolescents. given these issues, there
are clear advantages for synthesizing anatomically accurate ct data from mri. despite the superior perfor-
mance, supervised methods require a large amount of paired data, which is
prohibitively expensive to acquire."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_6.pdf,"however, enforcing pixel-wise consistency may introduce unde-
sirable artifacts in the synthetic results. this problem is particularly relevant
in brain scanning, where both the pixel-wise correlation and noise statistics in
mr and ct images are diﬀerent, as a direct consequence of the signal acqui-
sition technique. the alternative shape-wise consistency methods [3,4,19] aim
58
v. m. h. phan et al.
to preserve the shapes of major body parts in the synthetic image."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_6.pdf,"we collected 270 volumetric t1-weighted mri and 267 thin-
slice ct head scans with bony reconstruction performed in pediatric patients
under routine scanning protocols1. we targeted the age group from 6–24 months
since pediatric patients are more susceptible to ionizing radiation and experience
a greater cancer risk (up to 24% increase) from radiation exposure [7]. further-
more, surgery for craniosynostosis, a birth defect in which the skull bones fuse
too early, typically occurs during this age [5,16]. the scans were acquired by
ingenia 3.0t mri scanners and philips brilliance 64 ct scanners."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_6.pdf,"[4]. shape-cyclegan requires anno-
tated segmentation to train a separate u-net. for a fair comparison, we imple-
ment shape-cyclegan using our extracted coarse masks based on the authors’
oﬃcial code. note that ct-to-mri synthesis is a secondary task supporting the
primary mri-to-ct synthesis task."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_57.pdf,"these models invoke an optimal projection of an input
sequence into memory units that compress the entire sequence. in this
paper, we propose the use of state space models as a multiple instance
learner to a variety of problems in digital pathology. across experiments
in metastasis detection, cancer subtyping, mutation classiﬁcation, and
multitask learning, we demonstrate the competitiveness of this new class
of models with existing state of the art approaches."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_57.pdf,"the resulting images are of gigapixel size, rendering their computational analysis
challenging. to deal with this issue, multiple instance learning (mil) schemes
based on weakly supervised training are used for wsi classiﬁcation tasks. [18] networks extracted for
each patch."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_57.pdf,"∈ rn,
and where the process is governed by matrices a ∈ rn×n, b ∈ rn×p, c ∈
rq×n, d ∈ rq×p. [9] (high-order polynomial projection operator),
continuous time memorisation is posed as a problem of function approximation
in a hilbert space deﬁned by a probability measure μ. the hippo mode of memorisation is shown empirically to be better suited to
modeling long-range dependencies (lrd) than other neural memory layers, for
which it serves as a drop-in replacement."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_57.pdf,"table 5 shows the
obtained average accuracy (weighted by the number of long sequences in each
validation set) and auroc on both clam models, transmil, and our proposed
method. both in terms of auroc and accuracy, our method outperforms the
other methods on long sequences, while the performances are comparable to
table 1, albeit slightly lower, illustrating the challenge of processing large wsis. table 5. results of clam sb, clam mb, transmil, and our proposed method on
long sequences."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_57.pdf,"[19]
0.9007
0.9652
ours
0.9220
0.9737
5
conclusions
in this work we have explored the ability of state space models to act as multiple
instance learners on sequences of patches extracted from histopathology images. these models have been developed for their ability to memorise long sequences,
and they have proven competitive with state of the art mil models across a range
of pathology problems. additionally, we demonstrated the ability of these models
to perform multiclass classiﬁcation, which furthermore allowed us to visualise the
localisation of metastasic regions."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_40.pdf,"transformers for medical image segmentation have attracted broad
interest. unlike convolutional networks (cnns), transformers use self-attentions
that do not have a strong inductive bias. this gives transformers the ability to
learn long-range dependencies and stronger modeling capacities."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_40.pdf,"although they,
e.g. swinunetr, achieve state-of-the-art (sota) results on some benchmarks,
the lack of inductive bias makes transformers harder to train, requires much
more training data, and are sensitive to training recipes. in many clinical scenar-
ios and challenges, transformers can still have inferior performances than sota
cnns like nnunet. a transformer backbone and corresponding training recipe,
which can achieve top performances under different medical image segmenta-
tion scenarios, still needs to be developed."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_40.pdf,"keywords: swin transformer · convolution · hybrid model · medical image
segmentation
1
introduction
medical image segmentation is a core step for quantitative and precision medicine. [21], has achieved top performances on over 20 medical segmenta-
tion challenges. the convolution operation
in cnn provides a strong inductive bias which is translational equivalent and efﬁ-
cient in capturing local features like boundary and texture."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_40.pdf,"the self-attention mechanism enables learning long-
range dependencies between far-away tokens. [23] has achieved the new
top performance in the msd challenge and beyond the cranial vault (btcv) segmen-
tation challenge by pretraining on large datasets. it has a u-shaped structure where the
encoder is a swin-transformer [16]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_40.pdf,"the self-attentions are good at learning complicated relational
interactions for high-level concepts [5] but are also observed to be ignoring local fea-
ture details [5]. [34],
where the challenge is in learning complex relationships and scene understanding from
a large amount of labeled training images, many medical image segmentation networks
need to be extremely focused on local boundary details while less in need of high-
level relationships. moreover, the number of training data is also limited."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_40.pdf,"[13] are all cnn based. besides lacking
inductive bias and enough training data, one extra reason could be that transformers are
computationally much expensive and harder to tune. more improvements and empirical
evidence are needed before we say transformers are ready to replace cnns for medical
image segmentation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_40.pdf,"in this paper, we try to develop a new “to-go” transformer for 3d medical image
segmentation, which is expected to exhibit strong performance under different data sit-
uations and does not require extensive hyperparameter tuning. swinunetr reaches
top performances on several large benchmarks, making itself the current sota, but
without effective pretraining and excessive tuning, its performance on new datasets and
challenges is not as high-performing as expected. a straightforward direction to improve transformers is to combine the merits of
both convolutions and self-attentions."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_40.pdf,"another line in 1) is changing the self-attention operation directly. [7] uses
gated positional self-attention which is equipped with a soft convolutional inductive
bias. works in the second direction 2) employs both convolution and self-attention in
the network [3,4,8,20,27,28,30,31,33,35]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_40.pdf,"a patch merging layer is applied after every swin transformer block to
reduce each spatial dimension by half.
420
y. he et al.
stage-wise convolution. although swin-transformer uses local window attention to
introduce inductive bias like convolutions, self-attentions can still mess up with the
local details. we experimented with multiple designs as in fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_40.pdf,"3
experiments
we use extensive experiments to show its effectiveness and justify its design for 3d
medical image segmentation. to make fair comparisons with baselines, we did not use
any pre-trained weights.
datasets. [17] (large-scale whole abdominal organ dataset) contains
150 high-resolution abdominal ct volumes, each with 16 pixel-level organ annota-
tions."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_40.pdf,"[1] prostate dataset contains 32 labeled prostate
mri with two modalities for the prostate peripheral zone (pz) and the transition
zone (tz). the challenges are the large inter-subject variability and limited training
data. the lung tumor dataset contains 63 lung ct images with tumor annotations."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_40.pdf,"swinunetr-v2: stronger swin backbone
421
(or cysts). the challenge is from the large label imbalances between the background,
pancreas, and tumor structures. for all three msd tasks, we perform 5-fold cross-
validation with 70%/10%/20% train, validation, and test splits."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_40.pdf,"all the
baseline scores are from [17] except nnformer and swinunetr. to make a fair com-
parison, we didn’t use any test-time augmentation or model ensemble. the test set dice
422
y. he et al.
table 1. word test set dice scores (%) and standard deviation in brackets."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_40.pdf,"we did not do any post-
processing or model ensembling, thus there can be a gap between the test values and
online msd leaderboard values. we didn’t compare with leaderboard results because
the purpose of the experiments is to make fair comparisons, while not resorting to addi-
tional training data/pretraining, postprocessing, or model ensembling.
variations of swinunetr-v2 in this section, we investigate other variations of adding
convolutions into swin transformer. we follow fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_40.pdf,"to improve this, our core intuition is to combine convolution with
window-based self-attention. although existing window-based attention already has a
convolution-like inductive bias, it is still not good enough for learning local details as
convolutions. we tried multiple combination strategies as in table 5 and found our cur-
rent design most effective."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_40.pdf,"the optimal combination of swin transformer
and convolution still lacks a clear principle and theory, and we can only rely on trial and
error in designing new architectures. we will apply the network to active challenges for
more evaluation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_8.pdf,"4
conclusion
we have developed a multi-sequence fusion network based on multi-b-value dwi
to synthesize ce-mri, using source data including dwis and t1-weighted fat-
suppressed mri. compared to existing methods, we avoid the challenges of
using full-sequence mri and aim to be selective on valuable source data dwi.
hierarchical fusion generation module, weighted diﬀerence module, and multi-
sequence attention module have all been shown to improve the performance of
synthesizing target images by addressing the problems of synthesis at diﬀerent
scales, leveraging diﬀerentiable information within and across sequences. given
that current research on synthetic ce-mri is relatively sparse and challenging,
our study provides a novel approach that may be instructive for future research
based on dwis."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_72.pdf,"deep learning based medical image recognition systems often
require a substantial amount of training data with expert annotations,
which can be expensive and time-consuming to obtain. recently, syn-
thetic augmentation techniques have been proposed to mitigate the issue
by generating realistic images conditioned on class labels. however, the
eﬀectiveness of these methods heavily depends on the representation
capability of the trained generative model, which cannot be guaranteed
without suﬃcient labeled training data."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_72.pdf,"however, unlike natural images in computer vision, the
number of medical images with expert annotations is often limited by the high
labeling cost and privacy concerns. to overcome this challenge, a natural choice
is to employ data augmentation to increase the number of training samples. while existing works have proven eﬀective in improv-
ing the performance of downstream models to some extent, a suﬃcient amount
of labeled data is still required to adequately train models to generate decent-
quality images."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_72.pdf,"although annotated data is typically hard to acquire for medical images,
unannotated data is often more accessible. to mitigate the issue existed in cur-
rent cgan-based synthetic augmentation methods [8,36–38], in this work, we
propose to leverage the diﬀusion model with unlabeled pre-training to reduce
the dependency on the amount of labeled data (see comparisons in fig. we
propose a novel synthetic augmentation method, named histodiﬀusion, which
can be pre-trained on large-scale unannotated datasets and adapted to small-
scale annotated datasets for augmented training."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_72.pdf,"it is worth noting that
the labels for these samples have been kept, which allows the ﬁne-tuning process
to be guided by labeled data, leading to better predictions on the speciﬁc task or
domain being trained. by ensuring that the ﬁne-tuning process is representative
of the entire dataset through even sampling from each tissue type, we can elim-
inate bias towards any particular tissue type. we evaluate the ﬁne-tuned model
on the oﬃcial test set."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_72.pdf,"[25] added before the output layer. [5] in all experiments to ensure fair comparisons. the default hyper-parameter
settings provided in their oﬃcially released codebases are followed."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_72.pdf,"[14] as the backbone generative model for cgan-based synthesis. to
ensure a fair comparison, all images synthesized by stylegan2 and histodiﬀu-
sion model are further selected based on feature centroid distances [36]. more
implementation details of our proposed histodiﬀusion, stylegan2, and baseline
classiﬁer can also be found in our supplementary materials."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_11.pdf,"however, cam has been criticized for highlighting
only the most discriminative parts of the object, leading to poor qual-
ity of pseudo-labels. although some recent methods have attempted to
extend cam to cover more areas, the fundamental problem still needs
to be solved. we believe this problem is due to the huge gap between
image-level labels and pixel-level predictions and that additional infor-
mation must be introduced to address this issue."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_11.pdf,"therefore, there is an
urgent need to pursue weakly supervised solutions for pixel-wise segmentation. nonetheless, weakly supervised histopathological image segmentation presents
a challenge due to the low contrast between diﬀerent tissues, intra-class vari-
ations, and inter-class similarities [4,11]. additionally, the tissue structures in
histopathology images can be randomly arranged and dispersed, which makes it
diﬃcult to identify complete tissues or regions of interest [7]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_11.pdf,"the proposed method
tpro for weakly supervised histopathology tissue segmentation
117
achieves the best results on two public datasets, luad-histoseg and bcss-
wsss, demonstrating the superiority of our method.
acknowledgment. this work was supported in part by the natural science foun-
dation of ningbo city, china, under grant 2021j052, in part by the ningbo clinical
research center for medical imaging under grant 2021l003 (open project 2022lyk-
fzd06), in part by the national natural science foundation of china under grant
62171377, in part by the key technologies research and development program under
grant 2022yfc2009903/2022yfc2009900, in part by the key research and develop-
ment program of shaanxi province, china, under grant 2022gy-084, and in part by
the science and technology innovation committee of shenzhen municipality, china,
under grants jcyj20220530161616036."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_52.pdf,"recently,
to overcome this limitation, multi-modality studies have been conducted, aiming
to enhance the expressive power of both text and image features. for instance,
clip [12] used contrastive learning based on image-text pairs to learn the sim-
ilarity between the image of an object and the text describing it, achieving
signiﬁcant performance gains in a variety of computer vision problems. the trend of text-image multi-modality-based research on image processing
has extended to the medical ﬁeld."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_52.pdf,"however, even in the same pelvis, the
shape of the bone shown in mr slices varies depending on the slice position of
the mri and the texture of the tissue around the bone is complex. this makes
ﬁnding an accurate roi a challenge. we segmented the pelvic bones in mri slices using the proposed method
to construct a fully automatic deep learning-based active sacroiliitis diagnosis
system, including roi settings from mri input images."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_27.pdf,"keywords: foundation models · multi-modality · model adaptation ·
pathological image classiﬁcation
1
introduction
deep learning for medical imaging has achieved remarkable progress, leading to
a growing body of parameter-tuning strategies [1–3]. those approaches are often
designed to address disease-speciﬁc problems with limitations in their general-
izability. in parallel, foundation models [4] have surged in computer vision [5,6]
and natural language processing [7,8] with growing model capacity and data
size, opening up perspectives in utilizing foundation models and large-scale clin-
ical data for diagnostic tasks."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_27.pdf,"in addition, task-speciﬁc models do
not generalize well with diﬀerent image modalities [2]. to tackle this issue, we
emphasize the adaptation of foundation models in a data-eﬃcient manner. recent work has made eﬀorts in pre-training
vision-language models."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_27.pdf,"however, existing prompt tuning methods lack expert knowl-
edge and understanding of downstream medical tasks. to address this challenge,
we leverage large language models pre-trained with biomedical text to inject
medical domain knowledge. biomedical language model utilization."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_27.pdf,"we resize the images to 224×224
to ﬁt the model and follow the original data pipeline in patchgastric [25]. a
class-balanced sampling strategy is adopted by choosing one image from each
class in turn. training is done with 1,000 iterations of stochastic gradient descent
(sgd), and the mini-batch size is 128, requiring 11.6 gb of gpu memory and
11 min on two nvidia geforce rtx 2080 ti gpus."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_27.pdf,"while clip gains such modality matching
through pre-training, our cite shows an appealing trait that irrelevant vision
and language models can be combined to exhibit similar multi-modal insights
on pathological tasks without a need of joint pre-training. 6
conclusion
adapting powerful foundation models into medical imaging constantly faces
data-limited challenges. in this study, we propose cite, a data-eﬃcient and
model-agnostic approach to adapt foundation models for pathological image clas-
siﬁcation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_18.pdf,"the role of subgroup separability
in group-fair medical image
classiﬁcation
charles jones(b), m´elanie roschewitz, and ben glocker
department of computing, imperial college london, london, uk
{charles.jones17,mb121,b.glocker}@imperial.ac.uk
abstract. we investigate performance disparities in deep classiﬁers."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_18.pdf,"we
ﬁnd that the ability of classiﬁers to separate individuals into subgroups
varies substantially across medical imaging modalities and protected char-
acteristics; crucially, we show that this property is predictive of algorith-
mic bias. through theoretical analysis and extensive empirical evalua-
tion (code is available at https://github.com/biomedia-mira/subgroup-
separability), we ﬁnd a relationship between subgroup separability, sub-
group disparities, and performance degradation when models are trained
on data with systematic bias such as underdiagnosis. our ﬁndings shed new
light on the question of how models become biased, providing important
insights for the development of fair medical imaging ai.
1
introduction
medical image computing has seen great progress with the development of deep
image classiﬁers, which can be trained to perform diagnostic tasks to the level of
skilled professionals [19]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_18.pdf,"recently, it was shown that these models might rely on
sensitive information when making their predictions [7,8] and that they exhibit
performance disparities across protected population subgroups [20]. although
many methods exist for mitigating bias in image classiﬁers, they often fail unex-
pectedly and may even be harmful in some situations [26]. [22,27], and none are suitable for real-world deployment."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_18.pdf,"if we wish to deploy appropriate and fair automated systems, we must ﬁrst
understand the underlying mechanisms causing erm models to become biased. an often overlooked aspect of this problem is subgroup separability: the ease
with which individuals can be identiﬁed as subgroup members. some medical
images encode sensitive information that models may leverage to classify indi-
viduals into subgroups [7]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_18.pdf,"c
⃝ the author(s), under exclusive license to springer nature switzerland ag 2023
h. greenspan et al. (eds.): miccai 2023, lncs 14222, pp. https://doi.org/10.1007/978-3-031-43898-1_18
180
c. jones et al.
image classiﬁers (e.g. biological sex from chest x-ray can be predicted with
> 0.98 auc). in contrast, groups with more subtle diﬀerences (e.g. due to ‘social
constructs’) may be harder for a model to classify."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_18.pdf,"we highlight how the separability of protected groups interacts in non-trivial
ways with the training of deep neural networks. we show that the ability of
models to detect which group an individual belongs to varies across modalities
and groups in medical imaging and that this property has profound consequences
for the performance and fairness of deep classiﬁers. to the best of our knowledge,
ours is the ﬁrst work which analyses group-fair image classiﬁcation through the
lens of subgroup separability."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_18.pdf,"our contributions are threefold:
– we demonstrate empirically that subgroup separability varies across real-
world modalities and protected characteristics. – we show theoretically that such diﬀerences in subgroup separability aﬀect
model bias in learned classiﬁers and that group fairness metrics may be inap-
propriate for datasets with low subgroup separability. – we corroborate our analysis with extensive testing on real-world medical
datasets, ﬁnding that performance degradation and subgroup disparities are
functions of subgroup separability when data is biased."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_18.pdf,"[20] highlighted that classiﬁcation models trained through erm underdiag-
nose historically underserved population subgroups. follow-up work has addi-
tionally shown that these models may use sensitive information to bias their
predictions [7,8]. unfortunately, standard bias mitigation methods from com-
puter vision, such as adversarial training [1,14] and domain-independent training
[24], are unlikely to be suitable solutions."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_18.pdf,"on
natural images, zietlow et al. [26] showed that bias mitigation methods worsen
performance for all groups compared to erm, giving a stark warning that blindly
applying methods and metrics leads to a dangerous ‘levelling down’ eﬀect [16]. one step towards overcoming these challenges and developing fair and perfor-
mant methods is understanding the circumstances under which deep classiﬁers
learn to exploit sensitive information inappropriately."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_18.pdf,"today, our understanding
of this topic is limited. closely related to our work is oakden-rayner et al., who
consider how ‘hidden stratiﬁcation’ may aﬀect learned classiﬁers [18]; similarly,
jabbour et al. use preprocessing ﬁlters to inject spurious correlations into chest
x-ray data, ﬁnding that erm-trained models are more biased when the corre-
lations are easier to learn [12]. outside of fairness, our work may have broader
impact in the ﬁelds of distribution shift and shortcut learning [6,25], where many
examples exist of models learning to exploit inappropriate spurious correlations
[3,5,17], yet tools for detecting and mitigating the problem remain immature. → [0, 1] the
underlying mapping between images and class labels."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_18.pdf,"suppose we have access to a
(biased) training dataset, where ptr is the conditional distribution between train-
ing images and training labels; we say that such a dataset is biased if ptr ̸= p.
we focus on group fairness, where each individual belongs to a subgroup a ∈ a
and aim to learn a fair model that maximises performance for all groups when
deployed on an unbiased test dataset drawn from p. we assume that the groups
are consistent across both datasets. the bias we consider in this work is under-
diagnosis, a form of label noise [4] where some truly positive individuals x+ are
mislabeled as negative. we are particularly concerned with cases where under-
diagnosis manifests in speciﬁc subgroups due to historic disparities in healthcare
provision or discriminatory diagnosis policy."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_18.pdf,"0.5|
n+,a
≈ tpr(u)
a
(8)
in the case of high subgroup separability, eq. (8) demonstrate that
tpr of the underdiagnosed group is directly aﬀected by bias from the training
set while other groups are mainly unaﬀected. given this diﬀerence across groups,
an appropriately selected group fairness metric may be able to identify the bias,
in some cases even without access to an unbiased test set [23]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_18.pdf,"(10) represents
performance degradation for all groups when separability is poor. in such sit-
uations, we expect performance degradation to be uniform across groups and
thus not be detected by group fairness metrics. the severity of the degrada-
tion depends on both the proportion of corrupted labels in the underdiagnosed
subgroup and the size of the underdiagnosed subgroup in the dataset."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_18.pdf,"in practice,
subgroup separability for real-world datasets may vary continuously between
these extremes. 4, we empirically investigate (i) how subgroup separa-
bility varies in the wild, (ii) how separability impacts performance for each group
when underdiagnosis bias is added to the datasets, (iii) how models encode sen-
sitive information in their representations. subgroup separability in medical image classiﬁcation
183
4
experiments and results
we support our analysis with experiments on ﬁve datasets adapted from a subset
of the medfair benchmark [27]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_18.pdf,"all attributes can
be predicted from chest x-ray scans with > 0.9 auc, implying that the modal-
ity encodes substantial information about patient identity. age is consistently
well predicted across all modalities, whereas separability of biological sex varies,
184
c. jones et al.
with prediction of sex from fundus images being especially weak. importantly,
the wide range of auc results [0.642 → 0.986] across the dataset-attribute com-
binations conﬁrms our premise that subgroup separability varies substantially
across medical imaging applications."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_18.pdf,"performance degradation under label bias
we now test our theoretical ﬁnding: models are aﬀected by underdiagnosis dif-
ferently depending on subgroup separability. we inject underdiagnosis bias into
each training dataset by randomly mislabelling 25% of positive individuals in
group 1 (see table 1) as negative. for each dataset-attribute combination, we
train ten disease classiﬁcation models with the biased training data and ten mod-
els with the original clean labels; we test all models on clean data."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_18.pdf,"3. we report
no statistically signiﬁcant performance degradation for dataset-attribute combi-
nations with low subgroup separability (<0.9 auc). in these experiments, the
proportion of mislabelled images is small relative to the total population; thus,
the underdiagnosed subgroups mostly recover from label bias by sharing the
subgroup separability in medical image classiﬁcation
185
correct mapping with the uncorrupted group. while we see surprising improve-
ments in performance for papila, note that this is the smallest dataset, and
these improvements are not signiﬁcant at pcritical = 0.05."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_18.pdf,"as subgroup separabil-
ity increases, performance degrades more for the underdiagnosed group (group
1), whilst performance for the uncorrupted group (group 0) remains somewhat
unharmed. we see a statistically signiﬁcant performance drop for group 0 in the
mimic-sex experiment – we believe this is because the model learns separate
group-wise mappings, shrinking the eﬀective size of the dataset for group 0.
use of sensitive information in biased models
finally, we investigate how biased models use sensitive information. [7,8] to all
models trained for the previous experiment, involving freezing the trained back-
bone and re-training the ﬁnal layer to predict the sensitive attribute."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_18.pdf,"we discuss four takeaways from our study:
subgroup separability varies substantially in medical imaging. in fairness liter-
ature, data is often assumed to contain suﬃcient information to identify indi-
viduals as subgroup members. but what if this information is only partially
encoded in the data?"
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_18.pdf,"performance degradation is a function of subgroup separability. we showed,
theoretically and empirically, that the performance and fairness of models trained
on biased data depends on subgroup separability. when separability is high,
models learn to exploit the sensitive information and the bias is reﬂected by stark
subgroup diﬀerences."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_18.pdf,"when separability is low, models cannot exploit sensitive
information, so they perform similarly for all groups. this indicates that group
fairness metrics may be insuﬃcient for detecting bias when separability is low. our analysis centred on bias in classiﬁers trained with the standard approach
of empirical risk minimisation – future work may wish to investigate whether
subgroup separability is a factor in the failure of bias mitigation methods and
whether it remains relevant in further image analysis tasks (e.g. segmentation)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_18.pdf,"sources of bias matter. in our experiments, we injected underdiagnosis bias
into the training set and treated the uncorrupted test set as an unbiased ground
truth. however, this is not an endorsement of the quality of the data."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_18.pdf,"this pre-existing bias will likely have
a smaller eﬀect size than our artiﬁcial bias, so it should not play a signiﬁcant
role in our results. still, the unmeasured bias may explain some variation in
results across datasets. future work should investigate how subgroup separability
interacts with other sources of bias."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_18.pdf,"we renew the call for future datasets to be
released with patient metadata and multiple annotations to enable analysis of
diﬀerent sources and causes of bias.
reproducibility and impact. this work tackles social and technical problems in
machine learning for medical imaging and is of interest to researchers and prac-
titioners seeking to develop and deploy medical ai. given the sensitive nature of
this topic, and its potential impact, we have made considerable eﬀorts to ensure
full reproducibility of our results."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_16.pdf,"thinking like sonographers: a deep
cnn model for diagnosing gout
from musculoskeletal ultrasound
zhi cao1, weijing zhang2, keke chen2, di zhao2, daoqiang zhang1,
hongen liao3, and fang chen1(b)
1 key laboratory of brain-machine intelligence technology, ministry of education,
nanjing university of aeronautics and astronautics, nanjing 210016, china
chenfang@nuaa.edu.cn
2 department of ultrasound, nanjing drum tower hosptial, the aﬃliated hospital
of nanjing university medical school, nanjing 210008, china
3 department of biomedical engineering, school of medicine,
tsinghua university, beijing 100084, china
abstract. we explore the potential of deep convolutional neural net-
work (cnn) models for diﬀerential diagnosis of gout from musculoskele-
tal ultrasound (mskus), as no prior study on this topic is known."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_16.pdf,"our
exhaustive study of state-of-the-art (sota) cnn image classiﬁcation
models for this problem reveals that they often fail to learn the gouty
mskus features, including the double contour sign, tophus, and snow-
storm, which are essential for sonographers’ decisions. to address this
issue, we establish a framework to adjust cnns to “think like sonog-
raphers” for gout diagnosis, which consists of three novel components:
(1) where to adjust: modeling sonographers’ gaze map to emphasize
the region that needs adjust; (2) what to adjust: classifying instances
to systematically detect predictions made based on unreasonable/biased
reasoning and adjust; (3) how to adjust: developing a training mecha-
nism to balance gout prediction accuracy and attention reasonability for
improved cnns. the experimental results on clinical mskus datasets
demonstrate the superiority of our method over several sota cnns."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_16.pdf,"yellow boxes denote the gaze areas of the sonographers and
red arrows denote the surrounding fascial tissues; (b) grad-cam visual of resnet18;
(c) grad-cam visual of densenet121; (d) grad-cam visual of our method. (color ﬁgure
online)
there are signiﬁcant challenges in cnn based gout diagnosis. firstly, the
gout-characteristics contain various types including double contour sign, syn-
ovial hypertrophy, synovial eﬀusion, synovial dislocation and bone erosion, and
these gout-characteristics are small and diﬃcult to localize in mskus."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_16.pdf,"secondly,
the surrounding fascial tissues such as the muscle, sarcolemma and articular
capsule have similar visual traits with gout-characteristics, and we found the
existing cnn models can’t accurately pay attention to the gout-characteristics
that radiologist doctors pay attention to during the diagnosis process (as shown
in fig. due to these issues, sota cnn models often fail to learn the gouty
mskus features which are key factors for sonographers’ decision. in medical image analysis, recent works have attempted to inject the recorded
gaze information of clinicians into deep cnn models for helping the models to
predict correctly based on lesion area."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_16.pdf,"thinking like sonographers
161
diﬀerent from the existing studies, we propose a novel framework to adjust
the general cnns to “think like sonographers” from three diﬀerent levels. (1)
where to adjust: modeling sonographers’ gaze map to emphasize the region that
needs adjust; (2) what to adjust: classify the instances to systemically detect
predictions made based on unreasonable/biased reasoning and adjust; (3) how
to adjust: developing a training mechanism to strike the balance between gout
prediction accuracy and attention reasonability.
2
method
fig. the overall framework of the proposed method.
figure 2 presents the overall framework, which controls cnns to “think like
sonographers” for gout diagnosis from three levels."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_16.pdf,"2) what to adjust: we divide instances into four categories to reﬂect
whether the model prediction given to the instance is reasonable and precise. 3)
how to adjust: a training mechanism is developed to strike the balance between
gout diagnosis and attention accuracy for improving cnn.
2.1
where to adjust
it is essential to obtain the gaze map corresponding to each mskus to emphasize
the region where gouty features are obvious. [8], we integrate transformer into cnns to capture multi-scale and long-
range contextual visual information for modeling sonographers’ gaze map."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_16.pdf,"in
this way, cnns not only ﬁnish correct gout
diagnosis, but also acquire the attention
region that agreements with the sonographers’
gaze map. 2.3
how to adjust
we proposed a training mechanism (algorithm 1) which can strike the balance
between the gout diagnosis error and the reasonability error of attention region
to promote the cnns to “think like sonographers”. lreasonability = l1(scam, ssono)
the total loss function can be expressed as the weighted sum the gout diagnosis
error and the reasonability error, as follows:
ltotal = αldiagnosis + (1 − α)lreasonability
the gout diagnosis error ldiagnosis is calculated by the cross-entropy loss, and
the reasonability is calculated by the l1-loss."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_16.pdf,"correspondingly, for sample in rip, α can
be set 0.8 to make cnn pay more attention to precise. for sample in rp and
uip, α can be set 0.5 to strike the balance between accuracy and reasonability. 3
experiments
mskus dataset collection."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_17.pdf,"thyroid nodule diagnosis in dynamic
contrast-enhanced ultrasound
via microvessel inﬁltration awareness
haojie han1, hongen liao2, daoqiang zhang1, wentao kong3,
and fang chen1(b)
1 key laboratory of brain-machine intelligence technology, ministry of education,
nanjing university of aeronautics and astronautics, nanjing 211106, china
chenfang@nuaa.edu.cn
2 department of biomedical engineering, school of medicine,
tsinghua university, beijing 10084, china
3 department of ultrasound, aﬃliated drum tower hospital,
nanjing university medical school, nanjing 21008, china
abstract. dynamic contrast-enhanced ultrasound (ceus) video with
microbubble contrast agents reﬂects the microvessel distribution and
dynamic microvessel perfusion, and may provide more discriminative
information than conventional gray ultrasound (us)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_17.pdf,"supplementary information the online version contains supplementary material
available at https://doi.org/10.1007/978-3-031-43987-2 17.
c
⃝ the author(s), under exclusive license to springer nature switzerland ag 2023
h. greenspan et al. https://doi.org/10.1007/978-3-031-43987-2_17
170
h. han et al.
keywords: contrast-enhanced ultrasound · thyroid nodule ·
dynamic perfusion · inﬁltration awareness
1
introduction
contrast-enhanced ultrasound (ceus) as a modality of functional imaging has
the ability to assess the intensity of vascular perfusion and haemodynamics in
the thyroid nodule, thus considered a valuable new approach in the determi-
nation of benign vs. malignant nodules [1]. in practice, ceus video allows the
dynamic observation of microvascular perfusion through intravenous injection of
contrast agents."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_17.pdf,"[4] proposed a hierarchical temporal attention network which
thyroid nodule diagnosis in dynamic ceus via mia
171
fig. the overall architecture which contains four parts: cross-task shared feature
extraction, temporal-based lesions area recognition, microvessel inﬁltration awareness
and thyroid nodules diagnosis. ˆpn} represents the inﬁltration pro-
cess of microvessels from gray us to ceus, and ˆpn is the ﬁnal segmentation result.
used the spatial feature enhancement for disease diagnosis based on dynamic
ceus."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_17.pdf,"in particular, few studies have developed the
ceus video based diagnostic model inspired by the dynamic microvessel per-
fusion, or these existing methods generally ignore the inﬂuence of microvessel
inﬁltrative expansion. whether the awareness of inﬁltrative area information can
be helpful in the improvement of diagnostic accuracy is still unexplored. here, we propose an explanatory framework for the diagnosis of thyroid nod-
ules based on dynamic ceus video, which considers the dynamic perfusion
characteristics and the ampliﬁcation of the lesion region caused by microves-
sel inﬁltration."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_17.pdf,"[fmuti, fmuti]
(1)
where ωiden, ωcls are the learnable weights. 2.1
temporal-based lesions area recognition (tlar)
the great challenge of automatic recognition of lesion area from ceus video is
that the semantic information of the lesion area is diﬀerent in the ceus video of
the diﬀerent microvessel perfusion periods. especially in the perfusion period and
the regression period, the semantic information of lesions cannot be fully depicted
in an isolated ceus frame."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_17.pdf,"finally, we input ffin into the
decoder of the tlar to acquire the feature map of lesion. 2.2
microvessel inﬁltration awareness (mia)
we design a mia module to learn the inﬁltrative areas of microvessel. the tumors
and margin depicted by ceus may be larger than those depicted by gray us
because of continuous inﬁltrative expansion."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_17.pdf,"iterative probabilistic optimization (ipo) unit. based on the fact that
inceptext [15] has experimentally demonstrated that asymmetric convolution
can eﬀectively solve the problem of highly variable size and aspect ratio, we use
asymmetric convolution in the ipo unit. asymmetric convolution-based ipo
unit can optimize the initial distribution pd to generate optimized probabil-
ity maps ˆp that can reﬂect the conﬁdence of benign and malignant diagnosis."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_17.pdf,"for diﬀerentiating malignant and benign, we employ a hybrid loss ltotal that
consists of the cross-entropy loss lcls, the loss of lmse computing optimized
probability maps ˆp, and task focus loss lta. the ltotal is denoted as follows:
ltotal = λ1 · lcls + λ2 · lmse + λ3 · lta
(10)
where λ1, λ2, λ3 are the hyper-parameters to balance the corresponding loss. as
the weight parameter, we set λ1, λ2, λ3 are 0.5,0.2,0.3 in the experiments."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_17.pdf,"3
experiments
dataset. our dataset contained 282 consecutive patients who underwent thy-
roid nodule examination at nanjing drum tower hospital. all patients per-
formed dynamic ceus examination by an experienced sonographer using an
iu22 scanner (philips healthcare, bothell, wa) equipped with a linear trans-
ducer l9-3 probe."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_17.pdf,"on the other hand, a sonographer with more than 10 years of experience
manually annotated the nodule lesion mask to obtain the pixel-level ground-
truth of thyroid nodules segmentation. all data were approved by the institu-
tional review board of nanjing drum tower hospital, and all patients signed
the informed consent before enrollment into the study. our network was implemented using pytorch frame-
work with the single 12 gb gpu of nvidia rtx 3060."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_17.pdf,"quantitative diagnostic results are compared with sota methods and abla-
tion experiments. for fair comparison, all methods used the manually
annotated lesion mask to assist the diagnosis. experimental results in table 2
revealed that our baseline network could be useful for the diagnosis."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_17.pdf,"with the
eﬀective baseline, the introduced modules including tlar, saf and ipo fur-
ther improved the diagnosis accuracy, increasing the accuracy by 9.5%. the
awareness of microvascular inﬁltration using saf and ipo unit was helpful for
ceus-based diagnosis, as it could improve the diagnosis accuracy by 7.69% (as
in table 2). as in appendix fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_39.pdf,"towards ai-driven radiology education:
a self-supervised segmentation-based
framework for high-precision medical
image editing
kazuma kobayashi1,2(b), lin gu2,3, ryuichiro hataya4,2, mototaka miyake5,
yasuyuki takamizawa5, sono ito5, hirokazu watanabe5, yukihiro yoshida5,
hiroki yoshimura6, tatsuya harada3,2, and ryuji hamamoto1,2
1 national cancer center research institute, tokyo, japan
kazumkob@ncc.go.jp
2 riken center for advanced intelligence project, tokyo, japan
3 the university of tokyo, tokyo, japan
4 riken information r&d and strategy headquarters, tokyo, japan
5 national cancer center hospital, tokyo, japan
6 hiroshima university school of medicine, hiroshima, japan
abstract. medical education is essential for providing the best patient
care in medicine, but creating educational materials using real-world
data poses many challenges."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_39.pdf,"trainee physicians require several
years of experience with a diverse range of clinical cases to develop suﬃcient
skills and expertise. however, designing educational materials solely based on
real-world data poses several challenges. for example, although small but signif-
icant disease characteristics (e.g., depth of cancer invasion) can sometimes alter
diagnosis and treatment, collecting pairs with and without these characteristics
is cumbersome."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_39.pdf,"several types of image editing techniques for medical imaging have been
introduced, mainly using generative adversarial networks [5] and, more recently,
diﬀusion models [2]. nevertheless, editing speciﬁc anatomical elements remains
a challenge [1,11]. latent space manipulation generates images by controlling
latent feature axes [4,14], but the editable attributes are often global rather than
ﬁne-grained."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_39.pdf,"the ct values in the range [−2048, 2048] were normalized to [−1, 1]. both were
in-house datasets collected from a single hospital. every image series comprises
two-dimensional (2d) consecutive slices, and we applied our algorithm on a per
2d slice basis.
self-supervised medical image segmentation: we began by optimiz-
ing the hyperparameters to achieve self-supervised segmentation."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_39.pdf,"our medical image editing method can be applied to
medical education, which has been overlooked as an application of ai. future
challenges include improving scalability with fewer manual operations, validat-
ing segmentation maps from a more objective perspective, and comparing our
proposed algorithm with existing methods, such as those based on superpixels
[10]. data use declaration and acknowledgment: the pelvic mri and chest ct
datasets were collected from the national cancer center hospital."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_64.pdf,"this results in anatomical landmarks with diﬀerent spa-
tial distributions across cases. to address these unique challenges, we proposed
a new contrastive learning (cl) framework to detect matching landmarks in
intra-operative us with those from mri as references. speciﬁcally, the technique
leverages two convolutional neural networks (cnns) to learn features between
mri and us that distinguish the inter-modal image patches which are cen-
tered at the matching landmarks from those that are not."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_64.pdf,"[21], we aimed to use infonce as our loss
function with a patch-based approach. to date, cl has not been explored in
multi-modal landmark detection, a unique problem in clinical applications. in
this paper, to bridge this knowledge gap, we proposed a novel cl-based frame-
work for mri-us anatomical landmark detection."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_64.pdf,"[10] (https://archive.sigma2.no/pages/
public/dataset detail.jsf?id=10.11582/2020.00025) to train and evaluate our
proposed method. this dataset is a deep-learning-ready version of the original
resect database, and was released as part of the 2020 learn2reg challenge
[24]. speciﬁcally, easy-resect contains mri and intra-operative us scans
(before resection) of 22 subjects who have undergone low-grade glioma resection
surgeries."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_64.pdf,"6
discussion
inter-modal anatomical landmark localization is still a diﬃcult task, espe-
cially for the described application, where landmarks have no consistent spa-
tial arrangement across diﬀerent cases and image features in us are rough. we
tackled the challenge with the cl framework for the ﬁrst time. as the ﬁrst step
towards multi-modal anatomical landmark detection
675
table 1: landmark identiﬁcation errors (mean±std) per case in mm."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_64.pdf,"we will explore
suitable solutions to extend the application scenarios of our proposed framework
as part of the future investigation. as a baseline comparison, we employed the
sift algorithm, which has demonstrated excellent performance in a large variety
of computer vision problems for keypoint matching. however, in the described
inter-modal landmark identiﬁcation for us-guided brain tumor resection, the
sift algorithm didn’t oﬀer satisfactory results."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_3.pdf,"existing deep learning models have achieved promising per-
formance in recognizing skin diseases from dermoscopic images. however,
these models can only recognize samples from predeﬁned categories, when
they are deployed in the clinic, data from new unknown categories are con-
stantly emerging. therefore, it is crucial to automatically discover and
identify new semantic categories from new data."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_3.pdf,"|n(i)| represents the number of samples. the overall contrastive loss can be expressed as: lcl = (1 − μ) 
i∈b lucl
i
+
μ 
i∈bl lscl
i , where μ denotes the balance coeﬃcient. bl is the labeled subset
of mini-batch data."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_3.pdf,"1, we maintain a ﬁrst-in-ﬁrst-out memory bank m = {zm
k , ym
k }n m
k=1
during the training process, which contains the features of n m most recent sam-
ples and their pseudo labels. n m
k=1 dkym
k , where ρ is the balance coeﬃcient. by aggregating
the information of the neighborhood samples, we are able to ensure consistency
between local samples, which further improves the clustering performance."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_3.pdf,"the dataset contains a total of 25,331 dermoscopic images from
eight categories: melanoma (mel), melanocytic nevus (nv), basal cell carci-
noma (bcc), actinic keratosis (ak), benign keratosis (bkl), dermatoﬁbroma
(df), vascular lesion (vasc), and squamous cell carcinoma (scc). since the
dataset suﬀers from severe category imbalance, we randomly sampled 500 sam-
ples from those major categories (mel, nv, bcc, bkl) to maintain category
balance. then, we construct the ncd task where we treat 50% of the categories
(ak, mel, nv, bcc) as known categories and the remaining 50% of the cate-
gories (bkl, scc, df, vasc) as unknown categories."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_29.pdf,"hence, the identiﬁcation of intrahep-
atic landmarks, such as vessels, and target lesions is crucial for successful and
safe surgery, and intraoperative ultrasound (ious) is the preferred technique
to accomplish this task. despite the increasing use of ious in surgery, its inte-
gration into laparoscopic workﬂows (i.e., laparoscopic intraoperative ultrasound)
remains challenging due to combined problems. c
⃝ the author(s), under exclusive license to springer nature switzerland ag 2023
h. greenspan et al. (eds.): miccai 2023, lncs 14229, pp."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_29.pdf,"our method improves upon previous solutions in terms of robustness and
accuracy, particularly in the presence of rotational motion. such motion is pre-
dominant in the context highlighted above and is the source of additional non-
linearity in the pose estimation problem. to the best of our knowledge, this
is the ﬁrst work that provides a clinically sound and eﬃcient 3d us volume
reconstruction during minimally invasive procedures."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_29.pdf,"frames were cropped to
remove the patient and probe characteristics, then down-sampled to a size of
128 × 128 with an image spacing of 0.22 mm per pixel. first and end stages of the
sequences were removed from the six acquired sequences, as they were considered
to be largely stationary, and aiming to avoid training bias. clips were created by
sliding a window of 7 frames (corresponding to a value of k = 2) with a stride of 1
trackerless volume reconstruction from intraoperative ultrasound images
309
over each continuous sequence, yielding a data set that contains a total of 13734
clips."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_29.pdf,"however, one may notice that the drift error increases with respect to the
sequence length. this remains a challenge for the community even in the case of
linear probe motions. (a) sequence of length 50 frames
(b) sequence of length 300 frames
fig."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_29.pdf,"our method does
not use any additional sensor data and is based on a siamese architecture that
leverages the ultrasound image features and the optical ﬂow to estimate relative
transformations. our method was evaluated on ex vivo porcine data and achieved
translation and orientation errors of 0.449±0.189 mm and 1.3±1.5◦ respectively
with a fair drift error. in the future work, we will extend our work to further
improve the volume reconstruction and use it to register a pre-operative ct
image in order to provide guidance during interventions.
aknowledgments."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_56.pdf,"endoscopy is the gold standard procedure for early detec-
tion and treatment of numerous diseases. obtaining 3d reconstructions
from real endoscopic videos would facilitate the development of assis-
tive tools for practitioners, but it is a challenging problem for current
structure from motion (sfm) methods. feature extraction and match-
ing are key steps in sfm approaches, and these are particularly diﬃcult in
the endoscopy domain due to deformations, poor texture, and numerous
artifacts in the images."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_56.pdf,"3d reconstruction strategies have been studied for long, and one crucial step
in these strategies is feature detection and matching which serves as input for
structure from motion (sfm) pipelines. endoscopic images are a challenging
case for feature detection and matching, due to several well known challenges
for these tasks, such as lack of texture, or the presence of frequent artifacts, like
specular reﬂections. these problems are accentuated when all the elements in
the scene are deformable, as it is the case in most endoscopy scenarios, and in
particular in the real use case studied in our work, the lower gastrointestinal
tract explored with colonoscopies."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_56.pdf,"both these feature extraction methods count with classical, hand-crafted
descriptors that allowed to build such complex applications. https://www.cs.ubc.ca/research/image-matching-challenge/2021/leaderboard/.
tracking adaptation to improve superpoint for reconstruction in endoscopy
585
several challenges. artifacts or the lack of texture result in low amount of corre-
spondences along real endoscopy videos, what motivates the need for improved
strategies."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_56.pdf,"[6] that built a
describe-and-detect strategy that aims to improve sfm applicability. [24] proposes a formulation of the
problem to optimize in an end-to-end manner. [5] on endoscopy
images."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_56.pdf,"sp only reconstructed 3 out of the 5 sequences
while sift and sp-e correctly reconstructed the 5 sequences, with an average
rmse of 4.61mm and 4.71 mm respectively. simulated data lacks some of the
biggest challenges of endoscopy images (e.g. specularities, deformations), but
this experiment suggests that the camera motion estimation quality is similarly
good for all methods when they manage to converge. 4. comparison of reconstructions obtained on seq 095 1 by sift, sp, and our
best model sp-e. the plot shows the reprojection error of each point reconstructed."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_32.pdf,"transliver: a hybrid transformer model
for multi-phase liver lesion classiﬁcation
xierui wang1, hanning ying2, xiaoyin xu3, xiujun cai2, and min zhang1(b)
1 college of computer science and technology,
zhejiang university, hangzhou, china
min zhang@zju.edu.cn
2 sir run run shaw hospital (srrsh), aﬃliated with the zhejiang university
school of medicine, hangzhou, china
3 brigham and women’s hospital, harvard medical school, boston, usa
abstract. early diagnosis of focal liver lesions (flls) can decrease the
fatality rate of liver cancer, which remains a big challenge."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_32.pdf,"for multi-phase fusion,
we utilize cross phase tokens to reinforce the phases communication. in
addition, we introduce a pre-processing unit to resolve realistic annota-
tion issues. extensive experiments are conducted, in which we achieve
an overall accuracy of 90.9% on an in-house dataset of four ct phases
and seven liver lesion classes."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_32.pdf,"a single-phase lesion annotation means the annotation of both lesion position
and its class. in hospitals, collected multi-phase cts are normally grouped by
patients rather than lesions, which makes single-phase lesion annotation insuﬃ-
cient for feature fusion learning. however, the number of lesions inside a single
patient can vary from one to dozens and they can be of diﬀerent types in realis-
tic cases."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_32.pdf,"the reason for this is twofold. [6], including ignoring local information within each patch, extracting only
single-scale features, and lacking inductive bias. second, no complete open liver
lesion classiﬁcation datasets exist."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_32.pdf,"each
convolutional down-sampler contains a residual structure with a 3×3 depthwise
convolution to increase the locality of our model. [4], but they are also prone to overﬁt on small datasets such as
private hospital datasets. [20] to largely reduce the computational overhead by reducing the size
of k and v using depthwise convolution."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_32.pdf,"3
experiments
3.1
liver lesion classiﬁcation
dataset. the employed single-phase annotated dataset is collected from sir run
run shaw hospital (srrsh), aﬃliated with the zhejiang university school of
medicine, and has received the ethics approval of irb. the collection process
can be found in supplementary materials."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_32.pdf,"after the pre-processing unit with window
dice threshold of 0.3, we screen 761 lesions from 444 patients with four phases
hybrid transformer model for multi-phase liver lesion classiﬁcation
335
of cts, seven types of lesions (13.2% of hcc, 5.3% of hm, 11.3% of icc, 22.6%
of hh, 31.1% of hc, 8.7% of fnh, and 7.8% of ha), and totally 4820 slices. to
handle the imbalance of dataset, we randomly select 586 lesions as the training
and validation set with no more than 700 axial slices in each lesion type, and the
rest 175 lesions constitute the test set. lesions from the same patient are either
assigned to the training and validation set or the test set, but not both.
implementations."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_32.pdf,"because the sources of data are diﬀerent among the methods compared above
and to the best of our knowledge, no relevant study based on transformers was
found, we further train some sota normal classiﬁcation models on our dataset. considering the fairness, all the models below are initialized with pre-trained
weights and adopt 2-d structures using the same slice-level classiﬁcation strategy. for completeness, we concatenate the multi-phase features to execute the fusion."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_32.pdf,"we suppose the reason is
twofold. most of lesions in our dataset having few slices weakens the redundancy
between slices in 2-d pipeline, while the number of slices is still obviously larger
than the number of lesions, alleviating the overﬁtting issue. furthermore, vision
transformers are mostly pretrained in 2-d images, causing poor performance
when transferring to 3-d pipeline."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_32.pdf,"then, we fuse the features from diﬀer-
ent phases through cross phase tokens to enhance their information exchange. hybrid transformer model for multi-phase liver lesion classiﬁcation
337
to handle the issues in realistic cases, we design a pre-processing unit to acquire
multi-phase annotated lesions from single-phase annotated ones. we report per-
formance of an overall 90.9% classiﬁcation accuracy on a four-phase seven-class
dataset through quantitative experiments and show obvious improvement com-
pared with sota classiﬁcation methods."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_20.pdf,
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_59.pdf,"by considering that there exists a certain common
mechanism for tumor progression among diﬀerent subtypes of breast
invasive carcinoma(brca), it becomes critical to utilize data from a
related subtype of brca to help predict the patients’ survival in the
target domain. to address this issue, we proposed a tils-tumor inter-
actions guided unsupervised domain adaptation (t2uda) algorithm to
predict the patients’ survival on the target bc subtype. diﬀerent from
the existing feature-level or instance-level transfer learning strategy, our
study considered the fact that the tumor-inﬁltrating lymphocytes (tils)
and its correlation with tumors reveal similar role in the prognosis of
diﬀerent brca subtypes."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_59.pdf,"y. wu and y. zuo—contribute equally to this work
c
⃝ the author(s), under exclusive license to springer nature switzerland ag 2023
h. greenspan et al. (eds.): miccai 2023, lncs 14225, pp. https://doi.org/10.1007/978-3-031-43987-2_59
t2uda
613
keywords: tumor-inﬁltrating lymphocytes · unsupervised domain
adaption · prognosis prediction · graph attention network · breast
cancer
1
introduction
breast cancer (bc) is the most common cancer diagnosed among females and
the second leading cause of cancer death among women after lung cancer [1]. the bc diﬀers greatly in clinical behavior, ranging from carcinoma in site to
aggressive metastatic disease [2,3]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_59.pdf,"[6] devel-
oped a gradient boosting algorithm to predict the disease progression for various
subtypes of bc. however, due to the high-cost of collecting survival information
from the patients, it is still a challenge to build eﬀective machine learning models
for speciﬁc bc subtypes with limited annotation data. to deal with the above challenges, several researchers began to design domain
adaption algorithms, which utilize the labeled data from a related cancer sub-
type to help predict the patients’ survival in the target domain."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_77.pdf,"triangular analysis of geographical
interplay of lymphocytes (triangil):
predicting immunotherapy response
in lung cancer
sara arabyarmohammadi1,2, german corredor1, yufei zhou2,
miguel l´opez de rodas3, kurt schalper3, and anant madabhushi1,4(b)
1 wallace h. coulter department of biomedical engineering, georgia institute
of technology and emory university, atlanta, usa
anantm@emory.edu
2 department of computer and data sciences, case western reserve university,
cleveland, usa
3 department of pathology, school of medicine, yale university, new haven, usa
4 atlanta veterans administration medical center, atlanta, usa
abstract. quantitative immunoﬂuorescence (qif) enables identifying
immune cell subtypes across histopathology images."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_77.pdf,"however, looking at the spatial inter-
play between more than two cell types reveals complex interactions and
co-dependencies that might have implications in predicting response to
therapies like immunotherapy. in this work we present, triangular anal-
ysis of geographical interplay of lymphocytes (triangil), a novel app-
roach involving building of heterogeneous subgraphs to precisely cap-
ture the spatial interplay between multiple cell families. primarily, tri-
angil focuses on triadic closures, and uses metrics to quantify triads
instead of two-by-two relations and therefore considers both inter- and
intra-family relationships between cells."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_77.pdf,"quantitative features that relate to the complex spatial interplay between
diﬀerent types of b- and t-cells in the tme might unlock attributes that are
associated with io response. in this study, we introduce a novel approach called
triangular analysis of geographical interplay of lymphocytes (triangil), rep-
resenting a unique and interpretable way to characterize the distribution, and
higher-order interaction of various cell families (e.g., cancerous cells, stromal
cells, lymphocyte subtypes) across digital histopathology slides. we demonstrate
the eﬃcacy of triaangil for characterizing tme in the context of predicting
1) response to io with immune checkpoint inhibitors (ici), 2) overall survival
(os), in patients with nsclc, and 3) providing novel insights into the spa-
tial interplay between diﬀerent immune cell subtype."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_77.pdf,"[9] which attempted to characterize the interplay between
immune and cancer cells and has proven to be helpful in predicting the recur-
rence in early-stage nsclc. all of these approaches point to overwhelming
evidence that spatial architecture of cells in tme is critical in predicting cancer
triangular analysis of geographical interplay of lymphocytes (triangil)
799
outcome. however, these approaches have not been able to exploit higher-order
interactions and dependencies between multiple cell types (> 2), relationships
that might provide additional actionable insights."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_77.pdf,"this in turn allows for development of
machine classiﬁers to predict outcome and response in lung cancer patients
treated with io.
(2) triangil includes a set of quantitative metrics that capture the interplay
within and between nuclei corresponding to diﬀerent types/families. [2,5,9,14]
while triangil measurements are able to consider inter- and intra-family
relationships.
(3) although deep learning (dl) models (e.g., graph neural networks(gnn))
have shown great capabilities in solving complex problems in the biomedical
ﬁeld, these tend to be black-box in nature. a key consideration in cancer
immunology is the need for actionable insights into the spatial relationships
between diﬀerent types of immune cells."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_77.pdf,"4.3
experiment 1: immunotherapy response prediction in lung
cancer
design: triangil was also trained to diﬀerentiate between patients who
responded to io and those who did not. for our study, the responders to io
were identiﬁed as those patients with complete response, partial response, and
triangular analysis of geographical interplay of lymphocytes (triangil)
803
stable disease, and non-responders were patients with progressive disease. a
linear discriminant analysis (lda) classiﬁer was trained on st to predict which
patients would respond to io."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_77.pdf,"asterisks * indicate the models with p < 0.05 that statistically signiﬁcantly prognosti-
cate os post-io. (color ﬁgure online)
triangular analysis of geographical interplay of lymphocytes (triangil)
805
were 0.64, and 0.63 respectively. therefore, overall triangil worked marginally
better than gnn, with much higher biological interpretability."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_4.pdf,"uncertainty-informed mutual learning
for joint medical image classiﬁcation
and segmentation
kai ren1,2, ke zou1,2, xianjie liu2, yidi chen3, xuedong yuan1,2(b),
xiaojing shen1,4, meng wang5, and huazhu fu5(b)
1 national key laboratory of fundamental science on synthetic vision,
sichuan university, chengdu, sichuan, china
yxd@scu.edu.cn
2 college of computer science, sichuan university, chengdu, sichuan, china
3 department of radiology, west china hospital, sichuan university, chengdu,
sichuan, china
4 college of mathematics, sichuan university, chengdu, sichuan, china
5 institute of high performance computing, agency for science, technology and
research, singapore, singapore
hzfu@ieee.org
abstract. classiﬁcation and segmentation are crucial in medical image
analysis as they enable accurate diagnosis and disease monitoring."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_4.pdf,"2.1
uncertainty estimation for classiﬁcation and segmentation
classiﬁcation uncertainty estimation. for the k classiﬁcation problems,
we utilize subjective logic [7] to produce the belief mass of each class and the
uncertainty mass of the whole image based on evidence. accordingly, given a
classiﬁcation result, its k + 1 mass values are all non-negative and their sum is
one:
k

k=1
bc
k + u c = 1,
(1)
where bc
k ≥ 0 and u c ≥ 0 denote the probability belonging to the kth class and
the overall uncertainty value, respectively."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_39.pdf,"[30] and map all lesion sub-types to the super-classes “benign”
or “malignant”. we emulate two acquisition shifts by deﬁning either images
from the memorial sloan kettering cancer center (mskcc) or hospital clinic
barcelona (hcb) as the target domain and the remaining images as the source
silent failures in medical image classiﬁcation
403
domain. further, a manifestation shift is designed by deﬁning the lesion sub-
types “keratosis-like” (benign) and “actinic keratosis” (malignant) as the tar-
get domain."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_58.pdf,"this design enables the network to capture optimal feature represen-
tations for both ct and x-ray images while maintaining the ability to learn
shared representations between the two modalities despite dimensional diﬀer-
ences. to address the challenge of information interaction between unpaired
cross-modal data, we introduce a momentum-updated prototype learning strat-
egy to condense modality-speciﬁc knowledge. this strategy groups similar repre-
sentations into the same prototype and iteratively updates the prototypes with a
momentum term to capture essential information in each modality."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_58.pdf,"we employ the online data argumen-
tation, including random cropping and zooming, random rotation, and horizon-
tal/vertical ﬂip, to enlarge the x-ray training dataset. we follow the extension of
[20] for weight initialization and use the adamw optimizer [11] and empirically
set the initial learning rate to 0.0001, batch size to 2 and 32 for segmentation
and classiﬁcation, maximum iterations to 25w, momentum factor λ to 0.99, and
the number of prototypes k to 256.
to evaluate the covid-19 segmentation performance, we utilized six met-
rics, including the dice similarity coeﬃcient (dsc), intersection over union
(iou), sensitivity (sen), speciﬁcity (spe), hausdorﬀ distance (hd), and aver-
age surface distance (asd). these metrics provide a comprehensive assessment
of the segmentation quality."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_58.pdf,"especially, uci includes a multi-modal shared encoder to cap-
ture optimal feature representations for ct and x-ray images while also learning
shared representations between the two modalities. to address the challenge of
information interaction between unpaired cross-modal data, uci further devel-
ops a kc and ki module to condense modality-speciﬁc knowledge and facilitates
cross-modal interaction, thereby enhancing segmentation training. our experi-
ments demonstrate that the uci method outperforms existing segmentation
models for covid-19 segmentation.
acknowledgment."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_7.pdf,"we additionally trimmed trees
to a depth of ten in our experiments. this decision reﬂects a balance between
the computational demands of depth-ﬁrst tree traversal in each training step
and the complexity of the training meshes. we excluded from our study trees
1 https://github.com/intra3d2019/intra."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_7.pdf,"results show high similarities between
histograms demonstrating that generated blood vessels are realistic. given the
diﬀerences with the baselines generated topologies, for a fair comparison, we
limited our evaluation to a visual inspection of the meshes. the qualitative analyses consisted of a visual evaluation of the reconstructed
outputs provided by the decoder network."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_7.pdf,"this could lead to more accurate and eﬃcient modeling of blood vessels
and potentially other non-tree-like structures such as capillary networks. since
the presented framework would require signiﬁcant adaptations to accommodate
such complex topologies, exploring this problem would certainly be an interest-
ing direction for future research. additionally, the generated geometries might
show self-intersections."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_72.pdf,"weakpolyp: you only look bounding box
for polyp segmentation
jun wei1,2, yiwen hu1,2,5, shuguang cui1,2, s. kevin zhou3,4,
and zhen li1,2(b)
1 fnii, cuhk-shenzhen, shenzhen, china
junwei@link.cuhk.edu.cn, lizhen@cuhk.edu.cn
2 sse, cuhk-shenzhen, shenzhen, china
3 school of biomedical engineering and suzhou institute for advanced research,
university of science and technology of china, suzhou, china
4 institute of computing technology, chinese academy of sciences, beijing, china
5 south china hospital, shenzhen university, shenzhen, china
abstract. limited by expensive pixel-level labels, polyp segmentation
models are plagued by data shortage and suﬀer from impaired general-
ization."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_72.pdf,"then, this transformed mask is supervised by the bounding box
annotation. this indirect supervision avoids the misleading of box-shape bias of
annotations. however, many regions in the predicted mask are lost in the projec-
tion and therefore get no supervision."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_72.pdf,"unfortunately, models trained in this way show poor generalization. because
there is a strong box-shape bias in b. training with this bias, the model is forced
to predict the box-shape mask, unable to maintain the polyp’s contours. to solve
this, we innovatively use b to supervise the bounding box mask (i.e.,t1/t2)
of p1/p2, rather than p1/p2 itself."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_72.pdf,"by m2b, p1 and p2 are transformed into t1 and t2, respectively. because both t1/t2 and b are box-like masks, we directly calculate the super-
vision loss between them without worrying about the misguidance of box-shape
bias. speciﬁcally, we follow [5,19] to adopt bce loss lbce and dice loss ldice
for model supervision, as shown in eq."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_72.pdf,"grabcut can not well distinguish between them, resulting in poor
masks. our weakpolyp predictably outperforms the model supervised by box
masks because it is not aﬀected by the box-shape bias of the annotations. interestingly, weakpolyp even surpasses the fully supervised model on sun-
seg, which indicates that there is a lot of noise in the pixel-level annota-
764
j. wei et al.
table 3."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_22.pdf,"wσ(dt, di)



composite kernel wti
(stj − sti) ≤ 0
∀t, i, j ̸= i
(2)
where the indices t, i, j traverse all n images in the batch since there are no
“hard” positive or negative samples, as in simclr or supcon, but all images
are considered as positive and negative at the same time. as commonly done in
cl [3], this condition can be transformed into an optimization problem using
230
e. sarfati et al.
fig. 1. example of representation space constructed by our loss function, leveraging
both continuous depth coordinate d and discrete label y (i.e., radiological diagnosis
yradio)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_22.pdf,"for sampling, inspired by [4], we propose a strategy well-adapted for con-
trastive learning in 2d medical imaging. we ﬁrst sample n patients, where n
is the batch size, in a balanced way with respect to the radiological/histological
classes; namely, we roughly have the same number of subjects per class. then,
we randomly select only one slice per subject."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_22.pdf,"we use the same sampling strategy also for clas-
siﬁcation baselines. for d2
histo, which has fewer patients than the batch size, we
use a balanced sampling strategy with respect to the radiological/histological
classes with no obligation of one slice per patient in the batch. as we work
with 2d slices rather than 3d volumes, we compute the average probability per
patient of having the pathology."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_22.pdf,"supcon per-
forms well on the training set of dradio (ﬁgure available in the supplementary
material), as well as d2
histo with tinynet, but it poorly generalizes to d1
histo
and d1+2
histo. the method depth-aware manages to correctly encode the depth
position but not the diagnostic class label.
to assess the clinical performance of the pretraining methods, we also com-
pute the balanced accuracy scores (bacc) of the trained classiﬁers, which is
compared in table 2 to the bacc achieved by radiologists who were asked to
visually assess the presence or absence of cirrhosis for the n=106 cases of d1
histo. table 2. comparison of the pretraining methods
with a binary radiological annotation for cirrhosis
on d1
histo."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_22.pdf,"[10] or barlow twins [25], that need smaller batch
sizes and have shown greater performances in computer vision tasks. in terms of
application, our method could be easily translated to other medical problems,
such as pancreas cancer prediction using the presence of intrapancreatic fat,
diabetes mellitus or obesity as discrete meta-labels.
acknowledgments. this work was supported by r´egion ile-de-france (chotheria
project) and anrt (cifre #2021/1735)."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_66.pdf,"we propose an unsupervised deep learning method to recon-
struct a 3d tomographic image from biplanar x-rays, to reduce the num-
ber of required projections, the patient dose, and the acquisition time. to
address this ill-posed problem, we introduce prior knowledge of anatomic
structures by training a generative model on 3d cts of head and neck. we optimize the latent vectors of the generative model to recover a vol-
ume that both integrates this prior knowledge and ensures consistency
between the reconstructed image and input projections."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_66.pdf,"we evaluate our
method in a clinical conﬁguration for radiotherapy. keywords: image reconstruction · inverse problem · sparse
sampling · deep generative model · ct
1
introduction
tomographic imaging estimates body density using hundreds of x-ray projec-
tions, but it’s slow and harmful to patients. acquisition time may be too high
for certain applications, and each projection adds dose to the patient."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_66.pdf,"this can improve image-guided therapies and preoperative planning, espe-
cially for radiotherapy, which requires precise patient positioning with minimal
radiation exposure. however, this task is an ill-posed inverse problem: x-ray measurements are
the result of attenuation integration across the body, which makes them very
supplementary information the online version contains supplementary material
available at https://doi.org/10.1007/978-3-031-43999-5_66. c
⃝ the author(s), under exclusive license to springer nature switzerland ag 2023
h. greenspan et al. (eds.): miccai 2023, lncs 14229, pp."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_66.pdf,"at inference, we
estimate the maximum a posteriori (map) volume on this manifold given very
few projections: we ﬁnd the latent vectors that minimize the error between the
synthetic projections from the corresponding volume on the manifold and the
real ones. in this section, we formalize the problem, describe how we learn the
manifold, and detail how we optimize the latent vectors. 2.1
problem formulation
given a small set of projections {ii}i, possibly as few as two, we would like
to reconstruct the 3d tomographic volume v that generates these projections."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_66.pdf,"as discussed in the introduction, we rely on a generative
model, which we describe in the next section. then, we describe how exactly we
use this generative model for regularization term r(v) and how this changes our
optimization problem. 2.2
manifold learning
to regularize the domain space of solutions, we leverage a style-based generative
model to learn deep priors of anatomic structures."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_66.pdf,"the mean μ and standard deviation σ of the mapped latent space can be
computed by mapping over initial latent space n(0, i ) after training. the map-
ping network learns to disentangle the initial latent space relatively to semantic
features which is crucial for the inverse problem. for the dis-
criminator, we use the non-saturating logistic loss with r1 regularization [19]."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_66.pdf,"for the reconstruction, we performed the optimization on
gpu v100 pci-e using adam, with learning rate of 1e−3. by grid search on the
validation set, we selected the best weights that well balance between structure
and ﬁne-grained details, λ2 = 10, λp = 0.1, λw = 0.1, λc = 0.05, λn = 10. we
perform 100 optimization steps starting from the mean of the mapped latent
space, which takes 25 s, enabling clinical use.
3.3
results and discussion
manifold learning."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_66.pdf,"x2ct-gan [30] pro-
duced realistic structures, but failed to match the actual structures as it does not
enforce consistency with the projections. [23]. without a previous ct volume, nerp lacks the necessary prior
to accurately solve the ill-posed problem. even when initialised with a previous
ct volume, nerp often fails to converge to the correct volume and introduces
many artifacts when few projections are used."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_66.pdf,"deviation from pro-
jections, as in x2ct-gan, leads to inaccurate reconstruction. however, relying
solely on projection consistency is inadequate for this ill-posed problem. nerp
matches projections but cannot reconstruct the volume correctly."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_5.pdf,"however, those works are mainly designed based on the experience of pre-
vious natural video object detection studies, ignoring the inherent uniqueness
of the colonoscopy motion patterns. thus, we rethink the video polyp detection
task and conclude three core challenges in colonoscopy videos. 1) fast motion
speed."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_5.pdf,"(b) the performance of
fgfa [26] using multiple reference frames increases on imagenetvid while decreasing
on ldpolypvideo. (c) the typical challenges in colonoscopy videos. yellow arrows
point to the polyp, and red arrows point to distraction that causes false detection."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_5.pdf,"as shown in fig. 1(e), we noticed that some polyps could be seen as
concealed objects in the colonoscopy video since such polyps have a very similar
appearance to the intestine wall. the model will be confused by such frames in
inference and result in high false-positive or false-negative predictions.
to address the above issues, we propose the yona framework, which fully
exploits the reference frame information and only needs one adjacent reference
frame for accurate video polyp detection. speciﬁcally, we propose the foreground
temporal alignment (fta) module to explicitly align the foreground channel
activation patterns between adjacent features according to their foreground simi-
larity."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_5.pdf,"[9] (train set: 20,942 frames, test set: 12,933
frames), and cvc-videoclinicdb [1] (train set: 7995 frames, test set: 2030
frames). for the fairness of the experiments, we keep the same dataset settings
for yona and all other methods. 50
y. jiang et al.
table 1."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_5.pdf,"in this paper, we proposed the yona frame-
work that requires only one adjacent reference frame for accurate and fast video
polyp detection. to address the problem of fast-moving polyps, we introduced
the foreground temporal alignment module, which explicitly aligns the channel
patterns of two frames according to their foreground similarity. for the complex
background content, we designed the background dynamic alignment module to
mitigate the large variances by exploiting the inter-frame diﬀerence."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_58.pdf,"vox2vec: a framework for self-supervised
contrastive learning of voxel-level
representations in medical images
mikhail goncharov1(b), vera soboleva2, anvar kurmukov3, maxim pisov4,
and mikhail belyaev1,3
1 skolkovo institute of science and technology, moscow, russia
mikhail.goncharov2@skoltech.ru
2 artiﬁcial intelligence research institute (airi), moscow, russia
3 institute for information transmission problems, moscow, russia
4 ira-labs, moscow, russia
abstract. this paper introduces vox2vec — a contrastive method for
self-supervised learning (ssl) of voxel-level representations."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_58.pdf,"the reason is that producing a fea-
ture map with more than 100 channels in full resolution is infeasible due to
memory constraints. meanwhile, to be suitable for many downstream tasks, rep-
resentations should have a dimensionality of about 1000, as in [8].
to address this issue, we utilize a 3d fpn architecture instead of a stan-
dard 3d unet. fpn returns voxel-level representations in the form of a feature
pyramid."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_58.pdf,"we
demonstrate an example of the excellent performance of vox2vec-fpn in both
linear and non-linear probing regimes in supplementary materials. we reproduce the key results on msd challenge ct datasets, which contain
tumor and organ segmentation tasks. table 2 shows that in the vox2vec repre-
sentation space, organ voxels can be separated from tumor voxels with a quality
comparable to the model trained from scratch."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_58.pdf,"the number of trainable paramaters of
diﬀerent models in diﬀerent evaluation
setups. cross validation dice score on ct tasks of msd challenge. liver
lung
pancreas
hepatic vessel spleen
colon
model
organ tumor tumor organ tumor organ
tumor
organ
cancer
from scratch
fpn
94.4
44.6
53.1
77.1
28.0
53.7
49.4
96.0
32.2
non-linear probing
vox2vec-fpn
94.7
43.9
49.5
71.4
28.5
58.1
54.8
95.1
24.8
ﬁne-tuning
swinunetr
95.0
49.3
55.2
75.2
35.9
60.9
57.5
95.5
29.2
vox2vec-fpn
95.6
51.0
56.6
77.0
31.8
59.5
62.4
96.1
30.1
6
conclusion
in this work, we present vox2vec — a self-supervised framework for voxel-wise
representation learning in medical imaging."
/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_58.pdf,"we plan to investigate
further how the performance of vox2vec scales with the increasing size of the
vox2vec
613
pre-training dataset and the pre-trained architecture size. another interesting
research direction is exploring the eﬀectiveness of vox2vec with regard to domain
adaptation to address the challenges of domain shift between diﬀerent medical
imaging datasets obtained from diﬀerent sources. a particular interest is a low-
shot scenario when only a few examples from the target domain are available.
acknowledgements."
