{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Libraries\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "import uuid # for generating unique identifiers for each paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Important paths\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base path to folder where output files will be stored\n",
    "output_path = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/database_analysis_output/outputs/'\n",
    "\n",
    "# Base path to folders \n",
    "base_path = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/'\n",
    "\n",
    "# Path to the MICCAI 2023 pdfs\n",
    "pdf_path = base_path + 'miccai_2023/'\n",
    "\n",
    "# Path to the MICCAI 2023 database of all 730 papers and their metadata\n",
    "database_path = base_path + 'databases/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Dataframe 1: MICCAI 2023\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_miccai = pd.read_csv(database_path +'database_miccai_2023.csv', index_col=[0], header=[0], encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 731 entries, 0 to 730\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   Title                731 non-null    object\n",
      " 1   Authors              731 non-null    object\n",
      " 2   Page numbers         731 non-null    object\n",
      " 3   DOI                  731 non-null    object\n",
      " 4   Year of publication  731 non-null    int64 \n",
      " 5   Part of publication  731 non-null    int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 40.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_miccai.info()\n",
    "\n",
    "#731 entries, 0 to 730 \n",
    "#6 columns in total\n",
    "#title, authors, page numbers, doi, year of publication, part of publication\n",
    "#dtype: int64(2), object(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a total of 730 papers in MICCAI 2023. However, the dataframe contains 731. Examining the dataframe, \n",
    "I will first look into the number of papers by publication (Part of Publication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Page numbers</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Year of publication</th>\n",
       "      <th>Part of publication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PET-Diffusion: Unsupervised PET Enhancement Ba...</td>\n",
       "      <td>Caiwen Jiang, Yongsheng Pan, Mianxin Liu, Lei ...</td>\n",
       "      <td>3-12</td>\n",
       "      <td>10.1007/978-3-031-43907-0_1</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MedIM: Boost Medical Image Representation via ...</td>\n",
       "      <td>Yutong Xie, Lin Gu, Tatsuya Harada, Jianpeng Z...</td>\n",
       "      <td>13-23</td>\n",
       "      <td>10.1007/978-3-031-43907-0_2</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UOD: Universal One-Shot Detection of Anatomica...</td>\n",
       "      <td>Heqin Zhu, Quan Quan, Qingsong Yao, Zaiyi Liu,...</td>\n",
       "      <td>24-34</td>\n",
       "      <td>10.1007/978-3-031-43907-0_3</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S2^2ME: Spatial-Spectral Mutual Teaching and E...</td>\n",
       "      <td>An Wang, Mengya Xu, Yang Zhang, Mobarakol Isla...</td>\n",
       "      <td>35-45</td>\n",
       "      <td>10.1007/978-3-031-43907-0_4</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Modularity-Constrained Dynamic Representation ...</td>\n",
       "      <td>Qianqian Wang, Mengqi Wu, Yuqi Fang, Wei Wang,...</td>\n",
       "      <td>46-56</td>\n",
       "      <td>10.1007/978-3-031-43907-0_5</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  PET-Diffusion: Unsupervised PET Enhancement Ba...   \n",
       "1  MedIM: Boost Medical Image Representation via ...   \n",
       "2  UOD: Universal One-Shot Detection of Anatomica...   \n",
       "3  S2^2ME: Spatial-Spectral Mutual Teaching and E...   \n",
       "4  Modularity-Constrained Dynamic Representation ...   \n",
       "\n",
       "                                             Authors Page numbers  \\\n",
       "0  Caiwen Jiang, Yongsheng Pan, Mianxin Liu, Lei ...         3-12   \n",
       "1  Yutong Xie, Lin Gu, Tatsuya Harada, Jianpeng Z...        13-23   \n",
       "2  Heqin Zhu, Quan Quan, Qingsong Yao, Zaiyi Liu,...        24-34   \n",
       "3  An Wang, Mengya Xu, Yang Zhang, Mobarakol Isla...        35-45   \n",
       "4  Qianqian Wang, Mengqi Wu, Yuqi Fang, Wei Wang,...        46-56   \n",
       "\n",
       "                           DOI  Year of publication  Part of publication  \n",
       "0  10.1007/978-3-031-43907-0_1                 2023                    1  \n",
       "1  10.1007/978-3-031-43907-0_2                 2023                    1  \n",
       "2  10.1007/978-3-031-43907-0_3                 2023                    1  \n",
       "3  10.1007/978-3-031-43907-0_4                 2023                    1  \n",
       "4  10.1007/978-3-031-43907-0_5                 2023                    1  "
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_miccai.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PET-Diffusion: Unsupervised PET Enhancement Based on\\xa0the\\xa0Latent Diffusion Model',\n",
       " 'MedIM: Boost Medical Image Representation via\\xa0Radiology Report-Guided Masking',\n",
       " 'UOD: Universal One-Shot Detection of\\xa0Anatomical Landmarks',\n",
       " 'S2^2ME: Spatial-Spectral Mutual Teaching and\\xa0Ensemble Learning for\\xa0Scribble-Supervised Polyp Segmentation',\n",
       " 'Modularity-Constrained Dynamic Representation Learning for Interpretable Brain Disorder Analysis with Functional MRI']"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_list_2023 = df_miccai['Title'].tolist()\n",
    "title_list_2023[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers in Publication 1: 73\n",
      "Number of papers in Publication 2: 74\n",
      "Number of papers in Publication 3: 72\n",
      "Number of papers in Publication 4: 75\n",
      "Number of papers in Publication 5: 76\n",
      "Number of papers in Publication 6: 77\n",
      "Number of papers in Publication 7: 75\n",
      "Number of papers in Publication 8: 65\n",
      "Number of papers in Publication 9: 70\n",
      "Number of papers in Publication 10: 74\n",
      "Total number of papers: 731\n"
     ]
    }
   ],
   "source": [
    "# count the number of papers for each publication. There is 10 publications in total\n",
    "\n",
    "print('Number of papers in Publication 1:', df_miccai['Part of publication'].value_counts()[1]) #73\n",
    "print('Number of papers in Publication 2:', df_miccai['Part of publication'].value_counts()[2]) #74\n",
    "print('Number of papers in Publication 3:', df_miccai['Part of publication'].value_counts()[3]) #72\n",
    "print('Number of papers in Publication 4:', df_miccai['Part of publication'].value_counts()[4]) #75\n",
    "print('Number of papers in Publication 5:', df_miccai['Part of publication'].value_counts()[5]) #76\n",
    "print('Number of papers in Publication 6:', df_miccai['Part of publication'].value_counts()[6]) #77\n",
    "print('Number of papers in Publication 7:', df_miccai['Part of publication'].value_counts()[7]) #75\n",
    "print('Number of papers in Publication 8:', df_miccai['Part of publication'].value_counts()[8]) #65\n",
    "print('Number of papers in Publication 9:', df_miccai['Part of publication'].value_counts()[9]) #70\n",
    "print('Number of papers in Publication 10:', df_miccai['Part of publication'].value_counts()[10]) #74\n",
    "\n",
    "# count the total number of papers in the dataframe\n",
    "print('Total number of papers:', df_miccai['Part of publication'].value_counts().sum()) #731"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Dataframe 1: MICCAI 2023 cancer papers by title\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "# selecting papers with cancer in the title, add them into a new dataframe\n",
    "df_cancer = df_miccai.loc[df_miccai.Title.str.contains('Cancer', regex=False, na=False)]\n",
    "\n",
    "print(len(df_cancer)) # 23 papers with cancer in the title\n",
    "\n",
    "# saving dataframe for papers with cancer in the title\n",
    "# df_cancer.to_csv(database_path +'database_miccai_2023_cancer.csv', index=True, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list_cancer = df_cancer[\"Title\"]\n",
    "author_list_cancer = df_cancer[\"Authors\"]\n",
    "\n",
    "author_list_cancer = author_list_cancer.to_list()\n",
    "title_list_cancer = title_list_cancer.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "print(len(author_list_cancer)) #23\n",
    "print(len(title_list_cancer))  #23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **Selecting a scope of papers from MICCAI 2023**\n",
    "***\n",
    "***\n",
    "\n",
    "**Scope criteria:** Selecting papers, that researched within the field of cancer-related illnesses by searching for cancer-related keywords in the text of each research paper. The text is defined from the start of Abstraction ending with the last line of Conclusion, exluding the Title of the paper, the authors and affiliations, the Acknowlegdement and the References. \n",
    "\n",
    "Cancer-related keywords could be words such as 'cancer', 'tumor' and/or 'tumours'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted titles from 189 selected papers.\n",
      "With the keyword(s) being ['cancer'], 189 papers were selected as relevant to cancer research.\n"
     ]
    }
   ],
   "source": [
    "# Function to extract the full text from the PDF\n",
    "def extract_text(pdf_path):\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        full_text = \"\"\n",
    "        for page in doc:\n",
    "            full_text += page.get_text()\n",
    "    return full_text\n",
    "\n",
    "# Function to find if any of the keywords appear in the section between Abstract and Conclusion\n",
    "def find_keywords_section(full_text, keywords):\n",
    "     # Regular expressions to find the end of the affiliations section\n",
    "    affiliations_end = re.search(r'\\d{1,2}\\s+(?:\\w+\\.)+@\\w+\\.\\w{2,}', full_text)\n",
    "    \n",
    "    # Start searching from the end of affiliations if found, otherwise from the start of the text\n",
    "    start_idx = affiliations_end.end() if affiliations_end else 0\n",
    "    \n",
    "    # Look for the Abstract and Conclusion sections\n",
    "    abstract_idx = full_text.lower().find(\"abstract\", start_idx)\n",
    "    conclusion_idx = full_text.lower().rfind(\"conclusion\", abstract_idx)\n",
    "    acknowledgements_idx = full_text.lower().find(\"acknowledgements\", conclusion_idx)\n",
    "    \n",
    "    # Adjust the end index to stop at Acknowledgements if it exists, otherwise use Conclusion index\n",
    "    end_search_idx = acknowledgements_idx if acknowledgements_idx != -1 else conclusion_idx\n",
    "    \n",
    "    # If neither Abstract nor Conclusion is found, search the entire text\n",
    "    if abstract_idx == -1 and conclusion_idx == -1:\n",
    "        searchable_text = full_text[start_idx:]\n",
    "    else:\n",
    "        # Search from Abstract to Conclusion or Acknowledgements\n",
    "        searchable_text = full_text[abstract_idx:end_search_idx].lower()\n",
    "    \n",
    "    # Search for each keyword within the determined section, stop at first match\n",
    "    for keyword in keywords:\n",
    "        if keyword.lower() in searchable_text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Function to extract the title from the PDF\n",
    "def extract_title(pdf_path):\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        first_page_text = doc[0].get_text(\"text\")\n",
    "        \n",
    "        # Regular expression to find the start of affiliations or author names\n",
    "        # Looks for sequences in author lists or affiliations, such as numbers and parentheses\n",
    "        author_or_affiliations_start = re.search(r'\\b[A-Z][a-z]+ [A-Z]\\.|\\b[A-Z][a-z]+\\s[A-Z][a-z]+[1-9]', first_page_text)\n",
    "\n",
    "        title = \"\"\n",
    "        if author_or_affiliations_start:\n",
    "            # Extract text up to the start of the author list or affiliations as potential title text\n",
    "            potential_title_text = first_page_text[:author_or_affiliations_start.start()].strip()\n",
    "            title_lines = potential_title_text.split('\\n')\n",
    "            \n",
    "            # The title is expected to be a continuous block of text at the top of the page,\n",
    "            # possibly after a journal header or similar: look for a large continuous block of text.\n",
    "            for line in reversed(title_lines):\n",
    "                if line.strip():  \n",
    "                    # Prepend to keep the title in the correct order\n",
    "                    title = line + \" \" + title\n",
    "                else:\n",
    "                    # An empty line might indicate the end of the title block\n",
    "                    break\n",
    "        else:\n",
    "            # If no author list or affiliation section is identified, use the first non-empty line\n",
    "            for line in first_page_text.split('\\n'):\n",
    "                if line.strip():\n",
    "                    title = line\n",
    "                    break\n",
    "\n",
    "        title = title.strip()  # Clean up whitespace\n",
    "        return title\n",
    "\n",
    "selected_papers = []\n",
    "titles = []\n",
    "\n",
    "# List of keywords to search for\n",
    "keywords = [\"cancer\"]\n",
    "\n",
    "# Iterate over each volume and search for keywords\n",
    "for i in range(1, 11):  # Volumes 1 to 10\n",
    "    folder_name = f\"miccai23vol{i}\"\n",
    "    folder_path = os.path.join(pdf_path, folder_name)\n",
    "    \n",
    "    for pdf in os.listdir(folder_path):\n",
    "        if pdf.endswith(\".pdf\"):\n",
    "            pdf_path_ = os.path.join(folder_path, pdf)\n",
    "            full_text = extract_text(pdf_path_)\n",
    "            if find_keywords_section(full_text, keywords):\n",
    "                selected_papers.append(os.path.join(folder_name, pdf))\n",
    "\n",
    "# Extract titles from selected papers\n",
    "for paper_path in selected_papers:\n",
    "    full_paper_path = os.path.join(pdf_path, paper_path)\n",
    "    title = extract_title(full_paper_path)\n",
    "    titles.append(title)\n",
    "\n",
    "print(f\"Extracted titles from {len(titles)} selected papers.\")\n",
    "print(f\"With the keyword(s) being {keywords}, {len(selected_papers)} papers were selected as relevant to cancer research.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Save the selected papers and their paths to a CSV file\n",
    "# selected_papers_path = pd.DataFrame({\"Path\": selected_papers, \"Title\": titles})\n",
    "# selected_papers_path.to_csv(output_path + 'papers_by_paths_titles.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the extracted titles to a CSV file\n",
    "# titles = pd.DataFrame({'Title': titles})\n",
    "# titles\n",
    "# titles.to_csv(output_path + 'titles.csv', index=False, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Geometry-Invariant Abnormality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TPRO: Text-Prompting-Based Weakly Supervised H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vox2vec: A Framework for Self-supervised Contr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pick the Best Pre-trained Model: Towards Trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Solving Low-Dose CT Reconstruction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Noise2Aliasing: Unsupervised Deep Learning for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Revealing Anatomical Structures in PET to Gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Geometric Ultrasound Localization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>FreeSeed: Frequency-Band-Aware and Self-guided...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title\n",
       "0                       Geometry-Invariant Abnormality\n",
       "1    3D Arterial Segmentation via Single 2D Project...\n",
       "2    TPRO: Text-Prompting-Based Weakly Supervised H...\n",
       "3    vox2vec: A Framework for Self-supervised Contr...\n",
       "4    Pick the Best Pre-trained Model: Towards Trans...\n",
       "..                                                 ...\n",
       "184                 Solving Low-Dose CT Reconstruction\n",
       "185  Noise2Aliasing: Unsupervised Deep Learning for...\n",
       "186  Revealing Anatomical Structures in PET to Gene...\n",
       "187                  Geometric Ultrasound Localization\n",
       "188  FreeSeed: Frequency-Band-Aware and Self-guided...\n",
       "\n",
       "[189 rows x 1 columns]"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Load the datasets\n",
    "# titles_df = pd.read_csv(output_path + 'titles.csv')\n",
    "# database_df = df_miccai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creates a search pattern from the first two words of each title\n",
    "# titles_df['search_pattern'] = titles_df['Title'].str.split().str.slice(0, 2).str.join(' ').str.lower()\n",
    "\n",
    "# # Find the rows in the database that match the search pattern\n",
    "# matched_rows = []\n",
    "# for pattern in titles_df['search_pattern']:\n",
    "#     matched_rows.extend(database_df[database_df['Title'].str.lower().str.startswith(pattern)].index.tolist())\n",
    "# matched_df = database_df.loc[matched_rows]\n",
    "\n",
    "# # Save the matched papers and the search pattern to CSV files\n",
    "# matched_df.to_csv(output_path + 'matched_papers.csv', index=False) #187 rows, missing two papers\n",
    "# titles_df.to_csv(output_path + 'search_pattern.csv') # 189 titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matched_df = pd.read_csv(output_path + 'matched_papers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hard coding: adding the two missing papers into the dataframe \"matched_df\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Page numbers</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Year of publication</th>\n",
       "      <th>Part of publication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PET-Diffusion: Unsupervised PET Enhancement Ba...</td>\n",
       "      <td>Caiwen Jiang, Yongsheng Pan, Mianxin Liu, Lei ...</td>\n",
       "      <td>3-12</td>\n",
       "      <td>10.1007/978-3-031-43907-0_1</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S2^2ME: Spatial-Spectral Mutual Teaching and E...</td>\n",
       "      <td>An Wang, Mengya Xu, Yang Zhang, Mobarakol Isla...</td>\n",
       "      <td>35-45</td>\n",
       "      <td>10.1007/978-3-031-43907-0_4</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  PET-Diffusion: Unsupervised PET Enhancement Ba...   \n",
       "3  S2^2ME: Spatial-Spectral Mutual Teaching and E...   \n",
       "\n",
       "                                             Authors Page numbers  \\\n",
       "0  Caiwen Jiang, Yongsheng Pan, Mianxin Liu, Lei ...         3-12   \n",
       "3  An Wang, Mengya Xu, Yang Zhang, Mobarakol Isla...        35-45   \n",
       "\n",
       "                           DOI  Year of publication  Part of publication  \n",
       "0  10.1007/978-3-031-43907-0_1                 2023                    1  \n",
       "3  10.1007/978-3-031-43907-0_4                 2023                    1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Locating the missing papers in the original database for all 730 papers \n",
    "# missing_papers = df_miccai.loc[df_miccai['Title'].isin(\n",
    "#     ['PET-Diffusion: Unsupervised PET Enhancement Based on the Latent Diffusion Model', \n",
    "#      'S2^2ME: Spatial-Spectral Mutual Teaching and Ensemble Learning for Scribble-Supervised Polyp Segmentation'])]\n",
    "\n",
    "# missing_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the matched and missing papers into a single dataframe\n",
    "#selected_papers_df = pd.merge(matched_df, missing_papers, on='Title', how='outer')\n",
    "\n",
    "# Drop the duplicate columns from the merge\n",
    "#selected_papers_df.drop(columns=['Part of publication_y', 'Authors_y', 'Page numbers_y', 'DOI_y','Year of publication_y'], inplace=True)\n",
    "#selected_papers_df.drop(columns=['Page numbers_y', 'DOI_y', 'Year of publication_y'], inplace=True)\n",
    "\n",
    "# Rename/refine the columns to match the original database \n",
    "#selected_papers_df.rename(columns={'Title': 'title', 'Part of publication_x': 'vol_number', 'Authors_x': 'authors', \n",
    "#                                   'DOI_x': 'doi', 'Year of publication_x': 'publication_year',\n",
    "#                                   'Page numbers_x': 'page_numbers'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the selected papers to a CSV file\n",
    "#selected_papers_df.to_csv(output_path + 'selected_papers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>page_numbers</th>\n",
       "      <th>doi</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>vol_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>Alina F. Dima, Veronika A. Zimmer, Martin J. M...</td>\n",
       "      <td>141-151</td>\n",
       "      <td>10.1007/978-3-031-43907-0_14</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D Mitochondria Instance Segmentation with Spa...</td>\n",
       "      <td>Omkar Thawakar, Rao Muhammad Anwer, Jorma Laak...</td>\n",
       "      <td>613-623</td>\n",
       "      <td>10.1007/978-3-031-43993-3_59</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Spatial-Temporal Deformable Attention Based ...</td>\n",
       "      <td>Chao Qin, Jiale Cao, Huazhu Fu, Rao Muhammad A...</td>\n",
       "      <td>479-488</td>\n",
       "      <td>10.1007/978-3-031-43895-0_45</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Spatial-Temporally Adaptive PINN Framework f...</td>\n",
       "      <td>Yubo Ye, Huafeng Liu, Xiajun Jiang, Maryam Tol...</td>\n",
       "      <td>163-172</td>\n",
       "      <td>10.1007/978-3-031-43990-2_16</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Texture Neural Network to Predict the Abnorm...</td>\n",
       "      <td>Weiguo Cao, Benjamin Howe, Nicholas Rhodes, Su...</td>\n",
       "      <td>470-480</td>\n",
       "      <td>10.1007/978-3-031-43993-3_46</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>WeakPolyp: You only Look Bounding Box for Poly...</td>\n",
       "      <td>Jun Wei, Yiwen Hu, Shuguang Cui, S. Kevin Zhou...</td>\n",
       "      <td>757-766</td>\n",
       "      <td>10.1007/978-3-031-43898-1_72</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Weakly-Supervised Positional Contrastive Learn...</td>\n",
       "      <td>Emma Sarfati, Alexandre Bône, Marc-Michel Rohé...</td>\n",
       "      <td>227-237</td>\n",
       "      <td>10.1007/978-3-031-43907-0_22</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>X2Vision: 3D CT Reconstruction from Biplanar X...</td>\n",
       "      <td>Alexandre Cafaro, Quentin Spinat, Amaury Leroy...</td>\n",
       "      <td>699-709</td>\n",
       "      <td>10.1007/978-3-031-43999-5_66</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>YONA: You Only Need One Adjacent Reference-Fra...</td>\n",
       "      <td>Yuncheng Jiang, Zixun Zhang, Ruimao Zhang, Gua...</td>\n",
       "      <td>44-54</td>\n",
       "      <td>10.1007/978-3-031-43904-9_5</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>vox2vec: A Framework for Self-supervised Contr...</td>\n",
       "      <td>Mikhail Goncharov, Vera Soboleva, Anvar Kurmuk...</td>\n",
       "      <td>605-614</td>\n",
       "      <td>10.1007/978-3-031-43907-0_58</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    3D Arterial Segmentation via Single 2D Project...   \n",
       "1    3D Mitochondria Instance Segmentation with Spa...   \n",
       "2    A Spatial-Temporal Deformable Attention Based ...   \n",
       "3    A Spatial-Temporally Adaptive PINN Framework f...   \n",
       "4    A Texture Neural Network to Predict the Abnorm...   \n",
       "..                                                 ...   \n",
       "184  WeakPolyp: You only Look Bounding Box for Poly...   \n",
       "185  Weakly-Supervised Positional Contrastive Learn...   \n",
       "186  X2Vision: 3D CT Reconstruction from Biplanar X...   \n",
       "187  YONA: You Only Need One Adjacent Reference-Fra...   \n",
       "188  vox2vec: A Framework for Self-supervised Contr...   \n",
       "\n",
       "                                               authors page_numbers  \\\n",
       "0    Alina F. Dima, Veronika A. Zimmer, Martin J. M...      141-151   \n",
       "1    Omkar Thawakar, Rao Muhammad Anwer, Jorma Laak...      613-623   \n",
       "2    Chao Qin, Jiale Cao, Huazhu Fu, Rao Muhammad A...      479-488   \n",
       "3    Yubo Ye, Huafeng Liu, Xiajun Jiang, Maryam Tol...      163-172   \n",
       "4    Weiguo Cao, Benjamin Howe, Nicholas Rhodes, Su...      470-480   \n",
       "..                                                 ...          ...   \n",
       "184  Jun Wei, Yiwen Hu, Shuguang Cui, S. Kevin Zhou...      757-766   \n",
       "185  Emma Sarfati, Alexandre Bône, Marc-Michel Rohé...      227-237   \n",
       "186  Alexandre Cafaro, Quentin Spinat, Amaury Leroy...      699-709   \n",
       "187  Yuncheng Jiang, Zixun Zhang, Ruimao Zhang, Gua...        44-54   \n",
       "188  Mikhail Goncharov, Vera Soboleva, Anvar Kurmuk...      605-614   \n",
       "\n",
       "                              doi  publication_year  vol_number  \n",
       "0    10.1007/978-3-031-43907-0_14            2023.0         1.0  \n",
       "1    10.1007/978-3-031-43993-3_59            2023.0         8.0  \n",
       "2    10.1007/978-3-031-43895-0_45            2023.0         2.0  \n",
       "3    10.1007/978-3-031-43990-2_16            2023.0         7.0  \n",
       "4    10.1007/978-3-031-43993-3_46            2023.0         8.0  \n",
       "..                            ...               ...         ...  \n",
       "184  10.1007/978-3-031-43898-1_72            2023.0         3.0  \n",
       "185  10.1007/978-3-031-43907-0_22            2023.0         1.0  \n",
       "186  10.1007/978-3-031-43999-5_66            2023.0        10.0  \n",
       "187   10.1007/978-3-031-43904-9_5            2023.0         5.0  \n",
       "188  10.1007/978-3-031-43907-0_58            2023.0         1.0  \n",
       "\n",
       "[189 rows x 6 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Display the selected papers\n",
    "# ''' The papers were choosen by searching for papers with the keyword \"cancer\" in the title and in the text starting from the abstract and \n",
    "# ending with the conclusion section of the paper'''\n",
    "\n",
    "# selected_papers_df = pd.read_csv(output_path + 'selected_papers.csv')\n",
    "# selected_papers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preliminary analysis of MICCAI 2023 - Selected papers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Preprocessing and Data Extraction\n",
    "\n",
    "- **Objective**: Extract relevant information (e.g., mentions of demographic data, ethical considerations, methodologies for bias mitigation) from the papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Setup and installation of the required packages\n",
    "#!pip install spacy nltk PyMuPDF\n",
    "#!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the paths of the selected papers\n",
    "selected_papers_paths = []\n",
    "for i in range(0, len(selected_papers)):  # Volumes 1 to 10\n",
    "    selected_papers_paths.append([base_path + 'miccai_2023/' + selected_papers[i]])\n",
    "\n",
    "# Check if the total number of paths is equal to the number of selected papers\n",
    "len(selected_papers_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: PDF Text Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the full text from the PDF\n",
    "def extract_text(pdf_path):\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        full_text = \"\"\n",
    "        for page in doc:\n",
    "            full_text += page.get_text()\n",
    "            # Regular expressions to find the end of the affiliations section\n",
    "            affiliations_end = re.search(r'\\d{1,2}\\s+(?:\\w+\\.)+@\\w+\\.\\w{2,}', full_text)\n",
    "            \n",
    "            # Start searching from the end of affiliations if found, otherwise from the start of the text\n",
    "            start_idx = affiliations_end.end() if affiliations_end else 0\n",
    "            \n",
    "            # Look for the Abstract and Conclusion sections\n",
    "            abstract_idx = full_text.lower().find(\"abstract\", start_idx)\n",
    "            conclusion_idx = full_text.lower().rfind(\"conclusion\", abstract_idx)\n",
    "            acknowledgements_idx = full_text.lower().find(\"acknowledgements\", conclusion_idx)\n",
    "            \n",
    "            # Adjust the end index to stop at Acknowledgements if it exists, otherwise use Conclusion index\n",
    "            end_search_idx = acknowledgements_idx if acknowledgements_idx != -1 else conclusion_idx\n",
    "            \n",
    "            # If neither Abstract nor Conclusion is found, search the entire text\n",
    "            if abstract_idx == -1 and conclusion_idx == -1:\n",
    "                searchable_text = full_text[start_idx:]\n",
    "            else:\n",
    "                # Search from Abstract to Conclusion or Acknowledgements\n",
    "                searchable_text = full_text[abstract_idx:end_search_idx].lower()          \n",
    "        \n",
    "    return searchable_text\n",
    "\n",
    "def extract_relevant_sentences(text, keywords):\n",
    "    relevant_sentences = []\n",
    "    doc = nlp(text)\n",
    "    # Regex pattern that matches whole words from the keywords list, case insensitive\n",
    "    pattern = r'\\b(' + '|'.join(re.escape(keyword) for keyword in keywords) + r')\\b'\n",
    "    for sent in doc.sents:\n",
    "        if re.search(pattern, sent.text, re.IGNORECASE):\n",
    "            relevant_sentences.append(sent.text.strip())\n",
    "    return relevant_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "    # Optionally, further preprocessing steps like removing stopwords, lemmatization, etc., can be added here\n",
    "    return \" \".join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Extracting Relevant Information\n",
    "For the purpose of extracting relevant information about demographic data, ethical considerations, and methodologies for bias mitigation, keywords or phrases that signify these concepts are defined, and search for sentences containing these keywords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5th and final attempt: saved as extracted_info.csv\n",
    "keywords = ['age', 'gender', 'sex', 'women', 'woman', 'female', 'men', 'man', 'male',\n",
    "            'location', 'geolocation', 'geographical', 'geographic', 'country', 'countries',\n",
    "             'city', 'cities', 'hospital', 'hospitals', 'clinic', 'clinics', 'society', 'societies',\n",
    "             'etnicity', 'etnicities', 'race', 'bias', 'biases', 'fairness', 'transparency', \n",
    "             'data gap', 'data gaps', 'data bias', 'data biases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to hold the extracted info\n",
    "extracted_info = {}\n",
    "\n",
    "for pdf_path in selected_papers_paths:\n",
    "    path = pdf_path[0]  # pdf_path is a list with the first element being the file path\n",
    "    text = extract_text(path)\n",
    "    relevant_sentences = extract_relevant_sentences(text, keywords)\n",
    "    \n",
    "    # If no relevant sentences were extracted, include the paper with extracted_sentence set to None\n",
    "    if not relevant_sentences:\n",
    "        extracted_info[path] = [None] # Probably better to change this to 0\n",
    "    else:\n",
    "        extracted_info[path] = relevant_sentences\n",
    "\n",
    "# Convert to DataFrame\n",
    "rows = []\n",
    "for paper_id, sentences in extracted_info.items():\n",
    "    if sentences == [None]:  # Check if the list contains only None, indicating no sentences were extracted\n",
    "        rows.append({'paper_id': paper_id, 'extracted_sentence': None})\n",
    "    else:\n",
    "        for sentence in sentences:\n",
    "            rows.append({'paper_id': paper_id, 'extracted_sentence': sentence})\n",
    "\n",
    "extracted_info_df = pd.DataFrame(rows)\n",
    "\n",
    "# Save to CSV\n",
    "extracted_info_df.to_csv(output_path + 'extracted_info.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Step 2: Structuring Data According to Key Indicators\n",
    "\n",
    "Objective: Organize extracted information under the key indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_papers_df = pd.read_csv(output_path + 'selected_papers_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>page_numbers</th>\n",
       "      <th>doi</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>vol_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>Alina F. Dima, Veronika A. Zimmer, Martin J. M...</td>\n",
       "      <td>141-151</td>\n",
       "      <td>10.1007/978-3-031-43907-0_14</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D Mitochondria Instance Segmentation with Spa...</td>\n",
       "      <td>Omkar Thawakar, Rao Muhammad Anwer, Jorma Laak...</td>\n",
       "      <td>613-623</td>\n",
       "      <td>10.1007/978-3-031-43993-3_59</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Spatial-Temporal Deformable Attention Based ...</td>\n",
       "      <td>Chao Qin, Jiale Cao, Huazhu Fu, Rao Muhammad A...</td>\n",
       "      <td>479-488</td>\n",
       "      <td>10.1007/978-3-031-43895-0_45</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Spatial-Temporally Adaptive PINN Framework f...</td>\n",
       "      <td>Yubo Ye, Huafeng Liu, Xiajun Jiang, Maryam Tol...</td>\n",
       "      <td>163-172</td>\n",
       "      <td>10.1007/978-3-031-43990-2_16</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Texture Neural Network to Predict the Abnorm...</td>\n",
       "      <td>Weiguo Cao, Benjamin Howe, Nicholas Rhodes, Su...</td>\n",
       "      <td>470-480</td>\n",
       "      <td>10.1007/978-3-031-43993-3_46</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>WeakPolyp: You only Look Bounding Box for Poly...</td>\n",
       "      <td>Jun Wei, Yiwen Hu, Shuguang Cui, S. Kevin Zhou...</td>\n",
       "      <td>757-766</td>\n",
       "      <td>10.1007/978-3-031-43898-1_72</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Weakly-Supervised Positional Contrastive Learn...</td>\n",
       "      <td>Emma Sarfati, Alexandre Bône, Marc-Michel Rohé...</td>\n",
       "      <td>227-237</td>\n",
       "      <td>10.1007/978-3-031-43907-0_22</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>X2Vision: 3D CT Reconstruction from Biplanar X...</td>\n",
       "      <td>Alexandre Cafaro, Quentin Spinat, Amaury Leroy...</td>\n",
       "      <td>699-709</td>\n",
       "      <td>10.1007/978-3-031-43999-5_66</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>YONA: You Only Need One Adjacent Reference-Fra...</td>\n",
       "      <td>Yuncheng Jiang, Zixun Zhang, Ruimao Zhang, Gua...</td>\n",
       "      <td>44-54</td>\n",
       "      <td>10.1007/978-3-031-43904-9_5</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>vox2vec: A Framework for Self-supervised Contr...</td>\n",
       "      <td>Mikhail Goncharov, Vera Soboleva, Anvar Kurmuk...</td>\n",
       "      <td>605-614</td>\n",
       "      <td>10.1007/978-3-031-43907-0_58</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    3D Arterial Segmentation via Single 2D Project...   \n",
       "1    3D Mitochondria Instance Segmentation with Spa...   \n",
       "2    A Spatial-Temporal Deformable Attention Based ...   \n",
       "3    A Spatial-Temporally Adaptive PINN Framework f...   \n",
       "4    A Texture Neural Network to Predict the Abnorm...   \n",
       "..                                                 ...   \n",
       "184  WeakPolyp: You only Look Bounding Box for Poly...   \n",
       "185  Weakly-Supervised Positional Contrastive Learn...   \n",
       "186  X2Vision: 3D CT Reconstruction from Biplanar X...   \n",
       "187  YONA: You Only Need One Adjacent Reference-Fra...   \n",
       "188  vox2vec: A Framework for Self-supervised Contr...   \n",
       "\n",
       "                                               authors page_numbers  \\\n",
       "0    Alina F. Dima, Veronika A. Zimmer, Martin J. M...      141-151   \n",
       "1    Omkar Thawakar, Rao Muhammad Anwer, Jorma Laak...      613-623   \n",
       "2    Chao Qin, Jiale Cao, Huazhu Fu, Rao Muhammad A...      479-488   \n",
       "3    Yubo Ye, Huafeng Liu, Xiajun Jiang, Maryam Tol...      163-172   \n",
       "4    Weiguo Cao, Benjamin Howe, Nicholas Rhodes, Su...      470-480   \n",
       "..                                                 ...          ...   \n",
       "184  Jun Wei, Yiwen Hu, Shuguang Cui, S. Kevin Zhou...      757-766   \n",
       "185  Emma Sarfati, Alexandre Bône, Marc-Michel Rohé...      227-237   \n",
       "186  Alexandre Cafaro, Quentin Spinat, Amaury Leroy...      699-709   \n",
       "187  Yuncheng Jiang, Zixun Zhang, Ruimao Zhang, Gua...        44-54   \n",
       "188  Mikhail Goncharov, Vera Soboleva, Anvar Kurmuk...      605-614   \n",
       "\n",
       "                              doi  publication_year  vol_number  \n",
       "0    10.1007/978-3-031-43907-0_14              2023           1  \n",
       "1    10.1007/978-3-031-43993-3_59              2023           8  \n",
       "2    10.1007/978-3-031-43895-0_45              2023           2  \n",
       "3    10.1007/978-3-031-43990-2_16              2023           7  \n",
       "4    10.1007/978-3-031-43993-3_46              2023           8  \n",
       "..                            ...               ...         ...  \n",
       "184  10.1007/978-3-031-43898-1_72              2023           3  \n",
       "185  10.1007/978-3-031-43907-0_22              2023           1  \n",
       "186  10.1007/978-3-031-43999-5_66              2023          10  \n",
       "187   10.1007/978-3-031-43904-9_5              2023           5  \n",
       "188  10.1007/978-3-031-43907-0_58              2023           1  \n",
       "\n",
       "[189 rows x 6 columns]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_info # Dictionary with the extracted info {<pdf_path>: [<extracted_sentences by keyword>]}\n",
    "selected_papers # List of path of selected papers with the keyword 'cancer' in the text\n",
    "df_miccai # Dataframe with the metadata of all 730 papers\n",
    "selected_papers_df # Dataframe with the metadata of the selected papers and paper_id as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(selected_papers_df.info())\n",
    "# # Convert dtype from float to int\n",
    "\n",
    "# selected_papers_df['vol_number'] = selected_papers_df['vol_number'].astype(int)\n",
    "# selected_papers_df['publication_year'] = selected_papers_df['publication_year'].astype(int)\n",
    "# selected_papers_df.info()\n",
    "# selected_papers_df.to_csv(output_path + 'selected_papers_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with unique identifiers for each paper\n",
    "\n",
    "# Option 1: Using the uuid as the unique identifier\n",
    "#df['paper_id'] = [uuid.uuid4() for _ in range(len(df))]\n",
    "#selected_papers_df['paper_id'] = [uuid.uuid4() for _ in range(len(selected_papers_df))]\n",
    "#selected_papers_df.to_csv(output_path + 'selected_papers_unique_ids.csv', index=False)\n",
    "\n",
    "\n",
    "# Option 2: Using the index as the unique identifier\n",
    "#df['paper_id'] = range(1, len(df) + 1)\n",
    "# selected_papers_df['paper_id'] = range(1, len(selected_papers_df) + 1)\n",
    "# selected_papers_df.to_csv(output_path + 'selected_papers_index_as_ids.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>page_numbers</th>\n",
       "      <th>doi</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>vol_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>Alina F. Dima, Veronika A. Zimmer, Martin J. M...</td>\n",
       "      <td>141-151</td>\n",
       "      <td>10.1007/978-3-031-43907-0_14</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3D Mitochondria Instance Segmentation with Spa...</td>\n",
       "      <td>Omkar Thawakar, Rao Muhammad Anwer, Jorma Laak...</td>\n",
       "      <td>613-623</td>\n",
       "      <td>10.1007/978-3-031-43993-3_59</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A Spatial-Temporal Deformable Attention Based ...</td>\n",
       "      <td>Chao Qin, Jiale Cao, Huazhu Fu, Rao Muhammad A...</td>\n",
       "      <td>479-488</td>\n",
       "      <td>10.1007/978-3-031-43895-0_45</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A Spatial-Temporally Adaptive PINN Framework f...</td>\n",
       "      <td>Yubo Ye, Huafeng Liu, Xiajun Jiang, Maryam Tol...</td>\n",
       "      <td>163-172</td>\n",
       "      <td>10.1007/978-3-031-43990-2_16</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>A Texture Neural Network to Predict the Abnorm...</td>\n",
       "      <td>Weiguo Cao, Benjamin Howe, Nicholas Rhodes, Su...</td>\n",
       "      <td>470-480</td>\n",
       "      <td>10.1007/978-3-031-43993-3_46</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>185</td>\n",
       "      <td>WeakPolyp: You only Look Bounding Box for Poly...</td>\n",
       "      <td>Jun Wei, Yiwen Hu, Shuguang Cui, S. Kevin Zhou...</td>\n",
       "      <td>757-766</td>\n",
       "      <td>10.1007/978-3-031-43898-1_72</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>186</td>\n",
       "      <td>Weakly-Supervised Positional Contrastive Learn...</td>\n",
       "      <td>Emma Sarfati, Alexandre Bône, Marc-Michel Rohé...</td>\n",
       "      <td>227-237</td>\n",
       "      <td>10.1007/978-3-031-43907-0_22</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>187</td>\n",
       "      <td>X2Vision: 3D CT Reconstruction from Biplanar X...</td>\n",
       "      <td>Alexandre Cafaro, Quentin Spinat, Amaury Leroy...</td>\n",
       "      <td>699-709</td>\n",
       "      <td>10.1007/978-3-031-43999-5_66</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>188</td>\n",
       "      <td>YONA: You Only Need One Adjacent Reference-Fra...</td>\n",
       "      <td>Yuncheng Jiang, Zixun Zhang, Ruimao Zhang, Gua...</td>\n",
       "      <td>44-54</td>\n",
       "      <td>10.1007/978-3-031-43904-9_5</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>189</td>\n",
       "      <td>vox2vec: A Framework for Self-supervised Contr...</td>\n",
       "      <td>Mikhail Goncharov, Vera Soboleva, Anvar Kurmuk...</td>\n",
       "      <td>605-614</td>\n",
       "      <td>10.1007/978-3-031-43907-0_58</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id                                              title  \\\n",
       "0           1  3D Arterial Segmentation via Single 2D Project...   \n",
       "1           2  3D Mitochondria Instance Segmentation with Spa...   \n",
       "2           3  A Spatial-Temporal Deformable Attention Based ...   \n",
       "3           4  A Spatial-Temporally Adaptive PINN Framework f...   \n",
       "4           5  A Texture Neural Network to Predict the Abnorm...   \n",
       "..        ...                                                ...   \n",
       "184       185  WeakPolyp: You only Look Bounding Box for Poly...   \n",
       "185       186  Weakly-Supervised Positional Contrastive Learn...   \n",
       "186       187  X2Vision: 3D CT Reconstruction from Biplanar X...   \n",
       "187       188  YONA: You Only Need One Adjacent Reference-Fra...   \n",
       "188       189  vox2vec: A Framework for Self-supervised Contr...   \n",
       "\n",
       "                                               authors page_numbers  \\\n",
       "0    Alina F. Dima, Veronika A. Zimmer, Martin J. M...      141-151   \n",
       "1    Omkar Thawakar, Rao Muhammad Anwer, Jorma Laak...      613-623   \n",
       "2    Chao Qin, Jiale Cao, Huazhu Fu, Rao Muhammad A...      479-488   \n",
       "3    Yubo Ye, Huafeng Liu, Xiajun Jiang, Maryam Tol...      163-172   \n",
       "4    Weiguo Cao, Benjamin Howe, Nicholas Rhodes, Su...      470-480   \n",
       "..                                                 ...          ...   \n",
       "184  Jun Wei, Yiwen Hu, Shuguang Cui, S. Kevin Zhou...      757-766   \n",
       "185  Emma Sarfati, Alexandre Bône, Marc-Michel Rohé...      227-237   \n",
       "186  Alexandre Cafaro, Quentin Spinat, Amaury Leroy...      699-709   \n",
       "187  Yuncheng Jiang, Zixun Zhang, Ruimao Zhang, Gua...        44-54   \n",
       "188  Mikhail Goncharov, Vera Soboleva, Anvar Kurmuk...      605-614   \n",
       "\n",
       "                              doi  publication_year  vol_number  \n",
       "0    10.1007/978-3-031-43907-0_14              2023           1  \n",
       "1    10.1007/978-3-031-43993-3_59              2023           8  \n",
       "2    10.1007/978-3-031-43895-0_45              2023           2  \n",
       "3    10.1007/978-3-031-43990-2_16              2023           7  \n",
       "4    10.1007/978-3-031-43993-3_46              2023           8  \n",
       "..                            ...               ...         ...  \n",
       "184  10.1007/978-3-031-43898-1_72              2023           3  \n",
       "185  10.1007/978-3-031-43907-0_22              2023           1  \n",
       "186  10.1007/978-3-031-43999-5_66              2023          10  \n",
       "187   10.1007/978-3-031-43904-9_5              2023           5  \n",
       "188  10.1007/978-3-031-43907-0_58              2023           1  \n",
       "\n",
       "[189 rows x 7 columns]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers = pd.read_csv(output_path + 'selected_papers_index_as_ids.csv')\n",
    "# Column to move to the first position\n",
    "column_to_move = 'paper_id'\n",
    "\n",
    "# Create a new list of column names with the specified column first\n",
    "new_columns = [column_to_move] + [col for col in papers.columns if col != column_to_move]\n",
    "\n",
    "# Reindex the DataFrame with the new column order\n",
    "papers = papers[new_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the papers and title_paths dataframes to give each paper a unique identifier\n",
    "# title_paths = pd.read_csv(output_path + 'papers_by_paths_titles.csv', header=[0], encoding='utf-8').sort_values(by='title')\n",
    "# title_paths['paper_id'] = range(1, len(title_paths) + 1)\n",
    "# title_paths\n",
    "\n",
    "# # Merge the papers and title_paths dataframes\n",
    "# papers_df = pd.merge(papers, title_paths, on='paper_id', how='inner').drop(columns=['title_y']).rename(columns={'title_x': 'title'})\n",
    "# papers_df.to_csv(output_path + 'papers_df.csv', index=False)\n",
    "\n",
    "# extracted_info_df = pd.read_csv(output_path + 'extracted_info.csv')\n",
    "\n",
    "# # Split the 'path' column and keep only the last two parts\n",
    "# extracted_info_df['path'] = extracted_info_df['paper_id'].str.split('/').apply(lambda x: '/'.join(x[-2:]))\n",
    "# extracted_info_df = extracted_info_df.drop(columns=['paper_id'])\n",
    "\n",
    "# papers_sent = pd.merge(papers_df, extracted_info_df, on='path',  how='inner')\n",
    "# papers_sent.to_csv(output_path + 'papers_sent.csv', index=False)\n",
    "# papers_sent = pd.read_csv(output_path + 'papers_sent.csv')\n",
    "# papers_sent.drop(columns=['path', 'authors', 'page_numbers', 'doi', 'publication_year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>page_numbers</th>\n",
       "      <th>doi</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>vol_number</th>\n",
       "      <th>path</th>\n",
       "      <th>extracted_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>Alina F. Dima, Veronika A. Zimmer, Martin J. M...</td>\n",
       "      <td>141-151</td>\n",
       "      <td>10.1007/978-3-031-43907-0_14</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>miccai23vol1/paper_14.pdf</td>\n",
       "      <td>for each foreground pixel in the annotation a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>Alina F. Dima, Veronika A. Zimmer, Martin J. M...</td>\n",
       "      <td>141-151</td>\n",
       "      <td>10.1007/978-3-031-43907-0_14</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>miccai23vol1/paper_14.pdf</td>\n",
       "      <td>the cohort consists of 141 patients with pancr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3D Mitochondria Instance Segmentation with Spa...</td>\n",
       "      <td>Omkar Thawakar, Rao Muhammad Anwer, Jorma Laak...</td>\n",
       "      <td>613-623</td>\n",
       "      <td>10.1007/978-3-031-43993-3_59</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>miccai23vol8/paper_59.pdf</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A Spatial-Temporal Deformable Attention Based ...</td>\n",
       "      <td>Chao Qin, Jiale Cao, Huazhu Fu, Rao Muhammad A...</td>\n",
       "      <td>479-488</td>\n",
       "      <td>10.1007/978-3-031-43895-0_45</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>miccai23vol2/paper_46.pdf</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A Spatial-Temporally Adaptive PINN Framework f...</td>\n",
       "      <td>Yubo Ye, Huafeng Liu, Xiajun Jiang, Maryam Tol...</td>\n",
       "      <td>163-172</td>\n",
       "      <td>10.1007/978-3-031-43990-2_16</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>miccai23vol8/paper_46.pdf</td>\n",
       "      <td>2\\nmaterials and method\\n2.1\\ndataset preparat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>185</td>\n",
       "      <td>WeakPolyp: You only Look Bounding Box for Poly...</td>\n",
       "      <td>Jun Wei, Yiwen Hu, Shuguang Cui, S. Kevin Zhou...</td>\n",
       "      <td>757-766</td>\n",
       "      <td>10.1007/978-3-031-43898-1_72</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>miccai23vol3/paper_72.pdf</td>\n",
       "      <td>our weakpolyp predictably outperforms the mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>186</td>\n",
       "      <td>Weakly-Supervised Positional Contrastive Learn...</td>\n",
       "      <td>Emma Sarfati, Alexandre Bône, Marc-Michel Rohé...</td>\n",
       "      <td>227-237</td>\n",
       "      <td>10.1007/978-3-031-43907-0_22</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>miccai23vol1/paper_22.pdf</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>187</td>\n",
       "      <td>X2Vision: 3D CT Reconstruction from Biplanar X...</td>\n",
       "      <td>Alexandre Cafaro, Quentin Spinat, Amaury Leroy...</td>\n",
       "      <td>699-709</td>\n",
       "      <td>10.1007/978-3-031-43999-5_66</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>miccai23vol10/paper_66.pdf</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>188</td>\n",
       "      <td>YONA: You Only Need One Adjacent Reference-Fra...</td>\n",
       "      <td>Yuncheng Jiang, Zixun Zhang, Ruimao Zhang, Gua...</td>\n",
       "      <td>44-54</td>\n",
       "      <td>10.1007/978-3-031-43904-9_5</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>miccai23vol5/paper_5.pdf</td>\n",
       "      <td>for the fairness of the experiments, we keep t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>189</td>\n",
       "      <td>vox2vec: A Framework for Self-supervised Contr...</td>\n",
       "      <td>Mikhail Goncharov, Vera Soboleva, Anvar Kurmuk...</td>\n",
       "      <td>605-614</td>\n",
       "      <td>10.1007/978-3-031-43907-0_58</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>miccai23vol1/paper_58.pdf</td>\n",
       "      <td>this means that matching regions\\ndescribing t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id                                              title  \\\n",
       "0           1  3D Arterial Segmentation via Single 2D Project...   \n",
       "1           1  3D Arterial Segmentation via Single 2D Project...   \n",
       "2           2  3D Mitochondria Instance Segmentation with Spa...   \n",
       "3           3  A Spatial-Temporal Deformable Attention Based ...   \n",
       "4           4  A Spatial-Temporally Adaptive PINN Framework f...   \n",
       "..        ...                                                ...   \n",
       "532       185  WeakPolyp: You only Look Bounding Box for Poly...   \n",
       "533       186  Weakly-Supervised Positional Contrastive Learn...   \n",
       "534       187  X2Vision: 3D CT Reconstruction from Biplanar X...   \n",
       "535       188  YONA: You Only Need One Adjacent Reference-Fra...   \n",
       "536       189  vox2vec: A Framework for Self-supervised Contr...   \n",
       "\n",
       "                                               authors page_numbers  \\\n",
       "0    Alina F. Dima, Veronika A. Zimmer, Martin J. M...      141-151   \n",
       "1    Alina F. Dima, Veronika A. Zimmer, Martin J. M...      141-151   \n",
       "2    Omkar Thawakar, Rao Muhammad Anwer, Jorma Laak...      613-623   \n",
       "3    Chao Qin, Jiale Cao, Huazhu Fu, Rao Muhammad A...      479-488   \n",
       "4    Yubo Ye, Huafeng Liu, Xiajun Jiang, Maryam Tol...      163-172   \n",
       "..                                                 ...          ...   \n",
       "532  Jun Wei, Yiwen Hu, Shuguang Cui, S. Kevin Zhou...      757-766   \n",
       "533  Emma Sarfati, Alexandre Bône, Marc-Michel Rohé...      227-237   \n",
       "534  Alexandre Cafaro, Quentin Spinat, Amaury Leroy...      699-709   \n",
       "535  Yuncheng Jiang, Zixun Zhang, Ruimao Zhang, Gua...        44-54   \n",
       "536  Mikhail Goncharov, Vera Soboleva, Anvar Kurmuk...      605-614   \n",
       "\n",
       "                              doi  publication_year  vol_number  \\\n",
       "0    10.1007/978-3-031-43907-0_14              2023           1   \n",
       "1    10.1007/978-3-031-43907-0_14              2023           1   \n",
       "2    10.1007/978-3-031-43993-3_59              2023           8   \n",
       "3    10.1007/978-3-031-43895-0_45              2023           2   \n",
       "4    10.1007/978-3-031-43990-2_16              2023           7   \n",
       "..                            ...               ...         ...   \n",
       "532  10.1007/978-3-031-43898-1_72              2023           3   \n",
       "533  10.1007/978-3-031-43907-0_22              2023           1   \n",
       "534  10.1007/978-3-031-43999-5_66              2023          10   \n",
       "535   10.1007/978-3-031-43904-9_5              2023           5   \n",
       "536  10.1007/978-3-031-43907-0_58              2023           1   \n",
       "\n",
       "                           path  \\\n",
       "0     miccai23vol1/paper_14.pdf   \n",
       "1     miccai23vol1/paper_14.pdf   \n",
       "2     miccai23vol8/paper_59.pdf   \n",
       "3     miccai23vol2/paper_46.pdf   \n",
       "4     miccai23vol8/paper_46.pdf   \n",
       "..                          ...   \n",
       "532   miccai23vol3/paper_72.pdf   \n",
       "533   miccai23vol1/paper_22.pdf   \n",
       "534  miccai23vol10/paper_66.pdf   \n",
       "535    miccai23vol5/paper_5.pdf   \n",
       "536   miccai23vol1/paper_58.pdf   \n",
       "\n",
       "                                    extracted_sentence  \n",
       "0    for each foreground pixel in the annotation a ...  \n",
       "1    the cohort consists of 141 patients with pancr...  \n",
       "2                                                 None  \n",
       "3                                                 None  \n",
       "4    2\\nmaterials and method\\n2.1\\ndataset preparat...  \n",
       "..                                                 ...  \n",
       "532  our weakpolyp predictably outperforms the mode...  \n",
       "533                                               None  \n",
       "534                                               None  \n",
       "535  for the fairness of the experiments, we keep t...  \n",
       "536  this means that matching regions\\ndescribing t...  \n",
       "\n",
       "[537 rows x 9 columns]"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_sent = pd.read_csv(output_path + 'papers_sent.csv')\n",
    "#df.fillna('None', inplace=True)\n",
    "papers_sent.fillna('None', inplace=True)\n",
    "papers_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Function to count keywords in a text\n",
    "def count_keywords(text, keywords):\n",
    "    # Counter object to count occurrences of each keyword\n",
    "    counts = Counter()\n",
    "    for keyword in keywords:\n",
    "        # Count occurrences of the keyword in the text\n",
    "        counts[keyword] = text.lower().count(keyword)\n",
    "    return counts\n",
    "\n",
    "# Aggregate 'extracted_sentences' for each 'title' and count keywords\n",
    "results = {}\n",
    "for title, group in papers_sent.groupby('title'):\n",
    "    # Combine all extracted sentences into one large text block\n",
    "    aggregated_text = \" \".join(group['extracted_sentence'].tolist())\n",
    "    # Count the keywords in this aggregated text\n",
    "    keyword_counts = count_keywords(aggregated_text, keywords)\n",
    "    # Store the result\n",
    "    results[title] = keyword_counts\n",
    "\n",
    "# Convert the results dictionary to a DataFrame \n",
    "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "results_df.to_csv(output_path + 'results_df.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.rename(columns={'Unnamed: 0': 'title'}, inplace=True)\n",
    "\n",
    "# # Example of calculating a simple score by summing counts of selected keywords\n",
    "# keywords_for_scoring = keywords\n",
    "# results_df['score'] = results_df[keywords_for_scoring].sum(axis=1)\n",
    "\n",
    "# # Example of flagging papers for review based on a score threshold\n",
    "# review_threshold = 5  # Papers with scores below this threshold require review\n",
    "# results_df['requires_review'] = results_df['score'] > review_threshold\n",
    "# results_df.to_csv(output_path + 'results_df.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df = pd.read_csv(output_path + 'results_df.csv')\n",
    "# results_df.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mapping of keywords to main categories\n",
    "# keyword_to_category = {\n",
    "#     'age'   : 'age_group',\n",
    "#     'gender': 'gender_group',\n",
    "#     'sex'   : 'gender_group',\n",
    "#     'female': 'gender_group',\n",
    "#     'women' : 'gender_group',\n",
    "#     'woman' : 'gender_group',\n",
    "#     'men'   : 'gender_group',\n",
    "#     'man'   : 'gender_group',\n",
    "#     'male'  : 'gender_group',\n",
    "#     'location'      : 'geolocation_group',\n",
    "#     'geolocation'   : 'geolocation_group',\n",
    "#     'geographical'  : 'geolocation_group',\n",
    "#     'geographic'    : 'geolocation_group',\n",
    "#     'country'       : 'geolocation_group',\n",
    "#     'countries'     : 'geolocation_group',\n",
    "#     'city'          : 'geolocation_group',\n",
    "#     'cities'        : 'geolocation_group',\n",
    "#     'hospital'      : 'geolocation_group',\n",
    "#     'hospitals'     : 'geolocation_group',\n",
    "#     'clinic'        : 'geolocation_group',\n",
    "#     'clinics'       : 'geolocation_group',\n",
    "#     'society'       : 'social factors',\n",
    "#     'societies'     : 'social factors',\n",
    "#     'etnicity'      : 'etnicity_group',\n",
    "#     'etnicities'    : 'etnicity_group',\n",
    "#     'race'          : 'etnicity_group',\n",
    "#     'bias'          : 'fairness_group',\n",
    "#     'biases'        : 'fairness_group',\n",
    "#     'fairness'      : 'fairness_group',\n",
    "#     'transparency'  : 'fairness_group',\n",
    "#     'data gap'      : 'data gaps_group',\n",
    "#     'data gaps'     : 'data gaps_group',\n",
    "#     'data bias'     : 'fairness_group',\n",
    "#     'data biases'   : 'fairness_group'\n",
    "# }\n",
    "# # Reverse the mapping for aggregation\n",
    "# category_to_keywords = {}\n",
    "# for keyword, category in keyword_to_category.items():\n",
    "#     category_to_keywords.setdefault(category, []).append(keyword)\n",
    "\n",
    "# # Aggregate columns into categories\n",
    "# for category, keywords in category_to_keywords.items():\n",
    "#     if category in results_df.columns:\n",
    "#         # If the category already exists, add to it\n",
    "#         results_df[category] += results_df[keywords].sum(axis=1)\n",
    "#     else:\n",
    "#         # Otherwise, create a new column for the category\n",
    "#         results_df[category] = results_df[keywords].sum(axis=1)\n",
    "#     # Drop the original keyword columns\n",
    "#     results_df.drop(columns=keywords, inplace=True)\n",
    "\n",
    "# results_df.rename(columns={'age_group' : 'age', 'gender_group' : 'gender', 'etnicity_group': 'etnicity', 'fairness_group': 'fairness',\n",
    "#                            'geolocation_group': 'geolocation',  'data gaps_group': 'data_gaps', 'score' : 'total_score'}, inplace=True)\n",
    "\n",
    "# results_df.to_csv(output_path + 'results_df_aggregated.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>total_score</th>\n",
       "      <th>requires_review</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>geolocation</th>\n",
       "      <th>social factors</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>fairness</th>\n",
       "      <th>data_gaps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D Mitochondria Instance Segmentation with Spa...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Spatial-Temporal Deformable Attention Based ...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Spatial-Temporally Adaptive PINN Framework f...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Texture Neural Network to Predict the Abnorm...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>WeakPolyp: You only Look Bounding Box for Poly...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Weakly-Supervised Positional Contrastive Learn...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>X2Vision: 3D CT Reconstruction from Biplanar X...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>YONA: You Only Need One Adjacent Reference-Fra...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>vox2vec: A Framework for Self-supervised Contr...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  total_score  \\\n",
       "0    3D Arterial Segmentation via Single 2D Project...            0   \n",
       "1    3D Mitochondria Instance Segmentation with Spa...            0   \n",
       "2    A Spatial-Temporal Deformable Attention Based ...            0   \n",
       "3    A Spatial-Temporally Adaptive PINN Framework f...            1   \n",
       "4    A Texture Neural Network to Predict the Abnorm...            1   \n",
       "..                                                 ...          ...   \n",
       "184  WeakPolyp: You only Look Bounding Box for Poly...            0   \n",
       "185  Weakly-Supervised Positional Contrastive Learn...            0   \n",
       "186  X2Vision: 3D CT Reconstruction from Biplanar X...            0   \n",
       "187  YONA: You Only Need One Adjacent Reference-Fra...            0   \n",
       "188  vox2vec: A Framework for Self-supervised Contr...            0   \n",
       "\n",
       "     requires_review  age  gender  geolocation  social factors  ethnicity  \\\n",
       "0              False    0       3            1               0          0   \n",
       "1              False    0       0            0               0          0   \n",
       "2              False    0       0            0               0          0   \n",
       "3              False    1       3            1               0          0   \n",
       "4              False    1       1            1               0          0   \n",
       "..               ...  ...     ...          ...             ...        ...   \n",
       "184            False    0       0            0               0          0   \n",
       "185            False    0       0            0               0          0   \n",
       "186            False    0       0            0               0          0   \n",
       "187            False    0       1            0               0          0   \n",
       "188            False    0       0            1               0          0   \n",
       "\n",
       "     fairness  data_gaps  \n",
       "0           0          0  \n",
       "1           0          0  \n",
       "2           0          0  \n",
       "3           0          0  \n",
       "4           0          0  \n",
       "..        ...        ...  \n",
       "184         6          0  \n",
       "185         0          0  \n",
       "186         0          0  \n",
       "187         1          0  \n",
       "188         0          0  \n",
       "\n",
       "[189 rows x 10 columns]"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_results_df = pd.read_csv(base_path + 'code/database_analysis_output/finals/results_df_aggregated.csv').drop(columns=['Unnamed: 0'])\n",
    "agg_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>total_score</th>\n",
       "      <th>requires_review</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>geolocation</th>\n",
       "      <th>social factors</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>fairness</th>\n",
       "      <th>data_gaps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D Mitochondria Instance Segmentation with Spa...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Spatial-Temporal Deformable Attention Based ...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Spatial-Temporally Adaptive PINN Framework f...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Texture Neural Network to Predict the Abnorm...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>WeakPolyp: You only Look Bounding Box for Poly...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Weakly-Supervised Positional Contrastive Learn...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>X2Vision: 3D CT Reconstruction from Biplanar X...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>YONA: You Only Need One Adjacent Reference-Fra...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>vox2vec: A Framework for Self-supervised Contr...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  total_score  \\\n",
       "0    3D Arterial Segmentation via Single 2D Project...            0   \n",
       "1    3D Mitochondria Instance Segmentation with Spa...            0   \n",
       "2    A Spatial-Temporal Deformable Attention Based ...            0   \n",
       "3    A Spatial-Temporally Adaptive PINN Framework f...            1   \n",
       "4    A Texture Neural Network to Predict the Abnorm...            1   \n",
       "..                                                 ...          ...   \n",
       "184  WeakPolyp: You only Look Bounding Box for Poly...            0   \n",
       "185  Weakly-Supervised Positional Contrastive Learn...            0   \n",
       "186  X2Vision: 3D CT Reconstruction from Biplanar X...            0   \n",
       "187  YONA: You Only Need One Adjacent Reference-Fra...            0   \n",
       "188  vox2vec: A Framework for Self-supervised Contr...            0   \n",
       "\n",
       "     requires_review  age  gender  geolocation  social factors  ethnicity  \\\n",
       "0              False    0       1            1               0          0   \n",
       "1              False    0       0            0               0          0   \n",
       "2              False    0       0            0               0          0   \n",
       "3              False    1       1            1               0          0   \n",
       "4              False    1       1            1               0          0   \n",
       "..               ...  ...     ...          ...             ...        ...   \n",
       "184            False    0       0            0               0          0   \n",
       "185            False    0       0            0               0          0   \n",
       "186            False    0       0            0               0          0   \n",
       "187            False    0       1            0               0          0   \n",
       "188            False    0       0            1               0          0   \n",
       "\n",
       "     fairness  data_gaps  \n",
       "0           0          0  \n",
       "1           0          0  \n",
       "2           0          0  \n",
       "3           0          0  \n",
       "4           0          0  \n",
       "..        ...        ...  \n",
       "184         1          0  \n",
       "185         0          0  \n",
       "186         0          0  \n",
       "187         1          0  \n",
       "188         0          0  \n",
       "\n",
       "[189 rows x 10 columns]"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns to convert to binary\n",
    "columns_to_convert = ['age', 'gender', 'geolocation','social factors','ethnicity','fairness','data_gaps']\n",
    "\n",
    "# Convert to binary: 1 if the count is greater than 0, else 0\n",
    "for column in columns_to_convert:\n",
    "    agg_results_df[column] = agg_results_df[column].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "agg_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
