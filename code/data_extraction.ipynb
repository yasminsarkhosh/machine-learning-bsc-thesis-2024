{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Libraries\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "import uuid # for generating unique identifiers for each paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Setup and installation of the required packages\n",
    "#!pip install spacy nltk PyMuPDF\n",
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Important paths\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base path to folder where output files will be stored\n",
    "output_path = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/finals'\n",
    "\n",
    "# Base path to folders \n",
    "base_path = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/'\n",
    "\n",
    "# Path to the MICCAI 2023 pdfs\n",
    "pdf_path = base_path + 'miccai_2023/'\n",
    "\n",
    "# Path to the MICCAI 2023 database of all 730 papers and their metadata\n",
    "database_path = base_path + 'databases/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(df, title):\n",
    "    df.to_csv(title + '.csv', index=True)\n",
    "\n",
    "def read_csv_file(path, filename, var_name):\n",
    "    var_name = pd.read_csv(path + filename + '.csv')\n",
    "    return var_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Dataframe 1: MICCAI 2023\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>page_numbers</th>\n",
       "      <th>doi</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>volume</th>\n",
       "      <th>paper_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>Alina F. Dima, Veronika A. Zimmer, Martin J. M...</td>\n",
       "      <td>141-151</td>\n",
       "      <td>10.1007/978-3-031-43907-0_14</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D Dental Mesh Segmentation Using Semantics-Ba...</td>\n",
       "      <td>Fan Duan, Li Chen</td>\n",
       "      <td>456-465</td>\n",
       "      <td>10.1007/978-3-031-43990-2_43</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3D Medical Image Segmentation with Sparse Anno...</td>\n",
       "      <td>Heng Cai, Lei Qi, Qian Yu, Yinghuan Shi, Yang Gao</td>\n",
       "      <td>614-624</td>\n",
       "      <td>10.1007/978-3-031-43898-1_59</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3D Mitochondria Instance Segmentation with Spa...</td>\n",
       "      <td>Omkar Thawakar, Rao Muhammad Anwer, Jorma Laak...</td>\n",
       "      <td>613-623</td>\n",
       "      <td>10.1007/978-3-031-43993-3_59</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3D Teeth Reconstruction from Panoramic Radiogr...</td>\n",
       "      <td>Sihwa Park, Seongjun Kim, In-Seok Song, Seung ...</td>\n",
       "      <td>376-386</td>\n",
       "      <td>10.1007/978-3-031-43999-5_36</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>\\(\\mathrm {H^{2}}\\)GM: A Hierarchical Hypergra...</td>\n",
       "      <td>Zhibin He, Wuyang Li, Tuo Zhang, Yixuan Yuan</td>\n",
       "      <td>548-558</td>\n",
       "      <td>10.1007/978-3-031-43999-5_52</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>\\(\\textsf{GLSFormer}\\): Gated - Long, Short Se...</td>\n",
       "      <td>Nisarg A. Shah, Shameema Sikder, S. Swaroop Ve...</td>\n",
       "      <td>386-396</td>\n",
       "      <td>10.1007/978-3-031-43996-4_37</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>atTRACTive: Semi-automatic White Matter Tract ...</td>\n",
       "      <td>Robin Peretzke, Klaus H. Maier-Hein, Jonas Boh...</td>\n",
       "      <td>237-246</td>\n",
       "      <td>10.1007/978-3-031-43993-3_23</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>cOOpD: Reformulating COPD Classification on Ch...</td>\n",
       "      <td>Silvia D. Almeida, Carsten T. Lüth, Tobias Nor...</td>\n",
       "      <td>33-43</td>\n",
       "      <td>10.1007/978-3-031-43904-9_4</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>vox2vec: A Framework for Self-supervised Contr...</td>\n",
       "      <td>Mikhail Goncharov, Vera Soboleva, Anvar Kurmuk...</td>\n",
       "      <td>605-614</td>\n",
       "      <td>10.1007/978-3-031-43907-0_58</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>730 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    3D Arterial Segmentation via Single 2D Project...   \n",
       "1    3D Dental Mesh Segmentation Using Semantics-Ba...   \n",
       "2    3D Medical Image Segmentation with Sparse Anno...   \n",
       "3    3D Mitochondria Instance Segmentation with Spa...   \n",
       "4    3D Teeth Reconstruction from Panoramic Radiogr...   \n",
       "..                                                 ...   \n",
       "725  \\(\\mathrm {H^{2}}\\)GM: A Hierarchical Hypergra...   \n",
       "726  \\(\\textsf{GLSFormer}\\): Gated - Long, Short Se...   \n",
       "727  atTRACTive: Semi-automatic White Matter Tract ...   \n",
       "728  cOOpD: Reformulating COPD Classification on Ch...   \n",
       "729  vox2vec: A Framework for Self-supervised Contr...   \n",
       "\n",
       "                                               authors page_numbers  \\\n",
       "0    Alina F. Dima, Veronika A. Zimmer, Martin J. M...      141-151   \n",
       "1                                    Fan Duan, Li Chen      456-465   \n",
       "2    Heng Cai, Lei Qi, Qian Yu, Yinghuan Shi, Yang Gao      614-624   \n",
       "3    Omkar Thawakar, Rao Muhammad Anwer, Jorma Laak...      613-623   \n",
       "4    Sihwa Park, Seongjun Kim, In-Seok Song, Seung ...      376-386   \n",
       "..                                                 ...          ...   \n",
       "725       Zhibin He, Wuyang Li, Tuo Zhang, Yixuan Yuan      548-558   \n",
       "726  Nisarg A. Shah, Shameema Sikder, S. Swaroop Ve...      386-396   \n",
       "727  Robin Peretzke, Klaus H. Maier-Hein, Jonas Boh...      237-246   \n",
       "728  Silvia D. Almeida, Carsten T. Lüth, Tobias Nor...        33-43   \n",
       "729  Mikhail Goncharov, Vera Soboleva, Anvar Kurmuk...      605-614   \n",
       "\n",
       "                              doi  publication_year  volume  paper_id  \n",
       "0    10.1007/978-3-031-43907-0_14              2023       1         1  \n",
       "1    10.1007/978-3-031-43990-2_43              2023       7         2  \n",
       "2    10.1007/978-3-031-43898-1_59              2023       3         3  \n",
       "3    10.1007/978-3-031-43993-3_59              2023       8         4  \n",
       "4    10.1007/978-3-031-43999-5_36              2023      10         5  \n",
       "..                            ...               ...     ...       ...  \n",
       "725  10.1007/978-3-031-43999-5_52              2023      10       726  \n",
       "726  10.1007/978-3-031-43996-4_37              2023       9       727  \n",
       "727  10.1007/978-3-031-43993-3_23              2023       8       728  \n",
       "728   10.1007/978-3-031-43904-9_4              2023       5       729  \n",
       "729  10.1007/978-3-031-43907-0_58              2023       1       730  \n",
       "\n",
       "[730 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the database of all MICCAI 2023 papers\n",
    "#df_miccai = pd.read_csv(database_path +'updated_database_miccai_2023.csv', index_col=[0], header=[0], encoding='utf-8')\n",
    "\n",
    "# Refine the database by adding a unique identifier for each paper\n",
    "#df_miccai.sort_values(by='Title', inplace=True)\n",
    "#df_miccai.reset_index(drop=True, inplace=True)\n",
    "#df_miccai['paper_id'] = range(1, len(df_miccai) + 1)\n",
    "\n",
    "# Save the dataframe to a csv file\n",
    "#df_miccai.to_csv(database_path + 'updated_df_miccai.csv', index=True)\n",
    "filename = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/databases/updated_df_miccai.csv'\n",
    "df_miccai = pd.read_csv(filename, index_col=[0], header=[0], encoding='utf-8')\n",
    "df_miccai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 730 entries, 0 to 729\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   title             730 non-null    object\n",
      " 1   authors           730 non-null    object\n",
      " 2   page_numbers      730 non-null    object\n",
      " 3   doi               730 non-null    object\n",
      " 4   publication_year  730 non-null    int64 \n",
      " 5   volume            730 non-null    int64 \n",
      " 6   paper_id          730 non-null    int64 \n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 45.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_miccai.info()\n",
    "\n",
    "#730 entries, 0 to 729 \n",
    "#6 columns in total\n",
    "#title, authors, page numbers, doi, year of publication, part of publication\n",
    "#dtype: int64(3), object(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a total of 730 papers in MICCAI 2023. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers in Volume 1: 73\n",
      "Number of papers in Volume 2: 73\n",
      "Number of papers in Volume 3: 72\n",
      "Number of papers in Volume 4: 75\n",
      "Number of papers in Volume 5: 76\n",
      "Number of papers in Volume 6: 77\n",
      "Number of papers in Volume 7: 75\n",
      "Number of papers in Volume 8: 65\n",
      "Number of papers in Volume 9: 70\n",
      "Number of papers in Volume 10: 74\n",
      "Total number of papers: 730\n"
     ]
    }
   ],
   "source": [
    "# count the number of papers for each Volume. There is 10 Volumes in total\n",
    "\n",
    "print('Number of papers in Volume 1:', df_miccai['volume'].value_counts()[1]) #73\n",
    "print('Number of papers in Volume 2:', df_miccai['volume'].value_counts()[2]) #73\n",
    "print('Number of papers in Volume 3:', df_miccai['volume'].value_counts()[3]) #72\n",
    "print('Number of papers in Volume 4:', df_miccai['volume'].value_counts()[4]) #75\n",
    "print('Number of papers in Volume 5:', df_miccai['volume'].value_counts()[5]) #76\n",
    "print('Number of papers in Volume 6:', df_miccai['volume'].value_counts()[6]) #77\n",
    "print('Number of papers in Volume 7:', df_miccai['volume'].value_counts()[7]) #75\n",
    "print('Number of papers in Volume 8:', df_miccai['volume'].value_counts()[8]) #65\n",
    "print('Number of papers in Volume 9:', df_miccai['volume'].value_counts()[9]) #70\n",
    "print('Number of papers in Volume 10:', df_miccai['volume'].value_counts()[10]) #74\n",
    "\n",
    "# count the total number of papers in the dataframe\n",
    "print('Total number of papers:', df_miccai['volume'].value_counts().sum()) #730"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# **Selecting a scope of papers from MICCAI 2023**\n",
    "***\n",
    "***\n",
    "\n",
    "**Scope criteria:** Selecting papers, that researched within the field of cancer-related illnesses by searching for cancer-related keywords in the text of each research paper. The text is defined from the start of Abstraction ending with the last line of Conclusion, exluding the Title of the paper, the authors and affiliations, the Acknowlegdement and the References. \n",
    "\n",
    "Cancer-related keywords could be words such as 'cancer', 'tumor' and/or 'tumours'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract papers that contain the word 'cancer' in the text\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted titles from 189 selected papers.\n",
      "With the keyword(s) being ['cancer'], 189 papers were selected as relevant to cancer research.\n"
     ]
    }
   ],
   "source": [
    "# Function to extract the full text from the PDF\n",
    "def extract_text(pdf_path):\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        full_text = \"\"\n",
    "        for page in doc:\n",
    "            full_text += page.get_text()\n",
    "    return full_text\n",
    "\n",
    "# Function to find if any of the keywords appear in the section between Abstract and Conclusion\n",
    "def find_keywords_section(full_text, keywords):\n",
    "     # Regular expressions to find the end of the affiliations section\n",
    "    affiliations_end = re.search(r'\\d{1,2}\\s+(?:\\w+\\.)+@\\w+\\.\\w{2,}', full_text)\n",
    "    \n",
    "    # Start searching from the end of affiliations if found, otherwise from the start of the text\n",
    "    start_idx = affiliations_end.end() if affiliations_end else 0\n",
    "    \n",
    "    # Look for the Abstract and Conclusion sections\n",
    "    abstract_idx = full_text.lower().find(\"abstract\", start_idx)\n",
    "    conclusion_idx = full_text.lower().rfind(\"conclusion\", abstract_idx)\n",
    "    acknowledgements_idx = full_text.lower().find(\"acknowledgements\", conclusion_idx)\n",
    "    \n",
    "    # Adjust the end index to stop at Acknowledgements if it exists, otherwise use Conclusion index\n",
    "    end_search_idx = acknowledgements_idx if acknowledgements_idx != -1 else conclusion_idx\n",
    "    \n",
    "    # If neither Abstract nor Conclusion is found, search the entire text\n",
    "    if abstract_idx == -1 and conclusion_idx == -1:\n",
    "        searchable_text = full_text[start_idx:]\n",
    "    else:\n",
    "        # Search from Abstract to Conclusion or Acknowledgements\n",
    "        searchable_text = full_text[abstract_idx:end_search_idx].lower()\n",
    "    \n",
    "    # Search for each keyword within the determined section, stop at first match\n",
    "    for keyword in keywords:\n",
    "        if keyword.lower() in searchable_text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Function to extract the title from the PDF\n",
    "def extract_title(pdf_path):\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        first_page_text = doc[0].get_text(\"text\")\n",
    "        \n",
    "        # Regular expression to find the start of affiliations or author names\n",
    "        # Looks for sequences in author lists or affiliations, such as numbers and parentheses\n",
    "        author_or_affiliations_start = re.search(r'\\b[A-Z][a-z]+ [A-Z]\\.|\\b[A-Z][a-z]+\\s[A-Z][a-z]+[1-9]', first_page_text)\n",
    "\n",
    "        title = \"\"\n",
    "        if author_or_affiliations_start:\n",
    "            # Extract text up to the start of the author list or affiliations as potential title text\n",
    "            potential_title_text = first_page_text[:author_or_affiliations_start.start()].strip()\n",
    "            title_lines = potential_title_text.split('\\n')\n",
    "            \n",
    "            # The title is expected to be a continuous block of text at the top of the page,\n",
    "            # possibly after a journal header or similar: look for a large continuous block of text.\n",
    "            for line in reversed(title_lines):\n",
    "                if line.strip():  \n",
    "                    # Prepend to keep the title in the correct order\n",
    "                    title = line + \" \" + title\n",
    "                else:\n",
    "                    # An empty line might indicate the end of the title block\n",
    "                    break\n",
    "        else:\n",
    "            # If no author list or affiliation section is identified, use the first non-empty line\n",
    "            for line in first_page_text.split('\\n'):\n",
    "                if line.strip():\n",
    "                    title = line\n",
    "                    break\n",
    "\n",
    "        title = title.strip()  # Clean up whitespace\n",
    "        return title\n",
    "\n",
    "selected_papers = []\n",
    "titles = []\n",
    "\n",
    "# List of keywords to search for\n",
    "keywords = [\"cancer\"]\n",
    "\n",
    "# Iterate over each volume and search for keywords\n",
    "for i in range(1, 11):  # Volumes 1 to 10\n",
    "    folder_name = f\"miccai23vol{i}\"\n",
    "    folder_path = os.path.join(pdf_path, folder_name)\n",
    "    \n",
    "    for pdf in os.listdir(folder_path):\n",
    "        if pdf.endswith(\".pdf\"):\n",
    "            pdf_path_ = os.path.join(folder_path, pdf)\n",
    "            full_text = extract_text(pdf_path_)\n",
    "            if find_keywords_section(full_text, keywords):\n",
    "                selected_papers.append(os.path.join(folder_name, pdf))\n",
    "\n",
    "# Extract titles from selected papers\n",
    "for paper_path in selected_papers:\n",
    "    full_paper_path = os.path.join(pdf_path, paper_path)\n",
    "    title = extract_title(full_paper_path)\n",
    "    titles.append(title)\n",
    "\n",
    "print(f\"Extracted titles from {len(titles)} selected papers.\")\n",
    "print(f\"With the keyword(s) being {keywords}, {len(selected_papers)} papers were selected as relevant to cancer research.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the selected papers into a dataframe with their related paths\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the selected papers and their paths to a CSV file\n",
    "#selected_papers_df = pd.DataFrame({\"path\": selected_papers, \"title\": titles})\n",
    "\n",
    "# Refine the selection of papers by adding a unique identifier for each paper\n",
    "# This will be useful for tracking papers in the pipeline\n",
    "#filename = 'selected_papers_paperid'\n",
    "\n",
    "# Rename the columns to lowercase\n",
    "#selected_papers_df.rename(columns={'Title': 'title', 'Path': 'path'}, inplace=True)\n",
    "\n",
    "# Sort the dataframe by title\n",
    "#selected_papers_df.sort_values(by='title', inplace=True)\n",
    "\n",
    "# Reset the index\n",
    "##selected_papers_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Add a unique identifier for each paper\n",
    "#selected_papers_df['paper_id'] = range(1, len(selected_papers_df) + 1)\n",
    "\n",
    "# Save the dataframe to a CSV file for later use in the pipeline. columns: path, title, paper_id\n",
    "#selected_papers_df.to_csv(filename +'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>title</th>\n",
       "      <th>paper_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>miccai23vol1/paper_14.pdf</td>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>miccai23vol8/paper_59.pdf</td>\n",
       "      <td>3D Mitochondria Instance Segmentation with Spa...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>miccai23vol2/paper_46.pdf</td>\n",
       "      <td>A Spatial-Temporal Deformable Attention Based ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>miccai23vol8/paper_46.pdf</td>\n",
       "      <td>A Texture Neural Network to Predict</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>miccai23vol6/paper_74.pdf</td>\n",
       "      <td>ALL-IN: A Local GLobal Graph-Based DIstillatio...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>miccai23vol3/paper_72.pdf</td>\n",
       "      <td>WeakPolyp: You only Look Bounding Box for Poly...</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>miccai23vol1/paper_22.pdf</td>\n",
       "      <td>Weakly-Supervised Positional Contrastive Learn...</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>miccai23vol10/paper_66.pdf</td>\n",
       "      <td>X2Vision: 3D CT Reconstruction from Biplanar X...</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>miccai23vol5/paper_5.pdf</td>\n",
       "      <td>YONA: You Only Need One Adjacent Reference-Fra...</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>miccai23vol1/paper_58.pdf</td>\n",
       "      <td>vox2vec: A Framework for Self-supervised Contr...</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           path  \\\n",
       "0     miccai23vol1/paper_14.pdf   \n",
       "1     miccai23vol8/paper_59.pdf   \n",
       "2     miccai23vol2/paper_46.pdf   \n",
       "3     miccai23vol8/paper_46.pdf   \n",
       "4     miccai23vol6/paper_74.pdf   \n",
       "..                          ...   \n",
       "184   miccai23vol3/paper_72.pdf   \n",
       "185   miccai23vol1/paper_22.pdf   \n",
       "186  miccai23vol10/paper_66.pdf   \n",
       "187    miccai23vol5/paper_5.pdf   \n",
       "188   miccai23vol1/paper_58.pdf   \n",
       "\n",
       "                                                 title  paper_id  \n",
       "0    3D Arterial Segmentation via Single 2D Project...         1  \n",
       "1    3D Mitochondria Instance Segmentation with Spa...         2  \n",
       "2    A Spatial-Temporal Deformable Attention Based ...         3  \n",
       "3                  A Texture Neural Network to Predict         4  \n",
       "4    ALL-IN: A Local GLobal Graph-Based DIstillatio...         5  \n",
       "..                                                 ...       ...  \n",
       "184  WeakPolyp: You only Look Bounding Box for Poly...       185  \n",
       "185  Weakly-Supervised Positional Contrastive Learn...       186  \n",
       "186  X2Vision: 3D CT Reconstruction from Biplanar X...       187  \n",
       "187  YONA: You Only Need One Adjacent Reference-Fra...       188  \n",
       "188  vox2vec: A Framework for Self-supervised Contr...       189  \n",
       "\n",
       "[189 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_papers_df = pd.read_csv('/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/finals/selected_papers_paperid.csv')\n",
    "selected_papers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the list of complete paths\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_29.pdf'],\n",
       " ['/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_14.pdf'],\n",
       " ['/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_11.pdf'],\n",
       " ['/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_58.pdf'],\n",
       " ['/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_64.pdf']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store the complete paths of the selected papers in a list for later use in the pipeline\n",
    "selected_papers_paths = []\n",
    "for i in range(0, len(selected_papers)):  # Volumes 1 to 10\n",
    "    selected_papers_paths.append([base_path + 'miccai_2023/' + selected_papers[i]])\n",
    "\n",
    "# Check if the total number of paths is equal to the number of selected papers\n",
    "len(selected_papers_paths)\n",
    "selected_papers_paths[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for keyword searching and sentence extractions\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# check text for keywords\n",
    " # Function to extract the full text from the PDF\n",
    "def extract_text(pdf_path):\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        full_text = \"\"\n",
    "        for page in doc:\n",
    "            full_text += page.get_text()\n",
    "            # Regular expressions to find the end of the affiliations section\n",
    "            affiliations_end = re.search(r'\\d{1,2}\\s+(?:\\w+\\.)+@\\w+\\.\\w{2,}', full_text)\n",
    "            \n",
    "            # Start searching from the end of affiliations if found, otherwise from the start of the text\n",
    "            start_idx = affiliations_end.end() if affiliations_end else 0\n",
    "            \n",
    "            # Look for the Abstract and Conclusion sections\n",
    "            abstract_idx = full_text.lower().find(\"abstract\", start_idx)\n",
    "            conclusion_idx = full_text.lower().rfind(\"conclusion\", abstract_idx)\n",
    "            acknowledgements_idx = full_text.lower().find(\"acknowledgements\", conclusion_idx)\n",
    "            \n",
    "            # Adjust the end index to stop at Acknowledgements if it exists, otherwise use Conclusion index\n",
    "            end_search_idx = acknowledgements_idx if acknowledgements_idx != -1 else conclusion_idx\n",
    "            \n",
    "            # If neither Abstract nor Conclusion is found, search the entire text\n",
    "            if abstract_idx == -1 and conclusion_idx == -1:\n",
    "                searchable_text = full_text[start_idx:]\n",
    "            else:\n",
    "                # Search from Abstract to Conclusion or Acknowledgements\n",
    "                searchable_text = full_text[abstract_idx:end_search_idx].lower()          \n",
    "        \n",
    "    return searchable_text\n",
    "\n",
    "def extract_relevant_sentences(text, keywords):\n",
    "    relevant_sentences = []\n",
    "    doc = nlp(text)\n",
    "    # Regex pattern that matches whole words from the keywords list, case insensitive\n",
    "    pattern = r'\\b(' + '|'.join(re.escape(keyword) for keyword in keywords) + r')\\b'\n",
    "    for sent in doc.sents:\n",
    "        if re.search(pattern, sent.text, re.IGNORECASE):\n",
    "            relevant_sentences.append(sent.text.strip())\n",
    "    return relevant_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to hold the extracted info\n",
    "def extract_sents_by_keywords(list_of_pdf_paths, keywords, col_title):\n",
    "    extracted_sents = {}\n",
    "\n",
    "    for pdf_path in list_of_pdf_paths:\n",
    "        path = pdf_path[0]  # pdf_path is a list with the first element being the file path\n",
    "        text = extract_text(path)\n",
    "        relevant_sentences = extract_relevant_sentences(text, keywords)\n",
    "        \n",
    "        # If no relevant sentences were extracted, include the paper with extracted_sentence set to None\n",
    "        if not relevant_sentences:\n",
    "            extracted_sents[path] = [None] # Probably better to change this to 0\n",
    "        else:\n",
    "            extracted_sents[path] = relevant_sentences\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    rows = []\n",
    "    for paper_id, sentences in extracted_sents.items():\n",
    "        if sentences == 0:  # Check if the list contains only None, indicating no sentences were extracted\n",
    "            rows.append({'paper_id': paper_id, col_title: None})\n",
    "        else:\n",
    "            for sentence in sentences:\n",
    "                rows.append({'paper_id': paper_id, col_title: sentence})\n",
    "\n",
    "    extracted_sents_df = pd.DataFrame(rows)\n",
    "    return extracted_sents_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence extraction\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract sentences by keyword = cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for 'cancer' in text for all 730 papers\n",
    "# Check procedure to see if the selected paper contains the word 'cancer'\n",
    "keywords = [\"cancer\"]\n",
    "\n",
    "# Extract sentences by cancer\n",
    "sents_by_cancer = extract_sents_by_keywords(selected_papers_paths, keywords, col_title='extracted_sent_cancer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "#csv_filename = 'extracted_sent_cancer.csv'\n",
    "#sents_by_cancer.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract sentences by list of keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant sentences from the selected papers by these keywords\n",
    "keywords = ['age', 'gender', 'sex', 'women', 'woman', 'female', 'male',\n",
    "            'geolocation', 'geographical', 'geographic', 'country', 'countries', 'city', 'cities', 'hospital', 'hospitals', 'clinic', 'clinics', \n",
    "            'society', 'societies',\n",
    "            'etnicity', 'etnicities', 'race', \n",
    "            'bias', 'biases', 'fair', 'unfair', 'fairness', 'transparency',\n",
    "            'imbalance', 'imbalanced', 'balance', 'balanced']\n",
    "\n",
    "# Extract sentences by keywords\n",
    "sents_by_keywords = extract_sents_by_keywords(selected_papers_paths, keywords, col_title='extracted_sents_keywords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "#csv_filename = 'extracted_sents_keywords.csv'\n",
    "#sents_by_keywords.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant sentences from the selected papers by these keywords\n",
    "keywords = ['age', 'gender', 'sex', 'women', 'woman', 'female', 'male',\n",
    "            'geolocation', 'geographical', 'geographic', 'country', 'countries', 'city', 'cities', 'hospital', 'hospitals', 'clinic', 'clinics', \n",
    "            'society', 'societies',\n",
    "            'etnicity', 'etnicities', 'race', \n",
    "            'bias', 'biases', 'fair', 'unfair', 'fairness', 'transparency',\n",
    "            'imbalance', 'imbalanced', 'balance', 'balanced',\n",
    "            'problem', 'problems', 'issue', 'issues', 'challenge', 'challenges', 'difficulty', 'difficulties',\n",
    "            'critic', 'critics', 'criticism', 'criticize', 'criticized', 'criticizing', 'critique', 'critiques', 'critiqued', 'critiquing']\n",
    "\n",
    "# Extract sentences by keywords\n",
    "sents_by_keywords = extract_sents_by_keywords(selected_papers_paths, keywords, col_title='extracted_sents_keywords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "#csv_filename = 'extracted_sents_keywords_2.csv'\n",
    "#sents_by_keywords.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract sentences by list of organs\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant sentences from the selected papers by organs\n",
    "\n",
    "organs = pd.read_csv(database_path + 'search words/organs.csv', header=None)\n",
    "organs = organs[0].tolist()\n",
    "organs\n",
    "\n",
    "keywords = ['adrenal', 'anal', 'anusarteries', 'gi', 'tract', 'gi-tract', 'colon', 'bladder', 'bone', 'marrow', 'bronchi', 'bronchioles', \n",
    "            'bulbourethral', 'capillaries', 'cecum', 'cerebellum', 'cerebral', 'cervix', 'choroid', 'plexus', 'ciliary', 'body', 'clitoris', \n",
    "            'cochlea', 'cornea', 'cranial', 'nerves', 'duodenum', 'eardrum', 'nervous', 'system', 'epididymis', 'esophagus', 'fallopian', 'tubes', \n",
    "            'gallbladder', 'ganglia', 'heart', 'skeleton', 'hypothalamus', 'ileum', 'interstitium', 'iris', 'jejunum', 'joint', 'joints', 'kidneys', \n",
    "            'larynx', 'ligament', 'ligaments', 'liver', 'lung', 'lungs', 'lymph', 'node', 'lymphatic', 'vessel', 'glands', 'oblongata', 'mesentery', \n",
    "            'brain', 'ear', 'ossicles', 'muscles', 'nasal', 'cavity', 'olfactory', 'epithelium', 'ovaries', 'pancreas', 'parathyroid', 'parotid', 'penis', \n",
    "            'pharynx', 'pineal', 'pituitary', 'placenta', 'prostate', 'rectum', 'retina', 'sigmoid', 'skin', 'spinal', 'nerves', 'spleen', 'stomach', \n",
    "            'tissue', 'sublingual', 'submandibular', 'teeth', 'tendons', 'testes', 'thalamus', 'spinal', 'cord', 'thymus', 'thyroid', 'tongue', 'tonsils', \n",
    "            'trachea', 'transverse', 'ureter', 'urethra', 'uterus', 'vagina', 'veins', 'vulva', 'lung', 'lungs', 'pulmonary', 'respiratory', 'bronchial', \n",
    "            'bronchi', 'bronchus', 'bronchial', 'trachea', 'tracheal', 'thoracic', 'thorax', 'diaphragm', 'diaphragmatic', 'pleural', 'pleura', 'alveolar', \n",
    "            'alveoli', 'gi-tract', 'gastrointestinal', 'gastro', 'intestinal', 'digestive', 'digestion', 'stomach', 'gastric', 'intestine', 'intestines', \n",
    "            'intestinal', 'colon', 'colonic', 'rectum', 'rectal', 'anus', 'anal', 'liver', 'hepatic', 'hepatitis', 'hepatocellular', 'hepatoma', 'hepatocarcinoma',\n",
    "            'cervical', 'cervix', 'uterus', 'uterine', 'endometrial', 'ovarian', 'ovary', 'fallopian', 'tube', 'vaginal', 'gland', 'prostate gland',\n",
    "            'prostate glands','testicular', 'testis', \n",
    "            'penile', 'breast', 'breast tissue']\n",
    "\n",
    "# Extract sentences by keywords\n",
    "sents_by_organs = extract_sents_by_keywords(selected_papers_paths, keywords, col_title='extracted_sents_organs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "#csv_filename = 'extracted_sents_organs.csv'\n",
    "#sents_by_organs.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV files with extracted sentences\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from CSV\n",
    "f_name_keywords = 'extracted_sents_keywords'\n",
    "f_name_keywords_2 = 'extracted_sents_keywords_2'\n",
    "f_name_cancer = 'extracted_sents_cancer'\n",
    "f_name_organs = 'extracted_sents_organs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refine the dataframe for extracted sentences by the list of keywords: 1st attempt\n",
    "f_name = f_name_keywords\n",
    "file_path = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/finals/' + f_name + '.csv'\n",
    "extracted_sents = pd.read_csv(file_path)\n",
    "\n",
    "# Fill NaN values with 'None'\n",
    "extracted_sents.fillna('None', inplace=True)\n",
    "\n",
    "# Refine the paper_id column to only include part of the pdf path \n",
    "extracted_sents['path'] = extracted_sents['paper_id'].str.split('/').apply(lambda x: '/'.join(x[-2:]))\n",
    "extracted_sents.rename(columns={'paper_id': 'path_long'}, inplace=True)\n",
    "\n",
    "# Save to CSV file for later use in the pipeline. columns: complete path, title, path\n",
    "# extracted_sents.to_csv('extracted_sents_keywords_refined.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refine the dataframe for extracted sentences by the list of keywords: 2nd attempt\n",
    "f_name = f_name_keywords_2\n",
    "file_path = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/finals/' + f_name + '.csv'\n",
    "extracted_sents = pd.read_csv(file_path)\n",
    "\n",
    "# Fill NaN values with 'None'\n",
    "extracted_sents.fillna('None', inplace=True)\n",
    "\n",
    "# Refine the paper_id column to only include part of the pdf path \n",
    "extracted_sents['path'] = extracted_sents['paper_id'].str.split('/').apply(lambda x: '/'.join(x[-2:]))\n",
    "extracted_sents.rename(columns={'paper_id': 'path_long'}, inplace=True)\n",
    "\n",
    "# Save to CSV file for later use in the pipeline. columns: complete path, title, path\n",
    "#extracted_sents.to_csv('extracted_sents_keywords_2_refined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path_long</th>\n",
       "      <th>extracted_sents_keywords</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>however, novel unsupervised\\nanomaly detectors...</td>\n",
       "      <td>miccai23vol1/paper_29.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>this transforms the problem to learning the co...</td>\n",
       "      <td>miccai23vol1/paper_29.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>we found when training the vq-vae model on dat...</td>\n",
       "      <td>miccai23vol1/paper_29.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>compared to\\ncenterline segmentation, where th...</td>\n",
       "      <td>miccai23vol1/paper_14.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>the cohort consists of 141 patients with pancr...</td>\n",
       "      <td>miccai23vol1/paper_14.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>such inconsis-\\ntent metrics suggest that the ...</td>\n",
       "      <td>miccai23vol10/paper_3.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>our work challenges the conventional\\nassumpti...</td>\n",
       "      <td>miccai23vol10/paper_21.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>to address these issues, we concentrate on the...</td>\n",
       "      <td>miccai23vol10/paper_24.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>lowering the dose of ct\\nscans has been widely...</td>\n",
       "      <td>miccai23vol10/paper_24.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>3. overview of dual-domain counterpart of free...</td>\n",
       "      <td>miccai23vol10/paper_24.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1303 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              path_long  \\\n",
       "0     /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "1     /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "2     /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "3     /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "4     /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "...                                                 ...   \n",
       "1298  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "1299  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "1300  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "1301  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "1302  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "\n",
       "                               extracted_sents_keywords  \\\n",
       "0     however, novel unsupervised\\nanomaly detectors...   \n",
       "1     this transforms the problem to learning the co...   \n",
       "2     we found when training the vq-vae model on dat...   \n",
       "3     compared to\\ncenterline segmentation, where th...   \n",
       "4     the cohort consists of 141 patients with pancr...   \n",
       "...                                                 ...   \n",
       "1298  such inconsis-\\ntent metrics suggest that the ...   \n",
       "1299  our work challenges the conventional\\nassumpti...   \n",
       "1300  to address these issues, we concentrate on the...   \n",
       "1301  lowering the dose of ct\\nscans has been widely...   \n",
       "1302  3. overview of dual-domain counterpart of free...   \n",
       "\n",
       "                            path  \n",
       "0      miccai23vol1/paper_29.pdf  \n",
       "1      miccai23vol1/paper_29.pdf  \n",
       "2      miccai23vol1/paper_29.pdf  \n",
       "3      miccai23vol1/paper_14.pdf  \n",
       "4      miccai23vol1/paper_14.pdf  \n",
       "...                          ...  \n",
       "1298   miccai23vol10/paper_3.pdf  \n",
       "1299  miccai23vol10/paper_21.pdf  \n",
       "1300  miccai23vol10/paper_24.pdf  \n",
       "1301  miccai23vol10/paper_24.pdf  \n",
       "1302  miccai23vol10/paper_24.pdf  \n",
       "\n",
       "[1303 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge selected papers with metadata from the complete list of MICCAI 2023 papers\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge MICCAI 2023 database with the selected papers to get the metadata \n",
    "#papers = pd.merge(df_miccai, selected_papers_df, on='paper_id', how='inner').drop(columns=['title_y']).rename(columns={'title_x': 'title'})\n",
    "#papers.to_csv('papers.csv', index=False)\n",
    "\n",
    "# Merge the papers with the extracted sentences by keywords\n",
    "#pd.merge(papers, extracted_sents, on='path', how='inner').to_csv('papers_with_sents_by_keywords_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge MICCAI 2023 database with the selected papers to get the metadata \n",
    "#papers = pd.merge(df_miccai, selected_papers_df, on='paper_id', how='inner').drop(columns=['title_y']).rename(columns={'title_x': 'title'})\n",
    "#papers.to_csv('papers.csv', index=False)\n",
    "\n",
    "# Merge the papers with the extracted sentences by keywords\n",
    "#pd.merge(papers, extracted_sents, on='path', how='inner').to_csv('papers_with_sents_by_keywords_metadata.csv_2', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Organs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge MICCAI 2023 database with the selected papers to get the metadata \n",
    "papers = pd.merge(df_miccai, selected_papers_df, on='paper_id', how='inner').drop(columns=['title_y']).rename(columns={'title_x': 'title'})\n",
    "#papers.to_csv('papers.csv', index=False)\n",
    "\n",
    "# Merge the papers with the extracted sentences by keywords\n",
    "papers_sents_organs = pd.merge(papers, extracted_sents, on='path', how='inner').to_csv('papers_with_sents_by_organs_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final dataframe with extracted sentences by the list of keywords and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_col_position_to_first(df, col_name):\n",
    "    # Column to move to the first position\n",
    "    column_to_move = col_name\n",
    "\n",
    "    # Create a new list of column names with the specified column first\n",
    "    new_columns = [column_to_move] + [col for col in df.columns if col != column_to_move]\n",
    "\n",
    "    # Reindex the DataFrame with the new column order\n",
    "    df = df[new_columns]\n",
    "    return df\n",
    "\n",
    "def move_col_position_to_last(df, col_name):\n",
    "    # Column to move to the first position\n",
    "    column_to_move = col_name\n",
    "\n",
    "    # Create a new list of column names with the specified column first\n",
    "    new_columns = [column_to_move] + [col for col in df.columns if col != column_to_move]\n",
    "\n",
    "    # Create a new list of column names with the specified column last\n",
    "    new_columns = [col for col in df.columns if col != column_to_move] + [column_to_move] \n",
    "\n",
    "    # Reindex the DataFrame with the new column order\n",
    "    df = df[new_columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of keywords\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>page_numbers</th>\n",
       "      <th>doi</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>volume</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>path</th>\n",
       "      <th>path_long</th>\n",
       "      <th>extracted_sents_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>Alina F. Dima, Veronika A. Zimmer, Martin J. M...</td>\n",
       "      <td>141-151</td>\n",
       "      <td>10.1007/978-3-031-43907-0_14</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>miccai23vol1/paper_14.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>the cohort consists of 141 patients with pancr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>Alina F. Dima, Veronika A. Zimmer, Martin J. M...</td>\n",
       "      <td>141-151</td>\n",
       "      <td>10.1007/978-3-031-43907-0_14</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>miccai23vol1/paper_14.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>we distinguish between models selected accordi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3D Dental Mesh Segmentation Using Semantics-Ba...</td>\n",
       "      <td>Fan Duan, Li Chen</td>\n",
       "      <td>456-465</td>\n",
       "      <td>10.1007/978-3-031-43990-2_43</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>miccai23vol8/paper_59.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>during training\\nof mitoem, for the fair compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3D Dental Mesh Segmentation Using Semantics-Ba...</td>\n",
       "      <td>Fan Duan, Li Chen</td>\n",
       "      <td>456-465</td>\n",
       "      <td>10.1007/978-3-031-43990-2_43</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>miccai23vol8/paper_59.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>for fair comparison with previous\\nworks, we u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3D Medical Image Segmentation with Sparse Anno...</td>\n",
       "      <td>Heng Cai, Lei Qi, Qian Yu, Yinghuan Shi, Yang Gao</td>\n",
       "      <td>614-624</td>\n",
       "      <td>10.1007/978-3-031-43898-1_59</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>miccai23vol2/paper_46.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>video\\nresnet-50 40.0 70.3\\n43.3\\nthe previous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>DeepGraphDMD: Interpretable Spatio-Temporal De...</td>\n",
       "      <td>Md Asadullah Turja, Martin Styner, Guorong Wu</td>\n",
       "      <td>358-368</td>\n",
       "      <td>10.1007/978-3-031-43993-3_35</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>186</td>\n",
       "      <td>miccai23vol1/paper_22.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>for d2\\nhisto, which has fewer patients than t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>DeepGraphDMD: Interpretable Spatio-Temporal De...</td>\n",
       "      <td>Md Asadullah Turja, Martin Styner, Guorong Wu</td>\n",
       "      <td>358-368</td>\n",
       "      <td>10.1007/978-3-031-43993-3_35</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>186</td>\n",
       "      <td>miccai23vol1/paper_22.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>the method depth-aware manages to correctly en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>DeepSOZ: A Robust Deep Model for Joint Tempora...</td>\n",
       "      <td>Deeksha M. Shama, Jiasen Jing, Archana Venkata...</td>\n",
       "      <td>184-194</td>\n",
       "      <td>10.1007/978-3-031-43993-3_18</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>187</td>\n",
       "      <td>miccai23vol10/paper_66.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>by grid search on the\\nvalidation set, we sele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>Democratizing Pathological Image Segmentation ...</td>\n",
       "      <td>Ruining Deng, Yanwei Li, Peize Li, Jiacheng Wa...</td>\n",
       "      <td>497-507</td>\n",
       "      <td>10.1007/978-3-031-43987-2_48</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>188</td>\n",
       "      <td>miccai23vol5/paper_5.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>for the fairness of the experiments, we keep t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>Dense Transformer based Enhanced Coding Networ...</td>\n",
       "      <td>Wangduo Xie, Matthew B. Blaschko</td>\n",
       "      <td>77-86</td>\n",
       "      <td>10.1007/978-3-031-43907-0_8</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>miccai23vol1/paper_58.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>661 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    3D Arterial Segmentation via Single 2D Project...   \n",
       "1    3D Arterial Segmentation via Single 2D Project...   \n",
       "2    3D Dental Mesh Segmentation Using Semantics-Ba...   \n",
       "3    3D Dental Mesh Segmentation Using Semantics-Ba...   \n",
       "4    3D Medical Image Segmentation with Sparse Anno...   \n",
       "..                                                 ...   \n",
       "656  DeepGraphDMD: Interpretable Spatio-Temporal De...   \n",
       "657  DeepGraphDMD: Interpretable Spatio-Temporal De...   \n",
       "658  DeepSOZ: A Robust Deep Model for Joint Tempora...   \n",
       "659  Democratizing Pathological Image Segmentation ...   \n",
       "660  Dense Transformer based Enhanced Coding Networ...   \n",
       "\n",
       "                                               authors page_numbers  \\\n",
       "0    Alina F. Dima, Veronika A. Zimmer, Martin J. M...      141-151   \n",
       "1    Alina F. Dima, Veronika A. Zimmer, Martin J. M...      141-151   \n",
       "2                                    Fan Duan, Li Chen      456-465   \n",
       "3                                    Fan Duan, Li Chen      456-465   \n",
       "4    Heng Cai, Lei Qi, Qian Yu, Yinghuan Shi, Yang Gao      614-624   \n",
       "..                                                 ...          ...   \n",
       "656      Md Asadullah Turja, Martin Styner, Guorong Wu      358-368   \n",
       "657      Md Asadullah Turja, Martin Styner, Guorong Wu      358-368   \n",
       "658  Deeksha M. Shama, Jiasen Jing, Archana Venkata...      184-194   \n",
       "659  Ruining Deng, Yanwei Li, Peize Li, Jiacheng Wa...      497-507   \n",
       "660                   Wangduo Xie, Matthew B. Blaschko        77-86   \n",
       "\n",
       "                              doi  publication_year  volume  paper_id  \\\n",
       "0    10.1007/978-3-031-43907-0_14              2023       1         1   \n",
       "1    10.1007/978-3-031-43907-0_14              2023       1         1   \n",
       "2    10.1007/978-3-031-43990-2_43              2023       7         2   \n",
       "3    10.1007/978-3-031-43990-2_43              2023       7         2   \n",
       "4    10.1007/978-3-031-43898-1_59              2023       3         3   \n",
       "..                            ...               ...     ...       ...   \n",
       "656  10.1007/978-3-031-43993-3_35              2023       8       186   \n",
       "657  10.1007/978-3-031-43993-3_35              2023       8       186   \n",
       "658  10.1007/978-3-031-43993-3_18              2023       8       187   \n",
       "659  10.1007/978-3-031-43987-2_48              2023       6       188   \n",
       "660   10.1007/978-3-031-43907-0_8              2023       1       189   \n",
       "\n",
       "                           path  \\\n",
       "0     miccai23vol1/paper_14.pdf   \n",
       "1     miccai23vol1/paper_14.pdf   \n",
       "2     miccai23vol8/paper_59.pdf   \n",
       "3     miccai23vol8/paper_59.pdf   \n",
       "4     miccai23vol2/paper_46.pdf   \n",
       "..                          ...   \n",
       "656   miccai23vol1/paper_22.pdf   \n",
       "657   miccai23vol1/paper_22.pdf   \n",
       "658  miccai23vol10/paper_66.pdf   \n",
       "659    miccai23vol5/paper_5.pdf   \n",
       "660   miccai23vol1/paper_58.pdf   \n",
       "\n",
       "                                             path_long  \\\n",
       "0    /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "1    /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "2    /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "3    /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "4    /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "..                                                 ...   \n",
       "656  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "657  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "658  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "659  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "660  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "\n",
       "                              extracted_sents_keywords  \n",
       "0    the cohort consists of 141 patients with pancr...  \n",
       "1    we distinguish between models selected accordi...  \n",
       "2    during training\\nof mitoem, for the fair compa...  \n",
       "3    for fair comparison with previous\\nworks, we u...  \n",
       "4    video\\nresnet-50 40.0 70.3\\n43.3\\nthe previous...  \n",
       "..                                                 ...  \n",
       "656  for d2\\nhisto, which has fewer patients than t...  \n",
       "657  the method depth-aware manages to correctly en...  \n",
       "658  by grid search on the\\nvalidation set, we sele...  \n",
       "659  for the fairness of the experiments, we keep t...  \n",
       "660                                               None  \n",
       "\n",
       "[661 rows x 10 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/papers_with_sents_by_keywords_metadata.csv'\n",
    "papers_with_sentences_df = pd.read_csv(filename)\n",
    "\n",
    "# Fill NaN values with 'None'\n",
    "papers_with_sentences_df.fillna('None', inplace=True)\n",
    "papers_with_sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange the columns to have paper_id first\n",
    "df = move_col_position_to_last(papers_with_sentences_df, 'extracted_sents_keywords')\n",
    "df = move_col_position_to_first(df, 'paper_id')\n",
    "#df.to_csv('papers_with_sents_by_keywords_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>page_numbers</th>\n",
       "      <th>doi</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>volume</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>path</th>\n",
       "      <th>path_long</th>\n",
       "      <th>extracted_sents_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>Alina F. Dima, Veronika A. Zimmer, Martin J. M...</td>\n",
       "      <td>141-151</td>\n",
       "      <td>10.1007/978-3-031-43907-0_14</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>miccai23vol1/paper_14.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>compared to\\ncenterline segmentation, where th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>Alina F. Dima, Veronika A. Zimmer, Martin J. M...</td>\n",
       "      <td>141-151</td>\n",
       "      <td>10.1007/978-3-031-43907-0_14</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>miccai23vol1/paper_14.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>the cohort consists of 141 patients with pancr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>Alina F. Dima, Veronika A. Zimmer, Martin J. M...</td>\n",
       "      <td>141-151</td>\n",
       "      <td>10.1007/978-3-031-43907-0_14</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>miccai23vol1/paper_14.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>we distinguish between models selected accordi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>Alina F. Dima, Veronika A. Zimmer, Martin J. M...</td>\n",
       "      <td>141-151</td>\n",
       "      <td>10.1007/978-3-031-43907-0_14</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>miccai23vol1/paper_14.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>with the exception of the single ﬁxed viewpoin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3D Dental Mesh Segmentation Using Semantics-Ba...</td>\n",
       "      <td>Fan Duan, Li Chen</td>\n",
       "      <td>456-465</td>\n",
       "      <td>10.1007/978-3-031-43990-2_43</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>miccai23vol8/paper_59.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>accurate 3d mitochondria instance segmentation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>Democratizing Pathological Image Segmentation ...</td>\n",
       "      <td>Ruining Deng, Yanwei Li, Peize Li, Jiacheng Wa...</td>\n",
       "      <td>497-507</td>\n",
       "      <td>10.1007/978-3-031-43987-2_48</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>188</td>\n",
       "      <td>miccai23vol5/paper_5.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>to address the problem of fast-moving polyps, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>Dense Transformer based Enhanced Coding Networ...</td>\n",
       "      <td>Wangduo Xie, Matthew B. Blaschko</td>\n",
       "      <td>77-86</td>\n",
       "      <td>10.1007/978-3-031-43907-0_8</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>miccai23vol1/paper_58.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>meanwhile, to be suitable for many downstream ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>Dense Transformer based Enhanced Coding Networ...</td>\n",
       "      <td>Wangduo Xie, Matthew B. Blaschko</td>\n",
       "      <td>77-86</td>\n",
       "      <td>10.1007/978-3-031-43907-0_8</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>miccai23vol1/paper_58.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>we reproduce the key results on msd challenge ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>Dense Transformer based Enhanced Coding Networ...</td>\n",
       "      <td>Wangduo Xie, Matthew B. Blaschko</td>\n",
       "      <td>77-86</td>\n",
       "      <td>10.1007/978-3-031-43907-0_8</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>miccai23vol1/paper_58.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>cross validation dice score on ct tasks of msd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>Dense Transformer based Enhanced Coding Networ...</td>\n",
       "      <td>Wangduo Xie, Matthew B. Blaschko</td>\n",
       "      <td>77-86</td>\n",
       "      <td>10.1007/978-3-031-43907-0_8</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>miccai23vol1/paper_58.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>another interesting\\nresearch direction is exp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1303 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     3D Arterial Segmentation via Single 2D Project...   \n",
       "1     3D Arterial Segmentation via Single 2D Project...   \n",
       "2     3D Arterial Segmentation via Single 2D Project...   \n",
       "3     3D Arterial Segmentation via Single 2D Project...   \n",
       "4     3D Dental Mesh Segmentation Using Semantics-Ba...   \n",
       "...                                                 ...   \n",
       "1298  Democratizing Pathological Image Segmentation ...   \n",
       "1299  Dense Transformer based Enhanced Coding Networ...   \n",
       "1300  Dense Transformer based Enhanced Coding Networ...   \n",
       "1301  Dense Transformer based Enhanced Coding Networ...   \n",
       "1302  Dense Transformer based Enhanced Coding Networ...   \n",
       "\n",
       "                                                authors page_numbers  \\\n",
       "0     Alina F. Dima, Veronika A. Zimmer, Martin J. M...      141-151   \n",
       "1     Alina F. Dima, Veronika A. Zimmer, Martin J. M...      141-151   \n",
       "2     Alina F. Dima, Veronika A. Zimmer, Martin J. M...      141-151   \n",
       "3     Alina F. Dima, Veronika A. Zimmer, Martin J. M...      141-151   \n",
       "4                                     Fan Duan, Li Chen      456-465   \n",
       "...                                                 ...          ...   \n",
       "1298  Ruining Deng, Yanwei Li, Peize Li, Jiacheng Wa...      497-507   \n",
       "1299                   Wangduo Xie, Matthew B. Blaschko        77-86   \n",
       "1300                   Wangduo Xie, Matthew B. Blaschko        77-86   \n",
       "1301                   Wangduo Xie, Matthew B. Blaschko        77-86   \n",
       "1302                   Wangduo Xie, Matthew B. Blaschko        77-86   \n",
       "\n",
       "                               doi  publication_year  volume  paper_id  \\\n",
       "0     10.1007/978-3-031-43907-0_14              2023       1         1   \n",
       "1     10.1007/978-3-031-43907-0_14              2023       1         1   \n",
       "2     10.1007/978-3-031-43907-0_14              2023       1         1   \n",
       "3     10.1007/978-3-031-43907-0_14              2023       1         1   \n",
       "4     10.1007/978-3-031-43990-2_43              2023       7         2   \n",
       "...                            ...               ...     ...       ...   \n",
       "1298  10.1007/978-3-031-43987-2_48              2023       6       188   \n",
       "1299   10.1007/978-3-031-43907-0_8              2023       1       189   \n",
       "1300   10.1007/978-3-031-43907-0_8              2023       1       189   \n",
       "1301   10.1007/978-3-031-43907-0_8              2023       1       189   \n",
       "1302   10.1007/978-3-031-43907-0_8              2023       1       189   \n",
       "\n",
       "                           path  \\\n",
       "0     miccai23vol1/paper_14.pdf   \n",
       "1     miccai23vol1/paper_14.pdf   \n",
       "2     miccai23vol1/paper_14.pdf   \n",
       "3     miccai23vol1/paper_14.pdf   \n",
       "4     miccai23vol8/paper_59.pdf   \n",
       "...                         ...   \n",
       "1298   miccai23vol5/paper_5.pdf   \n",
       "1299  miccai23vol1/paper_58.pdf   \n",
       "1300  miccai23vol1/paper_58.pdf   \n",
       "1301  miccai23vol1/paper_58.pdf   \n",
       "1302  miccai23vol1/paper_58.pdf   \n",
       "\n",
       "                                              path_long  \\\n",
       "0     /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "1     /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "2     /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "3     /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "4     /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "...                                                 ...   \n",
       "1298  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "1299  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "1300  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "1301  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "1302  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "\n",
       "                               extracted_sents_keywords  \n",
       "0     compared to\\ncenterline segmentation, where th...  \n",
       "1     the cohort consists of 141 patients with pancr...  \n",
       "2     we distinguish between models selected accordi...  \n",
       "3     with the exception of the single ﬁxed viewpoin...  \n",
       "4     accurate 3d mitochondria instance segmentation...  \n",
       "...                                                 ...  \n",
       "1298  to address the problem of fast-moving polyps, ...  \n",
       "1299  meanwhile, to be suitable for many downstream ...  \n",
       "1300  we reproduce the key results on msd challenge ...  \n",
       "1301  cross validation dice score on ct tasks of msd...  \n",
       "1302  another interesting\\nresearch direction is exp...  \n",
       "\n",
       "[1303 rows x 10 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/papers_with_sents_by_keywords_metadata_2.csv'\n",
    "papers_with_sentences_df = pd.read_csv(filename)\n",
    "\n",
    "# Fill NaN values with 'None'\n",
    "papers_with_sentences_df.fillna('None', inplace=True)\n",
    "papers_with_sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange the columns to have paper_id first\n",
    "df = move_col_position_to_last(papers_with_sentences_df, 'extracted_sents_keywords')\n",
    "df = move_col_position_to_first(df, 'paper_id')\n",
    "#df.to_csv('papers_with_sents_by_keywords_metadata_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organs\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>page_numbers</th>\n",
       "      <th>doi</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>volume</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>path</th>\n",
       "      <th>path_long</th>\n",
       "      <th>extracted_sents_organs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>Alina F. Dima, Veronika A. Zimmer, Martin J. M...</td>\n",
       "      <td>141-151</td>\n",
       "      <td>10.1007/978-3-031-43907-0_14</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>miccai23vol1/paper_14.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>3d vessel segmentation is being actively inves...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>Alina F. Dima, Veronika A. Zimmer, Martin J. M...</td>\n",
       "      <td>141-151</td>\n",
       "      <td>10.1007/978-3-031-43907-0_14</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>miccai23vol1/paper_14.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>this is especially the case for 3d\\nvessel seg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>Alina F. Dima, Veronika A. Zimmer, Martin J. M...</td>\n",
       "      <td>141-151</td>\n",
       "      <td>10.1007/978-3-031-43907-0_14</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>miccai23vol1/paper_14.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>our\\ncode is available at: https://github.com/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>Alina F. Dima, Veronika A. Zimmer, Martin J. M...</td>\n",
       "      <td>141-151</td>\n",
       "      <td>10.1007/978-3-031-43907-0_14</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>miccai23vol1/paper_14.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>automatic vessel segmentation has been extensi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>Alina F. Dima, Veronika A. Zimmer, Martin J. M...</td>\n",
       "      <td>141-151</td>\n",
       "      <td>10.1007/978-3-031-43907-0_14</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>miccai23vol1/paper_14.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>[8], or more recently with deep learning [3,5,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2660</th>\n",
       "      <td>Dense Transformer based Enhanced Coding Networ...</td>\n",
       "      <td>Wangduo Xie, Matthew B. Blaschko</td>\n",
       "      <td>77-86</td>\n",
       "      <td>10.1007/978-3-031-43907-0_8</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>miccai23vol1/paper_58.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>[8] or non-contrastive [9] joint embedding met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2661</th>\n",
       "      <td>Dense Transformer based Enhanced Coding Networ...</td>\n",
       "      <td>Wangduo Xie, Matthew B. Blaschko</td>\n",
       "      <td>77-86</td>\n",
       "      <td>10.1007/978-3-031-43907-0_8</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>miccai23vol1/paper_58.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>[24]. unet’s back-\\nbone returns a feature map...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2662</th>\n",
       "      <td>Dense Transformer based Enhanced Coding Networ...</td>\n",
       "      <td>Wangduo Xie, Matthew B. Blaschko</td>\n",
       "      <td>77-86</td>\n",
       "      <td>10.1007/978-3-031-43907-0_8</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>miccai23vol1/paper_58.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>[1,3,5,15,21,27], totaling\\nmore than 6550 cts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>Dense Transformer based Enhanced Coding Networ...</td>\n",
       "      <td>Wangduo Xie, Matthew B. Blaschko</td>\n",
       "      <td>77-86</td>\n",
       "      <td>10.1007/978-3-031-43907-0_8</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>miccai23vol1/paper_58.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>4.2\\nevaluation\\nwe evaluate our method on the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2664</th>\n",
       "      <td>Dense Transformer based Enhanced Coding Networ...</td>\n",
       "      <td>Wangduo Xie, Matthew B. Blaschko</td>\n",
       "      <td>77-86</td>\n",
       "      <td>10.1007/978-3-031-43907-0_8</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>miccai23vol1/paper_58.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>liver\\nlung\\npancreas\\nhepatic vessel spleen\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2665 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     3D Arterial Segmentation via Single 2D Project...   \n",
       "1     3D Arterial Segmentation via Single 2D Project...   \n",
       "2     3D Arterial Segmentation via Single 2D Project...   \n",
       "3     3D Arterial Segmentation via Single 2D Project...   \n",
       "4     3D Arterial Segmentation via Single 2D Project...   \n",
       "...                                                 ...   \n",
       "2660  Dense Transformer based Enhanced Coding Networ...   \n",
       "2661  Dense Transformer based Enhanced Coding Networ...   \n",
       "2662  Dense Transformer based Enhanced Coding Networ...   \n",
       "2663  Dense Transformer based Enhanced Coding Networ...   \n",
       "2664  Dense Transformer based Enhanced Coding Networ...   \n",
       "\n",
       "                                                authors page_numbers  \\\n",
       "0     Alina F. Dima, Veronika A. Zimmer, Martin J. M...      141-151   \n",
       "1     Alina F. Dima, Veronika A. Zimmer, Martin J. M...      141-151   \n",
       "2     Alina F. Dima, Veronika A. Zimmer, Martin J. M...      141-151   \n",
       "3     Alina F. Dima, Veronika A. Zimmer, Martin J. M...      141-151   \n",
       "4     Alina F. Dima, Veronika A. Zimmer, Martin J. M...      141-151   \n",
       "...                                                 ...          ...   \n",
       "2660                   Wangduo Xie, Matthew B. Blaschko        77-86   \n",
       "2661                   Wangduo Xie, Matthew B. Blaschko        77-86   \n",
       "2662                   Wangduo Xie, Matthew B. Blaschko        77-86   \n",
       "2663                   Wangduo Xie, Matthew B. Blaschko        77-86   \n",
       "2664                   Wangduo Xie, Matthew B. Blaschko        77-86   \n",
       "\n",
       "                               doi  publication_year  volume  paper_id  \\\n",
       "0     10.1007/978-3-031-43907-0_14              2023       1         1   \n",
       "1     10.1007/978-3-031-43907-0_14              2023       1         1   \n",
       "2     10.1007/978-3-031-43907-0_14              2023       1         1   \n",
       "3     10.1007/978-3-031-43907-0_14              2023       1         1   \n",
       "4     10.1007/978-3-031-43907-0_14              2023       1         1   \n",
       "...                            ...               ...     ...       ...   \n",
       "2660   10.1007/978-3-031-43907-0_8              2023       1       189   \n",
       "2661   10.1007/978-3-031-43907-0_8              2023       1       189   \n",
       "2662   10.1007/978-3-031-43907-0_8              2023       1       189   \n",
       "2663   10.1007/978-3-031-43907-0_8              2023       1       189   \n",
       "2664   10.1007/978-3-031-43907-0_8              2023       1       189   \n",
       "\n",
       "                           path  \\\n",
       "0     miccai23vol1/paper_14.pdf   \n",
       "1     miccai23vol1/paper_14.pdf   \n",
       "2     miccai23vol1/paper_14.pdf   \n",
       "3     miccai23vol1/paper_14.pdf   \n",
       "4     miccai23vol1/paper_14.pdf   \n",
       "...                         ...   \n",
       "2660  miccai23vol1/paper_58.pdf   \n",
       "2661  miccai23vol1/paper_58.pdf   \n",
       "2662  miccai23vol1/paper_58.pdf   \n",
       "2663  miccai23vol1/paper_58.pdf   \n",
       "2664  miccai23vol1/paper_58.pdf   \n",
       "\n",
       "                                              path_long  \\\n",
       "0     /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "1     /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "2     /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "3     /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "4     /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "...                                                 ...   \n",
       "2660  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "2661  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "2662  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "2663  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "2664  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "\n",
       "                                 extracted_sents_organs  \n",
       "0     3d vessel segmentation is being actively inves...  \n",
       "1     this is especially the case for 3d\\nvessel seg...  \n",
       "2     our\\ncode is available at: https://github.com/...  \n",
       "3     automatic vessel segmentation has been extensi...  \n",
       "4     [8], or more recently with deep learning [3,5,...  \n",
       "...                                                 ...  \n",
       "2660  [8] or non-contrastive [9] joint embedding met...  \n",
       "2661  [24]. unet’s back-\\nbone returns a feature map...  \n",
       "2662  [1,3,5,15,21,27], totaling\\nmore than 6550 cts...  \n",
       "2663  4.2\\nevaluation\\nwe evaluate our method on the...  \n",
       "2664  liver\\nlung\\npancreas\\nhepatic vessel spleen\\n...  \n",
       "\n",
       "[2665 rows x 10 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/papers_with_sents_by_organs_metadata.csv'\n",
    "papers_with_sentences_organs_df = pd.read_csv(filename)\n",
    "\n",
    "# Fill NaN values with 'None'\n",
    "papers_with_sentences_organs_df.fillna('None', inplace=True)\n",
    "papers_with_sentences_organs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_cancer = pd.read_csv('/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/finals/finalspapers_with_sentences_metadata.csv')\n",
    "#df_cancer.drop(columns='extracted_sents_keywords', inplace=True)\n",
    "#df_cancer.to_csv(output_path + 'papers_with_sentences_cancer_metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preliminary analysis of MICCAI 2023 - Selected papers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>page_numbers</th>\n",
       "      <th>doi</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>volume</th>\n",
       "      <th>path</th>\n",
       "      <th>path_long</th>\n",
       "      <th>extracted_sents_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>Alina F. Dima, Veronika A. Zimmer, Martin J. M...</td>\n",
       "      <td>141-151</td>\n",
       "      <td>10.1007/978-3-031-43907-0_14</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>miccai23vol1/paper_14.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>compared to\\ncenterline segmentation, where th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>Alina F. Dima, Veronika A. Zimmer, Martin J. M...</td>\n",
       "      <td>141-151</td>\n",
       "      <td>10.1007/978-3-031-43907-0_14</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>miccai23vol1/paper_14.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>the cohort consists of 141 patients with pancr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>Alina F. Dima, Veronika A. Zimmer, Martin J. M...</td>\n",
       "      <td>141-151</td>\n",
       "      <td>10.1007/978-3-031-43907-0_14</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>miccai23vol1/paper_14.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>we distinguish between models selected accordi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>Alina F. Dima, Veronika A. Zimmer, Martin J. M...</td>\n",
       "      <td>141-151</td>\n",
       "      <td>10.1007/978-3-031-43907-0_14</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>miccai23vol1/paper_14.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>with the exception of the single ﬁxed viewpoin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3D Dental Mesh Segmentation Using Semantics-Ba...</td>\n",
       "      <td>Fan Duan, Li Chen</td>\n",
       "      <td>456-465</td>\n",
       "      <td>10.1007/978-3-031-43990-2_43</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>miccai23vol8/paper_59.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>accurate 3d mitochondria instance segmentation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>188</td>\n",
       "      <td>Democratizing Pathological Image Segmentation ...</td>\n",
       "      <td>Ruining Deng, Yanwei Li, Peize Li, Jiacheng Wa...</td>\n",
       "      <td>497-507</td>\n",
       "      <td>10.1007/978-3-031-43987-2_48</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>miccai23vol5/paper_5.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>to address the problem of fast-moving polyps, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>189</td>\n",
       "      <td>Dense Transformer based Enhanced Coding Networ...</td>\n",
       "      <td>Wangduo Xie, Matthew B. Blaschko</td>\n",
       "      <td>77-86</td>\n",
       "      <td>10.1007/978-3-031-43907-0_8</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>miccai23vol1/paper_58.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>meanwhile, to be suitable for many downstream ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>189</td>\n",
       "      <td>Dense Transformer based Enhanced Coding Networ...</td>\n",
       "      <td>Wangduo Xie, Matthew B. Blaschko</td>\n",
       "      <td>77-86</td>\n",
       "      <td>10.1007/978-3-031-43907-0_8</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>miccai23vol1/paper_58.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>we reproduce the key results on msd challenge ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>189</td>\n",
       "      <td>Dense Transformer based Enhanced Coding Networ...</td>\n",
       "      <td>Wangduo Xie, Matthew B. Blaschko</td>\n",
       "      <td>77-86</td>\n",
       "      <td>10.1007/978-3-031-43907-0_8</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>miccai23vol1/paper_58.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>cross validation dice score on ct tasks of msd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>189</td>\n",
       "      <td>Dense Transformer based Enhanced Coding Networ...</td>\n",
       "      <td>Wangduo Xie, Matthew B. Blaschko</td>\n",
       "      <td>77-86</td>\n",
       "      <td>10.1007/978-3-031-43907-0_8</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>miccai23vol1/paper_58.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>another interesting\\nresearch direction is exp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1303 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      paper_id                                              title  \\\n",
       "0            1  3D Arterial Segmentation via Single 2D Project...   \n",
       "1            1  3D Arterial Segmentation via Single 2D Project...   \n",
       "2            1  3D Arterial Segmentation via Single 2D Project...   \n",
       "3            1  3D Arterial Segmentation via Single 2D Project...   \n",
       "4            2  3D Dental Mesh Segmentation Using Semantics-Ba...   \n",
       "...        ...                                                ...   \n",
       "1298       188  Democratizing Pathological Image Segmentation ...   \n",
       "1299       189  Dense Transformer based Enhanced Coding Networ...   \n",
       "1300       189  Dense Transformer based Enhanced Coding Networ...   \n",
       "1301       189  Dense Transformer based Enhanced Coding Networ...   \n",
       "1302       189  Dense Transformer based Enhanced Coding Networ...   \n",
       "\n",
       "                                                authors page_numbers  \\\n",
       "0     Alina F. Dima, Veronika A. Zimmer, Martin J. M...      141-151   \n",
       "1     Alina F. Dima, Veronika A. Zimmer, Martin J. M...      141-151   \n",
       "2     Alina F. Dima, Veronika A. Zimmer, Martin J. M...      141-151   \n",
       "3     Alina F. Dima, Veronika A. Zimmer, Martin J. M...      141-151   \n",
       "4                                     Fan Duan, Li Chen      456-465   \n",
       "...                                                 ...          ...   \n",
       "1298  Ruining Deng, Yanwei Li, Peize Li, Jiacheng Wa...      497-507   \n",
       "1299                   Wangduo Xie, Matthew B. Blaschko        77-86   \n",
       "1300                   Wangduo Xie, Matthew B. Blaschko        77-86   \n",
       "1301                   Wangduo Xie, Matthew B. Blaschko        77-86   \n",
       "1302                   Wangduo Xie, Matthew B. Blaschko        77-86   \n",
       "\n",
       "                               doi  publication_year  volume  \\\n",
       "0     10.1007/978-3-031-43907-0_14              2023       1   \n",
       "1     10.1007/978-3-031-43907-0_14              2023       1   \n",
       "2     10.1007/978-3-031-43907-0_14              2023       1   \n",
       "3     10.1007/978-3-031-43907-0_14              2023       1   \n",
       "4     10.1007/978-3-031-43990-2_43              2023       7   \n",
       "...                            ...               ...     ...   \n",
       "1298  10.1007/978-3-031-43987-2_48              2023       6   \n",
       "1299   10.1007/978-3-031-43907-0_8              2023       1   \n",
       "1300   10.1007/978-3-031-43907-0_8              2023       1   \n",
       "1301   10.1007/978-3-031-43907-0_8              2023       1   \n",
       "1302   10.1007/978-3-031-43907-0_8              2023       1   \n",
       "\n",
       "                           path  \\\n",
       "0     miccai23vol1/paper_14.pdf   \n",
       "1     miccai23vol1/paper_14.pdf   \n",
       "2     miccai23vol1/paper_14.pdf   \n",
       "3     miccai23vol1/paper_14.pdf   \n",
       "4     miccai23vol8/paper_59.pdf   \n",
       "...                         ...   \n",
       "1298   miccai23vol5/paper_5.pdf   \n",
       "1299  miccai23vol1/paper_58.pdf   \n",
       "1300  miccai23vol1/paper_58.pdf   \n",
       "1301  miccai23vol1/paper_58.pdf   \n",
       "1302  miccai23vol1/paper_58.pdf   \n",
       "\n",
       "                                              path_long  \\\n",
       "0     /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "1     /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "2     /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "3     /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "4     /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "...                                                 ...   \n",
       "1298  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "1299  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "1300  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "1301  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "1302  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "\n",
       "                               extracted_sents_keywords  \n",
       "0     compared to\\ncenterline segmentation, where th...  \n",
       "1     the cohort consists of 141 patients with pancr...  \n",
       "2     we distinguish between models selected accordi...  \n",
       "3     with the exception of the single ﬁxed viewpoin...  \n",
       "4     accurate 3d mitochondria instance segmentation...  \n",
       "...                                                 ...  \n",
       "1298  to address the problem of fast-moving polyps, ...  \n",
       "1299  meanwhile, to be suitable for many downstream ...  \n",
       "1300  we reproduce the key results on msd challenge ...  \n",
       "1301  cross validation dice score on ct tasks of msd...  \n",
       "1302  another interesting\\nresearch direction is exp...  \n",
       "\n",
       "[1303 rows x 10 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataframe with extracted sentences by list of keywords\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Function to count keywords in a text\n",
    "def count_keywords(text, keywords):\n",
    "    # Counter object to count occurrences of each keyword\n",
    "    counts = Counter()\n",
    "    for keyword in keywords:\n",
    "        # Count occurrences of the keyword in the text\n",
    "        counts[keyword] = text.lower().count(keyword)\n",
    "    return counts\n",
    "\n",
    "def agg_keywords(df, col_title, keywords):\n",
    "    # Aggregate 'extracted_sentences' for each 'title' and count keywords\n",
    "    results = {}\n",
    "    for title, group in df.groupby('title'):\n",
    "        # Combine all extracted sentences into one large text block\n",
    "        aggregated_text = \" \".join(group[col_title].tolist())\n",
    "        # Count the keywords in this aggregated text\n",
    "        keyword_counts = count_keywords(aggregated_text, keywords)\n",
    "        # Store the result\n",
    "        results[title] = keyword_counts\n",
    "\n",
    "    # Convert the results dictionary to a DataFrame \n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the mapping for aggregation\n",
    "def agg_columns_to_categories(df, keyword_to_category):\n",
    "    category_to_keywords = {}\n",
    "    for keyword, category in keyword_to_category.items():\n",
    "        category_to_keywords.setdefault(category, []).append(keyword)\n",
    "\n",
    "    # Aggregate columns into categories\n",
    "    for category, keywords in category_to_keywords.items():\n",
    "        if category in df.columns:\n",
    "            # If the category already exists, add to it\n",
    "            df[category] += df[keywords].sum(axis=1)\n",
    "        else:\n",
    "            # Otherwise, create a new column for the category\n",
    "            df[category] = df[keywords].sum(axis=1)\n",
    "        # Drop the original keyword columns\n",
    "        df.drop(columns=keywords, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping of keywords to main categories\n",
    "keyword_to_category = {\n",
    "    'age'   : 'age_',\n",
    "    'gender': 'gender_',\n",
    "    'sex'   : 'gender_',\n",
    "    'female': 'gender_',\n",
    "    'women' : 'gender_',\n",
    "    'woman' : 'gender_',\n",
    "    'male'  : 'gender_',\n",
    "    'geolocation'   : 'geolocation_',\n",
    "    'geographical'  : 'geolocation_',\n",
    "    'geographic'    : 'geolocation_',\n",
    "    'country'       : 'geolocation_',\n",
    "    'countries'     : 'geolocation_',\n",
    "    'city'          : 'geolocation_',\n",
    "    'cities'        : 'geolocation_',\n",
    "    'hospital'      : 'geolocation_',\n",
    "    'hospitals'     : 'geolocation_',\n",
    "    'clinic'        : 'geolocation_',\n",
    "    'clinics'       : 'geolocation_',\n",
    "    'society'       : 'social factors',\n",
    "    'societies'     : 'social factors',\n",
    "    'etnicity'      : 'etnicity_',\n",
    "    'etnicities'    : 'etnicity_',\n",
    "    'race'          : 'etnicity_',\n",
    "    'bias'          : 'bias_',\n",
    "    'biases'        : 'bias_',\n",
    "    'unfair'        : 'fairness_',\n",
    "    'fair'          : 'fairness_',\n",
    "    'fairness'      : 'fairness_',\n",
    "    'transparency'  : 'fairness_',\n",
    "    'imbalance'     : 'fairness_',\n",
    "    'imbalanced'    : 'fairness_',\n",
    "    'balance'       : 'fairness_',\n",
    "    'balanced'      :'fairness_',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert counts to binary values\n",
    "def convert_to_binary_values(df):\n",
    "    columns_to_convert = df.columns.tolist()\n",
    "\n",
    "    # Convert to binary: 1 if the count is greater than 0, else 0\n",
    "    for column in columns_to_convert:\n",
    "        df[column] = df[column].apply(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of keywords\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for keywords in the selected papers\n",
    "keywords = ['age', 'gender', 'sex', 'women', 'woman', 'female', 'male',\n",
    "            'geolocation', 'geographical', 'geographic', 'country', 'countries', 'city', 'cities', 'hospital', 'hospitals', 'clinic', 'clinics', \n",
    "            'society', 'societies',\n",
    "            'etnicity', 'etnicities', 'race', \n",
    "            'bias', 'biases', 'fair', 'unfair', 'fairness', 'transparency',\n",
    "            'imbalance', 'imbalanced', 'balance', 'balanced']\n",
    "\n",
    "#keywords_df = pd.DataFrame(keywords, columns=['keyword'])\n",
    "#keywords_df.to_csv('list_of_keywords.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of occurrences of each keyword in the extracted sentences\n",
    "count_keywords_df = agg_keywords(df, 'extracted_sents_keywords', keywords)\n",
    "#count_keywords_df.to_csv('keyword_counts.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the keywords into categories and aggregate the counts by category\n",
    "res = agg_columns_to_categories(count_keywords_df, keyword_to_category)\n",
    "#save_to_csv(res, 'agg_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the counts to binary values for each category\n",
    "binary_df =  convert_to_binary_values(res)\n",
    "#save_to_csv(binary_df, 'agg_columns_binary_values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>sex</th>\n",
       "      <th>women</th>\n",
       "      <th>woman</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>geolocation</th>\n",
       "      <th>geographical</th>\n",
       "      <th>geographic</th>\n",
       "      <th>...</th>\n",
       "      <th>bias</th>\n",
       "      <th>biases</th>\n",
       "      <th>fair</th>\n",
       "      <th>unfair</th>\n",
       "      <th>fairness</th>\n",
       "      <th>transparency</th>\n",
       "      <th>imbalance</th>\n",
       "      <th>imbalanced</th>\n",
       "      <th>balance</th>\n",
       "      <th>balanced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3D Arterial Segmentation via Single 2D Projections and Depth Supervision in Contrast-Enhanced CT Images</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D Dental Mesh Segmentation Using Semantics-Based Feature Learning with Graph-Transformer</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D Medical Image Segmentation with Sparse Annotation via Cross-Teaching Between 3D and 2D Networks</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D Mitochondria Instance Segmentation with Spatio-Temporal Transformers</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D Teeth Reconstruction from Panoramic Radiographs Using Neural Implicit Functions</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deep Unsupervised Clustering for Conditional Identification of Subgroups Within a Digital Pathology Image Set</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepGraphDMD: Interpretable Spatio-Temporal Decomposition of Non-linear Functional Brain Network Dynamics</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSOZ: A Robust Deep Model for Joint Temporal and Spatial Seizure Onset Localization from Multichannel EEG Data</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Democratizing Pathological Image Segmentation with Lay Annotators via Molecular-Empowered Learning</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dense Transformer based Enhanced Coding Network for Unsupervised Metal Artifact Reduction</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    age  gender  sex  women  \\\n",
       "3D Arterial Segmentation via Single 2D Projecti...    0       0    0      0   \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...    0       0    0      0   \n",
       "3D Medical Image Segmentation with Sparse Annot...    0       0    0      0   \n",
       "3D Mitochondria Instance Segmentation with Spat...    1       0    0      0   \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...    1       0    0      0   \n",
       "...                                                 ...     ...  ...    ...   \n",
       "Deep Unsupervised Clustering for Conditional Id...    0       0    0      0   \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...    1       0    0      0   \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...    0       0    0      0   \n",
       "Democratizing Pathological Image Segmentation w...    0       0    0      0   \n",
       "Dense Transformer based Enhanced Coding Network...    0       0    0      0   \n",
       "\n",
       "                                                    woman  female  male  \\\n",
       "3D Arterial Segmentation via Single 2D Projecti...      0       1     2   \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...      0       0     0   \n",
       "3D Medical Image Segmentation with Sparse Annot...      0       0     0   \n",
       "3D Mitochondria Instance Segmentation with Spat...      0       1     2   \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...      0       0     0   \n",
       "...                                                   ...     ...   ...   \n",
       "Deep Unsupervised Clustering for Conditional Id...      0       0     0   \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...      0       0     0   \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...      0       0     0   \n",
       "Democratizing Pathological Image Segmentation w...      0       0     0   \n",
       "Dense Transformer based Enhanced Coding Network...      0       0     0   \n",
       "\n",
       "                                                    geolocation  geographical  \\\n",
       "3D Arterial Segmentation via Single 2D Projecti...            0             0   \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...            0             0   \n",
       "3D Medical Image Segmentation with Sparse Annot...            0             0   \n",
       "3D Mitochondria Instance Segmentation with Spat...            0             0   \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...            0             0   \n",
       "...                                                         ...           ...   \n",
       "Deep Unsupervised Clustering for Conditional Id...            0             0   \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...            0             0   \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...            0             0   \n",
       "Democratizing Pathological Image Segmentation w...            0             0   \n",
       "Dense Transformer based Enhanced Coding Network...            0             0   \n",
       "\n",
       "                                                    geographic  ...  bias  \\\n",
       "3D Arterial Segmentation via Single 2D Projecti...           0  ...     0   \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...           0  ...     0   \n",
       "3D Medical Image Segmentation with Sparse Annot...           0  ...     0   \n",
       "3D Mitochondria Instance Segmentation with Spat...           0  ...     0   \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...           0  ...     0   \n",
       "...                                                        ...  ...   ...   \n",
       "Deep Unsupervised Clustering for Conditional Id...           0  ...     6   \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...           0  ...     0   \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...           0  ...     0   \n",
       "Democratizing Pathological Image Segmentation w...           0  ...     0   \n",
       "Dense Transformer based Enhanced Coding Network...           0  ...     0   \n",
       "\n",
       "                                                    biases  fair  unfair  \\\n",
       "3D Arterial Segmentation via Single 2D Projecti...       0     2       1   \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...       0     2       0   \n",
       "3D Medical Image Segmentation with Sparse Annot...       0     1       0   \n",
       "3D Mitochondria Instance Segmentation with Spat...       0     1       0   \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...       0     0       0   \n",
       "...                                                    ...   ...     ...   \n",
       "Deep Unsupervised Clustering for Conditional Id...       0     0       0   \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...       0     0       0   \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...       0     0       0   \n",
       "Democratizing Pathological Image Segmentation w...       0     1       0   \n",
       "Dense Transformer based Enhanced Coding Network...       0     0       0   \n",
       "\n",
       "                                                    fairness  transparency  \\\n",
       "3D Arterial Segmentation via Single 2D Projecti...         0             0   \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...         0             0   \n",
       "3D Medical Image Segmentation with Sparse Annot...         0             0   \n",
       "3D Mitochondria Instance Segmentation with Spat...         0             0   \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...         0             0   \n",
       "...                                                      ...           ...   \n",
       "Deep Unsupervised Clustering for Conditional Id...         0             0   \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...         0             0   \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...         0             0   \n",
       "Democratizing Pathological Image Segmentation w...         1             0   \n",
       "Dense Transformer based Enhanced Coding Network...         0             0   \n",
       "\n",
       "                                                    imbalance  imbalanced  \\\n",
       "3D Arterial Segmentation via Single 2D Projecti...          0           0   \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...          0           0   \n",
       "3D Medical Image Segmentation with Sparse Annot...          0           0   \n",
       "3D Mitochondria Instance Segmentation with Spat...          0           0   \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...          0           0   \n",
       "...                                                       ...         ...   \n",
       "Deep Unsupervised Clustering for Conditional Id...          0           0   \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...          0           0   \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...          0           0   \n",
       "Democratizing Pathological Image Segmentation w...          0           0   \n",
       "Dense Transformer based Enhanced Coding Network...          0           0   \n",
       "\n",
       "                                                    balance  balanced  \n",
       "3D Arterial Segmentation via Single 2D Projecti...        0         0  \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...        0         0  \n",
       "3D Medical Image Segmentation with Sparse Annot...        0         0  \n",
       "3D Mitochondria Instance Segmentation with Spat...        0         0  \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...        2         2  \n",
       "...                                                     ...       ...  \n",
       "Deep Unsupervised Clustering for Conditional Id...        0         0  \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...        3         3  \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...        1         0  \n",
       "Democratizing Pathological Image Segmentation w...        0         0  \n",
       "Dense Transformer based Enhanced Coding Network...        0         0  \n",
       "\n",
       "[189 rows x 33 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_keywords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_</th>\n",
       "      <th>gender_</th>\n",
       "      <th>geolocation_</th>\n",
       "      <th>social factors</th>\n",
       "      <th>etnicity_</th>\n",
       "      <th>bias_</th>\n",
       "      <th>fairness_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3D Arterial Segmentation via Single 2D Projections and Depth Supervision in Contrast-Enhanced CT Images</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D Dental Mesh Segmentation Using Semantics-Based Feature Learning with Graph-Transformer</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D Medical Image Segmentation with Sparse Annotation via Cross-Teaching Between 3D and 2D Networks</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D Mitochondria Instance Segmentation with Spatio-Temporal Transformers</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D Teeth Reconstruction from Panoramic Radiographs Using Neural Implicit Functions</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deep Unsupervised Clustering for Conditional Identification of Subgroups Within a Digital Pathology Image Set</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepGraphDMD: Interpretable Spatio-Temporal Decomposition of Non-linear Functional Brain Network Dynamics</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSOZ: A Robust Deep Model for Joint Temporal and Spatial Seizure Onset Localization from Multichannel EEG Data</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Democratizing Pathological Image Segmentation with Lay Annotators via Molecular-Empowered Learning</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dense Transformer based Enhanced Coding Network for Unsupervised Metal Artifact Reduction</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    age_  gender_  \\\n",
       "3D Arterial Segmentation via Single 2D Projecti...     0        1   \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...     0        0   \n",
       "3D Medical Image Segmentation with Sparse Annot...     0        0   \n",
       "3D Mitochondria Instance Segmentation with Spat...     1        1   \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...     1        0   \n",
       "...                                                  ...      ...   \n",
       "Deep Unsupervised Clustering for Conditional Id...     0        0   \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...     1        0   \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...     0        0   \n",
       "Democratizing Pathological Image Segmentation w...     0        0   \n",
       "Dense Transformer based Enhanced Coding Network...     0        0   \n",
       "\n",
       "                                                    geolocation_  \\\n",
       "3D Arterial Segmentation via Single 2D Projecti...             0   \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...             0   \n",
       "3D Medical Image Segmentation with Sparse Annot...             0   \n",
       "3D Mitochondria Instance Segmentation with Spat...             1   \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...             1   \n",
       "...                                                          ...   \n",
       "Deep Unsupervised Clustering for Conditional Id...             0   \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...             1   \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...             0   \n",
       "Democratizing Pathological Image Segmentation w...             0   \n",
       "Dense Transformer based Enhanced Coding Network...             0   \n",
       "\n",
       "                                                    social factors  etnicity_  \\\n",
       "3D Arterial Segmentation via Single 2D Projecti...               0          0   \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...               0          0   \n",
       "3D Medical Image Segmentation with Sparse Annot...               0          0   \n",
       "3D Mitochondria Instance Segmentation with Spat...               0          0   \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...               0          0   \n",
       "...                                                            ...        ...   \n",
       "Deep Unsupervised Clustering for Conditional Id...               0          0   \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...               0          0   \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...               0          0   \n",
       "Democratizing Pathological Image Segmentation w...               0          0   \n",
       "Dense Transformer based Enhanced Coding Network...               0          0   \n",
       "\n",
       "                                                    bias_  fairness_  \n",
       "3D Arterial Segmentation via Single 2D Projecti...      0          1  \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...      0          1  \n",
       "3D Medical Image Segmentation with Sparse Annot...      0          1  \n",
       "3D Mitochondria Instance Segmentation with Spat...      0          1  \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...      0          1  \n",
       "...                                                   ...        ...  \n",
       "Deep Unsupervised Clustering for Conditional Id...      1          0  \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...      0          1  \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...      0          1  \n",
       "Democratizing Pathological Image Segmentation w...      0          1  \n",
       "Dense Transformer based Enhanced Coding Network...      0          0  \n",
       "\n",
       "[189 rows x 7 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_</th>\n",
       "      <th>gender_</th>\n",
       "      <th>geolocation_</th>\n",
       "      <th>social factors</th>\n",
       "      <th>etnicity_</th>\n",
       "      <th>bias_</th>\n",
       "      <th>fairness_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3D Arterial Segmentation via Single 2D Projections and Depth Supervision in Contrast-Enhanced CT Images</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D Dental Mesh Segmentation Using Semantics-Based Feature Learning with Graph-Transformer</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D Medical Image Segmentation with Sparse Annotation via Cross-Teaching Between 3D and 2D Networks</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D Mitochondria Instance Segmentation with Spatio-Temporal Transformers</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D Teeth Reconstruction from Panoramic Radiographs Using Neural Implicit Functions</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deep Unsupervised Clustering for Conditional Identification of Subgroups Within a Digital Pathology Image Set</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepGraphDMD: Interpretable Spatio-Temporal Decomposition of Non-linear Functional Brain Network Dynamics</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSOZ: A Robust Deep Model for Joint Temporal and Spatial Seizure Onset Localization from Multichannel EEG Data</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Democratizing Pathological Image Segmentation with Lay Annotators via Molecular-Empowered Learning</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dense Transformer based Enhanced Coding Network for Unsupervised Metal Artifact Reduction</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    age_  gender_  \\\n",
       "3D Arterial Segmentation via Single 2D Projecti...     0        1   \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...     0        0   \n",
       "3D Medical Image Segmentation with Sparse Annot...     0        0   \n",
       "3D Mitochondria Instance Segmentation with Spat...     1        1   \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...     1        0   \n",
       "...                                                  ...      ...   \n",
       "Deep Unsupervised Clustering for Conditional Id...     0        0   \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...     1        0   \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...     0        0   \n",
       "Democratizing Pathological Image Segmentation w...     0        0   \n",
       "Dense Transformer based Enhanced Coding Network...     0        0   \n",
       "\n",
       "                                                    geolocation_  \\\n",
       "3D Arterial Segmentation via Single 2D Projecti...             0   \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...             0   \n",
       "3D Medical Image Segmentation with Sparse Annot...             0   \n",
       "3D Mitochondria Instance Segmentation with Spat...             1   \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...             1   \n",
       "...                                                          ...   \n",
       "Deep Unsupervised Clustering for Conditional Id...             0   \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...             1   \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...             0   \n",
       "Democratizing Pathological Image Segmentation w...             0   \n",
       "Dense Transformer based Enhanced Coding Network...             0   \n",
       "\n",
       "                                                    social factors  etnicity_  \\\n",
       "3D Arterial Segmentation via Single 2D Projecti...               0          0   \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...               0          0   \n",
       "3D Medical Image Segmentation with Sparse Annot...               0          0   \n",
       "3D Mitochondria Instance Segmentation with Spat...               0          0   \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...               0          0   \n",
       "...                                                            ...        ...   \n",
       "Deep Unsupervised Clustering for Conditional Id...               0          0   \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...               0          0   \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...               0          0   \n",
       "Democratizing Pathological Image Segmentation w...               0          0   \n",
       "Dense Transformer based Enhanced Coding Network...               0          0   \n",
       "\n",
       "                                                    bias_  fairness_  \n",
       "3D Arterial Segmentation via Single 2D Projecti...      0          1  \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...      0          1  \n",
       "3D Medical Image Segmentation with Sparse Annot...      0          1  \n",
       "3D Mitochondria Instance Segmentation with Spat...      0          1  \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...      0          1  \n",
       "...                                                   ...        ...  \n",
       "Deep Unsupervised Clustering for Conditional Id...      1          0  \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...      0          1  \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...      0          1  \n",
       "Democratizing Pathological Image Segmentation w...      0          1  \n",
       "Dense Transformer based Enhanced Coding Network...      0          0  \n",
       "\n",
       "[189 rows x 7 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "2nd attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping of keywords to main categories\n",
    "keyword_to_category = {\n",
    "    'age'   : 'age_',\n",
    "    'gender': 'gender_',\n",
    "    'sex'   : 'gender_',\n",
    "    'female': 'gender_',\n",
    "    'women' : 'gender_',\n",
    "    'woman' : 'gender_',\n",
    "    'male'  : 'gender_',\n",
    "    'geolocation'   : 'geolocation_',\n",
    "    'geographical'  : 'geolocation_',\n",
    "    'geographic'    : 'geolocation_',\n",
    "    'country'       : 'geolocation_',\n",
    "    'countries'     : 'geolocation_',\n",
    "    'city'          : 'geolocation_',\n",
    "    'cities'        : 'geolocation_',\n",
    "    'hospital'      : 'geolocation_',\n",
    "    'hospitals'     : 'geolocation_',\n",
    "    'clinic'        : 'geolocation_',\n",
    "    'clinics'       : 'geolocation_',\n",
    "    'society'       : 'social factors',\n",
    "    'societies'     : 'social factors',\n",
    "    'etnicity'      : 'etnicity_',\n",
    "    'etnicities'    : 'etnicity_',\n",
    "    'race'          : 'etnicity_',\n",
    "    'bias'          : 'bias_',\n",
    "    'biases'        : 'bias_',\n",
    "    'unfair'        : 'fairness_',\n",
    "    'fair'          : 'fairness_',\n",
    "    'fairness'      : 'fairness_',\n",
    "    'transparency'  : 'fairness_',\n",
    "    'imbalance'     : 'fairness_',\n",
    "    'imbalanced'    : 'fairness_',\n",
    "    'balance'       : 'fairness_',\n",
    "    'balanced'      :'fairness_',\n",
    "    'problem'       : 'concerns',\n",
    "    'problems'      : 'concerns',\n",
    "    'issue'         : 'concerns',\n",
    "    'issues'        : 'concerns',\n",
    "    'challenge'     : 'concerns',\n",
    "    'challenges'    : 'concerns',\n",
    "    'difficulty'    : 'concerns',\n",
    "    'difficulties'  : 'concerns',\n",
    "    'critic'        : 'criticism_',\n",
    "    'critics'       : 'criticism_',\n",
    "    'criticism'     : 'criticism_',\n",
    "    'criticize'     : 'criticism_',\n",
    "    'criticized'    : 'criticism_',        \n",
    "    'criticizing'   : 'criticism_',\n",
    "    'critique'      : 'criticism_',\n",
    "    'critiques'     : 'criticism_',\n",
    "    'critiqued'     : 'criticism_',\n",
    "    'critiquing'    : 'criticism_',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant sentences from the selected papers by these keywords\n",
    "keywords = ['age', 'gender', 'sex', 'women', 'woman', 'female', 'male',\n",
    "            'geolocation', 'geographical', 'geographic', 'country', 'countries', 'city', 'cities', 'hospital', 'hospitals', 'clinic', 'clinics', \n",
    "            'society', 'societies',\n",
    "            'etnicity', 'etnicities', 'race', \n",
    "            'bias', 'biases', 'fair', 'unfair', 'fairness', 'transparency',\n",
    "            'imbalance', 'imbalanced', 'balance', 'balanced',\n",
    "            'problem', 'problems', 'issue', 'issues', 'challenge', 'challenges', 'difficulty', 'difficulties',\n",
    "            'critic', 'critics', 'criticism', 'criticize', 'criticized', 'criticizing', 'critique', 'critiques', 'critiqued', 'critiquing']\n",
    "\n",
    "\n",
    "#keywords_2_df = pd.DataFrame(keywords, columns=['keyword'])\n",
    "#keywords_2_df.to_csv('list_of_keywords_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of occurrences of each keyword in the extracted sentences\n",
    "count_keywords_2_df = agg_keywords(df, 'extracted_sents_keywords', keywords)\n",
    "count_keywords_2_df.to_csv('keyword_counts_2.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the keywords into categories and aggregate the counts by category\n",
    "res = agg_columns_to_categories(count_keywords_2_df, keyword_to_category)\n",
    "save_to_csv(res, 'agg_counts_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the counts to binary values for each category\n",
    "binary_df =  convert_to_binary_values(res)\n",
    "save_to_csv(binary_df, 'agg_columns_binary_values_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Organs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = papers_with_sentences_organs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for organs in the selected papers\n",
    "keywords = ['adrenal', 'anal', 'anusarteries', 'gi', 'tract', 'gi-tract', 'colon', 'bladder', 'bone', 'marrow', 'bronchi', 'bronchioles', \n",
    "            'bulbourethral', 'capillaries', 'cecum', 'cerebellum', 'cerebral', 'cervix', 'choroid', 'plexus', 'ciliary', 'body', 'clitoris', \n",
    "            'cochlea', 'cornea', 'cranial', 'nerves', 'duodenum', 'eardrum', 'nervous', 'system', 'epididymis', 'esophagus', 'fallopian', 'tubes', \n",
    "            'gallbladder', 'ganglia', 'heart', 'skeleton', 'hypothalamus', 'ileum', 'interstitium', 'iris', 'jejunum', 'joint', 'joints', 'kidneys', \n",
    "            'larynx', 'ligament', 'ligaments', 'liver', 'lung', 'lungs', 'lymph', 'node', 'lymphatic', 'vessel', 'glands', 'oblongata', 'mesentery', \n",
    "            'brain', 'ear', 'ossicles', 'muscles', 'nasal', 'cavity', 'olfactory', 'epithelium', 'ovaries', 'pancreas', 'parathyroid', 'parotid', 'penis', \n",
    "            'pharynx', 'pineal', 'pituitary', 'placenta', 'prostate', 'rectum', 'retina', 'sigmoid', 'skin', 'spinal', 'nerves', 'spleen', 'stomach', \n",
    "            'tissue', 'sublingual', 'submandibular', 'teeth', 'tendons', 'testes', 'thalamus', 'spinal', 'cord', 'thymus', 'thyroid', 'tongue', 'tonsils', \n",
    "            'trachea', 'transverse', 'ureter', 'urethra', 'uterus', 'vagina', 'veins', 'vulva', 'lung', 'lungs', 'pulmonary', 'respiratory', 'bronchial', \n",
    "            'bronchi', 'bronchus', 'bronchial', 'trachea', 'tracheal', 'thoracic', 'thorax', 'diaphragm', 'diaphragmatic', 'pleural', 'pleura', 'alveolar', \n",
    "            'alveoli', 'gi-tract', 'gastrointestinal', 'gastro', 'intestinal', 'digestive', 'digestion', 'stomach', 'gastric', 'intestine', 'intestines', \n",
    "            'intestinal', 'colon', 'colonic', 'rectum', 'rectal', 'anus', 'anal', 'liver', 'hepatic', 'hepatitis', 'hepatocellular', 'hepatoma', 'hepatocarcinoma',\n",
    "            'cervical', 'cervix', 'uterus', 'uterine', 'endometrial', 'ovarian', 'ovary', 'fallopian', 'tube', 'vaginal', 'gland', 'prostate gland',\n",
    "            'prostate glands','testicular', 'testis', \n",
    "            'penile', 'breast', 'breast tissue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "female = [\n",
    "    'clitoris',       \n",
    "    'cervix',        \n",
    "    'fallopian',     \n",
    "    'tubes',         \n",
    "    'uterus',        \n",
    "    'vagina',        \n",
    "    'vulva',         \n",
    "    'cervical',      \n",
    "    'uterus',        \n",
    "    'uterine',       \n",
    "    'endometrial', \n",
    "    'ovarian', \n",
    "    'ovary', \n",
    "    'fallopian tube', \n",
    "    'vaginal', \n",
    "    'vaginal gland',\n",
    "    'placenta',\n",
    "    'ureter',\n",
    "    'urethra']\n",
    " \n",
    "\n",
    "male = [\n",
    "    'prostate',      \n",
    "    'prostate gland',\n",
    "    'testes',\n",
    "    'testicular', \n",
    "    'testis', \n",
    "    'penile',\n",
    "    'penis',\n",
    "    'pineal',\n",
    "    'prostate glands']\n",
    "\n",
    "\n",
    "both_sex = [\n",
    "    'adrenal',\n",
    "    'anal',\n",
    "    'anusarteries',\n",
    "    'gi',\n",
    "    'tract',\n",
    "    'gi-tract',\n",
    "    'colon',\n",
    "    'bladder',\n",
    "    'bone',\n",
    "    'marrow',\n",
    "    'bronchi',\n",
    "    'bronchioles',\n",
    "    'bulbourethral',\n",
    "    'capillaries',\n",
    "    'cecum',\n",
    "    'cerebellum',\n",
    "    'cerebral',\n",
    "    'choroid',\n",
    "    'plexus',\n",
    "    'ciliary',\n",
    "    'body',\n",
    "    'cochlea',\n",
    "    'cornea',\n",
    "    'cranial',\n",
    "    'nerves',\n",
    "    'duodenum',\n",
    "    'eardrum',\n",
    "    'nervous',\n",
    "    'system',\n",
    "    'epididymis',\n",
    "    'esophagus',\n",
    "    'gallbladder',\n",
    "    'ganglia',\n",
    "    'heart',\n",
    "    'skeleton',\n",
    "    'hypothalamus',\n",
    "    'ileum',\n",
    "    'interstitium',\n",
    "    'iris',\n",
    "    'jejunum',\n",
    "    'joint',\n",
    "    'joints',\n",
    "    'kidneys',\n",
    "    'larynx',\n",
    "    'ligament',\n",
    "    'ligaments',\n",
    "    'liver',\n",
    "    'lung',\n",
    "    'lungs',\n",
    "    'lymph',\n",
    "    'node',\n",
    "    'lymphatic',\n",
    "    'vessel',\n",
    "    'glands',\n",
    "    'oblongata',\n",
    "    'mesentery',\n",
    "    'brain',\n",
    "    'ear',\n",
    "    'ossicles',\n",
    "    'muscles',\n",
    "    'nasal',\n",
    "    'cavity',\n",
    "    'olfactory',\n",
    "    'epithelium',\n",
    "    'pancreas',\n",
    "    'parathyroid',\n",
    "    'parotid',\n",
    "    'pharynx',\n",
    "    'pituitary',\n",
    "    'rectum',\n",
    "    'retina',\n",
    "    'sigmoid',\n",
    "    'skin',\n",
    "    'spinal',\n",
    "    'nerves',\n",
    "    'spleen',\n",
    "    'stomach',\n",
    "    'tissue',\n",
    "    'sublingual',\n",
    "    'submandibular',\n",
    "    'teeth',\n",
    "    'tendons',\n",
    "    'thalamus',\n",
    "    'spinal',\n",
    "    'cord',\n",
    "    'thymus',\n",
    "    'thyroid',\n",
    "    'tongue',\n",
    "    'tonsils',\n",
    "    'trachea',\n",
    "    'transverse',\n",
    "    'veins',\n",
    "    'vulva',\n",
    "    'lung',\n",
    "    'lungs',\n",
    "    'pulmonary',\n",
    "    'respiratory',\n",
    "    'bronchial',\n",
    "    'bronchi',\n",
    "    'bronchus',\n",
    "    'bronchial',\n",
    "    'trachea',\n",
    "    'tracheal',\n",
    "    'thoracic',\n",
    "    'thorax',\n",
    "    'diaphragm',\n",
    "    'diaphragmatic',\n",
    "    'pleural',\n",
    "    'pleura',\n",
    "    'alveolar',\n",
    "    'alveoli',\n",
    "    'gi-tract',\n",
    "    'gastrointestinal',\n",
    "    'gastro',\n",
    "    'intestinal',\n",
    "    'digestive',\n",
    "    'digestion',\n",
    "    'stomach',\n",
    "    'gastric',\n",
    "    'intestine',\n",
    "    'intestines',\n",
    "    'intestinal',\n",
    "    'colon',\n",
    "    'colonic',\n",
    "    'rectum',\n",
    "    'rectal',\n",
    "    'anus',\n",
    "    'anal',\n",
    "    'liver',\n",
    "    'hepatic',\n",
    "    'hepatitis',\n",
    "    'hepatocellular',\n",
    "    'hepatoma',\n",
    "    'hepatocarcinoma',\n",
    "    'breast',\n",
    "    'breast tissue']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of occurrences of each keyword in the extracted sentences\n",
    "count_organs_df = agg_keywords(df, 'extracted_sents_organs', keywords)\n",
    "count_organs_df\n",
    "count_organs_df.to_csv('count_organs_df.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the counts to binary values for each category\n",
    "binary_organs_df =  convert_to_binary_values(count_organs_df)\n",
    "#binary_organs_df.to_csv('agg_organs_binary_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>adrenal</th>\n",
       "      <th>anal</th>\n",
       "      <th>anusarteries</th>\n",
       "      <th>gi</th>\n",
       "      <th>tract</th>\n",
       "      <th>gi-tract</th>\n",
       "      <th>colon</th>\n",
       "      <th>bladder</th>\n",
       "      <th>bone</th>\n",
       "      <th>...</th>\n",
       "      <th>tube</th>\n",
       "      <th>vaginal</th>\n",
       "      <th>gland</th>\n",
       "      <th>prostate gland</th>\n",
       "      <th>prostate glands</th>\n",
       "      <th>testicular</th>\n",
       "      <th>testis</th>\n",
       "      <th>penile</th>\n",
       "      <th>breast</th>\n",
       "      <th>breast tissue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D Dental Mesh Segmentation Using Semantics-Ba...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3D Medical Image Segmentation with Sparse Anno...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3D Mitochondria Instance Segmentation with Spa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3D Teeth Reconstruction from Panoramic Radiogr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Deep Unsupervised Clustering for Conditional I...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>DeepGraphDMD: Interpretable Spatio-Temporal De...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>DeepSOZ: A Robust Deep Model for Joint Tempora...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Democratizing Pathological Image Segmentation ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Dense Transformer based Enhanced Coding Networ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  adrenal  anal  \\\n",
       "0    3D Arterial Segmentation via Single 2D Project...        0     0   \n",
       "1    3D Dental Mesh Segmentation Using Semantics-Ba...        0     0   \n",
       "2    3D Medical Image Segmentation with Sparse Anno...        0     0   \n",
       "3    3D Mitochondria Instance Segmentation with Spa...        0     0   \n",
       "4    3D Teeth Reconstruction from Panoramic Radiogr...        0     0   \n",
       "..                                                 ...      ...   ...   \n",
       "184  Deep Unsupervised Clustering for Conditional I...        0     0   \n",
       "185  DeepGraphDMD: Interpretable Spatio-Temporal De...        0     0   \n",
       "186  DeepSOZ: A Robust Deep Model for Joint Tempora...        0     0   \n",
       "187  Democratizing Pathological Image Segmentation ...        0     0   \n",
       "188  Dense Transformer based Enhanced Coding Networ...        0     0   \n",
       "\n",
       "     anusarteries  gi  tract  gi-tract  colon  bladder  bone  ...  tube  \\\n",
       "0               0   1      0         0      0        0     1  ...     0   \n",
       "1               0   0      0         0      0        0     0  ...     0   \n",
       "2               0   1      0         0      0        0     1  ...     0   \n",
       "3               0   1      0         0      0        0     0  ...     0   \n",
       "4               0   1      1         0      0        0     0  ...     0   \n",
       "..            ...  ..    ...       ...    ...      ...   ...  ...   ...   \n",
       "184             0   0      0         0      0        0     0  ...     0   \n",
       "185             0   1      0         0      0        0     0  ...     0   \n",
       "186             0   1      0         0      0        0     0  ...     0   \n",
       "187             0   0      0         0      1        0     0  ...     0   \n",
       "188             0   1      0         0      1        0     1  ...     0   \n",
       "\n",
       "     vaginal  gland  prostate gland  prostate glands  testicular  testis  \\\n",
       "0          0      0               0                0           0       0   \n",
       "1          0      0               0                0           0       0   \n",
       "2          0      0               0                0           0       0   \n",
       "3          0      0               0                0           0       0   \n",
       "4          0      0               0                0           0       0   \n",
       "..       ...    ...             ...              ...         ...     ...   \n",
       "184        0      0               0                0           0       0   \n",
       "185        0      0               0                0           0       0   \n",
       "186        0      0               0                0           0       0   \n",
       "187        0      0               0                0           0       0   \n",
       "188        0      0               0                0           0       0   \n",
       "\n",
       "     penile  breast  breast tissue  \n",
       "0         0       0              0  \n",
       "1         0       0              0  \n",
       "2         0       1              0  \n",
       "3         0       1              0  \n",
       "4         0       0              0  \n",
       "..      ...     ...            ...  \n",
       "184       0       0              0  \n",
       "185       0       0              0  \n",
       "186       0       0              0  \n",
       "187       0       0              0  \n",
       "188       0       0              0  \n",
       "\n",
       "[189 rows x 150 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_organs = pd.read_csv('/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/agg_organs_binary_values.csv')\n",
    "df_organs.rename(columns={'Unnamed: 0': 'title'}, inplace=True)\n",
    "df_organs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title            3D Arterial Segmentation via Single 2D Project...\n",
      "adrenal                                                          0\n",
      "anal                                                             0\n",
      "anusarteries                                                     0\n",
      "gi                                                               1\n",
      "                                       ...                        \n",
      "testicular                                                       0\n",
      "testis                                                           0\n",
      "penile                                                           0\n",
      "breast                                                           0\n",
      "breast tissue                                                    0\n",
      "Name: 0, Length: 150, dtype: object\n",
      "title            3D Teeth Reconstruction from Panoramic Radiogr...\n",
      "adrenal                                                          0\n",
      "anal                                                             0\n",
      "anusarteries                                                     0\n",
      "gi                                                               1\n",
      "                                       ...                        \n",
      "testicular                                                       0\n",
      "testis                                                           0\n",
      "penile                                                           0\n",
      "breast                                                           0\n",
      "breast tissue                                                    0\n",
      "Name: 4, Length: 150, dtype: object\n",
      "title            A Coupled-Mechanisms Modelling Framework for N...\n",
      "adrenal                                                          0\n",
      "anal                                                             0\n",
      "anusarteries                                                     0\n",
      "gi                                                               1\n",
      "                                       ...                        \n",
      "testicular                                                       0\n",
      "testis                                                           0\n",
      "penile                                                           0\n",
      "breast                                                           1\n",
      "breast tissue                                                    0\n",
      "Name: 7, Length: 150, dtype: object\n",
      "title            A Unified Deep-Learning-Based Framework for Co...\n",
      "adrenal                                                          0\n",
      "anal                                                             1\n",
      "anusarteries                                                     0\n",
      "gi                                                               1\n",
      "                                       ...                        \n",
      "testicular                                                       0\n",
      "testis                                                           0\n",
      "penile                                                           0\n",
      "breast                                                           0\n",
      "breast tissue                                                    0\n",
      "Name: 31, Length: 150, dtype: object\n",
      "title            An Interpretable and Attention-Based Method fo...\n",
      "adrenal                                                          0\n",
      "anal                                                             0\n",
      "anusarteries                                                     0\n",
      "gi                                                               1\n",
      "                                       ...                        \n",
      "testicular                                                       0\n",
      "testis                                                           0\n",
      "penile                                                           0\n",
      "breast                                                           0\n",
      "breast tissue                                                    0\n",
      "Name: 62, Length: 150, dtype: object\n",
      "title            Beyond the Snapshot: Brain Tokenized Graph Tra...\n",
      "adrenal                                                          0\n",
      "anal                                                             1\n",
      "anusarteries                                                     0\n",
      "gi                                                               1\n",
      "                                       ...                        \n",
      "testicular                                                       0\n",
      "testis                                                           0\n",
      "penile                                                           0\n",
      "breast                                                           0\n",
      "breast tissue                                                    0\n",
      "Name: 86, Length: 150, dtype: object\n",
      "title            Can Point Cloud Networks Learn Statistical Sha...\n",
      "adrenal                                                          0\n",
      "anal                                                             1\n",
      "anusarteries                                                     0\n",
      "gi                                                               1\n",
      "                                       ...                        \n",
      "testicular                                                       0\n",
      "testis                                                           0\n",
      "penile                                                           0\n",
      "breast                                                           0\n",
      "breast tissue                                                    0\n",
      "Name: 110, Length: 150, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bn/qvp15lc54w559qnxjpvy0bzw0000gn/T/ipykernel_71997/1258061832.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if row[i] != 0:\n",
      "/var/folders/bn/qvp15lc54w559qnxjpvy0bzw0000gn/T/ipykernel_71997/1258061832.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if row[i] != 0:\n",
      "/var/folders/bn/qvp15lc54w559qnxjpvy0bzw0000gn/T/ipykernel_71997/1258061832.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if row[i] != 0:\n",
      "/var/folders/bn/qvp15lc54w559qnxjpvy0bzw0000gn/T/ipykernel_71997/1258061832.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if row[i] != 0:\n",
      "/var/folders/bn/qvp15lc54w559qnxjpvy0bzw0000gn/T/ipykernel_71997/1258061832.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if row[i] != 0:\n",
      "/var/folders/bn/qvp15lc54w559qnxjpvy0bzw0000gn/T/ipykernel_71997/1258061832.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if row[i] != 0:\n",
      "/var/folders/bn/qvp15lc54w559qnxjpvy0bzw0000gn/T/ipykernel_71997/1258061832.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if row[i] != 0:\n",
      "/var/folders/bn/qvp15lc54w559qnxjpvy0bzw0000gn/T/ipykernel_71997/1258061832.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if row[i] != 0:\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 150 is out of bounds for axis 0 with size 150",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,row \u001b[38;5;129;01min\u001b[39;00m df_organs\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mprint\u001b[39m(row)\n",
      "File \u001b[0;32m~/Documents/GitHub/machine-learning-bsc-thesis-2024/venv/lib/python3.9/site-packages/pandas/core/series.py:1109\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(key) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_should_fallback_to_positional:\n\u001b[1;32m   1100\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;66;03m# GH#50617\u001b[39;00m\n\u001b[1;32m   1102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.__getitem__ treating keys as positions is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1108\u001b[0m     )\n\u001b[0;32m-> 1109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m   1112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(key)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 150 is out of bounds for axis 0 with size 150"
     ]
    }
   ],
   "source": [
    "for i,row in df_organs.iterrows():\n",
    "    if row[i] != 0:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
