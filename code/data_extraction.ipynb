{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Libraries\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "import uuid # for generating unique identifiers for each paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Setup and installation of the required packages\n",
    "#!pip install spacy nltk PyMuPDF\n",
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Important paths\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base path to folder where output files will be stored\n",
    "output_path = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/finals'\n",
    "\n",
    "# Base path to folders \n",
    "base_path = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/'\n",
    "\n",
    "# Path to the MICCAI 2023 pdfs\n",
    "pdf_path = base_path + 'miccai_2023/'\n",
    "\n",
    "# Path to the MICCAI 2023 database of all 730 papers and their metadata\n",
    "database_path = base_path + 'databases/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(df, title):\n",
    "    df.to_csv(title + '.csv', index=True)\n",
    "\n",
    "def read_csv_file(path, filename, var_name):\n",
    "    var_name = pd.read_csv(path + filename + '.csv')\n",
    "    return var_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Dataframe 1: MICCAI 2023\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>page_numbers</th>\n",
       "      <th>doi</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>volume</th>\n",
       "      <th>paper_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>Alina F. Dima, Veronika A. Zimmer, Martin J. M...</td>\n",
       "      <td>141-151</td>\n",
       "      <td>10.1007/978-3-031-43907-0_14</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D Dental Mesh Segmentation Using Semantics-Ba...</td>\n",
       "      <td>Fan Duan, Li Chen</td>\n",
       "      <td>456-465</td>\n",
       "      <td>10.1007/978-3-031-43990-2_43</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3D Medical Image Segmentation with Sparse Anno...</td>\n",
       "      <td>Heng Cai, Lei Qi, Qian Yu, Yinghuan Shi, Yang Gao</td>\n",
       "      <td>614-624</td>\n",
       "      <td>10.1007/978-3-031-43898-1_59</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3D Mitochondria Instance Segmentation with Spa...</td>\n",
       "      <td>Omkar Thawakar, Rao Muhammad Anwer, Jorma Laak...</td>\n",
       "      <td>613-623</td>\n",
       "      <td>10.1007/978-3-031-43993-3_59</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3D Teeth Reconstruction from Panoramic Radiogr...</td>\n",
       "      <td>Sihwa Park, Seongjun Kim, In-Seok Song, Seung ...</td>\n",
       "      <td>376-386</td>\n",
       "      <td>10.1007/978-3-031-43999-5_36</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>\\(\\mathrm {H^{2}}\\)GM: A Hierarchical Hypergra...</td>\n",
       "      <td>Zhibin He, Wuyang Li, Tuo Zhang, Yixuan Yuan</td>\n",
       "      <td>548-558</td>\n",
       "      <td>10.1007/978-3-031-43999-5_52</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>\\(\\textsf{GLSFormer}\\): Gated - Long, Short Se...</td>\n",
       "      <td>Nisarg A. Shah, Shameema Sikder, S. Swaroop Ve...</td>\n",
       "      <td>386-396</td>\n",
       "      <td>10.1007/978-3-031-43996-4_37</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>atTRACTive: Semi-automatic White Matter Tract ...</td>\n",
       "      <td>Robin Peretzke, Klaus H. Maier-Hein, Jonas Boh...</td>\n",
       "      <td>237-246</td>\n",
       "      <td>10.1007/978-3-031-43993-3_23</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>cOOpD: Reformulating COPD Classification on Ch...</td>\n",
       "      <td>Silvia D. Almeida, Carsten T. Lüth, Tobias Nor...</td>\n",
       "      <td>33-43</td>\n",
       "      <td>10.1007/978-3-031-43904-9_4</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>vox2vec: A Framework for Self-supervised Contr...</td>\n",
       "      <td>Mikhail Goncharov, Vera Soboleva, Anvar Kurmuk...</td>\n",
       "      <td>605-614</td>\n",
       "      <td>10.1007/978-3-031-43907-0_58</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>730 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    3D Arterial Segmentation via Single 2D Project...   \n",
       "1    3D Dental Mesh Segmentation Using Semantics-Ba...   \n",
       "2    3D Medical Image Segmentation with Sparse Anno...   \n",
       "3    3D Mitochondria Instance Segmentation with Spa...   \n",
       "4    3D Teeth Reconstruction from Panoramic Radiogr...   \n",
       "..                                                 ...   \n",
       "725  \\(\\mathrm {H^{2}}\\)GM: A Hierarchical Hypergra...   \n",
       "726  \\(\\textsf{GLSFormer}\\): Gated - Long, Short Se...   \n",
       "727  atTRACTive: Semi-automatic White Matter Tract ...   \n",
       "728  cOOpD: Reformulating COPD Classification on Ch...   \n",
       "729  vox2vec: A Framework for Self-supervised Contr...   \n",
       "\n",
       "                                               authors page_numbers  \\\n",
       "0    Alina F. Dima, Veronika A. Zimmer, Martin J. M...      141-151   \n",
       "1                                    Fan Duan, Li Chen      456-465   \n",
       "2    Heng Cai, Lei Qi, Qian Yu, Yinghuan Shi, Yang Gao      614-624   \n",
       "3    Omkar Thawakar, Rao Muhammad Anwer, Jorma Laak...      613-623   \n",
       "4    Sihwa Park, Seongjun Kim, In-Seok Song, Seung ...      376-386   \n",
       "..                                                 ...          ...   \n",
       "725       Zhibin He, Wuyang Li, Tuo Zhang, Yixuan Yuan      548-558   \n",
       "726  Nisarg A. Shah, Shameema Sikder, S. Swaroop Ve...      386-396   \n",
       "727  Robin Peretzke, Klaus H. Maier-Hein, Jonas Boh...      237-246   \n",
       "728  Silvia D. Almeida, Carsten T. Lüth, Tobias Nor...        33-43   \n",
       "729  Mikhail Goncharov, Vera Soboleva, Anvar Kurmuk...      605-614   \n",
       "\n",
       "                              doi  publication_year  volume  paper_id  \n",
       "0    10.1007/978-3-031-43907-0_14              2023       1         1  \n",
       "1    10.1007/978-3-031-43990-2_43              2023       7         2  \n",
       "2    10.1007/978-3-031-43898-1_59              2023       3         3  \n",
       "3    10.1007/978-3-031-43993-3_59              2023       8         4  \n",
       "4    10.1007/978-3-031-43999-5_36              2023      10         5  \n",
       "..                            ...               ...     ...       ...  \n",
       "725  10.1007/978-3-031-43999-5_52              2023      10       726  \n",
       "726  10.1007/978-3-031-43996-4_37              2023       9       727  \n",
       "727  10.1007/978-3-031-43993-3_23              2023       8       728  \n",
       "728   10.1007/978-3-031-43904-9_4              2023       5       729  \n",
       "729  10.1007/978-3-031-43907-0_58              2023       1       730  \n",
       "\n",
       "[730 rows x 7 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the database of all MICCAI 2023 papers\n",
    "#df_miccai = pd.read_csv(database_path +'updated_database_miccai_2023.csv', index_col=[0], header=[0], encoding='utf-8')\n",
    "\n",
    "# Refine the database by adding a unique identifier for each paper\n",
    "#df_miccai.sort_values(by='Title', inplace=True)\n",
    "#df_miccai.reset_index(drop=True, inplace=True)\n",
    "#df_miccai['paper_id'] = range(1, len(df_miccai) + 1)\n",
    "\n",
    "# Save the dataframe to a csv file\n",
    "#df_miccai.to_csv(database_path + 'updated_df_miccai.csv', index=True)\n",
    "filename = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/databases/updated_df_miccai.csv'\n",
    "df_miccai = pd.read_csv(filename, index_col=[0], header=[0], encoding='utf-8')\n",
    "df_miccai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 730 entries, 0 to 730\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   Title                730 non-null    object\n",
      " 1   Authors              730 non-null    object\n",
      " 2   Page numbers         730 non-null    object\n",
      " 3   DOI                  730 non-null    object\n",
      " 4   Year of publication  730 non-null    int64 \n",
      " 5   Part of publication  730 non-null    int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 39.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_miccai.info()\n",
    "\n",
    "#731 entries, 0 to 730 \n",
    "#6 columns in total\n",
    "#title, authors, page numbers, doi, year of publication, part of publication\n",
    "#dtype: int64(2), object(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a total of 730 papers in MICCAI 2023. However, the dataframe contains 731. Examining the dataframe, \n",
    "I will first look into the number of papers by publication (Part of Publication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers in Publication 1: 73\n",
      "Number of papers in Publication 2: 73\n",
      "Number of papers in Publication 3: 72\n",
      "Number of papers in Publication 4: 75\n",
      "Number of papers in Publication 5: 76\n",
      "Number of papers in Publication 6: 77\n",
      "Number of papers in Publication 7: 75\n",
      "Number of papers in Publication 8: 65\n",
      "Number of papers in Publication 9: 70\n",
      "Number of papers in Publication 10: 74\n",
      "Total number of papers: 730\n"
     ]
    }
   ],
   "source": [
    "# count the number of papers for each publication. There is 10 publications in total\n",
    "\n",
    "print('Number of papers in Publication 1:', df_miccai['Part of publication'].value_counts()[1]) #73\n",
    "print('Number of papers in Publication 2:', df_miccai['Part of publication'].value_counts()[2]) #73\n",
    "print('Number of papers in Publication 3:', df_miccai['Part of publication'].value_counts()[3]) #72\n",
    "print('Number of papers in Publication 4:', df_miccai['Part of publication'].value_counts()[4]) #75\n",
    "print('Number of papers in Publication 5:', df_miccai['Part of publication'].value_counts()[5]) #76\n",
    "print('Number of papers in Publication 6:', df_miccai['Part of publication'].value_counts()[6]) #77\n",
    "print('Number of papers in Publication 7:', df_miccai['Part of publication'].value_counts()[7]) #75\n",
    "print('Number of papers in Publication 8:', df_miccai['Part of publication'].value_counts()[8]) #65\n",
    "print('Number of papers in Publication 9:', df_miccai['Part of publication'].value_counts()[9]) #70\n",
    "print('Number of papers in Publication 10:', df_miccai['Part of publication'].value_counts()[10]) #74\n",
    "\n",
    "# count the total number of papers in the dataframe\n",
    "print('Total number of papers:', df_miccai['Part of publication'].value_counts().sum()) #730"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# **Selecting a scope of papers from MICCAI 2023**\n",
    "***\n",
    "***\n",
    "\n",
    "**Scope criteria:** Selecting papers, that researched within the field of cancer-related illnesses by searching for cancer-related keywords in the text of each research paper. The text is defined from the start of Abstraction ending with the last line of Conclusion, exluding the Title of the paper, the authors and affiliations, the Acknowlegdement and the References. \n",
    "\n",
    "Cancer-related keywords could be words such as 'cancer', 'tumor' and/or 'tumours'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract papers that contain the word 'cancer' in the text\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted titles from 189 selected papers.\n",
      "With the keyword(s) being ['cancer'], 189 papers were selected as relevant to cancer research.\n"
     ]
    }
   ],
   "source": [
    "# Function to extract the full text from the PDF\n",
    "def extract_text(pdf_path):\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        full_text = \"\"\n",
    "        for page in doc:\n",
    "            full_text += page.get_text()\n",
    "    return full_text\n",
    "\n",
    "# Function to find if any of the keywords appear in the section between Abstract and Conclusion\n",
    "def find_keywords_section(full_text, keywords):\n",
    "     # Regular expressions to find the end of the affiliations section\n",
    "    affiliations_end = re.search(r'\\d{1,2}\\s+(?:\\w+\\.)+@\\w+\\.\\w{2,}', full_text)\n",
    "    \n",
    "    # Start searching from the end of affiliations if found, otherwise from the start of the text\n",
    "    start_idx = affiliations_end.end() if affiliations_end else 0\n",
    "    \n",
    "    # Look for the Abstract and Conclusion sections\n",
    "    abstract_idx = full_text.lower().find(\"abstract\", start_idx)\n",
    "    conclusion_idx = full_text.lower().rfind(\"conclusion\", abstract_idx)\n",
    "    acknowledgements_idx = full_text.lower().find(\"acknowledgements\", conclusion_idx)\n",
    "    \n",
    "    # Adjust the end index to stop at Acknowledgements if it exists, otherwise use Conclusion index\n",
    "    end_search_idx = acknowledgements_idx if acknowledgements_idx != -1 else conclusion_idx\n",
    "    \n",
    "    # If neither Abstract nor Conclusion is found, search the entire text\n",
    "    if abstract_idx == -1 and conclusion_idx == -1:\n",
    "        searchable_text = full_text[start_idx:]\n",
    "    else:\n",
    "        # Search from Abstract to Conclusion or Acknowledgements\n",
    "        searchable_text = full_text[abstract_idx:end_search_idx].lower()\n",
    "    \n",
    "    # Search for each keyword within the determined section, stop at first match\n",
    "    for keyword in keywords:\n",
    "        if keyword.lower() in searchable_text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Function to extract the title from the PDF\n",
    "def extract_title(pdf_path):\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        first_page_text = doc[0].get_text(\"text\")\n",
    "        \n",
    "        # Regular expression to find the start of affiliations or author names\n",
    "        # Looks for sequences in author lists or affiliations, such as numbers and parentheses\n",
    "        author_or_affiliations_start = re.search(r'\\b[A-Z][a-z]+ [A-Z]\\.|\\b[A-Z][a-z]+\\s[A-Z][a-z]+[1-9]', first_page_text)\n",
    "\n",
    "        title = \"\"\n",
    "        if author_or_affiliations_start:\n",
    "            # Extract text up to the start of the author list or affiliations as potential title text\n",
    "            potential_title_text = first_page_text[:author_or_affiliations_start.start()].strip()\n",
    "            title_lines = potential_title_text.split('\\n')\n",
    "            \n",
    "            # The title is expected to be a continuous block of text at the top of the page,\n",
    "            # possibly after a journal header or similar: look for a large continuous block of text.\n",
    "            for line in reversed(title_lines):\n",
    "                if line.strip():  \n",
    "                    # Prepend to keep the title in the correct order\n",
    "                    title = line + \" \" + title\n",
    "                else:\n",
    "                    # An empty line might indicate the end of the title block\n",
    "                    break\n",
    "        else:\n",
    "            # If no author list or affiliation section is identified, use the first non-empty line\n",
    "            for line in first_page_text.split('\\n'):\n",
    "                if line.strip():\n",
    "                    title = line\n",
    "                    break\n",
    "\n",
    "        title = title.strip()  # Clean up whitespace\n",
    "        return title\n",
    "\n",
    "selected_papers = []\n",
    "titles = []\n",
    "\n",
    "# List of keywords to search for\n",
    "keywords = [\"cancer\"]\n",
    "\n",
    "# Iterate over each volume and search for keywords\n",
    "for i in range(1, 11):  # Volumes 1 to 10\n",
    "    folder_name = f\"miccai23vol{i}\"\n",
    "    folder_path = os.path.join(pdf_path, folder_name)\n",
    "    \n",
    "    for pdf in os.listdir(folder_path):\n",
    "        if pdf.endswith(\".pdf\"):\n",
    "            pdf_path_ = os.path.join(folder_path, pdf)\n",
    "            full_text = extract_text(pdf_path_)\n",
    "            if find_keywords_section(full_text, keywords):\n",
    "                selected_papers.append(os.path.join(folder_name, pdf))\n",
    "\n",
    "# Extract titles from selected papers\n",
    "for paper_path in selected_papers:\n",
    "    full_paper_path = os.path.join(pdf_path, paper_path)\n",
    "    title = extract_title(full_paper_path)\n",
    "    titles.append(title)\n",
    "\n",
    "print(f\"Extracted titles from {len(titles)} selected papers.\")\n",
    "print(f\"With the keyword(s) being {keywords}, {len(selected_papers)} papers were selected as relevant to cancer research.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the selected papers into a dataframe with their related paths\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the selected papers and their paths to a CSV file\n",
    "selected_papers_df = pd.DataFrame({\"path\": selected_papers, \"title\": titles})\n",
    "\n",
    "# Refine the selection of papers by adding a unique identifier for each paper\n",
    "# This will be useful for tracking papers in the pipeline\n",
    "filename = 'selected_papers_paperid'\n",
    "\n",
    "# Rename the columns to lowercase\n",
    "selected_papers_df.rename(columns={'Title': 'title', 'Path': 'path'}, inplace=True)\n",
    "\n",
    "# Sort the dataframe by title\n",
    "selected_papers_df.sort_values(by='title', inplace=True)\n",
    "\n",
    "# Reset the index\n",
    "selected_papers_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Add a unique identifier for each paper\n",
    "selected_papers_df['paper_id'] = range(1, len(selected_papers_df) + 1)\n",
    "\n",
    "# Save the dataframe to a CSV file for later use in the pipeline. columns: path, title, paper_id\n",
    "selected_papers_df.to_csv(filename +'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the list of complete paths\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_29.pdf'],\n",
       " ['/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_14.pdf'],\n",
       " ['/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_11.pdf'],\n",
       " ['/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_58.pdf'],\n",
       " ['/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_64.pdf']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store the complete paths of the selected papers in a list for later use in the pipeline\n",
    "selected_papers_paths = []\n",
    "for i in range(0, len(selected_papers)):  # Volumes 1 to 10\n",
    "    selected_papers_paths.append([base_path + 'miccai_2023/' + selected_papers[i]])\n",
    "\n",
    "# Check if the total number of paths is equal to the number of selected papers\n",
    "len(selected_papers_paths)\n",
    "selected_papers_paths[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for keyword searching and sentence extractions\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# check text for keywords\n",
    " # Function to extract the full text from the PDF\n",
    "def extract_text(pdf_path):\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        full_text = \"\"\n",
    "        for page in doc:\n",
    "            full_text += page.get_text()\n",
    "            # Regular expressions to find the end of the affiliations section\n",
    "            affiliations_end = re.search(r'\\d{1,2}\\s+(?:\\w+\\.)+@\\w+\\.\\w{2,}', full_text)\n",
    "            \n",
    "            # Start searching from the end of affiliations if found, otherwise from the start of the text\n",
    "            start_idx = affiliations_end.end() if affiliations_end else 0\n",
    "            \n",
    "            # Look for the Abstract and Conclusion sections\n",
    "            abstract_idx = full_text.lower().find(\"abstract\", start_idx)\n",
    "            conclusion_idx = full_text.lower().rfind(\"conclusion\", abstract_idx)\n",
    "            acknowledgements_idx = full_text.lower().find(\"acknowledgements\", conclusion_idx)\n",
    "            \n",
    "            # Adjust the end index to stop at Acknowledgements if it exists, otherwise use Conclusion index\n",
    "            end_search_idx = acknowledgements_idx if acknowledgements_idx != -1 else conclusion_idx\n",
    "            \n",
    "            # If neither Abstract nor Conclusion is found, search the entire text\n",
    "            if abstract_idx == -1 and conclusion_idx == -1:\n",
    "                searchable_text = full_text[start_idx:]\n",
    "            else:\n",
    "                # Search from Abstract to Conclusion or Acknowledgements\n",
    "                searchable_text = full_text[abstract_idx:end_search_idx].lower()          \n",
    "        \n",
    "    return searchable_text\n",
    "\n",
    "def extract_relevant_sentences(text, keywords):\n",
    "    relevant_sentences = []\n",
    "    doc = nlp(text)\n",
    "    # Regex pattern that matches whole words from the keywords list, case insensitive\n",
    "    pattern = r'\\b(' + '|'.join(re.escape(keyword) for keyword in keywords) + r')\\b'\n",
    "    for sent in doc.sents:\n",
    "        if re.search(pattern, sent.text, re.IGNORECASE):\n",
    "            relevant_sentences.append(sent.text.strip())\n",
    "    return relevant_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to hold the extracted info\n",
    "def extract_sents_by_keywords(list_of_pdf_paths, keywords, col_title):\n",
    "    extracted_sents = {}\n",
    "\n",
    "    for pdf_path in list_of_pdf_paths:\n",
    "        path = pdf_path[0]  # pdf_path is a list with the first element being the file path\n",
    "        text = extract_text(path)\n",
    "        relevant_sentences = extract_relevant_sentences(text, keywords)\n",
    "        \n",
    "        # If no relevant sentences were extracted, include the paper with extracted_sentence set to None\n",
    "        if not relevant_sentences:\n",
    "            extracted_sents[path] = [None] # Probably better to change this to 0\n",
    "        else:\n",
    "            extracted_sents[path] = relevant_sentences\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    rows = []\n",
    "    for paper_id, sentences in extracted_sents.items():\n",
    "        if sentences == 0:  # Check if the list contains only None, indicating no sentences were extracted\n",
    "            rows.append({'paper_id': paper_id, col_title: None})\n",
    "        else:\n",
    "            for sentence in sentences:\n",
    "                rows.append({'paper_id': paper_id, col_title: sentence})\n",
    "\n",
    "    extracted_sents_df = pd.DataFrame(rows)\n",
    "    return extracted_sents_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence extraction\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract sentences by keyword = cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for 'cancer' in text for all 730 papers\n",
    "# Check procedure to see if the selected paper contains the word 'cancer'\n",
    "keywords = [\"cancer\"]\n",
    "\n",
    "# Extract sentences by cancer\n",
    "sents_by_cancer = extract_sents_by_keywords(selected_papers_paths, keywords, col_title='extracted_sent_cancer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "#csv_filename = 'extracted_sent_cancer.csv'\n",
    "#sents_by_cancer.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract sentences by list of keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant sentences from the selected papers by these keywords\n",
    "keywords = ['age', 'gender', 'sex', 'women', 'woman', 'female', 'male',\n",
    "            'geolocation', 'geographical', 'geographic', 'country', 'countries', 'city', 'cities', 'hospital', 'hospitals', 'clinic', 'clinics', \n",
    "            'society', 'societies',\n",
    "            'etnicity', 'etnicities', 'race', \n",
    "            'bias', 'biases', 'fair', 'unfair', 'fairness', 'transparency',\n",
    "            'imbalance', 'imbalanced', 'balance', 'balanced']\n",
    "\n",
    "# Extract sentences by keywords\n",
    "sents_by_keywords = extract_sents_by_keywords(selected_papers_paths, keywords, col_title='extracted_sents_keywords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "#csv_filename = 'extracted_sents_keywords.csv'\n",
    "#sents_by_keywords.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV files with extracted sentences\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from CSV\n",
    "f_name_keywords = 'extracted_sents_keywords'\n",
    "f_name_cancer = 'extracted_sents_cancer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refine the dataframe for extracted sentences by the list of keywords\n",
    "f_name = f_name_keywords\n",
    "file_path = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/finals/' + f_name + '.csv'\n",
    "extracted_sents = pd.read_csv(file_path)\n",
    "\n",
    "# Fill NaN values with 'None'\n",
    "extracted_sents.fillna('None', inplace=True)\n",
    "\n",
    "# Refine the paper_id column to only include part of the pdf path \n",
    "extracted_sents['path'] = extracted_sents['paper_id'].str.split('/').apply(lambda x: '/'.join(x[-2:]))\n",
    "extracted_sents.rename(columns={'paper_id': 'path_long'}, inplace=True)\n",
    "\n",
    "# Save to CSV file for later use in the pipeline. columns: complete path, title, path\n",
    "# extracted_sents.to_csv('extracted_sents_keywords_refined.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge selected papers with metadata from the complete list of MICCAI 2023 papers\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge MICCAI 2023 database with the selected papers to get the metadata \n",
    "#papers = pd.merge(df_miccai, selected_papers_df, on='paper_id', how='inner').drop(columns=['title_y']).rename(columns={'title_x': 'title'})\n",
    "#papers.to_csv('papers.csv', index=False)\n",
    "\n",
    "# Merge the papers with the extracted sentences by keywords\n",
    "#pd.merge(papers, extracted_sents, on='path', how='inner').to_csv('papers_with_sents_by_keywords_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final dataframe with extracted sentences by the list of keywords and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>page_numbers</th>\n",
       "      <th>doi</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>volume</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>path</th>\n",
       "      <th>path_long</th>\n",
       "      <th>extracted_sents_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>Alina F. Dima, Veronika A. Zimmer, Martin J. M...</td>\n",
       "      <td>141-151</td>\n",
       "      <td>10.1007/978-3-031-43907-0_14</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>miccai23vol1/paper_14.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>the cohort consists of 141 patients with pancr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>Alina F. Dima, Veronika A. Zimmer, Martin J. M...</td>\n",
       "      <td>141-151</td>\n",
       "      <td>10.1007/978-3-031-43907-0_14</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>miccai23vol1/paper_14.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>we distinguish between models selected accordi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3D Dental Mesh Segmentation Using Semantics-Ba...</td>\n",
       "      <td>Fan Duan, Li Chen</td>\n",
       "      <td>456-465</td>\n",
       "      <td>10.1007/978-3-031-43990-2_43</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>miccai23vol8/paper_59.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>during training\\nof mitoem, for the fair compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3D Dental Mesh Segmentation Using Semantics-Ba...</td>\n",
       "      <td>Fan Duan, Li Chen</td>\n",
       "      <td>456-465</td>\n",
       "      <td>10.1007/978-3-031-43990-2_43</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>miccai23vol8/paper_59.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>for fair comparison with previous\\nworks, we u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3D Medical Image Segmentation with Sparse Anno...</td>\n",
       "      <td>Heng Cai, Lei Qi, Qian Yu, Yinghuan Shi, Yang Gao</td>\n",
       "      <td>614-624</td>\n",
       "      <td>10.1007/978-3-031-43898-1_59</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>miccai23vol2/paper_46.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>video\\nresnet-50 40.0 70.3\\n43.3\\nthe previous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>DeepGraphDMD: Interpretable Spatio-Temporal De...</td>\n",
       "      <td>Md Asadullah Turja, Martin Styner, Guorong Wu</td>\n",
       "      <td>358-368</td>\n",
       "      <td>10.1007/978-3-031-43993-3_35</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>186</td>\n",
       "      <td>miccai23vol1/paper_22.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>for d2\\nhisto, which has fewer patients than t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>DeepGraphDMD: Interpretable Spatio-Temporal De...</td>\n",
       "      <td>Md Asadullah Turja, Martin Styner, Guorong Wu</td>\n",
       "      <td>358-368</td>\n",
       "      <td>10.1007/978-3-031-43993-3_35</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>186</td>\n",
       "      <td>miccai23vol1/paper_22.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>the method depth-aware manages to correctly en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>DeepSOZ: A Robust Deep Model for Joint Tempora...</td>\n",
       "      <td>Deeksha M. Shama, Jiasen Jing, Archana Venkata...</td>\n",
       "      <td>184-194</td>\n",
       "      <td>10.1007/978-3-031-43993-3_18</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>187</td>\n",
       "      <td>miccai23vol10/paper_66.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>by grid search on the\\nvalidation set, we sele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>Democratizing Pathological Image Segmentation ...</td>\n",
       "      <td>Ruining Deng, Yanwei Li, Peize Li, Jiacheng Wa...</td>\n",
       "      <td>497-507</td>\n",
       "      <td>10.1007/978-3-031-43987-2_48</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>188</td>\n",
       "      <td>miccai23vol5/paper_5.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>for the fairness of the experiments, we keep t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>Dense Transformer based Enhanced Coding Networ...</td>\n",
       "      <td>Wangduo Xie, Matthew B. Blaschko</td>\n",
       "      <td>77-86</td>\n",
       "      <td>10.1007/978-3-031-43907-0_8</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>miccai23vol1/paper_58.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>661 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    3D Arterial Segmentation via Single 2D Project...   \n",
       "1    3D Arterial Segmentation via Single 2D Project...   \n",
       "2    3D Dental Mesh Segmentation Using Semantics-Ba...   \n",
       "3    3D Dental Mesh Segmentation Using Semantics-Ba...   \n",
       "4    3D Medical Image Segmentation with Sparse Anno...   \n",
       "..                                                 ...   \n",
       "656  DeepGraphDMD: Interpretable Spatio-Temporal De...   \n",
       "657  DeepGraphDMD: Interpretable Spatio-Temporal De...   \n",
       "658  DeepSOZ: A Robust Deep Model for Joint Tempora...   \n",
       "659  Democratizing Pathological Image Segmentation ...   \n",
       "660  Dense Transformer based Enhanced Coding Networ...   \n",
       "\n",
       "                                               authors page_numbers  \\\n",
       "0    Alina F. Dima, Veronika A. Zimmer, Martin J. M...      141-151   \n",
       "1    Alina F. Dima, Veronika A. Zimmer, Martin J. M...      141-151   \n",
       "2                                    Fan Duan, Li Chen      456-465   \n",
       "3                                    Fan Duan, Li Chen      456-465   \n",
       "4    Heng Cai, Lei Qi, Qian Yu, Yinghuan Shi, Yang Gao      614-624   \n",
       "..                                                 ...          ...   \n",
       "656      Md Asadullah Turja, Martin Styner, Guorong Wu      358-368   \n",
       "657      Md Asadullah Turja, Martin Styner, Guorong Wu      358-368   \n",
       "658  Deeksha M. Shama, Jiasen Jing, Archana Venkata...      184-194   \n",
       "659  Ruining Deng, Yanwei Li, Peize Li, Jiacheng Wa...      497-507   \n",
       "660                   Wangduo Xie, Matthew B. Blaschko        77-86   \n",
       "\n",
       "                              doi  publication_year  volume  paper_id  \\\n",
       "0    10.1007/978-3-031-43907-0_14              2023       1         1   \n",
       "1    10.1007/978-3-031-43907-0_14              2023       1         1   \n",
       "2    10.1007/978-3-031-43990-2_43              2023       7         2   \n",
       "3    10.1007/978-3-031-43990-2_43              2023       7         2   \n",
       "4    10.1007/978-3-031-43898-1_59              2023       3         3   \n",
       "..                            ...               ...     ...       ...   \n",
       "656  10.1007/978-3-031-43993-3_35              2023       8       186   \n",
       "657  10.1007/978-3-031-43993-3_35              2023       8       186   \n",
       "658  10.1007/978-3-031-43993-3_18              2023       8       187   \n",
       "659  10.1007/978-3-031-43987-2_48              2023       6       188   \n",
       "660   10.1007/978-3-031-43907-0_8              2023       1       189   \n",
       "\n",
       "                           path  \\\n",
       "0     miccai23vol1/paper_14.pdf   \n",
       "1     miccai23vol1/paper_14.pdf   \n",
       "2     miccai23vol8/paper_59.pdf   \n",
       "3     miccai23vol8/paper_59.pdf   \n",
       "4     miccai23vol2/paper_46.pdf   \n",
       "..                          ...   \n",
       "656   miccai23vol1/paper_22.pdf   \n",
       "657   miccai23vol1/paper_22.pdf   \n",
       "658  miccai23vol10/paper_66.pdf   \n",
       "659    miccai23vol5/paper_5.pdf   \n",
       "660   miccai23vol1/paper_58.pdf   \n",
       "\n",
       "                                             path_long  \\\n",
       "0    /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "1    /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "2    /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "3    /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "4    /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "..                                                 ...   \n",
       "656  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "657  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "658  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "659  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "660  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "\n",
       "                              extracted_sents_keywords  \n",
       "0    the cohort consists of 141 patients with pancr...  \n",
       "1    we distinguish between models selected accordi...  \n",
       "2    during training\\nof mitoem, for the fair compa...  \n",
       "3    for fair comparison with previous\\nworks, we u...  \n",
       "4    video\\nresnet-50 40.0 70.3\\n43.3\\nthe previous...  \n",
       "..                                                 ...  \n",
       "656  for d2\\nhisto, which has fewer patients than t...  \n",
       "657  the method depth-aware manages to correctly en...  \n",
       "658  by grid search on the\\nvalidation set, we sele...  \n",
       "659  for the fairness of the experiments, we keep t...  \n",
       "660                                               None  \n",
       "\n",
       "[661 rows x 10 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/papers_with_sents_by_keywords_metadata.csv'\n",
    "papers_with_sentences_df = pd.read_csv(filename)\n",
    "\n",
    "# Fill NaN values with 'None'\n",
    "papers_with_sentences_df.fillna('None', inplace=True)\n",
    "papers_with_sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_col_position_to_first(df, col_name):\n",
    "    # Column to move to the first position\n",
    "    column_to_move = col_name\n",
    "\n",
    "    # Create a new list of column names with the specified column first\n",
    "    new_columns = [column_to_move] + [col for col in df.columns if col != column_to_move]\n",
    "\n",
    "    # Reindex the DataFrame with the new column order\n",
    "    df = df[new_columns]\n",
    "    return df\n",
    "\n",
    "def move_col_position_to_last(df, col_name):\n",
    "    # Column to move to the first position\n",
    "    column_to_move = col_name\n",
    "\n",
    "    # Create a new list of column names with the specified column first\n",
    "    new_columns = [column_to_move] + [col for col in df.columns if col != column_to_move]\n",
    "\n",
    "    # Create a new list of column names with the specified column last\n",
    "    new_columns = [col for col in df.columns if col != column_to_move] + [column_to_move] \n",
    "\n",
    "    # Reindex the DataFrame with the new column order\n",
    "    df = df[new_columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange the columns to have paper_id first\n",
    "df = move_col_position_to_last(papers_with_sentences_df, 'extracted_sents_keywords')\n",
    "df = move_col_position_to_first(df, 'paper_id')\n",
    "#df.to_csv('papers_with_sents_by_keywords_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_cancer = pd.read_csv('/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/finals/finalspapers_with_sentences_metadata.csv')\n",
    "#df_cancer.drop(columns='extracted_sents_keywords', inplace=True)\n",
    "#df_cancer.to_csv(output_path + 'papers_with_sentences_cancer_metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preliminary analysis of MICCAI 2023 - Selected papers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>page_numbers</th>\n",
       "      <th>doi</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>volume</th>\n",
       "      <th>path</th>\n",
       "      <th>path_long</th>\n",
       "      <th>extracted_sents_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>Alina F. Dima, Veronika A. Zimmer, Martin J. M...</td>\n",
       "      <td>141-151</td>\n",
       "      <td>10.1007/978-3-031-43907-0_14</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>miccai23vol1/paper_14.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>the cohort consists of 141 patients with pancr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>Alina F. Dima, Veronika A. Zimmer, Martin J. M...</td>\n",
       "      <td>141-151</td>\n",
       "      <td>10.1007/978-3-031-43907-0_14</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>miccai23vol1/paper_14.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>we distinguish between models selected accordi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3D Dental Mesh Segmentation Using Semantics-Ba...</td>\n",
       "      <td>Fan Duan, Li Chen</td>\n",
       "      <td>456-465</td>\n",
       "      <td>10.1007/978-3-031-43990-2_43</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>miccai23vol8/paper_59.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>during training\\nof mitoem, for the fair compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3D Dental Mesh Segmentation Using Semantics-Ba...</td>\n",
       "      <td>Fan Duan, Li Chen</td>\n",
       "      <td>456-465</td>\n",
       "      <td>10.1007/978-3-031-43990-2_43</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>miccai23vol8/paper_59.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>for fair comparison with previous\\nworks, we u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3D Medical Image Segmentation with Sparse Anno...</td>\n",
       "      <td>Heng Cai, Lei Qi, Qian Yu, Yinghuan Shi, Yang Gao</td>\n",
       "      <td>614-624</td>\n",
       "      <td>10.1007/978-3-031-43898-1_59</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>miccai23vol2/paper_46.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>video\\nresnet-50 40.0 70.3\\n43.3\\nthe previous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>186</td>\n",
       "      <td>DeepGraphDMD: Interpretable Spatio-Temporal De...</td>\n",
       "      <td>Md Asadullah Turja, Martin Styner, Guorong Wu</td>\n",
       "      <td>358-368</td>\n",
       "      <td>10.1007/978-3-031-43993-3_35</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>miccai23vol1/paper_22.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>for d2\\nhisto, which has fewer patients than t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>186</td>\n",
       "      <td>DeepGraphDMD: Interpretable Spatio-Temporal De...</td>\n",
       "      <td>Md Asadullah Turja, Martin Styner, Guorong Wu</td>\n",
       "      <td>358-368</td>\n",
       "      <td>10.1007/978-3-031-43993-3_35</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>miccai23vol1/paper_22.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>the method depth-aware manages to correctly en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>187</td>\n",
       "      <td>DeepSOZ: A Robust Deep Model for Joint Tempora...</td>\n",
       "      <td>Deeksha M. Shama, Jiasen Jing, Archana Venkata...</td>\n",
       "      <td>184-194</td>\n",
       "      <td>10.1007/978-3-031-43993-3_18</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>miccai23vol10/paper_66.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>by grid search on the\\nvalidation set, we sele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>188</td>\n",
       "      <td>Democratizing Pathological Image Segmentation ...</td>\n",
       "      <td>Ruining Deng, Yanwei Li, Peize Li, Jiacheng Wa...</td>\n",
       "      <td>497-507</td>\n",
       "      <td>10.1007/978-3-031-43987-2_48</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>miccai23vol5/paper_5.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>for the fairness of the experiments, we keep t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>189</td>\n",
       "      <td>Dense Transformer based Enhanced Coding Networ...</td>\n",
       "      <td>Wangduo Xie, Matthew B. Blaschko</td>\n",
       "      <td>77-86</td>\n",
       "      <td>10.1007/978-3-031-43907-0_8</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>miccai23vol1/paper_58.pdf</td>\n",
       "      <td>/Users/yasminsarkhosh/Documents/GitHub/machine...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>661 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id                                              title  \\\n",
       "0           1  3D Arterial Segmentation via Single 2D Project...   \n",
       "1           1  3D Arterial Segmentation via Single 2D Project...   \n",
       "2           2  3D Dental Mesh Segmentation Using Semantics-Ba...   \n",
       "3           2  3D Dental Mesh Segmentation Using Semantics-Ba...   \n",
       "4           3  3D Medical Image Segmentation with Sparse Anno...   \n",
       "..        ...                                                ...   \n",
       "656       186  DeepGraphDMD: Interpretable Spatio-Temporal De...   \n",
       "657       186  DeepGraphDMD: Interpretable Spatio-Temporal De...   \n",
       "658       187  DeepSOZ: A Robust Deep Model for Joint Tempora...   \n",
       "659       188  Democratizing Pathological Image Segmentation ...   \n",
       "660       189  Dense Transformer based Enhanced Coding Networ...   \n",
       "\n",
       "                                               authors page_numbers  \\\n",
       "0    Alina F. Dima, Veronika A. Zimmer, Martin J. M...      141-151   \n",
       "1    Alina F. Dima, Veronika A. Zimmer, Martin J. M...      141-151   \n",
       "2                                    Fan Duan, Li Chen      456-465   \n",
       "3                                    Fan Duan, Li Chen      456-465   \n",
       "4    Heng Cai, Lei Qi, Qian Yu, Yinghuan Shi, Yang Gao      614-624   \n",
       "..                                                 ...          ...   \n",
       "656      Md Asadullah Turja, Martin Styner, Guorong Wu      358-368   \n",
       "657      Md Asadullah Turja, Martin Styner, Guorong Wu      358-368   \n",
       "658  Deeksha M. Shama, Jiasen Jing, Archana Venkata...      184-194   \n",
       "659  Ruining Deng, Yanwei Li, Peize Li, Jiacheng Wa...      497-507   \n",
       "660                   Wangduo Xie, Matthew B. Blaschko        77-86   \n",
       "\n",
       "                              doi  publication_year  volume  \\\n",
       "0    10.1007/978-3-031-43907-0_14              2023       1   \n",
       "1    10.1007/978-3-031-43907-0_14              2023       1   \n",
       "2    10.1007/978-3-031-43990-2_43              2023       7   \n",
       "3    10.1007/978-3-031-43990-2_43              2023       7   \n",
       "4    10.1007/978-3-031-43898-1_59              2023       3   \n",
       "..                            ...               ...     ...   \n",
       "656  10.1007/978-3-031-43993-3_35              2023       8   \n",
       "657  10.1007/978-3-031-43993-3_35              2023       8   \n",
       "658  10.1007/978-3-031-43993-3_18              2023       8   \n",
       "659  10.1007/978-3-031-43987-2_48              2023       6   \n",
       "660   10.1007/978-3-031-43907-0_8              2023       1   \n",
       "\n",
       "                           path  \\\n",
       "0     miccai23vol1/paper_14.pdf   \n",
       "1     miccai23vol1/paper_14.pdf   \n",
       "2     miccai23vol8/paper_59.pdf   \n",
       "3     miccai23vol8/paper_59.pdf   \n",
       "4     miccai23vol2/paper_46.pdf   \n",
       "..                          ...   \n",
       "656   miccai23vol1/paper_22.pdf   \n",
       "657   miccai23vol1/paper_22.pdf   \n",
       "658  miccai23vol10/paper_66.pdf   \n",
       "659    miccai23vol5/paper_5.pdf   \n",
       "660   miccai23vol1/paper_58.pdf   \n",
       "\n",
       "                                             path_long  \\\n",
       "0    /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "1    /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "2    /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "3    /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "4    /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "..                                                 ...   \n",
       "656  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "657  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "658  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "659  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "660  /Users/yasminsarkhosh/Documents/GitHub/machine...   \n",
       "\n",
       "                              extracted_sents_keywords  \n",
       "0    the cohort consists of 141 patients with pancr...  \n",
       "1    we distinguish between models selected accordi...  \n",
       "2    during training\\nof mitoem, for the fair compa...  \n",
       "3    for fair comparison with previous\\nworks, we u...  \n",
       "4    video\\nresnet-50 40.0 70.3\\n43.3\\nthe previous...  \n",
       "..                                                 ...  \n",
       "656  for d2\\nhisto, which has fewer patients than t...  \n",
       "657  the method depth-aware manages to correctly en...  \n",
       "658  by grid search on the\\nvalidation set, we sele...  \n",
       "659  for the fairness of the experiments, we keep t...  \n",
       "660                                               None  \n",
       "\n",
       "[661 rows x 10 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataframe with extracted sentences by list of keywords\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Function to count keywords in a text\n",
    "def count_keywords(text, keywords):\n",
    "    # Counter object to count occurrences of each keyword\n",
    "    counts = Counter()\n",
    "    for keyword in keywords:\n",
    "        # Count occurrences of the keyword in the text\n",
    "        counts[keyword] = text.lower().count(keyword)\n",
    "    return counts\n",
    "\n",
    "def agg_keywords(df, col_title, keywords):\n",
    "    # Aggregate 'extracted_sentences' for each 'title' and count keywords\n",
    "    results = {}\n",
    "    for title, group in df.groupby('title'):\n",
    "        # Combine all extracted sentences into one large text block\n",
    "        aggregated_text = \" \".join(group[col_title].tolist())\n",
    "        # Count the keywords in this aggregated text\n",
    "        keyword_counts = count_keywords(aggregated_text, keywords)\n",
    "        # Store the result\n",
    "        results[title] = keyword_counts\n",
    "\n",
    "    # Convert the results dictionary to a DataFrame \n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the mapping for aggregation\n",
    "def agg_columns_to_categories(df, keyword_to_category):\n",
    "    category_to_keywords = {}\n",
    "    for keyword, category in keyword_to_category.items():\n",
    "        category_to_keywords.setdefault(category, []).append(keyword)\n",
    "\n",
    "    # Aggregate columns into categories\n",
    "    for category, keywords in category_to_keywords.items():\n",
    "        if category in df.columns:\n",
    "            # If the category already exists, add to it\n",
    "            df[category] += df[keywords].sum(axis=1)\n",
    "        else:\n",
    "            # Otherwise, create a new column for the category\n",
    "            df[category] = df[keywords].sum(axis=1)\n",
    "        # Drop the original keyword columns\n",
    "        df.drop(columns=keywords, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping of keywords to main categories\n",
    "keyword_to_category = {\n",
    "    'age'   : 'age_',\n",
    "    'gender': 'gender_',\n",
    "    'sex'   : 'gender_',\n",
    "    'female': 'gender_',\n",
    "    'women' : 'gender_',\n",
    "    'woman' : 'gender_',\n",
    "    'male'  : 'gender_',\n",
    "    'geolocation'   : 'geolocation_',\n",
    "    'geographical'  : 'geolocation_',\n",
    "    'geographic'    : 'geolocation_',\n",
    "    'country'       : 'geolocation_',\n",
    "    'countries'     : 'geolocation_',\n",
    "    'city'          : 'geolocation_',\n",
    "    'cities'        : 'geolocation_',\n",
    "    'hospital'      : 'geolocation_',\n",
    "    'hospitals'     : 'geolocation_',\n",
    "    'clinic'        : 'geolocation_',\n",
    "    'clinics'       : 'geolocation_',\n",
    "    'society'       : 'social factors',\n",
    "    'societies'     : 'social factors',\n",
    "    'etnicity'      : 'etnicity_',\n",
    "    'etnicities'    : 'etnicity_',\n",
    "    'race'          : 'etnicity_',\n",
    "    'bias'          : 'bias_',\n",
    "    'biases'        : 'bias_',\n",
    "    'unfair'        : 'fairness_',\n",
    "    'fair'          : 'fairness_',\n",
    "    'fairness'      : 'fairness_',\n",
    "    'transparency'  : 'fairness_',\n",
    "    'imbalance'     : 'fairness_',\n",
    "    'imbalanced'    : 'fairness_',\n",
    "    'balance'       : 'fairness_',\n",
    "    'balanced'      :'fairness_',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert counts to binary values\n",
    "def convert_to_binary_values(df):\n",
    "    columns_to_convert = df.columns.tolist()\n",
    "\n",
    "    # Convert to binary: 1 if the count is greater than 0, else 0\n",
    "    for column in columns_to_convert:\n",
    "        df[column] = df[column].apply(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for keywords in the selected papers\n",
    "keywords = ['age', 'gender', 'sex', 'women', 'woman', 'female', 'male',\n",
    "            'geolocation', 'geographical', 'geographic', 'country', 'countries', 'city', 'cities', 'hospital', 'hospitals', 'clinic', 'clinics', \n",
    "            'society', 'societies',\n",
    "            'etnicity', 'etnicities', 'race', \n",
    "            'bias', 'biases', 'fair', 'unfair', 'fairness', 'transparency',\n",
    "            'imbalance', 'imbalanced', 'balance', 'balanced']\n",
    "\n",
    "#keywords_df = pd.DataFrame(keywords, columns=['keyword'])\n",
    "#keywords_df.to_csv('list_of_keywords.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of occurrences of each keyword in the extracted sentences\n",
    "count_keywords_df = agg_keywords(df, 'extracted_sents_keywords', keywords)\n",
    "#count_keywords_df.to_csv('keyword_counts.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the keywords into categories and aggregate the counts by category\n",
    "res = agg_columns_to_categories(count_keywords_df, keyword_to_category)\n",
    "#save_to_csv(res, 'agg_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the counts to binary values for each category\n",
    "binary_df =  convert_to_binary_values(res)\n",
    "#save_to_csv(binary_df, 'agg_columns_binary_values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>sex</th>\n",
       "      <th>women</th>\n",
       "      <th>woman</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>geolocation</th>\n",
       "      <th>geographical</th>\n",
       "      <th>geographic</th>\n",
       "      <th>...</th>\n",
       "      <th>bias</th>\n",
       "      <th>biases</th>\n",
       "      <th>fair</th>\n",
       "      <th>unfair</th>\n",
       "      <th>fairness</th>\n",
       "      <th>transparency</th>\n",
       "      <th>imbalance</th>\n",
       "      <th>imbalanced</th>\n",
       "      <th>balance</th>\n",
       "      <th>balanced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3D Arterial Segmentation via Single 2D Projections and Depth Supervision in Contrast-Enhanced CT Images</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D Dental Mesh Segmentation Using Semantics-Based Feature Learning with Graph-Transformer</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D Medical Image Segmentation with Sparse Annotation via Cross-Teaching Between 3D and 2D Networks</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D Mitochondria Instance Segmentation with Spatio-Temporal Transformers</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D Teeth Reconstruction from Panoramic Radiographs Using Neural Implicit Functions</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deep Unsupervised Clustering for Conditional Identification of Subgroups Within a Digital Pathology Image Set</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepGraphDMD: Interpretable Spatio-Temporal Decomposition of Non-linear Functional Brain Network Dynamics</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSOZ: A Robust Deep Model for Joint Temporal and Spatial Seizure Onset Localization from Multichannel EEG Data</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Democratizing Pathological Image Segmentation with Lay Annotators via Molecular-Empowered Learning</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dense Transformer based Enhanced Coding Network for Unsupervised Metal Artifact Reduction</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    age  gender  sex  women  \\\n",
       "3D Arterial Segmentation via Single 2D Projecti...    0       0    0      0   \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...    0       0    0      0   \n",
       "3D Medical Image Segmentation with Sparse Annot...    0       0    0      0   \n",
       "3D Mitochondria Instance Segmentation with Spat...    1       0    0      0   \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...    1       0    0      0   \n",
       "...                                                 ...     ...  ...    ...   \n",
       "Deep Unsupervised Clustering for Conditional Id...    0       0    0      0   \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...    1       0    0      0   \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...    0       0    0      0   \n",
       "Democratizing Pathological Image Segmentation w...    0       0    0      0   \n",
       "Dense Transformer based Enhanced Coding Network...    0       0    0      0   \n",
       "\n",
       "                                                    woman  female  male  \\\n",
       "3D Arterial Segmentation via Single 2D Projecti...      0       1     2   \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...      0       0     0   \n",
       "3D Medical Image Segmentation with Sparse Annot...      0       0     0   \n",
       "3D Mitochondria Instance Segmentation with Spat...      0       1     2   \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...      0       0     0   \n",
       "...                                                   ...     ...   ...   \n",
       "Deep Unsupervised Clustering for Conditional Id...      0       0     0   \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...      0       0     0   \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...      0       0     0   \n",
       "Democratizing Pathological Image Segmentation w...      0       0     0   \n",
       "Dense Transformer based Enhanced Coding Network...      0       0     0   \n",
       "\n",
       "                                                    geolocation  geographical  \\\n",
       "3D Arterial Segmentation via Single 2D Projecti...            0             0   \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...            0             0   \n",
       "3D Medical Image Segmentation with Sparse Annot...            0             0   \n",
       "3D Mitochondria Instance Segmentation with Spat...            0             0   \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...            0             0   \n",
       "...                                                         ...           ...   \n",
       "Deep Unsupervised Clustering for Conditional Id...            0             0   \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...            0             0   \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...            0             0   \n",
       "Democratizing Pathological Image Segmentation w...            0             0   \n",
       "Dense Transformer based Enhanced Coding Network...            0             0   \n",
       "\n",
       "                                                    geographic  ...  bias  \\\n",
       "3D Arterial Segmentation via Single 2D Projecti...           0  ...     0   \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...           0  ...     0   \n",
       "3D Medical Image Segmentation with Sparse Annot...           0  ...     0   \n",
       "3D Mitochondria Instance Segmentation with Spat...           0  ...     0   \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...           0  ...     0   \n",
       "...                                                        ...  ...   ...   \n",
       "Deep Unsupervised Clustering for Conditional Id...           0  ...     6   \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...           0  ...     0   \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...           0  ...     0   \n",
       "Democratizing Pathological Image Segmentation w...           0  ...     0   \n",
       "Dense Transformer based Enhanced Coding Network...           0  ...     0   \n",
       "\n",
       "                                                    biases  fair  unfair  \\\n",
       "3D Arterial Segmentation via Single 2D Projecti...       0     2       1   \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...       0     2       0   \n",
       "3D Medical Image Segmentation with Sparse Annot...       0     1       0   \n",
       "3D Mitochondria Instance Segmentation with Spat...       0     1       0   \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...       0     0       0   \n",
       "...                                                    ...   ...     ...   \n",
       "Deep Unsupervised Clustering for Conditional Id...       0     0       0   \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...       0     0       0   \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...       0     0       0   \n",
       "Democratizing Pathological Image Segmentation w...       0     1       0   \n",
       "Dense Transformer based Enhanced Coding Network...       0     0       0   \n",
       "\n",
       "                                                    fairness  transparency  \\\n",
       "3D Arterial Segmentation via Single 2D Projecti...         0             0   \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...         0             0   \n",
       "3D Medical Image Segmentation with Sparse Annot...         0             0   \n",
       "3D Mitochondria Instance Segmentation with Spat...         0             0   \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...         0             0   \n",
       "...                                                      ...           ...   \n",
       "Deep Unsupervised Clustering for Conditional Id...         0             0   \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...         0             0   \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...         0             0   \n",
       "Democratizing Pathological Image Segmentation w...         1             0   \n",
       "Dense Transformer based Enhanced Coding Network...         0             0   \n",
       "\n",
       "                                                    imbalance  imbalanced  \\\n",
       "3D Arterial Segmentation via Single 2D Projecti...          0           0   \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...          0           0   \n",
       "3D Medical Image Segmentation with Sparse Annot...          0           0   \n",
       "3D Mitochondria Instance Segmentation with Spat...          0           0   \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...          0           0   \n",
       "...                                                       ...         ...   \n",
       "Deep Unsupervised Clustering for Conditional Id...          0           0   \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...          0           0   \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...          0           0   \n",
       "Democratizing Pathological Image Segmentation w...          0           0   \n",
       "Dense Transformer based Enhanced Coding Network...          0           0   \n",
       "\n",
       "                                                    balance  balanced  \n",
       "3D Arterial Segmentation via Single 2D Projecti...        0         0  \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...        0         0  \n",
       "3D Medical Image Segmentation with Sparse Annot...        0         0  \n",
       "3D Mitochondria Instance Segmentation with Spat...        0         0  \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...        2         2  \n",
       "...                                                     ...       ...  \n",
       "Deep Unsupervised Clustering for Conditional Id...        0         0  \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...        3         3  \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...        1         0  \n",
       "Democratizing Pathological Image Segmentation w...        0         0  \n",
       "Dense Transformer based Enhanced Coding Network...        0         0  \n",
       "\n",
       "[189 rows x 33 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_keywords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_</th>\n",
       "      <th>gender_</th>\n",
       "      <th>geolocation_</th>\n",
       "      <th>social factors</th>\n",
       "      <th>etnicity_</th>\n",
       "      <th>bias_</th>\n",
       "      <th>fairness_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3D Arterial Segmentation via Single 2D Projections and Depth Supervision in Contrast-Enhanced CT Images</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D Dental Mesh Segmentation Using Semantics-Based Feature Learning with Graph-Transformer</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D Medical Image Segmentation with Sparse Annotation via Cross-Teaching Between 3D and 2D Networks</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D Mitochondria Instance Segmentation with Spatio-Temporal Transformers</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D Teeth Reconstruction from Panoramic Radiographs Using Neural Implicit Functions</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deep Unsupervised Clustering for Conditional Identification of Subgroups Within a Digital Pathology Image Set</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepGraphDMD: Interpretable Spatio-Temporal Decomposition of Non-linear Functional Brain Network Dynamics</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSOZ: A Robust Deep Model for Joint Temporal and Spatial Seizure Onset Localization from Multichannel EEG Data</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Democratizing Pathological Image Segmentation with Lay Annotators via Molecular-Empowered Learning</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dense Transformer based Enhanced Coding Network for Unsupervised Metal Artifact Reduction</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    age_  gender_  \\\n",
       "3D Arterial Segmentation via Single 2D Projecti...     0        1   \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...     0        0   \n",
       "3D Medical Image Segmentation with Sparse Annot...     0        0   \n",
       "3D Mitochondria Instance Segmentation with Spat...     1        1   \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...     1        0   \n",
       "...                                                  ...      ...   \n",
       "Deep Unsupervised Clustering for Conditional Id...     0        0   \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...     1        0   \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...     0        0   \n",
       "Democratizing Pathological Image Segmentation w...     0        0   \n",
       "Dense Transformer based Enhanced Coding Network...     0        0   \n",
       "\n",
       "                                                    geolocation_  \\\n",
       "3D Arterial Segmentation via Single 2D Projecti...             0   \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...             0   \n",
       "3D Medical Image Segmentation with Sparse Annot...             0   \n",
       "3D Mitochondria Instance Segmentation with Spat...             1   \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...             1   \n",
       "...                                                          ...   \n",
       "Deep Unsupervised Clustering for Conditional Id...             0   \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...             1   \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...             0   \n",
       "Democratizing Pathological Image Segmentation w...             0   \n",
       "Dense Transformer based Enhanced Coding Network...             0   \n",
       "\n",
       "                                                    social factors  etnicity_  \\\n",
       "3D Arterial Segmentation via Single 2D Projecti...               0          0   \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...               0          0   \n",
       "3D Medical Image Segmentation with Sparse Annot...               0          0   \n",
       "3D Mitochondria Instance Segmentation with Spat...               0          0   \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...               0          0   \n",
       "...                                                            ...        ...   \n",
       "Deep Unsupervised Clustering for Conditional Id...               0          0   \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...               0          0   \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...               0          0   \n",
       "Democratizing Pathological Image Segmentation w...               0          0   \n",
       "Dense Transformer based Enhanced Coding Network...               0          0   \n",
       "\n",
       "                                                    bias_  fairness_  \n",
       "3D Arterial Segmentation via Single 2D Projecti...      0          1  \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...      0          1  \n",
       "3D Medical Image Segmentation with Sparse Annot...      0          1  \n",
       "3D Mitochondria Instance Segmentation with Spat...      0          1  \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...      0          1  \n",
       "...                                                   ...        ...  \n",
       "Deep Unsupervised Clustering for Conditional Id...      1          0  \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...      0          1  \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...      0          1  \n",
       "Democratizing Pathological Image Segmentation w...      0          1  \n",
       "Dense Transformer based Enhanced Coding Network...      0          0  \n",
       "\n",
       "[189 rows x 7 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_</th>\n",
       "      <th>gender_</th>\n",
       "      <th>geolocation_</th>\n",
       "      <th>social factors</th>\n",
       "      <th>etnicity_</th>\n",
       "      <th>bias_</th>\n",
       "      <th>fairness_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3D Arterial Segmentation via Single 2D Projections and Depth Supervision in Contrast-Enhanced CT Images</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D Dental Mesh Segmentation Using Semantics-Based Feature Learning with Graph-Transformer</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D Medical Image Segmentation with Sparse Annotation via Cross-Teaching Between 3D and 2D Networks</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D Mitochondria Instance Segmentation with Spatio-Temporal Transformers</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D Teeth Reconstruction from Panoramic Radiographs Using Neural Implicit Functions</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deep Unsupervised Clustering for Conditional Identification of Subgroups Within a Digital Pathology Image Set</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepGraphDMD: Interpretable Spatio-Temporal Decomposition of Non-linear Functional Brain Network Dynamics</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSOZ: A Robust Deep Model for Joint Temporal and Spatial Seizure Onset Localization from Multichannel EEG Data</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Democratizing Pathological Image Segmentation with Lay Annotators via Molecular-Empowered Learning</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dense Transformer based Enhanced Coding Network for Unsupervised Metal Artifact Reduction</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    age_  gender_  \\\n",
       "3D Arterial Segmentation via Single 2D Projecti...     0        1   \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...     0        0   \n",
       "3D Medical Image Segmentation with Sparse Annot...     0        0   \n",
       "3D Mitochondria Instance Segmentation with Spat...     1        1   \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...     1        0   \n",
       "...                                                  ...      ...   \n",
       "Deep Unsupervised Clustering for Conditional Id...     0        0   \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...     1        0   \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...     0        0   \n",
       "Democratizing Pathological Image Segmentation w...     0        0   \n",
       "Dense Transformer based Enhanced Coding Network...     0        0   \n",
       "\n",
       "                                                    geolocation_  \\\n",
       "3D Arterial Segmentation via Single 2D Projecti...             0   \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...             0   \n",
       "3D Medical Image Segmentation with Sparse Annot...             0   \n",
       "3D Mitochondria Instance Segmentation with Spat...             1   \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...             1   \n",
       "...                                                          ...   \n",
       "Deep Unsupervised Clustering for Conditional Id...             0   \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...             1   \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...             0   \n",
       "Democratizing Pathological Image Segmentation w...             0   \n",
       "Dense Transformer based Enhanced Coding Network...             0   \n",
       "\n",
       "                                                    social factors  etnicity_  \\\n",
       "3D Arterial Segmentation via Single 2D Projecti...               0          0   \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...               0          0   \n",
       "3D Medical Image Segmentation with Sparse Annot...               0          0   \n",
       "3D Mitochondria Instance Segmentation with Spat...               0          0   \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...               0          0   \n",
       "...                                                            ...        ...   \n",
       "Deep Unsupervised Clustering for Conditional Id...               0          0   \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...               0          0   \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...               0          0   \n",
       "Democratizing Pathological Image Segmentation w...               0          0   \n",
       "Dense Transformer based Enhanced Coding Network...               0          0   \n",
       "\n",
       "                                                    bias_  fairness_  \n",
       "3D Arterial Segmentation via Single 2D Projecti...      0          1  \n",
       "3D Dental Mesh Segmentation Using Semantics-Bas...      0          1  \n",
       "3D Medical Image Segmentation with Sparse Annot...      0          1  \n",
       "3D Mitochondria Instance Segmentation with Spat...      0          1  \n",
       "3D Teeth Reconstruction from Panoramic Radiogra...      0          1  \n",
       "...                                                   ...        ...  \n",
       "Deep Unsupervised Clustering for Conditional Id...      1          0  \n",
       "DeepGraphDMD: Interpretable Spatio-Temporal Dec...      0          1  \n",
       "DeepSOZ: A Robust Deep Model for Joint Temporal...      0          1  \n",
       "Democratizing Pathological Image Segmentation w...      0          1  \n",
       "Dense Transformer based Enhanced Coding Network...      0          0  \n",
       "\n",
       "[189 rows x 7 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
