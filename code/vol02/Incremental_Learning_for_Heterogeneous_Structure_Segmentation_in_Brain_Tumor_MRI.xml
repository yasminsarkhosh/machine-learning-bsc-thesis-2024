<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Incremental Learning for Heterogeneous Structure Segmentation in Brain Tumor MRI</title>
				<funder ref="#_5GWSfVY #_Jt6rgkF #_dChrEU5">
					<orgName type="full">National Institutes of Health</orgName>
					<orgName type="abbreviated">NIH</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xiaofeng</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Gordon Center for Medical Imaging</orgName>
								<orgName type="department" key="dep2">Department of Radiology</orgName>
								<orgName type="institution" key="instit1">Massachusetts General Hospital</orgName>
								<orgName type="institution" key="instit2">Harvard Medical School</orgName>
								<address>
									<postCode>02114</postCode>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Helen</forename><forename type="middle">A</forename><surname>Shih</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Radiation Oncology</orgName>
								<orgName type="department" key="dep2">Harvard Medical School</orgName>
								<orgName type="institution">Massachusetts General Hospital</orgName>
								<address>
									<postCode>02114</postCode>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fangxu</forename><surname>Xing</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Gordon Center for Medical Imaging</orgName>
								<orgName type="department" key="dep2">Department of Radiology</orgName>
								<orgName type="institution" key="instit1">Massachusetts General Hospital</orgName>
								<orgName type="institution" key="instit2">Harvard Medical School</orgName>
								<address>
									<postCode>02114</postCode>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Emiliano</forename><surname>Santarnecchi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Gordon Center for Medical Imaging</orgName>
								<orgName type="department" key="dep2">Department of Radiology</orgName>
								<orgName type="institution" key="instit1">Massachusetts General Hospital</orgName>
								<orgName type="institution" key="instit2">Harvard Medical School</orgName>
								<address>
									<postCode>02114</postCode>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Georges</forename><surname>El Fakhri</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Gordon Center for Medical Imaging</orgName>
								<orgName type="department" key="dep2">Department of Radiology</orgName>
								<orgName type="institution" key="instit1">Massachusetts General Hospital</orgName>
								<orgName type="institution" key="instit2">Harvard Medical School</orgName>
								<address>
									<postCode>02114</postCode>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jonghye</forename><surname>Woo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Gordon Center for Medical Imaging</orgName>
								<orgName type="department" key="dep2">Department of Radiology</orgName>
								<orgName type="institution" key="instit1">Massachusetts General Hospital</orgName>
								<orgName type="institution" key="instit2">Harvard Medical School</orgName>
								<address>
									<postCode>02114</postCode>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Incremental Learning for Heterogeneous Structure Segmentation in Brain Tumor MRI</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="46" to="56"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">1650905202A8AC5CD81237F34AA561F9</idno>
					<idno type="DOI">10.1007/978-3-031-43895-0_5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-23T22:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep learning (DL) models for segmenting various anatomical structures have achieved great success via a static DL model that is trained in a single source domain. Yet, the static DL model is likely to perform poorly in a continually evolving environment, requiring appropriate model updates. In an incremental learning setting, we would expect that well-trained static models are updated, following continually evolving target domain data-e.g., additional lesions or structures of interest-collected from different sites, without catastrophic forgetting. This, however, poses challenges, due to distribution shifts, additional structures not seen during the initial model training, and the absence of training data in a source domain. To address these challenges, in this work, we seek to progressively evolve an "off-the-shelf" trained segmentation model to diverse datasets with additional anatomical categories in a unified manner. Specifically, we first propose a divergence-aware dualflow module with balanced rigidity and plasticity branches to decouple old and new tasks, which is guided by continuous batch renormalization. Then, a complementary pseudo-label training scheme with self-entropy regularized momentum MixUp decay is developed for adaptive network optimization. We evaluated our framework on a brain tumor segmentation task with continually changing target domains-i.e., new MRI scanners/modalities with incremental structures. Our framework was able to well retain the discriminability of previously learned structures, hence enabling the realistic life-long segmentation model extension along with the widespread accumulation of big medical data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Accurate segmentation of a variety of anatomical structures is a crucial prerequisite for subsequent diagnosis or treatment <ref type="bibr" target="#b27">[28]</ref>. While recent advances in datadriven deep learning (DL) have achieved superior segmentation performance <ref type="bibr" target="#b28">[29]</ref>, the segmentation task is often constrained by the availability of costly pixel-wise labeled training datasets. In addition, even if static DL models are trained with extraordinarily large amounts of training datasets in a supervised learning manner <ref type="bibr" target="#b28">[29]</ref>, there exists a need for a segmentor to update a trained model with new data alongside incremental anatomical structures <ref type="bibr" target="#b23">[24]</ref>.</p><p>In real-world scenarios, clinical databases are often sequentially constructed from various clinical sites with varying imaging protocols <ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b22">23]</ref>. As well, labeled anatomical structures are incrementally increased with additional lesions or new structures of interest, depending on study goals or clinical needs <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b26">27]</ref>. Furthermore, access to previously used data for training can be restricted, due to data privacy protocols <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref>. Therefore, efficiently utilizing heterogeneous structure-incremental (HSI) learning is highly desired for clinical practice to develop a DL model that can be generalized well for different types of input data and varying structures involved. Straightforwardly fine-tuning DL models with either new structures <ref type="bibr" target="#b29">[30]</ref> or heterogeneous data <ref type="bibr" target="#b16">[17]</ref> in the absence of the data used for the initial model training, unfortunately, can easily overwrite previously learned knowledge, i.e., catastrophic forgetting <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b29">30]</ref>.</p><p>At present, satisfactory methods applied in the realistic HSI setting are largely unavailable. F irst, recent structure-incremental works cannot deal with domain shift. Early attempts <ref type="bibr" target="#b26">[27]</ref> simply used exemplar data in the previous stage. <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b32">33</ref>] combined a trained model prediction and a new class mask as a pseudo-label. However, predictions from the old model under a domain shift are likely to be unreliable <ref type="bibr" target="#b37">[38]</ref>. The widely used pooled feature statistics consistency <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b29">30]</ref> is also not applicable for heterogeneous data, since the statistics are domain-specific <ref type="bibr" target="#b1">[2]</ref>. In addition, a few works <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b33">34]</ref> proposed to increase the capacity of networks to avoid directly overwriting parameters that are entangled with old and new knowledge. However, the solutions cannot be domain adaptive. Second, from the perspective of continuous domain adaptation with the consistent class label, old exemplars have been used for the application of prostate MRI segmentation <ref type="bibr" target="#b31">[32]</ref>. While Li et al. <ref type="bibr" target="#b16">[17]</ref> further proposed to recover the missing old stage data with an additional generative model, hallucinating realistic data, given only the trained model itself, is a highly challenging task <ref type="bibr" target="#b30">[31]</ref> and may lead to sensitive information leakage <ref type="bibr" target="#b34">[35]</ref>. T hird, while, for natural image classification, Kundu et al. <ref type="bibr" target="#b15">[16]</ref> updated the model for class-incremental unsupervised domain adaption, its class prototype is not applicable for segmentation.</p><p>In this work, we propose a unified HSI segmentor evolving framework with a divergence-aware decoupled dual-flow (D 3 F) module, which is adaptively optimized via HSI pseudo-label distillation using a momentum MixUp decay (MMD) scheme. To explicitly avoid the overwriting of previously learned parameters, our D 3 F follows a "divide-and-conquer" strategy to balance the old and new tasks with a fixed rigidity branch and a compensated learnable plasticity branch, which is guided by our novel divergence-aware continuous batch renormalization (cBRN). The complementary knowledge can be flexibly integrated with the model re-parameterization <ref type="bibr" target="#b3">[4]</ref>. Our additional parameters are constant in training, and 0 in testing. Then, the flexible D 3 F module is trained following the knowledge distillation with novel HSI pseudo-labels. Specifically, inspired by the self-knowledge distillation <ref type="bibr" target="#b14">[15]</ref> and self-training <ref type="bibr" target="#b37">[38]</ref> that utilize the previous prediction for better generalization, we adaptively construct the HSI pseudo-label with an MMD scheme to smoothly adjust the contribution of potential noisy old model predictions on heterogeneous data and progressively learned new model predictions along with the training. In addition, unsupervised self-entropy minimization is added to further enhance performance.</p><p>Our main contributions can be summarized as follow:</p><p>• To our knowledge, this is the first attempt at realistic HSI segmentation with both incremental structures of interest and diverse domains. • We propose a divergence-aware decoupled dual-flow module guided by our novel continuous batch renormalization (cBRN) for alleviating the catastrophic forgetting under domain shift scenarios. • The adaptively constructed HSI pseudo-label with self-training is developed for efficient HSI knowledge distillation.</p><p>We evaluated our framework on anatomical structure segmentation tasks from different types of MRI data collected from multiple sites. Our HSI scheme demonstrated superior performance in segmenting all structures with diverse data distributions, surpassing conventional class-incremental methods without considering data shift, by a large margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>For the segmentation model under incremental structures of interest and domain shift scenarios, we are given an off-the-shelf segmentor f θ 0 : X 0 → Y 0 parameterized with θ 0 , which has been trained with the data {x 0 n , y 0 n } N 0 n=1 in an initial source domain D 0 = {X 0 , Y 0 }, where x 0 n ∈ R H×W and y 0 n ∈ R H×W are the paired image slice and its segmentation mask with the height of H and width of W , respectively. There are T consecutive evolving stages with heterogeneous target domains D t = {X t , S t } T t=1 , each with the paired slice set {x t n } N t n=1 ∈ X t and the current stage label set {s t n } N t n=1 ∈ S t , where x t n , s t n ∈ R H×W . Due to heterogeneous domain shifts, X t from different sites or modalities follows diverse distributions across all T stages. Due to incremental anatomical structures, the overall label space, across the previous t stages, Y t is expanded from Y t-1 with the additional annotated structures</p><formula xml:id="formula_0">S t in stage t, i.e., Y t = Y t-1 ∪ S t = Y 0 ∪ S 1 • • • ∪ S t . We are targeting to learn f θ T : {X t } T t=1 → Y T that performs well on all {X t } T t=1</formula><p>for delineating all of the structures Y T seen in T stages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">cBRN Guided Divergence-Aware Decoupled Dual-Flow</head><p>To alleviate the forgetting through parameter overwriting, caused by both new structures and data shift, we propose a D 3 F module for flexible decoupling and integration of old and new knowledge. Specifically, we duplicate the convolution in each layer initialized with the previous model f θ t-1 to form two branches as in <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b33">34]</ref>. The first rigidity branch f r θ t is fixed at the stage t to keep the old knowledge we have learned. In contrast, the extended plasticity branch f p θ t is expected to be adaptively updated 2 } with the model re-parameterization <ref type="bibr" target="#b3">[4]</ref>. In fact, the dual-flow model can be regarded as an implicit ensemble scheme <ref type="bibr" target="#b8">[9]</ref> to integrate multiple sub-modules with a different focus. In addition, as demonstrated in <ref type="bibr" target="#b5">[6]</ref>, the fixed modules will regularize the learnable modules to act as the fixed one. Thus, the plasticity modules can also be implicitly encouraged to keep the previous knowledge along with its HSI learning.</p><p>However, under the domain shift, it can be sub-optimal to directly average the parameters, since f r θ t may not perform well to predict Y t-1 on X t . It has been demonstrated that batch statistics adaptation plays an important role in domain generalizable model training <ref type="bibr" target="#b21">[22]</ref>. Therefore, we propose a continual batch renormalization (cBRN) to mitigate the feature statistics divergence between each training batch at a specific stage and the life-long global data distribution.</p><p>Of note, as a default block in the modern convolutional neural networks (CNN) <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b36">37]</ref>, batch normalization (BN) <ref type="bibr" target="#b10">[11]</ref> normalizes the input feature of each CNN channel z ∈ R Hc×Wc with its batch-wise statistics, e.g., mean μ B and standard deviation σ B , and learnable scaling and shifting factors {γ, β} as zi = zi-μB σB • γ + β, where i indexes the spatial position in R Hc×Wc . BN assumes that the same mini-batch training and testing distribution <ref type="bibr" target="#b9">[10]</ref>, which does not hold in HSI. Simply enforcing the same statistics across domains as <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b32">33]</ref> can weaken the model expressiveness <ref type="bibr" target="#b35">[36]</ref>.</p><p>The recent BRN <ref type="bibr" target="#b9">[10]</ref> proposes to rectify the data shift between each batch and the dataset by using the moving average μ and σ along with the training:</p><formula xml:id="formula_1">μ = (1 -η) • μ + η • μ B , σ = (1 -η) • σ + η • σ B , (<label>1</label></formula><formula xml:id="formula_2">)</formula><p>where η ∈ [0, 1] is applied to balance the global statistics and the current batch.</p><p>In addition, γ = σB σ and β = μB -μ σ are used in both training and testing. Therefore, BRN renormalizes zi = zi-μ σ to highlight the dependency on the global statistics {μ, σ} in training for a more generalizable model, while limited to the static learning.</p><p>In this work, we further explore the potential of BRN in the continuously evolving HSI task to be general for all of domains involved. Specifically, we extend BRN to cBRN across multiple consecutive stages by updating {μ c , σ c } along with all stages of training, which is transferred as shown in Fig. <ref type="figure" target="#fig_0">1</ref>. The conventional BN also inherits {μ, σ} for testing, while not being used in training <ref type="bibr" target="#b10">[11]</ref>. At the stage t, μ c and σ c are succeeded from t -1 stage, and are updated with the current batch-wise {μ r B , σ r B } and {μ p B , σ p B } in rigidity and plasticity branches:</p><formula xml:id="formula_3">μ c = (1 -η) • μ c + η • 1 2 {μ r B + μ p B }, σ c = (1 -η) • σ c + η • 1 2 {σ r B + σ p B }. (2)</formula><p>For testing, the two branches in final model f θ T can be merged for the lightweight implementation:</p><formula xml:id="formula_4">z = W r T z + b r T + μc 2σc + W p T z + b p T + μc 2σc = W r T + W p T 2σc z + b r T + b p T + 2μc 2σc = Ŵ z + b.<label>(3)</label></formula><p>Therefore, f T θ does not introduce additional parameters for deployment (Fig. <ref type="figure" target="#fig_1">2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">HSI Pseudo-label Distillation with Momentum MixUp Decay</head><p>The training of our developed f θ t with D 3 F is supervised with the previous model f θ t-1 and current stage data {x t n , s t n } N t n=1 . In conventional class incremental learning, the knowledge distillation <ref type="bibr" target="#b30">[31]</ref> is widely used to construct the combined label y t n ∈ R H×W by adding s t n and the prediction of f θ t-1 (x t n ). Then, f θ t can be optimized by the training pairs of {x t n , y t n } N t n=1 . However, with heterogeneous data in different stages, f θ t-1 (x t n ) can be highly unreliable. Simply using it as ground truth cannot guide the correct knowledge transfer.</p><p>In this work, we construct a complementary pseudo-label ŷt n ∈ R H×W with a MixUp decay scheme to adaptively exploit the knowledge in the old segmentor for the progressively learned new segmentor. In the initial training epochs, f θ t-1 could be a more reliable supervision signal, while we would expect f θ t can learn to perform better on predicting Y t-1 . Of note, even with the rigidity branch, the integrated network can be largely distracted by the plasticity branch in the initial epochs. Therefore, we propose to dynamically adjust their importance in constructing pseudo-label along with the training progress. Specifically, we MixUp the predictions of f θ t-1 and f θ t w.r.t. Y t-1 , i.e., f θ t (•)[: t -1], and control their pixel-wise proportion for the pseudo-label ŷt n with MMD:</p><formula xml:id="formula_5">ŷt n:i = {λf θ t-1 (x t n:i ) + (1 -λ)f θ t (x t n:i )[: t -1]} ∪ s t n:i , λ = λ 0 exp(-I),<label>(4)</label></formula><p>where i indexes each pixel, and λ is the adaptation momentum factor with the exponential decay of iteration I. λ 0 is the initial weight of f θ t-1 (x t n:i ), which is empirically set to 1 to constrain λ ∈ (0, 1]. Therefore, the weight of old model prediction can be smoothly decreased along with the training, and f θ t (x t n:i ) gradually represents the target data for the old classes in [: t <ref type="bibr">-1]</ref>. Of note, we have ground-truth of new structure s t n:i under HSI scenarios <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b32">33]</ref>. We calculate the cross-entropy loss L CE with the pseudo-label ŷt n:i as self-training <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b37">38]</ref>. In addition to the old knowledge inherited in f θ t-1 , we propose to explore unsupervised learning protocols to stabilize the initial training. We adopt the widely used self-entropy (SE) minimization <ref type="bibr" target="#b6">[7]</ref> as a simple add-on training objective. Specifically, we have the slice-level segmentation SE, which is the averaged entropy of the pixel-wise softmax prediction as</p><formula xml:id="formula_6">L SE = E i {-f θ t (x t n:i )logf θ t (x t n:i )}.</formula><p>In training, the overall optimization loss is formulated as follows:</p><formula xml:id="formula_7">L = L CE (ŷ t n:i , f θ t (x t n:i )) + αL SE (f θ t (x t n:i )), α = I max -I I max α 0 , (<label>5</label></formula><formula xml:id="formula_8">)</formula><p>where α is used to balance our HSI distillation and SE minimization terms, and I max is the scheduled iteration. Of note, strictly minimizing the SE can result in a trivial solution of always predicting a one-hot distribution <ref type="bibr" target="#b6">[7]</ref>, and a linear decreasing of α is usually applied, where λ 0 and α 0 are reset in each stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head><p>We carried out two evaluation settings using the BraTS2018 database <ref type="bibr" target="#b0">[1]</ref>, including cross-subset (relatively small domain shift) and cross-modality (relatively large domain shift) tasks. The BraTS2018 database is a continually evolving database <ref type="bibr" target="#b0">[1]</ref> with a total of 285 glioblastoma or low-grade gliomas subjects,  comprising three consecutive subsets, i.e., 30 subjects from BraTS2013 <ref type="bibr" target="#b25">[26]</ref>, 167 subjects from TCIA <ref type="bibr" target="#b2">[3]</ref>, and 88 subjects from CBICA <ref type="bibr" target="#b0">[1]</ref>. Notably, these three subsets were collected from different clinical sites, vendors, or populations <ref type="bibr" target="#b0">[1]</ref>. Each subject has T1, T1ce, T2, and FLAIR MRI volumes with voxel-wise labels for the tumor core (CoreT), the enhancing tumor (EnhT), and the edema (ED). We incrementally learned CoreT, EnhT, and ED structures throughout three consecutive stages, each following different data distributions. We used subjectindependent 7/1/2 split for training, validation, and testing. For a fair comparison, we adopted the ResNet-based 2D nnU-Net backbone with BN as in <ref type="bibr" target="#b11">[12]</ref> for all of the methods and all stages used in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Cross-Subset Structure Incremental Evolving</head><p>In our cross-subset setting, three structures were sequentially learned across three stages: (CoreT with BraTS2013) → (EnhT with TCIA) → (ED with CBICA). Of note, we used a CoreT segmentator trained with BraTS2013 as our off-the-shelf segmentor in t = 0. Testing involved all subsets and anatomical structures. We compared our framework with the three typical structureincremental (SI-only) segmentation methods, e.g., PLOP <ref type="bibr" target="#b4">[5]</ref>, MargExcIL <ref type="bibr" target="#b17">[18]</ref>, and UCD <ref type="bibr" target="#b29">[30]</ref>, which cannot address the heterogeneous data across stages. As tabulated in Table <ref type="table" target="#tab_0">1</ref>, PLOP <ref type="bibr" target="#b4">[5]</ref> with additional feature statistic constraints has lower performance than MargExcIL <ref type="bibr" target="#b17">[18]</ref>, since the feature statistic consistency was not held in HSI scenarios. Of note, the domain-incremental methods <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b31">32]</ref> cannot handle the changing output space. Our proposed HSI framework outperformed SI-only methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b29">30]</ref> with respect to both DSC and HD, by a large margin. For the anatomical structure CoreT learned in t = 0, the difference between our HSI and these SI-only methods was larger than 10% DSC, which indicates the data shift related forgetting lead to a more severe performance drop in the early stages. We set η = 0.01 and α 0 = 10 according to the sensitivity study in the supplementary material.</p><p>For the ablation study, we denote HSI-D 3 F as our HSI without the D 3 F module, simply fine-tuning the model parameters. HSI-cBRN used dual-flow to avoid direct overwriting, while the model was not guided by cBRN for more generalized prediction on heterogeneous data. As shown in Table <ref type="table" target="#tab_0">1</ref>, both the dual-flow and cBRN improve the performance. Notably, the dual-flow model with flexible re-parameterization was able to alleviate the overwriting, while our cBRN was developed to deal with heterogeneous data. In addition, HSI-MMD indicates our HSI without the momentum MixUp decay in pseudo-label construction, i.e., simply regarding the prediction of f θ t-1 (x t ) is ground truth for Y t-1 . However, f θ t-1 (x t ) can be quite noisy, due to the low quantification performance of early stage structures, which can be aggravated in the case of the long-term evolving scenario. Of note, the pseudo-label construction is necessary as in <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b29">30]</ref>. We also provide the qualitative comparison with SI-only methods and ablation studies in Fig. <ref type="figure" target="#fig_2">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Cross-Modality Structure Incremental Evolving</head><p>In our cross-modality setting, three structures were sequentially learned across three stages: (CoreT with T1) → (EnhT with T2) → (ED with T2 FLAIR). Of note, we used the CoreT segmentator trained with T1 modality as our off-the-shelf segmentor in t = 0. Testing involved all MRI modalities and all structures. With the hyperparameter validation, we empirically set η = 0.01 and α 0 = 10.</p><p>In Table <ref type="table" target="#tab_2">2</ref>, we provide quantitative evaluation results. We can see that our HSI framework outperformed SI-only methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b29">30]</ref> consistently. The improvement can be even larger, compared with the cross-subset task, since we have much more diverse input data in the cross-modality setting. Catastrophic forgetting can be severe, when we use SI-only method for predicting early stage structures, e.g., CoreT. We also provide the ablation study with respect to D 3 F, cBRN, and MMD in Table <ref type="table" target="#tab_2">2</ref>. The inferior performance of HSI-D 3 F/cBRN/MMD demonstrates the effectiveness of these modules for mitigating domain shifts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>This work proposed an HSI framework under a clinically meaningful scenario, in which clinical databases are sequentially constructed from different sites/imaging protocols with new labels. To alleviate the catastrophic forgetting alongside continuously varying structures and data shifts, our HSI resorted to a D 3 F module for learning and integrating old and new knowledge nimbly. In doing so, we were able to achieve divergence awareness with our cBRN-guided model adaptation for all the data involved. Our framework was optimized with a self-entropy regularized HSI pseudo-label distillation scheme with MMD to efficiently utilize the previous model in different types of MRI data. Our framework demonstrated superior segmentation performance in learning new anatomical structures from cross-subset/modality MRI data. It was experimentally shown that a large improvement in learning anatomic structures was observed.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Illustration of one layer in our proposed divergence-aware decoupled dualflow module guided with cBRN for our cross-MR-modality HSI task, i.e., subjectindependent (CoreT with T1) → (EnhT with T2) → (ED with FLAIR). Notably, we do not require the dual-flow or cBRN, for the initial segmentor.</figDesc><graphic coords="4,58,98,53,78,334,51,210,91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Illustration of the proposed HSI pseudo-label distillation with MMD</figDesc><graphic coords="5,43,29,54,53,337,45,109,18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Segmentation examples in t = 1 and t = 2 in the cross-subset brain tumor HSI segmentation task.</figDesc><graphic coords="7,43,29,206,21,337,33,113,02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Numerical comparisons and ablation studies of the cross-subset brain tumor HSI segmentation task × 59.83 ± 0.131 45.50 57.39 76.59 19.2 ± 0.14 22.0 19.8 15.9</figDesc><table><row><cell>Method</cell><cell>Data shift</cell><cell cols="4">Dice similarity coefficient (DSC) [%] ↑ Hausdorff distance (HD)[mm] ↓</cell></row><row><cell></cell><cell>consideration</cell><cell>Mean</cell><cell>CoreT EnhT ED</cell><cell>Mean</cell><cell>CoreT EnhT ED</cell></row><row><cell>PLOP [5]</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">MargExcIL [18] ×</cell><cell cols="4">60.49 ± 0.127 48.37 56.28 76.81 18.9 ± 0.11 21.4</cell><cell>19.8 15.5</cell></row><row><cell>UCD [30] HSI-MMD HSI-D 3 F HSI-cBRN HSI</cell><cell>× √ √ √ √</cell><cell cols="4">61.84 ± 0.129 49.23 58.81 77.48 19.0 ± 0.15 21.8 66.87 ± 0.126 59.42 61.26 79.93 16.8 ± 0.13 18.5 67.18 ± 0.118 60.18 63.09 78.26 16.7 ± 0.14 18.0 68.07 ± 0.121 61.52 63.45 79.25 16.3 ± 0.14 17.8 69.44 ± 0</cell><cell>19.4 15.7 17.8 14.2 17.5 14.5 17.3 13.8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>.119 63.79 64.71 79.81 15.7 ± 0.12 16.7 16.9 13.6</head><label></label><figDesc>Joint Static √ (upper bound) 73.98 ± 0.117 71.14 68.35 82.46 15.0 ± 0.13 15.7 16.2 13.2</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Numerical comparisons and ablation studies of the cross-modality brain tumor HSI segmentation task</figDesc><table><row><cell>Method</cell><cell cols="2">Data shift</cell><cell cols="3">Dice similarity coefficient (DSC) [%] ↑ Hausdorff distance (HD)[mm] ↓</cell></row><row><cell></cell><cell cols="2">consideration</cell><cell>Mean</cell><cell>CoreT EnhT ED</cell><cell>Mean</cell><cell>CoreT EnhT ED</cell></row><row><cell>PLOP [5]</cell><cell>×</cell><cell></cell><cell cols="3">39.58 ± 0.231 13.84 38.93 65.98 30.7 ± 0.26 48.1</cell><cell>25.4 18.7</cell></row><row><cell cols="2">MargExcIL [18] ×</cell><cell></cell><cell cols="3">42.84 ± 0.189 19.56 41.56 67.40 29.1 ± 0.28 46.7</cell><cell>22.1 18.6</cell></row><row><cell>UCD [30] HSI-MMD HSI-D 3 F HSI-cBRN HSI Joint Static</cell><cell>× √ √ √ √ √</cell><cell cols="4">44.67 ± 0.214 21.39 45.28 67.35 29.4 ± 0.32 46.2 59.81 ± 0.207 51.63 53.82 73.97 19.4 ± 0.26 21.6 60.81 ± 0.195 53.87 55.42 73.15 19.2 ± 0.21 21.4 61.87 ± 0.180 54.90 56.62 74.08 18.5 ± 0.25 20.1 64.15 ± 0.205 58.11 59.51 74.83 17.7 ± 0.29 18.9 18.6 15.8 23.6 18.4 20.5 16.2 19.9 16.2 19.5 16.0 (upper bound) 70.64 ± 0.184 67.48 65.75 78.68 16.7 ± 0.26 17.2 17.8 15.1</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This work is supported by <rs type="funder">NIH</rs> <rs type="grantNumber">R01DC018511</rs>, <rs type="grantNumber">R01DE027989</rs>, and <rs type="grantNumber">P41EB022544</rs>. The authors would like to thank <rs type="person">Dr. Jonghyun Choi</rs> for his valuable insights and helpful discussions.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_5GWSfVY">
					<idno type="grant-number">R01DC018511</idno>
				</org>
				<org type="funding" xml:id="_Jt6rgkF">
					<idno type="grant-number">R01DE027989</idno>
				</org>
				<org type="funding" xml:id="_dChrEU5">
					<idno type="grant-number">P41EB022544</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Identifying the best machine learning algorithms for brain tumor segmentation, progression assessment, and overall survival prediction in the brats challenge</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bakas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.02629</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Domain-specific batch normalization for unsupervised domain adaptation</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">G</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="7354" to="7362" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The cancer imaging archive (TCIA): maintaining and operating a public information repository</title>
		<author>
			<persName><forename type="first">K</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Digit. Imaging</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1045" to="1057" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">RepVGG: making VGGstyle convnets great again</title>
		<author>
			<persName><forename type="first">X</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="13733" to="13742" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">PLOP: learning without forgetting for continual semantic segmentation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Douillard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dapogny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cord</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4040" to="4050" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Interactive knowledge distillation for image classification</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">449</biblScope>
			<biblScope unit="page" from="411" to="421" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Semi-supervised learning by entropy minimization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Grandvalet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep networks with stochastic depth</title>
		<author>
			<persName><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sedra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-46493-0_39</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-46493-0" />
	</analytic>
	<monogr>
		<title level="m">ECCV 2016</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Leibe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Matas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Sebe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">9908</biblScope>
			<biblScope unit="page">39</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Batch renormalization: towards reducing minibatch dependence in batchnormalized models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Batch normalization: accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PMLR</title>
		<imprint>
			<biblScope unit="page" from="448" to="456" />
			<date type="published" when="2015">2015</date>
		</imprint>
		<respStmt>
			<orgName>ICML</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Isensee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Kohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Maier-Hein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="211" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Reparameterizing convolutions for incremental multi-task learning without task interference</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kanakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bruggemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Georgoulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Obukhov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-58565-5_41</idno>
		<idno>978-3-030-58565-5 41</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">ECCV 2020</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Bischof</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J.-M</forename><surname>Frahm</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12365</biblScope>
			<biblScope unit="page" from="689" to="707" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.00829</idno>
		<title level="m">Incremental learning with maximum entropy regularization: Rethinking forgetting and intransigence</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Self-knowledge distillation: a simple way for better generalization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hwang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.12000</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Classincremental domain adaptation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Kundu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Venkat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Revanur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">V</forename><surname>Babu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-58601-0_4</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-58601-04" />
	</analytic>
	<monogr>
		<title level="m">ECCV 2020</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Bischof</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J.-M</forename><surname>Frahm</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12358</biblScope>
			<biblScope unit="page" from="53" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Domain-incremental cardiac image segmentation with style-oriented replay and domain-sensitive feature whitening</title>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TMI</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="570" to="581" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning incrementally to segment multiple organs in a CT image</title>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16440-8_68</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16440-8" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13434</biblScope>
			<biblScope unit="page">68</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Attentive continuous generative self-training for unsupervised domain adaptive medical image translation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Memory consistent unsupervised offthe-shelf model adaptation for source-relaxed medical image segmentation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>El Fakhri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Woo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page">102641</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Act: Semi-supervised domain-adaptive medical image segmentation with asymmetric co-training</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16443-9_7</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16443-97" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13435</biblScope>
			<biblScope unit="page" from="66" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Adapting off-the-shelf source segmenter for target medical image segmentation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>El Fakhri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Woo</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87196-3_51</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87196-351" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12902</biblScope>
			<biblScope unit="page" from="549" to="559" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Subtype-aware dynamic unsupervised domain adaptation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TNNLS</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep unsupervised domain adaptation: a review of recent advances and perspectives</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">APSIPA Trans. Signal Inf. Process</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Adaptive aggregation networks for class-incremental learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2544" to="2553" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The multimodal brain tumor image segmentation benchmark (BRATS)</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Menze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TMI</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1993" to="2024" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learn the new, keep the old: extending pretrained models with new anatomy and images</title>
		<author>
			<persName><forename type="first">F</forename><surname>Ozdemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fuernstahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Goksel</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-00937-3_42</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-00937-3" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2018</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Schnabel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Davatzikos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Alberola-López</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Fichtinger</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">11073</biblScope>
			<biblScope unit="page">42</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Automated delineation of the clinical target volume using anatomically constrained 3D expansion of the gross tumor volume</title>
		<author>
			<persName><forename type="first">N</forename><surname>Shusharina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Söderberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Edmunds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Löfman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bortfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiot. Oncol</title>
		<imprint>
			<biblScope unit="volume">146</biblScope>
			<biblScope unit="page" from="37" to="43" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Embracing imperfect datasets: a review of deep learning solutions for medical image segmentation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Tajbakhsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jeyaseelan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page">101693</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Uncertainty-aware contrastive distillation for incremental semantic segmentation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="2567" to="2581" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Dreaming to distill: Data-free knowledge transfer via deepinversion</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8715" to="8724" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Incremental learning meets transfer learning: application to multisite prostate MRI segmentation</title>
		<author>
			<persName><forename type="first">C</forename><surname>You</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.01369</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Self-training for class-incremental semantic segmentation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Van De Weijer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Representation compensation networks for continual semantic segmentation</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Cheng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Unsupervised domain adaptation of black-box source models</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.02839</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Generalizable semantic segmentation via modelagnostic learning and target-specific normalization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.12296</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Normalization in training u-net for 2-D biomedical semantic segmentation</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Z</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robot. Autom. Lett</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1792" to="1799" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Confidence regularized self-training</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5982" to="5991" />
		</imprint>
		<respStmt>
			<orgName>ICCV</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
