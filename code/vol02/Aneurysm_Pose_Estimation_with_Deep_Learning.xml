<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Aneurysm Pose Estimation with Deep Learning</title>
				<funder>
					<orgName type="full">Grand-Est Region</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Youssef</forename><surname>Assis</surname></persName>
							<email>youssef.assis@loria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université de Lorraine</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">LORIA</orgName>
								<address>
									<postCode>54000</postCode>
									<settlement>Nancy</settlement>
									<region>Inria</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Liang</forename><surname>Liao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université de Lorraine</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">LORIA</orgName>
								<address>
									<postCode>54000</postCode>
									<settlement>Nancy</settlement>
									<region>Inria</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Diagnostic and Therapeutic Interventional Neuroradiology</orgName>
								<orgName type="institution" key="instit1">Université de Lorraine</orgName>
								<orgName type="institution" key="instit2">CHRU-Nancy</orgName>
								<address>
									<postCode>54000</postCode>
									<settlement>Nancy</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Université de Lorraine</orgName>
								<address>
									<settlement>Inserm</settlement>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">IADI</orgName>
								<address>
									<postCode>54000</postCode>
									<settlement>Nancy</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fabien</forename><surname>Pierre</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université de Lorraine</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">LORIA</orgName>
								<address>
									<postCode>54000</postCode>
									<settlement>Nancy</settlement>
									<region>Inria</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">René</forename><surname>Anxionnat</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Diagnostic and Therapeutic Interventional Neuroradiology</orgName>
								<orgName type="institution" key="instit1">Université de Lorraine</orgName>
								<orgName type="institution" key="instit2">CHRU-Nancy</orgName>
								<address>
									<postCode>54000</postCode>
									<settlement>Nancy</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Université de Lorraine</orgName>
								<address>
									<settlement>Inserm</settlement>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">IADI</orgName>
								<address>
									<postCode>54000</postCode>
									<settlement>Nancy</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Erwan</forename><surname>Kerrien</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université de Lorraine</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">LORIA</orgName>
								<address>
									<postCode>54000</postCode>
									<settlement>Nancy</settlement>
									<region>Inria</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Aneurysm Pose Estimation with Deep Learning</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="543" to="553"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">02B171A7074A9339E83C20745C78CB55</idno>
					<idno type="DOI">10.1007/978-3-031-43895-0_51</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-23T22:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Object Pose Estimation</term>
					<term>3D YOLO</term>
					<term>Intracranial Aneurysms</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The diagnosis of unruptured intracranial aneurysms from time-of-flight Magnetic Resonance Angiography (TOF-MRA) images is a challenging clinical problem that is extremely difficult to automate. We propose to go beyond the mere detection of each aneurysm and also estimate its size and the orientation of its main axis for an immediate visualization in appropriate reformatted cut planes. To address this issue, and inspired by the idea behind YOLO architecture, a novel one-stage deep learning approach is described to simultaneously estimate the localization, size and orientation of each aneurysm in 3D images. It combines fast and approximate annotation, data sampling and generation to tackle the class imbalance problem, and a cosine similarity loss to optimize the orientation. We evaluate our approach on two large datasets containing 416 patients with 317 aneurysms using a 5-fold cross-validation scheme. Our method achieves a median localization error of 0.48 mm and a median 3D orientation error of 12.27 • C, demonstrating an accurate localization of aneurysms and an orientation estimation that comply with clinical practice. Further evaluation is performed in a more classical detection setting to compare with state-of-the-art nnDetecton and nnUNet methods. Competitive performance is reported with an average precision of 76.60%, a sensitivity score of 82.93%, and 0.44 false positives per case. Code and annotations are publicly available at https://gitlab.inria.fr/yassis/DeepAnePose.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Intracranial aneurysms are abnormal focal dilations of cerebral blood vessels. Their rupturing accounts for 85% of Subarachnoid Hemorrhages (SAH), and is associated with high morbidity and mortality rates <ref type="bibr" target="#b23">[23]</ref>. Early detection and monitoring of Unruptured Intracranial Aneurysms (UIA) has become a problem of increasing clinical importance. Due to its non-invasive nature, 3D time-of-flight Magnetic Resonance Angiography (TOF-MRA) is the most suitable imaging technique for screening. However, detecting aneurysms in TOF-MRA volumes is a costly process that requires radiologists to scroll through different cut planes <ref type="bibr" target="#b7">[7]</ref>. Therefore, an automated method to detect aneurysms and provide immediate appropriate visualization would be a valuable tool to assist radiologists in their clinical routine. We envision a dynamic browsing of cut planes rotating around the main axis of the aneurysm to facilitate the analysis of the aneurysm and the surrounding angioarchitecture. This requires estimating the location and orientation, i.e. the pose, of the aneurysm. This pose has been related to the risk of rupture <ref type="bibr" target="#b13">[13]</ref> and could also be used for image registration <ref type="bibr" target="#b17">[17]</ref>.</p><p>Automated methods for detecting UIAs range from traditional Computer-Aided Detection (CAD) systems using image filtering techniques <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b27">27]</ref>, to advanced deep learning methods based on Convolutional Neural Networks (CNNs). Although 2D and 2.5D methods have been proposed <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b26">26]</ref>, most recent methods are fully 3D patch-based approaches. In 2020, the Aneurysm Detection and SegMentation (ADAM) challenge <ref type="bibr" target="#b25">[25]</ref> compared various detection methods using TOF-MRA data. The class imbalance problem caused by the scarcity of aneurysm voxels inside an image volume, was addressed through loss functions and/or data augmentation. The top-performing method was nnDetection <ref type="bibr" target="#b3">[3]</ref>, which relies on a 3D bounding box representation. nnUNet <ref type="bibr" target="#b9">[9]</ref>, ranked third, uses the UNet <ref type="bibr" target="#b6">[6]</ref> semantic segmentation architecture. Both methods consider large patches as input, which requires significant computing power and large databases for reliable sample modeling. Detection provides localization, but aneurysm orientation is challenging to estimate, due to the noise/artifacts in medical images, annotation burden, with inter-and intra-observer variability, and small size and shape diversity which imply more uncertainty than for larger objects.</p><p>Estimating the pose of organs has been investigated in the literature as a slice positioning problem. A set of slices must be optimally selected relative to the pose of the knee <ref type="bibr" target="#b5">[5,</ref><ref type="bibr" target="#b14">14,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b29">29]</ref>, shoulder <ref type="bibr" target="#b29">[29]</ref>, or brain <ref type="bibr" target="#b4">[4,</ref><ref type="bibr" target="#b10">10,</ref><ref type="bibr" target="#b12">12]</ref>. These organs are single instances of large objects with specific shapes, standard positions and orientations within the images. On the contrary, aneurysms are very small pathologies with unspecific shapes, undefined locations and numbers. These algorithms can be categorized into registration-based and learning-based methods. Registrationbased methods <ref type="bibr" target="#b5">[5,</ref><ref type="bibr" target="#b12">12]</ref> rely on rigid transformations, which limits their application to (quasi-)rigid body parts. Learning-based methods <ref type="bibr" target="#b10">[10,</ref><ref type="bibr" target="#b20">20,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b29">29]</ref> typically consist of a two-stage pipeline. The first stage detects the Regions-of-Interest (ROIs), while the second stage regresses/estimates the object orientation for each ROI. For instance, faster-RCNN <ref type="bibr" target="#b22">[22]</ref> and V-Net <ref type="bibr" target="#b18">[18]</ref> architectures were employed in <ref type="bibr" target="#b29">[29]</ref> to localize and segment the orientation plane, defined by a center location and two unit vectors. However, existing methods are mainly intended for low-resolution images like MR scout scans, and their computational demands increase with high-resolution images. One-stage approaches, such as YOLO <ref type="bibr" target="#b21">[21]</ref>, demonstrate promising performance in object detection with greater flexibility than two-stage approaches.</p><p>In this paper, we introduce a novel one-stage method to simultaneously localize, and estimate the size and the orientation of aneurysms from 3D TOF-MRA images. A fast and approximate annotation is used. To address the class imbalance problem, a small patch approach is combined with dedicated data sampling and generation strategies. We follow a landmark approach to estimate the aneurysm pose, while avoiding rotation discontinuity problems associated with Euler angles and quaternions <ref type="bibr" target="#b30">[30]</ref>. Furthermore, we propose a 3D extension of YOLO architecture, using a cosine similarity loss for the orientation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Materiels and Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Datasets and Data Annotation</head><p>In this work, two TOF-MRA aneurysm datasets were used. The first dataset includes 132 exams (75 female, 57 male) collected at our medical institution between 2015 and 2021 according to the following inclusion criteria: diagnosed unruptured saccular aneurysms smaller than 20 mm, no pre-treated aneurysm or fusiform aneurysm. A single exam was included per patient (i.e. no follow-up exams). All images were acquired using a 3T scanner (GE Discovery MR750w). Acquisition parameters included TR = 28 ms, TE = 3.4 ms, slice thickness= 0.8 mm, and 4 slabs (54 slices/slab), resulting in 512 × 512 × 254 volumes with a 0.47×0.47×0.4mm 3 voxel size. Each DICOM data was anonymized on the clinical site before processing. As per the charter of our university hospital, the anonymous use of imaging data acquired in clinical practice is authorized for research purposes, in accordance with the principle of non-opposition of the patient. Each image contained from one (84/132) to five aneurysms (4 subjects), totaling 206 aneurysms with a mean diameter of 3.97 ± 2.32 mm (range: 0.96-19.63 mm). Most aneurysms were small, with 81 below 3 mm and 77 between 3-5 mm.</p><p>The second dataset is the public aneurysm dataset <ref type="bibr" target="#b7">[7]</ref>, which comprises 412 images. After applying the same inclusion criteria as the in-house dataset, 270 images were selected for analysis. Two expert neuroradiologists reviewed the dataset, identifying 7 additional aneurysms and removing 5 aneurysms as they were simple irregularities on the vessel surface. The resulting images contains 164 aneurysms with similar statistics to the first dataset: mean diameter of 3.74 ± 2.17 mm (range: 1.37-13.64 mm), 66 below 3 mm and 72 between 3-5 mm. Each image contained from 0 (130 healthy subjects) to 3 (3 subjects) aneurysms.</p><p>Previous works on aneurysm detection and segmentation relied on voxel-wise labeling, which is time-consuming and susceptible to intra-and inter-rater variability. To address these limitations, weak annotations using spheres have been recently investigated <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b7">7]</ref>. Similar to <ref type="bibr" target="#b1">[2]</ref>, our annotation involves labeling each aneurysm using two points: the center of the neck (i.e. ostium) and another point along its main axis (i.e. dome). This method provides information about aneurysms location, size, and their orientation (see Fig. <ref type="figure" target="#fig_0">1</ref>). To simplify the placement of the two points in the volume rendering view, we developed a Python extension for the 3D Slicer software <ref type="bibr" target="#b8">[8]</ref>, which provides a real-time visualization of the sphere in the canonical cut planes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Data Sampling and Generation</head><p>Accurate modeling of aneurysm and background properties is crucial for pose estimation tasks. We use small 96 × 96 × 96 voxel patches with an isotropic voxel size of 0.4 mm, resulting in 38.4 mm side length patches. This approach is computationally efficient compared to larger patch methods, such as nnDetection <ref type="bibr" target="#b3">[3]</ref> and nnUNet <ref type="bibr" target="#b9">[9]</ref>. It also allows for the extraction of multiple non-intersecting negative (aneurysm-free) patches from each image for more training data and reliable background modeling. However, this approach introduces a class imbalance problem, as there is only a single positive patch for each aneurysm. To overcome this, we used adapted data sampling strategies. Our first strategy duplicates each positive patch 50 times and applies random distortions at each epoch to synthesize a variety of aneurysm shapes: each control point on a 3 × 3 × 3 lattice enclosing the patch, except the central point, is moved randomly by 3 mm in all 3 space directions, and the distortion field is interpolated using cubic spline interpolation. To guide the model to discriminate between healthy vessels and aneurysms, our second strategy pre-selects 40 non-intersecting negative patches per image, 30 of which are centered on blood vessels by iteratively choosing the brightest voxels as patch centers. Each training epoch used a set composed of all positive patches, completed with random negative patches equally drawn among images (15% of the training set). Random rotations (0 to 180 • ), shifts (0 to 10 mm) and horizontal flips were applied as data augmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Neural Network Architecture</head><p>Inspired by YOLO <ref type="bibr" target="#b21">[21]</ref>, we present a one-stage neural network architecture for aneurysm pose estimation in 3D images. As shown in Fig. <ref type="figure" target="#fig_1">2</ref>, our architecture follows a grid-based approach and divides the input 3D patch (96 × 96 × 96 voxels) into 12 × 12 × 12 = 1728 cells of 8 × 8 × 8 voxels.</p><p>To encode the input patch into feature maps, we use residual convolutional blocks and down-sampling operations. The Localization and Orientation Head splits the encoded feature maps into a grid of 1728 cells using two consecutive convolutional blocks followed by three parallel convolutions. The first convolution generates a confidence probability score indicating whether the cell contains an aneurysm center. For positive cells (i.e. containing an aneurysm center), the second convolution, followed by sigmoid function, predicts the aneurysm center coordinates C = (C x , C y , C z ) relative to the cell size, while the third convolution estimates the aneurysm size and its orientation by calculating the axis vector </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Loss Function</head><p>Due to the grid-based nature of our architecture, there is a high imbalance between the number of negative cells and a very small number of positive cells. Inspired by <ref type="bibr" target="#b21">[21]</ref>, a weighted loss function was employed, which encompasses the sum of terms pertaining to confidence, localization, and orientation estimation.</p><p>To optimize the detection confidence, we used the binary cross-entropy (BCE) loss function for both positive (BCE P ) and negative (BCE N ) cells. To prioritize identifying aneurysms over background, we weighted the negative cell term by half the number of positive cells (#P ) in the batch (Eq. 1). Aneurysm localization and dimensions are assessed using mean squared error (MSE) (Eq. 2). Orientation estimation is enforced through the cosine similarity of v (Eq. 3). These last two terms are only computed on positive cells with a weight of 5 to account for the limited number of such cells.</p><formula xml:id="formula_0">⎧ ⎪ ⎨ ⎪ ⎩ Confidence = BCE P + 0.5 × #P × BCE N (1) Localization = 5 × MSE(C x , C y , C z , v x , v y , v z ) (0 for negative cells) (2) Orientation = 5 × (1 -Cosine Similarity( v)) (0 for negative cells) (3)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Implementation Details</head><p>We implemented our method using PyTorch framework (1.10.0). The model has approximately 28 million parameters, that were optimized using the stochastic gradient descent algorithm. The hyper-parameters were determined using a subset of the in-house dataset: 200 epochs, balanced batch sampling technique between negative and positive patches, batch size of 32, and initial learning rate of 10 -2 . Each input volume was normalized using z-score normalization. Training and inference were performed on an NVIDIA RTX A6000 GPU with 48 GB of memory. During inference, a patch reconstruction technique is used to predict the location and orientation of aneurysms in the entire volume. The original volume is split into patches with an isotropic voxel resolution of 0.4 mm. To mitigate border effects caused by convolutions, a 16 voxel overlap is considered between adjacent patches. Predictions are made for each patch and converted back to the original volume resolution: a pose is kept only if the predicted center is inside the central 64 × 64 × 64 part of the patch. Non-Maximum Suppression (NMS) is used to eliminate overlapping predictions, considered as spheres (see Sect. 2.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Evaluation Metrics</head><p>For the pose estimation task, our method was evaluated based on two standard metrics. First, the Euclidean distance (in mm) was measured between the predicted aneurysm center (C) and its corresponding ground truth (GT). The second metric computes the angular difference (in degrees) between the predicted aneurysm orientation vector ( v) and its corresponding GT.</p><p>For the detection task, our evaluation was based on the Intersection-over-Union (IoU) between the predicted and GT spheres at a threshold of 10% <ref type="bibr" target="#b3">[3,</ref><ref type="bibr" target="#b16">16]</ref>. A GT sphere with an IoU score above 10% was tagged as a true positive (TP), else it was a false negative (FN). A false positive (FP) was counted for each predicted sphere with no IoU score above 10%. We report the Average Precision metric (AP 0.1 ), as well as the sensitivity score (Sensitivity 0.5 ) and the number of false positives per case (FPs/case 0.5 ), both at a default 50% confidence threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Pose Estimation</head><p>We conducted 5-fold cross-validation separately on two large datasets (see Sect. 2.1) to evaluate the performance of our method for aneurysm pose estimation. Each dataset was randomly split into five subsets, with 25 or 26 patients per subset for the in-house dataset and 54 patients per subset for dataset <ref type="bibr" target="#b7">[7]</ref>. The number of aneurysms and mean aneurysm size for each subset were as follows: (In-house) aneurysms: 47, 32, 45, 38, and 44; size: 4.15 mm, 3.61 mm, 3.88 mm, 3.85 mm, and 4.25 mm; (Dataset <ref type="bibr" target="#b7">[7]</ref>) aneurysms: 32, 33, 43, 28, and 28; size: 3.56 mm, 3.19 mm, 4.05 mm, 4.21 mm, and 3.70 mm. We trained five models for each dataset, using four subsets for training and one subset for testing. This resulted in, for each fold, around 9655 training patches for the in-house dataset and 7595 training patches for dataset <ref type="bibr" target="#b7">[7]</ref>.</p><p>The results on both datasets are shown in Table <ref type="table" target="#tab_0">1</ref>. In the in-house dataset, the median (mean ± std) errors were 0.49 mm (0.54 mm±0.32) for the aneurysm  center location; and 11.91 • (15.26 • ±10.92) for its orientation. In dataset <ref type="bibr" target="#b7">[7]</ref>, the median errors were 0.48 mm (0.51 mm±0.26) for the center location; and 12.27 • (14.58 • ±10.53), for the orientation. Figure <ref type="figure" target="#fig_2">3</ref> illustrates that the pose computed by our method is sufficiently accurate for clinical use. It was used to display a cut plane through aneurysms with diverse shapes and sizes. Figure <ref type="figure" target="#fig_2">3a</ref> reports on the case of a small aneurysm (size 1.97 mm). The pose was estimated with 8.20 • orientation error and 0.82 mm center location error. This accuracy, especially on the location, makes it possible to infer a cut plane through the aneurysm that is fit for immediate clinical analysis. Similarly, the case of a larger, spherical-shaped aneurysm (size 7.69 mm) is shown in Fig. <ref type="figure" target="#fig_2">3b</ref>. Our method estimated the pose with an orientation error of 10.62 • and center location error of 0.72 mm. Larger orientation errors occurred in rare cases like the aneurysm in Fig. <ref type="figure" target="#fig_2">3c</ref> (size 3.52 mm). We related such errors (here 41.54 • ) to the complex shape of the aneurysm, that implied annotation uncertainty for the axis orientation. Besides, our method was able to detect some aneurysms that were missed in the initial annotation by radiologists. Figure <ref type="figure" target="#fig_2">3d</ref> shows such an aneurysm detection (size 3.50 mm).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Object Detection</head><p>We also evaluated the effectiveness of our method on the classical detection task by comparing it with two public and fully-automated state-of-the-art baselines, nnDetection <ref type="bibr" target="#b3">[3]</ref> and nnUNet <ref type="bibr" target="#b9">[9]</ref>. nnDetection is based on an improved RetinaNet architecture, which has demonstrated superior performance compared to SSD Table <ref type="table">2</ref>. The results (mean ± std) of aneurysm detection task using dataset <ref type="bibr" target="#b7">[7]</ref>. The results of our method on the in-house dataset are added for comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>AP0.1 (%) Sensitivity0.5 (%) FPs/case0. and Faster RCNN <ref type="bibr" target="#b15">[15]</ref>. We used 5-fold cross-validation on the public dataset <ref type="bibr" target="#b7">[7]</ref> to guarantee the reproducibility of the results. The 5 models trained in Sect. 3.1 were used to assess the performance of our method. To ensure a fair comparison, we converted the output of nnDetection and nnUNet to spherical representations. Specifically, for nnDetection, we transformed the predicted 3D bounding boxes into spheres using the largest extent of the box as the sphere diameter. For nnUNet, we fitted one sphere on each connected component from the segmented voxel image. The diameter was computed as the maximum distance between two voxel locations, and the confidence score as the maximum predicted voxel value.</p><p>As shown in Table <ref type="table">2</ref>, our method exhibited competitive performance compared to the two baselines achieving an AP 0.1 score of 76.60% (nnDetection: 73.68% and nnUNet: 72.46%). Additionally, our method demonstrated a good trade-off between sensitivity and FP/case, with a Sensitivity 0.5 score of 82.93% associated with 0.44 FPs/case 0.5 . In comparison, based on Free-response Receiver Operating Characteristic (FROC) curves, nnUNet achieves a maximum sensitivity of 81.90% with a higher FP/case of 1.04, while nnDetection achieves the same sensitivity of 82.93% but with a higher FP/case of 0.51.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we proposed a novel one-stage deep learning approach for aneurysm pose estimation from TOF-MRA images, which can also be used for the classical detection task. It was evaluated using two large datasets, including a public one <ref type="bibr" target="#b7">[7]</ref>. The results demonstrate the effectiveness of our proposed method in both tasks.</p><p>In the pose estimation task, our method achieved good and similar performance on both datasets, accurately estimating the pose of aneurysms with diverse shapes and sizes. Rare errors in orientation were primarily due to small aneurysms and sometimes complex aneurysm shapes, leading to weak and uncertain GT annotations. Specifically, on the public dataset <ref type="bibr" target="#b7">[7]</ref>, the median orientation error was 14.79 • for small aneurysms (&lt;3 mm), 11.49 • for medium-sized aneurysms (3-5 mm), and 10.69 • for large aneurysms. A current work consists in giving a better clinical definition of the aneurysm axis to reduce this error.</p><p>In the aneurysm detection task, our proposed method exhibited promising performance compared to two state-of-the-art baselines, nnDetection <ref type="bibr" target="#b3">[3]</ref> and nnUNet <ref type="bibr" target="#b9">[9]</ref>, with an average precision score of 76.60% and a good balance between sensitivity and FPs/case scores. Besides, these baselines are more computationally demanding compared to our method, which is based on small nonintersecting patches. Out of the 164 aneurysms in dataset <ref type="bibr" target="#b7">[7]</ref>, half of the 28 FN aneurysms had a size below 3 mm. Part of these misses are related to the annotation uncertainty on such aneurysms, which are difficult to diagnose in TOF-MRA <ref type="bibr" target="#b11">[11]</ref>. Nevertheless, our future work will address this specific class of aneurysms, including the management of multiple annotators for finer uncertainty modeling.</p><p>Our method represents a promising step towards automated aneurysm pose estimation and detection, offering several advantages over existing approaches. It demonstrated multi-task learning capabilities by simultaneously localizing, and estimating the size and the orientation of aneurysms in a single forward pass. Preliminary qualitative tests are hopeful indicators for its clinical utility.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Fast aneurysm annotation: 2 points (P 1, P 2) define a sphere. The ground truth pose is inferred as the center C = (P 1 + P 2)/2 and axis vector v = P 2 -C.</figDesc><graphic coords="4,164,79,53,87,94,75,79,84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Our aneurysm pose estimation architecture. 2D feature maps are used only for visualization purposes; their actual sizes in 3D are displayed.</figDesc><graphic coords="5,60,96,54,17,330,64,144,55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Qualitative results on dataset [7]: predicted (blue) and GT (green) landmarks. Each reformatted cut plane was determined by rotating around the aneurysm axis passing through the predicted landmarks. The orientation error is (a) 8.2 • , (b) 10.62 • , (c) 41.54 • , (d) unlabelled aneurysm detected by our method. (Color figure online)</figDesc><graphic coords="7,55,98,142,28,340,12,96,64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Pose estimation performance evaluation of our method.</figDesc><table><row><cell>Datasets</cell><cell cols="2">Center error (mm)</cell><cell></cell><cell>Orientation error ( • )</cell></row><row><cell></cell><cell cols="3">Mean ± std Median Range</cell><cell cols="2">Mean ± std Median Range</cell></row><row><cell>In-house</cell><cell>0.54 ± 0.32</cell><cell>0.49</cell><cell cols="2">0.05-1.74 15.26 ± 10.92 11.91</cell><cell>0.21 -68.35</cell></row><row><cell cols="2">Dataset [7] 0.51 ± 0.26</cell><cell>0.48</cell><cell cols="2">0.05-1.43 14.58 ± 10.53 12.27</cell><cell>1.05-68.30</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgment. The authors would like to acknowledge the financial support provided by the <rs type="funder">Grand-Est Region</rs> and the <rs type="institution">University Hospital (CHRU) of Nancy, France</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Automated computerized scheme for detection of unruptured intracranial aneurysms in three-dimensional magnetic resonance angiography1</title>
		<author>
			<persName><forename type="first">H</forename><surname>Arimura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Korogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acad. Radiol</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1093" to="1104" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An efficient data strategy for the detection of brain aneurysms from mra with deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Assis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pierre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Anxionnat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kerrien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DGM4MICCAI/DALI -2021</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Engelhardt</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">13003</biblScope>
			<biblScope unit="page" from="226" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Cham</forename><surname>Springer</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-88210-5_22</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-88210-522" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">nnDetection: a selfconfiguring method for medical object detection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Baumgartner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Jäger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Isensee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Maier-Hein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87240-3_51</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87240-351" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12905</biblScope>
			<biblScope unit="page" from="530" to="539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Comparison of manual and automatic section positioning of brain MR images</title>
		<author>
			<persName><forename type="first">T</forename><surname>Benner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Wisco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Van Der Kouwe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fischl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">239</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="246" to="254" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Automated planning of MRI scans of knee joints</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bystrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Dries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Heese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Van Muiswinkel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization and Image-Guided Procedures</title>
		<imprint>
			<publisher>SPIE</publisher>
			<date type="published" when="2007">2007. 2007</date>
			<biblScope unit="volume">6509</biblScope>
			<biblScope unit="page" from="1023" to="1031" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">3D U-Net: learning dense volumetric segmentation from sparse annotation</title>
		<author>
			<persName><forename type="first">Ö</forename><surname>Abdulkadir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lienkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-46723-8_49</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-46723-8" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2016</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Ourselin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Joskowicz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Sabuncu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Unal</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Wells</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">9901</biblScope>
			<biblScope unit="page">49</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Towards automated brain aneurysm detection in TOF-MRA: open data, weak labels, and anatomical knowledge</title>
		<author>
			<persName><forename type="first">T</forename><surname>Di Noto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Marie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tourbier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroinformatics</title>
		<imprint>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">3D slicer as an image computing platform for the quantitative imaging network</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fedorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Beichel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<ptr target="https://slicer.org" />
	</analytic>
	<monogr>
		<title level="j">Magnetic Resonance Imaging</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">22770690</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Isensee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Kohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Maier-Hein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="211" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Automatic identification of landmarks for standard slice positioning in brain MRI</title>
		<author>
			<persName><forename type="first">A</forename><surname>Iskurt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Becerikli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mahmutyazicioglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Magn. Reson. Imaging</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="499" to="510" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Features of &quot;false positive&quot; unruptured intracranial aneurysms on screening magnetic resonance angiography</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">238597</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">On-line automatic slice positioning for brain MR imaging</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Van Der Kouwe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="222" to="230" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Unruptured intracranial aneurysms and the assessment of rupture risk based on anatomical and morphological factors: sifting through the sands of data</title>
		<author>
			<persName><forename type="first">R</forename><surname>Lall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Eddleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Bendok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurosurg. Focus</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Clinical evaluation of automated scan prescription of knee MR images</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Lecouvet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Claus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Denolin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Vande Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Magnetic Reson. Imaging Official J. Inter. Soc. Magnetic Reson. Med</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="141" to="145" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Focal loss for dense object detection</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Maier-Hein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.01653</idno>
		<title level="m">Metrics reloaded: Pitfalls and recommendations for image analysis validation</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Automatic pose initialization for accurate 2D/3D registration applied to abdominal aortic aneurysm endovascular repair</title>
		<author>
			<persName><forename type="first">S</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Liao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image-Guided Procedures, Robotic Interventions, and Modeling</title>
		<imprint>
			<biblScope unit="volume">8316</biblScope>
			<biblScope unit="page" from="243" to="250" />
			<date type="published" when="2012">2012. 2012</date>
			<publisher>SPIE</publisher>
		</imprint>
	</monogr>
	<note>Medical Imaging</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">V-net: fully convolutional neural networks for volumetric medical image segmentation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Milletari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Ahmadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fourth International Conference on 3D Vision (3DV)</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="565" to="571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep neural network-based computerassisted detection of cerebral aneurysms in MR angiography</title>
		<author>
			<persName><forename type="first">T</forename><surname>Nakao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hanaoka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nomura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Magnetic Resonance Imaging</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="948" to="953" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A Steering engine: learning 3-D anatomy orientation using regression forests</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Reda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">S</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-24574-4_73</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-24574-473" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2015</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hornegger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">9351</biblScope>
			<biblScope unit="page" from="612" to="619" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.02767</idno>
		<title level="m">Yolov3: an incremental improvement</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Faster R-CNN: towards real-time object detection with region proposal networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep learning-based detection of intracranial aneurysms in 3D TOF-MRA</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sichtermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Faron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sijben</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Neuroradiol</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="32" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for the detection and measurement of cerebral aneurysms on magnetic resonance angiography</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Stember</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Stember</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Digit. Imaging</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="808" to="815" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Comparing methods of detecting and segmenting unruptured intracranial aneurysms on TOF-MRAs: the ADAM challenge</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Timmins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">C</forename><surname>Van Der Schaaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bennink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">238</biblScope>
			<biblScope unit="page">118216</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep learning for MR angiography: automated detection of cerebral aneurysms</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ueda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nishimori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="187" to="194" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Computer-aided detection of intracranial aneurysms in MR angiography</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Blezek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">T</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Digit. Imaging</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="86" to="95" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Robust automatic knee MR slice positioning through redundant and hierarchical anatomy detection</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dewan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Harder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">S</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2087" to="2100" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep learning solution for medical image localization and orientation detection</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page">102529</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">On the continuity of rotation representations in neural networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5745" to="5753" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
