<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PLD-AL: Pseudo-label Divergence-Based Active Learning in Carotid Intima-Media Segmentation for Ultrasound Images</title>
				<funder ref="#_Vd3VGfm">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_Bx9he26">
					<orgName type="full">Key Research Project</orgName>
				</funder>
				<funder ref="#_4Hdqkdw">
					<orgName type="full">National Key Research and Development Programme of China</orgName>
				</funder>
				<funder ref="#_QRQe5P6">
					<orgName type="full">Research Initiation Project</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yucheng</forename><surname>Tang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Mathematical Sciences</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Zhejiang Lab</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yipeng</forename><surname>Hu</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Centre for Medical Image Computing and Wellcome/EPSRC Centre for Interventional &amp; Surgical Sciences</orgName>
								<orgName type="institution">University College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jing</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Zhejiang Lab</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hu</forename><surname>Lin</surname></persName>
							<email>hxlin@zhejianglab.edu.cn</email>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Department of Endocrinology</orgName>
								<orgName type="department" key="dep2">Zhejiang University School of Medicine</orgName>
								<orgName type="institution">Children&apos;s Hospital</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiang</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Mathematical Sciences</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ke</forename><surname>Huang</surname></persName>
							<email>kehuang@zju.edu.cn</email>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Department of Endocrinology</orgName>
								<orgName type="department" key="dep2">Zhejiang University School of Medicine</orgName>
								<orgName type="institution">Children&apos;s Hospital</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hongxiang</forename><surname>Lin</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Zhejiang Lab</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">PLD-AL: Pseudo-label Divergence-Based Active Learning in Carotid Intima-Media Segmentation for Ultrasound Images</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="57" to="67"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">D2C7243E36473E73BB37055930D0A509</idno>
					<idno type="DOI">10.1007/978-3-031-43895-0_6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-23T22:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Carotid intima-media complex</term>
					<term>active learning</term>
					<term>image segmentation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Segmentation of the carotid intima-media (CIM) offers more precise morphological evidence for obesity and atherosclerotic disease compared to the method that measures its thickness and roughness during routine ultrasound scans. Although advanced deep learning technology has shown promise in enabling automatic and accurate medical image segmentation, the lack of a large quantity of high-quality CIM labels may hinder the model training process. Active learning (AL) tackles this issue by iteratively annotating the subset whose labels contribute the most to the training performance at each iteration. However, this approach substantially relies on the expert's experience, particularly when addressing ambiguous CIM boundaries that may be present in real-world ultrasound images. Our proposed approach, called pseudo-label divergence-based active learning (PLD-AL), aims to train segmentation models using a gradually enlarged and refined labeled pool. The approach has an outer and an inner loops: The outer loop calculates the Kullback-Leibler (KL) divergence of predictive pseudo-labels related to two consecutive AL iterations. It determines which portion of the unlabeled pool should be annotated by an expert. The inner loop trains two networks: The student network is fully trained on the current labeled pool, while the teacher network is weighted upon itself and the student one, ultimately refining the labeled pool. We evaluated our approach using both the Carotid Ultrasound Boundary Study dataset and an in-house dataset from Children's Hospital, Zhejiang University School of Medicine. Our results demonstrate that our approach outperforms state-of-the-art AL approaches. Furthermore, the visualization results show that our approach less overestimates the CIM area than the rest methods, especially for severely ambiguous ultrasound images at the thickness direction.</p><p>Y. Tang-This work was performed when Yucheng Tang was visiting Zhejiang Lab as an intern.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Carotid intima-media (CIM) segmentation has been widely applied in clinical practice, providing a diagnostic basis for atherosclerotic disease (one of the complications of obesity). To identify the contour of the intima-media, i.e., the structure between the lumen-intima (LI) and the media-adventitia (MA), one of the available solutions is deep learning-based medical image segmentation for CIM. Currently, this CIM segmentation approach faces the challenges of lack of largequantity images, high-quality labels from ultrasound experts, and a mixture of clear and ambiguous CIM areas in carotid ultrasound images.</p><p>Semi-supervised learning recently applies novel frameworks to a general segmentation task <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref>. In particular, the combination of consistency regularization and pseudo-labeling utilizes unlabeled data to partially address the lack-of-label issue <ref type="bibr" target="#b4">[5]</ref>. A different strategy to efficiently utilize labeling effort is active learning (AL), which can iteratively select a subset of unlabeled data for annotation by experts, but still reach a model performance otherwise requiring a much larger training set. AL has been widely applied to image classification <ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref>, semantic segmentation <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref> and medical image segmentation <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>. These methods have effectively improved accuracy through experts' involvement. However, carotid ultrasound images are user-end protocol dependent, and with high variability in quality, real-world labels on ultrasound images generally share the same characteristics in high variability. Therefore, after testing several state-of-the-art AL methods, we would like to incorporate methodologies from semi-supervised learning designed to extract predictive information from unlabeled data, and between labeled and unlabeled data, for AL.</p><p>In this work, we propose pseudo-label divergence-based active learning (PLD-AL) to obtain accurate CIM segmentation contributing to the clinical diagnosis of obesity and atherosclerotic disease. As shown in Fig. <ref type="figure" target="#fig_0">1</ref>, unlike the conventional AL framework that utilizes one machine learning model, PLD-AL is composed by two networks: the student network is fully trained on the current labeled pool, and the teacher network is weighted upon previous itself and the student one. We use divergence, which measures the distance between two model predictions, to select data for annotation. Furthermore, we use the teacher network to refine the labels to reduce the noise of labels and improve the effectiveness of the next network optimization stage.</p><p>Our contributions are as follows: we propose PLD-AL, which aims to train segmentation models using a gradually enlarged and refined labeled pool. First, we automatically select and annotate large divergence data between the current and previous AI models, facilitating fast convergence of the AL model to most sound data in the unlabeled pool. Second, we propose a strategy to refine the labels in the labeled pool alternatingly with the proposed label-divergence-based AL algorithm, which improves the robustness compared to the conventional AL approach. We conducted experiments to demonstrate that our method yielded competitive performance gains over other AL methods. Finally, we applied the trained model to a real-world in-house hospital dataset with noisy labels and obtain accurate CIM segmentation results. We release our code at https:// github.com/CrystalWei626/PLD AL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>Section 2.1 establishes mathematical formulation on the main task of CIM segmentation in our AL framework. Our proposed AL approach has two loops: in Sect. 2.2, the outer loop implements progressive annotation on the automatically selected unlabeled pool; in Sect. 2.3, the inner loop trains the neural networks on the labeled pool and subsequently refines it through a feedback routine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Mathematical Notations and Formulation</head><p>Denote x ∈ R I×J a carotid ultrasound image and y ∈ R I×J the corresponding CIM mask. Let D L = X L ×Y L and X U be the initial labeled and unlabeled pools, where X L is the carotid ultrasound image set, and Y L is the corresponding label set. We aim to improve generalization ability of the AI model by selecting the most informative data in X U and delivering them to an expert for annotation.</p><p>We propose a novel AL framework: PLD-AL for CIM segmentation, as illustrated in Fig. <ref type="figure" target="#fig_0">1</ref> and Algorithm 1. First, AI models are trained on D L and used to refine Y L . Then, the AI models select data from X U for expert to annotate, forming a new set of labeled data. Finally, we update D L and X U and use new D L to train the same AI models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1: PLD-AL</head><p>1 Input: Initial labeled pool DL = XL × YL; Unlabeled pool XU ; Judgment threshold τ ; Refining threshold λ; 2 Initialize θS and θT ;</p><formula xml:id="formula_0">3 for t = 1, • • • T do 4 θ (0) T ← θT ; θ (0) S ← θS; 5 for k = 1, • • • , K do 6 θ (k) S := Opt(θ (k-1) S ; DL, lr); Optimize θ (k) S on DL 7 θ (k) T := αθ (k) S + (1 -α)θ (k-1) T ; Update θ (k) T by EMA 8 M (k) = mean (x,y)∈D L IoU(y, F (x|θ (k) S )); Calculate mIoU 9 if k &gt; K1 then 10 M = argmin k l=1 M -M (l) 2 2 ;</formula><p>Fit the mIoU curve In each AL iteration, we use a mean-teacher architecture as the backbone of AL. The student and the teacher networks, respectively parameterized by θ S and θ T , share the same neural network architecture F , which maps the carotid ultrasound image x ∈ R I×J to the extended three-dimensional CIM mask probability p ∈ R I×J×2 , whose 3rd-dimensional component p ij ∈ R 2 denotes the softmax probability output for binary classification at the pixel (i, j). We use the divergence between pseudo-labels generated by student and teacher networks to assist in selecting data for the expert to annotate.</p><formula xml:id="formula_1">11 if M (k) -M (k -1) &lt; τ then 12 for x ∈ XL, i ∈ {1, 2, ...I}, j ∈ {1, 2, ...J} do 13 pij = F (x(i, j)|θ (k) T ); Predict on teacher network 14 y(i, j) = argmax{pij} if max pij &gt; λ; Refine YL 15 θS ← θ (k) S , θT ← θ (k) T ; 16 break; 17 d(x) = meani,jDivKL(x(i, j), θS, θT ), x ∈ XU ; Compute KL divergence</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Outer Loop: Divergence Based AL</head><p>The outer loop is an AL cycle that selects data for the expert to annotate according to the divergence between the predictions of the student and teacher networks. First, we initialize θ S and θ T . We complete the inner loop proposed in Sect. 2.3, and obtain the trained parameters for the student and teacher networks. Then, we select n data from X U for the expert to annotate. We suggest using the Kullback-Leibler (KL) divergence to assist in selecting data, as shown in Eq. ( <ref type="formula" target="#formula_2">1</ref>):</p><formula xml:id="formula_2">Div KL (x(i, j), θ S , θ T ) = 2 c=1 F (x(i, j)|θ T ) log F (x(i, j)|θ T ) F (x(i, j)|θ S ) . (<label>1</label></formula><formula xml:id="formula_3">)</formula><p>We consider data prediction uncertainty as a decisive metric for data selection.</p><p>It is deduced that the KL divergence between the output of the primary and the auxiliary models in a dual-decoder architecture can approximate the prediction uncertainty <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref>. We compute the KL divergence scores d(x) = mean i,j Div KL (x(i, j), θ S , θ T ) of the data in X U . Let X A be the subset that contains data x in X U corresponding to the top-n largest d(x) values (denoted by TOP n d(x)). With this, we can next obtain the label set Y A in terms of X A by means of the expert's annotates and the required post-processing step; see Sect. 3.1 for details. Lastly, we add the selected dataset with its label set X A × Y A into D L and delete X A from X U . We repeat the above steps until reaching the maximum number of AL iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Inner Loop: Network Optimization and Label Refinement</head><p>The inner loop trains the neural networks by the labeled pool and refines noisy labels through a feedback routine. In the k th epoch of the inner loop, we first use the last labeled pool D L to optimize the training parameter θ (k) S by minibatch stochastic gradient descent. The loss function consists of a supervised loss L sup between labels and predictions of the student model, and a consistency loss L con between the predictions of the student and the teacher models. These can be implemented using the cross-entropy loss and the mean squared error loss, respectively. Then, we update θ (k)</p><p>T by exponential moving average (EMA) with a decay rate α as Eq. (2):</p><formula xml:id="formula_4">θ (k) T = αθ (k) S + (1 -α)θ (k-1) T . (<label>2</label></formula><formula xml:id="formula_5">)</formula><p>We refine noisy labels based on the idea that the fitness soars sharply at first but slows down after the model begins to fit noise <ref type="bibr" target="#b14">[15]</ref>. We interrupt the model training before it begins to fit noise, then refine the labels utilizing the current network output. We calculate the model fitness via a series of the intersection over union (mIoU) <ref type="bibr" target="#b15">[16]</ref> scores sampled at every training epoch. To estimate the ratio of change of the model fitness, we fit the mIoU curve M(k) via e.g., the exponential regression formed in Eq. (3) when the length of mIoU series is larger than a designated parameter</p><formula xml:id="formula_6">K 1 ∈ N + : M(k) = a(1 -exp{-b • k c }),<label>(3)</label></formula><p>where a, b, and c are the fitting parameters to be determined by least squared estimate. Then we calculate the ratio of change of the model fitness γ k via the derivative of the mIoU curve M (k):</p><formula xml:id="formula_7">γ k = M (k) -M (k -1).</formula><p>When training stops at this epoch k satisfying γ k &lt; τ (τ is a judgment threshold), we lastly predict the CIM mask probability p ij = F (x(i, j)|θ</p><formula xml:id="formula_8">(k)</formula><p>T ) via the teacher network for each pixel at (i, j) and update the noisy label y(i, j) in Y L if max p ij &gt; λ (λ is a refining threshold).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experiment Settings</head><p>Implementation Details. We used the PyTorch platform (version 1.13.1) to implement our method. And we adapted the same UNet++ <ref type="bibr" target="#b16">[17]</ref> structures as the encoding-decoding structures for the student and the teacher networks. We implemented 1000 training iterations with a total mini-batch size of 14 and initial batch size of labeled data of 2 on an Nvidia GeForce RTX 3070 GPU with 8192 MB of memory (Nvidia, Santa Clara, CA, United States). Since the number of labeled data increases after completing each AL iteration, the batch size of labeled data should increase by 2 synchronously to keep the total epoch num unchanged. We used stochastic gradient descent (SGD) as the optimizer with the parameter settings: momentum (0.9) and weight decay (0.0001). We set EMA decay rate α = min{1 -1/(iter + 1), 0.99}, where iter is the current training iteration number. 2021 regions of interest (ROI) of size 256 × 128 were cropped from original carotid ultrasound images for model training using template matching technique <ref type="bibr" target="#b17">[18]</ref>. We set the number of AL iterations, fixed labeling budget, initial labeled and unlabeled data, and the test data as 5, 200,159, 1857, and 1204, respectively. During each annotation phase, experts manually marked the CIM boundaries with scatters and we subsequently generated the complete CIM masks via the Akima interpolation method <ref type="bibr" target="#b18">[19]</ref>. θ S and θ T was initialized by the pre-train model<ref type="foot" target="#foot_0">1</ref> on ImageNet <ref type="bibr" target="#b19">[20]</ref>. At our best practice, we chose the hyper-parameters λ = 0.8, τ = 0.005 and K 1 = 1.</p><p>Dataset. We employed the publicly available Carotid Ultrasound Boundary Study (CUBS) dataset<ref type="foot" target="#foot_1">2</ref>  <ref type="bibr" target="#b20">[21]</ref> and the in-house dataset acquired at Children's Hospital, Zhejiang University School of Medicine. The CUBS dataset contains ultrasound images of the left and right carotid arteries from 1088 patients across two medical centers and three manual annotations of LI and MA boundaries by experts. According to the description of these annotations in the dataset specification, the analytic hierarchy process (AHP) <ref type="bibr" target="#b21">[22]</ref> was adapted to weigh the three expert's annotations to obtain accurate labels for testing. We randomly performed morphological transformations (dilation and erosion) by OpenCV <ref type="bibr" target="#b22">[23]</ref> on the accurate labels to generate noisy labels for training. The in-house dataset comes from 373 patients aged 6-12, with 2704 carotid ultrasound images. We picked 350 images with visible CIM areas and applied the model trained on CBUS to CIM segmentation. The data acquisition and the experimental protocol have been approved by the institutional review board of Children's Hospital, Zhejiang University School of Medicine.</p><p>Table <ref type="table">1</ref>. Quantitative results of performance comparison, the metrics were calculated over the test dataset and took the mean. Bold font highlights the optimal performance except for the upper limit. The asterisk * denotes p &lt; 0.001 compared with the rest methods. Evaluation Metrics. We utilized dice coefficient (Dice) <ref type="bibr" target="#b23">[24]</ref>, intersection over union (IoU) <ref type="bibr" target="#b15">[16]</ref>, average surface distance (ASD), 95% covered Hausdorff distance (95HD) <ref type="bibr" target="#b24">[25]</ref>, and the average training time of 5 AL iterations as evaluation metrics of the CIM segmentation performance compared to the generated ground truth on the unseen test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Performance Comparison</head><p>We evaluated the performance of AL methods on the CIM segmentation task using the CUBS dataset.</p><p>Baselines. We compared our method to other AL methods, including AL methods with query strategy based on random selection (Random), entropy increase (Entropy) <ref type="bibr" target="#b25">[26]</ref>, prediction confidence (Confidence) <ref type="bibr" target="#b11">[12]</ref>, CoreSet <ref type="bibr" target="#b26">[27]</ref> and predicted probability diverse contexts (CDAL) <ref type="bibr" target="#b27">[28]</ref>. All of the backbones of these baseline methods are fully supervised models. Furthermore, we trained a supervised model by the fully labeled pool with accurate labels yielding an upper limit of generalization ability. We compared this upper limit to the performance of all the methods.</p><p>Table <ref type="table">1</ref> illustrates the quantitative results of different methods on the test dataset. It shows that our method based on the KL divergence query strategy improves the mean generalization metrics (Dice, IoU, ASD, and 95HD) compared with other AL methods. In particular, it significantly (two-tailed Wilcoxon signed-rank test with p &lt; 0.001) outperforms the others in terms of any metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Ablation Study</head><p>We conducted ablation study on the CUBS dataset to demonstrate the importance of the label refinement module proposed in Sect. 2.3. We canceled the label refinement module and substituted the label refinement module with confidence learning (CL) for noise label correction <ref type="bibr" target="#b28">[29]</ref>.</p><p>Table <ref type="table">2</ref>. Quantitative results of ablation study, the metrics were calculated over the test dataset and took the mean. The abbreviations, Refine and CL, represent the label refinement module and confidence learning <ref type="bibr" target="#b28">[29]</ref>, respectively. Bold font highlights the optimal performance except for the upper limit. The asterisk * denotes p &lt; 0.001 compared with the rest methods.  Table <ref type="table">2</ref> illustrates the results of ablation study experiment. Our method substantially outperforms the method without the label refinement module and slightly outperforms the method with CL. In particular, it significantly (twotailed Wilcoxon signed-rank test with p &lt; 0.001) outperforms the others in terms of all the metrics. Moreover, the training time of our method is significantly reduced compared to CL since CL needs to estimate the uncertainty during training to correct the noisy data smoothly, which leads to more computational cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Application on In-house Dataset</head><p>We applied the teacher network trained in Sect. 3.2 to the in-house dataset acquired at a pediatric hospital. Figure <ref type="figure" target="#fig_2">2</ref> visualizes three example images with different CIM area qualities (clear, mildly ambiguous, severely ambiguous). Qualitatively, the generalization ability of the model trained by our method is much better than those trained by other methods, regardless of image quality. Moreover, as shown in Fig. <ref type="figure" target="#fig_2">2</ref>, Random over-estimates the CIM area, while CoreSet, CDAL, and our method produces more conservative results but lost continuity in the severely ambiguous image. Quantitatively, the mean Dice, IoU, ASD, and 95HD of our method are 79.20%, 66.99%, 1.92 voxels, and 6.12 voxels, respectively, indicating a small but rational generalization loss on the in-house data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We propose a novel AL framework PLD-AL, by training segmentation models using a gradually enlarged and refined labeled pool to obtain accurate and efficient CIM segmentation. Compared with other AL methods, it achieves competitive performance gains. Furthermore, we applied the trained model to an in-house hospital dataset and obtained accurate CIM segmentation results. In the future, we will extend our approach to subsequently calculate CIM thickness and roughness for clinical evaluation of obesity or atherosclerotic disease. We will also investigate the robustness of the proposed method in terms of inter-expert variations and noisy annotation labels. Our approach merely involves one expert in the loop, which may potentially be sensitive to the expert's experience. Multiple experts may consider minimizing inter-reader differences during human-AI interactive labeling <ref type="bibr" target="#b29">[30]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. (a) Conventional AL that trains a machine learning model to select an unlabeled subset for an expert to annotate. (b) We propose a novel AL framework to progressively annotate data by selecting top-n largest divergence between student and teacher network predictions. Additionally, such a framework can also refine the labeled data assumed to be noisy.</figDesc><graphic coords="3,58,98,53,87,334,48,145,84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>18 XA</head><label>18</label><figDesc>= arg x∈X U TOPnd(x); Select unlaleled data 19 YA = {y = Expert(x) : x ∈ XA}; Annotate by expert 20 DA = XA × YA; DL ← DL DA; XU ← XU \ XA; Update DL, XU 21 Output: DL; θT</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Qualitative results of application study. It shows the visualization of CIM segmentation on input images with clear, mildly ambiguous, and severely ambiguous CIM areas, respectively. The images are chosen from the in-house dataset. We used the model with the best quantitative results in Sect. 3.2 to generate the masks. The green, red, and blue masks represent segmented true positive, false positive, and false negative, respectively.</figDesc><graphic coords="8,44,79,193,16,334,60,102,91" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://github.com/pprp/timm.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://data.mendeley.com/datasets/fpv535fss7/1.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement. This work was supported in part by <rs type="funder">Research Initiation Project</rs> (<rs type="grantNumber">2021ND0PI02</rs>) and <rs type="funder">Key Research Project</rs> (<rs type="grantNumber">2022KI0AC01</rs>) of <rs type="person">Zhejiang Lab</rs>, <rs type="funder">National Key Research and Development Programme of China</rs> (No. <rs type="grantNumber">2021YFC2701902</rs>), and <rs type="funder">National Natural Science Foundation of China</rs> (No. <rs type="grantNumber">12071430</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_QRQe5P6">
					<idno type="grant-number">2021ND0PI02</idno>
				</org>
				<org type="funding" xml:id="_Bx9he26">
					<idno type="grant-number">2022KI0AC01</idno>
				</org>
				<org type="funding" xml:id="_4Hdqkdw">
					<idno type="grant-number">2021YFC2701902</idno>
				</org>
				<org type="funding" xml:id="_Vd3VGfm">
					<idno type="grant-number">12071430</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Mean teachers are better role models: weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
		<editor>NeurIPS, NIPS, Long Beach</editor>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Bayesian pseudo labels: expectation maximization for robust and efficient semi-supervised segmentation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Xu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16443-9_56</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16443-956" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13435</biblScope>
			<biblScope unit="page" from="580" to="590" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Enhancing pseudo label quality for semi-supervised domaingeneralized medical image segmentation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>AAAI</publisher>
			<biblScope unit="page" from="3099" to="3107" />
		</imprint>
		<respStmt>
			<orgName>AAAI</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">ACPL: anticurriculum pseudo-labelling for semi-supervised medical image classification</title>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Belagiannis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Carneiro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>IEEE Computer Society</publisher>
			<biblScope unit="page" from="20697" to="20706" />
			<pubPlace>New Orleans</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Uncertainty-aware pseudo-label and consistency for semi-supervised medical image segmentation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomed. Signal Process. Control</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">104203</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Active learning by feature mixing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Parvaneh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Abbasnejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Teney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Haffari</surname></persName>
		</author>
		<author>
			<persName><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hengel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Q</forename><surname>Shi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>IEEE Computer Society</publisher>
			<biblScope unit="page" from="12237" to="12246" />
			<pubPlace>New Orleans</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Variational adversarial active learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ebrahimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<editor>ICCV, Seoul</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="5972" to="5981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Sequential graph convolutional network for active learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Caramalau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bhattarai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Kim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>IEEE Computer Society</publisher>
			<biblScope unit="page" from="9583" to="9592" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Pinheiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Rostamzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Pal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.06583</idno>
		<title level="m">Reinforced active learning for image segmentation</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Viewal: active learning with viewpoint entropy for semantic segmentation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Siddiqui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Valentin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nießner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>IEEE Computer Society</publisher>
			<biblScope unit="page" from="9433" to="9443" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Suggestive annotation: a deep active learning framework for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Z</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-66179-7_46</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-66179-7" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2017</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Descoteaux</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Maier-Hein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Franz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Jannin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Collins</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Duchesne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">10435</biblScope>
			<biblScope unit="page">46</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Partially-supervised learning for vessel segmentation in ocular images</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87193-2_26</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87193-226" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12901</biblScope>
			<biblScope unit="page" from="271" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Rectifying pseudo label learning via uncertainty estimation for domain adaptive semantic segmentation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vision</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1106" to="1120" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Efficient semi-supervised gross target volume of nasopharyngeal carcinoma segmentation via uncertainty rectified pyramid consistency</title>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87196-3_30</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87196-330" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12902</biblScope>
			<biblScope unit="page" from="318" to="329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Adaptive early-learning correction for segmentation from noisy annotations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fernandez-Granda</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>IEEE Computer Society</publisher>
			<biblScope unit="page" from="2606" to="2616" />
			<pubPlace>New Orleans</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Optimizing intersection-over-union in deep neural networks for image segmentation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-50835-1_22</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-50835-122" />
	</analytic>
	<monogr>
		<title level="m">ISVC 2016</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Bebis</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">10072</biblScope>
			<biblScope unit="page" from="234" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">UNet++: redesigning skip connections to exploit multiscale features in image segmentation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M R</forename><surname>Siddiquee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tajbakhsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1856" to="1867" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Template Matching Techniques in Computer Vision: Theory and Practice</title>
		<author>
			<persName><forename type="first">R</forename><surname>Brunelli</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Wiley</publisher>
			<pubPlace>Hoboken</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A method of bivariate interpolation and smooth surface fitting based on local procedures</title>
		<author>
			<persName><forename type="first">H</forename><surname>Akima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="18" to="20" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Rethinking imagenet pre-training</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<editor>ICCV, Seoul</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="4918" to="4927" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">DATASET for &quot;Carotid Ultrasound Boundary Study (CUBS): an open multi-center analysis of computerized intima-media thickness measurement systems and their clinical impact</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Meiburger</surname></persName>
		</author>
		<idno type="DOI">10.17632/fpv535fss7.1</idno>
		<ptr target="https://doi.org/10.17632/fpv535fss7.1" />
	</analytic>
	<monogr>
		<title level="j">Mendeley Data</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The analytic hierarchy process and analytic network process: an overview of applications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sipahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Timor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Manag. Decis</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="775" to="808" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The openCV library</title>
		<author>
			<persName><forename type="first">G</forename><surname>Bradski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dr. Dobb&apos;s J. Softw. Tools Prof. Program</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="120" to="123" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Optimizing the dice score and jaccard index for medical image segmentation: theory and practice</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bertels</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-32245-8_11</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-32245-811" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2019</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11765</biblScope>
			<biblScope unit="page" from="92" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Mesh: measuring errors between surfaces using the hausdorff distance</title>
		<author>
			<persName><forename type="first">N</forename><surname>Aspert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Santa-Cruz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ebrahimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICME</title>
		<imprint>
			<biblScope unit="page" from="705" to="708" />
			<date type="published" when="2022">2022</date>
			<publisher>IEEE</publisher>
			<pubPlace>Lausanne</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A new active labeling method for deep learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCNN</title>
		<imprint>
			<biblScope unit="page" from="112" to="119" />
			<date type="published" when="2014">2014</date>
			<publisher>IEEE</publisher>
			<pubPlace>Beijing</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Active learning for convolutional neural networks: a core-set approach</title>
		<author>
			<persName><forename type="first">O</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.00489</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Contextual diversity for active learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Arora</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-58517-4_9</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-58517-49" />
	</analytic>
	<monogr>
		<title level="m">ECCV 2020</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Bischof</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J.-M</forename><surname>Frahm</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12361</biblScope>
			<biblScope unit="page" from="137" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Noisy labels are treasure: mean-teacher-assisted confident learning for hepatic vessel segmentation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87193-2_1</idno>
		<idno>978- 3-030-87193-2 1</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12901</biblScope>
			<biblScope unit="page" from="3" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning from multiple annotators for medical image segmentation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">138</biblScope>
			<biblScope unit="page">109400</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
