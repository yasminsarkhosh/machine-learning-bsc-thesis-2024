<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Semantic Difference Guidance for the Uncertain Boundary Segmentation of CT Left Atrial Appendage</title>
				<funder ref="#_7XPM8X2">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_VyRsYKH">
					<orgName type="full">National Key R&amp;D Program of China</orgName>
				</funder>
				<funder ref="#_wJR7fMB">
					<orgName type="full">Shanghai Health and Family Planning Commission</orgName>
				</funder>
				<funder ref="#_5RZASts">
					<orgName type="full">School of Medicine</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xin</forename><surname>You</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Medical Robotics</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ming</forename><surname>Ding</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Shanghai Xinhua Hospital</orgName>
								<orgName type="institution" key="instit2">Shanghai Jiaotong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Minghui</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Medical Robotics</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yangqian</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Medical Robotics</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yi</forename><surname>Yu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Shanghai Xinhua Hospital</orgName>
								<orgName type="institution" key="instit2">Shanghai Jiaotong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yun</forename><surname>Gu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Medical Robotics</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Jie</forename><surname>Yang</surname></persName>
							<email>jieyang@sjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Medical Robotics</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Semantic Difference Guidance for the Uncertain Boundary Segmentation of CT Left Atrial Appendage</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="121" to="131"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">4A786B56FB6DDF9C814BAE9440367364</idno>
					<idno type="DOI">10.1007/978-3-031-43990-2_12</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-23T22:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Left atrial appendage</term>
					<term>Difference operator</term>
					<term>Uncertain boundary</term>
					<term>Image segmentation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Atrial fibrillation (AF) is one of the most common types of cardiac arrhythmia, which is closely relevant to anatomical structures including the left atrium (LA) and the left atrial appendage (LAA). Thus, a thorough understanding of the LA and LAA is essential for the AF treatment. In this paper, we have modeled relative relations between the LA and LAA via deep segmentation networks for the first time, and introduce a new LA &amp; LAA CT dataset. To deal with uncertain boundaries between the LA and LAA, we propose the semantic difference module (SDM) based on diffusion theory to refine features with enhanced boundary information. Besides, disconnections between the LA and LAA are frequently observed in the segmentation results due to uncertain boundaries of the LAA region and CT imaging noise. To address this issue, we devise another connectivity-refined network with the connectivity loss. The loss function exerts a distance regularization on coarse predictions from the first-stage network. Experiments demonstrate that our proposed model can achieve state-of-the-art segmentation performance compared with classic convolutional-neural-networks (CNNs) and recent Transformer-based models on this new dataset. Specifically, SDM can also outperform existing methods on refining uncertain boundaries. Codes are available at https://github.com/AlexYouXin/LA-LAAsegmentation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Atrial fibrillation (AF) has been one of the most common types of cardiovascular diseases and is closely related to the left atrium (LA) <ref type="bibr" target="#b17">[18]</ref>. Beside this chamber structure, there is a finer anatomy termed with the left atrial appendage (LAA). The majority of strokes due to AF result from clots existing in the LAA <ref type="bibr" target="#b12">[13]</ref>. A common measure for treatment is anticoagulant therapy. However, many patients have contraindications to this type of therapy. A more effective and feasible stroke prevention procedure is the left atrial appendage closure, which can avoid most of the drawbacks by anticoagulant therapy <ref type="bibr" target="#b11">[12]</ref>. And the size of occlusion devices designed for patients is strongly associated with the anatomical interface between the LA and LAA <ref type="bibr" target="#b12">[13]</ref>. Thus, enhancing the understanding for the structure of the LA and LAA is beneficial to carry out treatments for strokes due to AF. A normal pre-surgery imaging is Cardiac Computed Tomography (Cardiac CT), which is a popular physical inspection for diagnoses <ref type="bibr" target="#b17">[18]</ref>. Thus, automatic and accurate segmentation of the LA and LAA from Cardiac CT images is essential to provide support for the diagnosis and treatment of various cardiovascular diseases.</p><p>Till now, many researches have focused on the automatic segmentation of the LA <ref type="bibr" target="#b23">[24]</ref>. Compared with that, the LAA has not been sufficiently researched, particularly the relative relations between the LA and LAA <ref type="bibr" target="#b26">[27]</ref>. In our work, we aim to design an automatic method for the correlation modeling between the LA and LAA, then give a quantitative and qualitative evaluation of segmentation performance. The LA and LAA both have large anatomical variations <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b26">27]</ref>. Besides, there are uncertain boundaries for the structure of the LAA, especially the interface between the LA and LAA. In contrast, cardiac tissues like the right atrium (RA), right ventricle (RV) and left ventricle (LV) have explicit boundaries, which can be easily and finely segmented <ref type="bibr" target="#b27">[28]</ref>. As shown in Fig. <ref type="figure" target="#fig_0">1</ref>, some cases show poor segmentation results on the uncertain boundary between the LA and LAA. There are many related works on the refinement for boundary segmentation, which can be grouped into three categories. The first strategy attempts to exert a strong loss constraint on boundaries via the multitask learning paradigm <ref type="bibr" target="#b3">[4]</ref>. Then some researchers apply a complex post-process to the segmentation of coarse boundaries, such as <ref type="bibr" target="#b25">[26]</ref>. All the methods above mainly emphasize on refining predicted masks for high-quality images with clear boundaries, are not applicable for ambiguous or unclear boundaries <ref type="bibr" target="#b22">[23]</ref> in the LA and LAA segmentation. Instead, the third strategy truly works, with the mechanism of enhancing deep features representing uncertain boundaries. Lee et al. <ref type="bibr" target="#b10">[11]</ref> proposed a novel boundary-preserving block (BPB) with the ground-truth structure information indicated by experts. Xie et al. <ref type="bibr" target="#b22">[23]</ref> used the confidence map to evaluate the uncertainty of each pixel to enhance the segmentation of ambiguous boundaries. Furthermore, some loss functions <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b24">25]</ref> are specifically designed for the segmentation of uncertain boundaries.</p><p>Diffusion is a physical model aimed at minimizing the spatial concentration difference <ref type="bibr" target="#b14">[15]</ref> and is widely used in computer vision <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>. In our work, we detailedly explain the process of refining uncertain boundaries based on diffusion theory. Then we propose a semantic guidance module based on differential operators to refine features from ambiguous boundaries, which is called semantic difference module (SDM). Here we introduce semantic information from deeper layers to guide the diffusion process. As a result of fuzzy boundaries of the LAA region and CT imaging noise, there exists a disconnection between the LA and LAA as shown in Fig. <ref type="figure" target="#fig_0">1</ref>. Thus, we design another connectivity-refined network (CRN) combined with the connectivity loss, to deal with the connectivity of two regions. The contributions of our work are listed as follows:</p><p>(1) We introduce a new LA &amp; LAA CT dataset. And as far as we are concerned, this is the first work based on deep neural networks, to model relative relations between the LA and LAA. <ref type="bibr" target="#b1">(2)</ref> We propose a novel semantic difference module based on diffusion theory to deal with the segmentation of uncertain boundaries. (3) We apply a connectivity-refined network with the connectivity loss to refine coarse masks, then achieve the connectivity between the LA and LAA. (4) Our proposed network achieves state-of-the-art segmentation performance on the LA and LAA. Specifically, SDM outperforms other methods related to refining the segmentation of uncertain boundaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Preliminaries</head><p>Diffusion is a physical phenomenon, in which molecules spread from regions with higher concentrations toward regions with lower concentrations <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref>. Then the whole system tends to be balanced. For a feature vector F to be smoothed, the diffusion process can be modeled as the following partial differential equation:</p><formula xml:id="formula_0">∂F ∂t = D • ∇ 2 F (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where D is the diffusivity function determining the diffusion speed along each direction, ∇ is the gradient operator. In our application, the stable state of F (t) will show a more accurate localization for uncertain boundaries of the LAA. Linear isotropic diffusion (D is equal to a constant) cannot be applied to complex scenes, because the diffusion velocity is the same in all directions. For a spatial-dependent function D = D(x, y, z), the process is linear anisotropic. However, if we aim to extract refined boundary features, adopting linear diffusion processes will smooth both backgrounds and the edges. A more feasible solution is to devise complex diffusion functions D = D(F ) with nonlinear characteristics <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>. As a result, the diffusion process exerts more smoothing to regions parallel to boundaries compared to regions vertical to these edges.</p><p>Detailedly, given a feature F where regions of uncertain boundaries are not highlighted, it is updated by the diffusion process in infinite time. The diffusion adjacent to ambiguous boundaries should be restrained, while the diffusion far away from boundaries is promoted. And the final state of the diffused feature will accurately localize uncertain boundaries of the LAA. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Semantic Difference Module</head><p>To localize fuzzy boundaries of the LAA, especially the interface between the LA and LAA, we propose the semantic difference module (SDM) to refine boundary features from these regions. Motivated by the diffusion process, we formulate the process of enhancing boundary features as solving a second-order partial differential equation. Due to the fact that semantic information is required to guide the localization of uncertain boundaries, we introduce the deep feature G from the precedent decoder layer to the diffusion process in each SDM.</p><p>Here we adopt ∇G as the semantic guidance map. And the square term h(|∇G| 2 ) is deployed as function D to model nonlinear characteristics of the diffusion process, where h is a projection function. In terms of <ref type="bibr" target="#b14">[15]</ref>, Eq. 1 can be approximately solved via iterative updates as depicted by the following equations:</p><formula xml:id="formula_2">F t+1 p = p∈δp h(|G p -G p | 2 ) • (F t p -F t p )<label>(2)</label></formula><formula xml:id="formula_3">F t+1 p = λ • F t p + ν • F t+1 p (<label>3</label></formula><formula xml:id="formula_4">)</formula><p>where p is the index of feature maps, δ p is the local neighborhood centered at p, λ and ν are weighting coefficients. Indeed, F t p -F t p is the differential information of original feature F t at point p, representing abundant boundary information, which contains complicated boundary features of anatomies as shown in Fig. <ref type="figure" target="#fig_1">2</ref>.c, including the RA RV, etc. However, predicted boundaries between the LA and LAA are not accurate enough only with the diffusion process. Thus, the semantic difference guidance |G p -G p | 2 is introduced to generate refined boundary feature F t+1 . F t+1 will diffuse into the stable state as t increases, which can highlight boundaries between the LA and LAA, and suppress the activation on other boundary regions. And refined feature F t+1 is attained by fusing the original feature F t with enhanced boundary feature F t+1 .</p><p>We design the semantic difference module based on Eq. 3 as illustrated by Fig. <ref type="figure" target="#fig_1">2</ref>. Here we make an improvement on the calculation of differential maps. Motivated by the fact that there exists an anisotropic distribution for our LA and LAA dataset in x, y and z dimensions, traditional edge operator cannot finely extract the differential map of feature F . Therefore, we propose a learnable boundary operator, which bears different values in each position of the kernel. As shown in Fig. <ref type="figure" target="#fig_1">2</ref>, we fix the center value as -1 to maintain the difference attribute of the edge kernel. The revised description of enhanced boundary feature is calculated by Eq. 4.</p><formula xml:id="formula_5">F t+1 p = p∈δp ω p • |α p G p -G p | 2 • (β p F t p -F t p )<label>(4)</label></formula><p>where α p and β p refer to the learnable edge operator for feature F and semantic feature G respectively. And ω p means a vanilla 3 × 3 × 3 convolution kernel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Connectivity-Refined Network</head><p>Due to the CT imaging noise, some cases show the phenomenon that the LAA is separated from the LA. To deal with disconnections between the LA and LAA, we propose the second-stage network called connectivity-refined network (CRN).</p><p>Inspired by the metric of 95% Hausdorff distance (HD 95 ) <ref type="bibr" target="#b6">[7]</ref>, we figure out that a poor connectivity between the LA and LAA will bring a large HD 95 value for the LAA segmentation, which is not what we expected. Therefore, we adopt another distance constraint loss called connectivity loss L c , besides the per-pixel Dice loss L d in the training process of CRN. Specifically, we choose coarse predictions from validation datasets from the first stage, concatenated with original images as the input of CRN. We firstly localize the predicted LAA region via its unique label. Then to make the region of LAA connected with the LA, we can only focus on the voxels most adjacent to the boundary interface. For the training efficiency, we locate the predicted LAA region with the approximately minimum external cube C (Please refer to supplementary material for more details about the algorithm). Four vertexes V i (i=1, 2, 3, 4) of C neighbored with the LA are selected to calculate the connectivity loss, which is indeed an improved minimal distance from vertexes to the surface of LA. Here we note the point set in the LA surface as P , and each point from P is noted as P j .</p><formula xml:id="formula_6">L c = σ 4 i=1 min P j ∈P D(Vi,Pj ) S -0.5 (5) L = L d + λ × L c (<label>6</label></formula><formula xml:id="formula_7">)</formula><p>where D means the Euclidean distance, σ is the sigmoid function. S is a scaling coefficient, and we set it as 20 according to the ablation study on this hyperparameter (Please refer to supplementary material for more quantitative results). Besides, λ is set as 1 if the training epoch reaches more 300 epochs, or it is 0. When there is no LAA predictions in a cropped patch, L c is equal to 0. On the ground that cases with a poor connectivity need to be refined in the training process of CRN, we increase sampling ratios of the whole LAA region from coarse masks of validation datasets. By cropping patches containing the boundary interface as network inputs, CRN will better learn the connectivity prior from the mapping between coarse predictions and expert annotations.</p><p>In the inference stage, final decoded features F d are applied with the softmax operator to attain predicted masks. However, different channels of F d bear different maximum values, which will affect segmentation performance. Thus, we propose the concept of channel calibration (CC). Before per-pixel selecting maximum values between channels, we uniform the maximum value of F d channel by channel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Settings</head><p>Dataset. To evaluate the performance of our network, we conduct experiments on a new dataset, containing accurate annotations of LA and LAA provided by multiple experts. In detail, we collect 80 CT scans from 80 patients, which are split into 45/15/20 for training, validation and testing cases in Stage 1. In Stage 2, 50 predictions of the validation dataset in Stage 1 are generated by various models, in which there are 30 predicted masks with disconnections. Then we randomly split them as 35/15 for training and validation. Moreover, we choose the Dice score and HD 95 as quantitative metrics. Implementation Details. In the first stage, we choose the vanilla 3D UNet as our baseline model, trained for 2000 epochs. And we utilize a combination of cross entropy loss and Dice loss followed by <ref type="bibr" target="#b7">[8]</ref>. For the second stage, CRN is trained for 500 epochs, which is a smaller 3D UNet with only 1.92M parameters.</p><p>And we utilize Dice loss and connectivity loss as illustrated by Eq. 6. We train all models using AdamW optimizer. With the linear warm-up strategy, the initial learning rate is set as 5e-4 with a cosine learning rate decay scheduler, and weight decay is set as 1e-5. The size of cropped patches is 160 × 160 × 192. All models are implemented based on Pytorch and trained on 2 NVIDIA Tesla V100 GPUs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experimental Results</head><p>Table <ref type="table" target="#tab_0">1</ref> consists of two sub-figures (a) and (b). According to Table <ref type="table" target="#tab_0">1</ref>.a, our proposed network outperforms classic CNNs and recent Transformer-based models. Specifically, our model shows superior to powerful nnUNet <ref type="bibr" target="#b7">[8]</ref> on four metrics, and there exist 0.69% increase on the Dice score of LAA, 0.54 mm decrease on the HD 95 of LA. Compared with nnUNet, our two-stage model requires less computational cost and is free from complicated multi-model ensembles. However, the Dice score of our model on LA is inferior to nnUNet. We argue that our model is aimed at improving the segmentation mask of LAA, which bears a different structure from LA. And the iterative optimization process of CRN in Fig. <ref type="figure" target="#fig_1">2</ref> shows the refinement for LAA segmentation. More results about the generalization of CRN can be found in supplementary material. Besides, Swin UNETR <ref type="bibr" target="#b16">[17]</ref> takes the lead in Transformer-based models, which is not as good as our model because Transformer-based models are data-hungry <ref type="bibr" target="#b5">[6]</ref>.</p><p>Another phenomenon worth to mention is that our model shows an ordinary performance on the HD 95 of LAA, which is owing to the appearance of outliers.</p><p>And not only our model but other CNNs and Transformer-based models suffer from the existence of outliers in predictions (More visualization results can be found in supplementary material). We will address this issue in the future research. In Table <ref type="table" target="#tab_0">1</ref>.b, we choose 3D UNet as the baseline model. SDM shows better segmentation performance compared with other methods on improving the segmentation of uncertain boundaries. And Fig. <ref type="figure" target="#fig_1">2</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Ablation Studies</head><p>Table <ref type="table" target="#tab_4">2</ref> shows ablation studies on key components and on the detailed structure of SDM. From Table <ref type="table" target="#tab_4">2</ref>.a, SDM, CRN and CC can all boost segmentation performance of the baseline model. Besides, we visualize qualitative results in Fig. <ref type="figure" target="#fig_2">3</ref>.</p><p>For the first row, our model give a more accurate localization for the boundary interface, which proves the effectiveness of SDM. The second row is a strong proof that CRN can effectively improve the connectivity between LA and LAA.</p><p>Then we probe into the efficacy of connectivity loss L c by removing it from CRN, which results in a 0.51mm increase on the HD 95 of LAA, which is reasonable because L c is indeed a distance regularization on LAA boundaries. In Table <ref type="table" target="#tab_4">2</ref>.b, we investigate the significance of each component in SDM.</p><p>(1) Without learnable difference kernels for differential maps of feature F and semantic feature G, the Dice score for LAA declines sharply, which reveals we need to focus on the anisotropic distribution of this dataset. <ref type="bibr" target="#b1">(2)</ref> In SDM, we adopt a residual block by fusing the original feature F and the boundary feature. With F removed, there is some details and texture information missing, resulting in a performance drop. (3) Finally, semantic guidance from deeper features is deployed to guide the extraction for uncertain boundaries between LA and LAA. Besides, some false boundaries are restrained, which is illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we introduce a new CT dataset on LA and LAA, then carry out the segmentation task. Detailedly, we explain the refined process for the segmentation of uncertain boundaries via diffusion theory. Based on this, we apply SDM to successfully improve the segmentation for uncertain boundaries between LA and LAA. Then CRN with the connectivity loss can deal with the poor connectivity between two structures. Detailed quantitative and qualitative results have demonstrated the efficacy of two proposed elements.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Improved segmentation results of the baseline model after adding SDM on case 1 and after adding CRN on case 2. (Green Area: LA. Red Area: LAA). (Color figure online)</figDesc><graphic coords="2,46,29,54,50,330,64,62,68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Our proposed two-stage network. (a) Baseline model with the semantic difference module (CC: channel calibration). (b) Connectivity-refined network. (c) Boundary feature enhancement. (d) Iterative optimizations for the predicted mask of a specific testing case.</figDesc><graphic coords="4,44,13,179,03,336,85,149,05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Qualitative segmentation results of other CNNs and Transformer-based models. (Green Area: LA. Red Area: LAA). (Color figure online)</figDesc><graphic coords="8,42,30,467,51,339,43,70,42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>(a) Results compared with other CNNs and Transformer-based models (Values on</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>both sides of '|' represent evaluation metrics for each stage of our model</head><label></label><figDesc></figDesc><table /><note><p>). (b) Segmentation performance including our SDM and other methods related to deal with uncertain boundaries (LA: Left Atrium, LAA: Left Atrial Appendage. Bold: the best, Underlined numbers: the second best. '-'</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>indicates that loss func- tions do not change Parameters and FLOPs of the baseline model).</head><label></label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>LAA LA</cell><cell>Average</cell><cell>LAA LA</cell><cell>Average</cell></row><row><cell>3D UNet [2]</cell><cell>16.47</cell><cell>0.514</cell><cell cols="2">76.64 95.75 86.19±13.0 10.25 6.94 8.59±5.0</cell></row><row><cell>ResUNet [3]</cell><cell>32.46</cell><cell>0.813</cell><cell cols="2">77.45 95.86 86.66±13.1 9.04 9.79 9.41±6.9</cell></row><row><cell>V-Net [14]</cell><cell>45.72</cell><cell>2.391</cell><cell cols="2">74.21 92.68 83.44±14.7 12.54 8.82 10.68±7.9</cell></row><row><cell>TransBTS [20]</cell><cell>35.61</cell><cell>0.613</cell><cell cols="2">73.65 95.05 84.35±12.5 10.85 15.53 13.19±11.1</cell></row><row><cell>UNETR [5]</cell><cell>93.54</cell><cell>0.458</cell><cell cols="2">75.97 95.26 85.62±12.9 11.41 15.32 13.37±10.1</cell></row><row><cell cols="2">TransUNet (3D) [1] 82.41</cell><cell>0.220</cell><cell cols="2">78.43 95.45 86.94±11.3 8.95 8.47 8.71±5.3</cell></row><row><cell>Swin UNETR [17]</cell><cell>62.19</cell><cell>0.975</cell><cell cols="2">76.32 95.94 86.13±12.9 11.45 7.71 9.58±5.7</cell></row><row><cell>UNeXt [19]</cell><cell>4.02</cell><cell>0.035</cell><cell cols="2">79.37 95.34 87.36±9.7 8.38 8.22 8.31±2.3</cell></row><row><cell>nnUNet [8]</cell><cell>30.79</cell><cell>0.835</cell><cell cols="2">81.16 96.29 88.72±9.6 8.67 7.17 7.92 ±2.8</cell></row><row><cell>Ours</cell><cell>23.47|1.92</cell><cell>0.666|0.</cell><cell></cell></row></table><note><p>(a) Segmentation benchmark on LA &amp; LAA Model Params(M) FLOPs(T) Dice score (%) ↑ HD95 (mm) ↓</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>130 81.85 95.96 88.91 ±6.9 8.87 6.63 7.75 ±2</head><label></label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>.4</cell></row><row><cell cols="4">(b) Comparison with other methods focused on uncertain boundaries</cell></row><row><cell>Baseline</cell><cell>16.47</cell><cell>0.514</cell><cell>76.64 95.75 86.19±13.0 10.25 6.94 8.59±5.0</cell></row><row><cell cols="2">+ Boundary loss [10] -</cell><cell>-</cell><cell>77.02 95.74 86.38 ±11.3 9.82 7.33 8.58 ±3.2</cell></row><row><cell>+ BU loss [25]</cell><cell>-</cell><cell>-</cell><cell>77.01 96.16 86.59 ±12.7 10.51 6.78 8.65 ±5.0</cell></row><row><cell>+ BPB [11]</cell><cell>27.97</cell><cell>0.717</cell><cell>77.49 96.02 86.76 ±12.8 9.96 6.97 8.46 ±4.7</cell></row><row><cell>+ CCM [23]</cell><cell>18.98</cell><cell>0.596</cell><cell>77.71 96.05 86.88 ±11.8 9.86 7.04 8.45 ±3.4</cell></row><row><cell>+ SDM (Ours)</cell><cell>23.47</cell><cell>0.666</cell><cell>78.88 95.91 87.40 ±8.6 9.76 6.93 8.35 ±3.5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 .</head><label>2</label><figDesc>(a) Ablation study on the structure of the semantic difference module (SDM). DK refers to difference kernel) (b) Ablation study on the efficacy of our proposed key components, including SDM, connectivity-refined network (CRN), channel calibration (CC) and connectivity loss.</figDesc><table><row><cell>(a) Ablation study on SDM</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Model</cell><cell cols="2">Dice score (%) ↑</cell><cell></cell><cell>HD95 (mm) ↓</cell><cell></cell><cell></cell></row><row><cell></cell><cell>LAA</cell><cell>LA</cell><cell>Average</cell><cell>LAA</cell><cell>LA</cell><cell>Average</cell></row><row><cell>+ SDM</cell><cell>78.88</cell><cell>95.91</cell><cell>87.40</cell><cell>9.76</cell><cell>6.93</cell><cell>8.35</cell></row><row><cell>w/o learnable DK</cell><cell cols="6">76.60 (↓ 2.28) 95.77 (↓ 0.14) 86.18 (↓ 1.22) 10.53 (↑ 0.77) 7.30 (↑ 0.37) 8.92 (↑ 0.57)</cell></row><row><cell>w/o original feature F</cell><cell cols="6">77.15 (↓ 1.73) 95.71 (↓ 0.20) 86.43 (↓ 0.97) 9.71 (↓ 0.05) 7.16 (↑ 0.23) 8.44 (↑ 0.09)</cell></row><row><cell>w/o semantic guidance</cell><cell cols="6">77.82 (↓ 1.06) 95.49 (↓ 0.42) 86.66 (↓ 0.74) 9.82 (↑ 0.06) 7.38 (↑ 0.45) 8.60 (↑ 0.25)</cell></row><row><cell cols="2">(b) Ablation study on key components</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Baseline</cell><cell>76.64</cell><cell>95.75</cell><cell>86.19</cell><cell>10.25</cell><cell>6.94</cell><cell>8.59</cell></row><row><cell>+ SDM</cell><cell>78.88</cell><cell>95.91</cell><cell>87.40</cell><cell>9.76</cell><cell>6.93</cell><cell>8.35</cell></row><row><cell>+ CC</cell><cell>77.44</cell><cell>96.06</cell><cell>86.75</cell><cell>9.70</cell><cell>6.84</cell><cell>8.27</cell></row><row><cell>+ SDM + CC</cell><cell>79.72</cell><cell>96.03</cell><cell>87.88</cell><cell>9.51</cell><cell>6.90</cell><cell>8.21</cell></row><row><cell>+ CRN</cell><cell>79.51</cell><cell>95.62</cell><cell>87.57</cell><cell>9.42</cell><cell>6.89</cell><cell>8.16</cell></row><row><cell cols="2">+ CRN w/o connectivity loss 78.24</cell><cell>95.65</cell><cell>86.95</cell><cell>9.93</cell><cell>6.95</cell><cell>8.44</cell></row><row><cell>+ SDM + CRN</cell><cell>81.32</cell><cell>95.64</cell><cell>88.48</cell><cell>9.08</cell><cell>6.78</cell><cell>7.93</cell></row><row><cell>+ SDM + CRN + CC</cell><cell cols="6">81.85 (↑ 5.21) 95.96 (↑ 0.21) 88.91 (↑ 2.72) 8.87 (↓ 1.38) 6.63 (↓ 0.31) 7.75 (↓ 0.84)</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement. This work is supported in part by <rs type="funder">National Key R&amp;D Program of China</rs> (<rs type="grantNumber">2019YFB1311503</rs>), the <rs type="programName">Shanghai Sailing Program</rs> (<rs type="grantNumber">20YF1420800</rs>), the <rs type="funder">Shanghai Health and Family Planning Commission</rs> (<rs type="grantNumber">202240110</rs>) and <rs type="person">Xinhua Hospital</rs> affiliated with the <rs type="funder">School of Medicine</rs> (<rs type="grantNumber">XHKC2021-07</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_VyRsYKH">
					<idno type="grant-number">2019YFB1311503</idno>
					<orgName type="program" subtype="full">Shanghai Sailing Program</orgName>
				</org>
				<org type="funding" xml:id="_wJR7fMB">
					<idno type="grant-number">20YF1420800</idno>
				</org>
				<org type="funding" xml:id="_5RZASts">
					<idno type="grant-number">202240110</idno>
				</org>
				<org type="funding" xml:id="_7XPM8X2">
					<idno type="grant-number">XHKC2021-07</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43990-2 12.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Transunet: transformers make strong encoders for medical image segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.04306</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">3D U-net: learning dense volumetric segmentation from sparse annotation</title>
		<author>
			<persName><forename type="first">Ö</forename><surname>Abdulkadir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lienkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-46723-8_49</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-46723-8" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2016</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Ourselin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Joskowicz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Sabuncu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Unal</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Wells</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">9901</biblScope>
			<biblScope unit="page">49</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Resunet-A: a deep learning framework for semantic segmentation of remotely sensed data</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">I</forename><surname>Diakogiannis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Waldner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Caccetta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS J. Photogrammetry Remote Sens</title>
		<imprint>
			<biblScope unit="volume">162</biblScope>
			<biblScope unit="page" from="94" to="114" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">End-to-end boundary aware networks for medical image segmentation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hatamizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Terzopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Myronenko</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-32692-0_22</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-32692-022" />
	</analytic>
	<monogr>
		<title level="m">MLMI 2019</title>
		<editor>
			<persName><forename type="first">H.-I</forename><surname>Suk</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Yan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Lian</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11861</biblScope>
			<biblScope unit="page" from="187" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">UnetR: transformers for 3D medical image segmentation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hatamizadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="574" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Transformers in medical image analysis: a review</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intell. Med</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Comparing images using the hausdorff distance</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Huttenlocher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="850" to="863" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">NNU-net: a self-configuring method for deep learning-based biomedical image segmentation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Isensee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A A</forename><surname>Kohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Maier-Hein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="211" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Left atrial appendage segmentation using fully convolutional neural networks and modified three-dimensional conditional random fields</title>
		<author>
			<persName><forename type="first">C</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Biomed. Health Inform</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1906" to="1916" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Boundary loss for highly unbalanced segmentation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kervadec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page">101851</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Structure boundary preserving segmentation for medical image with ambiguous boundary</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">U</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">M</forename><surname>Ro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4817" to="4826" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">A survey of left atrial appendage segmentation and analysis in 3D and 4d medical images</title>
		<author>
			<persName><forename type="first">H</forename><surname>Leventić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Benčević</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Babin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Habijan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Galić</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.06486</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Left atrial appendage segmentation from 3D CCTA images for occluder placement procedure</title>
		<author>
			<persName><forename type="first">H</forename><surname>Leventić</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Biol. Med</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="163" to="174" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">V-net: fully convolutional neural networks for volumetric medical image segmentation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Milletari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-A</forename><surname>Ahmadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fourth International Conference on 3D Vision (3DV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="565" to="571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Geometric Partial Differential Equations and Image Analysis</title>
		<author>
			<persName><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Semantic diffusion network for semantic segmentation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Sitong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="8702" to="8716" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Self-supervised pre-training of swin transformers for 3D medical image analysis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="20730" to="20740" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Benchmark for algorithms segmenting the left atrium from 3D CT and MRI datasets</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tobon-Gomez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1460" to="1473" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">UNeXt: MLP-based rapid medical image segmentation network</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M J</forename><surname>Valanarasu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16443-9_3</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16443-93" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13435</biblScope>
			<biblScope unit="page" from="23" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">TransBTS: multimodal brain tumor segmentation using transformer</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87193-2_11</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87193-211" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12901</biblScope>
			<biblScope unit="page" from="109" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Coherence-enhancing diffusion filtering</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weickert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vision</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page">111</biblScope>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Efficient and reliable schemes for nonlinear diffusion filtering</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weickert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Ter Haar Romeny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Viergever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="398" to="410" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Uncertainty-aware cascade network for ultrasound image segmentation with ambiguous boundary</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16440-8_26</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16440-826" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13434</biblScope>
			<biblScope unit="page" from="268" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A global benchmark of algorithms for segmenting the left atrium from late gadolinium-enhanced cardiac magnetic resonance imaging</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page">101832</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Incorporating boundary uncertainty into loss functions for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-B</forename><surname>Schönlieb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rundo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.00533</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">SegFix: model-agnostic boundary refinement for segmentation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-58610-2_29</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-58610-2" />
	</analytic>
	<monogr>
		<title level="m">ECCV 2020</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Bischof</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J.-M</forename><surname>Frahm</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12357</biblScope>
			<biblScope unit="page">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Multi-part modeling and segmentation of left atrium in c-arm CT for image-guided ablation of atrial fibrillation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Comaniciu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="318" to="331" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Multi-scale patch and multi-modality atlases for whole heart segmentation of MRI</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="77" to="87" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
