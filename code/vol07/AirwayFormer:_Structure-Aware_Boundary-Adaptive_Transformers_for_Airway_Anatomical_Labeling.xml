<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">AirwayFormer: Structure-Aware Boundary-Adaptive Transformers for Airway Anatomical Labeling</title>
				<funder ref="#_3J6sGYQ #_jYm59pX">
					<orgName type="full">National Key R&amp;D Program of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Weihao</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Medical Robotics</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hao</forename><surname>Zheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Medical Robotics</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Tencent Jarvis Lab</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yun</forename><surname>Gu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Medical Robotics</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fangfang</forename><surname>Xie</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Shanghai Chest Hospital</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiayuan</forename><surname>Sun</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Shanghai Chest Hospital</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Jie</forename><surname>Yang</surname></persName>
							<email>jieyang@sjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Medical Robotics</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Committee of Science and Technology</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">AirwayFormer: Structure-Aware Boundary-Adaptive Transformers for Airway Anatomical Labeling</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="393" to="402"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">7775EC794C6D6DCEF43321250B1AF677</idno>
					<idno type="DOI">10.1007/978-3-031-43990-2_37</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-23T22:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Airway anatomical labeling</term>
					<term>Structural prior</term>
					<term>Dynamic decision boundary</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Pulmonary airway labeling identifies anatomical names for branches in bronchial trees. These fine-grained labels are critical for disease diagnosis and intra-operative navigation. Recently, various methods have been proposed for this task. However, accurate labeling of each bronchus is challenging due to the fine-grained categories and interindividual variations. On the one hand, training a network with limited data to recognize multitudinous classes sets an obstacle to the design of algorithms. We propose to maximize the use of latent relationships by a transformer-based network. Neighborhood information is properly integrated to capture the priors in the tree structure, while a U-shape layout is introduced to exploit the correspondence between different nomenclature levels. On the other hand, individual variations cause the distribution overlapping of adjacent classes in feature space. To resolve the confusion between sibling categories, we present a novel generator that predicts the weight matrix of the classifier to produce dynamic decision boundaries between subsegmental classes. Extensive experiments performed on publicly available datasets demonstrate that our method can perform better than state-of-the-art methods. The code is publicly available at https://github.com/EndoluminalSurgicalVision-IMR/AirwayFormer.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Automatic airway labeling aims to assign the corresponding anatomical names to the branches in airway trees. The identification of peripheral branches plays an essential role in bronchoscopic navigation. Figure <ref type="figure" target="#fig_0">1</ref> illustrates the hierarchical nomenclature <ref type="bibr" target="#b10">[11]</ref> from lobar to subsegmental levels in the bronchial tree. In the first level, the naming is based on the five lung lobes, and similarly, the subtrees are further divided according to the 18 lung segments. The nomenclature of subsegmental bronchi is more complex, which contains six classes (a, b, c, a+b, a+c, and b+c) for the subtrees and their common branches.</p><p>Various methods have been proposed for airway labeling <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22]</ref> in recent years. Several works <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b15">16]</ref> adopted graph-matching-based algorithms to clarify the candidate trees based on a reference tree. However, the performance is limited at the subsegmental level due to individual variation. Deep learning methods <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22]</ref> are also developed for this task. Tan et al. <ref type="bibr" target="#b13">[14]</ref> proposed a multi-task U-Net <ref type="bibr" target="#b11">[12]</ref> with a structure-aware graph convolutional network (GCN) <ref type="bibr" target="#b4">[5]</ref> to segment the airway tree semantically. Yu et al. <ref type="bibr" target="#b20">[21]</ref> converted the airway tree from the image to the graph space and designed a multi-stage framework with hypergraph neural networks (HGNN) for node classification. There are two main challenges for these learning-based methods. First, 127 classes are included in the nomenclature up to subsegmental level. The annotation is quite time-consuming and labor-intensive. Classification for over one hundred categories with limited training data is an extremely hard problem. Second, the inter-individual differences regarding the location, direction, length, and diameter of branches become increasingly significant from the lobar order to the subsegmental level. Figure <ref type="figure" target="#fig_0">1</ref>(d) demonstrates the t-distributed stochastic neighbor embedding (t-sne) results of the learned features of RB10 branches in two examples. The distribution of RB10b in the first case is overlapped with the distribution of RB10c in the second example. Such individual variation dramatically affects the generalization ability of models.</p><p>To resolve the first problem, in this work, we propose to fully use the latent relationships within the tree structure and airway nomenclature by a novel network named AirwayFormer. The tree structure provides inherent message transmission roads, while both global and local information is critical for anatomical labeling. To this end, we first adopt a neighborhood information encoding module based on the transformer block to aggregate both global and local features within the tree structure. Another structural relationship appears in the nomenclature of bronchial trees. As shown in Fig. <ref type="figure" target="#fig_0">1</ref>(a), (b), and (c), the subsegmental bronchi RB10a belong to RB10 in the segmental level and the right lower lobe bronchi (RLL) in the lobar level, respectively. The consistency between classes at different levels is an important cue in this task. In previous works, Yu et al. <ref type="bibr" target="#b20">[21]</ref> introduced the classification results of the current stage to the next stage as extra constraints. However, the inference is only single-directional, where the prediction is not used to refine the classification in the upper level. To achieve a bi-directional refinement, a U-shape layout is designed to explore the correspondence between different nomenclature levels. For the second challenge, an ideal solution is that the model can adaptively adjust itself to deal with individual variation. Especially in subsegmental level, the same category in different cases may have distinct features. Actually, the nomenclature of subsegmental bronchi depends on their relative positions to the sibling branches within a segment. Based on this prior knowledge, we design a novel generator that learns to capture the relative relationships by predicting the weights of the last fully connected layer. More specifically, the weight for a subsegmental class is generated based on the feature representation of the corresponding segmental class. As illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>, compared with using fixed weights in the classifier, the predicted weights dynamically adjust the decision boundaries according to the characteristics of the segmental bronchi in each case, alleviating the overfitting problem caused by individual variation.</p><p>Our main contributions can be summarized as follows: (1) AirwayFormer is proposed for accurate airway labeling up to subsegmental level by exploiting the latent structural relationships. (2) A weight generator is designed to mitigate the overfitting caused by individual variation via adaptive decision boundary adjustment. ( <ref type="formula">3</ref>) With extensive experiments on the public dataset, our method achieves state-of-the-art results in lobar, segmental, and subsegmental levels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>An overview of our proposed method is illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>. Following previous work <ref type="bibr" target="#b20">[21]</ref>, each branch is regarded as a node in a graph space with well-designed 20-dimensional features. Five transformer blocks are used to classify these nodes hierarchically. The weight matrix of the subsegmental classifier is dynamically updated according to the segmental features. We denote the function of the  m-th transformer blocks as</p><formula xml:id="formula_0">F m (•), 1 ≤ m ≤ M = 5. X m ∈ R n×d</formula><p>denotes the input feature of the corresponding transformers. The node number and feature dimension are denoted by n and d, respectively. The number of categories of the m-th classifier is c m . More details about our method are introduced in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Structure-Aware Transformers</head><p>We propose a transformer-based model named AirwayFormer to exploit the structural relationships in airway labeling. The tree structure is introduced into the self-attention calculation, while the class consistency in the hierarchical nomenclature is encoded in the U-shape layout. Self-attention module in transformers enables nodes to aggregate messages from a global scale while neglecting the local structure prior. Recent studies <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b19">20]</ref> showed that incorporating graph information into vanilla transformers can achieve competitive performance. As the labeling of peripheral branches needs both global and local information, we adopt a neighborhood information encoding (NIE) module, which integrates the structural prior into the selfattention mechanism. Given an airway tree with n branches, each branch can be seen as a node v. The parent bronchus and children bronchus is adjacent. Then we adopt a distance function ψ(v i , v j ) to measure the spatial relation between nodes v i and v j . Here, ψ(v i , v j ) is defined as the shortest path distance (SPD) between v i and v j . Finally, a codebook C m is used to convert the SPD matrix D ∈ R n×n to learnable scale parameters, which can serve as a graph bias term of the attention map A ∈ R n×n :</p><formula xml:id="formula_1">A = X m Q(X m K) T √ d + C m (D).<label>(1)</label></formula><p>Here, Q ∈ R d×d and K ∈ R d×d are trainable parameters. Matrix D encodes the neighborhood information of the tree structure, and the network can adaptively concentrate on the local structure by optimizing C m .</p><p>To simultaneously utilize the bi-directional correspondence between different levels, AirwayFormer adopts a U-shape layout. Concretely, the network performs nodes classification hierarchically from lobar level to subsegmental level and then back to lobar level:</p><formula xml:id="formula_2">G m = F m (X m ). (<label>2</label></formula><formula xml:id="formula_3">)</formula><formula xml:id="formula_4">X m+1 = G m , 1 ≤ m &lt; M 2 , CAT (G m , G M -m ), M 2 ≤ m &lt; M.</formula><p>(3)</p><formula xml:id="formula_5">P m = Z m (G m ).<label>(4)</label></formula><p>Here, G m ∈ R n×d is the output feature of the m-th transformer blocks, and CAT (•) denotes the concatenate operation. Z m (•) is the m-th classifier consisting of a simple linear layer while P m ∈ R n×cm is the prediction result. The advantages of this design are two-fold. First, the output of coarser level is used as the input of finer level, which is helpful for the network to learn the corresponding relationship of the categories from coarse to fine. Second, the results of coarser level can be directly deduced from the predictions of finer level. Fine-grained features feedback to coarser level reduces the classification difficulty of coarser level and promotes the labeling performance. Besides, transformers conducting labeling of the same level are connected directly using highways. The same-level features can prevent performance degradation and ameliorate training stability. We further stop gradient back-propagation from segmental level to subsegmental level. The reason is that the severe distribution overlap in subsegments makes the feature learning in this level markedly different from others. This is further discussed in the supplementary materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Boundary-Adaptive Classifier</head><p>Individual variations cause the distribution of adjacent classes to intersect, especially in subsegmental level. Although most subsegmental bronchi in the same tree are separable according to their relative positions, the inter-individual differences seriously affect the generalization performance of the model. To introduce case-specific information, we propose a boundary-adaptive classifier that adopts a novel generator to predict case-specific weights for each subsegmental category. Let G k ∈ R n×d denote the subsegmental output feature. We first use the next segmental level feature G k+1 ∈ R n×d and prediction P k+1 ∈ R n×c k+1 to obtain coarser representation for each segmental class:</p><formula xml:id="formula_6">S k+1 = Sof tmax(P k+1 ). (<label>5</label></formula><formula xml:id="formula_7">) H = (S k+1 α ) T G k+1 . (<label>6</label></formula><formula xml:id="formula_8">)</formula><p>Here, S k+1 ∈ R n×c k+1 denotes the probability matrix of the segmental level while α is a learnable cluster parameter. H = (h 1 , h 2 , ..., h c k+1 ) T ∈ R c k+1 ×d are representations for c k+1 segmental categories. However, the segmental prediction P k+1 is not always perfect and may contain some classification errors. To avoid potential error propagation and obtain better class representations, these cluster centers are refined using a vanilla transformer. Specifically, we take H as query vectors and G k+1 as key and value vectors:</p><formula xml:id="formula_9">H = transf ormer(q = H, k = v = G k+1 ). (<label>7</label></formula><formula xml:id="formula_10">)</formula><p>After getting the enhanced segmental class representations, a generator network T (•) is used to produce classifier weights for subsegmental categories. Since each segment contains six subsegmental bronchi, T (•) transforms each segmental center into the seven (including itself) classifier weights:</p><formula xml:id="formula_11">w i = T ( hi ) = U (Gelu(V ( hi ))), 1 ≤ i ≤ c k+1 . (<label>8</label></formula><formula xml:id="formula_12">)</formula><p>Here, Gelu(•) denotes the GELU activation function <ref type="bibr" target="#b2">[3]</ref>. A bottleneck architecture is used to limit the number of parameters: V ∈ R d×b and U ∈ R b×7×d are down-projection and up-projection learnable matrices respectively where b d. Finally, the weight matrix of the subsegmental classifier can be obtained by stacking w i ∈ R 7×d .</p><p>We use cross-entropy loss with labeling smoothing <ref type="bibr" target="#b12">[13]</ref> as the loss function for each task. Then the total loss function can be formulated as</p><formula xml:id="formula_13">L total = M m=1 γ m L ce , (<label>9</label></formula><formula xml:id="formula_14">)</formula><p>where γ m is the weight of the m-th loss function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset and Implementation Details</head><p>We evaluated our method on the public Airway Tree Labeling (ATL) Dataset<ref type="foot" target="#foot_0">1</ref>  <ref type="bibr" target="#b20">[21]</ref>. The dataset contains 104 labeled bronchial trees from CT scans whose slice thickness ≤ 0.67 mm and spatial resolution ranges from 0.78 mm to 0.82 mm. The annotation is three-level, including six lobar bronchi, 19 segmental bronchi, and 127 subsegmental bronchi. We conducted 4-fold cross-validation on the dataset. We set the label smoothing hyperparameter σ of the loss function to 0.02. The weight of loss function γ m was set to 1. More experiments about hyperparameters can be found in the supplementary materials. We stacked two transformer blocks for airway labeling of each level. The model was trained using Adam optimizer (β 1 = 0.9, β 2 = 0.999) with a learning rate of 5e -4 for 800 epoches. Predictions of the last lobar and segmental classifiers were used to be the final results of these levels. Four evaluation metrics were used: (a) accuracy (ACC), (b) precision(PR), (c) recall (RC), and (d) F1 score (F1). All the networks were implemented in PyTorch framework with a GeForce GTX TITAN XP GPU.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluations</head><p>Table <ref type="table" target="#tab_1">1</ref> compares the quantitative results of our proposed method with other methods. GNNs methods such as GCN <ref type="bibr" target="#b4">[5]</ref> and GAT <ref type="bibr" target="#b17">[18]</ref> only aggregate information from neighborhoods, while DAGNN <ref type="bibr" target="#b14">[15]</ref> gradually performs message passing and updating from root nodes to the end. These methods merely encode the local structure of airway trees and are seriously disturbed by distribution overlapping in subsegments. Thus, they fail to achieve satisfactory performance, especially in subsegmental level. In HGNN methods, HyperGCN <ref type="bibr" target="#b18">[19]</ref> and UniSAGE <ref type="bibr" target="#b3">[4]</ref> use hyperedges to represent subtrees. TNN <ref type="bibr" target="#b20">[21]</ref> further proposes a sub-network for subtrees to exchange information and outperforms other HGNNs methods. SGNet <ref type="bibr" target="#b13">[14]</ref> uses CNNs to conduct semantic segmentation directly on CT images, which can be easily affected by class imbalance. Conventional methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b15">16]</ref> usually adopt graph-matching-based algorithms, but the reference tree cannot meet all situations due to individual variations. Thus, their performance drops a lot in the subsegmental level. Vanilla Transformer <ref type="bibr" target="#b16">[17]</ref> achieves the same effect as TNN owing to the global-scale self-attention module while lacking the utilization of structural prior. Compared to all the above methods, our approach improves the accuracy by more than 2% and 4% respectively in segmental and subsegmental levels, demonstrating the effectiveness of the proposed method.</p><p>Qualitative results are displayed in Fig. <ref type="figure" target="#fig_2">3</ref> to demonstrate the superior performance of our model at different levels. In segmental labeling, transformer lacks the local structural prior, in which way the sibling categories cannot be classified well. The problem is more severe in subsegments. TNN adopts a subtree interaction module to learn relative information, but the correspondence between different nomenclature level is not fully utilized. By contrast, our method can perform accurate airway labeling both in segmental and subsegmental levels. We further conducted ablation studies to verify the effectiveness of each component of AirwayFormer. Table <ref type="table" target="#tab_3">2</ref> shows the results. Vanilla transformer performing bronchi labeling for each level independently is used as the baseline. The U-shape layout encodes the correspondence of nomenclature and improves the results in all three levels. NIE module introduces the local structure prior to selfattention calculation and also promotes the labeling performance, especially in the subsegmental level. Combining the two modules, the performance is further ameliorated. The weight generator network dynamically adjusts the classification weights and improves the subsegmental results. When applying the three modules simultaneously, the network demonstrates the most powerful ability for airway labeling. The experimental results indicate that these proposed modules do contribute to the satisfactory performance of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>This paper presented a transformer-based method named AirwayFormer for airway anatomical labeling. A U-shape layout integrating graph information is used to exploit the latent relationships fully. Meanwhile, a weight generator that produces the dynamic decision boundaries is designed to capture the relative relationships between sibling categories. Extensive experiments showed that our proposed method achieved superior performance in the bronchi labeling of all three levels, leading to an efficient clinical tool for intra-operative navigation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Three-level nomenclature of the bronchial tree, and visualization of branch features and decision boundaries of different methods. The text color is consistent with the classes. Colors in t-sne figures are consistent with those in the airway tree. RLL is short for the right lower lobe.</figDesc><graphic coords="3,57,96,53,96,336,16,180,76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Overview of the proposed method for bronchi anatomical labeling.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The results of airway labeling are displayed from the perspective of graph and 3D. The first (last) two rows are the results of segmental (subsegmental) bronchi.</figDesc><graphic coords="7,61,98,382,64,328,36,163,60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Comparison with different methods in airway anatomical labeling (%). Feragen et al. [2] 94.1 94.1 93.6 93.8 81.8 80.1 83.2 81.7 62.8 60.2 56.2 58.1</figDesc><table><row><cell>Method</cell><cell>Lobar</cell><cell>Segmental</cell><cell cols="3">Subsegmental</cell></row><row><cell></cell><cell cols="5">ACC PR RC F1 ACC PR RC F1 ACC PR RC F1</cell></row><row><cell>(A) GNNs</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>GCN [5]</cell><cell cols="5">98.0 96.8 96.1 96.5 85.4 86.3 84.0 85.2 60.2 59.5 62.2 60.8</cell></row><row><cell>GAT [18]</cell><cell cols="5">98.6 98.0 97.0 97.5 88.6 89.6 88.7 89.2 70.7 63.7 66.6 65.1</cell></row><row><cell>DAGNN [15]</cell><cell cols="5">98.5 97.7 97.2 97.4 89.1 88.6 88.1 88.3 74.0 67.8 71.1 69.4</cell></row><row><cell>(B) HGNNs</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>HyperGCN [19]</cell><cell cols="5">98.4 98.1 96.5 97.3 87.6 83.9 85.1 84.5 61.8 48.2 52.5 50.3</cell></row><row><cell>UniSAGE [4]</cell><cell cols="5">98.6 98.0 97.0 97.5 89.0 89.6 88.6 89.1 70.9 66.5 68.7 67.6</cell></row><row><cell>TNN [21]</cell><cell cols="5">98.6 98.4 96.4 97.4 93.6 93.0 93.6 93.3 82.0 76.9 79.7 78.2</cell></row><row><cell>(C) CNNs</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>SGNet [14]</cell><cell cols="3">96.8 96.5 95.8 96.1 83.2 76.6 75.1 74.8 -</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>(D) Conventional</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Kitaoka et al. [6]</cell><cell cols="5">92.5 92.2 91.3 91.8 78.7 77.3 77.4 77.3 55.9 54.2 53.6 53.9</cell></row><row><cell cols="6">Tschirren et al. [16] 92.8 92.6 92.2 92.4 79.5 78.6 77.5 78.0 57.1 54.5 56.1 55.4</cell></row><row><cell>(E) Transformers</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Transformer [17]</cell><cell cols="5">98.8 98.5 97.6 98.0 93.1 93.0 92.8 92.9 82.5 77.8 80.8 79.3</cell></row><row><cell>Ours</cell><cell>99.2</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>98.8 98.2 98.5 95.7 95.9 95.9 95.9 86.0 83.5 84.5 84.0</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 .</head><label>2</label><figDesc>Ablation study of key components (%). U denotes the U-shape layout, NIE is neighborhood information encoding module, and G is the weight generator network.</figDesc><table><row><cell cols="2">Components Lobar</cell><cell>Segmental</cell><cell>Subsegmental</cell></row><row><cell cols="2">U NIE G ACC PR RC F1</cell><cell>ACC PR RC F1</cell><cell>ACC PR RC F1</cell></row><row><cell>× ×</cell><cell cols="3">× 98.8 98.5 97.6 98.0 93.1 93.0 92.8 92.9 82.5 77.8 80.8 79.3</cell></row><row><cell>×</cell><cell cols="3">× 99.1 98.5 98.0 98.2 94.7 94.8 94.7 94.7 83.6 80.7 82.2 81.4</cell></row><row><cell>×</cell><cell cols="3">× 99.0 98.2 98.0 98.1 94.6 94.5 94.1 94.3 84.8 81.6 82.7 82.2</cell></row><row><cell></cell><cell cols="3">× 99.0 98.6 97.9 98.3 95.4 95.6 95.6 95.6 85.4 83.0 84.1 83.6</cell></row><row><cell>×</cell><cell cols="3">99.1 98.6 98.0 98.3 95.0 95.2 94.9 95.0 84.3 81.8 83.0 82.4</cell></row><row><cell></cell><cell cols="3">99.2 98.8 98.2 98.5 95.7 95.9 95.9 95.9 86.0 83.5 84.5 84.0</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://github.com/yuyouxixi/airway-labeling/tree/main/dataset.</p></note>
		</body>
		<back>

			<div type="funding">
<div><p>This work was partly supported by <rs type="funder">National Key R&amp;D Program of China</rs> (<rs type="grantNumber">2019YFB1311503</rs>, <rs type="grantNumber">2017YFC0112700</rs>),</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_3J6sGYQ">
					<idno type="grant-number">2019YFB1311503</idno>
				</org>
				<org type="funding" xml:id="_jYm59pX">
					<idno type="grant-number">2017YFC0112700</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43990-2 37.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">A generalization of transformer networks to graphs</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">P</forename><surname>Dwivedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.09699</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Geodesic atlas-based labeling of anatomical trees: application and evaluation on airways extracted from CT</title>
		<author>
			<persName><forename type="first">A</forename><surname>Feragen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1212" to="1226" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.08415</idno>
		<title level="m">Gaussian error linear units (GELUs)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Unignn: a unified framework for graph and hypergraph neural networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.00956</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Automated nomenclature labeling of the bronchial tree in 3D-CT lung images</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kitaoka</surname></persName>
		</author>
		<idno type="DOI">10.1007/3-540-45787-9_1</idno>
		<ptr target="https://doi.org/10.1007/3-540-45787-91" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2002</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Dohi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Kikinis</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">2489</biblScope>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A bottom-up approach for labeling of human airway trees</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Van Rikxoort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Goldin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Abtin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MICCAI Int. WS. Pulm. Im. Anal</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Min</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.08455</idno>
		<title level="m">Transformer for graphs: an overview from architecture perspective</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Automated anatomical labeling of the bronchial branch and its application to the virtual bronchoscopy system</title>
		<author>
			<persName><forename type="first">K</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Hasegawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Suenaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Toriwaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="103" to="114" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Automated anatomical labeling of bronchial branches extracted from CT datasets based on machine learning and combination optimization and its application to bronchoscope guidance</title>
		<author>
			<persName><forename type="first">K</forename><surname>Mori</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-04271-3_86</idno>
		<ptr target="https://doi.org/10.1007/978-3-642-04271-386" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2009</title>
		<editor>
			<persName><forename type="first">G.-Z</forename><surname>Yang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Hawkes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Noble</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Taylor</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">5762</biblScope>
			<biblScope unit="page" from="707" to="714" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">H</forename><surname>Netter</surname></persName>
		</author>
		<title level="m">Atlas of human anatomy, Professional Edition E-Book: including NetterReference. com Access with full downloadable image Bank</title>
		<imprint>
			<publisher>Elsevier health sciences</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">U-Net: convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-24574-4_28</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-24574-428" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2015</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hornegger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">9351</biblScope>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">SGNet: structure-aware graph-based network for airway semantic segmentation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87193-2_15</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87193-215" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12901</biblScope>
			<biblScope unit="page" from="153" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Thost</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.07965</idno>
		<title level="m">Directed acyclic graph neural networks</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Matching and anatomical labeling of human airway tree</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tschirren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mclennan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Palágyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sonka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1540" to="1547" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Graph attention networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10903</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Hypergcn: a new method for training graph convolutional networks on hypergraphs</title>
		<author>
			<persName><forename type="first">N</forename><surname>Yadati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nimishakavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Nitin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Louis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Talukdar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Do transformers really perform badly for graph representation?</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ying</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural. Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="28877" to="28888" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">TNN: tree neural network for airway anatomical labeling</title>
		<author>
			<persName><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="103" to="118" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Bronchus segmentation and classification by neural networks and linear programming</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mao</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-32226-7_26</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-32226-726" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2019</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11769</biblScope>
			<biblScope unit="page" from="230" to="239" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
