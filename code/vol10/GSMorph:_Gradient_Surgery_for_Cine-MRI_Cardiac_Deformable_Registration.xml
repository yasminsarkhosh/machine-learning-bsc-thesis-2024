<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">GSMorph: Gradient Surgery for Cine-MRI Cardiac Deformable Registration</title>
				<funder ref="#_JVSXGYM">
					<orgName type="full">Royal Academy of Engineering</orgName>
				</funder>
				<funder ref="#_ECK5VJm #_k5CMy98 #_q7PgyrB">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_U5Z6zKQ">
					<orgName type="full">Shenzhen Science and Technology Innovations Committee</orgName>
				</funder>
				<funder ref="#_gyEZBBg">
					<orgName type="full">Engineering and Physical Sciences Research Council UKRI Frontier Research Guarantee Programmes (INSILICO</orgName>
				</funder>
				<funder ref="#_N4B6EwT">
					<orgName type="full">Royal Society Exchange Programme</orgName>
				</funder>
				<funder ref="#_q52XGfE">
					<orgName type="full">Nanjing University of Information Science and Technology</orgName>
				</funder>
				<funder>
					<orgName type="full">Ph.D. foundation for Innovation and Entrepreneurship in Jiangsu Province</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Haoran</forename><surname>Dou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Centre for Computational Imaging and Simulation Technologies in Biomedicine (CISTIB)</orgName>
								<orgName type="institution">University of Leeds</orgName>
								<address>
									<settlement>Leeds</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ning</forename><surname>Bi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Centre for Computational Imaging and Simulation Technologies in Biomedicine (CISTIB)</orgName>
								<orgName type="institution">University of Leeds</orgName>
								<address>
									<settlement>Leeds</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Luyi</forename><surname>Han</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Radiology and Nuclear Medicine</orgName>
								<orgName type="institution">Radboud University Medical Centre</orgName>
								<address>
									<settlement>Nijmegen</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Radiology</orgName>
								<orgName type="institution">Netherlands Cancer Institute</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuhao</forename><surname>Huang</surname></persName>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">School of Biomedical Engineering</orgName>
								<orgName type="department" key="dep2">Health Science Center</orgName>
								<orgName type="laboratory">Engineering Laboratory for Medical Ultrasound</orgName>
								<orgName type="institution" key="instit1">National-Regional Key Technology</orgName>
								<orgName type="institution" key="instit2">Shenzhen University</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Medical Ultrasound Image Computing (MUSIC) Lab</orgName>
								<orgName type="institution">Shenzhen University</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution" key="instit1">Marshall Laboratory of Biomedical Engineering</orgName>
								<orgName type="institution" key="instit2">Shenzhen University</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ritse</forename><surname>Mann</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Radiology and Nuclear Medicine</orgName>
								<orgName type="institution">Radboud University Medical Centre</orgName>
								<address>
									<settlement>Nijmegen</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Radiology</orgName>
								<orgName type="institution">Netherlands Cancer Institute</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xin</forename><surname>Yang</surname></persName>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">School of Biomedical Engineering</orgName>
								<orgName type="department" key="dep2">Health Science Center</orgName>
								<orgName type="laboratory">Engineering Laboratory for Medical Ultrasound</orgName>
								<orgName type="institution" key="instit1">National-Regional Key Technology</orgName>
								<orgName type="institution" key="instit2">Shenzhen University</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Medical Ultrasound Image Computing (MUSIC) Lab</orgName>
								<orgName type="institution">Shenzhen University</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution" key="instit1">Marshall Laboratory of Biomedical Engineering</orgName>
								<orgName type="institution" key="instit2">Shenzhen University</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff6">
								<orgName type="institution">Shenzhen RayShape Medical Technology Co., Ltd</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dong</forename><surname>Ni</surname></persName>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">School of Biomedical Engineering</orgName>
								<orgName type="department" key="dep2">Health Science Center</orgName>
								<orgName type="laboratory">Engineering Laboratory for Medical Ultrasound</orgName>
								<orgName type="institution" key="instit1">National-Regional Key Technology</orgName>
								<orgName type="institution" key="instit2">Shenzhen University</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Medical Ultrasound Image Computing (MUSIC) Lab</orgName>
								<orgName type="institution">Shenzhen University</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution" key="instit1">Marshall Laboratory of Biomedical Engineering</orgName>
								<orgName type="institution" key="instit2">Shenzhen University</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nishant</forename><surname>Ravikumar</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Centre for Computational Imaging and Simulation Technologies in Biomedicine (CISTIB)</orgName>
								<orgName type="institution">University of Leeds</orgName>
								<address>
									<settlement>Leeds</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff7">
								<orgName type="department" key="dep1">Division of Informatics, Imaging and Data Science</orgName>
								<orgName type="department" key="dep2">Schools of Computer Science and Health Sciences</orgName>
								<orgName type="institution">University of Manchester</orgName>
								<address>
									<settlement>Manchester</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alejandro</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Centre for Computational Imaging and Simulation Technologies in Biomedicine (CISTIB)</orgName>
								<orgName type="institution">University of Leeds</orgName>
								<address>
									<settlement>Leeds</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff7">
								<orgName type="department" key="dep1">Division of Informatics, Imaging and Data Science</orgName>
								<orgName type="department" key="dep2">Schools of Computer Science and Health Sciences</orgName>
								<orgName type="institution">University of Manchester</orgName>
								<address>
									<settlement>Manchester</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff8">
								<orgName type="department" key="dep1">Medical Imaging Research Center (MIRC)</orgName>
								<orgName type="department" key="dep2">Electrical Engineering and Cardiovascular Sciences Departments</orgName>
								<orgName type="institution">KU Leuven</orgName>
								<address>
									<settlement>Leuven</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
							<affiliation key="aff9">
								<orgName type="institution">Alan Turing Institute</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Yunzhi</forename><surname>Huang</surname></persName>
							<email>yunzhi.huang.scu@gmail.com</email>
							<affiliation key="aff10">
								<orgName type="department" key="dep1">Institute for AI in Medicine</orgName>
								<orgName type="department" key="dep2">School of Artificial Intelligence</orgName>
								<orgName type="institution">Nanjing University of Information Science and Technology</orgName>
								<address>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">GSMorph: Gradient Surgery for Cine-MRI Cardiac Deformable Registration</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="613" to="622"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">B032971436B91199B7CE03A95882B1C7</idno>
					<idno type="DOI">10.1007/978-3-031-43999-5_58</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-23T22:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Medical image registration</term>
					<term>Gradient surgery</term>
					<term>Regularization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep learning-based deformable registration methods have been widely investigated in diverse medical applications. Learning-based deformable registration relies on weighted objective functions trading off registration accuracy and smoothness of the deformation field. Therefore, they inevitably require tuning the hyperparameter for optimal registration performance. Tuning the hyperparameters is highly computationally expensive and introduces undesired dependencies on domain knowledge. In this study, we construct a registration model based on the gradient surgery mechanism, named GSMorph, to achieve a hyperparameter-free balance on multiple losses. In GSMorph, we reformulate the optimization procedure by projecting the gradient of similarity loss orthogonally to the plane associated with the smoothness constraint, rather than additionally introducing a hyperparameter to balance these two competing H. Dou and N. Bi-Contributed equally to this work.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Image registration is fundamental to many medical image analysis applications, e.g., motion tracking, atlas construction, and disease diagnosis <ref type="bibr" target="#b4">[5]</ref>. Conventional registration methods usually require computationally expensive iterative optimization, making it inefficient in clinical practice <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b18">19]</ref>. Deep learning has recently been widely exploited in the registration domain due to its superior representation extraction capability and fast inference speed <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b6">7]</ref>. Deep-learningbased registration (DLR) formulates registration as a network learning process minimizing a composite objective function comprising one similarity loss to penalize the difference in the appearance of the image pair, and a regularization term to ensure the smoothness of deformation field. Typically, to balance the registration accuracy and smoothness of the deformation field, a hyperparameter is introduced in the objective function. However, performing hyperparameter tuning is labor-intensive, time-consuming, and ad-hoc; searching for the optimal parameter setting requires extensive ablation studies and hence training tens of models and establishing a reasonable parameter search space. Therefore, alleviating, even circumventing, hyperparameter search to accelerate development and deployment of DLR models remains challenging.</p><p>Recent advances <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b12">13]</ref> in DLR have primarily focused on network architecture design to boost registration performance. Few studies <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b15">16]</ref> investigated the potential in preventing hyperparameter searching by hypernetwork <ref type="bibr" target="#b7">[8]</ref> and conditional learning <ref type="bibr" target="#b9">[10]</ref>. Hoopes et al. <ref type="bibr" target="#b8">[9]</ref> leveraged a hyper-network that takes the hyperparameter as input to generate the weight of the DLR network. Although effective, it introduces a large number of additional parameters to the basic DLR network, making the framework computationally expensive. In parallel, Mok et al. <ref type="bibr" target="#b15">[16]</ref> proposed to learn the effect of the hyperparameter and condition it on the feature statistics (usually illustrated as style in computer vision <ref type="bibr" target="#b9">[10]</ref>) to manipulate the smoothness of the deformation field in the inference phase. Both methods can avoid hyperparameter tuning while training the DLR model. However, they still require a reasonable sampling space and strategy of the hyperparameter, which can be empirically dependent.</p><p>Gradient surgery (GS) projects conflicting gradients of different losses during the optimization process of the model to mitigate gradient interference. This has proven useful in multi-task learning <ref type="bibr" target="#b19">[20]</ref> and domain generalization <ref type="bibr" target="#b14">[15]</ref>. Motivated by these studies, we propose utilizing the GS to moderate the discordance between the similarity loss and regularization loss. The proposed method can further avert searching the weight for balancing losses in training the DLR.</p><p>-We propose GSMorph, a gradient-surgery-based DLR model. Our method can circumvent tuning the hyperparameter in composite loss function with a gradient-level reformulation to reach the trade-off between registration accuracy and smoothness of the deformation field. -Existing GS approaches have operated the parameters' gradients independently or integrally. We propose a layer-wise GS to group by the parameters for optimization to ensure the flexibility and robustness of the optimization process. -Our method is model-agnostic and can be integrated into any DLR network without extra parameters or losing inference speed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>Deformable image registration estimates the non-linear correspondence field φ between the moving, M , and fixed, F , images (Fig. <ref type="figure" target="#fig_0">1</ref>). Such procedure is mathematically formulated as φ = f θ (F, M ). For learning-based registration methods, f θ (usually adopted by a neural network) takes the fixed and moving image pair as input and outputs the deformation field via the optimal parameters θ. Typically, θ can be updated using standard mini-batch gradient descent as follows:</p><formula xml:id="formula_0">θ := θ -α∇ θ (L sim (θ; F, M • φ) + λL Reg (θ; φ)) (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where α is the learning rate; L sim is the similarity loss to penalize differences in the appearance of the moving and fixed images (e.g., mean square error, mutual information or local negative cross-correlation); L reg is the regularization loss to encourage the smoothness of the deformation field (this can be computed by the gradient of the deformation field); λ is the hyperparameter balancing the tradeoff between L sim and L reg to achieve desired registration accuracy while preserving the smoothness of the deformation field in the meantime. However, hyperparameter tuning is time-consuming and highly experience-dependent, making it tough to reach the optimal solution. Insight into the optimization procedure in Eq. 1, as registration accuracy and spatial smoothness are potentially controversial in model optimization, the two constraints might have different directions and strengths while going through the gradient descent. Based on this, we provide a geometric view to depict the gradient changes for θ based on the gradient surgery technique. The conflicting relationship between two controversial constraints can be geometrically projected as orthogonal vectors. Depending on the orthogonal relationship, merely updating the gradients of the similarity loss would automatically associate with the updates of the regularization term. In this way, we avoid tuning the hyperparameter λ to optimize θ. The Eq. 1 can then be rewritten into a non-hyperparameter pattern:</p><formula xml:id="formula_2">θ := θ -αΦ(∇ θ L sim (θ; F, M • φ)) (<label>2</label></formula><formula xml:id="formula_3">)</formula><p>where Φ(•) is the operation of proposed GS method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Layer-Wise Gradient Surgery</head><p>Figure <ref type="figure">2</ref> illustrates the two scenarios of gradients while optimizing the DLR network via vanilla gradient descent or gradient surgery. We first define that the gradient of similarity loss, g sim , and that of regularization loss, g reg , are conflicting when the angle between g sim and g reg is the obtuse angle, viz. g sim , g reg &lt; 0.</p><p>In this study, we propose updating the parameters of neural networks by the original g sim independently, when g sim and g reg are non-conflicting, representing g sim has no incompatible component of the gradient along the direction of g reg . Consequently, optimization with sole g sim within a non-conflicting scenario can inherently facilitate the spatial smoothness of deformations. Conversely, as shown in Fig. <ref type="figure">2</ref>, conflicting gradients are the dominant reason associated with non-smooth deformations. Hence, deconflicting gradients in the optimization of the DLR network to ensure high registration accuracy, as well as smooth deformation, is the primary goal of our study. Following a simple and intuitive procedure, we project the g sim onto the normal plane of the g reg , where the projected similarity gradient g and g reg are non-conflicting along each gradient's direction.</p><p>Existing studies <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b19">20]</ref> performed the GS in terms of independent parameters or the entire network. Despite the effectiveness, these can be either unstable or inflexible. Considering that a neural network usually extracts features through the collaboration of each parameter group in the convolution layers, we introduce a layer-wise GS to ensure its stability and flexibility. The parameter updating rule is detailed in the Algorithm 1. Specifically, in each gradient updating iteration, we first compute the gradients of two losses for the parameter group in</p><formula xml:id="formula_4">Vanilla Gradient Descent = Gradient Surgery = Φ( , )</formula><p>Non-conflicting Conflicting Fig. <ref type="figure">2</ref>. Visualization of vanilla gradient descent and gradient surgery for non-conflicting and conflicting gradients. Regarding vanilla gradient descent, the gradient, g, is computed based on the average of gsim and greg. Our GS-based approach projects the gsim onto the normal vector of greg to prevent disagreements between the similarity loss and regularization loss. On the other hand, we only update the gsim in non-conflicting scenarios.</p><p>each layer separately. Then, the conflicting relationship between the two gradients is calculated based on their inner production. Once the two gradients are non-conflicting, the gradients used to update its corresponding parameter group will be only the original gradients of similarity loss; on the contrary, the gradients will be the projected similarity gradients orthogonal to the gradients of regularization, which can be calculated as g i sim -</p><formula xml:id="formula_5">g i sim ,g i reg g i reg 2 g i reg .</formula><p>After performing GS on all layer-wise parameter groups in the network, the final gradients will be used to update the model's parameters. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1. Gradient surgery</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Network Architecture</head><p>Our network architecture (seen in Fig. <ref type="figure" target="#fig_0">1</ref>) is similar to VoxelMorph <ref type="bibr" target="#b6">[7]</ref> that comprises naive U-Net <ref type="bibr" target="#b17">[18]</ref> and spatial transform network (STN) <ref type="bibr" target="#b11">[12]</ref>. The U-Net takes the moving and fixed image pair as input and outputs the deformation field, which is used to warp the moving image via STN. The U-Net consists of an encoder and a decoder with skip connections, which forward the features from each layer in the encoder to the corresponding layer in the decoder by concatenation to enhance the feature aggregation and prevent gradient vanishing. The number of feature maps in the encoder part of the network is 16, 32, 64, 128, and 256, increasing the number of features as their size shrinks, and vice versa in the decoder part. Each convolutional block in the encoder and decoder has two sequential convolutions with a kernel size of 3, followed by a batch normalization and a leaky rectified linear unit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets and Implementations</head><p>Datasets. In this study, we used two public cardiac cine-MRI datasets for investigation and comparison: ACDC <ref type="bibr" target="#b2">[3]</ref> and M&amp;M <ref type="bibr" target="#b3">[4]</ref>. ACDC and M&amp;M contain 100 and 249 subjects, respectively. We followed a proportion of 75%, 5%, and 20% to split each dataset for training, validation, and testing. We selected the image from the cine-MRI cardiac sequence at the End Systole (ES) time point of the cardiac cycle as the moving image, and that at the End Diastole (ED) as the fixed one. All images were cropped into the size of 128×128 centralized to the heart. We normalized the intensity of images into the range from 0 to 1 before inputting them into the model. Implementation Details. We implemented our model in PyTorch <ref type="bibr" target="#b16">[17]</ref>, using a standard PC with an NVIDIA GTX 2080ti GPU. We trained the network through Adam optimizer <ref type="bibr" target="#b13">[14]</ref> with a learning rate of 5e-3 and a batch size of 32 for 500 epochs. We also implemented and trained alternative methods for comparison with the same data and similar hyper-parameters for optimization. Our source code is available at https://github.com/wulalago/GSMorph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Alternative Methods and Evaluation Criteria</head><p>To demonstrate the advantages of our proposed method in medical image registration, we compared it with two conventional deformable registration methods, i.e., Demons <ref type="bibr" target="#b18">[19]</ref> and SyN <ref type="bibr" target="#b0">[1]</ref>, and a widely-used DLR model, Voxel-Morph <ref type="bibr" target="#b6">[7]</ref>. These methods usually need laborious effort in hyperparameter tuning. Additionally, we reported the results of VoxelMorph trained with different λ (i.e., 0.1, 0.01, and 0.001, denoted as VoxelMorph-l, VoxelMorphm, VoxelMorph-s). Meanwhile, we compared our approach to one alternative DLR model based on the hyperparameter learning, i.e., HyperMorph <ref type="bibr" target="#b8">[9]</ref>. This method only require additional validations in searching the optimal hyperparameter without necessarily tuning it from scratch. Finally, we reformulated two variations of GS based on our concept for further comparison. Specifically, GS-Agr <ref type="bibr" target="#b14">[15]</ref> treats the gradient of each parameter independently. It updates the parameter with the gradient of similarity loss in the non-conflicting scenario, and a random gradient sampled from the Gaussian distribution when conflicting. While GS-PCGrad <ref type="bibr" target="#b19">[20]</ref> uses the same GS strategy as ours, but with respect to the whole parameters of the entire network. The Initial represents the results without any deformation.</p><p>In this study, we used six criteria to evaluate the efficacy and efficiency of the investigated methods, including Dice score (Dice) and 95% Hausdorff distance (HD95) to validate the registration accuracy of the regions of interest, Mean square error (MSE) to evaluate the pixel-level appearance difference between the moved and fixed image-pairs, the percentage of pixels with negative Jacobian determinant (NJD) values to compare the smoothness and diffeomorphism of the deformation field, the number of parameters (Param) of the neural network and inference speed (Speed) to investigate the efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results</head><p>As summarized in Table <ref type="table" target="#tab_1">1</ref>, our method could obtain the best MSE in the ACDC dataset and Dice in the M&amp;M dataset while achieving comparable performance with the tuned VoxelMorph over other metrics. The Dice and HD95 reported in Table <ref type="table" target="#tab_1">1</ref> were averaged over three anatomical regions of interest in the heart, i.e., Left ventricle, Myocardium, and Right Ventricle (LV, Myo, and RV). Consequently, the proposed model achieved superior registration accuracy and spatial regularization with faster inference speed than the two conventional registration methods. We also observed that our approach gained higher registration performance than HyperMorph in both datasets. Regarding the GS-based methods, GS-Agr totally collapsed, as the conflicting gradients accounted for most have  been replaced by random noise. On the other hand, GS-PCGrad only yielded an inadequate registration performance with an inclination of over-regularization.</p><p>The comparison in the GS-based method shows the flexibility and robustness of our approach. Figure <ref type="figure" target="#fig_1">3</ref> illustrates the sample cases of the warped images and the corresponding deformation fields from the compared methods. It can be observed our methods could obtain the moved images most similar to the fixed ones. Voxelmorph could achieve comparable results to us but still require a time-consuming hyperparameter tuning. Overall, the results of the comparisons in Table <ref type="table" target="#tab_1">1</ref> and Fig. <ref type="figure" target="#fig_1">3</ref> indicate that our method performed the best among all the techniques that we implemented and examined, showing the effectiveness of our model in balancing the trade-off between registration accuracy and smoothness of deformations.</p><p>In Table <ref type="table" target="#tab_2">2</ref>, we have also reported the number of parameters and inference speed. We observed that DLR methods could obtain faster speed compared with conventional ones in general. As our proposed approach only modified the optimization procedure of the backbone network, it could maintain the original inference speed and the number of parameters. Conversely, HyperMorph intro- duced tremendous extra parameters and loss of inference speed as they adopted the secondary network to generate the conditions or weights of the main network architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>This work presents a gradient-surgery-based registration framework for medical images. To the best of our knowledge, this is the first study to employ gradient surgery to refine the optimization procedure in learning the deformation fields.</p><p>In our GSMorph, the gradients from the similarity constraint were projected onto the plane orthogonal to those from the regularization term. In this way, merely updating the gradients in optimizing the registration accuracy would result in a joint updating of the gradients from the similarity and regularity constraints. Then, no additional regularization loss is required in the network optimization and no hyperparameter is further required to explicitly trade off between registration accuracy and spatial smoothness. Our model outperformed the conventional registration methods and the alternative DLR models. Finally, the proposed method is model-agnostic and can be integrated into any DLR network without introducing extra parameters or compromising the inference speed. We believe GSMorph will facilitate the development and deployment of DLR models and alleviate the influence of hyperparameters on performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Schematic illustration of our proposed GSMorph. GS modifies the gradients computed by similarity loss Lsim and regularization loss Lreg, then updates the model's parameters θ.</figDesc><graphic coords="4,92,61,54,59,271,93,96,10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Visual comparison of the registration results of the investigated methods for two representative test cases in ACDC and M&amp;M datasets. The top rows are the fixed images and moved images from different methods; the bottom rows are the moving images and deformation fields. (We encourage you to zoom in for better visualization)</figDesc><graphic coords="8,56,31,53,84,311,38,146,32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Parameters θi in ith layer of the network; Number of layers in the network N . 1: gsim ← ∇ θ Lsim 2: greg ← ∇ θ Lreg 3: for i = 1 → N do</figDesc><table><row><cell>4: 5:</cell><cell cols="2">if g i sim , g i reg &gt; 0 then gi = g i sim</cell><cell></cell></row><row><cell>6: 7:</cell><cell>else gi = g i sim -</cell><cell>g i sim ,g i reg g i reg 2</cell><cell>g i reg</cell></row><row><cell>8:</cell><cell>end if</cell><cell></cell><cell></cell></row><row><cell>9:</cell><cell>Δθi = gi</cell><cell></cell><cell></cell></row><row><cell cols="2">10: end for</cell><cell></cell><cell></cell></row><row><cell cols="2">11: Update θ</cell><cell></cell><cell></cell></row></table><note><p>Require:</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Quantitative comparison of investigated methods on the testing datasets over ACDC and M&amp;M.</figDesc><table><row><cell>Methods</cell><cell>Dataset</cell><cell></cell><cell></cell></row><row><cell></cell><cell>ACDC</cell><cell></cell><cell>M&amp;M</cell></row><row><cell></cell><cell>Dice(%)</cell><cell>HD95(mm) MSE(10 -2 ) NJD(%)</cell><cell>Dice(%)</cell><cell>HD95(mm) MSE(10 -2 ) NJD(%)</cell></row><row><cell>Initial</cell><cell cols="2">61.81±8.68 4.40±1.33 1.58±0.52 -</cell><cell cols="2">61.03±10.16 4.79±1.82 1.90±1.08 -</cell></row><row><cell>Demons</cell><cell cols="4">85.38±3.52 1.67±0.75 0.46±0.21 1.31±0.59 75.66±10.30 17.79±6.23 0.71±0.61 1.84±1.19</cell></row><row><cell>SyN</cell><cell cols="4">79.28±8.23 2.24±1.28 0.65±0.21 0.30±0.27 81.97±9.36 2.45±2.04 0.84±0.12 0.49±0.47</cell></row><row><cell cols="5">VoxelMorph-s 86.69±2.17 1.30±0.24 0.39±0.14 2.01±0.96 77.12±9.36 3.43±2.18 0.42±0.29 3.45±2.33</cell></row><row><cell cols="5">VoxelMorph-m 87.47±2.21 1.29±0.30 0.42±0.15 0.67±0.48 79.93±8.57 2.91±1.98 0.48±0.32 1.31±1.10</cell></row><row><cell cols="5">VoxelMorph-l 82.12±4.30 1.87±0.64 0.59±0.18 0.10±0.14 77.18±8.69 2.81±1.60 0.74±0.43 0.16±0.22</cell></row><row><cell>HyperMorph</cell><cell cols="4">83.44±3.55 1.75±0.64 0.47±0.20 1.60±0.86 77.21±8.45 3.28±1.99 0.59±0.37 2.50±1.22</cell></row><row><cell>GS-Agr</cell><cell cols="2">63.40±9.15 4.20±1.35 1.33±0.43 0</cell><cell cols="2">63.41±9.85 4.50±1.77 1.55±0.86 &lt;0.001</cell></row><row><cell>GS-PCGrad</cell><cell cols="4">84.59±3.53 1.62±0.53 0.51±0.16 0.11±0.17 80.67±8.18 2.48±1.67 0.59±0.36 0.41±0.44</cell></row><row><cell>GSMorph</cell><cell cols="4">87.45±2.27 1.34±0.40 0.31±0.11 0.87±0.52 82.26±6.59 2.66±1.93 0.49±0.27 0.98±0.84</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Number of parameters and inference speed of investigated methods on the testing datasets over ACDC and M&amp;M.</figDesc><table><row><cell cols="2">Methods Demons</cell><cell>SyN</cell><cell cols="3">VoxelMorph HyperMorph GSMorph</cell></row><row><cell cols="2">Params -</cell><cell>-</cell><cell>1.96M</cell><cell>126M</cell><cell>1.96M</cell></row><row><cell>Speed</cell><cell cols="3">7.55±1.79 16.59±5.48 2.29±0.83</cell><cell>2.96±1.09</cell><cell>2.29±0.83</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement. This work was supported by the <rs type="funder">National Natural Science Foundation of China</rs> (<rs type="grantNumber">62101365</rs>, <rs type="grantNumber">62171290</rs>, <rs type="grantNumber">62101343</rs>), <rs type="programName">Shenzhen-Hong Kong Joint Research Program</rs> (<rs type="grantNumber">SGDX20201103095613036</rs>), <rs type="funder">Shenzhen Science and Technology Innovations Committee</rs> (<rs type="grantNumber">20200812143441001</rs>), the startup foundation of <rs type="funder">Nanjing University of Information Science and Technology</rs>, the <rs type="funder">Ph.D. foundation for Innovation and Entrepreneurship in Jiangsu Province</rs>, the <rs type="funder">Royal Academy of Engineering</rs> (<rs type="grantNumber">INSILEX CiET1819/19</rs>), <rs type="funder">Engineering and Physical Sciences Research Council UKRI Frontier Research Guarantee Programmes (INSILICO</rs>, <rs type="grantNumber">EP/Y030494/1</rs>), and the <rs type="funder">Royal Society Exchange Programme</rs> <rs type="grantNumber">CROSSLINK IES\NSFC\201380</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_ECK5VJm">
					<idno type="grant-number">62101365</idno>
				</org>
				<org type="funding" xml:id="_k5CMy98">
					<idno type="grant-number">62171290</idno>
				</org>
				<org type="funding" xml:id="_q7PgyrB">
					<idno type="grant-number">62101343</idno>
					<orgName type="program" subtype="full">Shenzhen-Hong Kong Joint Research Program</orgName>
				</org>
				<org type="funding" xml:id="_U5Z6zKQ">
					<idno type="grant-number">SGDX20201103095613036</idno>
				</org>
				<org type="funding" xml:id="_q52XGfE">
					<idno type="grant-number">20200812143441001</idno>
				</org>
				<org type="funding" xml:id="_JVSXGYM">
					<idno type="grant-number">INSILEX CiET1819/19</idno>
				</org>
				<org type="funding" xml:id="_gyEZBBg">
					<idno type="grant-number">EP/Y030494/1</idno>
				</org>
				<org type="funding" xml:id="_N4B6EwT">
					<idno type="grant-number">CROSSLINK IES\NSFC\201380</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Symmetric diffeomorphic image registration with cross-correlation: evaluating automated labeling of elderly and neurodegenerative brain</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">B</forename><surname>Avants</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Gee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="26" to="41" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An unsupervised learning model for deformable medical image registration</title>
		<author>
			<persName><forename type="first">G</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Sabuncu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guttag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Dalca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="9252" to="9260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deep learning techniques for automatic MRI cardiac multistructures segmentation and diagnosis: is the problem solved?</title>
		<author>
			<persName><forename type="first">O</forename><surname>Bernard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2514" to="2525" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multi-centre, multi-vendor and multi-disease cardiac segmentation: the M&amp;Ms challenge</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Campello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3543" to="3554" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep learning in medical image registration</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Diaz-Pinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ravikumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Prog. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">12003</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A deep discontinuity-preserving image registration network</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ravikumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87202-1_5</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87202-15" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12904</biblScope>
			<biblScope unit="page" from="46" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Unsupervised learning for fast probabilistic diffeomorphic registration</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Dalca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guttag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Sabuncu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-00928-1_82</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-00928-182" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2018</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Schnabel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Davatzikos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Alberola-López</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Fichtinger</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">11070</biblScope>
			<biblScope unit="page" from="729" to="738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">D</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.09106</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Hypernetworks</publisher>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">HyperMorph: amortized hyperparameter learning for image registration</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hoopes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fischl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guttag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Dalca</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-78191-0_1</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-78191-01" />
	</analytic>
	<monogr>
		<title level="m">IPMI 2021</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Feragen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Sommer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Schnabel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Nielsen</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12729</biblScope>
			<biblScope unit="page" from="3" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Arbitrary style transfer in real-time with adaptive instance normalization</title>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1501" to="1510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Difficulty-aware hierarchical convolutional neural networks for deformable registration of brain MR images</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Yap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page">101817</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Spatial transformer networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning a model-driven variational network for deformable image registration</title>
		<author>
			<persName><forename type="first">X</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Thorley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">B</forename><surname>Styles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Leonardis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>De Marvao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>O'regan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="199" to="212" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: a method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Domain generalization via gradient surgery</title>
		<author>
			<persName><forename type="first">L</forename><surname>Mansilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Echeveste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Milone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ferrante</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="6630" to="6638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Conditional deformable image registration with convolutional neural network</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C W</forename><surname>Mok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C S</forename><surname>Chung</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87202-1_4</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87202-14" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12904</biblScope>
			<biblScope unit="page" from="35" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">PyTorch: an imperative style, high-performance deep learning library</title>
		<author>
			<persName><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">U-Net: convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-24574-4_28</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-24574-428" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2015</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hornegger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">9351</biblScope>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Diffeomorphic demons: efficient non-parametric image registration</title>
		<author>
			<persName><forename type="first">T</forename><surname>Vercauteren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Pennec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Perchant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ayache</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="S72" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Gradient surgery for multi-task learning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hausman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="5824" to="5836" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
