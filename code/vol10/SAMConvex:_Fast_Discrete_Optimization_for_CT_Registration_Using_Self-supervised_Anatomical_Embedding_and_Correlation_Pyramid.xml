<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SAMConvex: Fast Discrete Optimization for CT Registration Using Self-supervised Anatomical Embedding and Correlation Pyramid</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zi</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">DAMO Academy</orgName>
								<orgName type="institution" key="instit2">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory">Hupan Lab</orgName>
								<address>
									<postCode>310023</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Lin</forename><surname>Tian</surname></persName>
							<email>lintian@cs.unc.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">DAMO Academy</orgName>
								<orgName type="institution" key="instit2">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of North Carolina at Chapel Hill</orgName>
								<address>
									<settlement>Chapel Hill</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tony</forename><forename type="middle">C W</forename><surname>Mok</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">DAMO Academy</orgName>
								<orgName type="institution" key="instit2">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory">Hupan Lab</orgName>
								<address>
									<postCode>310023</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaoyu</forename><surname>Bai</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">DAMO Academy</orgName>
								<orgName type="institution" key="instit2">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory">Hupan Lab</orgName>
								<address>
									<postCode>310023</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Puyang</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">DAMO Academy</orgName>
								<orgName type="institution" key="instit2">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory">Hupan Lab</orgName>
								<address>
									<postCode>310023</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jia</forename><surname>Ge</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">The First Affiliated Hospital of College of Medicine</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jingren</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">DAMO Academy</orgName>
								<orgName type="institution" key="instit2">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory">Hupan Lab</orgName>
								<address>
									<postCode>310023</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Le</forename><surname>Lu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">DAMO Academy</orgName>
								<orgName type="institution" key="instit2">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xianghua</forename><surname>Ye</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">The First Affiliated Hospital of College of Medicine</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ke</forename><surname>Yan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">DAMO Academy</orgName>
								<orgName type="institution" key="instit2">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory">Hupan Lab</orgName>
								<address>
									<postCode>310023</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dakai</forename><surname>Jin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">DAMO Academy</orgName>
								<orgName type="institution" key="instit2">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SAMConvex: Fast Discrete Optimization for CT Registration Using Self-supervised Anatomical Embedding and Correlation Pyramid</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="559" to="569"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">771B3266AD634262873BD3E932FE181A</idno>
					<idno type="DOI">10.1007/978-3-031-43999-5_53</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-23T22:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Medical Image Registration</term>
					<term>Large Deformation Z</term>
					<term>Li and L</term>
					<term>Tian-Equal contribution</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Estimating displacement vector field via a cost volume computed in the feature space has shown great success in image registration, but it suffers excessive computation burdens. Moreover, existing feature descriptors only extract local features incapable of representing the global semantic information, which is especially important for solving large transformations. To address the discussed issues, we propose SAMConvex, a fast coarse-to-fine discrete optimization method for CT registration that includes a decoupled convex optimization procedure to obtain deformation fields based on a self-supervised anatomical embedding (SAM) feature extractor that captures both local and global information. To be specific, SAMConvex extracts per-voxel features and builds 6D correlation volumes based on SAM features, and iteratively updates a flow field by performing lookups on the correlation volumes with a coarse-to-fine scheme. SAMConvex outperforms the state-of-the-art learning-based methods and optimization-based methods over two inter-patient registration datasets (Abdomen CT and HeadNeck CT) and one intra-patient registration dataset (Lung CT). Moreover, as an optimization-based method, SAMConvex only takes ∼2 s (∼5 s with instance optimization) for one paired images.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Deformable image registration <ref type="bibr" target="#b20">[21]</ref>, a fundamental medical image analysis task, has traditionally been approached as a continuous optimization <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b23">24]</ref> problem over the space of dense displacement fields between image pairs. The iterative process always leads to inefficiency. Recent learning-based approaches that use a deep network to predict a displacement field <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b29">30]</ref>, yield much faster runtime and have gained huge attention. However, they often struggle with versatile applicability due to the fact that they require training per registration task. Moreover, gathering enough data for the training is not a trivial task in practice. In addition, both optimization and learning-based methods rely on similarity measures computed over the intensity, which prevents the methods to utilize the anatomy correspondence. Several works <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b9">10]</ref> use feature descriptors that provide modality and contrast invariant information but they still can only represent local information and do not contain the global semantic information. Thus, they face challenges in settings with large deformations or complex anatomical differences (e.g., inter-patient Abdomen).</p><p>To address this issue, we incorporate a Self-supervised Anatomical eMbedding (SAM) <ref type="bibr" target="#b26">[27]</ref> into registration. SAM generates a unique semantic embedding for each voxel in CT that describes its anatomical structure, thus, providing semantically coherent information suitable for registration. SAME <ref type="bibr" target="#b14">[15]</ref> enhances learning-based registration with SAM embeddings, but it suffers the applicability issue as the other learning-based methods even when the SAM embedding is pre-trained and ready to use out of the box for multiple anatomical regions.</p><p>Registration has also been formulated as a discrete optimization problem <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b25">26]</ref> that employs a dense set of discrete displacements, called cost volume. The main challenge of this category of approach is the massive size of the search space, as millions of voxels exist in a typical 3D CT scan and each voxel in the moving scan can be reasonably paired with thousands of points in the other scan, leading to a high computational burden. To obtain fast registration with discrete optimization, Heinrich et al. <ref type="bibr" target="#b10">[11]</ref> prunes the search space by constructing the cost volume only within the neighborhood of each voxel. However, the magnitude range of the deformation it can solve is limited by the size of the neighborhood window, leading to reliance on an accurate pre-alignment.</p><p>We propose SAMConvex, a coarse-to-fine discrete optimization method for CT registration. Specifically, SAMConvex presents two main components: (1) a discriminative feature extractor that encodes global and local embeddings for each voxel; (2) a lightweight correlation pyramid that constructs multi-scale 6D cost volume by taking the inner product of SAM embeddings. It enjoys the strengths of state-of-the-art accuracy (Sect. 3.2), good generalization (Sect. 3.2 and Sect. 3.3) and fast runtime (Sect. 3.2). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">SAMConvex Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem Formulation</head><p>Given a source image I s : Ω s → R and a target image I t : Ω t → R within a spatial domain Ω ⊂ R n , our goal is to find the spatial transformation ϕ -<ref type="foot" target="#foot_0">1</ref> : Ω t → Ω s . We aim at minimizing the following energy:</p><formula xml:id="formula_0">û = arg min u E D (I s • ϕ -1 , I t ) + λE R (u),<label>(1)</label></formula><p>where the transformation model is the displacement vector field (DVF) ϕ -1 = Id + u with Id being the identity transformation, the E D is the similarity term measuring the similarity between I t and warped image</p><formula xml:id="formula_1">I s • ϕ -1 , E R = ||∇u|| 2 2</formula><p>is the diffusion regularizer that advocates the regularity of ϕ -1 . λ weights between the data matching term and the regularization term.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Decoupling to Convex Optimizations</head><p>We conduct the optimization scheme proposed in <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b28">29]</ref> and we give a brief review here. By introducing an extra term into Eq. 1</p><formula xml:id="formula_2">v, û = arg min v,u E D (I s • (Id + v), I t ) + 1 2θ v -u 2 + λE R (u),<label>(2)</label></formula><p>the optimization then can be decomposed into two sub-optimization problems</p><formula xml:id="formula_3">1 ⎧ ⎪ ⎨ ⎪ ⎩ v = arg min v E D (I s • (Id + v), I t ) + 1 2θ v -û 2 + const, û = arg min u 1 2θ v -u 2 + λE R (u) + const.</formula><p>(</p><formula xml:id="formula_4">)<label>3</label></formula><p>with each can be solved via global optimizations. By alternatively optimizing the two subproblems and progressively reducing θ during the alternative optimization, we get v ≈ û and obtain the solution of Eq. 1 as ϕ -1 = Id + v. To be noted, the first problem in Eq. 3 can be solved point-wise because the spatial derivatives of v is not involved. We can search over the cost volume of each point to obtain the optimal solution of the first problem in Eq. 3. For the second problem, we are inspired by mean-field inference <ref type="bibr" target="#b13">[14]</ref> and process u using average pooling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">E D (•, •) Using Global and Local Semantic Embedding</head><p>Presumably, handling complex registration tasks rely on: (1) distinct features that are robust to inter-subject variation, organ deformation, contrast injection, and pathological changes, and (2) global/contextual information that can benefit the registration accuracy in complex deformation. To achieve these goals, we adopt self-supervised anatomical embedding (SAM) <ref type="bibr" target="#b26">[27]</ref> based feature descriptor that encodes both global and local embeddings. The global embeddings memorize the 3D contextual information of body parts on a coarse level, while the local embeddings differentiate adjacent structures with similar appearances, as shown on the left of Fig. <ref type="figure" target="#fig_0">1</ref>. The former helps the latter to focus on small regions to distinguish with fine-level features.</p><p>To be specific, given an image I ∈ R H×W ×D , we utilize a pre-trained SAM model that outputs a global embedding</p><formula xml:id="formula_5">f global ∈ R 128× H 8 × W 8 × D 2 and a local embedding f local ∈ R 128× H 2 × W 2 × D 2 .</formula><p>We resample the global embedding with bilinear interpolation to match the shape of f global to f local and concatenate them to get</p><formula xml:id="formula_6">f SAM ∈ R 256× H 2 × W 2 × D 2 .</formula><p>We normalize f global and f local before concatenation and adopt the dot product &lt; •, • &gt; as the similarity measure in the following part, with a higher value indicating better alignment.</p><p>With f SAM , we construct E D (•, •) as the cost volume in the SAM feature space within a neighborhood of [-N, N ], where N represents searching radius. Given two images I 0 and I 1 , the resulting E D (•, •) can then be formulated as</p><formula xml:id="formula_7">E D (I 0 , I 1 ) =&lt; f 0 SAM (x), f 1 SAM (x + d) &gt; (4)</formula><p>where f 0 SAM and f 1 SAM are the SAM embedding of I 0 and I 1 , respectively. x is any voxel in the image domain and d is the voxel displacement within the neighborhood.</p><formula xml:id="formula_8">E D (•, •) has the shape of (2N +1)×(2N +1)×(2N +1)× H 2 × W 2 × D 2 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Coarse-to-Fine Optimization Strategy</head><p>Since E D (•, •) is computed within the neighborhood, the magnitude of deformation is bounded by the size of the neighborhood. Our approach to addressing this issue is based on a surprisingly simple but effective observation: performing registration based on a coarse-to-fine scheme with a small search range at each level instead of a large search range at one resolution benefits to 1) significantly improve the efficiency such as low computation burden and fast running time;</p><p>2) enlarge receptive field and improve registration accuracy.</p><p>We first build an image pyramid of I s and I t . At each resolution, we warp the source image with the composed deformation computed from all the previous levels (starting from the coarsest resolution), transform the warped image and target image to the SAM space, and conduct the decoupling to convex optimizations strategy to obtain the deformation between the warped image and target at the current resolution. With such a coarse-to-fine strategy, we estimate a sequence of displacement fields from a starting identity transformation. The final field is computed via the composition of all the displacement fields <ref type="bibr" target="#b29">[30]</ref>.</p><p>To be noted, the cost volume at each level is computed by taking the inputs of {1, 1  2 , 1 4 } resolution. Adding one coarser level consumes less computation than doubling the size of the neighborhood at the fine resolution but yields the same search range.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Implementation Detail</head><p>We conduct the registration in 3 levels of resolutions. At each level, we solve Eq. 3 via five alternative optimizations with 1 2θ = {0.003, 0.01, 0.03, 0.1, 0.3, 1}. To further improve the registration performance, we append a SAM-based instance optimization after the coarse-to-fine registration with a learning rate of 0.05 for 50 iterations. It solves an instance-specific optimization problem <ref type="bibr" target="#b2">[3]</ref> in the SAM feature space. The optimization objective consists of similarity (dot product between SAM feature vectors on the highest resolution) and diffusion regularization terms. All the experiments are run on the CPU of Intel Xeon Platinum 8163 with 16 cores of 2.50 GHz and the GPU of NVIDIA Tesla V100. Code will be available at https://github.com/Alison-brie/SAMConvex.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets and Evaluation Metrics</head><p>We split Abdomen and HeadNeck into a training set and test set to accommodate the requirement of the training dataset of comparing learning-based methods. Lung dataset contains 35 CT pairs, which is not sufficient for developing learningbased methods. Hence, it is only used as a testing set for optimization-based methods. All the methods are evaluated on the test set. The SAM is pre-trained on NIH Lymph Nodes dataset <ref type="bibr" target="#b26">[27]</ref>. All 3 datasets in this paper are not used for pre-training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inter-patient Task on Abdomen:</head><p>The Abdomen CT dataset <ref type="bibr" target="#b11">[12]</ref> contains 30 abdominal scans with 20 for training and 10 for testing. Each image has 13 manually labeled anatomical structures: spleen, right kidney, left kidney, gall bladder, esophagus, liver, stomach, aorta, inferior vena cava, portal and splenic vein, pancreas, left adrenal gland, and right adrenal gland. The images are resampled to the same voxel resolution of 2 mm and spatial dimensions of 192 × 160 × 256.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inter-patient Task on HeadNeck:</head><p>The HeadNeck CT dataset <ref type="bibr" target="#b27">[28]</ref> contains 72 subjects with 13 organs labeled. The manually labeled anatomical structures include the brainstem, left eye, right eye, left lens, right lens, optic chiasm, left optic nerve, right optic nerve, left parotid, right parotid, left and right temporomandibular joint, and spinal cord. We split the dataset into 52, 10, and 10 for training, validation, and test set. For testing, we construct 90 image pairs for registration, with each image, resampled to an isotropic resolution of 2 mm and cropped to 256 × 128 × 224.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Intra-patient Task on Lung:</head><p>The images are acquired as part of the radiotherapy planning process for the treatment of malignancies. We collect a lung 4D CT dataset containing 35 patients, each with inspiratory and expiratory breath-hold image pairs, and take this dataset as an extra test set. Each image has labeled malignancies, and we try to align two phases for motion estimation of malignancies. The images are resampled to a spacing of 2 × 2 × 2 mm and cropped to 256 × 256 × 112. All images are used as testing cases. Evaluation Metrics: We use the average Dice score (DSC) to evaluate the accuracy and compute the standard deviation of the logarithm of the Jacobian determinant (SDlogJ) to evaluate the plausibility of deformation fields, also comparing running time (T test ) on the same hardware.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Registration Results</head><p>We compare with five widely-used and top-performing deformable registration methods, including NiftyReg <ref type="bibr" target="#b23">[24]</ref>, Deeds <ref type="bibr" target="#b8">[9]</ref>, top-ranked ConvexAdam <ref type="bibr" target="#b19">[20]</ref> in Learn2Reg Challenge <ref type="bibr" target="#b11">[12]</ref>, and SOTA learning-based methods LapIRN <ref type="bibr" target="#b17">[18]</ref> and SAME <ref type="bibr" target="#b14">[15]</ref>. All results are based on the SAM-affine <ref type="bibr" target="#b14">[15]</ref> pre-alignment.</p><p>As shown in Table <ref type="table" target="#tab_0">1</ref>, SAMConvex outperforms the widely-used NiftyReg <ref type="bibr" target="#b23">[24]</ref> across the three datasets with an average of 10.0% Dice score improvement. Compared with the best traditional optimization-based method Deeds <ref type="bibr" target="#b8">[9]</ref>, SAM-Convex performs better or comparatively on the three datasets with approximately 20-100 times faster runtime. We also see a better performance of SAMConvex over ConvexAdam <ref type="bibr" target="#b19">[20]</ref>. To be noted, the performance gap between SAMConvex and ConvexAdam is greater on Abdomen CT than the other two datasets. This may be because the deformation is more complex in Abdomen and the anatomical differences between inter-subjects make the registration more challenging. With a coarse-to-fine strategy, SAMConvex can better bear these issues. Although LapIRN <ref type="bibr" target="#b17">[18]</ref> has the fastest inference time, it has slightly inferior registration accuracy as compared to SAMConvex. Moreover, it needs training when being applied to a new dataset. Equipped with SAM, SAME achieves the overall 2nd best performance in two inter-patient registration tasks but with a notably higher folding rate overall. Moreover, it also requires individual training for a new dataset and struggles with the intra-patient lung registration task (small dataset and no available training data). In summary, our SAMConvex achieves the overall best performance as compared to other methods with a fast inference time and comparable deformation field smoothness.</p><p>To better understand the performance of different deformable registration methods, we display organ-specific results of the inter-patient registration task of abdomen CT in Fig. <ref type="figure" target="#fig_1">2</ref> where large deformations and complex anatomical differences exist. As shown, SAMConvex is consistently better than the secondbest and third-best registration methods on most examined abdominal organs, in 11 out of 13 organs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Ablation Study on SAMConvex</head><p>Loss Landscape of SAM. We explore the loss landscapes of SAM-global, SAMlocal, SAM (SAM-global and SAM-local), and MIND via varying the transformation parameters. We conduct experiments on the abdomen dataset<ref type="foot" target="#foot_1">2</ref> . Figure <ref type="figure" target="#fig_3">3</ref> shows the comparison of landscapes when we vary the rotation along two axes. The loss landscape falls to flat quickly when the rotation is greater than 20  Robustness to Pre-alignment. We study the robustness of SAMConvex over different affine pre-alignment. Elastix-Affine <ref type="bibr" target="#b12">[13]</ref> and SAM-Affine are used as the pre-alignment and results are notated as Initial e and Initial a in Table <ref type="table" target="#tab_1">2</ref>, respectively. Compared to ConvexAdam, our method SAMConvex is less affected by the performance of the Affine pre-alignment. This is in line with our expectations. The global information contained in SAM provides E D (I s • ϕ, I t ) a greater capture range than features that contain local information only. Thus, SAM-Convex can register images with larger transformation, leading to less reliance on the performance of the pre-alignment.</p><p>Ablation on Coarse-to-Fine. We study how the number of coarse-to-fine layers and how the size of the neighborhood window affect the registration result on the Abdomen dataset. From Table <ref type="table" target="#tab_2">3</ref>, we can conclude that performing registration with a small search range with a coarse-to-fine scheme instead of a cost volume with a large search range can help to improve registration accuracy and computation efficiency.  Discussion About the Differences with ConvexAdam <ref type="bibr" target="#b19">[20]</ref>. Apart from the SAM extraction module, first, we introduce a cost volume pyramid to the convex optimization framework to reduce the intensive computation burdens. To be specific, with the coarse-to-fine strategy, one can sparsely search on a coarser level with a smaller search radius in each iteration, reaching the same search range as the complete search with less computational complexity. Second, we explicitly validate the robustness of the SAM feature against geometrical transformations and integrate the SAM feature into an instance-specific optimization pipeline. Our SAMConvex is less sensitive to local minimal, achieving superior performance with comparable running time. Ablation study on pyramid designs (Table <ref type="table" target="#tab_2">3</ref>) and leading accuracy on large deformation registration tasks (Table <ref type="table" target="#tab_0">1</ref>) further support our claims.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We present SAMConvex, a coarse-to-fine discrete optimization method for CT registration. It extracts per-voxel semantic global and local features and builds a series of lightweight 6D correlation volumes, and iteratively updates a flow field by performing lookups on the correlation volumes. The performance on two interpatient and one intra-patient registration datasets demonstrates state-of-the-art accuracy, good generalization, and high computation efficiency of SAMConvex.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Left: Image pyramid and refinement at one pyramid level by discrete registration with convex optimization. Right: the detail of convex optimization that consists of SA pyramid and hierarchical optimization at one pyramid level.</figDesc><graphic coords="3,56,46,54,14,339,94,97,57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Comparison of performance-top-three deformable registration methods on all organ groups on Abdomen dataset.</figDesc><graphic coords="7,55,98,53,69,340,30,93,01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>• degrees and 40 • degrees for SAM-local and MIND, respectively. The flattened area indicates where the similarity measure loses the capability to guide the registration because multiple transformation parameters yield the same similarity value. Compared with SAM-local and MIND, SAM-global does not have the flattened area within [-60 • , 60 • ], meaning it can give correct measure over a larger capture range. However, it does not have the fast converging area shown as a spike for the loss landscapes of MIND and SAM-local. When combining SAMglobal and SAM-local together, SAM shows a greater capture range meanwhile fast convergence when the transformation is small.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Loss landscapes of MIND, SAM-global, SAM-local and SAM on Abdomen dataset with varying rotations along two axes.</figDesc><graphic coords="8,41,79,172,64,340,33,142,21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Quantitative results of inter-and intra-subject registration. The subscript of each metric indicates the number of anatomical structures involved. ↑: higher is better, and ↓: lower is better. Initial: initial affine results without deformable registration. Ours indicates the coarse-to-fine registration and IO indicates the instance optimization.</figDesc><table><row><cell>Method</cell><cell cols="2">Abdomen CT</cell><cell></cell><cell cols="2">HeadNeck CT</cell><cell></cell><cell cols="2">Lung CT</cell><cell></cell></row><row><cell>Initial</cell><cell>32.64</cell><cell>-</cell><cell>-</cell><cell>33.91</cell><cell>-</cell><cell>-</cell><cell>67.06</cell><cell>-</cell><cell>-</cell></row><row><cell>NiftyReg</cell><cell>34.98</cell><cell>0.22</cell><cell cols="2">186.54 s 57.66</cell><cell>0.21</cell><cell cols="2">168.39 s 74.59</cell><cell>0.02</cell><cell>85.50 s</cell></row><row><cell>Deeds</cell><cell>46.52</cell><cell>0.44</cell><cell cols="2">45.21 s 61.32</cell><cell>1.07</cell><cell cols="2">42.05 s 81.53</cell><cell>0.49</cell><cell>227.59 s</cell></row><row><cell cols="2">ConvexAdam 44.44</cell><cell>0.74</cell><cell cols="2">6.06 s 61.45</cell><cell>0.77</cell><cell cols="2">3.12 s 79.26</cell><cell>1.17</cell><cell>2.20 s</cell></row><row><cell>LapIRN</cell><cell>46.44</cell><cell>0.72</cell><cell cols="2">0.07 s 60.16</cell><cell>0.58</cell><cell cols="2">0.03 s -</cell><cell>-</cell><cell>-</cell></row><row><cell>SAME</cell><cell>47.12</cell><cell>0.90</cell><cell cols="2">6.88 s 61.35</cell><cell>1.00</cell><cell cols="2">3.34 s -</cell><cell>-</cell><cell>-</cell></row><row><cell>Ours</cell><cell>48.30</cell><cell>0.86</cell><cell cols="2">2.12 s 61.88</cell><cell>0.79</cell><cell cols="2">1.88 s 80.13</cell><cell>0.37</cell><cell>1.86 s</cell></row><row><cell>Ours + IO</cell><cell>51.17</cell><cell>0.86</cell><cell cols="2">5.14 s 63.72</cell><cell>0.88</cell><cell cols="3">4.59 s 81.61 0.21</cell><cell>4.34 s</cell></row></table><note><p>DSC13 ↑ SDlogJ ↓ Ttest ↓ DSC13 ↑ SDlogJ ↓ Ttest ↓ DSC1 ↑ SDlogJ ↓ Ttest ↓</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>ConvexAdam and SAMConvex on different affine pre-alignment.</figDesc><table><row><cell>Method</cell><cell cols="2">DSC 13 ↑</cell></row><row><cell></cell><cell cols="2">Initiale Initiala</cell></row><row><cell>Initial</cell><cell>25.88</cell><cell>32.64</cell></row><row><cell cols="2">ConvexAdam 34.42</cell><cell>44.44</cell></row><row><cell cols="2">SAMConvex 45.38</cell><cell>48.30</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Ablation study on how different pyramid designs affect the performance. The subscript of Pym indicates the number of scales. DSC 13 ↑ SDlogJ ↓ T test ↓</figDesc><table><row><cell>Method</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Pym 1 N ∈ [3]</cell><cell>40.51</cell><cell>0.59</cell><cell>1.69 s</cell></row><row><cell>Pym 1 N ∈ [6]</cell><cell>44.22</cell><cell>1.62</cell><cell>7.84 s</cell></row><row><cell>Pym 2 N ∈ [3, 3]</cell><cell>47.80</cell><cell>0.76</cell><cell>2.03 s</cell></row><row><cell cols="2">Pym 3 N ∈ [2, 3, 3] 48.30</cell><cell>0.86</cell><cell>2.12 s</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>For better illustration, we substitute λER(u) and ED(Is • ϕ, It) with const in the two equations in Eq. 3, respectively.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Refer to Appendix for more experiment results.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43999-5 53.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A fast diffeomorphic image registration algorithm</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ashburner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="95" to="113" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Symmetric diffeomorphic image registration with cross-correlation: evaluating automated labeling of elderly and neurodegenerative brain</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">B</forename><surname>Avants</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Gee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="26" to="41" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Voxelmorph: a learning framework for deformable medical image registration</title>
		<author>
			<persName><forename type="first">G</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Sabuncu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Guttag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Dalca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1788" to="1800" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An algorithm for total variation minimization and applications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chambolle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Math. Imaging Vis</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="89" to="97" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Full flow: optical flow estimation by global optimization over regular grids</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="4706" to="4714" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Automated learning for deformable medical image registration by jointly optimizing network architectures and objective functions</title>
		<author>
			<persName><forename type="first">X</forename><surname>Fan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.06810</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Closing the gap between deep and conventional image registration using probabilistic dense displacement networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Heinrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">MIND: modality independent neighbourhood descriptor for multi-modal deformable registration</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Heinrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1423" to="1435" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Globally optimal deformable registration on a minimum spanning tree using dense displacement sampling</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Heinrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jenkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Brady</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Schnabel</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-33454-2_15</idno>
		<ptr target="https://doi.org/10.1007/978-3-642-33454-215" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2012</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ayache</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Delingette</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Golland</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Mori</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">7512</biblScope>
			<biblScope unit="page" from="115" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Towards realtime multimodal fusion for image-guided interventions using self-similarities</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Heinrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jenkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Papiez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brady</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Schnabel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<biblScope unit="volume">8149</biblScope>
			<biblScope unit="page" from="187" to="194" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Non-parametric discrete registration with convex optimisation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Heinrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Papież</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Schnabel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Handels</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-08554-8_6</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-08554-86" />
	</analytic>
	<monogr>
		<title level="m">WBIR 2014</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Ourselin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Modat</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">8545</biblScope>
			<biblScope unit="page" from="51" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learn2Reg: comprehensive multi-task medical image registration challenge, dataset and evaluation in the era of deep learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="697" to="712" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">elastix: a toolbox for intensity-based medical image registration</title>
		<author>
			<persName><forename type="first">S</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Staring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Viergever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P W</forename><surname>Pluim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="196" to="205" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Efficient inference in fully connected CRFs with gaussian edge potentials</title>
		<author>
			<persName><forename type="first">P</forename><surname>Krähenbühl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="109" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">SAME: deformable image registration based on self-supervised anatomical embeddings</title>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87202-1_9</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87202-19" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12904</biblScope>
			<biblScope unit="page" from="87" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning deformable image registration from optimization: perspective, modules, bilevel training and beyond</title>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="7688" to="7704" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Bi-level probabilistic feature learning for deformable image registration</title>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Ninth International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="723" to="730" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Large deformation diffeomorphic image registration with laplacian pyramid networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C W</forename><surname>Mok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C S</forename><surname>Chung</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59716-0_21</idno>
		<idno>978-3-030-59716-0 21</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12263</biblScope>
			<biblScope unit="page" from="211" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Hammer: hierarchical attribute matching mechanism for elastic registration</title>
		<author>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Davatzikos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1421" to="1439" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Fast 3D registration with accurate optimisation and little learning for Learn2Reg 2021</title>
		<author>
			<persName><forename type="first">H</forename><surname>Siebert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Heinrich</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-97281-3_25</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-97281-325" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Aubreville</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Zimmerer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Heinrich</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13166</biblScope>
			<biblScope unit="page" from="174" to="179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deformable medical image registration: a survey</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sotiras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Davatzikos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Paragios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1153" to="1190" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Large displacement optical flow computation withoutwarping</title>
		<author>
			<persName><forename type="first">F</forename><surname>Steinbrücker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICCV.2009.5459364</idno>
		<ptr target="https://doi.org/10.1109/ICCV.2009.5459364" />
	</analytic>
	<monogr>
		<title level="m">IEEE 12th International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2009">2009. 2009</date>
			<biblScope unit="page" from="1609" to="1614" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Large displacement optical flow computation withoutwarping</title>
		<author>
			<persName><forename type="first">F</forename><surname>Steinbrücker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 12th International Conference on Computer Vision</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009. 2009</date>
			<biblScope unit="page" from="1609" to="1614" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Free-form deformation using lower-order bspline for nonrigid image registration</title>
		<author>
			<persName><forename type="first">W</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Niessen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Computing and Computer Assisted Intervention</title>
		<imprint>
			<biblScope unit="page" from="194" to="201" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Greer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">X</forename><surname>Vialard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kwitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S J</forename><surname>Estépar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Niethammer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.05897</idno>
		<title level="m">Gradicon: approximate diffeomorphisms via gradient inverse consistency</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Accurate optical flow via direct cost volume processing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranftl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5807" to="5815" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">SAM: Self-supervised learning of pixel-wise anatomical embeddings in radiological images</title>
		<author>
			<persName><forename type="first">K</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2658" to="2669" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Comprehensive and clinically accurate head and neck cancer organsat-risk delineation on a multi-institutional study</title>
		<author>
			<persName><forename type="first">X</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">6137</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A duality based approach for realtime TV-L 1 optical flow</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-540-74936-3_22</idno>
		<ptr target="https://doi.org/10.1007/978-3-540-74936-322" />
	</analytic>
	<monogr>
		<title level="m">DAGM 2007</title>
		<editor>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Hamprecht</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Schnörr</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Jähne</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">4713</biblScope>
			<biblScope unit="page" from="214" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Unsupervised 3D end-toend medical image registration with volume tweening network</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Biomed. Health Inform</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1394" to="1404" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
