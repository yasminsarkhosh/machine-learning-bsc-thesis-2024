{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import fitz  # PyMuPDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base path to folder where output files will be stored\n",
    "output_path = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/database_analysis_output/'\n",
    "\n",
    "# Base path to folders \n",
    "base_path = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/'\n",
    "\n",
    "# Path to the MICCAI 2023 pdfs\n",
    "pdf_path = base_path + 'miccai_2023/'\n",
    "\n",
    "# Path to the MICCAI 2023 database of all 730 papers and their metadata\n",
    "database_path = base_path + 'databases/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_miccai = pd.read_csv(database_path +'database_miccai_2023.csv', index_col=[0], header=[0], encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 731 entries, 0 to 730\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   Title                731 non-null    object\n",
      " 1   Authors              731 non-null    object\n",
      " 2   Page numbers         731 non-null    object\n",
      " 3   DOI                  731 non-null    object\n",
      " 4   Year of publication  731 non-null    int64 \n",
      " 5   Part of publication  731 non-null    int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 40.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_miccai.info()\n",
    "\n",
    "#731 entries, 0 to 730 \n",
    "#6 columns in total\n",
    "#title, authors, page numbers, doi, year of publication, part of publication\n",
    "#dtype: int64(2), object(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a total of 730 papers in MICCAI 2023. However, the dataframe contains 731. Examining the dataframe, \n",
    "I will first look into the number of papers by publication (Part of Publication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Page numbers</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Year of publication</th>\n",
       "      <th>Part of publication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PET-Diffusion: Unsupervised PET Enhancement Ba...</td>\n",
       "      <td>Caiwen Jiang, Yongsheng Pan, Mianxin Liu, Lei ...</td>\n",
       "      <td>3-12</td>\n",
       "      <td>10.1007/978-3-031-43907-0_1</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MedIM: Boost Medical Image Representation via ...</td>\n",
       "      <td>Yutong Xie, Lin Gu, Tatsuya Harada, Jianpeng Z...</td>\n",
       "      <td>13-23</td>\n",
       "      <td>10.1007/978-3-031-43907-0_2</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UOD: Universal One-Shot Detection of Anatomica...</td>\n",
       "      <td>Heqin Zhu, Quan Quan, Qingsong Yao, Zaiyi Liu,...</td>\n",
       "      <td>24-34</td>\n",
       "      <td>10.1007/978-3-031-43907-0_3</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S2^2ME: Spatial-Spectral Mutual Teaching and E...</td>\n",
       "      <td>An Wang, Mengya Xu, Yang Zhang, Mobarakol Isla...</td>\n",
       "      <td>35-45</td>\n",
       "      <td>10.1007/978-3-031-43907-0_4</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Modularity-Constrained Dynamic Representation ...</td>\n",
       "      <td>Qianqian Wang, Mengqi Wu, Yuqi Fang, Wei Wang,...</td>\n",
       "      <td>46-56</td>\n",
       "      <td>10.1007/978-3-031-43907-0_5</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  PET-Diffusion: Unsupervised PET Enhancement Ba...   \n",
       "1  MedIM: Boost Medical Image Representation via ...   \n",
       "2  UOD: Universal One-Shot Detection of Anatomica...   \n",
       "3  S2^2ME: Spatial-Spectral Mutual Teaching and E...   \n",
       "4  Modularity-Constrained Dynamic Representation ...   \n",
       "\n",
       "                                             Authors Page numbers  \\\n",
       "0  Caiwen Jiang, Yongsheng Pan, Mianxin Liu, Lei ...         3-12   \n",
       "1  Yutong Xie, Lin Gu, Tatsuya Harada, Jianpeng Z...        13-23   \n",
       "2  Heqin Zhu, Quan Quan, Qingsong Yao, Zaiyi Liu,...        24-34   \n",
       "3  An Wang, Mengya Xu, Yang Zhang, Mobarakol Isla...        35-45   \n",
       "4  Qianqian Wang, Mengqi Wu, Yuqi Fang, Wei Wang,...        46-56   \n",
       "\n",
       "                           DOI  Year of publication  Part of publication  \n",
       "0  10.1007/978-3-031-43907-0_1                 2023                    1  \n",
       "1  10.1007/978-3-031-43907-0_2                 2023                    1  \n",
       "2  10.1007/978-3-031-43907-0_3                 2023                    1  \n",
       "3  10.1007/978-3-031-43907-0_4                 2023                    1  \n",
       "4  10.1007/978-3-031-43907-0_5                 2023                    1  "
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_miccai.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PET-Diffusion: Unsupervised PET Enhancement Based on\\xa0the\\xa0Latent Diffusion Model',\n",
       " 'MedIM: Boost Medical Image Representation via\\xa0Radiology Report-Guided Masking',\n",
       " 'UOD: Universal One-Shot Detection of\\xa0Anatomical Landmarks',\n",
       " 'S2^2ME: Spatial-Spectral Mutual Teaching and\\xa0Ensemble Learning for\\xa0Scribble-Supervised Polyp Segmentation',\n",
       " 'Modularity-Constrained Dynamic Representation Learning for Interpretable Brain Disorder Analysis with Functional MRI']"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_list_2023 = df_miccai['Title'].tolist()\n",
    "title_list_2023[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers in Publication 1: 73\n",
      "Number of papers in Publication 2: 74\n",
      "Number of papers in Publication 3: 72\n",
      "Number of papers in Publication 4: 75\n",
      "Number of papers in Publication 5: 76\n",
      "Number of papers in Publication 6: 77\n",
      "Number of papers in Publication 7: 75\n",
      "Number of papers in Publication 8: 65\n",
      "Number of papers in Publication 9: 70\n",
      "Number of papers in Publication 10: 74\n",
      "Total number of papers: 731\n"
     ]
    }
   ],
   "source": [
    "# count the number of papers for each publication. There is 10 publications in total\n",
    "\n",
    "print('Number of papers in Publication 1:', df_miccai['Part of publication'].value_counts()[1]) #73\n",
    "print('Number of papers in Publication 2:', df_miccai['Part of publication'].value_counts()[2]) #74\n",
    "print('Number of papers in Publication 3:', df_miccai['Part of publication'].value_counts()[3]) #72\n",
    "print('Number of papers in Publication 4:', df_miccai['Part of publication'].value_counts()[4]) #75\n",
    "print('Number of papers in Publication 5:', df_miccai['Part of publication'].value_counts()[5]) #76\n",
    "print('Number of papers in Publication 6:', df_miccai['Part of publication'].value_counts()[6]) #77\n",
    "print('Number of papers in Publication 7:', df_miccai['Part of publication'].value_counts()[7]) #75\n",
    "print('Number of papers in Publication 8:', df_miccai['Part of publication'].value_counts()[8]) #65\n",
    "print('Number of papers in Publication 9:', df_miccai['Part of publication'].value_counts()[9]) #70\n",
    "print('Number of papers in Publication 10:', df_miccai['Part of publication'].value_counts()[10]) #74\n",
    "\n",
    "# count the total number of papers in the dataframe\n",
    "print('Total number of papers:', df_miccai['Part of publication'].value_counts().sum()) #731"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe: papers with cancer in their title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "# selecting papers with cancer in the title, add them into a new dataframe\n",
    "df_cancer = df_miccai.loc[df_miccai.Title.str.contains('Cancer', regex=False, na=False)]\n",
    "\n",
    "print(len(df_cancer)) # 23 papers with cancer in the title\n",
    "\n",
    "# saving dataframe for papers with cancer in the title\n",
    "df_cancer.to_csv(database_path +'database_miccai_2023_cancer.csv', index=True, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list_cancer = df_cancer[\"Title\"]\n",
    "author_list_cancer = df_cancer[\"Authors\"]\n",
    "\n",
    "author_list_cancer = author_list_cancer.to_list()\n",
    "title_list_cancer = title_list_cancer.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "print(len(author_list_cancer)) #23\n",
    "print(len(title_list_cancer))  #23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Selecting a scope of papers from MICCAI 2023**\n",
    "\n",
    "**Scope criteria:** Selecting papers, that researched within the field of cancer-related illnesses by searching for cancer-related keywords in the text of each research paper. The text is defined from the start of Abstraction ending with the last line of Conclusion, exluding the Title of the paper, the authors and affiliations, the Acknowlegdement and the References. \n",
    "\n",
    "Cancer-related keywords could be words such as 'cancer', 'tumor' and/or 'tumours'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted titles from 189 selected papers.\n",
      "With the keyword(s) being ['cancer'], 189 papers were selected as relevant to cancer research.\n"
     ]
    }
   ],
   "source": [
    "# Function to extract the full text from the PDF\n",
    "def extract_text(pdf_path):\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        full_text = \"\"\n",
    "        for page in doc:\n",
    "            full_text += page.get_text()\n",
    "    return full_text\n",
    "\n",
    "# Function to find if any of the keywords appear in the section between Abstract and Conclusion\n",
    "def find_keywords_section(full_text, keywords):\n",
    "     # Use regular expressions to find the end of the affiliations section\n",
    "    affiliations_end = re.search(r'\\d{1,2}\\s+(?:\\w+\\.)+@\\w+\\.\\w{2,}', full_text)\n",
    "    \n",
    "    # Start searching from the end of affiliations if found, otherwise from the start of the text\n",
    "    start_idx = affiliations_end.end() if affiliations_end else 0\n",
    "    \n",
    "    # Look for the Abstract and Conclusion sections\n",
    "    abstract_idx = full_text.lower().find(\"abstract\", start_idx)\n",
    "    conclusion_idx = full_text.lower().rfind(\"conclusion\", abstract_idx)\n",
    "    acknowledgements_idx = full_text.lower().find(\"acknowledgements\", conclusion_idx)\n",
    "    \n",
    "    # Adjust the end index to stop at Acknowledgements if it exists, otherwise use Conclusion index\n",
    "    end_search_idx = acknowledgements_idx if acknowledgements_idx != -1 else conclusion_idx\n",
    "    \n",
    "    # If neither Abstract nor Conclusion is found, search the entire text\n",
    "    if abstract_idx == -1 and conclusion_idx == -1:\n",
    "        searchable_text = full_text[start_idx:]\n",
    "    else:\n",
    "        # Search from Abstract to Conclusion or Acknowledgements\n",
    "        searchable_text = full_text[abstract_idx:end_search_idx].lower()\n",
    "    \n",
    "    # Search for each keyword within the determined section, stop at first match\n",
    "    for keyword in keywords:\n",
    "        if keyword.lower() in searchable_text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Function to extract the title from the PDF\n",
    "def extract_title(pdf_path):\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        first_page_text = doc[0].get_text(\"text\")\n",
    "        \n",
    "        # Regular expression to find the start of affiliations or author names\n",
    "        # Looks for sequences typical in author lists or affiliations, such as numbers and parentheses\n",
    "        author_or_affiliations_start = re.search(r'\\b[A-Z][a-z]+ [A-Z]\\.|\\b[A-Z][a-z]+\\s[A-Z][a-z]+[1-9]', first_page_text)\n",
    "\n",
    "        title = \"\"\n",
    "        if author_or_affiliations_start:\n",
    "            # Extract text up to the start of the author list or affiliations as potential title text\n",
    "            potential_title_text = first_page_text[:author_or_affiliations_start.start()].strip()\n",
    "            title_lines = potential_title_text.split('\\n')\n",
    "            \n",
    "            # The title is expected to be a continuous block of text at the top of the page,\n",
    "            # possibly after a journal header or similar. We look for a large continuous block of text.\n",
    "            for line in reversed(title_lines):\n",
    "                if line.strip():  # Non-empty line suggests part of the title\n",
    "                    # Prepend to keep the title in the correct order\n",
    "                    title = line + \" \" + title\n",
    "                else:\n",
    "                    # An empty line might indicate the end of the title block\n",
    "                    break\n",
    "        else:\n",
    "            # If no author list or affiliation section is identified, use the first non-empty line\n",
    "            for line in first_page_text.split('\\n'):\n",
    "                if line.strip():\n",
    "                    title = line\n",
    "                    break\n",
    "\n",
    "        title = title.strip()  # Clean up whitespace\n",
    "        return title\n",
    "\n",
    "selected_papers = []\n",
    "titles = []\n",
    "\n",
    "# List of keywords to search for\n",
    "keywords = [\"cancer\"]\n",
    "\n",
    "# Iterate over each volume and search for keywords\n",
    "for i in range(1, 11):  # Volumes 1 to 10\n",
    "    folder_name = f\"miccai23vol{i}\"\n",
    "    folder_path = os.path.join(pdf_path, folder_name)\n",
    "    \n",
    "    for pdf in os.listdir(folder_path):\n",
    "        if pdf.endswith(\".pdf\"):\n",
    "            pdf_path_ = os.path.join(folder_path, pdf)\n",
    "            full_text = extract_text(pdf_path_)\n",
    "            if find_keywords_section(full_text, keywords):\n",
    "                selected_papers.append(os.path.join(folder_name, pdf))\n",
    "\n",
    "# Extract titles from selected papers\n",
    "for paper_path in selected_papers:\n",
    "    full_paper_path = os.path.join(pdf_path, paper_path)\n",
    "    title = extract_title(full_paper_path)\n",
    "    titles.append(title)\n",
    "\n",
    "print(f\"Extracted titles from {len(titles)} selected papers.\")\n",
    "print(f\"With the keyword(s) being {keywords}, {len(selected_papers)} papers were selected as relevant to cancer research.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titles = pd.DataFrame({'Title': titles})\n",
    "titles\n",
    "titles.to_csv(output_path + 'titles.csv', index=False, header=True, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Geometry-Invariant Abnormality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TPRO: Text-Prompting-Based Weakly Supervised H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vox2vec: A Framework for Self-supervised Contr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pick the Best Pre-trained Model: Towards Trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Solving Low-Dose CT Reconstruction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Noise2Aliasing: Unsupervised Deep Learning for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Revealing Anatomical Structures in PET to Gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Geometric Ultrasound Localization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>FreeSeed: Frequency-Band-Aware and Self-guided...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title\n",
       "0                       Geometry-Invariant Abnormality\n",
       "1    3D Arterial Segmentation via Single 2D Project...\n",
       "2    TPRO: Text-Prompting-Based Weakly Supervised H...\n",
       "3    vox2vec: A Framework for Self-supervised Contr...\n",
       "4    Pick the Best Pre-trained Model: Towards Trans...\n",
       "..                                                 ...\n",
       "184                 Solving Low-Dose CT Reconstruction\n",
       "185  Noise2Aliasing: Unsupervised Deep Learning for...\n",
       "186  Revealing Anatomical Structures in PET to Gene...\n",
       "187                  Geometric Ultrasound Localization\n",
       "188  FreeSeed: Frequency-Band-Aware and Self-guided...\n",
       "\n",
       "[189 rows x 1 columns]"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the datasets\n",
    "titles_df = pd.read_csv(output_path + 'titles.csv')\n",
    "database_df = df_miccai\n",
    "\n",
    "titles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df['search_pattern'] = titles_df['Title'].str.split().str.slice(0, 2).str.join(' ').str.lower()\n",
    "\n",
    "matched_rows = []\n",
    "for pattern in titles_df['search_pattern']:\n",
    "    matched_rows.extend(database_df[database_df['Title'].str.lower().str.startswith(pattern)].index.tolist())\n",
    "matched_df = database_df.loc[matched_rows]\n",
    "matched_df\n",
    "\n",
    "matched_df.to_csv(output_path + 'matched_papers.csv', index=False) #187 rows, missing two papers\n",
    "titles_df.to_csv(output_path + 'search_pattern.csv') # 189 titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hard coding: adding the two missing papers into the dataframe \"matched_df\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Page numbers</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Year of publication</th>\n",
       "      <th>Part of publication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PET-Diffusion: Unsupervised PET Enhancement Ba...</td>\n",
       "      <td>Caiwen Jiang, Yongsheng Pan, Mianxin Liu, Lei ...</td>\n",
       "      <td>3-12</td>\n",
       "      <td>10.1007/978-3-031-43907-0_1</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S2^2ME: Spatial-Spectral Mutual Teaching and E...</td>\n",
       "      <td>An Wang, Mengya Xu, Yang Zhang, Mobarakol Isla...</td>\n",
       "      <td>35-45</td>\n",
       "      <td>10.1007/978-3-031-43907-0_4</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  PET-Diffusion: Unsupervised PET Enhancement Ba...   \n",
       "3  S2^2ME: Spatial-Spectral Mutual Teaching and E...   \n",
       "\n",
       "                                             Authors Page numbers  \\\n",
       "0  Caiwen Jiang, Yongsheng Pan, Mianxin Liu, Lei ...         3-12   \n",
       "3  An Wang, Mengya Xu, Yang Zhang, Mobarakol Isla...        35-45   \n",
       "\n",
       "                           DOI  Year of publication  Part of publication  \n",
       "0  10.1007/978-3-031-43907-0_1                 2023                    1  \n",
       "3  10.1007/978-3-031-43907-0_4                 2023                    1  "
      ]
     },
     "execution_count": 725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Locating the missing papers in the original database for all 730 papers \n",
    "missing_papers = df_miccai.loc[df_miccai['Title'].isin(\n",
    "    ['PET-Diffusion: Unsupervised PET Enhancement Based on the Latent Diffusion Model', \n",
    "     'S2^2ME: Spatial-Spectral Mutual Teaching and Ensemble Learning for Scribble-Supervised Polyp Segmentation'])]\n",
    "\n",
    "missing_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the matched and missing papers into a single dataframe\n",
    "selected_papers_df = pd.merge(matched_df, missing_papers, on='Title', how='outer')\n",
    "\n",
    "# Drop the duplicate columns from the merge\n",
    "#selected_papers_df.drop(columns=['Part of publication_y', 'Authors_y', 'Page numbers_y', 'DOI_y', 'Year of publication_y'], inplace=True)\n",
    "#selected_papers_df.drop(columns=['Page numbers_y', 'DOI_y', 'Year of publication_y'], inplace=True)\n",
    "\n",
    "# Rename/refine the columns to match the original database \n",
    "#selected_papers_df.rename(columns={'Title': 'title', 'Part of publication_x': 'vol_number', 'Authors_x': 'authors', \n",
    "#                                   'DOI_x': 'doi', 'Year of publication_x': 'publication_year',\n",
    "#                                   'Page numbers_x': 'page_numbers'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the selected papers to a CSV file\n",
    "#selected_papers_df.to_csv(output_path + 'selected_papers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>page_numbers</th>\n",
       "      <th>doi</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>vol_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Arterial Segmentation via Single 2D Project...</td>\n",
       "      <td>Alina F. Dima, Veronika A. Zimmer, Martin J. M...</td>\n",
       "      <td>141-151</td>\n",
       "      <td>10.1007/978-3-031-43907-0_14</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D Mitochondria Instance Segmentation with Spa...</td>\n",
       "      <td>Omkar Thawakar, Rao Muhammad Anwer, Jorma Laak...</td>\n",
       "      <td>613-623</td>\n",
       "      <td>10.1007/978-3-031-43993-3_59</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Spatial-Temporal Deformable Attention Based ...</td>\n",
       "      <td>Chao Qin, Jiale Cao, Huazhu Fu, Rao Muhammad A...</td>\n",
       "      <td>479-488</td>\n",
       "      <td>10.1007/978-3-031-43895-0_45</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Spatial-Temporally Adaptive PINN Framework f...</td>\n",
       "      <td>Yubo Ye, Huafeng Liu, Xiajun Jiang, Maryam Tol...</td>\n",
       "      <td>163-172</td>\n",
       "      <td>10.1007/978-3-031-43990-2_16</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Texture Neural Network to Predict the Abnorm...</td>\n",
       "      <td>Weiguo Cao, Benjamin Howe, Nicholas Rhodes, Su...</td>\n",
       "      <td>470-480</td>\n",
       "      <td>10.1007/978-3-031-43993-3_46</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>WeakPolyp: You only Look Bounding Box for Poly...</td>\n",
       "      <td>Jun Wei, Yiwen Hu, Shuguang Cui, S. Kevin Zhou...</td>\n",
       "      <td>757-766</td>\n",
       "      <td>10.1007/978-3-031-43898-1_72</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Weakly-Supervised Positional Contrastive Learn...</td>\n",
       "      <td>Emma Sarfati, Alexandre Bône, Marc-Michel Rohé...</td>\n",
       "      <td>227-237</td>\n",
       "      <td>10.1007/978-3-031-43907-0_22</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>X2Vision: 3D CT Reconstruction from Biplanar X...</td>\n",
       "      <td>Alexandre Cafaro, Quentin Spinat, Amaury Leroy...</td>\n",
       "      <td>699-709</td>\n",
       "      <td>10.1007/978-3-031-43999-5_66</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>YONA: You Only Need One Adjacent Reference-Fra...</td>\n",
       "      <td>Yuncheng Jiang, Zixun Zhang, Ruimao Zhang, Gua...</td>\n",
       "      <td>44-54</td>\n",
       "      <td>10.1007/978-3-031-43904-9_5</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>vox2vec: A Framework for Self-supervised Contr...</td>\n",
       "      <td>Mikhail Goncharov, Vera Soboleva, Anvar Kurmuk...</td>\n",
       "      <td>605-614</td>\n",
       "      <td>10.1007/978-3-031-43907-0_58</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    3D Arterial Segmentation via Single 2D Project...   \n",
       "1    3D Mitochondria Instance Segmentation with Spa...   \n",
       "2    A Spatial-Temporal Deformable Attention Based ...   \n",
       "3    A Spatial-Temporally Adaptive PINN Framework f...   \n",
       "4    A Texture Neural Network to Predict the Abnorm...   \n",
       "..                                                 ...   \n",
       "184  WeakPolyp: You only Look Bounding Box for Poly...   \n",
       "185  Weakly-Supervised Positional Contrastive Learn...   \n",
       "186  X2Vision: 3D CT Reconstruction from Biplanar X...   \n",
       "187  YONA: You Only Need One Adjacent Reference-Fra...   \n",
       "188  vox2vec: A Framework for Self-supervised Contr...   \n",
       "\n",
       "                                               authors page_numbers  \\\n",
       "0    Alina F. Dima, Veronika A. Zimmer, Martin J. M...      141-151   \n",
       "1    Omkar Thawakar, Rao Muhammad Anwer, Jorma Laak...      613-623   \n",
       "2    Chao Qin, Jiale Cao, Huazhu Fu, Rao Muhammad A...      479-488   \n",
       "3    Yubo Ye, Huafeng Liu, Xiajun Jiang, Maryam Tol...      163-172   \n",
       "4    Weiguo Cao, Benjamin Howe, Nicholas Rhodes, Su...      470-480   \n",
       "..                                                 ...          ...   \n",
       "184  Jun Wei, Yiwen Hu, Shuguang Cui, S. Kevin Zhou...      757-766   \n",
       "185  Emma Sarfati, Alexandre Bône, Marc-Michel Rohé...      227-237   \n",
       "186  Alexandre Cafaro, Quentin Spinat, Amaury Leroy...      699-709   \n",
       "187  Yuncheng Jiang, Zixun Zhang, Ruimao Zhang, Gua...        44-54   \n",
       "188  Mikhail Goncharov, Vera Soboleva, Anvar Kurmuk...      605-614   \n",
       "\n",
       "                              doi  publication_year  vol_number  \n",
       "0    10.1007/978-3-031-43907-0_14            2023.0         1.0  \n",
       "1    10.1007/978-3-031-43993-3_59            2023.0         8.0  \n",
       "2    10.1007/978-3-031-43895-0_45            2023.0         2.0  \n",
       "3    10.1007/978-3-031-43990-2_16            2023.0         7.0  \n",
       "4    10.1007/978-3-031-43993-3_46            2023.0         8.0  \n",
       "..                            ...               ...         ...  \n",
       "184  10.1007/978-3-031-43898-1_72            2023.0         3.0  \n",
       "185  10.1007/978-3-031-43907-0_22            2023.0         1.0  \n",
       "186  10.1007/978-3-031-43999-5_66            2023.0        10.0  \n",
       "187   10.1007/978-3-031-43904-9_5            2023.0         5.0  \n",
       "188  10.1007/978-3-031-43907-0_58            2023.0         1.0  \n",
       "\n",
       "[189 rows x 6 columns]"
      ]
     },
     "execution_count": 739,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the selected papers\n",
    "''' The papers were choosen by searching for papers with the keyword \"cancer\" in the title and in the text starting from the abstract and \n",
    "ending with the conclusion section of the paper'''\n",
    "\n",
    "selected_papers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
