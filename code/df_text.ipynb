{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<h1>ALL-IN: A Local GLobal Graph-Based| DIstillatioN Model for Representation| Learning of Gigapixel Histopathology| Images With Application In Cancer Risk| Assessment|', '', '<p>Puria Azadi', '<s3>1', '<p>, Jonathan Suderman', '<s3>1', '<p>, Ramin Nakhli', '<s3>1', '<p>, Katherine Rich', '<s3>1', '<p>,| Maryam Asadi', '<s3>1', '<p>, Sonia Kung', '<s3>2', '<p>, Htoo Oo', '<s3>2', '<p>, Mira Keyes', '<s3>1', '<p>, Hossein Farahani', '<s3>1', '<p>,| Calum MacAulay', '<s3>3', '<p>, Larry Goldenberg', '<s3>2', '<p>, Peter Black', '<s3>2', '<p>, and Ali Bashashati', '<s3>1(', '<h3>B', '<s3>)|', '', '<s5>1', '<s1> University of British Columbia, Vancouver, BC, Canada| ali.bashashati@ubc.ca|', '<s5>2', '<s1> Vancouver Prostate Centre, Vancouver, BC, Canada|', '<s5>3', '<s1> BC Cancer Agency, Vancouver, BC, Canada|', '<s1>Abstract.  The utility of machine learning models in histopathology| image analysis for disease diagnosis has been extensively studied. How-| ever, eﬀorts to stratify patient risk are relatively under-explored. While| most current techniques utilize small ﬁelds of view (so-called local fea-| tures) to link histopathology images to patient outcome, in this work we| investigate the combination of global (i.e., contextual) and local features| in a graph-based neural network for patient risk stratiﬁcation. The pro-| posed network not only combines both ﬁne and coarse histological pat-| terns but also utilizes their interactions for improved risk stratiﬁcation.| We compared the performance of our proposed model against the state-| of-the-art (SOTA) techniques in histopathology risk stratiﬁcation in two| cancer datasets. Our results suggest that the proposed model is capable| of stratifying patients into statistically signiﬁcant risk groups ( p <  0 . 01| across the two datasets) with clinical utility while competing models fail| to achieve a statistical signiﬁcance endpoint ( p  = 0 . 148  −  0 . 494).|', '<s1>Keywords:  Histopathology', '<h2> ·', '<s1> Risk Assessment', '<h2> ·', '<s1> Graph Processing|', '', '<h2>1| Introduction|', '', '<p>The examination of tissue and cells using microscope (referred to as histology)| has been a key component of cancer diagnosis and prognostication since more| than a hundred years ago. Histological features allow visual readout of cancer| biology as they represent the overall impact of genetic changes on cells [ 20 ].| The great rise of deep learning in the past decade and our ability to digitize| histopathology slides using high-throughput slide scanners have fueled inter-| ests in the applications of deep learning in histopathology image analysis. The|', '', '<s1>Supplementary Information  The online version contains supplementary material| available at  https://doi.org/10.1007/978-3-031-43987-2 74 .|', '', '<s3>c| ⃝  The Author(s), under exclusive license to Springer Nature Switzerland AG 2023| H. Greenspan et al. (Eds.): MICCAI 2023, LNCS 14225, pp. 765–775, 2023.| https://doi.org/10.1007/978-3-031-43987-2', '<s2>_', '<s3>74|', '', '<s1>766| P. Azadi et al.|', '', '<p>majority of the eﬀorts, so far, focus on the deployment of these models for diag-| nosis and classiﬁcation [ 27 ]. As such, there is a paucity of eﬀorts that embark| on utilizing machine learning models for patient prognostication and survival| analysis (for example, predicting risk of cancer recurrence or expected patient| survival). While prognostication and survival analysis oﬀer invaluable insights| for patient management, biological studies and drug development eﬀorts, they| require careful tracking of patients for a lengthy period of time; rendering this| as a task that requires a signiﬁcant amount of eﬀort and funding.| In the machine learning domain, patient prognostication can be treated as a| weakly supervised problem, which a model would predict the outcome (e.g., time| to cancer recurrence) based on the histopathology images. Their majority have| utilized Multiple Instance Learning (MIL) [ 8 ] that is a two-step learning method.| First, representation maps for a set of patches (i.e., small ﬁelds of view), called| a bag of instances, are extracted. Then, a second pooling model is applied to the| feature maps for the ﬁnal prediction. Diﬀerent MIL variations have shown supe-| rior performances in grading or subtype classiﬁcation in comparison to outcome| prediction [ 10 ]. This is perhaps due to the fact that MIL-based technique do| not incorporate patch locations and interactions as well as tissue heterogeneity| which can potentially have a vital role in deﬁning clinical outcomes [ 4 , 26 ].| To address this issue, graph neural networks (GNN) have recently received| more attention in histology. They can model patch relations [ 17 ] by utilizing mes-| sage passing mechanism via edges connecting the nodes (i.e., small patches in our| case). However, most GNN-based models suﬀer from over smoothing [ 22 ] which| limits nodes’ receptive ﬁelds [ 3 ]. While local contexts mainly capture cell-cell| interactions, global patterns such as immune cell inﬁltration patterns and tumor| invasion in normal tissue structures (e.g., depth of invasion through myometrium| in endometrial cancer [ 1 ]) could capture critical information about outcome [ 10 ].| Hence, locally focused methods are unable to beneﬁt from the coarse properties| of slides due to their high dimensions which may lead to poor performance.| This paper aims to investigate the potential of extracting ﬁne and coarse| features from histopathology slides and integrating them for risk stratiﬁcation| in cancer patients. Therefore, the contributions of this work can be summarized| as: 1) a novel graph-based model for predicting survival that extracts both local| and global properties by identifying morphological super-nodes; 2) introducing| a ﬁne-coarse feature distillation module with 3 various strategies to aggregate| interactions at diﬀerent scales; 3) outperforming SOTA approaches in both risk| prediction and patient stratiﬁcation scenarios on two datasets; 4) publishing| two large and rare prostate cancer datasets containing more than 220 graphs for| active surveillance and 240 graphs for brachytherapy cases. The code and graph| embeddings are publicly available at  https://github.com/pazadimo/ALL-IN|', '', '<h2>2| Related Works|', '', '<p>2.1| Weakly Supervised Learning in Histopathology|', '<p>Utilizing Weakly Supervised Learning for modeling histopathology problems has| been getting popular due to the high resolution of slides and substantial time|', '', '<s1>ALL-IN| 767|', '', '<p>and ﬁnancial costs associated with annotating them as well as the development| of powerful deep discriminative models in the recent years [ 24 ].| Such models are used to perform nuclei segmentation [ 18 ], identify novel| subtypes [ 12 ], or later descendants are even able to pinpoint sub-areas with a| high diagnostic value [ 19 ].|', '<p>2.2| Survival Analysis and GNNs in Histopathology|', '<p>MIL-based models have been utilized for outcome prediction [ 29 , 32 ] which can| also be integrated with attention-based variants [ 14 ]. GNNs due to their struc-| tural preserving capacity [ 28 ] have drawn attention in various histology domains| by constructing the graph on cells or patches. However, current GNN-based risk| assessment variants are only focused on short-range interactions [ 16 , 17 ] or con-| sider local contexts [ 10 ]. We hypothesize that graph-based models’ performance| in survival prediction improves by leveraging both ﬁne and coarse properties.|', '', '<h2>3| Method|', '', '<p>Figure  1  summarizes our proposed end-to-end solution. Below, we have provided| details of each module.|', '<p>3.1| Problem Formulation|', '<p>For  P', '<s3>n', '<p>, which is the n-th patient, a set of patches  { patch', '<s3>j', '<p>}', '<s3>M| j =1', '<p>is extracted| from the related whole slide images. In addition, a latent vector  z', '<s3>j', '<p> ∈  R', '<s3>1 × d', '<p>is| extracted from  patch', '<s3>j', '<p> using our encoder network (described in Sect.  3.2 ) that| results in feature matrix  Z', '<s3>n', '<p> ∈  R', '<s3>M × d', '<p>for  P', '<s3>n', '<p>. Finally, a speciﬁc graph ( G', '<s3>n', '<p>) for| the n-th patient ( P', '<s3>n', '<p>) can be constructed by assuming patches as nodes. Also,| edges are connected based on the patches’ k-nearest neighbour in the spatial| domain resulting in an adjacency matrix  A', '<s3>n', '<p>. Therefore, for each patient such| as  P', '<s3>n', '<p>, we have a graph deﬁned by adjacency matrix  A', '<s3>n', '<p> with size  M  ×  M  and| features matrix  Z', '<s3>n', '<p> ( G', '<s3>n', '<p> =  graph ( Z', '<s3>n', '<p>, A', '<s3>n', '<p>)). We estimate  K  super-nodes as matrix| S', '<s3>n', '<p> ∈  R', '<s3>K × d', '<p>representing groups of local nodes with similar properties as coarse| features for  P', '<s3>n', '<p>’s slides. The ﬁnal model ( ϵ', '<s3>θ', '<p>) with parameters  θ  utilizes  G', '<s3>n', '<p> and| S', '<s3>n', '<p> to predict the risk associated with this patient:|', '<p>risk', '<s3>n', '<p> =  ϵ', '<s3>θ', '<p>( G', '<s3>n', '<p>, S', '<s3>n', '<p>) =  ϵ', '<s3>θ', '<p>( graph ( X', '<s3>n', '<p>, A', '<s3>n', '<p>) , S', '<s3>n', '<p>)| (1)|', '<p>3.2| Self-supervised Encoder|', '<p>Due to computational limits and large number of patches available for each| patient, we utilize a self-supervised approach to train an encoder to reduce| the inputs’ feature space size. Therefore, We use DINO [ 9 ], a knowledge dis-| tillation model (KDM), with vision transformer (ViT) [ 13 ] as the backbone. It| utilizes global and local augmentations of the input  patch', '<s3>j', '<p> and passes them| to the student ( S', '<s3>θ', '<s6>1', '<s3>,V iT', '<p> ) and teacher ( T', '<s3>θ', '<s6>2', '<s3>,V iT', '<p> ) models to ﬁnd their respective|', '', '<s1>768| P. Azadi et al.|', '<s1>Fig. 1.  The overview of our proposed method. a) The input slide is tiled into non-| overlapping patches. b) The patches are fed into a self-supervised encoder to extract| embeddings. c) A graph is constructed and the new local instance-level embeddings| are obtained through the message-passing process. d) The global context representa-| tions in the form of super-nodes are extracted utilizing two unsupervised loss functions| ( R', '<s5>minCUT', '<s1> ,  R', '<s5>orthognal', '<s1>). e) The ﬁne and coarse feature vectors are aggregated in the| distillation module to obtain a representation that accounts for both local and global| (contextual) histo-morphological features. Three diﬀerent strategies (S1, S2, S3) are| explored in this module. Finally, a Multilayer Perceptron (MLP) is deployed to esti-| mate the risk using ﬁnal resultant vectors.|', '', '<p>representations without any labels. Then, by using distillation loss, it makes the| representations’ distribution similar to each other. Finally, the ﬁxed weights of| the teacher model are utilized in order to encode the input patches.|', '<p>3.3| Local Graph Neural Network|', '<p>GNN’s objective is to ﬁnd new nodes’ embeddings via integrating local neighbors’| interactions with individual properties of patches. By exploiting the message| passing mechanism, this module iteratively aggregates features from neighbors| of each vertex and generates the new node representations. We employ two graph| convolution isomorphism operators (GINconv) [ 30 ] with the generalized form as:|', '<p>X', '<s3>′| n', '<p>=  φ  ( A', '<s3>n', '<p>+ (1 +  ϵ ) .I ) .X', '<s3>n', '<p>)  ,| (2)|', '<p>where  ϵ  is a small positive value and  I  is the identity matrix. Also,  φ  denotes the| weights of two MLP layers.  X', '<s3>n', '<p> ∈  R', '<s3>M × d', '<p>and  X', '<s3>′| n', '<p>∈  R', '<s3>M × d', '<p> are GINconv’s input| and output feature matrices for  P', '<s3>n', '<p>, which  X', '<s3>n', '<p> equals  Z', '<s3>n', '<p> for the ﬁrst layer.|', '<p>3.4| Super-Nodes Extractor|', '<p>In order to ﬁnd the coarse histo-morphological patterns disguised in the local| graph, we propose extracting  K  Super-nodes, which each represents a weighted| cluster of further processed local features. Intuitively, the number of super-nodes| K should not be very large or small, as the former encourages them to only| represent local clusters and the latter leads to larger clusters and loses subtle|', '', '<s1>ALL-IN| 769|', '', '<p>details. We exploit the minCUT [ 5 ] idea to extract super-nodes in a diﬀerentiable| process after an auxiliary GINconv to focus more on large-scale interactions and| to ﬁnally learn the most global correlated super-nodes. Inspired by the relaxation| form of the known K-way minCUT problem, we create a continuous cluster| matrix  C', '<s3>n', '<p> ∈  R', '<s3>M × K', '<p>using MLP layers and can ﬁnally estimate the super-nodes| features ( S', '<s3>n', '<p> ∈  R', '<s3>M × d', '<p>) as:|', '<p>S', '<s3>n', '<p> =  C', '<s3>T| n', '<p>.X', '<s3>′| n', '<p>,| C', '<s3>n', '<p> =  softmax  ( ReLU ( X', '<s3>′| n', '<p>.W', '<s3>1', '<p>) .W', '<s3>2', '<p>)  ,| (3)|', '<p>where  W', '<s3>1', '<p>, W', '<s3>2', '<p> are MLPs’ weights. Hence, the extracted nodes are directly depen-| dent on the ﬁnal survival-speciﬁc loss. In addition, two additional unsupervised| weighted regularization terms are optimized to improve the process:|', '<p>MinCut Regularizer.  This term is motivated by the original minCUT problem| and intends to solve it for the the patients’ graph. It is deﬁned as:|', '<p>R', '<s3>minCUT', '<p> =  − Tr ( C', '<s3>T| n', '<p>.A', '<s3>n,norm', '<p>.C', '<s3>n', '<p>)|', '<p>Tr ( C', '<s3>T n', '<p> .D', '<s3>n', '<p>.C', '<s3>n', '<p>)| ,| (4)|', '<p>where  D', '<s3>n', '<p> is the diagonal degree matrix for  A', '<s3>n', '<p>. Also,  Tr ( . ) represents the trace| of matrix and  A', '<s3>n,norm', '<p> is the normalized adjacency matrix.  R', '<s3>minCUT', '<p> ’s mini-| mum value happens when  Tr ( C', '<s3>T| n', '<p>.A', '<s3>n,norm', '<p>.C', '<s3>n', '<p>) equals  Tr ( C', '<s3>T| n', '<p>.D', '<s3>g,n', '<p>.C', '<s3>n', '<p>). There-| fore, minimizing  R', '<s3>minCUT', '<p> causes assigning strongly similar nodes to a same| super-node and prevent their association with others.|', '<p>Orthogonality Regularizer.  R', '<s3>minCUT', '<p> is non-convex and potent to local min-| ima such as assigning all vertexes to a super-node or having multiple super-nodes| with only a single vertex.  R', '<s3>orthogonal', '<p> penalizes such solutions and helps the model| to distribute the graph’s features between super-nodes. It can be formulated as:|', '<p>R', '<s3>orthogonal', '<p> =| \\x02\\x02\\x02\\x02|', '<p>\\x02\\x02\\x02\\x02| C', '<s3>T| n', '<p>.C', '<s3>n|', '', '<p>|| C', '<s3>T n', '<p> .C', '<s3>n', '<p>||', '<s3>F|', '<p>−| I| √|', '<p>K|', '<p>\\x02\\x02\\x02\\x02|', '<p>\\x02\\x02\\x02\\x02|', '<s3>F|', '<p>,| (5)|', '<p>where  || . ||', '<s3>F', '<p> is the Frobenius norm, and  I  is the identity matrix. This term pushes| the model’s parameters to ﬁnd coarse features that are orthogonal to each other| resulting in having the most useful global features.| Overall, utilizing these two terms encourages the model to extract super-| nodes by leaning more towards the strongly associated vertexes and keeping| them against weakly connected ones [ 5 ], while the main survival loss still controls| the global extraction process.|', '<p>3.5| Fine-Coarse Distillation|', '<p>We propose our ﬁne-coarse morphological feature distillation module to leverage| all-scale interactions in the ﬁnal prediction by ﬁnding a local and a global patient-| level representations ( ˆ h', '<s3>l,n', '<p>,  ˆ h', '<s3>g,n', '<p>). Assume that  X', '<s3>′| n', '<p>∈  R', '<s3>M × d', '<p> and  S', '<s3>n', '<p>∈  R', '<s3>K × d', '<p> are| the feature matrices taken from local GNN (Sect.  3.3 ) and super-nodes for  P', '<s3>n', '<p>,| respectively. We explore 3 diﬀerent attention-based feature distillation strategies| for this task, including:|', '', '<s1>770| P. Azadi et al.|', '', '<p>–  Dual Attention (DA):  Two gated self-attention modules for local and| global properties with separate weights ( W', '<s3>φ,l', '<p>, W', '<s3>φ,g', '<p>, W', '<s3>k,l', '<p>, W', '<s3>k,g', '<p>, W', '<s3>q,l', '<p>, W', '<s3>q,g', '<p>)| are utilized to ﬁnd patches scores  α', '<s3>l', '<p> ∈  R', '<s3>1 × M', '<p>and  α', '<s3>g', '<p> ∈  R', '<s3>1 × K', '<p>and the ﬁnal| features ( ˆ h', '<s3>l,n', '<p>,  ˆ h', '<s3>g,n', '<p> ) as:|', '', '<s1>ˆ h', '<s5>l,n', '<s1> =|', '', '<s5>M|', '<s1>\\x02|', '', '<s5>i =1|', '<s1>W', '<s5>φ,l', '<s1>α', '<s5>l,i', '<s1>x', '<s5>′| n,i', '<s1>, α', '<s5>l', '<s1>=  softmax| \\x03| W', '<s5>v,l|', '<s1>\\x04| tanh ( W', '<s5>q,l', '<s1>X|', '<s6>′', '<s5>T| n', '<s1>)  ·  sigm ( W', '<s5>k,l', '<s1>X|', '<s6>′', '<s5>T| n', '<s1>)| \\x05\\x06| ,|', '', '<p>(6)|', '', '<s1>ˆ h', '<s5>g,n', '<s1> =|', '', '<s5>K|', '<s1>\\x02|', '', '<s5>i =1|', '<s1>W', '<s5>φ,g', '<s1>α', '<s5>g,i', '<s1>s', '<s5>n,i', '<s1>, α', '<s5>g', '<s1> =  softmax| \\x03| W', '<s5>v,g|', '<s1>\\x04| tanh ( W', '<s5>q,g', '<s1>S', '<s5>T| n', '<s1>)  ·  sigm ( W', '<s5>k,g', '<s1>S', '<s5>T| n', '<s1>)| \\x05\\x06| ,|', '', '<p>(7)| where  x', '<s3>′| n,i', '<p>and  s', '<s3>n,i', '<p> are rows of  X', '<s3>′| n', '<p>and  S', '<s3>n', '<p>, respectively, and the ﬁnal repre-| sentation ( ˆ h ) is generated as  ˆ h  =  cat ( ˆ h', '<s3>l', '<p>, ˆ h', '<s3>g', '<p>).| –  Mixed Guided Attention (MGA):  In the ﬁrst strategy, the information| ﬂows from local and global features to the ﬁnal representations in paral-| lel without mixing any knowledge. The purpose of this policy is the heavy| fusion of ﬁne and coarse knowledge by exploiting shared weights ( W', '<s3>φ,shared', '<p>,| W', '<s3>k,shared', '<p>,  W', '<s3>q,shared', '<p>,  W', '<s3>v,shared', '<p>) in both routes and beneﬁting from the guid-| ance of local representation on learning the global one by modifying Eq. ( 7 )| to:|', '<s1>α', '<s5>g', '<s1> =  softmax| \\x03| W', '<s5>φ,g|', '<s1>\\x04| tanh ( W', '<s5>q,g', '<s1>S', '<s5>T| n', '<s1>ˆ h', '<s5>l,n', '<s1>)  ·  sigm ( W', '<s5>k,g', '<s1>S', '<s5>T| n', '<s1>ˆ h', '<s5>l,n', '<s1>)| \\x05\\x06|', '<p>(8)|', '<p>–  Mixed Co-Attention (MCA):  While the ﬁrst strategy allows the extreme| separation of two paths, the second one has the highest level of mixing infor-| mation. Here, we take a balanced policy between the independence and knowl-| edge mixture of the two routes by only sharing the weights without using any| guidance.|', '', '<h2>4| Experiments and Results|', '', '<p>4.1| Dataset|', '<p>We utilize two prostate cancer (PCa) datasets to evaluate the performance of| our proposed model. The ﬁrst set (PCa-AS) includes 179 PCa patients who| were managed with Active Surveillance (AS). Radical therapy is considered| overtreatment in these patients, so they are instead monitored with regular| serum prostate-speciﬁc antigen (PSA) measurements, physical examinations,| sequential biopsies, and magnetic resonance imaging [ 23 ]. However, AS may be| over- or under-utilized in low- and intermediate-risk PCa due to the uncertainty| of current methods to distinguish indolent from aggressive cancers [ 11 ]. Although| majority of patients in our cohort are classiﬁed as low-risk based on NCCN guide-| lines [ 21 ], a signiﬁcant subset of them experienced disease upgrade that triggered| deﬁnitive therapy (range: 6.2 to 224 months after diagnosis).| The second dataset (PCa-BT) includes 105 PCa patients with low to high| risk disease who went through brachytherapy. This treatment involves placing a| radioactive material inside the body to safely deliver larger dose of radiation at|', '', '<s1>ALL-IN| 771|', '<s1>Table 1.  Comparison of our method against baselines and ablation study on policies.|', '', '<s4>Model| c-index  ↑| p-value  ↓| High  ↓  - Low  ↑  Median Time Parameters|', '<s4>PCa-AS| PCa-BT| PCa-AS PCa-BT PCa-AS| PCa-BT| PCa-AS|', '<s4>DeepSet| 0 . 495  ±  0 . 017| 0 . 50  ±  0 . 0| 0.837| 0.912| 67.78–71.87| 24.62–24.89| 329K|', '<s4>AMIL| 0 . 544  ±  0 . 06| 0 . 533  ±  0 . 060| 0.820| 0.148| 48.99–89.10| 21.86–30.71| 592K|', '<s4>DGC| 0 . 522  ±  0 . 113| 0 . 572  ±  0 . 150| 0.494| 0.223| 47.61–96.66| 23.44–24.85| 626K|', '<s4>Patch-GCN| 0 . 555  ±  0 . 059| 0 . 541  ±  0 . 118| 0.630| 0.981| 37.72–94.95| 23.05–25.25| 1,302K|', '<s4>ALL-IN +| DA (ours)|', '<s4>0 . 631  ±  0 . 058| 0 . 596  ±  0 . 062| <  0 . 01| <  0 . 01| 37.72–115.91| 21.86–35.77| 850K|', '<s4>ALL-IN +| MGA (ours)|', '<s4>0 . 632  ±  0 . 060| 0 . 589  ±  0 . 074| <  0 . 01| <  0 . 01| 47.61–101.39| 21.86–35.77| 653K|', '<s4>ALL-IN +| MCA (ours)|', '<s4>0 . 639  ±  0 . 048 0 . 600  ±  0 . 077  <  0.01| <  0.01| 36.5–131.71 21.86–35.77| 653K|', '', '<p>one time [ 25 ]. The recorded endpoint for this set is biochemical recurrence with| time to recurrence ranging from 11.7 to 56.1 months.| We also utilized the Prostate cANcer graDe Assessment (PANDA) Challenge| dataset [ 7 ] that includes more than 10,000 PCa needle biopsy slides (no outcome| data) as an external dataset for training the encoder of our model.|', '<p>4.2| Experiments|', '<p>We evaluate the models’ performance in two scenarios utilizing several objective| metrics. Implementation details are available in supplementary material.|', '<p>Hazard (Risk) Prediction.  We utilize concordance-index (c-index) that mea-| sures the relative ordering of patients with observed events and un-censored| cases relative to censored instances [ 2 ]. Using c-index, we compare the quality| of hazard ranking against multiple methods including two MIL (DeepSet [ 31 ],| AMIL [ 14 ]) and graph-based (DGC [ 17 ] and Patch-GCN [ 10 ]) models that were| utilized recently for histopathology risk assessment. C-index values are avail-| able in Table  1 . The proposed model with all strategies outperforms baselines| across all sets and is able to achieve 0.639 and 0.600 on PCa-AS and PCa-BT,| while the baselines, at best, obtain 0.555, and 0.572, respectively. Statistical tests| (paired t-test) on c-indices also show that our model is statistically better than| all baselines in PCa-AS and also superior to all models, except DGC, in PCa-BT.| Superior performance of our MCA policy implies that balanced exploitation of| ﬁne and coarse features with shared weights may provide more robust contex-| tual information compared to using mixed guided information or utilizing them| independently.|', '<p>Patient Stratiﬁcation.  The capacity of stratifying patients into risk groups| (e.g., low and high risk) is another criterion that we employ to assess the util-| ity of models in clinical practice. We evaluate model performances via Kaplan-| Meier curve [ 15 ] (cut-oﬀ set as the ratio of patients with recurrence within 3|', '', '<s1>772| P. Azadi et al.|', '<s1>Fig. 2.  Kaplan-Meier curves of mixed co-attention model for PCa-AS and PCa-BT.|', '', '<p>years of therapy initiation for PCa-BT and the ratio of upgraded cases for PCa-| AS), LogRank test [ 6 ] (with 0.05 as signiﬁcance level), and median outcome| associated with risk groups (Table  1  and Fig.  2 ). Our model stratiﬁed PCa-AS| patients into high- and low-risk groups with median time to progression of 36.5| and 131.7 months, respectively. Moreover, PCa-BT cases assigned to high- and| low-risk groups have median recurrence time of 21.86 and 35.7 months. While| none of the baselines are capable of assigning patients into risk groups with| statistical signiﬁcance, our distillation policies achieve signiﬁcant separation in| both PCa-AS and PCa-BT datasets; suggesting that global histo-morphological| properties improve patient stratiﬁcation performance. Furthermore, our ﬁndings| have signiﬁcant clinical implications as they identify, for the ﬁrst time, high-| risk prostate cancer patients who are otherwise known to be low-risk based on| clinico-pathological parameters. This group should be managed diﬀerently from| the rest of the low-risk prostate cancer patients in the clinic. Therefore, pro-| viding evidence of the predictive (as opposed to prognostic) clinical information| that our model provides. While a prognostic biomarker provides information| about a patient’s outcome (without speciﬁc recommendation on the next course| of action), a predictive biomarker gives insights about the eﬀect of a therapeutic| intervention and potential actions that can be taken.|', '<p>Ablation Study.  We perform ablation study (Table  2 ) on various components| of our framework including local nodes, self-supervised ViT-based encoder, and| most importantly, super-nodes in addition to ﬁne-coarse distillation module.| Although our local-only model is still showing superior results compared to| baselines, this analysis demonstrates that all modules are essential for learn-| ing the most eﬀective representations. We also assess the impact of our ViT on| the baselines (full-results in appendix), showing that it can, on average, improve| their performance by an increase of  ∼  0 . 03 in c-index for PCa-AS. However, the| best baseline with ViT still has poorer performance compared to our model in| both datasets, while the number of parameters (reported for ViT embeddings’| size in Table  1 ) in our full-model is about half of this baseline. Achieving higher| c-indices in our all model versions indicates the important role of coarse features| and global context in patient risk estimation in addition to local patterns.|', '', '<s1>ALL-IN| 773|', '<s1>Table 2.  Ablation study on diﬀerent modules.|', '<s1>Modules| c-index  ↑|', '<s1>Model| Local-node our KDM-| ViT|', '<s1>Super-node| + Distillation| Model|', '<s1>PCa-AS| PCa-BT|', '<s1>Patch-GCN  ✓| ✓| ✗| 0 . 627  ±  0 . 046| 0 . 588  ±  0 . 067|', '<s1>Ours| ✓| ✗| ✗| 0 . 584  ±  0 . 072| 0 . 550  ±  0 . 109|', '<s1>✓| ✓| ✗| 0 . 622  ±  0 . 055| 0 . 597  ±  0 . 045|', '<s1>✓| ✓| ✓| 0 . 639  ±  0 . 048 0 . 600  ±  0 . 077|', '', '<h2>5| Conclusion|', '', '<p>While risk assessment is relatively under-explored, most existing methods are| focused only on small ﬁelds of view. In this work, we introduce a novel graph-| based model for integrating global and local features, which utilizes interactions| at a larger scale for improved risk stratiﬁcation. Using two cancer datasets, we| evaluated the eﬀectiveness of our model against the baseline methods for hazard| prediction and patients stratiﬁcation. Our results suggest that the proposed| model outperforms them in risk assessment and is capable of separating patients| into statistically signiﬁcant risk groups with actionable clinical utility. The full| capacity of this work can be revealed by extending it to other histology tasks.|', '', '<s1>Acknowledgment:.  This work was supported by a Canadian Institutes of Health| Research grant to AB, PB, and LG and Michael Smith Health Research BC Scholar| grant to AB.|', '', '<h2>References|', '', '<s1>1. Abu-Rustum, N.R., et al.: The revised 2009 ﬁgo staging system for endometrial| cancer: should the 1988 ﬁgo stages ia and ib be altered? Int. J. Gynecol. Cancer| 21 (3) (2011)| 2. Alabdallah, A., Ohlsson, M., Pashami, S., R¨ognvaldsson, T.: The concordance| index decomposition-a measure for a deeper understanding of survival prediction| models. arXiv preprint  arXiv:2203.00144  (2022)| 3. Alon, U., Yahav, E.: On the bottleneck of graph neural networks and its practical| implications. arXiv preprint  arXiv:2006.05205  (2020)| 4. Angell, H., Galon, J.: From the immune contexture to the immunoscore: the role of| prognostic and predictive immune markers in cancer. Curr. Opin. Immunol.  25 (2),| 261–267 (2013)| 5. Bianchi, F.M., Grattarola, D., Alippi, C.: Spectral clustering with graph neural| networks for graph pooling. In: International Conference on Machine Learning,| pp. 874–883. PMLR (2020)| 6. Bland, J.M., Altman, D.G.: The logrank test. BMJ  328 (7447), 1073 (2004)| 7. Bulten, W., et al.: Artiﬁcial intelligence for diagnosis and gleason grading of| prostate cancer: the panda challenge. Nat. Med.  28 (1), 154–163 (2022)|', '<s1>774| P. Azadi et al.|', '<s1>8. Carbonneau, M.A., Cheplygina, V., Granger, E., Gagnon, G.: Multiple instance| learning: a survey of problem characteristics and applications. Pattern Recogn.| 77 , 329–353 (2018)| 9. Caron, M., Touvron, H., Misra, I., J´egou, H., Mairal, J., Bojanowski, P., Joulin, A.:| Emerging properties in self-supervised vision transformers. In: Proceedings of the| IEEE/CVF International Conference on Computer Vision, pp. 9650–9660 (2021)| 10. Chen, R.J., et al.: Whole slide images are 2D point clouds: context-aware survival| prediction using patch-based graph convolutional networks. In: de Bruijne, M.,| et al. (eds.) MICCAI 2021. LNCS, vol. 12908, pp. 339–349. Springer, Cham (2021).| https://doi.org/10.1007/978-3-030-87237-3 33|', '<s1>11. Cooperberg,| M.R.,| et| al.:| Outcomes| of| active| surveillance| for| men| with| intermediate-risk prostate cancer. J. Clin. Oncol. Oﬀ. J. Am. Soc. Clin. Oncol.| 29 (2), 228–234 (2011)| 12. Darbandsari, A., et al.: Identiﬁcation of a novel subtype of endometrial cancer| with unfavorable outcome using artiﬁcial intelligence-based histopathology image| analysis (2022)| 13. Dosovitskiy, A., et al.: An image is worth 16 × 16 words: transformers for image| recognition at scale. arXiv preprint  arXiv:2010.11929  (2020)| 14. Ilse, M., Tomczak, J., Welling, M.: Attention-based deep multiple instance learning.| In: International Conference on Machine Learning, pp. 2127–2136. PMLR (2018)| 15. Kaplan, E.L., Meier, P.: Nonparametric estimation from incomplete observations.| J. Am. Stat. Assoc.  53 (282), 457–481 (1958)| 16. Lee, Y., et al.: Derivation of prognostic contextual histopathological features from| whole-slide images of tumours via graph deep learning. Nat. Biomed. Eng., 1–15| (2022)| 17. Li, R., Yao, J., Zhu, X., Li, Y., Huang, J.: Graph CNN for survival analysis on| whole slide pathological images. In: Frangi, A.F., Schnabel, J.A., Davatzikos, C.,| Alberola-L´opez, C., Fichtinger, G. (eds.) MICCAI 2018. LNCS, vol. 11071, pp.| 174–182. Springer, Cham (2018).  https://doi.org/10.1007/978-3-030-00934-2 20|', '<s1>18. Liu, W., He, Q., He, X.: Weakly supervised nuclei segmentation via instance learn-| ing. In: 2022 IEEE 19th International Symposium on Biomedical Imaging (ISBI),| pp. 1–5. IEEE (2022)| 19. Lu, M.Y., Williamson, D.F., Chen, T.Y., Chen, R.J., Barbieri, M., Mahmood,| F.: Data-eﬃcient and weakly supervised computational pathology on whole-slide| images. Nat. Biomed. Eng.  5 (6), 555–570 (2021)| 20. Mobadersany, P., et al.: Predicting cancer outcomes from histology and genomics| using convolutional networks. Proc. Natl. Acad. Sci.  115 (13), E2970–E2979 (2018)| 21. Moses, K.A., et al.: Nccn guidelines', '<s5> R|', '<s1>⃝  insights: prostate cancer early detection, ver-| sion 1.2023: featured updates to the nccn guidelines. J. Natl. Comprehens. Cancer| Netw.  21 (3), 236–246 (2023)| 22. Oono, K., Suzuki, T.: Graph neural networks exponentially lose expressive power| for node classiﬁcation. arXiv preprint  arXiv:1905.10947  (2019)| 23. Ouzzane, A., et al.: Magnetic resonance imaging targeted biopsy improves selection| of patients considered for active surveillance for clinically low risk prostate cancer| based on systematic biopsies. J. Urol.  194 (2), 350–356 (2015)| 24. Rony, J., Belharbi, S., Dolz, J., Ayed, I.B., McCaﬀrey, L., Granger, E.: Deep| weakly-supervised learning methods for classiﬁcation and localization in histology| images: a survey. arXiv preprint  arXiv:1909.03354  (2019)| 25. Skowronek, J.: Current status of brachytherapy in cancer treatment-short overview.| J. Contemp. Brachyther.  9 (6), 581–589 (2017)|', '<s1>ALL-IN| 775|', '<s1>26. Son, B., Lee, S., Youn, H., Kim, E., Kim, W., Youn, B.: The role of tumor microen-| vironment in therapeutic resistance. Oncotarget  8 (3), 3933 (2017)| 27. Srinidhi, C.L., Ciga, O., Martel, A.L.: Deep neural network models for computa-| tional histopathology: a survey. Med. Image Anal.  67 , 101813 (2021)| 28. Tang, S., Chen, D., Bai, L., Liu, K., Ge, Y., Ouyang, W.: Mutual crf-gnn for few-| shot learning. In: Proceedings of the IEEE/CVF Conference on Computer Vision| and Pattern Recognition, pp. 2329–2339 (2021)| 29. Wetstein, S.C., et al.: Deep learning-based breast cancer grading and survival anal-| ysis on whole-slide histopathology images. Sci. Rep.  12 (1), 1–12 (2022)| 30. Xu, K., Hu, W., Leskovec, J., Jegelka, S.: How powerful are graph neural networks?| arXiv preprint  arXiv:1810.00826  (2018)| 31. Zaheer, M., Kottur, S., Ravanbakhsh, S., Poczos, B., Salakhutdinov, R.R., Smola,| A.J.: Deep sets. Adv. Neural Inf. Process. Syst.  30 , 1–11 (2017)| 32. Zhu, X., Yao, J., Zhu, F., Huang, J.: Wsisa: making survival prediction from whole| slide histopathological images. In: Proceedings of the IEEE Conference on Com-| puter Vision and Pattern Recognition, pp. 7234–7242 (2017)|']\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "import fitz\n",
    "import json\n",
    "\n",
    "\n",
    "def fonts(doc, granularity=False):\n",
    "    \"\"\"Extracts fonts and their usage in PDF documents.\n",
    "\n",
    "    :param doc: PDF document to iterate through\n",
    "    :type doc: <class 'fitz.fitz.Document'>\n",
    "    :param granularity: also use 'font', 'flags' and 'color' to discriminate text\n",
    "    :type granularity: bool\n",
    "\n",
    "    :rtype: [(font_size, count), (font_size, count}], dict\n",
    "    :return: most used fonts sorted by count, font style information\n",
    "    \"\"\"\n",
    "    styles = {}\n",
    "    font_counts = {}\n",
    "\n",
    "    for page in doc:\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        for b in blocks:  # iterate through the text blocks\n",
    "            if b['type'] == 0:  # block contains text\n",
    "                for l in b[\"lines\"]:  # iterate through the text lines\n",
    "                    for s in l[\"spans\"]:  # iterate through the text spans\n",
    "                        if granularity:\n",
    "                            identifier = \"{0}_{1}_{2}_{3}\".format(s['size'], s['flags'], s['font'], s['color'])\n",
    "                            styles[identifier] = {'size': s['size'], 'flags': s['flags'], 'font': s['font'],\n",
    "                                                  'color': s['color']}\n",
    "                        else:\n",
    "                            identifier = \"{0}\".format(s['size'])\n",
    "                            styles[identifier] = {'size': s['size'], 'font': s['font']}\n",
    "\n",
    "                        font_counts[identifier] = font_counts.get(identifier, 0) + 1  # count the fonts usage\n",
    "\n",
    "    font_counts = sorted(font_counts.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "    if len(font_counts) < 1:\n",
    "        raise ValueError(\"Zero discriminating fonts found!\")\n",
    "\n",
    "    return font_counts, styles\n",
    "\n",
    "\n",
    "def font_tags(font_counts, styles):\n",
    "    \"\"\"Returns dictionary with font sizes as keys and tags as value.\n",
    "\n",
    "    :param font_counts: (font_size, count) for all fonts occuring in document\n",
    "    :type font_counts: list\n",
    "    :param styles: all styles found in the document\n",
    "    :type styles: dict\n",
    "\n",
    "    :rtype: dict\n",
    "    :return: all element tags based on font-sizes\n",
    "    \"\"\"\n",
    "    p_style = styles[font_counts[0][0]]  # get style for most used font by count (paragraph)\n",
    "    p_size = p_style['size']  # get the paragraph's size\n",
    "\n",
    "    # sorting the font sizes high to low, so that we can append the right integer to each tag\n",
    "    font_sizes = []\n",
    "    for (font_size, count) in font_counts:\n",
    "        font_sizes.append(float(font_size))\n",
    "    font_sizes.sort(reverse=True)\n",
    "\n",
    "    # aggregating the tags for each font size\n",
    "    idx = 0\n",
    "    size_tag = {}\n",
    "    for size in font_sizes:\n",
    "        idx += 1\n",
    "        if size == p_size:\n",
    "            idx = 0\n",
    "            size_tag[size] = '<p>'\n",
    "        if size > p_size:\n",
    "            size_tag[size] = '<h{0}>'.format(idx)\n",
    "        elif size < p_size:\n",
    "            size_tag[size] = '<s{0}>'.format(idx)\n",
    "\n",
    "    return size_tag\n",
    "\n",
    "\n",
    "def headers_para(doc, size_tag):\n",
    "    \"\"\"Scrapes headers & paragraphs from PDF and return texts with element tags.\n",
    "\n",
    "    :param doc: PDF document to iterate through\n",
    "    :type doc: <class 'fitz.fitz.Document'>\n",
    "    :param size_tag: textual element tags for each size\n",
    "    :type size_tag: dict\n",
    "\n",
    "    :rtype: list\n",
    "    :return: texts with pre-prended element tags\n",
    "    \"\"\"\n",
    "    header_para = []  # list with headers and paragraphs\n",
    "    first = True  # boolean operator for first header\n",
    "    previous_s = {}  # previous span\n",
    "\n",
    "    for page in doc:\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        for b in blocks:  # iterate through the text blocks\n",
    "            if b['type'] == 0:  # this block contains text\n",
    "\n",
    "                # REMEMBER: multiple fonts and sizes are possible IN one block\n",
    "\n",
    "                block_string = \"\"  # text found in block\n",
    "                for l in b[\"lines\"]:  # iterate through the text lines\n",
    "                    for s in l[\"spans\"]:  # iterate through the text spans\n",
    "                        if s['text'].strip():  # removing whitespaces:\n",
    "                            if first:\n",
    "                                previous_s = s\n",
    "                                first = False\n",
    "                                block_string = size_tag[s['size']] + s['text']\n",
    "                            else:\n",
    "                                if s['size'] == previous_s['size']:\n",
    "\n",
    "                                    if block_string and all((c == \"|\") for c in block_string):\n",
    "                                        # block_string only contains pipes\n",
    "                                        block_string = size_tag[s['size']] + s['text']\n",
    "                                    if block_string == \"\":\n",
    "                                        # new block has started, so append size tag\n",
    "                                        block_string = size_tag[s['size']] + s['text']\n",
    "                                    else:  # in the same block, so concatenate strings\n",
    "                                        block_string += \" \" + s['text']\n",
    "\n",
    "                                else:\n",
    "                                    header_para.append(block_string)\n",
    "                                    block_string = size_tag[s['size']] + s['text']\n",
    "\n",
    "                                previous_s = s\n",
    "\n",
    "                    # new block started, indicating with a pipe\n",
    "                    block_string += \"|\"\n",
    "\n",
    "                header_para.append(block_string)\n",
    "\n",
    "    return header_para\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    document = '/Users/yasminsarkhosh/Downloads/storage/IZXYGYNV/Azadi m.fl. - 2023 - ALL-IN A Local GLobal Graph-Based DIstillatioN Mo.pdf'\n",
    "    doc = fitz.open(document)\n",
    "\n",
    "    font_counts, styles = fonts(doc, granularity=False)\n",
    "\n",
    "    size_tag = font_tags(font_counts, styles)\n",
    "\n",
    "    elements = headers_para(doc, size_tag)\n",
    "\n",
    "    with open(\"doc.json\", 'w') as json_out:\n",
    "        json.dump(elements, json_out)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pymupdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = '/Users/yasminsarkhosh/Downloads/storage/IZXYGYNV/Azadi m.fl. - 2023 - ALL-IN A Local GLobal Graph-Based DIstillatioN Mo.pdf'\n",
    "doc = fitz.open(my_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "import os\n",
    "\n",
    "for foldername,subfolders,files in os.walk(r\"C:/my_path\"):\n",
    "    for file in files:\n",
    "        # open the pdf file\n",
    "        object = PyPDF2.PdfFileReader(os.path.join(foldername,file))\n",
    "\n",
    "        # get number of pages\n",
    "        NumPages = object.getNumPages()\n",
    "\n",
    "        # define keyterms\n",
    "        String = \"New York State Real Property Law\"\n",
    "\n",
    "        # extract text and do the search\n",
    "        for i in range(0, NumPages):\n",
    "            PageObj = object.getPage(i)\n",
    "            print(\"this is page \" + str(i)) \n",
    "            Text = PageObj.extractText() \n",
    "            # print(Text)\n",
    "            ResSearch = re.search(String, Text)\n",
    "            print(ResSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL-IN: A Local GLobal Graph-Based\n",
      "DIstillatioN Model for Representation\n",
      "Learning of Gigapixel Histopathology\n",
      "Images With Application In Cancer Risk\n",
      "Assessment\n",
      "Puria Azadi1, Jonathan Suderman1, Ramin Nakhli1, Katherine Rich1,\n",
      "Maryam Asadi1, Sonia Kung2, Htoo Oo2, Mira Keyes1, Hossein Farahani1,\n",
      "Calum MacAulay3, Larry Goldenberg2, Peter Black2, and Ali Bashashati1(B)\n",
      "1 University of British Columbia, Vancouver, BC, Canada\n",
      "ali.bashashati@ubc.ca\n",
      "2 Vancouver Prostate Centre, Vancouver, BC, Canada\n",
      "3 BC Cancer Agency, Vancouver, BC, Canada\n",
      "Abstract. The utility of machine learning models in histopathology\n",
      "image analysis for disease diagnosis has been extensively studied. How-\n",
      "ever, eﬀorts to stratify patient risk are relatively under-explored. While\n",
      "most current techniques utilize small ﬁelds of view (so-called local fea-\n",
      "tures) to link histopathology images to patient outcome, in this work we\n",
      "investigate the combination of global (i.e., contextual) and local features\n",
      "in a graph-based neural network for patient risk stratiﬁcation. The pro-\n",
      "posed network not only combines both ﬁne and coarse histological pat-\n",
      "terns but also utilizes their interactions for improved risk stratiﬁcation.\n",
      "We compared the performance of our proposed model against the state-\n",
      "of-the-art (SOTA) techniques in histopathology risk stratiﬁcation in two\n",
      "cancer datasets. Our results suggest that the proposed model is capable\n",
      "of stratifying patients into statistically signiﬁcant risk groups (p < 0.01\n",
      "across the two datasets) with clinical utility while competing models fail\n",
      "to achieve a statistical signiﬁcance endpoint (p = 0.148 − 0.494).\n",
      "Keywords: Histopathology · Risk Assessment · Graph Processing\n",
      "1\n",
      "Introduction\n",
      "The examination of tissue and cells using microscope (referred to as histology)\n",
      "has been a key component of cancer diagnosis and prognostication since more\n",
      "than a hundred years ago. Histological features allow visual readout of cancer\n",
      "biology as they represent the overall impact of genetic changes on cells [20].\n",
      "The great rise of deep learning in the past decade and our ability to digitize\n",
      "histopathology slides using high-throughput slide scanners have fueled inter-\n",
      "ests in the applications of deep learning in histopathology image analysis. The\n",
      "Supplementary Information The online version contains supplementary material\n",
      "available at https://doi.org/10.1007/978-3-031-43987-2 74.\n",
      "c\n",
      "⃝ The Author(s), under exclusive license to Springer Nature Switzerland AG 2023\n",
      "H. Greenspan et al. (Eds.): MICCAI 2023, LNCS 14225, pp. 765–775, 2023.\n",
      "https://doi.org/10.1007/978-3-031-43987-2_74\n",
      "\n",
      "766\n",
      "P. Azadi et al.\n",
      "majority of the eﬀorts, so far, focus on the deployment of these models for diag-\n",
      "nosis and classiﬁcation [27]. As such, there is a paucity of eﬀorts that embark\n",
      "on utilizing machine learning models for patient prognostication and survival\n",
      "analysis (for example, predicting risk of cancer recurrence or expected patient\n",
      "survival). While prognostication and survival analysis oﬀer invaluable insights\n",
      "for patient management, biological studies and drug development eﬀorts, they\n",
      "require careful tracking of patients for a lengthy period of time; rendering this\n",
      "as a task that requires a signiﬁcant amount of eﬀort and funding.\n",
      "In the machine learning domain, patient prognostication can be treated as a\n",
      "weakly supervised problem, which a model would predict the outcome (e.g., time\n",
      "to cancer recurrence) based on the histopathology images. Their majority have\n",
      "utilized Multiple Instance Learning (MIL) [8] that is a two-step learning method.\n",
      "First, representation maps for a set of patches (i.e., small ﬁelds of view), called\n",
      "a bag of instances, are extracted. Then, a second pooling model is applied to the\n",
      "feature maps for the ﬁnal prediction. Diﬀerent MIL variations have shown supe-\n",
      "rior performances in grading or subtype classiﬁcation in comparison to outcome\n",
      "prediction [10]. This is perhaps due to the fact that MIL-based technique do\n",
      "not incorporate patch locations and interactions as well as tissue heterogeneity\n",
      "which can potentially have a vital role in deﬁning clinical outcomes [4,26].\n",
      "To address this issue, graph neural networks (GNN) have recently received\n",
      "more attention in histology. They can model patch relations [17] by utilizing mes-\n",
      "sage passing mechanism via edges connecting the nodes (i.e., small patches in our\n",
      "case). However, most GNN-based models suﬀer from over smoothing [22] which\n",
      "limits nodes’ receptive ﬁelds [3]. While local contexts mainly capture cell-cell\n",
      "interactions, global patterns such as immune cell inﬁltration patterns and tumor\n",
      "invasion in normal tissue structures (e.g., depth of invasion through myometrium\n",
      "in endometrial cancer [1]) could capture critical information about outcome [10].\n",
      "Hence, locally focused methods are unable to beneﬁt from the coarse properties\n",
      "of slides due to their high dimensions which may lead to poor performance.\n",
      "This paper aims to investigate the potential of extracting ﬁne and coarse\n",
      "features from histopathology slides and integrating them for risk stratiﬁcation\n",
      "in cancer patients. Therefore, the contributions of this work can be summarized\n",
      "as: 1) a novel graph-based model for predicting survival that extracts both local\n",
      "and global properties by identifying morphological super-nodes; 2) introducing\n",
      "a ﬁne-coarse feature distillation module with 3 various strategies to aggregate\n",
      "interactions at diﬀerent scales; 3) outperforming SOTA approaches in both risk\n",
      "prediction and patient stratiﬁcation scenarios on two datasets; 4) publishing\n",
      "two large and rare prostate cancer datasets containing more than 220 graphs for\n",
      "active surveillance and 240 graphs for brachytherapy cases. The code and graph\n",
      "embeddings are publicly available at https://github.com/pazadimo/ALL-IN\n",
      "2\n",
      "Related Works\n",
      "2.1\n",
      "Weakly Supervised Learning in Histopathology\n",
      "Utilizing Weakly Supervised Learning for modeling histopathology problems has\n",
      "been getting popular due to the high resolution of slides and substantial time\n",
      "\n",
      "ALL-IN\n",
      "767\n",
      "and ﬁnancial costs associated with annotating them as well as the development\n",
      "of powerful deep discriminative models in the recent years [24].\n",
      "Such models are used to perform nuclei segmentation [18], identify novel\n",
      "subtypes [12], or later descendants are even able to pinpoint sub-areas with a\n",
      "high diagnostic value [19].\n",
      "2.2\n",
      "Survival Analysis and GNNs in Histopathology\n",
      "MIL-based models have been utilized for outcome prediction [29,32] which can\n",
      "also be integrated with attention-based variants [14]. GNNs due to their struc-\n",
      "tural preserving capacity [28] have drawn attention in various histology domains\n",
      "by constructing the graph on cells or patches. However, current GNN-based risk\n",
      "assessment variants are only focused on short-range interactions [16,17] or con-\n",
      "sider local contexts [10]. We hypothesize that graph-based models’ performance\n",
      "in survival prediction improves by leveraging both ﬁne and coarse properties.\n",
      "3\n",
      "Method\n",
      "Figure 1 summarizes our proposed end-to-end solution. Below, we have provided\n",
      "details of each module.\n",
      "3.1\n",
      "Problem Formulation\n",
      "For Pn, which is the n-th patient, a set of patches {patchj}M\n",
      "j=1 is extracted\n",
      "from the related whole slide images. In addition, a latent vector zj ∈ R1×d is\n",
      "extracted from patchj using our encoder network (described in Sect. 3.2) that\n",
      "results in feature matrix Zn ∈ RM×d for Pn. Finally, a speciﬁc graph (Gn) for\n",
      "the n-th patient (Pn) can be constructed by assuming patches as nodes. Also,\n",
      "edges are connected based on the patches’ k-nearest neighbour in the spatial\n",
      "domain resulting in an adjacency matrix An. Therefore, for each patient such\n",
      "as Pn, we have a graph deﬁned by adjacency matrix An with size M × M and\n",
      "features matrix Zn (Gn = graph(Zn, An)). We estimate K super-nodes as matrix\n",
      "Sn ∈ RK×d representing groups of local nodes with similar properties as coarse\n",
      "features for Pn’s slides. The ﬁnal model (ϵθ) with parameters θ utilizes Gn and\n",
      "Sn to predict the risk associated with this patient:\n",
      "riskn = ϵθ(Gn, Sn) = ϵθ(graph(Xn, An), Sn)\n",
      "(1)\n",
      "3.2\n",
      "Self-supervised Encoder\n",
      "Due to computational limits and large number of patches available for each\n",
      "patient, we utilize a self-supervised approach to train an encoder to reduce\n",
      "the inputs’ feature space size. Therefore, We use DINO [9], a knowledge dis-\n",
      "tillation model (KDM), with vision transformer (ViT) [13] as the backbone. It\n",
      "utilizes global and local augmentations of the input patchj and passes them\n",
      "to the student (Sθ1,V iT ) and teacher (Tθ2,V iT ) models to ﬁnd their respective\n",
      "\n",
      "768\n",
      "P. Azadi et al.\n",
      "Fig. 1. The overview of our proposed method. a) The input slide is tiled into non-\n",
      "overlapping patches. b) The patches are fed into a self-supervised encoder to extract\n",
      "embeddings. c) A graph is constructed and the new local instance-level embeddings\n",
      "are obtained through the message-passing process. d) The global context representa-\n",
      "tions in the form of super-nodes are extracted utilizing two unsupervised loss functions\n",
      "(RminCUT , Rorthognal). e) The ﬁne and coarse feature vectors are aggregated in the\n",
      "distillation module to obtain a representation that accounts for both local and global\n",
      "(contextual) histo-morphological features. Three diﬀerent strategies (S1, S2, S3) are\n",
      "explored in this module. Finally, a Multilayer Perceptron (MLP) is deployed to esti-\n",
      "mate the risk using ﬁnal resultant vectors.\n",
      "representations without any labels. Then, by using distillation loss, it makes the\n",
      "representations’ distribution similar to each other. Finally, the ﬁxed weights of\n",
      "the teacher model are utilized in order to encode the input patches.\n",
      "3.3\n",
      "Local Graph Neural Network\n",
      "GNN’s objective is to ﬁnd new nodes’ embeddings via integrating local neighbors’\n",
      "interactions with individual properties of patches. By exploiting the message\n",
      "passing mechanism, this module iteratively aggregates features from neighbors\n",
      "of each vertex and generates the new node representations. We employ two graph\n",
      "convolution isomorphism operators (GINconv) [30] with the generalized form as:\n",
      "X′\n",
      "n = φ (An + (1 + ϵ).I).Xn) ,\n",
      "(2)\n",
      "where ϵ is a small positive value and I is the identity matrix. Also, φ denotes the\n",
      "weights of two MLP layers. Xn ∈ RM×d and X′\n",
      "n ∈ RM×d are GINconv’s input\n",
      "and output feature matrices for Pn, which Xn equals Zn for the ﬁrst layer.\n",
      "3.4\n",
      "Super-Nodes Extractor\n",
      "In order to ﬁnd the coarse histo-morphological patterns disguised in the local\n",
      "graph, we propose extracting K Super-nodes, which each represents a weighted\n",
      "cluster of further processed local features. Intuitively, the number of super-nodes\n",
      "K should not be very large or small, as the former encourages them to only\n",
      "represent local clusters and the latter leads to larger clusters and loses subtle\n",
      "\n",
      "ALL-IN\n",
      "769\n",
      "details. We exploit the minCUT [5] idea to extract super-nodes in a diﬀerentiable\n",
      "process after an auxiliary GINconv to focus more on large-scale interactions and\n",
      "to ﬁnally learn the most global correlated super-nodes. Inspired by the relaxation\n",
      "form of the known K-way minCUT problem, we create a continuous cluster\n",
      "matrix Cn ∈ RM×K using MLP layers and can ﬁnally estimate the super-nodes\n",
      "features (Sn ∈ RM×d) as:\n",
      "Sn = CT\n",
      "n .X′\n",
      "n,\n",
      "Cn = softmax (ReLU(X′\n",
      "n.W1).W2) ,\n",
      "(3)\n",
      "where W1, W2 are MLPs’ weights. Hence, the extracted nodes are directly depen-\n",
      "dent on the ﬁnal survival-speciﬁc loss. In addition, two additional unsupervised\n",
      "weighted regularization terms are optimized to improve the process:\n",
      "MinCut Regularizer. This term is motivated by the original minCUT problem\n",
      "and intends to solve it for the the patients’ graph. It is deﬁned as:\n",
      "RminCUT = −Tr(CT\n",
      "n .An,norm.Cn)\n",
      "Tr(CTn .Dn.Cn)\n",
      ",\n",
      "(4)\n",
      "where Dn is the diagonal degree matrix for An. Also, Tr(.) represents the trace\n",
      "of matrix and An,norm is the normalized adjacency matrix. RminCUT ’s mini-\n",
      "mum value happens when Tr(CT\n",
      "n .An,norm.Cn) equals Tr(CT\n",
      "n .Dg,n.Cn). There-\n",
      "fore, minimizing RminCUT causes assigning strongly similar nodes to a same\n",
      "super-node and prevent their association with others.\n",
      "Orthogonality Regularizer. RminCUT is non-convex and potent to local min-\n",
      "ima such as assigning all vertexes to a super-node or having multiple super-nodes\n",
      "with only a single vertex. Rorthogonal penalizes such solutions and helps the model\n",
      "to distribute the graph’s features between super-nodes. It can be formulated as:\n",
      "Rorthogonal =\n",
      "\u0002\u0002\u0002\u0002\n",
      "\u0002\u0002\u0002\u0002\n",
      "CT\n",
      "n .Cn\n",
      "||CTn .Cn||F\n",
      "−\n",
      "I\n",
      "√\n",
      "K\n",
      "\u0002\u0002\u0002\u0002\n",
      "\u0002\u0002\u0002\u0002\n",
      "F\n",
      ",\n",
      "(5)\n",
      "where ||.||F is the Frobenius norm, and I is the identity matrix. This term pushes\n",
      "the model’s parameters to ﬁnd coarse features that are orthogonal to each other\n",
      "resulting in having the most useful global features.\n",
      "Overall, utilizing these two terms encourages the model to extract super-\n",
      "nodes by leaning more towards the strongly associated vertexes and keeping\n",
      "them against weakly connected ones [5], while the main survival loss still controls\n",
      "the global extraction process.\n",
      "3.5\n",
      "Fine-Coarse Distillation\n",
      "We propose our ﬁne-coarse morphological feature distillation module to leverage\n",
      "all-scale interactions in the ﬁnal prediction by ﬁnding a local and a global patient-\n",
      "level representations (ˆhl,n, ˆhg,n). Assume that X′\n",
      "n ∈ RM×d and Sn ∈ RK×d are\n",
      "the feature matrices taken from local GNN (Sect. 3.3) and super-nodes for Pn,\n",
      "respectively. We explore 3 diﬀerent attention-based feature distillation strategies\n",
      "for this task, including:\n",
      "\n",
      "770\n",
      "P. Azadi et al.\n",
      "– Dual Attention (DA): Two gated self-attention modules for local and\n",
      "global properties with separate weights (Wφ,l, Wφ,g, Wk,l, Wk,g, Wq,l, Wq,g)\n",
      "are utilized to ﬁnd patches scores αl ∈ R1×M and αg ∈ R1×K and the ﬁnal\n",
      "features (ˆhl,n, ˆhg,n ) as:\n",
      "ˆhl,n =\n",
      "M\n",
      "\u0002\n",
      "i=1\n",
      "Wφ,lαl,ix′\n",
      "n,i, αl = softmax\n",
      "\u0003\n",
      "Wv,l\n",
      "\u0004\n",
      "tanh(Wq,lX\n",
      "′T\n",
      "n ) · sigm(Wk,lX\n",
      "′T\n",
      "n )\n",
      "\u0005\u0006\n",
      ",\n",
      "(6)\n",
      "ˆhg,n =\n",
      "K\n",
      "\u0002\n",
      "i=1\n",
      "Wφ,gαg,isn,i, αg = softmax\n",
      "\u0003\n",
      "Wv,g\n",
      "\u0004\n",
      "tanh(Wq,gST\n",
      "n ) · sigm(Wk,gST\n",
      "n )\n",
      "\u0005\u0006\n",
      ",\n",
      "(7)\n",
      "where x′\n",
      "n,i and sn,i are rows of X′\n",
      "n and Sn, respectively, and the ﬁnal repre-\n",
      "sentation (ˆh) is generated as ˆh = cat(ˆhl, ˆhg).\n",
      "– Mixed Guided Attention (MGA): In the ﬁrst strategy, the information\n",
      "ﬂows from local and global features to the ﬁnal representations in paral-\n",
      "lel without mixing any knowledge. The purpose of this policy is the heavy\n",
      "fusion of ﬁne and coarse knowledge by exploiting shared weights (Wφ,shared,\n",
      "Wk,shared, Wq,shared, Wv,shared) in both routes and beneﬁting from the guid-\n",
      "ance of local representation on learning the global one by modifying Eq. (7)\n",
      "to:\n",
      "αg = softmax\n",
      "\u0003\n",
      "Wφ,g\n",
      "\u0004\n",
      "tanh(Wq,gST\n",
      "n ˆhl,n) · sigm(Wk,gST\n",
      "n ˆhl,n)\n",
      "\u0005\u0006\n",
      "(8)\n",
      "– Mixed Co-Attention (MCA): While the ﬁrst strategy allows the extreme\n",
      "separation of two paths, the second one has the highest level of mixing infor-\n",
      "mation. Here, we take a balanced policy between the independence and knowl-\n",
      "edge mixture of the two routes by only sharing the weights without using any\n",
      "guidance.\n",
      "4\n",
      "Experiments and Results\n",
      "4.1\n",
      "Dataset\n",
      "We utilize two prostate cancer (PCa) datasets to evaluate the performance of\n",
      "our proposed model. The ﬁrst set (PCa-AS) includes 179 PCa patients who\n",
      "were managed with Active Surveillance (AS). Radical therapy is considered\n",
      "overtreatment in these patients, so they are instead monitored with regular\n",
      "serum prostate-speciﬁc antigen (PSA) measurements, physical examinations,\n",
      "sequential biopsies, and magnetic resonance imaging [23]. However, AS may be\n",
      "over- or under-utilized in low- and intermediate-risk PCa due to the uncertainty\n",
      "of current methods to distinguish indolent from aggressive cancers [11]. Although\n",
      "majority of patients in our cohort are classiﬁed as low-risk based on NCCN guide-\n",
      "lines [21], a signiﬁcant subset of them experienced disease upgrade that triggered\n",
      "deﬁnitive therapy (range: 6.2 to 224 months after diagnosis).\n",
      "The second dataset (PCa-BT) includes 105 PCa patients with low to high\n",
      "risk disease who went through brachytherapy. This treatment involves placing a\n",
      "radioactive material inside the body to safely deliver larger dose of radiation at\n",
      "\n",
      "ALL-IN\n",
      "771\n",
      "Table 1. Comparison of our method against baselines and ablation study on policies.\n",
      "Model\n",
      "c-index ↑\n",
      "p-value ↓\n",
      "High ↓ - Low ↑ Median Time Parameters\n",
      "PCa-AS\n",
      "PCa-BT\n",
      "PCa-AS PCa-BT PCa-AS\n",
      "PCa-BT\n",
      "PCa-AS\n",
      "DeepSet\n",
      "0.495 ± 0.017\n",
      "0.50 ± 0.0\n",
      "0.837\n",
      "0.912\n",
      "67.78–71.87\n",
      "24.62–24.89\n",
      "329K\n",
      "AMIL\n",
      "0.544 ± 0.06\n",
      "0.533 ± 0.060\n",
      "0.820\n",
      "0.148\n",
      "48.99–89.10\n",
      "21.86–30.71\n",
      "592K\n",
      "DGC\n",
      "0.522 ± 0.113\n",
      "0.572 ± 0.150\n",
      "0.494\n",
      "0.223\n",
      "47.61–96.66\n",
      "23.44–24.85\n",
      "626K\n",
      "Patch-GCN\n",
      "0.555 ± 0.059\n",
      "0.541 ± 0.118\n",
      "0.630\n",
      "0.981\n",
      "37.72–94.95\n",
      "23.05–25.25\n",
      "1,302K\n",
      "ALL-IN +\n",
      "DA (ours)\n",
      "0.631 ± 0.058\n",
      "0.596 ± 0.062\n",
      "< 0.01\n",
      "< 0.01\n",
      "37.72–115.91\n",
      "21.86–35.77\n",
      "850K\n",
      "ALL-IN +\n",
      "MGA (ours)\n",
      "0.632 ± 0.060\n",
      "0.589 ± 0.074\n",
      "< 0.01\n",
      "< 0.01\n",
      "47.61–101.39\n",
      "21.86–35.77\n",
      "653K\n",
      "ALL-IN +\n",
      "MCA (ours)\n",
      "0.639 ± 0.048 0.600 ± 0.077 < 0.01\n",
      "< 0.01\n",
      "36.5–131.71 21.86–35.77\n",
      "653K\n",
      "one time [25]. The recorded endpoint for this set is biochemical recurrence with\n",
      "time to recurrence ranging from 11.7 to 56.1 months.\n",
      "We also utilized the Prostate cANcer graDe Assessment (PANDA) Challenge\n",
      "dataset [7] that includes more than 10,000 PCa needle biopsy slides (no outcome\n",
      "data) as an external dataset for training the encoder of our model.\n",
      "4.2\n",
      "Experiments\n",
      "We evaluate the models’ performance in two scenarios utilizing several objective\n",
      "metrics. Implementation details are available in supplementary material.\n",
      "Hazard (Risk) Prediction. We utilize concordance-index (c-index) that mea-\n",
      "sures the relative ordering of patients with observed events and un-censored\n",
      "cases relative to censored instances [2]. Using c-index, we compare the quality\n",
      "of hazard ranking against multiple methods including two MIL (DeepSet [31],\n",
      "AMIL [14]) and graph-based (DGC [17] and Patch-GCN [10]) models that were\n",
      "utilized recently for histopathology risk assessment. C-index values are avail-\n",
      "able in Table 1. The proposed model with all strategies outperforms baselines\n",
      "across all sets and is able to achieve 0.639 and 0.600 on PCa-AS and PCa-BT,\n",
      "while the baselines, at best, obtain 0.555, and 0.572, respectively. Statistical tests\n",
      "(paired t-test) on c-indices also show that our model is statistically better than\n",
      "all baselines in PCa-AS and also superior to all models, except DGC, in PCa-BT.\n",
      "Superior performance of our MCA policy implies that balanced exploitation of\n",
      "ﬁne and coarse features with shared weights may provide more robust contex-\n",
      "tual information compared to using mixed guided information or utilizing them\n",
      "independently.\n",
      "Patient Stratiﬁcation. The capacity of stratifying patients into risk groups\n",
      "(e.g., low and high risk) is another criterion that we employ to assess the util-\n",
      "ity of models in clinical practice. We evaluate model performances via Kaplan-\n",
      "Meier curve [15] (cut-oﬀ set as the ratio of patients with recurrence within 3\n",
      "\n",
      "772\n",
      "P. Azadi et al.\n",
      "Fig. 2. Kaplan-Meier curves of mixed co-attention model for PCa-AS and PCa-BT.\n",
      "years of therapy initiation for PCa-BT and the ratio of upgraded cases for PCa-\n",
      "AS), LogRank test [6] (with 0.05 as signiﬁcance level), and median outcome\n",
      "associated with risk groups (Table 1 and Fig. 2). Our model stratiﬁed PCa-AS\n",
      "patients into high- and low-risk groups with median time to progression of 36.5\n",
      "and 131.7 months, respectively. Moreover, PCa-BT cases assigned to high- and\n",
      "low-risk groups have median recurrence time of 21.86 and 35.7 months. While\n",
      "none of the baselines are capable of assigning patients into risk groups with\n",
      "statistical signiﬁcance, our distillation policies achieve signiﬁcant separation in\n",
      "both PCa-AS and PCa-BT datasets; suggesting that global histo-morphological\n",
      "properties improve patient stratiﬁcation performance. Furthermore, our ﬁndings\n",
      "have signiﬁcant clinical implications as they identify, for the ﬁrst time, high-\n",
      "risk prostate cancer patients who are otherwise known to be low-risk based on\n",
      "clinico-pathological parameters. This group should be managed diﬀerently from\n",
      "the rest of the low-risk prostate cancer patients in the clinic. Therefore, pro-\n",
      "viding evidence of the predictive (as opposed to prognostic) clinical information\n",
      "that our model provides. While a prognostic biomarker provides information\n",
      "about a patient’s outcome (without speciﬁc recommendation on the next course\n",
      "of action), a predictive biomarker gives insights about the eﬀect of a therapeutic\n",
      "intervention and potential actions that can be taken.\n",
      "Ablation Study. We perform ablation study (Table 2) on various components\n",
      "of our framework including local nodes, self-supervised ViT-based encoder, and\n",
      "most importantly, super-nodes in addition to ﬁne-coarse distillation module.\n",
      "Although our local-only model is still showing superior results compared to\n",
      "baselines, this analysis demonstrates that all modules are essential for learn-\n",
      "ing the most eﬀective representations. We also assess the impact of our ViT on\n",
      "the baselines (full-results in appendix), showing that it can, on average, improve\n",
      "their performance by an increase of ∼ 0.03 in c-index for PCa-AS. However, the\n",
      "best baseline with ViT still has poorer performance compared to our model in\n",
      "both datasets, while the number of parameters (reported for ViT embeddings’\n",
      "size in Table 1) in our full-model is about half of this baseline. Achieving higher\n",
      "c-indices in our all model versions indicates the important role of coarse features\n",
      "and global context in patient risk estimation in addition to local patterns.\n",
      "\n",
      "ALL-IN\n",
      "773\n",
      "Table 2. Ablation study on diﬀerent modules.\n",
      "Modules\n",
      "c-index ↑\n",
      "Model\n",
      "Local-node our KDM-\n",
      "ViT\n",
      "Super-node\n",
      "+ Distillation\n",
      "Model\n",
      "PCa-AS\n",
      "PCa-BT\n",
      "Patch-GCN ✓\n",
      "✓\n",
      "✗\n",
      "0.627 ± 0.046\n",
      "0.588 ± 0.067\n",
      "Ours\n",
      "✓\n",
      "✗\n",
      "✗\n",
      "0.584 ± 0.072\n",
      "0.550 ± 0.109\n",
      "✓\n",
      "✓\n",
      "✗\n",
      "0.622 ± 0.055\n",
      "0.597 ± 0.045\n",
      "✓\n",
      "✓\n",
      "✓\n",
      "0.639 ± 0.048 0.600 ± 0.077\n",
      "5\n",
      "Conclusion\n",
      "While risk assessment is relatively under-explored, most existing methods are\n",
      "focused only on small ﬁelds of view. In this work, we introduce a novel graph-\n",
      "based model for integrating global and local features, which utilizes interactions\n",
      "at a larger scale for improved risk stratiﬁcation. Using two cancer datasets, we\n",
      "evaluated the eﬀectiveness of our model against the baseline methods for hazard\n",
      "prediction and patients stratiﬁcation. Our results suggest that the proposed\n",
      "model outperforms them in risk assessment and is capable of separating patients\n",
      "into statistically signiﬁcant risk groups with actionable clinical utility. The full\n",
      "capacity of this work can be revealed by extending it to other histology tasks.\n",
      "Acknowledgment:. This work was supported by a Canadian Institutes of Health\n",
      "Research grant to AB, PB, and LG and Michael Smith Health Research BC Scholar\n",
      "grant to AB.\n",
      "References\n",
      "1. Abu-Rustum, N.R., et al.: The revised 2009 ﬁgo staging system for endometrial\n",
      "cancer: should the 1988 ﬁgo stages ia and ib be altered? Int. J. Gynecol. Cancer\n",
      "21(3) (2011)\n",
      "2. Alabdallah, A., Ohlsson, M., Pashami, S., R¨ognvaldsson, T.: The concordance\n",
      "index decomposition-a measure for a deeper understanding of survival prediction\n",
      "models. arXiv preprint arXiv:2203.00144 (2022)\n",
      "3. Alon, U., Yahav, E.: On the bottleneck of graph neural networks and its practical\n",
      "implications. arXiv preprint arXiv:2006.05205 (2020)\n",
      "4. Angell, H., Galon, J.: From the immune contexture to the immunoscore: the role of\n",
      "prognostic and predictive immune markers in cancer. Curr. Opin. Immunol. 25(2),\n",
      "261–267 (2013)\n",
      "5. Bianchi, F.M., Grattarola, D., Alippi, C.: Spectral clustering with graph neural\n",
      "networks for graph pooling. In: International Conference on Machine Learning,\n",
      "pp. 874–883. PMLR (2020)\n",
      "6. Bland, J.M., Altman, D.G.: The logrank test. BMJ 328(7447), 1073 (2004)\n",
      "7. Bulten, W., et al.: Artiﬁcial intelligence for diagnosis and gleason grading of\n",
      "prostate cancer: the panda challenge. Nat. Med. 28(1), 154–163 (2022)\n",
      "\n",
      "774\n",
      "P. Azadi et al.\n",
      "8. Carbonneau, M.A., Cheplygina, V., Granger, E., Gagnon, G.: Multiple instance\n",
      "learning: a survey of problem characteristics and applications. Pattern Recogn.\n",
      "77, 329–353 (2018)\n",
      "9. Caron, M., Touvron, H., Misra, I., J´egou, H., Mairal, J., Bojanowski, P., Joulin, A.:\n",
      "Emerging properties in self-supervised vision transformers. In: Proceedings of the\n",
      "IEEE/CVF International Conference on Computer Vision, pp. 9650–9660 (2021)\n",
      "10. Chen, R.J., et al.: Whole slide images are 2D point clouds: context-aware survival\n",
      "prediction using patch-based graph convolutional networks. In: de Bruijne, M.,\n",
      "et al. (eds.) MICCAI 2021. LNCS, vol. 12908, pp. 339–349. Springer, Cham (2021).\n",
      "https://doi.org/10.1007/978-3-030-87237-3 33\n",
      "11. Cooperberg,\n",
      "M.R.,\n",
      "et\n",
      "al.:\n",
      "Outcomes\n",
      "of\n",
      "active\n",
      "surveillance\n",
      "for\n",
      "men\n",
      "with\n",
      "intermediate-risk prostate cancer. J. Clin. Oncol. Oﬀ. J. Am. Soc. Clin. Oncol.\n",
      "29(2), 228–234 (2011)\n",
      "12. Darbandsari, A., et al.: Identiﬁcation of a novel subtype of endometrial cancer\n",
      "with unfavorable outcome using artiﬁcial intelligence-based histopathology image\n",
      "analysis (2022)\n",
      "13. Dosovitskiy, A., et al.: An image is worth 16×16 words: transformers for image\n",
      "recognition at scale. arXiv preprint arXiv:2010.11929 (2020)\n",
      "14. Ilse, M., Tomczak, J., Welling, M.: Attention-based deep multiple instance learning.\n",
      "In: International Conference on Machine Learning, pp. 2127–2136. PMLR (2018)\n",
      "15. Kaplan, E.L., Meier, P.: Nonparametric estimation from incomplete observations.\n",
      "J. Am. Stat. Assoc. 53(282), 457–481 (1958)\n",
      "16. Lee, Y., et al.: Derivation of prognostic contextual histopathological features from\n",
      "whole-slide images of tumours via graph deep learning. Nat. Biomed. Eng., 1–15\n",
      "(2022)\n",
      "17. Li, R., Yao, J., Zhu, X., Li, Y., Huang, J.: Graph CNN for survival analysis on\n",
      "whole slide pathological images. In: Frangi, A.F., Schnabel, J.A., Davatzikos, C.,\n",
      "Alberola-L´opez, C., Fichtinger, G. (eds.) MICCAI 2018. LNCS, vol. 11071, pp.\n",
      "174–182. Springer, Cham (2018). https://doi.org/10.1007/978-3-030-00934-2 20\n",
      "18. Liu, W., He, Q., He, X.: Weakly supervised nuclei segmentation via instance learn-\n",
      "ing. In: 2022 IEEE 19th International Symposium on Biomedical Imaging (ISBI),\n",
      "pp. 1–5. IEEE (2022)\n",
      "19. Lu, M.Y., Williamson, D.F., Chen, T.Y., Chen, R.J., Barbieri, M., Mahmood,\n",
      "F.: Data-eﬃcient and weakly supervised computational pathology on whole-slide\n",
      "images. Nat. Biomed. Eng. 5(6), 555–570 (2021)\n",
      "20. Mobadersany, P., et al.: Predicting cancer outcomes from histology and genomics\n",
      "using convolutional networks. Proc. Natl. Acad. Sci. 115(13), E2970–E2979 (2018)\n",
      "21. Moses, K.A., et al.: Nccn guidelines R\n",
      "⃝ insights: prostate cancer early detection, ver-\n",
      "sion 1.2023: featured updates to the nccn guidelines. J. Natl. Comprehens. Cancer\n",
      "Netw. 21(3), 236–246 (2023)\n",
      "22. Oono, K., Suzuki, T.: Graph neural networks exponentially lose expressive power\n",
      "for node classiﬁcation. arXiv preprint arXiv:1905.10947 (2019)\n",
      "23. Ouzzane, A., et al.: Magnetic resonance imaging targeted biopsy improves selection\n",
      "of patients considered for active surveillance for clinically low risk prostate cancer\n",
      "based on systematic biopsies. J. Urol. 194(2), 350–356 (2015)\n",
      "24. Rony, J., Belharbi, S., Dolz, J., Ayed, I.B., McCaﬀrey, L., Granger, E.: Deep\n",
      "weakly-supervised learning methods for classiﬁcation and localization in histology\n",
      "images: a survey. arXiv preprint arXiv:1909.03354 (2019)\n",
      "25. Skowronek, J.: Current status of brachytherapy in cancer treatment-short overview.\n",
      "J. Contemp. Brachyther. 9(6), 581–589 (2017)\n",
      "\n",
      "ALL-IN\n",
      "775\n",
      "26. Son, B., Lee, S., Youn, H., Kim, E., Kim, W., Youn, B.: The role of tumor microen-\n",
      "vironment in therapeutic resistance. Oncotarget 8(3), 3933 (2017)\n",
      "27. Srinidhi, C.L., Ciga, O., Martel, A.L.: Deep neural network models for computa-\n",
      "tional histopathology: a survey. Med. Image Anal. 67, 101813 (2021)\n",
      "28. Tang, S., Chen, D., Bai, L., Liu, K., Ge, Y., Ouyang, W.: Mutual crf-gnn for few-\n",
      "shot learning. In: Proceedings of the IEEE/CVF Conference on Computer Vision\n",
      "and Pattern Recognition, pp. 2329–2339 (2021)\n",
      "29. Wetstein, S.C., et al.: Deep learning-based breast cancer grading and survival anal-\n",
      "ysis on whole-slide histopathology images. Sci. Rep. 12(1), 1–12 (2022)\n",
      "30. Xu, K., Hu, W., Leskovec, J., Jegelka, S.: How powerful are graph neural networks?\n",
      "arXiv preprint arXiv:1810.00826 (2018)\n",
      "31. Zaheer, M., Kottur, S., Ravanbakhsh, S., Poczos, B., Salakhutdinov, R.R., Smola,\n",
      "A.J.: Deep sets. Adv. Neural Inf. Process. Syst. 30, 1–11 (2017)\n",
      "32. Zhu, X., Yao, J., Zhu, F., Huang, J.: Wsisa: making survival prediction from whole\n",
      "slide histopathological images. In: Proceedings of the IEEE Conference on Com-\n",
      "puter Vision and Pattern Recognition, pp. 7234–7242 (2017)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for page in doc:\n",
    "    text = page.get_text()\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(334.6109924316406,\n",
       "  31.01311492919922,\n",
       "  399.40130615234375,\n",
       "  39.979515075683594,\n",
       "  'ALL-IN\\n775\\n',\n",
       "  0,\n",
       "  0),\n",
       " (53.57623291015625,\n",
       "  56.92424774169922,\n",
       "  399.344970703125,\n",
       "  230.27182006835938,\n",
       "  '26. Son, B., Lee, S., Youn, H., Kim, E., Kim, W., Youn, B.: The role of tumor microen-\\nvironment in therapeutic resistance. Oncotarget 8(3), 3933 (2017)\\n27. Srinidhi, C.L., Ciga, O., Martel, A.L.: Deep neural network models for computa-\\ntional histopathology: a survey. Med. Image Anal. 67, 101813 (2021)\\n28. Tang, S., Chen, D., Bai, L., Liu, K., Ge, Y., Ouyang, W.: Mutual crf-gnn for few-\\nshot learning. In: Proceedings of the IEEE/CVF Conference on Computer Vision\\nand Pattern Recognition, pp. 2329–2339 (2021)\\n29. Wetstein, S.C., et al.: Deep learning-based breast cancer grading and survival anal-\\nysis on whole-slide histopathology images. Sci. Rep. 12(1), 1–12 (2022)\\n30. Xu, K., Hu, W., Leskovec, J., Jegelka, S.: How powerful are graph neural networks?\\narXiv preprint arXiv:1810.00826 (2018)\\n31. Zaheer, M., Kottur, S., Ravanbakhsh, S., Poczos, B., Salakhutdinov, R.R., Smola,\\nA.J.: Deep sets. Adv. Neural Inf. Process. Syst. 30, 1–11 (2017)\\n32. Zhu, X., Yao, J., Zhu, F., Huang, J.: Wsisa: making survival prediction from whole\\nslide histopathological images. In: Proceedings of the IEEE Conference on Com-\\nputer Vision and Pattern Recognition, pp. 7234–7242 (2017)\\n',\n",
       "  1,\n",
       "  0)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = page.get_text(\"blocks\")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Puria Azadi1, Jonathan Suderman1, Ramin Nakhli1, Katherine Rich1,\n",
      "Maryam Asadi1, Sonia Kung2, Htoo Oo2, Mira Keyes1, Hossein Farahani1,\n",
      "Calum MacAulay3, Larry Goldenberg2, Peter Black2, and Ali Bashashati1(B)\n",
      "\n",
      "\n",
      "\n",
      "1 University of British Columbia, Vancouver, BC, Canada\n",
      "ali.bashashati@ubc.ca\n",
      "2 Vancouver Prostate Centre, Vancouver, BC, Canada\n",
      "3 BC Cancer Agency, Vancouver, BC, Canada\n",
      "\n",
      "\n",
      "\n",
      "Abstract. The utility of machine learning models in histopathology\n",
      "image analysis for disease diagnosis has been extensively studied. How-\n",
      "ever, eﬀorts to stratify patient risk are relatively under-explored. While\n",
      "most current techniques utilize small ﬁelds of view (so-called local fea-\n",
      "tures) to link histopathology images to patient outcome, in this work we\n",
      "investigate the combination of global (i.e., contextual) and local features\n",
      "in a graph-based neural network for patient risk stratiﬁcation. The pro-\n",
      "posed network not only combines both ﬁne and coarse histological pat-\n",
      "terns but also utilizes their interactions for improved risk stratiﬁcation.\n",
      "We compared the performance of our proposed model against the state-\n",
      "of-the-art (SOTA) techniques in histopathology risk stratiﬁcation in two\n",
      "cancer datasets. Our results suggest that the proposed model is capable\n",
      "of stratifying patients into statistically signiﬁcant risk groups (p < 0.01\n",
      "across the two datasets) with clinical utility while competing models fail\n",
      "to achieve a statistical signiﬁcance endpoint (p = 0.148 − 0.494).\n",
      "\n",
      "\n",
      "\n",
      "Keywords: Histopathology · Risk Assessment · Graph Processing\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Introduction\n",
      "\n",
      "\n",
      "\n",
      "The examination of tissue and cells using microscope (referred to as histology)\n",
      "has been a key component of cancer diagnosis and prognostication since more\n",
      "than a hundred years ago. Histological features allow visual readout of cancer\n",
      "biology as they represent the overall impact of genetic changes on cells [20].\n",
      "The great rise of deep learning in the past decade and our ability to digitize\n",
      "histopathology slides using high-throughput slide scanners have fueled inter-\n",
      "ests in the applications of deep learning in histopathology image analysis. The\n",
      "\n",
      "\n",
      "\n",
      "Supplementary Information The online version contains supplementary material\n",
      "available at https://doi.org/10.1007/978-3-031-43987-2 74.\n",
      "\n",
      "\n",
      "\n",
      "c\n",
      "⃝ The Author(s), under exclusive license to Springer Nature Switzerland AG 2023\n",
      "H. Greenspan et al. (Eds.): MICCAI 2023, LNCS 14225, pp. 765–775, 2023.\n",
      "https://doi.org/10.1007/978-3-031-43987-2_74\n",
      "\n",
      "\n",
      "\n",
      "majority of the eﬀorts, so far, focus on the deployment of these models for diag-\n",
      "nosis and classiﬁcation [27]. As such, there is a paucity of eﬀorts that embark\n",
      "on utilizing machine learning models for patient prognostication and survival\n",
      "analysis (for example, predicting risk of cancer recurrence or expected patient\n",
      "survival). While prognostication and survival analysis oﬀer invaluable insights\n",
      "for patient management, biological studies and drug development eﬀorts, they\n",
      "require careful tracking of patients for a lengthy period of time; rendering this\n",
      "as a task that requires a signiﬁcant amount of eﬀort and funding.\n",
      "In the machine learning domain, patient prognostication can be treated as a\n",
      "weakly supervised problem, which a model would predict the outcome (e.g., time\n",
      "to cancer recurrence) based on the histopathology images. Their majority have\n",
      "utilized Multiple Instance Learning (MIL) [8] that is a two-step learning method.\n",
      "First, representation maps for a set of patches (i.e., small ﬁelds of view), called\n",
      "a bag of instances, are extracted. Then, a second pooling model is applied to the\n",
      "feature maps for the ﬁnal prediction. Diﬀerent MIL variations have shown supe-\n",
      "rior performances in grading or subtype classiﬁcation in comparison to outcome\n",
      "prediction [10]. This is perhaps due to the fact that MIL-based technique do\n",
      "not incorporate patch locations and interactions as well as tissue heterogeneity\n",
      "which can potentially have a vital role in deﬁning clinical outcomes [4,26].\n",
      "To address this issue, graph neural networks (GNN) have recently received\n",
      "more attention in histology. They can model patch relations [17] by utilizing mes-\n",
      "sage passing mechanism via edges connecting the nodes (i.e., small patches in our\n",
      "case). However, most GNN-based models suﬀer from over smoothing [22] which\n",
      "limits nodes’ receptive ﬁelds [3]. While local contexts mainly capture cell-cell\n",
      "interactions, global patterns such as immune cell inﬁltration patterns and tumor\n",
      "invasion in normal tissue structures (e.g., depth of invasion through myometrium\n",
      "in endometrial cancer [1]) could capture critical information about outcome [10].\n",
      "Hence, locally focused methods are unable to beneﬁt from the coarse properties\n",
      "of slides due to their high dimensions which may lead to poor performance.\n",
      "This paper aims to investigate the potential of extracting ﬁne and coarse\n",
      "features from histopathology slides and integrating them for risk stratiﬁcation\n",
      "in cancer patients. Therefore, the contributions of this work can be summarized\n",
      "as: 1) a novel graph-based model for predicting survival that extracts both local\n",
      "and global properties by identifying morphological super-nodes; 2) introducing\n",
      "a ﬁne-coarse feature distillation module with 3 various strategies to aggregate\n",
      "interactions at diﬀerent scales; 3) outperforming SOTA approaches in both risk\n",
      "prediction and patient stratiﬁcation scenarios on two datasets; 4) publishing\n",
      "two large and rare prostate cancer datasets containing more than 220 graphs for\n",
      "active surveillance and 240 graphs for brachytherapy cases. The code and graph\n",
      "embeddings are publicly available at https://github.com/pazadimo/ALL-IN\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "Related Works\n",
      "\n",
      "\n",
      "\n",
      "2.1\n",
      "Weakly Supervised Learning in Histopathology\n",
      "\n",
      "\n",
      "\n",
      "Utilizing Weakly Supervised Learning for modeling histopathology problems has\n",
      "been getting popular due to the high resolution of slides and substantial time\n",
      "\n",
      "\n",
      "\n",
      "and ﬁnancial costs associated with annotating them as well as the development\n",
      "of powerful deep discriminative models in the recent years [24].\n",
      "Such models are used to perform nuclei segmentation [18], identify novel\n",
      "subtypes [12], or later descendants are even able to pinpoint sub-areas with a\n",
      "high diagnostic value [19].\n",
      "\n",
      "\n",
      "\n",
      "2.2\n",
      "Survival Analysis and GNNs in Histopathology\n",
      "\n",
      "\n",
      "\n",
      "MIL-based models have been utilized for outcome prediction [29,32] which can\n",
      "also be integrated with attention-based variants [14]. GNNs due to their struc-\n",
      "tural preserving capacity [28] have drawn attention in various histology domains\n",
      "by constructing the graph on cells or patches. However, current GNN-based risk\n",
      "assessment variants are only focused on short-range interactions [16,17] or con-\n",
      "sider local contexts [10]. We hypothesize that graph-based models’ performance\n",
      "in survival prediction improves by leveraging both ﬁne and coarse properties.\n",
      "\n",
      "\n",
      "\n",
      "3\n",
      "Method\n",
      "\n",
      "\n",
      "\n",
      "Figure 1 summarizes our proposed end-to-end solution. Below, we have provided\n",
      "details of each module.\n",
      "\n",
      "\n",
      "\n",
      "3.1\n",
      "Problem Formulation\n",
      "\n",
      "\n",
      "\n",
      "For Pn, which is the n-th patient, a set of patches {patchj}M\n",
      "j=1 is extracted\n",
      "from the related whole slide images. In addition, a latent vector zj ∈ R1×d is\n",
      "extracted from patchj using our encoder network (described in Sect. 3.2) that\n",
      "results in feature matrix Zn ∈ RM×d for Pn. Finally, a speciﬁc graph (Gn) for\n",
      "the n-th patient (Pn) can be constructed by assuming patches as nodes. Also,\n",
      "edges are connected based on the patches’ k-nearest neighbour in the spatial\n",
      "domain resulting in an adjacency matrix An. Therefore, for each patient such\n",
      "as Pn, we have a graph deﬁned by adjacency matrix An with size M × M and\n",
      "features matrix Zn (Gn = graph(Zn, An)). We estimate K super-nodes as matrix\n",
      "Sn ∈ RK×d representing groups of local nodes with similar properties as coarse\n",
      "features for Pn’s slides. The ﬁnal model (ϵθ) with parameters θ utilizes Gn and\n",
      "Sn to predict the risk associated with this patient:\n",
      "\n",
      "\n",
      "\n",
      "riskn = ϵθ(Gn, Sn) = ϵθ(graph(Xn, An), Sn)\n",
      "(1)\n",
      "\n",
      "\n",
      "\n",
      "3.2\n",
      "Self-supervised Encoder\n",
      "\n",
      "\n",
      "\n",
      "Due to computational limits and large number of patches available for each\n",
      "patient, we utilize a self-supervised approach to train an encoder to reduce\n",
      "the inputs’ feature space size. Therefore, We use DINO [9], a knowledge dis-\n",
      "tillation model (KDM), with vision transformer (ViT) [13] as the backbone. It\n",
      "utilizes global and local augmentations of the input patchj and passes them\n",
      "to the student (Sθ1,V iT ) and teacher (Tθ2,V iT ) models to ﬁnd their respective\n",
      "\n",
      "\n",
      "\n",
      "Fig. 1. The overview of our proposed method. a) The input slide is tiled into non-\n",
      "overlapping patches. b) The patches are fed into a self-supervised encoder to extract\n",
      "embeddings. c) A graph is constructed and the new local instance-level embeddings\n",
      "are obtained through the message-passing process. d) The global context representa-\n",
      "tions in the form of super-nodes are extracted utilizing two unsupervised loss functions\n",
      "(RminCUT , Rorthognal). e) The ﬁne and coarse feature vectors are aggregated in the\n",
      "distillation module to obtain a representation that accounts for both local and global\n",
      "(contextual) histo-morphological features. Three diﬀerent strategies (S1, S2, S3) are\n",
      "explored in this module. Finally, a Multilayer Perceptron (MLP) is deployed to esti-\n",
      "mate the risk using ﬁnal resultant vectors.\n",
      "\n",
      "\n",
      "\n",
      "representations without any labels. Then, by using distillation loss, it makes the\n",
      "representations’ distribution similar to each other. Finally, the ﬁxed weights of\n",
      "the teacher model are utilized in order to encode the input patches.\n",
      "\n",
      "\n",
      "\n",
      "3.3\n",
      "Local Graph Neural Network\n",
      "\n",
      "\n",
      "\n",
      "GNN’s objective is to ﬁnd new nodes’ embeddings via integrating local neighbors’\n",
      "interactions with individual properties of patches. By exploiting the message\n",
      "passing mechanism, this module iteratively aggregates features from neighbors\n",
      "of each vertex and generates the new node representations. We employ two graph\n",
      "convolution isomorphism operators (GINconv) [30] with the generalized form as:\n",
      "\n",
      "\n",
      "\n",
      "X′\n",
      "n = φ (An + (1 + ϵ).I).Xn) ,\n",
      "(2)\n",
      "\n",
      "\n",
      "\n",
      "where ϵ is a small positive value and I is the identity matrix. Also, φ denotes the\n",
      "weights of two MLP layers. Xn ∈ RM×d and X′\n",
      "n ∈ RM×d are GINconv’s input\n",
      "and output feature matrices for Pn, which Xn equals Zn for the ﬁrst layer.\n",
      "\n",
      "\n",
      "\n",
      "3.4\n",
      "Super-Nodes Extractor\n",
      "\n",
      "\n",
      "\n",
      "In order to ﬁnd the coarse histo-morphological patterns disguised in the local\n",
      "graph, we propose extracting K Super-nodes, which each represents a weighted\n",
      "cluster of further processed local features. Intuitively, the number of super-nodes\n",
      "K should not be very large or small, as the former encourages them to only\n",
      "represent local clusters and the latter leads to larger clusters and loses subtle\n",
      "\n",
      "\n",
      "\n",
      "details. We exploit the minCUT [5] idea to extract super-nodes in a diﬀerentiable\n",
      "process after an auxiliary GINconv to focus more on large-scale interactions and\n",
      "to ﬁnally learn the most global correlated super-nodes. Inspired by the relaxation\n",
      "form of the known K-way minCUT problem, we create a continuous cluster\n",
      "matrix Cn ∈ RM×K using MLP layers and can ﬁnally estimate the super-nodes\n",
      "features (Sn ∈ RM×d) as:\n",
      "\n",
      "\n",
      "\n",
      "Sn = CT\n",
      "n .X′\n",
      "n,\n",
      "Cn = softmax (ReLU(X′\n",
      "n.W1).W2) ,\n",
      "(3)\n",
      "\n",
      "\n",
      "\n",
      "where W1, W2 are MLPs’ weights. Hence, the extracted nodes are directly depen-\n",
      "dent on the ﬁnal survival-speciﬁc loss. In addition, two additional unsupervised\n",
      "weighted regularization terms are optimized to improve the process:\n",
      "\n",
      "\n",
      "\n",
      "MinCut Regularizer. This term is motivated by the original minCUT problem\n",
      "and intends to solve it for the the patients’ graph. It is deﬁned as:\n",
      "\n",
      "\n",
      "\n",
      "RminCUT = −Tr(CT\n",
      "n .An,norm.Cn)\n",
      "\n",
      "\n",
      "\n",
      "Tr(CTn .Dn.Cn)\n",
      ",\n",
      "(4)\n",
      "\n",
      "\n",
      "\n",
      "where Dn is the diagonal degree matrix for An. Also, Tr(.) represents the trace\n",
      "of matrix and An,norm is the normalized adjacency matrix. RminCUT ’s mini-\n",
      "mum value happens when Tr(CT\n",
      "n .An,norm.Cn) equals Tr(CT\n",
      "n .Dg,n.Cn). There-\n",
      "fore, minimizing RminCUT causes assigning strongly similar nodes to a same\n",
      "super-node and prevent their association with others.\n",
      "\n",
      "\n",
      "\n",
      "Orthogonality Regularizer. RminCUT is non-convex and potent to local min-\n",
      "ima such as assigning all vertexes to a super-node or having multiple super-nodes\n",
      "with only a single vertex. Rorthogonal penalizes such solutions and helps the model\n",
      "to distribute the graph’s features between super-nodes. It can be formulated as:\n",
      "\n",
      "\n",
      "\n",
      "Rorthogonal =\n",
      "\u0002\u0002\u0002\u0002\n",
      "\n",
      "\n",
      "\n",
      "\u0002\u0002\u0002\u0002\n",
      "CT\n",
      "n .Cn\n",
      "\n",
      "\n",
      "\n",
      "||CTn .Cn||F\n",
      "−\n",
      "I\n",
      "√\n",
      "\n",
      "\n",
      "\n",
      "K\n",
      "\n",
      "\n",
      "\n",
      "\u0002\u0002\u0002\u0002\n",
      "\n",
      "\n",
      "\n",
      "\u0002\u0002\u0002\u0002\n",
      "F\n",
      ",\n",
      "(5)\n",
      "\n",
      "\n",
      "\n",
      "where ||.||F is the Frobenius norm, and I is the identity matrix. This term pushes\n",
      "the model’s parameters to ﬁnd coarse features that are orthogonal to each other\n",
      "resulting in having the most useful global features.\n",
      "Overall, utilizing these two terms encourages the model to extract super-\n",
      "nodes by leaning more towards the strongly associated vertexes and keeping\n",
      "them against weakly connected ones [5], while the main survival loss still controls\n",
      "the global extraction process.\n",
      "\n",
      "\n",
      "\n",
      "3.5\n",
      "Fine-Coarse Distillation\n",
      "\n",
      "\n",
      "\n",
      "We propose our ﬁne-coarse morphological feature distillation module to leverage\n",
      "all-scale interactions in the ﬁnal prediction by ﬁnding a local and a global patient-\n",
      "level representations (ˆhl,n, ˆhg,n). Assume that X′\n",
      "n ∈ RM×d and Sn ∈ RK×d are\n",
      "the feature matrices taken from local GNN (Sect. 3.3) and super-nodes for Pn,\n",
      "respectively. We explore 3 diﬀerent attention-based feature distillation strategies\n",
      "for this task, including:\n",
      "\n",
      "\n",
      "\n",
      "– Dual Attention (DA): Two gated self-attention modules for local and\n",
      "global properties with separate weights (Wφ,l, Wφ,g, Wk,l, Wk,g, Wq,l, Wq,g)\n",
      "are utilized to ﬁnd patches scores αl ∈ R1×M and αg ∈ R1×K and the ﬁnal\n",
      "features (ˆhl,n, ˆhg,n ) as:\n",
      "\n",
      "\n",
      "\n",
      "ˆhl,n =\n",
      "\n",
      "\n",
      "\n",
      "M\n",
      "\u0002\n",
      "\n",
      "\n",
      "\n",
      "i=1\n",
      "Wφ,lαl,ix′\n",
      "n,i, αl = softmax\n",
      "\u0003\n",
      "Wv,l\n",
      "\u0004\n",
      "tanh(Wq,lX\n",
      "′T\n",
      "n ) · sigm(Wk,lX\n",
      "′T\n",
      "n )\n",
      "\u0005\u0006\n",
      ",\n",
      "\n",
      "\n",
      "\n",
      "(6)\n",
      "\n",
      "\n",
      "\n",
      "ˆhg,n =\n",
      "\n",
      "\n",
      "\n",
      "K\n",
      "\u0002\n",
      "\n",
      "\n",
      "\n",
      "i=1\n",
      "Wφ,gαg,isn,i, αg = softmax\n",
      "\u0003\n",
      "Wv,g\n",
      "\u0004\n",
      "tanh(Wq,gST\n",
      "n ) · sigm(Wk,gST\n",
      "n )\n",
      "\u0005\u0006\n",
      ",\n",
      "\n",
      "\n",
      "\n",
      "(7)\n",
      "where x′\n",
      "n,i and sn,i are rows of X′\n",
      "n and Sn, respectively, and the ﬁnal repre-\n",
      "sentation (ˆh) is generated as ˆh = cat(ˆhl, ˆhg).\n",
      "– Mixed Guided Attention (MGA): In the ﬁrst strategy, the information\n",
      "ﬂows from local and global features to the ﬁnal representations in paral-\n",
      "lel without mixing any knowledge. The purpose of this policy is the heavy\n",
      "fusion of ﬁne and coarse knowledge by exploiting shared weights (Wφ,shared,\n",
      "Wk,shared, Wq,shared, Wv,shared) in both routes and beneﬁting from the guid-\n",
      "ance of local representation on learning the global one by modifying Eq. (7)\n",
      "to:\n",
      "αg = softmax\n",
      "\u0003\n",
      "Wφ,g\n",
      "\u0004\n",
      "tanh(Wq,gST\n",
      "n ˆhl,n) · sigm(Wk,gST\n",
      "n ˆhl,n)\n",
      "\u0005\u0006\n",
      "(8)\n",
      "\n",
      "\n",
      "\n",
      "– Mixed Co-Attention (MCA): While the ﬁrst strategy allows the extreme\n",
      "separation of two paths, the second one has the highest level of mixing infor-\n",
      "mation. Here, we take a balanced policy between the independence and knowl-\n",
      "edge mixture of the two routes by only sharing the weights without using any\n",
      "guidance.\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      "Experiments and Results\n",
      "\n",
      "\n",
      "\n",
      "4.1\n",
      "Dataset\n",
      "\n",
      "\n",
      "\n",
      "We utilize two prostate cancer (PCa) datasets to evaluate the performance of\n",
      "our proposed model. The ﬁrst set (PCa-AS) includes 179 PCa patients who\n",
      "were managed with Active Surveillance (AS). Radical therapy is considered\n",
      "overtreatment in these patients, so they are instead monitored with regular\n",
      "serum prostate-speciﬁc antigen (PSA) measurements, physical examinations,\n",
      "sequential biopsies, and magnetic resonance imaging [23]. However, AS may be\n",
      "over- or under-utilized in low- and intermediate-risk PCa due to the uncertainty\n",
      "of current methods to distinguish indolent from aggressive cancers [11]. Although\n",
      "majority of patients in our cohort are classiﬁed as low-risk based on NCCN guide-\n",
      "lines [21], a signiﬁcant subset of them experienced disease upgrade that triggered\n",
      "deﬁnitive therapy (range: 6.2 to 224 months after diagnosis).\n",
      "The second dataset (PCa-BT) includes 105 PCa patients with low to high\n",
      "risk disease who went through brachytherapy. This treatment involves placing a\n",
      "radioactive material inside the body to safely deliver larger dose of radiation at\n",
      "\n",
      "\n",
      "\n",
      "Table 1. Comparison of our method against baselines and ablation study on policies.\n",
      "\n",
      "\n",
      "\n",
      "Model\n",
      "c-index ↑\n",
      "p-value ↓\n",
      "High ↓ - Low ↑ Median Time Parameters\n",
      "\n",
      "\n",
      "\n",
      "PCa-AS\n",
      "PCa-BT\n",
      "PCa-AS PCa-BT PCa-AS\n",
      "PCa-BT\n",
      "PCa-AS\n",
      "\n",
      "\n",
      "\n",
      "DeepSet\n",
      "0.495 ± 0.017\n",
      "0.50 ± 0.0\n",
      "0.837\n",
      "0.912\n",
      "67.78–71.87\n",
      "24.62–24.89\n",
      "329K\n",
      "\n",
      "\n",
      "\n",
      "AMIL\n",
      "0.544 ± 0.06\n",
      "0.533 ± 0.060\n",
      "0.820\n",
      "0.148\n",
      "48.99–89.10\n",
      "21.86–30.71\n",
      "592K\n",
      "\n",
      "\n",
      "\n",
      "DGC\n",
      "0.522 ± 0.113\n",
      "0.572 ± 0.150\n",
      "0.494\n",
      "0.223\n",
      "47.61–96.66\n",
      "23.44–24.85\n",
      "626K\n",
      "\n",
      "\n",
      "\n",
      "Patch-GCN\n",
      "0.555 ± 0.059\n",
      "0.541 ± 0.118\n",
      "0.630\n",
      "0.981\n",
      "37.72–94.95\n",
      "23.05–25.25\n",
      "1,302K\n",
      "\n",
      "\n",
      "\n",
      "ALL-IN +\n",
      "DA (ours)\n",
      "\n",
      "\n",
      "\n",
      "0.631 ± 0.058\n",
      "0.596 ± 0.062\n",
      "< 0.01\n",
      "< 0.01\n",
      "37.72–115.91\n",
      "21.86–35.77\n",
      "850K\n",
      "\n",
      "\n",
      "\n",
      "ALL-IN +\n",
      "MGA (ours)\n",
      "\n",
      "\n",
      "\n",
      "0.632 ± 0.060\n",
      "0.589 ± 0.074\n",
      "< 0.01\n",
      "< 0.01\n",
      "47.61–101.39\n",
      "21.86–35.77\n",
      "653K\n",
      "\n",
      "\n",
      "\n",
      "ALL-IN +\n",
      "MCA (ours)\n",
      "\n",
      "\n",
      "\n",
      "0.639 ± 0.048 0.600 ± 0.077 < 0.01\n",
      "< 0.01\n",
      "36.5–131.71 21.86–35.77\n",
      "653K\n",
      "\n",
      "\n",
      "\n",
      "one time [25]. The recorded endpoint for this set is biochemical recurrence with\n",
      "time to recurrence ranging from 11.7 to 56.1 months.\n",
      "We also utilized the Prostate cANcer graDe Assessment (PANDA) Challenge\n",
      "dataset [7] that includes more than 10,000 PCa needle biopsy slides (no outcome\n",
      "data) as an external dataset for training the encoder of our model.\n",
      "\n",
      "\n",
      "\n",
      "4.2\n",
      "Experiments\n",
      "\n",
      "\n",
      "\n",
      "We evaluate the models’ performance in two scenarios utilizing several objective\n",
      "metrics. Implementation details are available in supplementary material.\n",
      "\n",
      "\n",
      "\n",
      "Hazard (Risk) Prediction. We utilize concordance-index (c-index) that mea-\n",
      "sures the relative ordering of patients with observed events and un-censored\n",
      "cases relative to censored instances [2]. Using c-index, we compare the quality\n",
      "of hazard ranking against multiple methods including two MIL (DeepSet [31],\n",
      "AMIL [14]) and graph-based (DGC [17] and Patch-GCN [10]) models that were\n",
      "utilized recently for histopathology risk assessment. C-index values are avail-\n",
      "able in Table 1. The proposed model with all strategies outperforms baselines\n",
      "across all sets and is able to achieve 0.639 and 0.600 on PCa-AS and PCa-BT,\n",
      "while the baselines, at best, obtain 0.555, and 0.572, respectively. Statistical tests\n",
      "(paired t-test) on c-indices also show that our model is statistically better than\n",
      "all baselines in PCa-AS and also superior to all models, except DGC, in PCa-BT.\n",
      "Superior performance of our MCA policy implies that balanced exploitation of\n",
      "ﬁne and coarse features with shared weights may provide more robust contex-\n",
      "tual information compared to using mixed guided information or utilizing them\n",
      "independently.\n",
      "\n",
      "\n",
      "\n",
      "Patient Stratiﬁcation. The capacity of stratifying patients into risk groups\n",
      "(e.g., low and high risk) is another criterion that we employ to assess the util-\n",
      "ity of models in clinical practice. We evaluate model performances via Kaplan-\n",
      "Meier curve [15] (cut-oﬀ set as the ratio of patients with recurrence within 3\n",
      "\n",
      "\n",
      "\n",
      "Fig. 2. Kaplan-Meier curves of mixed co-attention model for PCa-AS and PCa-BT.\n",
      "\n",
      "\n",
      "\n",
      "years of therapy initiation for PCa-BT and the ratio of upgraded cases for PCa-\n",
      "AS), LogRank test [6] (with 0.05 as signiﬁcance level), and median outcome\n",
      "associated with risk groups (Table 1 and Fig. 2). Our model stratiﬁed PCa-AS\n",
      "patients into high- and low-risk groups with median time to progression of 36.5\n",
      "and 131.7 months, respectively. Moreover, PCa-BT cases assigned to high- and\n",
      "low-risk groups have median recurrence time of 21.86 and 35.7 months. While\n",
      "none of the baselines are capable of assigning patients into risk groups with\n",
      "statistical signiﬁcance, our distillation policies achieve signiﬁcant separation in\n",
      "both PCa-AS and PCa-BT datasets; suggesting that global histo-morphological\n",
      "properties improve patient stratiﬁcation performance. Furthermore, our ﬁndings\n",
      "have signiﬁcant clinical implications as they identify, for the ﬁrst time, high-\n",
      "risk prostate cancer patients who are otherwise known to be low-risk based on\n",
      "clinico-pathological parameters. This group should be managed diﬀerently from\n",
      "the rest of the low-risk prostate cancer patients in the clinic. Therefore, pro-\n",
      "viding evidence of the predictive (as opposed to prognostic) clinical information\n",
      "that our model provides. While a prognostic biomarker provides information\n",
      "about a patient’s outcome (without speciﬁc recommendation on the next course\n",
      "of action), a predictive biomarker gives insights about the eﬀect of a therapeutic\n",
      "intervention and potential actions that can be taken.\n",
      "\n",
      "\n",
      "\n",
      "Ablation Study. We perform ablation study (Table 2) on various components\n",
      "of our framework including local nodes, self-supervised ViT-based encoder, and\n",
      "most importantly, super-nodes in addition to ﬁne-coarse distillation module.\n",
      "Although our local-only model is still showing superior results compared to\n",
      "baselines, this analysis demonstrates that all modules are essential for learn-\n",
      "ing the most eﬀective representations. We also assess the impact of our ViT on\n",
      "the baselines (full-results in appendix), showing that it can, on average, improve\n",
      "their performance by an increase of ∼ 0.03 in c-index for PCa-AS. However, the\n",
      "best baseline with ViT still has poorer performance compared to our model in\n",
      "both datasets, while the number of parameters (reported for ViT embeddings’\n",
      "size in Table 1) in our full-model is about half of this baseline. Achieving higher\n",
      "c-indices in our all model versions indicates the important role of coarse features\n",
      "and global context in patient risk estimation in addition to local patterns.\n",
      "\n",
      "\n",
      "\n",
      "Table 2. Ablation study on diﬀerent modules.\n",
      "\n",
      "\n",
      "\n",
      "Modules\n",
      "c-index ↑\n",
      "\n",
      "\n",
      "\n",
      "Model\n",
      "Local-node our KDM-\n",
      "ViT\n",
      "\n",
      "\n",
      "\n",
      "Super-node\n",
      "+ Distillation\n",
      "Model\n",
      "\n",
      "\n",
      "\n",
      "PCa-AS\n",
      "PCa-BT\n",
      "\n",
      "\n",
      "\n",
      "Patch-GCN ✓\n",
      "✓\n",
      "✗\n",
      "0.627 ± 0.046\n",
      "0.588 ± 0.067\n",
      "\n",
      "\n",
      "\n",
      "Ours\n",
      "✓\n",
      "✗\n",
      "✗\n",
      "0.584 ± 0.072\n",
      "0.550 ± 0.109\n",
      "\n",
      "\n",
      "\n",
      "✓\n",
      "✓\n",
      "✗\n",
      "0.622 ± 0.055\n",
      "0.597 ± 0.045\n",
      "\n",
      "\n",
      "\n",
      "✓\n",
      "✓\n",
      "✓\n",
      "0.639 ± 0.048 0.600 ± 0.077\n",
      "\n",
      "\n",
      "\n",
      "5\n",
      "Conclusion\n",
      "\n",
      "\n",
      "\n",
      "While risk assessment is relatively under-explored, most existing methods are\n",
      "focused only on small ﬁelds of view. In this work, we introduce a novel graph-\n",
      "based model for integrating global and local features, which utilizes interactions\n",
      "at a larger scale for improved risk stratiﬁcation. Using two cancer datasets, we\n",
      "evaluated the eﬀectiveness of our model against the baseline methods for hazard\n",
      "prediction and patients stratiﬁcation. Our results suggest that the proposed\n",
      "model outperforms them in risk assessment and is capable of separating patients\n",
      "into statistically signiﬁcant risk groups with actionable clinical utility. The full\n",
      "capacity of this work can be revealed by extending it to other histology tasks.\n",
      "\n",
      "\n",
      "\n",
      "Acknowledgment:. This work was supported by a Canadian Institutes of Health\n",
      "Research grant to AB, PB, and LG and Michael Smith Health Research BC Scholar\n",
      "grant to AB.\n",
      "\n",
      "\n",
      "\n",
      "References\n",
      "\n",
      "\n",
      "\n",
      "1. Abu-Rustum, N.R., et al.: The revised 2009 ﬁgo staging system for endometrial\n",
      "cancer: should the 1988 ﬁgo stages ia and ib be altered? Int. J. Gynecol. Cancer\n",
      "21(3) (2011)\n",
      "2. Alabdallah, A., Ohlsson, M., Pashami, S., R¨ognvaldsson, T.: The concordance\n",
      "index decomposition-a measure for a deeper understanding of survival prediction\n",
      "models. arXiv preprint arXiv:2203.00144 (2022)\n",
      "3. Alon, U., Yahav, E.: On the bottleneck of graph neural networks and its practical\n",
      "implications. arXiv preprint arXiv:2006.05205 (2020)\n",
      "4. Angell, H., Galon, J.: From the immune contexture to the immunoscore: the role of\n",
      "prognostic and predictive immune markers in cancer. Curr. Opin. Immunol. 25(2),\n",
      "261–267 (2013)\n",
      "5. Bianchi, F.M., Grattarola, D., Alippi, C.: Spectral clustering with graph neural\n",
      "networks for graph pooling. In: International Conference on Machine Learning,\n",
      "pp. 874–883. PMLR (2020)\n",
      "6. Bland, J.M., Altman, D.G.: The logrank test. BMJ 328(7447), 1073 (2004)\n",
      "7. Bulten, W., et al.: Artiﬁcial intelligence for diagnosis and gleason grading of\n",
      "prostate cancer: the panda challenge. Nat. Med. 28(1), 154–163 (2022)\n",
      "\n",
      "\n",
      "\n",
      "8. Carbonneau, M.A., Cheplygina, V., Granger, E., Gagnon, G.: Multiple instance\n",
      "learning: a survey of problem characteristics and applications. Pattern Recogn.\n",
      "77, 329–353 (2018)\n",
      "9. Caron, M., Touvron, H., Misra, I., J´egou, H., Mairal, J., Bojanowski, P., Joulin, A.:\n",
      "Emerging properties in self-supervised vision transformers. In: Proceedings of the\n",
      "IEEE/CVF International Conference on Computer Vision, pp. 9650–9660 (2021)\n",
      "10. Chen, R.J., et al.: Whole slide images are 2D point clouds: context-aware survival\n",
      "prediction using patch-based graph convolutional networks. In: de Bruijne, M.,\n",
      "et al. (eds.) MICCAI 2021. LNCS, vol. 12908, pp. 339–349. Springer, Cham (2021).\n",
      "https://doi.org/10.1007/978-3-030-87237-3 33\n",
      "\n",
      "\n",
      "\n",
      "11. Cooperberg,\n",
      "M.R.,\n",
      "et\n",
      "al.:\n",
      "Outcomes\n",
      "of\n",
      "active\n",
      "surveillance\n",
      "for\n",
      "men\n",
      "with\n",
      "intermediate-risk prostate cancer. J. Clin. Oncol. Oﬀ. J. Am. Soc. Clin. Oncol.\n",
      "29(2), 228–234 (2011)\n",
      "12. Darbandsari, A., et al.: Identiﬁcation of a novel subtype of endometrial cancer\n",
      "with unfavorable outcome using artiﬁcial intelligence-based histopathology image\n",
      "analysis (2022)\n",
      "13. Dosovitskiy, A., et al.: An image is worth 16×16 words: transformers for image\n",
      "recognition at scale. arXiv preprint arXiv:2010.11929 (2020)\n",
      "14. Ilse, M., Tomczak, J., Welling, M.: Attention-based deep multiple instance learning.\n",
      "In: International Conference on Machine Learning, pp. 2127–2136. PMLR (2018)\n",
      "15. Kaplan, E.L., Meier, P.: Nonparametric estimation from incomplete observations.\n",
      "J. Am. Stat. Assoc. 53(282), 457–481 (1958)\n",
      "16. Lee, Y., et al.: Derivation of prognostic contextual histopathological features from\n",
      "whole-slide images of tumours via graph deep learning. Nat. Biomed. Eng., 1–15\n",
      "(2022)\n",
      "17. Li, R., Yao, J., Zhu, X., Li, Y., Huang, J.: Graph CNN for survival analysis on\n",
      "whole slide pathological images. In: Frangi, A.F., Schnabel, J.A., Davatzikos, C.,\n",
      "Alberola-L´opez, C., Fichtinger, G. (eds.) MICCAI 2018. LNCS, vol. 11071, pp.\n",
      "174–182. Springer, Cham (2018). https://doi.org/10.1007/978-3-030-00934-2 20\n",
      "\n",
      "\n",
      "\n",
      "18. Liu, W., He, Q., He, X.: Weakly supervised nuclei segmentation via instance learn-\n",
      "ing. In: 2022 IEEE 19th International Symposium on Biomedical Imaging (ISBI),\n",
      "pp. 1–5. IEEE (2022)\n",
      "19. Lu, M.Y., Williamson, D.F., Chen, T.Y., Chen, R.J., Barbieri, M., Mahmood,\n",
      "F.: Data-eﬃcient and weakly supervised computational pathology on whole-slide\n",
      "images. Nat. Biomed. Eng. 5(6), 555–570 (2021)\n",
      "20. Mobadersany, P., et al.: Predicting cancer outcomes from histology and genomics\n",
      "using convolutional networks. Proc. Natl. Acad. Sci. 115(13), E2970–E2979 (2018)\n",
      "21. Moses, K.A., et al.: Nccn guidelines R\n",
      "⃝ insights: prostate cancer early detection, ver-\n",
      "sion 1.2023: featured updates to the nccn guidelines. J. Natl. Comprehens. Cancer\n",
      "Netw. 21(3), 236–246 (2023)\n",
      "22. Oono, K., Suzuki, T.: Graph neural networks exponentially lose expressive power\n",
      "for node classiﬁcation. arXiv preprint arXiv:1905.10947 (2019)\n",
      "23. Ouzzane, A., et al.: Magnetic resonance imaging targeted biopsy improves selection\n",
      "of patients considered for active surveillance for clinically low risk prostate cancer\n",
      "based on systematic biopsies. J. Urol. 194(2), 350–356 (2015)\n",
      "24. Rony, J., Belharbi, S., Dolz, J., Ayed, I.B., McCaﬀrey, L., Granger, E.: Deep\n",
      "weakly-supervised learning methods for classiﬁcation and localization in histology\n",
      "images: a survey. arXiv preprint arXiv:1909.03354 (2019)\n",
      "25. Skowronek, J.: Current status of brachytherapy in cancer treatment-short overview.\n",
      "J. Contemp. Brachyther. 9(6), 581–589 (2017)\n",
      "\n",
      "\n",
      "\n",
      "26. Son, B., Lee, S., Youn, H., Kim, E., Kim, W., Youn, B.: The role of tumor microen-\n",
      "vironment in therapeutic resistance. Oncotarget 8(3), 3933 (2017)\n",
      "27. Srinidhi, C.L., Ciga, O., Martel, A.L.: Deep neural network models for computa-\n",
      "tional histopathology: a survey. Med. Image Anal. 67, 101813 (2021)\n",
      "28. Tang, S., Chen, D., Bai, L., Liu, K., Ge, Y., Ouyang, W.: Mutual crf-gnn for few-\n",
      "shot learning. In: Proceedings of the IEEE/CVF Conference on Computer Vision\n",
      "and Pattern Recognition, pp. 2329–2339 (2021)\n",
      "29. Wetstein, S.C., et al.: Deep learning-based breast cancer grading and survival anal-\n",
      "ysis on whole-slide histopathology images. Sci. Rep. 12(1), 1–12 (2022)\n",
      "30. Xu, K., Hu, W., Leskovec, J., Jegelka, S.: How powerful are graph neural networks?\n",
      "arXiv preprint arXiv:1810.00826 (2018)\n",
      "31. Zaheer, M., Kottur, S., Ravanbakhsh, S., Poczos, B., Salakhutdinov, R.R., Smola,\n",
      "A.J.: Deep sets. Adv. Neural Inf. Process. Syst. 30, 1–11 (2017)\n",
      "32. Zhu, X., Yao, J., Zhu, F., Huang, J.: Wsisa: making survival prediction from whole\n",
      "slide histopathological images. In: Proceedings of the IEEE Conference on Com-\n",
      "puter Vision and Pattern Recognition, pp. 7234–7242 (2017)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for page in doc:\n",
    "    output = page.get_text(\"blocks\")                   \n",
    "    previous_block_id = 0 # Set a variable to mark the block id\n",
    "    for block in output:\n",
    "        if block[6] == 0: # We only take the text\n",
    "            if previous_block_id != block[5]: # Compare the block number \n",
    "                print(\"\\n\")\n",
    "                print(block[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install Unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL-IN: A Local GLobal Graph-Based\n",
      "DIstillatioN Model for Representation\n",
      "Learning of Gigapixel Histopathology\n",
      "Images With Application In Cancer Risk\n",
      "Assessment\n",
      "\n",
      "\n",
      "\n",
      "Puria Azadi1, Jonathan Suderman1, Ramin Nakhli1, Katherine Rich1,\n",
      "Maryam Asadi1, Sonia Kung2, Htoo Oo2, Mira Keyes1, Hossein Farahani1,\n",
      "Calum MacAulay3, Larry Goldenberg2, Peter Black2, and Ali Bashashati1(B)\n",
      "\n",
      "\n",
      "\n",
      "1 University of British Columbia, Vancouver, BC, Canada\n",
      "ali.bashashati@ubc.ca\n",
      "2 Vancouver Prostate Centre, Vancouver, BC, Canada\n",
      "3 BC Cancer Agency, Vancouver, BC, Canada\n",
      "\n",
      "\n",
      "\n",
      "Abstract. The utility of machine learning models in histopathology\n",
      "image analysis for disease diagnosis has been extensively studied. How-\n",
      "ever, efforts to stratify patient risk are relatively under-explored. While\n",
      "most current techniques utilize small fields of view (so-called local fea-\n",
      "tures) to link histopathology images to patient outcome, in this work we\n",
      "investigate the combination of global (i.e., contextual) and local features\n",
      "in a graph-based neural network for patient risk stratification. The pro-\n",
      "posed network not only combines both fine and coarse histological pat-\n",
      "terns but also utilizes their interactions for improved risk stratification.\n",
      "We compared the performance of our proposed model against the state-\n",
      "of-the-art (SOTA) techniques in histopathology risk stratification in two\n",
      "cancer datasets. Our results suggest that the proposed model is capable\n",
      "of stratifying patients into statistically significant risk groups (p < 0.01\n",
      "across the two datasets) with clinical utility while competing models fail\n",
      "to achieve a statistical significance endpoint (p = 0.148 - 0.494).\n",
      "\n",
      "\n",
      "\n",
      "Keywords: Histopathology * Risk Assessment * Graph Processing\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Introduction\n",
      "\n",
      "\n",
      "\n",
      "The examination of tissue and cells using microscope (referred to as histology)\n",
      "has been a key component of cancer diagnosis and prognostication since more\n",
      "than a hundred years ago. Histological features allow visual readout of cancer\n",
      "biology as they represent the overall impact of genetic changes on cells [20].\n",
      "The great rise of deep learning in the past decade and our ability to digitize\n",
      "histopathology slides using high-throughput slide scanners have fueled inter-\n",
      "ests in the applications of deep learning in histopathology image analysis. The\n",
      "\n",
      "\n",
      "\n",
      "Supplementary Information The online version contains supplementary material\n",
      "available at https://doi.org/10.1007/978-3-031-43987-2 74.\n",
      "\n",
      "\n",
      "\n",
      "c\n",
      " The Author(s), under exclusive license to Springer Nature Switzerland AG 2023\n",
      "H. Greenspan et al. (Eds.): MICCAI 2023, LNCS 14225, pp. 765-775, 2023.\n",
      "https://doi.org/10.1007/978-3-031-43987-2_74\n",
      "\n",
      "766\n",
      "P. Azadi et al.\n",
      "\n",
      "\n",
      "\n",
      "majority of the efforts, so far, focus on the deployment of these models for diag-\n",
      "nosis and classification [27]. As such, there is a paucity of efforts that embark\n",
      "on utilizing machine learning models for patient prognostication and survival\n",
      "analysis (for example, predicting risk of cancer recurrence or expected patient\n",
      "survival). While prognostication and survival analysis offer invaluable insights\n",
      "for patient management, biological studies and drug development efforts, they\n",
      "require careful tracking of patients for a lengthy period of time; rendering this\n",
      "as a task that requires a significant amount of effort and funding.\n",
      "In the machine learning domain, patient prognostication can be treated as a\n",
      "weakly supervised problem, which a model would predict the outcome (e.g., time\n",
      "to cancer recurrence) based on the histopathology images. Their majority have\n",
      "utilized Multiple Instance Learning (MIL) [8] that is a two-step learning method.\n",
      "First, representation maps for a set of patches (i.e., small fields of view), called\n",
      "a bag of instances, are extracted. Then, a second pooling model is applied to the\n",
      "feature maps for the final prediction. Different MIL variations have shown supe-\n",
      "rior performances in grading or subtype classification in comparison to outcome\n",
      "prediction [10]. This is perhaps due to the fact that MIL-based technique do\n",
      "not incorporate patch locations and interactions as well as tissue heterogeneity\n",
      "which can potentially have a vital role in defining clinical outcomes [4,26].\n",
      "To address this issue, graph neural networks (GNN) have recently received\n",
      "more attention in histology. They can model patch relations [17] by utilizing mes-\n",
      "sage passing mechanism via edges connecting the nodes (i.e., small patches in our\n",
      "case). However, most GNN-based models suffer from over smoothing [22] which\n",
      "limits nodes' receptive fields [3]. While local contexts mainly capture cell-cell\n",
      "interactions, global patterns such as immune cell infiltration patterns and tumor\n",
      "invasion in normal tissue structures (e.g., depth of invasion through myometrium\n",
      "in endometrial cancer [1]) could capture critical information about outcome [10].\n",
      "Hence, locally focused methods are unable to benefit from the coarse properties\n",
      "of slides due to their high dimensions which may lead to poor performance.\n",
      "This paper aims to investigate the potential of extracting fine and coarse\n",
      "features from histopathology slides and integrating them for risk stratification\n",
      "in cancer patients. Therefore, the contributions of this work can be summarized\n",
      "as: 1) a novel graph-based model for predicting survival that extracts both local\n",
      "and global properties by identifying morphological super-nodes; 2) introducing\n",
      "a fine-coarse feature distillation module with 3 various strategies to aggregate\n",
      "interactions at different scales; 3) outperforming SOTA approaches in both risk\n",
      "prediction and patient stratification scenarios on two datasets; 4) publishing\n",
      "two large and rare prostate cancer datasets containing more than 220 graphs for\n",
      "active surveillance and 240 graphs for brachytherapy cases. The code and graph\n",
      "embeddings are publicly available at https://github.com/pazadimo/ALL-IN\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "Related Works\n",
      "\n",
      "\n",
      "\n",
      "2.1\n",
      "Weakly Supervised Learning in Histopathology\n",
      "\n",
      "\n",
      "\n",
      "Utilizing Weakly Supervised Learning for modeling histopathology problems has\n",
      "been getting popular due to the high resolution of slides and substantial time\n",
      "\n",
      "ALL-IN\n",
      "767\n",
      "\n",
      "\n",
      "\n",
      "and financial costs associated with annotating them as well as the development\n",
      "of powerful deep discriminative models in the recent years [24].\n",
      "Such models are used to perform nuclei segmentation [18], identify novel\n",
      "subtypes [12], or later descendants are even able to pinpoint sub-areas with a\n",
      "high diagnostic value [19].\n",
      "\n",
      "\n",
      "\n",
      "2.2\n",
      "Survival Analysis and GNNs in Histopathology\n",
      "\n",
      "\n",
      "\n",
      "MIL-based models have been utilized for outcome prediction [29,32] which can\n",
      "also be integrated with attention-based variants [14]. GNNs due to their struc-\n",
      "tural preserving capacity [28] have drawn attention in various histology domains\n",
      "by constructing the graph on cells or patches. However, current GNN-based risk\n",
      "assessment variants are only focused on short-range interactions [16,17] or con-\n",
      "sider local contexts [10]. We hypothesize that graph-based models' performance\n",
      "in survival prediction improves by leveraging both fine and coarse properties.\n",
      "\n",
      "\n",
      "\n",
      "3\n",
      "Method\n",
      "\n",
      "\n",
      "\n",
      "Figure 1 summarizes our proposed end-to-end solution. Below, we have provided\n",
      "details of each module.\n",
      "\n",
      "\n",
      "\n",
      "3.1\n",
      "Problem Formulation\n",
      "\n",
      "\n",
      "\n",
      "For Pn, which is the n-th patient, a set of patches {patchj}M\n",
      "j=1 is extracted\n",
      "from the related whole slide images. In addition, a latent vector zj  R1xd is\n",
      "extracted from patchj using our encoder network (described in Sect. 3.2) that\n",
      "results in feature matrix Zn  RMxd for Pn. Finally, a specific graph (Gn) for\n",
      "the n-th patient (Pn) can be constructed by assuming patches as nodes. Also,\n",
      "edges are connected based on the patches' k-nearest neighbour in the spatial\n",
      "domain resulting in an adjacency matrix An. Therefore, for each patient such\n",
      "as Pn, we have a graph defined by adjacency matrix An with size M x M and\n",
      "features matrix Zn (Gn = graph(Zn, An)). We estimate K super-nodes as matrix\n",
      "Sn  RKxd representing groups of local nodes with similar properties as coarse\n",
      "features for Pn's slides. The final model (th) with parameters th utilizes Gn and\n",
      "Sn to predict the risk associated with this patient:\n",
      "\n",
      "\n",
      "\n",
      "riskn = th(Gn, Sn) = th(graph(Xn, An), Sn)\n",
      "(1)\n",
      "\n",
      "\n",
      "\n",
      "3.2\n",
      "Self-supervised Encoder\n",
      "\n",
      "\n",
      "\n",
      "Due to computational limits and large number of patches available for each\n",
      "patient, we utilize a self-supervised approach to train an encoder to reduce\n",
      "the inputs' feature space size. Therefore, We use DINO [9], a knowledge dis-\n",
      "tillation model (KDM), with vision transformer (ViT) [13] as the backbone. It\n",
      "utilizes global and local augmentations of the input patchj and passes them\n",
      "to the student (Sth1,V iT ) and teacher (Tth2,V iT ) models to find their respective\n",
      "\n",
      "768\n",
      "P. Azadi et al.\n",
      "\n",
      "\n",
      "\n",
      "Fig. 1. The overview of our proposed method. a) The input slide is tiled into non-\n",
      "overlapping patches. b) The patches are fed into a self-supervised encoder to extract\n",
      "embeddings. c) A graph is constructed and the new local instance-level embeddings\n",
      "are obtained through the message-passing process. d) The global context representa-\n",
      "tions in the form of super-nodes are extracted utilizing two unsupervised loss functions\n",
      "(RminCUT , Rorthognal). e) The fine and coarse feature vectors are aggregated in the\n",
      "distillation module to obtain a representation that accounts for both local and global\n",
      "(contextual) histo-morphological features. Three different strategies (S1, S2, S3) are\n",
      "explored in this module. Finally, a Multilayer Perceptron (MLP) is deployed to esti-\n",
      "mate the risk using final resultant vectors.\n",
      "\n",
      "\n",
      "\n",
      "representations without any labels. Then, by using distillation loss, it makes the\n",
      "representations' distribution similar to each other. Finally, the fixed weights of\n",
      "the teacher model are utilized in order to encode the input patches.\n",
      "\n",
      "\n",
      "\n",
      "3.3\n",
      "Local Graph Neural Network\n",
      "\n",
      "\n",
      "\n",
      "GNN's objective is to find new nodes' embeddings via integrating local neighbors'\n",
      "interactions with individual properties of patches. By exploiting the message\n",
      "passing mechanism, this module iteratively aggregates features from neighbors\n",
      "of each vertex and generates the new node representations. We employ two graph\n",
      "convolution isomorphism operators (GINconv) [30] with the generalized form as:\n",
      "\n",
      "\n",
      "\n",
      "X'\n",
      "n = ph (An + (1 + ).I).Xn) ,\n",
      "(2)\n",
      "\n",
      "\n",
      "\n",
      "where  is a small positive value and I is the identity matrix. Also, ph denotes the\n",
      "weights of two MLP layers. Xn  RMxd and X'\n",
      "n  RMxd are GINconv's input\n",
      "and output feature matrices for Pn, which Xn equals Zn for the first layer.\n",
      "\n",
      "\n",
      "\n",
      "3.4\n",
      "Super-Nodes Extractor\n",
      "\n",
      "\n",
      "\n",
      "In order to find the coarse histo-morphological patterns disguised in the local\n",
      "graph, we propose extracting K Super-nodes, which each represents a weighted\n",
      "cluster of further processed local features. Intuitively, the number of super-nodes\n",
      "K should not be very large or small, as the former encourages them to only\n",
      "represent local clusters and the latter leads to larger clusters and loses subtle\n",
      "\n",
      "ALL-IN\n",
      "769\n",
      "\n",
      "\n",
      "\n",
      "details. We exploit the minCUT [5] idea to extract super-nodes in a differentiable\n",
      "process after an auxiliary GINconv to focus more on large-scale interactions and\n",
      "to finally learn the most global correlated super-nodes. Inspired by the relaxation\n",
      "form of the known K-way minCUT problem, we create a continuous cluster\n",
      "matrix Cn  RMxK using MLP layers and can finally estimate the super-nodes\n",
      "features (Sn  RMxd) as:\n",
      "\n",
      "\n",
      "\n",
      "Sn = CT\n",
      "n .X'\n",
      "n,\n",
      "Cn = softmax (ReLU(X'\n",
      "n.W1).W2) ,\n",
      "(3)\n",
      "\n",
      "\n",
      "\n",
      "where W1, W2 are MLPs' weights. Hence, the extracted nodes are directly depen-\n",
      "dent on the final survival-specific loss. In addition, two additional unsupervised\n",
      "weighted regularization terms are optimized to improve the process:\n",
      "\n",
      "\n",
      "\n",
      "MinCut Regularizer. This term is motivated by the original minCUT problem\n",
      "and intends to solve it for the the patients' graph. It is defined as:\n",
      "\n",
      "\n",
      "\n",
      "RminCUT = -Tr(CT\n",
      "n .An,norm.Cn)\n",
      "\n",
      "\n",
      "\n",
      "Tr(CTn .Dn.Cn)\n",
      ",\n",
      "(4)\n",
      "\n",
      "\n",
      "\n",
      "where Dn is the diagonal degree matrix for An. Also, Tr(.) represents the trace\n",
      "of matrix and An,norm is the normalized adjacency matrix. RminCUT 's mini-\n",
      "mum value happens when Tr(CT\n",
      "n .An,norm.Cn) equals Tr(CT\n",
      "n .Dg,n.Cn). There-\n",
      "fore, minimizing RminCUT causes assigning strongly similar nodes to a same\n",
      "super-node and prevent their association with others.\n",
      "\n",
      "\n",
      "\n",
      "Orthogonality Regularizer. RminCUT is non-convex and potent to local min-\n",
      "ima such as assigning all vertexes to a super-node or having multiple super-nodes\n",
      "with only a single vertex. Rorthogonal penalizes such solutions and helps the model\n",
      "to distribute the graph's features between super-nodes. It can be formulated as:\n",
      "\n",
      "\n",
      "\n",
      "Rorthogonal =\n",
      "\u0002\u0002\u0002\u0002\n",
      "\n",
      "\n",
      "\n",
      "\u0002\u0002\u0002\u0002\n",
      "CT\n",
      "n .Cn\n",
      "\n",
      "\n",
      "\n",
      "||CTn .Cn||F\n",
      "-\n",
      "I\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "K\n",
      "\n",
      "\n",
      "\n",
      "\u0002\u0002\u0002\u0002\n",
      "\n",
      "\n",
      "\n",
      "\u0002\u0002\u0002\u0002\n",
      "F\n",
      ",\n",
      "(5)\n",
      "\n",
      "\n",
      "\n",
      "where ||.||F is the Frobenius norm, and I is the identity matrix. This term pushes\n",
      "the model's parameters to find coarse features that are orthogonal to each other\n",
      "resulting in having the most useful global features.\n",
      "Overall, utilizing these two terms encourages the model to extract super-\n",
      "nodes by leaning more towards the strongly associated vertexes and keeping\n",
      "them against weakly connected ones [5], while the main survival loss still controls\n",
      "the global extraction process.\n",
      "\n",
      "\n",
      "\n",
      "3.5\n",
      "Fine-Coarse Distillation\n",
      "\n",
      "\n",
      "\n",
      "We propose our fine-coarse morphological feature distillation module to leverage\n",
      "all-scale interactions in the final prediction by finding a local and a global patient-\n",
      "level representations (^hl,n, ^hg,n). Assume that X'\n",
      "n  RMxd and Sn  RKxd are\n",
      "the feature matrices taken from local GNN (Sect. 3.3) and super-nodes for Pn,\n",
      "respectively. We explore 3 different attention-based feature distillation strategies\n",
      "for this task, including:\n",
      "\n",
      "770\n",
      "P. Azadi et al.\n",
      "\n",
      "\n",
      "\n",
      "- Dual Attention (DA): Two gated self-attention modules for local and\n",
      "global properties with separate weights (Wph,l, Wph,g, Wk,l, Wk,g, Wq,l, Wq,g)\n",
      "are utilized to find patches scores al  R1xM and ag  R1xK and the final\n",
      "features (^hl,n, ^hg,n ) as:\n",
      "\n",
      "\n",
      "\n",
      "^hl,n =\n",
      "\n",
      "\n",
      "\n",
      "M\n",
      "\u0002\n",
      "\n",
      "\n",
      "\n",
      "i=1\n",
      "Wph,lal,ix'\n",
      "n,i, al = softmax\n",
      "\u0003\n",
      "Wv,l\n",
      "\u0004\n",
      "tanh(Wq,lX\n",
      "'T\n",
      "n ) * sigm(Wk,lX\n",
      "'T\n",
      "n )\n",
      "\u0005\u0006\n",
      ",\n",
      "\n",
      "\n",
      "\n",
      "(6)\n",
      "\n",
      "\n",
      "\n",
      "^hg,n =\n",
      "\n",
      "\n",
      "\n",
      "K\n",
      "\u0002\n",
      "\n",
      "\n",
      "\n",
      "i=1\n",
      "Wph,gag,isn,i, ag = softmax\n",
      "\u0003\n",
      "Wv,g\n",
      "\u0004\n",
      "tanh(Wq,gST\n",
      "n ) * sigm(Wk,gST\n",
      "n )\n",
      "\u0005\u0006\n",
      ",\n",
      "\n",
      "\n",
      "\n",
      "(7)\n",
      "where x'\n",
      "n,i and sn,i are rows of X'\n",
      "n and Sn, respectively, and the final repre-\n",
      "sentation (^h) is generated as ^h = cat(^hl, ^hg).\n",
      "- Mixed Guided Attention (MGA): In the first strategy, the information\n",
      "flows from local and global features to the final representations in paral-\n",
      "lel without mixing any knowledge. The purpose of this policy is the heavy\n",
      "fusion of fine and coarse knowledge by exploiting shared weights (Wph,shared,\n",
      "Wk,shared, Wq,shared, Wv,shared) in both routes and benefiting from the guid-\n",
      "ance of local representation on learning the global one by modifying Eq. (7)\n",
      "to:\n",
      "ag = softmax\n",
      "\u0003\n",
      "Wph,g\n",
      "\u0004\n",
      "tanh(Wq,gST\n",
      "n ^hl,n) * sigm(Wk,gST\n",
      "n ^hl,n)\n",
      "\u0005\u0006\n",
      "(8)\n",
      "\n",
      "\n",
      "\n",
      "- Mixed Co-Attention (MCA): While the first strategy allows the extreme\n",
      "separation of two paths, the second one has the highest level of mixing infor-\n",
      "mation. Here, we take a balanced policy between the independence and knowl-\n",
      "edge mixture of the two routes by only sharing the weights without using any\n",
      "guidance.\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      "Experiments and Results\n",
      "\n",
      "\n",
      "\n",
      "4.1\n",
      "Dataset\n",
      "\n",
      "\n",
      "\n",
      "We utilize two prostate cancer (PCa) datasets to evaluate the performance of\n",
      "our proposed model. The first set (PCa-AS) includes 179 PCa patients who\n",
      "were managed with Active Surveillance (AS). Radical therapy is considered\n",
      "overtreatment in these patients, so they are instead monitored with regular\n",
      "serum prostate-specific antigen (PSA) measurements, physical examinations,\n",
      "sequential biopsies, and magnetic resonance imaging [23]. However, AS may be\n",
      "over- or under-utilized in low- and intermediate-risk PCa due to the uncertainty\n",
      "of current methods to distinguish indolent from aggressive cancers [11]. Although\n",
      "majority of patients in our cohort are classified as low-risk based on NCCN guide-\n",
      "lines [21], a significant subset of them experienced disease upgrade that triggered\n",
      "definitive therapy (range: 6.2 to 224 months after diagnosis).\n",
      "The second dataset (PCa-BT) includes 105 PCa patients with low to high\n",
      "risk disease who went through brachytherapy. This treatment involves placing a\n",
      "radioactive material inside the body to safely deliver larger dose of radiation at\n",
      "\n",
      "ALL-IN\n",
      "771\n",
      "\n",
      "\n",
      "\n",
      "Table 1. Comparison of our method against baselines and ablation study on policies.\n",
      "\n",
      "\n",
      "\n",
      "Model\n",
      "c-index |\n",
      "p-value |\n",
      "High | - Low | Median Time Parameters\n",
      "\n",
      "\n",
      "\n",
      "PCa-AS\n",
      "PCa-BT\n",
      "PCa-AS PCa-BT PCa-AS\n",
      "PCa-BT\n",
      "PCa-AS\n",
      "\n",
      "\n",
      "\n",
      "DeepSet\n",
      "0.495 +- 0.017\n",
      "0.50 +- 0.0\n",
      "0.837\n",
      "0.912\n",
      "67.78-71.87\n",
      "24.62-24.89\n",
      "329K\n",
      "\n",
      "\n",
      "\n",
      "AMIL\n",
      "0.544 +- 0.06\n",
      "0.533 +- 0.060\n",
      "0.820\n",
      "0.148\n",
      "48.99-89.10\n",
      "21.86-30.71\n",
      "592K\n",
      "\n",
      "\n",
      "\n",
      "DGC\n",
      "0.522 +- 0.113\n",
      "0.572 +- 0.150\n",
      "0.494\n",
      "0.223\n",
      "47.61-96.66\n",
      "23.44-24.85\n",
      "626K\n",
      "\n",
      "\n",
      "\n",
      "Patch-GCN\n",
      "0.555 +- 0.059\n",
      "0.541 +- 0.118\n",
      "0.630\n",
      "0.981\n",
      "37.72-94.95\n",
      "23.05-25.25\n",
      "1,302K\n",
      "\n",
      "\n",
      "\n",
      "ALL-IN +\n",
      "DA (ours)\n",
      "\n",
      "\n",
      "\n",
      "0.631 +- 0.058\n",
      "0.596 +- 0.062\n",
      "< 0.01\n",
      "< 0.01\n",
      "37.72-115.91\n",
      "21.86-35.77\n",
      "850K\n",
      "\n",
      "\n",
      "\n",
      "ALL-IN +\n",
      "MGA (ours)\n",
      "\n",
      "\n",
      "\n",
      "0.632 +- 0.060\n",
      "0.589 +- 0.074\n",
      "< 0.01\n",
      "< 0.01\n",
      "47.61-101.39\n",
      "21.86-35.77\n",
      "653K\n",
      "\n",
      "\n",
      "\n",
      "ALL-IN +\n",
      "MCA (ours)\n",
      "\n",
      "\n",
      "\n",
      "0.639 +- 0.048 0.600 +- 0.077 < 0.01\n",
      "< 0.01\n",
      "36.5-131.71 21.86-35.77\n",
      "653K\n",
      "\n",
      "\n",
      "\n",
      "one time [25]. The recorded endpoint for this set is biochemical recurrence with\n",
      "time to recurrence ranging from 11.7 to 56.1 months.\n",
      "We also utilized the Prostate cANcer graDe Assessment (PANDA) Challenge\n",
      "dataset [7] that includes more than 10,000 PCa needle biopsy slides (no outcome\n",
      "data) as an external dataset for training the encoder of our model.\n",
      "\n",
      "\n",
      "\n",
      "4.2\n",
      "Experiments\n",
      "\n",
      "\n",
      "\n",
      "We evaluate the models' performance in two scenarios utilizing several objective\n",
      "metrics. Implementation details are available in supplementary material.\n",
      "\n",
      "\n",
      "\n",
      "Hazard (Risk) Prediction. We utilize concordance-index (c-index) that mea-\n",
      "sures the relative ordering of patients with observed events and un-censored\n",
      "cases relative to censored instances [2]. Using c-index, we compare the quality\n",
      "of hazard ranking against multiple methods including two MIL (DeepSet [31],\n",
      "AMIL [14]) and graph-based (DGC [17] and Patch-GCN [10]) models that were\n",
      "utilized recently for histopathology risk assessment. C-index values are avail-\n",
      "able in Table 1. The proposed model with all strategies outperforms baselines\n",
      "across all sets and is able to achieve 0.639 and 0.600 on PCa-AS and PCa-BT,\n",
      "while the baselines, at best, obtain 0.555, and 0.572, respectively. Statistical tests\n",
      "(paired t-test) on c-indices also show that our model is statistically better than\n",
      "all baselines in PCa-AS and also superior to all models, except DGC, in PCa-BT.\n",
      "Superior performance of our MCA policy implies that balanced exploitation of\n",
      "fine and coarse features with shared weights may provide more robust contex-\n",
      "tual information compared to using mixed guided information or utilizing them\n",
      "independently.\n",
      "\n",
      "\n",
      "\n",
      "Patient Stratification. The capacity of stratifying patients into risk groups\n",
      "(e.g., low and high risk) is another criterion that we employ to assess the util-\n",
      "ity of models in clinical practice. We evaluate model performances via Kaplan-\n",
      "Meier curve [15] (cut-off set as the ratio of patients with recurrence within 3\n",
      "\n",
      "772\n",
      "P. Azadi et al.\n",
      "\n",
      "\n",
      "\n",
      "Fig. 2. Kaplan-Meier curves of mixed co-attention model for PCa-AS and PCa-BT.\n",
      "\n",
      "\n",
      "\n",
      "years of therapy initiation for PCa-BT and the ratio of upgraded cases for PCa-\n",
      "AS), LogRank test [6] (with 0.05 as significance level), and median outcome\n",
      "associated with risk groups (Table 1 and Fig. 2). Our model stratified PCa-AS\n",
      "patients into high- and low-risk groups with median time to progression of 36.5\n",
      "and 131.7 months, respectively. Moreover, PCa-BT cases assigned to high- and\n",
      "low-risk groups have median recurrence time of 21.86 and 35.7 months. While\n",
      "none of the baselines are capable of assigning patients into risk groups with\n",
      "statistical significance, our distillation policies achieve significant separation in\n",
      "both PCa-AS and PCa-BT datasets; suggesting that global histo-morphological\n",
      "properties improve patient stratification performance. Furthermore, our findings\n",
      "have significant clinical implications as they identify, for the first time, high-\n",
      "risk prostate cancer patients who are otherwise known to be low-risk based on\n",
      "clinico-pathological parameters. This group should be managed differently from\n",
      "the rest of the low-risk prostate cancer patients in the clinic. Therefore, pro-\n",
      "viding evidence of the predictive (as opposed to prognostic) clinical information\n",
      "that our model provides. While a prognostic biomarker provides information\n",
      "about a patient's outcome (without specific recommendation on the next course\n",
      "of action), a predictive biomarker gives insights about the effect of a therapeutic\n",
      "intervention and potential actions that can be taken.\n",
      "\n",
      "\n",
      "\n",
      "Ablation Study. We perform ablation study (Table 2) on various components\n",
      "of our framework including local nodes, self-supervised ViT-based encoder, and\n",
      "most importantly, super-nodes in addition to fine-coarse distillation module.\n",
      "Although our local-only model is still showing superior results compared to\n",
      "baselines, this analysis demonstrates that all modules are essential for learn-\n",
      "ing the most effective representations. We also assess the impact of our ViT on\n",
      "the baselines (full-results in appendix), showing that it can, on average, improve\n",
      "their performance by an increase of ~ 0.03 in c-index for PCa-AS. However, the\n",
      "best baseline with ViT still has poorer performance compared to our model in\n",
      "both datasets, while the number of parameters (reported for ViT embeddings'\n",
      "size in Table 1) in our full-model is about half of this baseline. Achieving higher\n",
      "c-indices in our all model versions indicates the important role of coarse features\n",
      "and global context in patient risk estimation in addition to local patterns.\n",
      "\n",
      "ALL-IN\n",
      "773\n",
      "\n",
      "\n",
      "\n",
      "Table 2. Ablation study on different modules.\n",
      "\n",
      "\n",
      "\n",
      "Modules\n",
      "c-index |\n",
      "\n",
      "\n",
      "\n",
      "Model\n",
      "Local-node our KDM-\n",
      "ViT\n",
      "\n",
      "\n",
      "\n",
      "Super-node\n",
      "+ Distillation\n",
      "Model\n",
      "\n",
      "\n",
      "\n",
      "PCa-AS\n",
      "PCa-BT\n",
      "\n",
      "\n",
      "\n",
      "Patch-GCN \n",
      "\n",
      "\n",
      "0.627 +- 0.046\n",
      "0.588 +- 0.067\n",
      "\n",
      "\n",
      "\n",
      "Ours\n",
      "\n",
      "\n",
      "\n",
      "0.584 +- 0.072\n",
      "0.550 +- 0.109\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.622 +- 0.055\n",
      "0.597 +- 0.045\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.639 +- 0.048 0.600 +- 0.077\n",
      "\n",
      "\n",
      "\n",
      "5\n",
      "Conclusion\n",
      "\n",
      "\n",
      "\n",
      "While risk assessment is relatively under-explored, most existing methods are\n",
      "focused only on small fields of view. In this work, we introduce a novel graph-\n",
      "based model for integrating global and local features, which utilizes interactions\n",
      "at a larger scale for improved risk stratification. Using two cancer datasets, we\n",
      "evaluated the effectiveness of our model against the baseline methods for hazard\n",
      "prediction and patients stratification. Our results suggest that the proposed\n",
      "model outperforms them in risk assessment and is capable of separating patients\n",
      "into statistically significant risk groups with actionable clinical utility. The full\n",
      "capacity of this work can be revealed by extending it to other histology tasks.\n",
      "\n",
      "\n",
      "\n",
      "Acknowledgment:. This work was supported by a Canadian Institutes of Health\n",
      "Research grant to AB, PB, and LG and Michael Smith Health Research BC Scholar\n",
      "grant to AB.\n",
      "\n",
      "\n",
      "\n",
      "References\n",
      "\n",
      "\n",
      "\n",
      "1. Abu-Rustum, N.R., et al.: The revised 2009 figo staging system for endometrial\n",
      "cancer: should the 1988 figo stages ia and ib be altered? Int. J. Gynecol. Cancer\n",
      "21(3) (2011)\n",
      "2. Alabdallah, A., Ohlsson, M., Pashami, S., R\"ognvaldsson, T.: The concordance\n",
      "index decomposition-a measure for a deeper understanding of survival prediction\n",
      "models. arXiv preprint arXiv:2203.00144 (2022)\n",
      "3. Alon, U., Yahav, E.: On the bottleneck of graph neural networks and its practical\n",
      "implications. arXiv preprint arXiv:2006.05205 (2020)\n",
      "4. Angell, H., Galon, J.: From the immune contexture to the immunoscore: the role of\n",
      "prognostic and predictive immune markers in cancer. Curr. Opin. Immunol. 25(2),\n",
      "261-267 (2013)\n",
      "5. Bianchi, F.M., Grattarola, D., Alippi, C.: Spectral clustering with graph neural\n",
      "networks for graph pooling. In: International Conference on Machine Learning,\n",
      "pp. 874-883. PMLR (2020)\n",
      "6. Bland, J.M., Altman, D.G.: The logrank test. BMJ 328(7447), 1073 (2004)\n",
      "7. Bulten, W., et al.: Artificial intelligence for diagnosis and gleason grading of\n",
      "prostate cancer: the panda challenge. Nat. Med. 28(1), 154-163 (2022)\n",
      "\n",
      "774\n",
      "P. Azadi et al.\n",
      "\n",
      "\n",
      "\n",
      "8. Carbonneau, M.A., Cheplygina, V., Granger, E., Gagnon, G.: Multiple instance\n",
      "learning: a survey of problem characteristics and applications. Pattern Recogn.\n",
      "77, 329-353 (2018)\n",
      "9. Caron, M., Touvron, H., Misra, I., J'egou, H., Mairal, J., Bojanowski, P., Joulin, A.:\n",
      "Emerging properties in self-supervised vision transformers. In: Proceedings of the\n",
      "IEEE/CVF International Conference on Computer Vision, pp. 9650-9660 (2021)\n",
      "10. Chen, R.J., et al.: Whole slide images are 2D point clouds: context-aware survival\n",
      "prediction using patch-based graph convolutional networks. In: de Bruijne, M.,\n",
      "et al. (eds.) MICCAI 2021. LNCS, vol. 12908, pp. 339-349. Springer, Cham (2021).\n",
      "https://doi.org/10.1007/978-3-030-87237-3 33\n",
      "\n",
      "\n",
      "\n",
      "11. Cooperberg,\n",
      "M.R.,\n",
      "et\n",
      "al.:\n",
      "Outcomes\n",
      "of\n",
      "active\n",
      "surveillance\n",
      "for\n",
      "men\n",
      "with\n",
      "intermediate-risk prostate cancer. J. Clin. Oncol. Off. J. Am. Soc. Clin. Oncol.\n",
      "29(2), 228-234 (2011)\n",
      "12. Darbandsari, A., et al.: Identification of a novel subtype of endometrial cancer\n",
      "with unfavorable outcome using artificial intelligence-based histopathology image\n",
      "analysis (2022)\n",
      "13. Dosovitskiy, A., et al.: An image is worth 16x16 words: transformers for image\n",
      "recognition at scale. arXiv preprint arXiv:2010.11929 (2020)\n",
      "14. Ilse, M., Tomczak, J., Welling, M.: Attention-based deep multiple instance learning.\n",
      "In: International Conference on Machine Learning, pp. 2127-2136. PMLR (2018)\n",
      "15. Kaplan, E.L., Meier, P.: Nonparametric estimation from incomplete observations.\n",
      "J. Am. Stat. Assoc. 53(282), 457-481 (1958)\n",
      "16. Lee, Y., et al.: Derivation of prognostic contextual histopathological features from\n",
      "whole-slide images of tumours via graph deep learning. Nat. Biomed. Eng., 1-15\n",
      "(2022)\n",
      "17. Li, R., Yao, J., Zhu, X., Li, Y., Huang, J.: Graph CNN for survival analysis on\n",
      "whole slide pathological images. In: Frangi, A.F., Schnabel, J.A., Davatzikos, C.,\n",
      "Alberola-L'opez, C., Fichtinger, G. (eds.) MICCAI 2018. LNCS, vol. 11071, pp.\n",
      "174-182. Springer, Cham (2018). https://doi.org/10.1007/978-3-030-00934-2 20\n",
      "\n",
      "\n",
      "\n",
      "18. Liu, W., He, Q., He, X.: Weakly supervised nuclei segmentation via instance learn-\n",
      "ing. In: 2022 IEEE 19th International Symposium on Biomedical Imaging (ISBI),\n",
      "pp. 1-5. IEEE (2022)\n",
      "19. Lu, M.Y., Williamson, D.F., Chen, T.Y., Chen, R.J., Barbieri, M., Mahmood,\n",
      "F.: Data-efficient and weakly supervised computational pathology on whole-slide\n",
      "images. Nat. Biomed. Eng. 5(6), 555-570 (2021)\n",
      "20. Mobadersany, P., et al.: Predicting cancer outcomes from histology and genomics\n",
      "using convolutional networks. Proc. Natl. Acad. Sci. 115(13), E2970-E2979 (2018)\n",
      "21. Moses, K.A., et al.: Nccn guidelines R\n",
      " insights: prostate cancer early detection, ver-\n",
      "sion 1.2023: featured updates to the nccn guidelines. J. Natl. Comprehens. Cancer\n",
      "Netw. 21(3), 236-246 (2023)\n",
      "22. Oono, K., Suzuki, T.: Graph neural networks exponentially lose expressive power\n",
      "for node classification. arXiv preprint arXiv:1905.10947 (2019)\n",
      "23. Ouzzane, A., et al.: Magnetic resonance imaging targeted biopsy improves selection\n",
      "of patients considered for active surveillance for clinically low risk prostate cancer\n",
      "based on systematic biopsies. J. Urol. 194(2), 350-356 (2015)\n",
      "24. Rony, J., Belharbi, S., Dolz, J., Ayed, I.B., McCaffrey, L., Granger, E.: Deep\n",
      "weakly-supervised learning methods for classification and localization in histology\n",
      "images: a survey. arXiv preprint arXiv:1909.03354 (2019)\n",
      "25. Skowronek, J.: Current status of brachytherapy in cancer treatment-short overview.\n",
      "J. Contemp. Brachyther. 9(6), 581-589 (2017)\n",
      "\n",
      "ALL-IN\n",
      "775\n",
      "\n",
      "\n",
      "\n",
      "26. Son, B., Lee, S., Youn, H., Kim, E., Kim, W., Youn, B.: The role of tumor microen-\n",
      "vironment in therapeutic resistance. Oncotarget 8(3), 3933 (2017)\n",
      "27. Srinidhi, C.L., Ciga, O., Martel, A.L.: Deep neural network models for computa-\n",
      "tional histopathology: a survey. Med. Image Anal. 67, 101813 (2021)\n",
      "28. Tang, S., Chen, D., Bai, L., Liu, K., Ge, Y., Ouyang, W.: Mutual crf-gnn for few-\n",
      "shot learning. In: Proceedings of the IEEE/CVF Conference on Computer Vision\n",
      "and Pattern Recognition, pp. 2329-2339 (2021)\n",
      "29. Wetstein, S.C., et al.: Deep learning-based breast cancer grading and survival anal-\n",
      "ysis on whole-slide histopathology images. Sci. Rep. 12(1), 1-12 (2022)\n",
      "30. Xu, K., Hu, W., Leskovec, J., Jegelka, S.: How powerful are graph neural networks?\n",
      "arXiv preprint arXiv:1810.00826 (2018)\n",
      "31. Zaheer, M., Kottur, S., Ravanbakhsh, S., Poczos, B., Salakhutdinov, R.R., Smola,\n",
      "A.J.: Deep sets. Adv. Neural Inf. Process. Syst. 30, 1-11 (2017)\n",
      "32. Zhu, X., Yao, J., Zhu, F., Huang, J.: Wsisa: making survival prediction from whole\n",
      "slide histopathological images. In: Proceedings of the IEEE Conference on Com-\n",
      "puter Vision and Pattern Recognition, pp. 7234-7242 (2017)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from unidecode import unidecode \n",
    "\n",
    "output = []\n",
    "\n",
    "for page in doc:\n",
    "\n",
    "    output += page.get_text(\"blocks\")\n",
    "\n",
    "previous_block_id = 0 # Set a variable to mark the block id\n",
    "\n",
    "for block in output:\n",
    "\n",
    "     if block[6] == 0: # We only take the text\n",
    "          if previous_block_id != block[5]: # Compare the block number \n",
    "              print(\"\\n\")\n",
    "\n",
    "          plain_text = unidecode(block[4])\n",
    "          print(plain_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /Users/yasminsarkhosh/Library/Python/3.9/lib/python/site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /Users/yasminsarkhosh/Library/Python/3.9/lib/python/site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/yasminsarkhosh/Library/Python/3.9/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/yasminsarkhosh/Library/Python/3.9/lib/python/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/yasminsarkhosh/Library/Python/3.9/lib/python/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/yasminsarkhosh/Library/Python/3.9/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.12.0)\n",
      "\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>text</th>\n",
       "      <th>block_no</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81.351791</td>\n",
       "      <td>52.889397</td>\n",
       "      <td>371.718781</td>\n",
       "      <td>138.980408</td>\n",
       "      <td>ALL-IN: A Local GLobal Graph-Based\\nDIstillati...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57.673523</td>\n",
       "      <td>161.491257</td>\n",
       "      <td>394.792328</td>\n",
       "      <td>197.548752</td>\n",
       "      <td>Puria Azadi1, Jonathan Suderman1, Ramin Nakhli...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108.621002</td>\n",
       "      <td>205.397125</td>\n",
       "      <td>344.299713</td>\n",
       "      <td>252.046631</td>\n",
       "      <td>1 University of British Columbia, Vancouver, B...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81.917480</td>\n",
       "      <td>262.790161</td>\n",
       "      <td>371.039948</td>\n",
       "      <td>431.532410</td>\n",
       "      <td>Abstract. The utility of machine learning mode...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81.918381</td>\n",
       "      <td>435.911743</td>\n",
       "      <td>353.175232</td>\n",
       "      <td>456.658844</td>\n",
       "      <td>Keywords: Histopathology · Risk Assessment · G...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>53.577000</td>\n",
       "      <td>458.899597</td>\n",
       "      <td>147.771240</td>\n",
       "      <td>470.866669</td>\n",
       "      <td>1\\nIntroduction\\n</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>53.576962</td>\n",
       "      <td>480.973267</td>\n",
       "      <td>399.473389</td>\n",
       "      <td>564.848450</td>\n",
       "      <td>The examination of tissue and cells using micr...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>53.576996</td>\n",
       "      <td>579.446106</td>\n",
       "      <td>399.331268</td>\n",
       "      <td>599.374817</td>\n",
       "      <td>Supplementary Information The online version c...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>53.576946</td>\n",
       "      <td>607.915588</td>\n",
       "      <td>343.219025</td>\n",
       "      <td>632.050476</td>\n",
       "      <td>c\\n⃝ The Author(s), under exclusive license to...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>39.402000</td>\n",
       "      <td>31.013115</td>\n",
       "      <td>130.415466</td>\n",
       "      <td>39.979515</td>\n",
       "      <td>766\\nP. Azadi et al.\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>39.401974</td>\n",
       "      <td>53.995289</td>\n",
       "      <td>385.317352</td>\n",
       "      <td>532.389282</td>\n",
       "      <td>majority of the eﬀorts, so far, focus on the d...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>39.402000</td>\n",
       "      <td>550.393738</td>\n",
       "      <td>146.738480</td>\n",
       "      <td>562.360779</td>\n",
       "      <td>2\\nRelated Works\\n</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>39.402000</td>\n",
       "      <td>572.633301</td>\n",
       "      <td>302.116852</td>\n",
       "      <td>584.548584</td>\n",
       "      <td>2.1\\nWeakly Supervised Learning in Histopathol...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>39.402000</td>\n",
       "      <td>591.114929</td>\n",
       "      <td>385.290558</td>\n",
       "      <td>615.211487</td>\n",
       "      <td>Utilizing Weakly Supervised Learning for model...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>334.610992</td>\n",
       "      <td>31.013115</td>\n",
       "      <td>399.401306</td>\n",
       "      <td>39.979515</td>\n",
       "      <td>ALL-IN\\n767\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>53.574982</td>\n",
       "      <td>53.995289</td>\n",
       "      <td>399.411743</td>\n",
       "      <td>113.957260</td>\n",
       "      <td>and ﬁnancial costs associated with annotating ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>53.574982</td>\n",
       "      <td>130.859802</td>\n",
       "      <td>316.959198</td>\n",
       "      <td>142.775070</td>\n",
       "      <td>2.2\\nSurvival Analysis and GNNs in Histopathol...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>53.572868</td>\n",
       "      <td>149.494858</td>\n",
       "      <td>399.412598</td>\n",
       "      <td>233.369919</td>\n",
       "      <td>MIL-based models have been utilized for outcom...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>53.577000</td>\n",
       "      <td>251.656693</td>\n",
       "      <td>119.929016</td>\n",
       "      <td>263.623749</td>\n",
       "      <td>3\\nMethod\\n</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>53.576996</td>\n",
       "      <td>273.811279</td>\n",
       "      <td>399.408722</td>\n",
       "      <td>297.907806</td>\n",
       "      <td>Figure 1 summarizes our proposed end-to-end so...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>53.576996</td>\n",
       "      <td>314.819305</td>\n",
       "      <td>186.871613</td>\n",
       "      <td>326.734589</td>\n",
       "      <td>3.1\\nProblem Formulation\\n</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>53.576599</td>\n",
       "      <td>333.445282</td>\n",
       "      <td>399.424347</td>\n",
       "      <td>480.040710</td>\n",
       "      <td>For Pn, which is the n-th patient, a set of pa...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>130.247925</td>\n",
       "      <td>486.985291</td>\n",
       "      <td>399.381683</td>\n",
       "      <td>500.623688</td>\n",
       "      <td>riskn = ϵθ(Gn, Sn) = ϵθ(graph(Xn, An), Sn)\\n(1)\\n</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>53.577850</td>\n",
       "      <td>524.662781</td>\n",
       "      <td>199.861710</td>\n",
       "      <td>536.578064</td>\n",
       "      <td>3.2\\nSelf-supervised Encoder\\n</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>53.577850</td>\n",
       "      <td>543.297852</td>\n",
       "      <td>399.433533</td>\n",
       "      <td>616.705688</td>\n",
       "      <td>Due to computational limits and large number o...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>39.402000</td>\n",
       "      <td>31.013115</td>\n",
       "      <td>130.415466</td>\n",
       "      <td>39.979515</td>\n",
       "      <td>768\\nP. Azadi et al.\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>39.401997</td>\n",
       "      <td>207.881226</td>\n",
       "      <td>385.209137</td>\n",
       "      <td>315.479950</td>\n",
       "      <td>Fig. 1. The overview of our proposed method. a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>39.402000</td>\n",
       "      <td>327.397278</td>\n",
       "      <td>385.266693</td>\n",
       "      <td>363.454895</td>\n",
       "      <td>representations without any labels. Then, by u...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>39.402000</td>\n",
       "      <td>379.691925</td>\n",
       "      <td>212.607819</td>\n",
       "      <td>391.607208</td>\n",
       "      <td>3.3\\nLocal Graph Neural Network\\n</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>39.402000</td>\n",
       "      <td>397.660492</td>\n",
       "      <td>385.271698</td>\n",
       "      <td>457.622406</td>\n",
       "      <td>GNN’s objective is to ﬁnd new nodes’ embedding...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>147.815002</td>\n",
       "      <td>465.232178</td>\n",
       "      <td>385.214905</td>\n",
       "      <td>479.842773</td>\n",
       "      <td>X′\\nn = φ (An + (1 + ϵ).I).Xn) ,\\n(2)\\n</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>39.402496</td>\n",
       "      <td>484.987000</td>\n",
       "      <td>385.231232</td>\n",
       "      <td>522.538696</td>\n",
       "      <td>where ϵ is a small positive value and I is the...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>39.403107</td>\n",
       "      <td>537.281738</td>\n",
       "      <td>181.977921</td>\n",
       "      <td>549.197021</td>\n",
       "      <td>3.4\\nSuper-Nodes Extractor\\n</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>39.403107</td>\n",
       "      <td>555.250305</td>\n",
       "      <td>385.297668</td>\n",
       "      <td>615.212219</td>\n",
       "      <td>In order to ﬁnd the coarse histo-morphological...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>334.610992</td>\n",
       "      <td>31.013115</td>\n",
       "      <td>399.401306</td>\n",
       "      <td>39.979515</td>\n",
       "      <td>ALL-IN\\n769\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>53.576996</td>\n",
       "      <td>53.995289</td>\n",
       "      <td>399.442322</td>\n",
       "      <td>134.476151</td>\n",
       "      <td>details. We exploit the minCUT [5] idea to ext...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>112.401093</td>\n",
       "      <td>134.014267</td>\n",
       "      <td>399.381073</td>\n",
       "      <td>148.615707</td>\n",
       "      <td>Sn = CT\\nn .X′\\nn,\\nCn = softmax (ReLU(X′\\nn.W...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>53.577255</td>\n",
       "      <td>154.255264</td>\n",
       "      <td>399.484650</td>\n",
       "      <td>190.312881</td>\n",
       "      <td>where W1, W2 are MLPs’ weights. Hence, the ext...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>53.577255</td>\n",
       "      <td>200.731766</td>\n",
       "      <td>399.434967</td>\n",
       "      <td>224.837265</td>\n",
       "      <td>MinCut Regularizer. This term is motivated by ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>149.372635</td>\n",
       "      <td>232.294266</td>\n",
       "      <td>299.632477</td>\n",
       "      <td>258.253021</td>\n",
       "      <td>RminCUT = −Tr(CT\\nn .An,norm.Cn)\\n</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>223.343994</td>\n",
       "      <td>239.034897</td>\n",
       "      <td>399.380829</td>\n",
       "      <td>260.476807</td>\n",
       "      <td>Tr(CTn .Dn.Cn)\\n,\\n(4)\\n</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>53.577484</td>\n",
       "      <td>265.108032</td>\n",
       "      <td>399.396271</td>\n",
       "      <td>325.078796</td>\n",
       "      <td>where Dn is the diagonal degree matrix for An....</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>53.577484</td>\n",
       "      <td>335.506287</td>\n",
       "      <td>399.439301</td>\n",
       "      <td>383.515778</td>\n",
       "      <td>Orthogonality Regularizer. RminCUT is non-conv...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>143.208267</td>\n",
       "      <td>385.232147</td>\n",
       "      <td>207.203064</td>\n",
       "      <td>440.339264</td>\n",
       "      <td>Rorthogonal =\\n\u0002\u0002\u0002\u0002\\n</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>207.206055</td>\n",
       "      <td>385.231140</td>\n",
       "      <td>249.480515</td>\n",
       "      <td>440.338226</td>\n",
       "      <td>\u0002\u0002\u0002\u0002\\nCT\\nn .Cn\\n</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>211.725006</td>\n",
       "      <td>393.155396</td>\n",
       "      <td>283.941528</td>\n",
       "      <td>423.763123</td>\n",
       "      <td>||CTn .Cn||F\\n−\\nI\\n√\\n</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>281.700104</td>\n",
       "      <td>408.031952</td>\n",
       "      <td>290.158356</td>\n",
       "      <td>417.994568</td>\n",
       "      <td>K\\n</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>292.077148</td>\n",
       "      <td>385.231567</td>\n",
       "      <td>295.394684</td>\n",
       "      <td>440.338654</td>\n",
       "      <td>\u0002\u0002\u0002\u0002\\n</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>295.397675</td>\n",
       "      <td>385.230560</td>\n",
       "      <td>399.381195</td>\n",
       "      <td>440.337677</td>\n",
       "      <td>\u0002\u0002\u0002\u0002\\nF\\n,\\n(5)\\n</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>53.577465</td>\n",
       "      <td>424.426025</td>\n",
       "      <td>399.433105</td>\n",
       "      <td>508.310394</td>\n",
       "      <td>where ||.||F is the Frobenius norm, and I is t...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            x0          y0          x1          y1  \\\n",
       "0    81.351791   52.889397  371.718781  138.980408   \n",
       "1    57.673523  161.491257  394.792328  197.548752   \n",
       "2   108.621002  205.397125  344.299713  252.046631   \n",
       "3    81.917480  262.790161  371.039948  431.532410   \n",
       "4    81.918381  435.911743  353.175232  456.658844   \n",
       "5    53.577000  458.899597  147.771240  470.866669   \n",
       "6    53.576962  480.973267  399.473389  564.848450   \n",
       "7    53.576996  579.446106  399.331268  599.374817   \n",
       "8    53.576946  607.915588  343.219025  632.050476   \n",
       "9    39.402000   31.013115  130.415466   39.979515   \n",
       "10   39.401974   53.995289  385.317352  532.389282   \n",
       "11   39.402000  550.393738  146.738480  562.360779   \n",
       "12   39.402000  572.633301  302.116852  584.548584   \n",
       "13   39.402000  591.114929  385.290558  615.211487   \n",
       "14  334.610992   31.013115  399.401306   39.979515   \n",
       "15   53.574982   53.995289  399.411743  113.957260   \n",
       "16   53.574982  130.859802  316.959198  142.775070   \n",
       "17   53.572868  149.494858  399.412598  233.369919   \n",
       "18   53.577000  251.656693  119.929016  263.623749   \n",
       "19   53.576996  273.811279  399.408722  297.907806   \n",
       "20   53.576996  314.819305  186.871613  326.734589   \n",
       "21   53.576599  333.445282  399.424347  480.040710   \n",
       "22  130.247925  486.985291  399.381683  500.623688   \n",
       "23   53.577850  524.662781  199.861710  536.578064   \n",
       "24   53.577850  543.297852  399.433533  616.705688   \n",
       "25   39.402000   31.013115  130.415466   39.979515   \n",
       "26   39.401997  207.881226  385.209137  315.479950   \n",
       "27   39.402000  327.397278  385.266693  363.454895   \n",
       "28   39.402000  379.691925  212.607819  391.607208   \n",
       "29   39.402000  397.660492  385.271698  457.622406   \n",
       "30  147.815002  465.232178  385.214905  479.842773   \n",
       "31   39.402496  484.987000  385.231232  522.538696   \n",
       "32   39.403107  537.281738  181.977921  549.197021   \n",
       "33   39.403107  555.250305  385.297668  615.212219   \n",
       "34  334.610992   31.013115  399.401306   39.979515   \n",
       "35   53.576996   53.995289  399.442322  134.476151   \n",
       "36  112.401093  134.014267  399.381073  148.615707   \n",
       "37   53.577255  154.255264  399.484650  190.312881   \n",
       "38   53.577255  200.731766  399.434967  224.837265   \n",
       "39  149.372635  232.294266  299.632477  258.253021   \n",
       "40  223.343994  239.034897  399.380829  260.476807   \n",
       "41   53.577484  265.108032  399.396271  325.078796   \n",
       "42   53.577484  335.506287  399.439301  383.515778   \n",
       "43  143.208267  385.232147  207.203064  440.339264   \n",
       "44  207.206055  385.231140  249.480515  440.338226   \n",
       "45  211.725006  393.155396  283.941528  423.763123   \n",
       "46  281.700104  408.031952  290.158356  417.994568   \n",
       "47  292.077148  385.231567  295.394684  440.338654   \n",
       "48  295.397675  385.230560  399.381195  440.337677   \n",
       "49   53.577465  424.426025  399.433105  508.310394   \n",
       "\n",
       "                                                 text  block_no  type  \n",
       "0   ALL-IN: A Local GLobal Graph-Based\\nDIstillati...         0     0  \n",
       "1   Puria Azadi1, Jonathan Suderman1, Ramin Nakhli...         1     0  \n",
       "2   1 University of British Columbia, Vancouver, B...         2     0  \n",
       "3   Abstract. The utility of machine learning mode...         3     0  \n",
       "4   Keywords: Histopathology · Risk Assessment · G...         4     0  \n",
       "5                                   1\\nIntroduction\\n         5     0  \n",
       "6   The examination of tissue and cells using micr...         6     0  \n",
       "7   Supplementary Information The online version c...         7     0  \n",
       "8   c\\n⃝ The Author(s), under exclusive license to...         8     0  \n",
       "9                              766\\nP. Azadi et al.\\n         0     0  \n",
       "10  majority of the eﬀorts, so far, focus on the d...         1     0  \n",
       "11                                 2\\nRelated Works\\n         2     0  \n",
       "12  2.1\\nWeakly Supervised Learning in Histopathol...         3     0  \n",
       "13  Utilizing Weakly Supervised Learning for model...         4     0  \n",
       "14                                      ALL-IN\\n767\\n         0     0  \n",
       "15  and ﬁnancial costs associated with annotating ...         1     0  \n",
       "16  2.2\\nSurvival Analysis and GNNs in Histopathol...         2     0  \n",
       "17  MIL-based models have been utilized for outcom...         3     0  \n",
       "18                                        3\\nMethod\\n         4     0  \n",
       "19  Figure 1 summarizes our proposed end-to-end so...         5     0  \n",
       "20                         3.1\\nProblem Formulation\\n         6     0  \n",
       "21  For Pn, which is the n-th patient, a set of pa...         7     0  \n",
       "22  riskn = ϵθ(Gn, Sn) = ϵθ(graph(Xn, An), Sn)\\n(1)\\n         8     0  \n",
       "23                     3.2\\nSelf-supervised Encoder\\n         9     0  \n",
       "24  Due to computational limits and large number o...        10     0  \n",
       "25                             768\\nP. Azadi et al.\\n         0     0  \n",
       "26  Fig. 1. The overview of our proposed method. a...         1     0  \n",
       "27  representations without any labels. Then, by u...         2     0  \n",
       "28                  3.3\\nLocal Graph Neural Network\\n         3     0  \n",
       "29  GNN’s objective is to ﬁnd new nodes’ embedding...         4     0  \n",
       "30            X′\\nn = φ (An + (1 + ϵ).I).Xn) ,\\n(2)\\n         5     0  \n",
       "31  where ϵ is a small positive value and I is the...         6     0  \n",
       "32                       3.4\\nSuper-Nodes Extractor\\n         7     0  \n",
       "33  In order to ﬁnd the coarse histo-morphological...         8     0  \n",
       "34                                      ALL-IN\\n769\\n         0     0  \n",
       "35  details. We exploit the minCUT [5] idea to ext...         1     0  \n",
       "36  Sn = CT\\nn .X′\\nn,\\nCn = softmax (ReLU(X′\\nn.W...         2     0  \n",
       "37  where W1, W2 are MLPs’ weights. Hence, the ext...         3     0  \n",
       "38  MinCut Regularizer. This term is motivated by ...         4     0  \n",
       "39                 RminCUT = −Tr(CT\\nn .An,norm.Cn)\\n         5     0  \n",
       "40                           Tr(CTn .Dn.Cn)\\n,\\n(4)\\n         6     0  \n",
       "41  where Dn is the diagonal degree matrix for An....         7     0  \n",
       "42  Orthogonality Regularizer. RminCUT is non-conv...         8     0  \n",
       "43                              Rorthogonal =\\n\u0002\u0002\u0002\u0002\\n         9     0  \n",
       "44                                  \u0002\u0002\u0002\u0002\\nCT\\nn .Cn\\n        10     0  \n",
       "45                            ||CTn .Cn||F\\n−\\nI\\n√\\n        11     0  \n",
       "46                                                K\\n        12     0  \n",
       "47                                             \u0002\u0002\u0002\u0002\\n        13     0  \n",
       "48                                  \u0002\u0002\u0002\u0002\\nF\\n,\\n(5)\\n        14     0  \n",
       "49  where ||.||F is the Frobenius norm, and I is t...        15     0  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(output, columns=[\"x0\", \"y0\", \"x1\", \"y1\", \"text\", \"block_no\", \"type\"])\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: unidecode(x))\n",
    "df = df.drop(df[df['type'] == '1' ].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_dict = {}\n",
    "\n",
    "page_num = 1\n",
    "\n",
    "for page in doc: # Iterate all pages in the document\n",
    "      file_dict = page.get_text('dict') # Get the page dictionary \n",
    "      block = file_dict['blocks'] # Get the block information\n",
    "      block_dict[page_num] = block # Store in block dictionary\n",
    "      page_num += 1 # Increase the page value by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "spans = pd.DataFrame(columns=['xmin', 'ymin', 'xmax', 'ymax', 'text', 'tag'])\n",
    "\n",
    "rows = []\n",
    "\n",
    "for page_num, blocks in block_dict.items():\n",
    "    for block in blocks:\n",
    "        if block['type'] == 0:\n",
    "            for line in block['lines']:\n",
    "                for span in line['spans']:\n",
    "                    xmin, ymin, xmax, ymax = list(span['bbox'])\n",
    "                    font_size = span['size']\n",
    "                    text = unidecode(span['text'])\n",
    "                    span_font = span['font']\n",
    "                    is_upper = False\n",
    "                    is_bold = False \n",
    "\n",
    "                    if \"bold\" in span_font.lower():\n",
    "                        is_bold = True \n",
    "\n",
    "                    if re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", text).isupper():\n",
    "                        is_upper = True\n",
    "\n",
    "                    if text.replace(\" \",\"\") !=  \"\":\n",
    "                        rows.append((xmin, ymin, xmax, ymax, text, is_upper, is_bold, span_font, font_size))\n",
    "\n",
    "span_df = pd.DataFrame(rows, columns=['xmin','ymin','xmax','ymax', 'text', 'is_upper','is_bold','span_font', 'font_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "span_scores = []\n",
    "span_num_occur = {}\n",
    "special = '[(_:/,#%\\=@)]'\n",
    "\n",
    "for index, span_row in span_df.iterrows():\n",
    "    score = round(span_row.font_size)\n",
    "    text = span_row.text\n",
    "\n",
    "    if not re.search(special, text):\n",
    "        if span_row.is_bold:\n",
    "            score +=1 \n",
    "\n",
    "        if span_row.is_upper:\n",
    "            score +=1\n",
    "\n",
    "    span_scores.append(score)\n",
    "\n",
    "values, counts = np.unique(span_scores, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 4),\n",
       " (14, 5),\n",
       " (12, 13),\n",
       " (8, 33),\n",
       " (6, 38),\n",
       " (11, 94),\n",
       " (7, 321),\n",
       " (9, 342),\n",
       " (10, 570)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "values, counts = np.unique(span_scores, return_counts=True)\n",
    "\n",
    "style_dict = {}\n",
    "\n",
    "for value, count in zip(values, counts):\n",
    "    style_dict[value] = count\n",
    "\n",
    "sorted(style_dict.items(), key=lambda x: x[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_size = max(style_dict, key=style_dict.get)\n",
    "\n",
    "idx = 0\n",
    "tag = {}\n",
    "\n",
    "for size in sorted(values, reverse = True):\n",
    "    idx += 1\n",
    "\n",
    "    if size == p_size:\n",
    "        idx = 0\n",
    "        tag[size] = 'p'\n",
    "\n",
    "    if size > p_size:\n",
    "        tag[size] = 'h{0}'.format(idx)\n",
    "\n",
    "    if size < p_size:\n",
    "        tag[size] = 's{0}'.format(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "span_tags = [tag[score] for score in span_scores]\n",
    "span_df['tag'] = span_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "headings_list = []\n",
    "text_list = []\n",
    "tmp = []\n",
    "heading = ''                                                                                                                \n",
    "\n",
    "for index, span_row in span_df.iterrows():\n",
    "    text = span_row.text\n",
    "    tag = span_row.tag\n",
    "\n",
    "    if 'h' in tag:\n",
    "        headings_list.append(text)\n",
    "        text_list.append('\\n'.join(tmp))\n",
    "        tmp = []\n",
    "        heading = text\n",
    "\n",
    "    else:\n",
    "        tmp.append(text)\n",
    "\n",
    "text_list.append('\\n'.join(tmp))\n",
    "text_list = text_list[1:]\n",
    "text_df = pd.DataFrame(zip(headings_list, text_list),columns=['heading', 'content'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALL-IN: A Local GLobal Graph-Based',\n",
       " 'DIstillatioN Model for Representation',\n",
       " 'Learning of Gigapixel Histopathology',\n",
       " 'Images With Application In Cancer Risk',\n",
       " 'Assessment',\n",
       " 'B',\n",
       " ' *',\n",
       " ' *',\n",
       " '1',\n",
       " 'Introduction',\n",
       " '2',\n",
       " 'Related Works',\n",
       " '3',\n",
       " 'Method',\n",
       " ' P',\n",
       " ' R',\n",
       " ' Z',\n",
       " ' R',\n",
       " ' P',\n",
       " 'G',\n",
       " 'P',\n",
       " ' A',\n",
       " ' P',\n",
       " ' A',\n",
       " ' M',\n",
       " ' M',\n",
       " ' Z',\n",
       " 'G',\n",
       " 'Z',\n",
       " ' K',\n",
       " 'S',\n",
       " ' R',\n",
       " ' P',\n",
       " ' G',\n",
       " 'S',\n",
       " 'G',\n",
       " 'X',\n",
       " 'S',\n",
       " 'T',\n",
       " 'X',\n",
       " 'A',\n",
       " '.I',\n",
       " '.X',\n",
       " ' I',\n",
       " ' X',\n",
       " ' R',\n",
       " ' X',\n",
       " ' R',\n",
       " ' P',\n",
       " ' X',\n",
       " ' Z',\n",
       " ' K',\n",
       " ' C',\n",
       " ' R',\n",
       " 'S',\n",
       " ' R',\n",
       " 'S',\n",
       " ' C',\n",
       " '.X',\n",
       " 'C',\n",
       " 'X',\n",
       " '.W',\n",
       " '.W',\n",
       " ' W',\n",
       " 'R',\n",
       " 'C',\n",
       " '.A',\n",
       " '.C',\n",
       " 'C',\n",
       " ' .D',\n",
       " '.C',\n",
       " ' D',\n",
       " ' A',\n",
       " ' A',\n",
       " ' R',\n",
       " 'C',\n",
       " '.A',\n",
       " '.C',\n",
       " 'C',\n",
       " '.D',\n",
       " '.C',\n",
       " ' R',\n",
       " ' R',\n",
       " ' R',\n",
       " 'R',\n",
       " 'C',\n",
       " '.C',\n",
       " 'C',\n",
       " ' .C',\n",
       " 'I',\n",
       " 'K',\n",
       " ' I',\n",
       " ' X',\n",
       " ' R',\n",
       " ' S',\n",
       " ' R',\n",
       " ' P',\n",
       " 'W',\n",
       " ' R',\n",
       " ' R',\n",
       " ' X',\n",
       " ' S',\n",
       " 'W',\n",
       " 'W',\n",
       " ' W',\n",
       " ' W',\n",
       " '4',\n",
       " 'Experiments and Results',\n",
       " 'AMIL [',\n",
       " '5',\n",
       " 'Conclusion',\n",
       " 'References']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.to_csv('text_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALL-IN: A Local GLobal Graph-Based\\nDIstillati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Puria Azadi1, Jonathan Suderman1, Ramin Nakhli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 University of British Columbia, Vancouver, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abstract. The utility of machine learning mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Keywords: Histopathology * Risk Assessment * G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1\\nIntroduction\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The examination of tissue and cells using micr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Supplementary Information The online version c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c\\n The Author(s), under exclusive license to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>766\\nP. Azadi et al.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>majority of the efforts, so far, focus on the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2\\nRelated Works\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.1\\nWeakly Supervised Learning in Histopathol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Utilizing Weakly Supervised Learning for model...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ALL-IN\\n767\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>and financial costs associated with annotating...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.2\\nSurvival Analysis and GNNs in Histopathol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MIL-based models have been utilized for outcom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3\\nMethod\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Figure 1 summarizes our proposed end-to-end so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0   ALL-IN: A Local GLobal Graph-Based\\nDIstillati...\n",
       "1   Puria Azadi1, Jonathan Suderman1, Ramin Nakhli...\n",
       "2   1 University of British Columbia, Vancouver, B...\n",
       "3   Abstract. The utility of machine learning mode...\n",
       "4   Keywords: Histopathology * Risk Assessment * G...\n",
       "5                                   1\\nIntroduction\\n\n",
       "6   The examination of tissue and cells using micr...\n",
       "7   Supplementary Information The online version c...\n",
       "8   c\\n The Author(s), under exclusive license to ...\n",
       "9                              766\\nP. Azadi et al.\\n\n",
       "10  majority of the efforts, so far, focus on the ...\n",
       "11                                 2\\nRelated Works\\n\n",
       "12  2.1\\nWeakly Supervised Learning in Histopathol...\n",
       "13  Utilizing Weakly Supervised Learning for model...\n",
       "14                                      ALL-IN\\n767\\n\n",
       "15  and financial costs associated with annotating...\n",
       "16  2.2\\nSurvival Analysis and GNNs in Histopathol...\n",
       "17  MIL-based models have been utilized for outcom...\n",
       "18                                        3\\nMethod\\n\n",
       "19  Figure 1 summarizes our proposed end-to-end so..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('output.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALL-IN: A Local GLobal Graph-Based\\nDIstillati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Puria Azadi1, Jonathan Suderman1, Ramin Nakhli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 University of British Columbia, Vancouver, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abstract. The utility of machine learning mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Keywords: Histopathology * Risk Assessment * G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>8. Carbonneau, M.A., Cheplygina, V., Granger, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>11. Cooperberg,\\nM.R.,\\net\\nal.:\\nOutcomes\\nof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>18. Liu, W., He, Q., He, X.: Weakly supervised...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>ALL-IN\\n775\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>26. Son, B., Lee, S., Youn, H., Kim, E., Kim, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    ALL-IN: A Local GLobal Graph-Based\\nDIstillati...\n",
       "1    Puria Azadi1, Jonathan Suderman1, Ramin Nakhli...\n",
       "2    1 University of British Columbia, Vancouver, B...\n",
       "3    Abstract. The utility of machine learning mode...\n",
       "4    Keywords: Histopathology * Risk Assessment * G...\n",
       "..                                                 ...\n",
       "105  8. Carbonneau, M.A., Cheplygina, V., Granger, ...\n",
       "106  11. Cooperberg,\\nM.R.,\\net\\nal.:\\nOutcomes\\nof...\n",
       "107  18. Liu, W., He, Q., He, X.: Weakly supervised...\n",
       "108                                      ALL-IN\\n775\\n\n",
       "109  26. Son, B., Lee, S., Youn, H., Kim, E., Kim, ...\n",
       "\n",
       "[110 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALL-IN: A Local GLobal Graph-Based\\nDIstillati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Puria Azadi1, Jonathan Suderman1, Ramin Nakhli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 University of British Columbia, Vancouver, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abstract. The utility of machine learning mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Keywords: Histopathology * Risk Assessment * G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>8. Carbonneau, M.A., Cheplygina, V., Granger, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>11. Cooperberg,\\nM.R.,\\net\\nal.:\\nOutcomes\\nof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>18. Liu, W., He, Q., He, X.: Weakly supervised...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>ALL-IN\\n775\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>26. Son, B., Lee, S., Youn, H., Kim, E., Kim, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    ALL-IN: A Local GLobal Graph-Based\\nDIstillati...\n",
       "1    Puria Azadi1, Jonathan Suderman1, Ramin Nakhli...\n",
       "2    1 University of British Columbia, Vancouver, B...\n",
       "3    Abstract. The utility of machine learning mode...\n",
       "4    Keywords: Histopathology * Risk Assessment * G...\n",
       "..                                                 ...\n",
       "105  8. Carbonneau, M.A., Cheplygina, V., Granger, ...\n",
       "106  11. Cooperberg,\\nM.R.,\\net\\nal.:\\nOutcomes\\nof...\n",
       "107  18. Liu, W., He, Q., He, X.: Weakly supervised...\n",
       "108                                      ALL-IN\\n775\\n\n",
       "109  26. Son, B., Lee, S., Youn, H., Kim, E., Kim, ...\n",
       "\n",
       "[110 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
