<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Attentive Deep Canonical Correlation Analysis for Diagnosing Alzheimer’s Disease Using Multimodal Imaging Genetics</title>
				<funder ref="#_rPyW8mc">
					<orgName type="full">FIG</orgName>
				</funder>
				<funder ref="#_mc984GB #_tYPWYfE">
					<orgName type="full">National Science Foundation</orgName>
				</funder>
				<funder ref="#_jSPwp2J #_QNYcgNH #_sBg7Q5e #_Xky4SDb #_FvxeXHk">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_CedKxDJ">
					<orgName type="full">Accelerator</orgName>
				</funder>
				<funder ref="#_jhgVgCa">
					<orgName type="full">National Institutes of Health</orgName>
				</funder>
				<funder ref="#_N8qrzDB">
					<orgName type="full">CORE</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Rong</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Lehigh University</orgName>
								<address>
									<settlement>Bethlehem</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Houliang</forename><surname>Zhou</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Brian</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Lehigh University</orgName>
								<address>
									<settlement>Bethlehem</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Li</forename><surname>Shen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Lehigh University</orgName>
								<address>
									<settlement>Bethlehem</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Biostatistics, Epidemiology and Informatics</orgName>
								<orgName type="institution">University of Pennsylvania</orgName>
								<address>
									<settlement>Philadelphia</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yu</forename><surname>Zhang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Bioengineering</orgName>
								<orgName type="institution">Lehigh University</orgName>
								<address>
									<settlement>Bethlehem</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lifang</forename><surname>He</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Lehigh University</orgName>
								<address>
									<settlement>Bethlehem</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Attentive Deep Canonical Correlation Analysis for Diagnosing Alzheimer’s Disease Using Multimodal Imaging Genetics</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="681" to="691"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">65769CEBDB73F8364A9F1FCBB67163DF</idno>
					<idno type="DOI">10.1007/978-3-031-43895-0_64</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-24T10:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Brain imaging genetics</term>
					<term>Canonical correlation analysis</term>
					<term>Self-attention</term>
					<term>Alzheimer&apos;s disease Supplementary Information The online version contains supplementary material</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Integration of imaging genetics data provides unprecedented opportunities for revealing biological mechanisms underpinning diseases and certain phenotypes. In this paper, a new model called attentive deep canonical correlation analysis (ADCCA) is proposed for the diagnosis of Alzheimer's disease using multimodal brain imaging genetics data. ADCCA combines the strengths of deep neural networks, attention mechanisms, and canonical correlation analysis to integrate and exploit the complementary information from multiple data modalities. This leads to improved interpretability and strong multimodal feature learning ability. The ADCCA model is evaluated using the ADNI database with three imaging modalities (VBM-MRI, FDG-PET, and AV45-PET) and genetic SNP data. The results indicate that this approach can achieve outstanding performance and identify meaningful biomarkers for Alzheimer's disease diagnosis. To promote reproducibility, the code has been made publicly available at https://github.com/rongzhou7/ADCCA.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Alzheimer's disease (AD) is an irreversible neurodegenerative disorder that affects millions of people worldwide <ref type="bibr" target="#b4">[5]</ref>. In recent years, brain imaging genetics has emerged as a promising field for the diagnosis and prediction of AD and its prodromal stage -mild cognitive impairment (MCI). This approach largely focuses on using neuroimaging techniques, such as MRI and PET, to identify brain regions that are associated with specific genetic variants such as single nucleotide polymorphisms (SNPs). Such analyses have produced a wealth of research findings <ref type="bibr" target="#b23">[23,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b28">28]</ref> that have demonstrated significant associations between imaging characteristics and genetics in AD, and have the great potential to identify new multimodal biomarkers affecting specific brain systems and provide an enormous impetus for drug discovery. and Y is the label information. DNNs first operate on each modality, generating hidden representations for each modality. These hidden representations go through a selfattention mechanism generating improved self-attention representations. At the same time, the hidden representations and label Y are multiplied by individual projection matrices U1, . . . , U4, Uy based on CCA, thus mapping them to a shared representation G. Finally, the disease prediction is calculated by self-attention representations with projection matrices and shared representation G.</p><p>In the literature, various methods have been proposed to brain imaging genetics analysis <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b11">[11]</ref><ref type="bibr" target="#b13">13,</ref><ref type="bibr" target="#b19">19,</ref><ref type="bibr" target="#b27">27,</ref><ref type="bibr" target="#b29">29]</ref>. In particular, canonical correlation analysis (CCA) <ref type="bibr" target="#b12">[12]</ref> is a powerful multivariate statistical technique for quantifying the associations between different sets of data. CCA and its variations have been widely applied in imaging genetics studies because of its advantages in biological interpretation. For example, Du et al. <ref type="bibr" target="#b7">[8]</ref> proposed a joint multitask sparse canonical correlation analysis and classification (MTSCCALR) for identifying imaging genetics biomarkers of AD. Kim et al. <ref type="bibr" target="#b16">[16]</ref> introduced a multi-task learning-based structured sparse canonical correlation analysis (MTS2CCA) for identifying brain imaging genetics related to sleep. Moon et al. <ref type="bibr" target="#b20">[20]</ref> proposed a supervised deep generalized canonical correlation analysis (SDGCCA) for improving the classification of phenotypes and revealing biomarkers associated with phenotypes in the context of AD. Despite much progress made in this area, CCA-based traditional shallow models assume that the relationships between genetic and imaging data are linear. However, this may not always be the case, and nonlinear relationships may exist in brain imaging genetics data, leading to biased results. On the other hand, the existing CCA-based deep models do not provide a direct interpretation of the underlying biological mechanisms driving the observed associations between genetic and imaging data. Most of them explored post-hoc explanations as justifications for model predictions. This can limit the ability to translate findings into clinically relevant insights.</p><p>In this paper, we propose a novel attentive deep canonical correlation analysis (ADCCA) model for diagnosing AD disease and discovering biomarkers using multimodal brain imaging genetics data. As illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>, the proposed framework comprises three key components: (i) deep neural network (DNN) modeling for generating latent representations of each modality to capture intramodality correlations; (ii) attention update mechanism for focusing on the most salient regions of input data; and (iii) nonlinear supervised CCA modeling for integrating multiple modalities to discriminate phenotypic groups. By combining the power of these techniques, the ADCCA approach effectively models nonlinear relationships among multimodal imaging genetics data and provides simultaneous predictions and interpretations. The model is trained end-to-end using a combination of classification and correlation losses.</p><p>Through extensive experiments on the real-world ADNI dataset with three imaging modalities (VBM-MRI, FDG-PET, and AV45-PET) and genetic SNP data, we show that our model achieves outstanding performance for classifying AD vs. HC, AD vs. MCI, and MCI vs. HC groups. Also, it is demonstrated that the model explanation can reveal disorder-specific biomarkers coinciding with neuroscience findings. Last, we show that the combination of classification and correlation models can boost disease prediction performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>Suppose that the problem includes N subjects with M modalities. Let X m ∈ R N ×dm denote the m-th modality data, where d m represents the dimension of features in the m-th modality,</p><formula xml:id="formula_0">m = 1, 2, • • • , M. Let Y ∈ R N denote</formula><p>the label information of all subjects. In this work, we seek to learn a disease prediction model that estimates Ŷ from {X m } M m=1 by making full use of all M modalities, as well as identify disease-specific biomarkers for clinical interpretation.</p><p>The proposed ADCCA aims to combine the strengths of DNN, attention mechanism, and CCA to integrate and exploit the complementary information from multiple data modalities (Fig. <ref type="figure" target="#fig_0">1</ref>). First, we use a separate DNN containing several fully-connected hidden layers to learn hidden representations for each modality, denoted as f m (X m ) ∈ R N ×lm , where l m represents the dimension of last layer of DNN corresponding to the m-th modality. Second, we employ the attention mechanism <ref type="bibr" target="#b25">[25]</ref> on the basis of the DNN model. With the help of the attention mechanism, our method can explicitly capture the important features hidden in the input data. Specifically, we use self-attention, sometimes called intra-attention, which is regarded as an improvement in attention that focuses on internal links of features and reduces external data dependency to compute its representation. Suppose there are three linear transformation matrices for the mth modality:</p><formula xml:id="formula_1">W m Q , W m K , W m V .</formula><p>Mathematically, the self-attention representation of f m (X m ) can be calculated as:</p><formula xml:id="formula_2">Att(f m (X m )) = Softmax f m (X m ) W m Q (f m (X m ) W m K ) √ l m f m (X m ) W m V . (1)</formula><p>Third, following <ref type="bibr" target="#b20">[20]</ref>, we learn cross-modality features and incorporate the label information of samples for supervised learning based on CCA. The correlation loss function is defined as follows:</p><formula xml:id="formula_3">L cor = G -U y Y 2 F + M m=1 G -U m f m (X m ) 2 F , s.t. GG = I.<label>(2)</label></formula><p>where U 1 , • • • , U 4 , U y are projection matrices for each modality and label information, respectively. I denotes the identity matrix. According to Eq. ( <ref type="formula" target="#formula_3">2</ref>), we have</p><formula xml:id="formula_4">G ≈ U m f m (X m ) ≈ U y Y.</formula><p>Thus, the label Y can be approximated as follows:</p><formula xml:id="formula_5">Y ≈ U y † U m f m (X m )</formula><p>, where U † y denotes the pseudo-inverse of U y . Then, we substitute self-attention representations that are more representative of each modality into the above equation and let</p><formula xml:id="formula_6">Ŷm = U y † U m Att (f m (X m )).</formula><p>Further, the conventional supervised crossentropy loss <ref type="bibr" target="#b6">[7]</ref> is used to enable the propagation of label information directly to the DNN of each modality.</p><formula xml:id="formula_7">L cls = M m=1</formula><p>CrossEntropy Y, Softmax( Ŷm ) .</p><p>(</p><p>The final label prediction of ADCCA can be obtained using the following soft voting of the label presentation of each modality: Ŷ = Softmax(( M m=1 Ŷm )/M ). Overall, our final training objective can be defined as:</p><formula xml:id="formula_9">L = L cls + λL cor , (<label>4</label></formula><formula xml:id="formula_10">)</formula><p>where L cls is the supervised cross-entropy disease prediction loss, L cor is the correlation loss, and λ is a tunable hyperparameter that scales the numerical value of each loss item to the same order of magnitude to balance their influence. The solution on loss function L is similar to the SGDCCA method except for substituting the outputs of DNN models to their self-attention representations.</p><p>3 Experiments and Results</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Acquisition and Preprocessing</head><p>Brain imaging genetic data used in this study were obtained from the public ADNI database <ref type="bibr" target="#b22">[22]</ref>. There is a total of 597 participants with both geno-type and brain imaging data, including 104 AD, 305 MCI, and 188 healthy control (HC) subjects. The image data consisted of three modalities including structural Magnetic Resonance Imaging (VBM-MRI), 18 F-fluorodeoxyglucose Positron Emission Tomography (FDG-PET), and 18 F-florbetapir PET (AV45-PET). These three imaging modalities allowed us to examine brain structure, glucose metabolism, and amyloid plaque deposition, respectively. Following the previous studies <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b30">30]</ref>, we preprocessed neuroimaging data to extract ROI-based features. Specifically, the multi-modality imaging scans were aligned to each participant's same visit. All imaging scans were aligned to a T1-weighted template image, and segmented into gray matter (GM), white matter (WM) and cerebrospinal fluid (CSF) maps. They were normalized to the standard Montreal Neurological Institute (MNI) space as 2 × 2 × 2 mm 3 voxels, being smoothed with an 8 mm FWHM kernel. We preprocessed the structural MRI scans with voxel-based morphometry (VBM) by using the SPM software <ref type="bibr" target="#b0">[1]</ref>, and registered the FDG-PET and AV45-PET scans to the MNI space by SPM. We subsampled the whole brain imaging and contained 90 ROIs (excluding the cerebellum and vermis) based on the AAL-90 atlas <ref type="bibr" target="#b24">[24]</ref>. ROI-level measures were calculated by averaging all the voxel-level measures within each ROI.</p><p>For genetic SNP data, according to the AlzGene database<ref type="foot" target="#foot_0">1</ref> , only the SNPs belonging to top AD gene candidates were selected. The genetic data were genotyped by the Human 610-Quad or OmniExpress Array platform (Illumina, Inc., San Diego, CA, USA), and preprocessed following standard quality control and imputation procedures. There were 54 SNPs included which were collected from the neighbor of AD risk gene APOE according to the ANNOVAR annotation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation of Disease Classification Performance</head><p>In our experiments, the whole data were separated into three groups, including AD vs. HC, AD vs. MCI, and MCI vs. HC. To quantitatively evaluate the performance of different methods, we considered four commonly-used evaluation metrics: accuracy (ACC), F1-score (F1), area under receiver operating characteristic curve (AUC), and Matthews correlation coefficient (MCC) <ref type="bibr" target="#b5">[6]</ref>. Since the number of subjects was limited, we calculated the mean and standard deviation of all metrics using 5-fold cross-validation (CV). Many researchers have successfully adopted multimodal brain imaging data into CCA. We carefully choose five related methods for comparison: 1) vanilla DNN <ref type="bibr" target="#b18">[18]</ref>, 2) generalized CCA (GCCA) <ref type="bibr" target="#b15">[15]</ref>, 3) deep generalized CCA (DGCCA) <ref type="bibr" target="#b3">[4]</ref>, 4) MTSCCALR <ref type="bibr" target="#b7">[8]</ref>, and 5) SDGCCA <ref type="bibr" target="#b20">[20]</ref>. Note that GCCA and DGCCA are unsupervised learning methods, and the others are supervised learning methods. The proposed model includes four DNNs, one for each modality, with three fully-connected layers and a Tanh activation function, which is trained with Adam optimizer with the learning rate set to 0.0001 and weight decay set to 0.001.</p><p>Table <ref type="table" target="#tab_0">1</ref> presents the classification results, where ± represents the standard deviation of evaluation scores across the 5 folds. From the results, it can be observed that the proposed ADCCA method significantly outperforms all other methods in terms of all four metrics. The higher AUC and MCC scores indicate that our method is able to accurately identify both positive and negative cases of AD. The smaller standard deviations of ADCCA illustrated the overall stability and reproducibility of the experiment. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">The Most Discriminative Brain Regions and SNPs</head><p>Identifying the most discriminative brain regions (i.e., ROIs) and SNPs is crucial for AD diagnosis. Here, we employed the integrated gradients interface provided by Captum <ref type="bibr" target="#b17">[17]</ref> to assign importance scores to each feature of different modalities by analyzing the pre-trained model, which can provide a comprehensive explanation of how the input features of a deep learning model contribute to the model's output. The reason why not using the self-attention weights is that we use the self-attention to assign attention scores to hidden representations instead of the original features, thus it may not fully capture the importance of the original features in the input data. Figure <ref type="figure">2(a-c</ref>) shows the top 20 discriminative ROIs identified by the proposed method from each individual brain imaging modality. Figure <ref type="figure">2(d)</ref> shows the top 20 discriminative ROIs selected by the average importance scores of ROIs from the three modalities. We found that the hippocampal, amygdala, uncus, and gyrus regions are only identified by using the three modalities together. These selected regions are known to be highly related to AD and MCI in previous studies <ref type="bibr" target="#b21">[21]</ref>. Besides, the result shows that the selected ROIs exhibited differences across different classification groups, indicating that our model can effectively differentiate the important ROIs for specific diseases. Figure <ref type="figure">3</ref> shows the most frequently selected SNPs with importance scores. The result indicates that rs6448453, rs3865444, and rs2718058 are the most discriminative SNPs which is consistent with previous evidence <ref type="bibr" target="#b14">[14]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Ablation Study</head><p>The proposed ADCCA is trained using both correlation and classification losses.</p><p>To understand the impact of each loss on classification, we conducted ablation studies by evaluating the performance of two additional models: the ADCCA model trained without the correlation loss (w/o L cor ) and without the classification loss (w/o L cls ). The results presented in Table <ref type="table" target="#tab_1">2</ref> indicate that ADCCA outperforms the other two models for all evaluation metrics on all three classification tasks, suggesting that both correlation and classification losses contribute to ADCCA's improved performance. Removing either loss leads to decreased performance, and the impact will be particularly significant if the classification loss is eliminated. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Hyperparameter Analysis</head><p>We investigated the impact of two important hyperparameters in the ADCCA model: λ, which appears in the loss function to balance the classification and correlation losses, and the dimension of the shared representation G. In order to explore the effects of these hyperparameters on the performance of the model, we conducted experiments using different values of λ and the shared representation dimensionality. Due to the space limit, we only report the classification results in AD vs. HC group, as shown in Fig. <ref type="figure" target="#fig_2">4</ref>. The results in other groups can be found in the supplementary material. We observed that decreasing the value of λ generally leads to improved model performance across various tasks, but a lambda value of zero causes the model's performance to deteriorate. This may indicate that for the ADCCA model, L cls is more important than L cor . Furthermore, combining these two loss functions to jointly guide the model can lead to improved model performance. We also found that for the AD vs. HC group, the model achieves good performance even with a low-dimensional shared representation. However, for other groups, the impact of the shared representation dimension on the model's performance seems not significant. One explanation for this could be that the AD vs. HC group exhibits distinct feature differences, allowing the original features to be well represented even when mapped into a low-dimensional shared representation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this work, we propose a novel deep canonical correlation analysis method for multimodal Alzheimer's disease diagnosis that leverages attention mechanisms to enhance interpretability and multimodal feature learning. Experimental results on the real-world imaging-genetics dataset demonstrate that our approach achieves better classification performance than the existing state-of-theart methods in terms of both classification accuracy and correlation between the modalities. In an exploratory analysis, we further show that the biomarkers identified by our model are closely associated with Alzheimer's disease. Our proposed approach is applicable to other diseases with multimodal data available. However, the limited size of medical datasets may restrict the effectiveness and generalization ability of such deep learning models. To address this issue, a potential future direction is to employ pre-training and transfer learning techniques that facilitate learning across datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. An overview of the proposed framework. X1, • • • , X4 are input modality data, and Y is the label information. DNNs first operate on each modality, generating hidden representations for each modality. These hidden representations go through a selfattention mechanism generating improved self-attention representations. At the same time, the hidden representations and label Y are multiplied by individual projection matrices U1, . . . , U4, Uy based on CCA, thus mapping them to a shared representation G. Finally, the disease prediction is calculated by self-attention representations with projection matrices and shared representation G.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .Fig. 3 .</head><label>23</label><figDesc>Fig. 2. Top 20 discriminative ROIs identified by ADCCA from three brain imaging modalities for three different classification groups in lateral, medial, and ventral view. The color bar indicates the importance score. The commonly selected ROIs across different modalities are circled in blue. (Color figure online)</figDesc><graphic coords="7,95,46,310,01,287,80,70,69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Sensitivity analysis of hyperparameters on AD vs. HC</figDesc><graphic coords="8,44,79,512,66,334,42,64,48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Classification performance comparison. The best results are in bold.</figDesc><table><row><cell>Task</cell><cell cols="2">Measures DNN</cell><cell>GCCA</cell><cell>DGCCA</cell><cell>MTSCCALR SDGCCA ADCCA</cell></row><row><cell cols="2">AD vs. HC ACC</cell><cell cols="4">.866 ± .037 .812 ± .037 .837 ± .028 .828 ± .047</cell><cell>.914 ± .029 .932 ± .010</cell></row><row><cell></cell><cell>F1</cell><cell cols="4">.873 ± .049 .811 ± .054 .833 ± .041 .862 ± .046</cell><cell>.883 ± .034 .901 ± .025</cell></row><row><cell></cell><cell>AUC</cell><cell cols="4">.943 ± .030 .930 ± .015 .939 ± .013 .893 ± .051</cell><cell>.978 ± .013 .979 ± .015</cell></row><row><cell></cell><cell>MCC</cell><cell cols="4">.720 ± .080 .652 ± .079 .688 ± .060 .629 ± .087</cell><cell>.822 ± .057 .895 ± .043</cell></row><row><cell cols="2">AD vs. MCI ACC</cell><cell cols="4">.689 ± .035 .618 ± .059 .638 ± .017 .746 ± .049</cell><cell>.812 ± .063 .825 ± .011</cell></row><row><cell></cell><cell>F1</cell><cell cols="4">.579 ± .032 .583 ± .038 .535 ± .037 .679 ± .041</cell><cell>.683 ± .079 .823 ± .032</cell></row><row><cell></cell><cell>AUC</cell><cell cols="4">.811 ± .025 .726 ± .050 .756 ± .022 .836 ± .039</cell><cell>.880 ± .043 .925 ± .050</cell></row><row><cell></cell><cell>MCC</cell><cell cols="4">.413 ± .046 .256 ± .054 .281 ± .048 .482 ± .104</cell><cell>.569 ± .110 .625 ± .024</cell></row><row><cell cols="2">MCI vs. HC ACC</cell><cell cols="4">.523 ± .026 .499 ± .024 .519 ± .044 .594 ± .029</cell><cell>.647 ± .058 .758 ± .033</cell></row><row><cell></cell><cell>F1</cell><cell cols="4">.529 ± .031 .543 ± .084 .513 ± .044 .513 ± .025</cell><cell>.702 ± .058 .799 ± .030</cell></row></table><note><p>AUC .570 ± .030 .540 ± .032 .574 ± .054 .637 ± .022 .796 ± .074 .816 ± .051 MCC .103 ± .058 .105 ± .075 .109 ± .100 .172 ± .045 .273 ± .110 .407 ± .073</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Classification performance comparison with and without Lcor and L cls .010 .901 ± .025 .979 ± .015 .895 ± .043 (w/o) L cor .924 ± .025 .892 ± .034 .963 ± .016 .837 ± .067 (w/o) L cls .876 ± .037 .853 ± .029 .928 ± .020 .791 ± .058 AD vs. MCI ADCCA .825 ± .011 .823 ± .032 .925 ± .050 .625 ± .024 (w/o) L cor .806 ± .029 .795 ± .032 .897 ± .048 .589 ± .033 (w/o) L cls .758 ± .059 .723 ± .038 .856 ± .050 .466 ± .054 MCI vs. HC ADCCA .758 ± .033 .799 ± .030 .816 ± .051 .407 ± .073 (w/o) L cor .692 ± .033 .713 ± .056 .761 ± .072 .317 ± .092 (w/o) L cls .619 ± .024 .683 ± .084 .599 ± .032 .176 ± .075</figDesc><table><row><cell>Task</cell><cell>Method</cell><cell>ACC</cell><cell>F1</cell><cell>AUC</cell><cell>MCC</cell></row><row><cell cols="2">AD vs. HC ADCCA</cell><cell>.932 ±</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>www.alzgene.org.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This work is partially supported by the <rs type="funder">National Science Foundation</rs> (<rs type="grantNumber">MRI-2215789</rs> and <rs type="grantNumber">IIS-1909879</rs>), <rs type="funder">National Institutes of Health</rs> (<rs type="grantNumber">U01AG068057</rs>, <rs type="grantNumber">U01AG-066833</rs>, <rs type="grantNumber">R01LM013463</rs>, <rs type="grantNumber">R01MH129694</rs>, and <rs type="grantNumber">R21MH130956</rs>), Alzheimer's <rs type="grantName">Association grant</rs> (<rs type="grantNumber">AARG-22-972541</rs>), and Lehigh's grants under <rs type="funder">Accelerator</rs> (<rs type="grantNumber">S00010293</rs>), <rs type="funder">CORE</rs> (<rs type="grantNumber">001250</rs>), and <rs type="funder">FIG</rs> ( <rs type="grantNumber">FIGAWD35</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_mc984GB">
					<idno type="grant-number">MRI-2215789</idno>
				</org>
				<org type="funding" xml:id="_tYPWYfE">
					<idno type="grant-number">IIS-1909879</idno>
				</org>
				<org type="funding" xml:id="_jhgVgCa">
					<idno type="grant-number">U01AG068057</idno>
				</org>
				<org type="funding" xml:id="_jSPwp2J">
					<idno type="grant-number">U01AG-066833</idno>
				</org>
				<org type="funding" xml:id="_QNYcgNH">
					<idno type="grant-number">R01LM013463</idno>
				</org>
				<org type="funding" xml:id="_sBg7Q5e">
					<idno type="grant-number">R01MH129694</idno>
				</org>
				<org type="funding" xml:id="_Xky4SDb">
					<idno type="grant-number">R21MH130956</idno>
					<orgName type="grant-name">Association grant</orgName>
				</org>
				<org type="funding" xml:id="_CedKxDJ">
					<idno type="grant-number">AARG-22-972541</idno>
				</org>
				<org type="funding" xml:id="_N8qrzDB">
					<idno type="grant-number">S00010293</idno>
				</org>
				<org type="funding" xml:id="_rPyW8mc">
					<idno type="grant-number">001250</idno>
				</org>
				<org type="funding" xml:id="_FvxeXHk">
					<idno type="grant-number">FIGAWD35</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Voxel-based morphometry-the methods</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ashburner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="805" to="821" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Stage-wise training: An improved feature learning strategy for deep models</title>
		<author>
			<persName><forename type="first">E</forename><surname>Barshan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fieguth</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Feature extraction: modern questions and challenges</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="49" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Probabilistic modeling of imaging, genetics and diagnosis</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Batmanghelich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dalca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Quon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sabuncu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Golland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1765" to="1779" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep generalized canonical correlation analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Benton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Khayrallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gujral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Reisinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Arora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Workshop on Representation Learning for NLP</title>
		<meeting>the 4th Workshop on Representation Learning for NLP</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
	<note>RepL4NLP-2019</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A novel bio-inspired strategy to prevent amyloidogenesis and synaptic damage in Alzheimer&apos;s disease</title>
		<author>
			<persName><forename type="first">M</forename><surname>Catania</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Psych</title>
		<imprint>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The advantages of the Matthews correlation coefficient (mcc) over f1 score and accuracy in binary classification evaluation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chicco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Jurman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Genomics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A tutorial on the crossentropy method</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>De Boer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kroese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mannor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Y</forename><surname>Rubinstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="page" from="19" to="67" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Identifying diagnosis-specific genotype-phenotype associations via joint multitask sparse canonical correlation analysis and classification</title>
		<author>
			<persName><forename type="first">L</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="371" to="379" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Detecting genetic associations with brain imaging phenotypes in Alzheimer&apos;s disease via a novel structured SCCA approach</title>
		<author>
			<persName><forename type="first">L</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page">101656</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Bridging imaging, genetics, and diagnosis in a coupled lowdimensional framework</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ghosal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer Assisted Intervention -MICCAI 2019: 22nd International Conference</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</editor>
		<meeting><address><addrLine>Shenzhen, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">October 13-17, 2019</date>
			<biblScope unit="page" from="647" to="655" />
		</imprint>
	</monogr>
	<note>Proceedings, Part IV</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Cham</forename><surname>Springer</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-32251-9_71</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-32251-9_71" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A biologically interpretable graph convolutional network to link genetic risk pathways and imaging phenotypes of disease</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ghosal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Relations between two sets of variates</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hotelling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3/4</biblScope>
			<biblScope unit="page" from="321" to="377" />
			<date type="published" when="1936">1936</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Adaptive sparse multiple canonical correlation analysis with application to imaging (epi) genomics study of schizophrenia</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="390" to="399" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Genome-wide meta-analysis identifies new loci and functional pathways influencing Alzheimer&apos;s disease risk</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">E</forename><surname>Jansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="404" to="413" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Canonical analysis of several sets of variables</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Kettenring</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="433" to="451" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multi-task learning based structured sparse canonical correlation analysis for brain imaging genetics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page">102297</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Captum: A unified and generic model interpretability library for pytorch</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kokhlikyan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.07896</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A review of multivariate analyses in imaging genetics</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">D</forename><surname>Calhoun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Neuroinform</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">29</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">SDGCCA: supervised deep generalized canonical correlation analysis for multi-omics integration</title>
		<author>
			<persName><forename type="first">S</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="892" to="907" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Adult hippocampal neurogenesis and its role in Alzheimer&apos;s disease</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">H</forename><surname>Gage</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Neurodegener</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The Alzheimer&apos;s disease neuroimaging initiative</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimaging Clin</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="869" to="877" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Brain imaging genetics: integrated analysis and machine learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Bioinformatics and Biomedicine (BIBM)</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="1" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Automated anatomical labeling of activations in SPM using a macroscopic anatomical parcellation of the MNI MRI single-subject brain</title>
		<author>
			<persName><forename type="first">N</forename><surname>Tzourio-Mazoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="273" to="289" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inform. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">The integration of neuroimaging and molecular genetics in the study of developmental cognitive neuroscience</title>
		<author>
			<persName><forename type="first">E</forename><surname>Viding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">E</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Hariri</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Machine learning for brain imaging genomics methods: a review</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">K</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Q</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Intell. Res</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="57" to="78" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A review of imaging genetics in Alzheimer&apos;s disease</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Clin. Neurosci</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page" from="155" to="163" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Sparse interpretation of graph convolutional networks for multi-modal diagnosis of Alzheimer&apos;s disease</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16452-1_45</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16452-1_45" />
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer Assisted Intervention -MICCAI 2022: 25th International Conference</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Singapore; Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">September 18-22, 2022. 2022</date>
			<biblScope unit="page" from="469" to="478" />
		</imprint>
	</monogr>
	<note>Proceedings, Part VIII</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Graphene and graphene oxide: synthesis, properties, and applications</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Mater</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">35</biblScope>
			<biblScope unit="page" from="3906" to="3924" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
