<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Longitudinal Multimodal Transformer Integrating Imaging and Latent Clinical Signatures from Routine EHRs for Pulmonary Nodule Classification</title>
				<funder ref="#_JtMH5CY #_ztk5azg">
					<orgName type="full">Vanderbilt Institute for Clinical and Translational Research</orgName>
				</funder>
				<funder ref="#_rjkbbJN">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder ref="#_gKWq7sw">
					<orgName type="full">National Institutes of Health</orgName>
					<orgName type="abbreviated">NIH</orgName>
				</funder>
				<funder ref="#_PGFTAFB">
					<orgName type="full">ViSE</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Thomas</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
							<email>thomas.z.li@vanderbilt.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Biomedical Engineering</orgName>
								<orgName type="institution">Vanderbilt University</orgName>
								<address>
									<postCode>37212</postCode>
									<settlement>Nashville</settlement>
									<region>TN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">John</forename><forename type="middle">M</forename><surname>Still</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Biomedical Informatics</orgName>
								<orgName type="institution">Vanderbilt University</orgName>
								<address>
									<postCode>37212</postCode>
									<settlement>Nashville</settlement>
									<region>TN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kaiwen</forename><surname>Xu</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">Vanderbilt University</orgName>
								<address>
									<postCode>37212</postCode>
									<settlement>Nashville</settlement>
									<region>TN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ho</forename><forename type="middle">Hin</forename><surname>Lee</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">Vanderbilt University</orgName>
								<address>
									<postCode>37212</postCode>
									<settlement>Nashville</settlement>
									<region>TN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Leon</forename><forename type="middle">Y</forename><surname>Cai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Biomedical Engineering</orgName>
								<orgName type="institution">Vanderbilt University</orgName>
								<address>
									<postCode>37212</postCode>
									<settlement>Nashville</settlement>
									<region>TN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aravind</forename><forename type="middle">R</forename><surname>Krishnan</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Electrical and Computer Engineering</orgName>
								<orgName type="institution">Vanderbilt University</orgName>
								<address>
									<postCode>37212</postCode>
									<settlement>Nashville</settlement>
									<region>TN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Riqiang</forename><surname>Gao</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Digital Technology and Innovation</orgName>
								<orgName type="institution">Siemens Healthineers</orgName>
								<address>
									<postCode>08540</postCode>
									<settlement>Princeton</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mirza</forename><forename type="middle">S</forename><surname>Khan</surname></persName>
							<affiliation key="aff5">
								<orgName type="institution">Saint Luke&apos;s Mid America Heart Institute</orgName>
								<address>
									<postCode>64111</postCode>
									<settlement>Kansas City</settlement>
									<region>MO</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sanja</forename><surname>Antic</surname></persName>
							<affiliation key="aff6">
								<orgName type="institution">Vanderbilt University Medical Center</orgName>
								<address>
									<postCode>37235</postCode>
									<settlement>Medicine, Nashville</settlement>
									<region>TN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><surname>Kammer</surname></persName>
							<affiliation key="aff6">
								<orgName type="institution">Vanderbilt University Medical Center</orgName>
								<address>
									<postCode>37235</postCode>
									<settlement>Medicine, Nashville</settlement>
									<region>TN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kim</forename><forename type="middle">L</forename><surname>Sandler</surname></persName>
							<affiliation key="aff7">
								<orgName type="department">Radiology</orgName>
								<orgName type="institution">Vanderbilt University Medical Center</orgName>
								<address>
									<postCode>37235</postCode>
									<settlement>Nashville</settlement>
									<region>TN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fabien</forename><surname>Maldonado</surname></persName>
							<affiliation key="aff6">
								<orgName type="institution">Vanderbilt University Medical Center</orgName>
								<address>
									<postCode>37235</postCode>
									<settlement>Medicine, Nashville</settlement>
									<region>TN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bennett</forename><forename type="middle">A</forename><surname>Landman</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Biomedical Engineering</orgName>
								<orgName type="institution">Vanderbilt University</orgName>
								<address>
									<postCode>37212</postCode>
									<settlement>Nashville</settlement>
									<region>TN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">Vanderbilt University</orgName>
								<address>
									<postCode>37212</postCode>
									<settlement>Nashville</settlement>
									<region>TN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Electrical and Computer Engineering</orgName>
								<orgName type="institution">Vanderbilt University</orgName>
								<address>
									<postCode>37212</postCode>
									<settlement>Nashville</settlement>
									<region>TN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff7">
								<orgName type="department">Radiology</orgName>
								<orgName type="institution">Vanderbilt University Medical Center</orgName>
								<address>
									<postCode>37235</postCode>
									<settlement>Nashville</settlement>
									<region>TN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><forename type="middle">A</forename><surname>Lasko</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Biomedical Informatics</orgName>
								<orgName type="institution">Vanderbilt University</orgName>
								<address>
									<postCode>37212</postCode>
									<settlement>Nashville</settlement>
									<region>TN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">Vanderbilt University</orgName>
								<address>
									<postCode>37212</postCode>
									<settlement>Nashville</settlement>
									<region>TN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Longitudinal Multimodal Transformer Integrating Imaging and Latent Clinical Signatures from Routine EHRs for Pulmonary Nodule Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A59E228CEC1FC409E6016C19EF808B89</idno>
					<idno type="DOI">10.1007/978-3-031-43895-061.</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-24T10:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Multimodal Transformers</term>
					<term>Latent Clinical Signatures</term>
					<term>Pulmonary Nodule Classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The accuracy of predictive models for solitary pulmonary nodule (SPN) diagnosis can be greatly increased by incorporating repeat imaging and medical context, such as electronic health records (EHRs). However, clinically routine modalities such as imaging and diagnostic codes can be asynchronous and irregularly sampled over different time scales which are obstacles to longitudinal multimodal learning. In this work, we propose a transformer-based multimodal strategy to integrate repeat imaging with longitudinal clinical signatures from routinely collected EHRs for SPN classification. We perform unsupervised disentanglement of latent clinical signatures and leverage time-distance scaled self-attention to jointly learn from clinical signatures expressions and chest computed tomography (CT) scans. Our classifier is pretrained on 2,668 scans from a public dataset and 1,149 subjects with longitudinal chest CTs, billing codes, medications, and laboratory tests from EHRs of our home institution. Evaluation on 227 subjects with challenging SPNs revealed a significant AUC improvement over a longitudinal multimodal baseline (0.824 vs 0.752 AUC), as well as improvements over a single cross-section multimodal scenario (0.809 AUC) and a longitudinal imaging-only scenario (0.741 AUC). This work demonstrates significant advantages with a novel approach for co-learning longitudinal</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The absence of highly accurate and noninvasive diagnostics for risk-stratifying benign vs malignant solitary pulmonary nodules (SPNs) leads to increased anxiety, costs, complications, and mortality <ref type="bibr" target="#b21">[22,</ref><ref type="bibr">26]</ref>. The use of noninvasive methods to discriminate malignant from benign SPNs is a high-priority public health initiative <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref>. Deep learning approaches have shown promise in classifying SPNs from longitudinal chest computed tomography (CT) <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b20">21]</ref>, but approaches that only consider imaging are fundamentally limited. Multimodal models generally outperform single modality models in disease diagnosis and prediction <ref type="bibr" target="#b23">[24]</ref>, and this is especially true in lung cancer which is heavily contextualized through non-imaging risk factors <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr">30]</ref>. Taken together, these findings suggest that learning across both time and multiple modalities is important in biomedical predictive modeling, especially SPN diagnosis. However, such an approach that scales across longitudinal multimodal data from comprehensive representations of the clinical routine has yet to be demonstrated <ref type="bibr" target="#b23">[24]</ref>. Related Work. Directly learning from routinely collected electronic health records (EHRs) is challenging because observations within and between modalities can be sparse and irregularly sampled. Previous studies overcome these challenges by aggregating over visits and binning time series within a Bidirectional Encoder Representations from Transformers (BERT) architecture <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b24">25]</ref>, limiting their scope to data collected on similar time scales, such as ICU measurements, <ref type="bibr" target="#b10">[11,</ref><ref type="bibr">29]</ref>, or leveraging graph guided transformers to handle asynchrony <ref type="bibr">[33]</ref>. Self-attention [31] has become the dominant technique for learning powerful representations of EHRs with trade-offs in interpretability and quadratic scaling with the number of visits or bins, which can be inefficient with data spanning multiple years. In contrast, others address the episodic nature of EHRs by converting non-imaging variables to continuous longitudinal curves that provide the instantaneous value of categorical variables as intensity functions <ref type="bibr" target="#b16">[17]</ref> or continuous variables as latent functions <ref type="bibr" target="#b15">[16]</ref>. Operating with the hypothesis that distinct disease mechanisms manifest independently of one another in a probabilistic manner, one can learn a transformation that disentangles latent sources, or clinical signatures, from these longitudinal curves. Clinical signatures learned in this way are expert-interpretable and have been well-validated to reflect known pathophysiology across many diseases <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b17">18]</ref>. Given that several clinical risk factors have been shown to independently contribute to lung cancer risk, these signatures are well poised for this predictive task. Despite the wealth of studies seeking to learn comprehensive representations of routine EHRs, these techniques have not been combined with longitudinal imaging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Present Work.</head><p>In this work, we jointly learn from longitudinal medical imaging, demographics, billing codes, medications, and lab values to classify SPNs. We converted 9195 non-imaging event streams from the EHR to longitudinal curves to impute cross-sections and synchronize across modalities. We use Independent Component Analyses (ICA) to disentangle latent clinical signatures from these curves, with the hypothesis that the disease mechanisms known to be important for SPN classification can also be captured with probabilistic independence. We leverage a transformer-based encoder to fuse features from both longitudinal imaging and clinical signature expressions sampled at intervals ranging from weeks to up to five years. Due to the importance of time dynamics in SPN classification, we use the time interval between samples to scale self-attention with the intuition that recent observations are more important to attend to than older observations. Compared with imaging-only and a baseline that aggregates longitudinal data into bins, our approach allowed us to incorporate additional modalities from routinely collected EHRs, which led to improved SPN classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>Latent Clinical Signatures via Probabilistic Independence. We obtained event streams for billing codes, medications, and laboratory tests across the full record of each subject in our EHR cohorts (up to 22 years). After removing variables with less than 1000 events and mapping billing codes to the SNOMED-CT ontology <ref type="bibr" target="#b6">[7]</ref>, we arrived at 9195 unique variables. We transformed each variable to a longitudinal curve at daily resolution, estimating the variable's instantaneous value for each day <ref type="bibr" target="#b17">[18]</ref>. We used smooth interpolation for continuous variables <ref type="bibr" target="#b3">[4]</ref> or a continuous estimate of event density per time for event data. Previous work used Gaussian process inference to compute both types of curves <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>. For this work we traded approximation for computational efficiency. To encode a limited memory into the curve values, each curve was smoothed using a rolling uniform mean of the past 365 d (Fig. <ref type="figure" target="#fig_0">1,</ref><ref type="figure">left</ref>).</p><p>We use an ICA model to estimate a linear decomposition of the observed curves from the EHR-Pulmonary cohort to independent latent sources, or clinical signatures. Formally, we have dataset D EHR-Pulmonary = {L k | k = 1, . . . , n} with longitudinal curves denoted as L k = {l i |i = 1, . . . , 9195}. We randomly sample l i ∀i ∈ <ref type="bibr" target="#b0">[1,</ref><ref type="bibr">9195]</ref> at a three-year resolution and concatenate samples across all subjects as x i ∈ R m . For D EHR-Pulmonary , m was empirically found to be 630037. We make a simplifying assumption that x i is a linear mixture of c latent sources, s, with longitudinal expression levels e ∈ R m : The linear mixture is then X = SE with x i forming the rows of X, S ∈ R 9195×c denoting the independent latent sources and E ∈ R c×m denoting the expression matrix. We set c = 2000 and estimated S in an unsupervised manner using FastICA <ref type="bibr" target="#b12">[13]</ref>. Given longitudinal curves for another cohort, for instance D Image-EHR = {X k | k = 1, . . . , n}, we obtain expressions of clinical signatures for subject k via E k = S -1 X k (Fig. <ref type="figure" target="#fig_0">1</ref>, left).</p><formula xml:id="formula_0">x i = e 1 s i,1 + e 2 s i,2 + . . . + e c s i,c<label>(1)</label></formula><p>Longitudinal Multimodal Transformer (TDSig). We represent our multimodal datasets D Image-EHR and }, where T is the maximum sequence length. We set T = 3 and added a fixed padding embedding to represent missing items in the sequence. Embeddings that incorporate positional and segment information are computed for each item in the sequence (Fig. <ref type="figure" target="#fig_0">1</ref>, right). Token embeddings for images are a convolutional embeddings of five concatenated 3D patches proposed by a pretrained SPN detection model <ref type="bibr" target="#b20">[21]</ref>. We use a 16-layer ResNet <ref type="bibr" target="#b9">[10]</ref> to compute this embedding. Likewise, token embeddings for clinical signature expressions are linear transformations to the same dimension as imaging token embeddings. The sequence of embeddings are then passed through a multi-headed Transformer. All embeddings except the nodule detection model are co-optimized with the Transformer. We will refer to this approach as TDSig.</p><formula xml:id="formula_1">D Image-EHR-SPN = {(E k , G k ) | k = 1, . . . ,</formula><p>Time-Distance Self-attention. Following <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr">32]</ref>, we intuit that if medical data is sampled as a cross-sectional manifestation of a continuously progressing phenotype, we can use a temporal emphasis model (TEM) emphasize the importance of recent observations over older ones. Additionally, self-attention is masked for padded embeddings, allowing our approach to scale with varying sequence lengths across subjects. Formally, if subject k has a sequence of T images at relative acquisition days t 1 . . . t T , we construct a matrix R of relative times with entries R i,j = |t T -t i | where t i is the acquisition day of tokens êk,i and ĝk,i , or 0 if they are padded embeddings. We map the relative times in R to a [0,1] value in R using a TEM of the form:</p><formula xml:id="formula_2">Ri,j = TEM(R i,j ) = 1 1 + exp(bR i,j -c) (2)</formula><p>This is a flipped sigmoid function that monotonically decreases with the relative time from the most recent observation. Its slope of decline and decline offset are governed by learnable non-negative parameters b and c respectively. A separate TEM is instantiated for each attention head, with the rationale that separate attention heads can learn to condition on time differently. The transformer encoder computes query, key, and value matrices as linear transformations of input embedding H = { Ê Ĝ} at attention head p</p><formula xml:id="formula_3">Q p = H p W Q p K p = H p W K p V p = H p W V p</formula><p>TEM-scaled self-attention is computed via element-wise multiplication of the query-key product and R:</p><formula xml:id="formula_4">softmax ReLU(Q p K p + M ) • R √ d V p (<label>3</label></formula><formula xml:id="formula_5">)</formula><p>where M is the padding mask [31] and d is the dimension of the query and key matrices. ReLU gating of the query-key product allows the TEM to adjust the attention weights in an unsigned direction.</p><p>Baselines. We compared against a popular multimodal strategy that aggregates event streams into a sequence of bins as opposed to our method of extracting instantaneous cross-sectional representations. For each scan, we computed a TF-IDF [27] weighted vector from all billing codes occurring up to one year before the scan acquisition date. We passed this through a published Word2Vec-based medical concept embedding <ref type="bibr" target="#b2">[3]</ref> to compute a contextual representation ∈ R 100 . This, along with the subject's scans, formed a sequence that was used as input to a model we call TDCode2vec. Our search for contextual embeddings for medications and laboratory values did not yield any robust published models that were compatible with our EHR's nomenclature, so these were not included in TDCode2vec. We also performed experiments using only image sequences as input, which we call TDImage. Finally, we implemented single cross-sectional versions of TDImage, TDCode2vec, and TDSig, CSImage, CSCode2vec, and CSSig respectively, using the scan date closest to the lung malignancy diagnosis for cases or SPN date for controls. All baselines except CSImage, which employed a multi-layer perceptron directly after the convolutional embedding, used the same architecture and time-distance self-attention as TDSig. The transformer encoders in this study were standardized to 4 heads, 4 blocks, input token size of 320, multi-layer perception size of 124, self-attention weights of size 64. This work was supported by Pytorch 1.13.1, CUDA 11.7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Setup</head><p>Datasets. This study used an imaging-only cohort from the NLST [28] and three multimodal cohorts from our home institution with IRB approval (Table <ref type="table" target="#tab_1">1</ref>). For the NLST cohort (https://cdas.cancer.gov/nlst/), we identified cases who had a biopsy-confirmed diagnosis of lung malignancy and controls who had a positive screening result for an SPN but no lung malignancy. We randomly sampled from the control group to obtain a 4:6 case control ratio. Next, EHR-Pulmonary was the unlabeled dataset used to learn clinical signatures in an unsupervised manner. We searched all records in our EHR archives for patients who had billing codes from a broad set of pulmonary conditions, intending to capture pulmonary conditions beyond just malignancy. Additionally, Image-EHR was a labeled dataset with paired imaging and EHRs. We searched our institution's imaging archive for patients with three chest CTs within five years. In the EHR-Image cohort, malignant cases were labeled as those with a billing code for lung malignancy and no cancer of any type prior. Importantly, this case criteria includes metastasis from cancer in non-lung locations. Benign controls were those who did not meet this criterion. Finally, Image-EHR-SPN was a subset of Image-EHR with the inclusion criteria that subjects had a billing code for an SPN and no cancer of any type prior to the SPN. We labeled malignant cases as those with a lung malignancy billing code occurring within three years after any scan and only used data collected before the lung malignancy code. All data within the five-year period were used for controls. We removed all billing codes relating to lung malignancy. A description of the billing codes used to define SPN and lung cancer events are provided in Supplementary 1.2. Training and Validation. All models were pretrained with the NLST cohort after which we froze the convolutional embedding layer. While this was the only pretraining step for image-only models (CSImage and TDimage), the multimodal models underwent another stage of pretraining using the Image-EHR cohort with subjects from Image-EHR-SPN subtracted. In this stage, we randomly selected one scan and the corresponding clinical signature expressions for each subject and each training epoch. Models were trained until the running mean over 100 global steps of the validation loss increased by more than 0.2. For evaluation, we performed five-fold cross-validation with Image-EHR-SPN, using up to three of the most recent scans in the longitudinal models. We report the mean AUC and 95% confidence interval from 1000 bootstrapped samples, sampling with replacement from the pooled predictions across all test folds. A two-sided Wilcoxon signed-rank test was used to test if differences in mean AUC between models were significant.</p><p>Reclassification Analysis. We performed a reclassification analysis of low, medium, and high-risk tiers separated by thresholds of 0.05 and 0.65, which are the cutoffs used to guide clinical management. Given a baseline comparison, our approach reclassifies a subject correctly if it predicts a higher risk tier than the baseline in cases, or a lower risk tier than the baseline in controls (Fig. <ref type="figure" target="#fig_1">2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>The significant improvement with TDSig over CSSig demonstrates the advantage of longitudinally in the context of combining images and clinical signatures (Table <ref type="table" target="#tab_2">2</ref>). There were large performance gaps between TDSig and TDCode2vec, as well as between CSSig and CSCode2vec, demonstrating the advantage of  clinical signatures over a binned embedding strategy. Cross-sectional embedded billing codes did not significantly improve performance over images alone (CSCode2vec vs CSImage, p = 0.56), but adding clinical signatures did (CSSig vs CSImage, p &lt; 0.01; TDSig vs TDImage, p &lt; 0.01) and the greatest improvement in longitudinal data over single cross sections occurred when clinical signatures were included. For control subjects, TDSig correctly/incorrectly reclassified 40/18 from TDCode2vec, 54/8 from TDImage, 12/18 from CSSig, 104/7 from CSCode2vec, and 125/5 from CSImage. For case subjects, TDSig correctly/incorrectly reclassified 13/10 from TDCode2vec, 17/8 from TDImage, 12/2 from CSSig, 23/16 from CSCode2vec, and 29/16 from CSImage (Fig. <ref type="figure" target="#fig_1">2</ref>). Full reclassification matrices are reported in Supplementary 6.1. On qualitative inspection of a control subject, clinical signatures likely added clarity to benign imaging findings that were difficult for baseline approaches to classify (Fig. <ref type="figure" target="#fig_2">3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion and Conclusion</head><p>This work presents a novel transformer-based strategy for integrating longitudinal imaging with interpretable clinical signatures learned from comprehensive multimodal EHRs. We demonstrated large performance gains in SPN classification compared with baselines, although calibration of our models is needed to assess clinical utility. We evaluated on clinically-billed SPNs, meaning that clinicians likely found these lesions difficult enough to conduct a clinical workup. In this setting, we found that adding clinical context increased the performance gap between longitudinal data and single cross-sections. Our clinical signatures incorporated longitudinality and additional modalities to build a better representation of clinical context than binned embeddings. We release our implementation at https://github.com/MASILab/lmsignatures.</p><p>The lack of longitudinal multimodal datasets has long been a limiting factor <ref type="bibr" target="#b23">[24]</ref> in conducting studies such as ours. One of our contributions is demonstrating training strategies in a small-dataset, incomplete-data regime. We were able to overcome our small cohort size (Image-EHR-SPN) by leveraging unsupervised learning on datasets without imaging (EHR-Pulmonary), pretraining on public datasets without EHRs (NLST), and pretraining on paired multimodal data with noisy labels (Image-EHR) within a flexible transformer architecture.</p><p>Our approach of sampling cross-sections where clinical decisions are likely to be made scales well with long, multi-year observation windows, which may not be true for BERT-based embeddings <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b24">25]</ref>. We did not compare against these contextual embeddings because none have been publically released, but integrating these with longitudinal imaging is an area of future investigation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. Left: Event streams for non-imaging variables are transformed into longitudinal curves. ICA learns independent latent signatures, S, in an unsupervised manner on a large non-imaging cohort. Right: Subject k's expressions of the signatures, E k , are sampled at scan dates. Input embeddings are the sum of 1) token embedding derived from signatures or imaging, 2) a fixed positional embedding indicating the token's position in the sequence, and 3) a learnable segment embedding indicating imaging or non-imaging modality. The time interval between scans is used to compute a timedistance scaled self-attention. This is a flexible approach that handles asynchronous modalities, incompleteness over varying sequence lengths, and irregular time intervals.</figDesc><graphic coords="4,44,79,54,47,331,63,112,24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. A comparison of median and interquartile range of predicted probabilities reveals that TDSig is more correctly confident than baselines. Blue and red indicate subjects that were correctly and incorrectly reclassified by TDSig respectively. When compared to these baselines, TDSig is more often reclassifying correctly than not. (Color figure online)</figDesc><graphic coords="7,63,09,61,07,332,32,101,20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. This is a control subject who developed a lesion over 3 months (a), to which the imaging-only approaches assigned a cancer probability of 0.4 (c). However, the subject's highest expressed clinical signature at the 3-month mark was a new pattern of bacterial pneumonia (b), offering to the model a benign explanation of an image that it would otherwise be less correctly confident in.</figDesc><graphic coords="8,63,81,198,62,296,95,122,92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Breakdown of modalities, size, and longitudinality of each dataset.</figDesc><table><row><cell></cell><cell>Modalities</cell><cell></cell><cell></cell><cell>Counts (cases/controls)</cell></row><row><cell></cell><cell cols="4">Demo Img Code Med Lab Subjects Scans</cell></row><row><cell>EHR-Pulmonary</cell><cell>-</cell><cell></cell><cell></cell><cell>288,428 -</cell></row><row><cell>NLST</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>533/801 1066/1602</cell></row><row><cell>Image-EHR</cell><cell></cell><cell></cell><cell></cell><cell>257/665 641/1624</cell></row><row><cell>Image-EHR-SPN</cell><cell></cell><cell></cell><cell></cell><cell>58/169 76/405</cell></row><row><cell cols="5">Demo: Demographics, Img: Chest CTs, Code: ICD billing codes,</cell></row><row><cell cols="3">Med: Medications, Lab: Laboratory tests.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Performance on SPN classification using different approaches and modalities.</figDesc><table><row><cell></cell><cell></cell><cell>Modalities</cell><cell></cell><cell></cell><cell></cell><cell>Pretrain</cell></row><row><cell></cell><cell>Mean AUC [95% CI]</cell><cell cols="5">Img Demo Code Med Lab NLST Image-EHR</cell></row><row><cell>CSImage</cell><cell>0.7392 [0.7367, 0.7416]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">CSCode2vec 0.7422 [0.7398, 0.7447]</cell><cell></cell><cell></cell><cell>-</cell><cell>-</cell><cell></cell></row><row><cell>CSSig</cell><cell>0.8097 [0.8075, 0.8120]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>TDImage</cell><cell>0.7406 [0.7381, 0.7432]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">TDCode2vec 0.7524 [0.7499, 0.7550]</cell><cell></cell><cell></cell><cell>-</cell><cell>-</cell><cell></cell></row><row><cell>TDSig</cell><cell>0.8238 [0.8216, 0.8260]*</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">* : p &lt; 0.01 against all other methods.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This research was funded by the <rs type="funder">NIH</rs> through <rs type="grantNumber">R01CA253923-02</rs> and in part by <rs type="funder">NSF</rs> <rs type="grantNumber">CAREER 1452485</rs> and <rs type="grantNumber">NSF 2040462</rs>. This research is also supported by <rs type="funder">ViSE</rs> through <rs type="grantNumber">T32EB021937-07</rs> and the <rs type="funder">Vanderbilt Institute for Clinical and Translational Research</rs> through <rs type="grantNumber">UL1TR002243-06</rs>. We thank the <rs type="institution">National Cancer Institute</rs> for providing data collected through the NLST.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_gKWq7sw">
					<idno type="grant-number">R01CA253923-02</idno>
				</org>
				<org type="funding" xml:id="_rjkbbJN">
					<idno type="grant-number">CAREER 1452485</idno>
				</org>
				<org type="funding" xml:id="_PGFTAFB">
					<idno type="grant-number">NSF 2040462</idno>
				</org>
				<org type="funding" xml:id="_JtMH5CY">
					<idno type="grant-number">T32EB021937-07</idno>
				</org>
				<org type="funding" xml:id="_ztk5azg">
					<idno type="grant-number">UL1TR002243-06</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">End-to-end lung cancer screening with three-dimensional deep learning on low-dose chest computed tomography</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ardila</surname></persName>
		</author>
		<ptr target="https://www.nature.com/articles/s41591-019-0447-x" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">RETAIN: an interpretable predictive model for healthcare using reverse time attention mechanism</title>
		<author>
			<persName><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Bahadori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kulas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schuetz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Stewart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Exploiting hierarchy in medical concept embedding</title>
		<author>
			<persName><forename type="first">A</forename><surname>Finch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMIA Open</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">22</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A method for constructing local monotone piecewise cubic interpolants</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">N</forename><surname>Fritsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Butland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Sci. Stat. Comput</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="300" to="304" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Time-distanced gates in long short-term memory networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page">101785</biblScope>
			<date type="published" when="2020">101785. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep multi-path network integrating incomplete biomarker and chest CT data for evaluating lung cancer risk</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Imaging 2021: Image Processing</title>
		<imprint>
			<publisher>SPIE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">11596</biblScope>
			<biblScope unit="page" from="387" to="393" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Use of the Systematized Nomenclature of Medicine Clinical Terms (SNOMED CT) for Processing Free Text in Health Care: Systematic Scoping Review</title>
		<author>
			<persName><forename type="first">C</forename><surname>Gaudet-Blavignac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Foufi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bjelogrlic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lovis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Med. Internet Res</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">24594</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Prevalence and variables associated with solitary pulmonary nodules in a routine clinic-based population: a cross-sectional study</title>
		<author>
			<persName><forename type="first">N</forename><surname>Gómez-Sáez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. Radiol</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2174" to="2182" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Recent trends in the identification of incidental pulmonary nodules</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Gould</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Respir. Crit. Care Med</title>
		<imprint>
			<biblScope unit="volume">192</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1208" to="1214" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Altosaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.05342</idno>
		<title level="m">Clinicalbert: Modeling clinical notes and predicting hospital readmission</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Prediction of lung cancer risk at follow-up screening with lowdose CT: a training and validation study of a deep learning method</title>
		<author>
			<persName><forename type="first">P</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lancet Dig. Health</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="353" to="e362" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Fast and robust fixed-point algorithms for independent component analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvarinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="626" to="634" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Effective self-supervised transformers for sparse time series data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Labach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pokhrel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zuberi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Volkovs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Krishnan</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=HUCgU5EQluN" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">EHR-driven machine-learning model to distinguish benign from malignant pulmonary nodules</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lasko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Nonstationary gaussian process regression for evaluating repeated clinical laboratory tests</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient inference of gaussian-process-modulated renewal processes with application to medical event data</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Lasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference. Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the Conference. Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<publisher>NIH Public Access</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">2014</biblScope>
			<biblScope unit="page">469</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Lasko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Mesa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11051</idno>
		<title level="m">Computational phenotype discovery via probabilistic independence</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Time-distance vision transformers in lung cancer diagnosis from longitudinal computed tomography</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.01676</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">BEHRT: transformer for electronic health records</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Evaluate the malignancy of pulmonary nodules using the 3D deep leaky noisy-or network</title>
		<author>
			<persName><forename type="first">F</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Netw. Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3484" to="3495" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Indeterminate pulmonary nodules: risk for having or for developing lung cancer?</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Massion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer Prev. Res. (Phila)</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1173" to="1178" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Probability of cancer in pulmonary nodules detected on first screening CT</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mcwilliams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">N. Engl. J. Med</title>
		<imprint>
			<biblScope unit="volume">369</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="910" to="919" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Artificial intelligence-based methods for fusion of electronic health records and imaging data</title>
		<author>
			<persName><forename type="first">F</forename><surname>Mohsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>El Hajj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">17981</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Med-BERT: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Rasmy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NPJ Dig. Med</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">86</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
