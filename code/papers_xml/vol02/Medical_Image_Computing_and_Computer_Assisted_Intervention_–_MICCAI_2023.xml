<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Medical Image Computing and Computer Assisted Intervention – MICCAI 2023</title>
				<funder>
					<orgName type="full">Advanced Computing Center for Research and Education</orgName>
					<orgName type="abbreviated">ACCRE</orgName>
				</funder>
				<funder ref="#_AsWNfDC #_vcbNWzT">
					<orgName type="full">National Institutes of Health</orgName>
				</funder>
				<funder ref="#_x3XcSkJ">
					<orgName type="full">National Science Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Han</forename><surname>Liu</surname></persName>
							<email>han.liu@vanderbilt.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Vanderbilt University</orgName>
								<address>
									<settlement>Nashville</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hao</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xing</forename><surname>Yao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Vanderbilt University</orgName>
								<address>
									<settlement>Nashville</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yubo</forename><surname>Fan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Vanderbilt University</orgName>
								<address>
									<settlement>Nashville</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dewei</forename><surname>Hu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Vanderbilt University</orgName>
								<address>
									<settlement>Nashville</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Benoit</forename><forename type="middle">M</forename><surname>Dawant</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Vanderbilt University</orgName>
								<address>
									<settlement>Nashville</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vishwesh</forename><surname>Nath</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Vanderbilt University</orgName>
								<address>
									<settlement>Nashville</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">NVIDIA</orgName>
								<address>
									<settlement>Nashville</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhoubing</forename><surname>Xu</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Siemens Healthineers</orgName>
								<address>
									<settlement>Princeton</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ipek</forename><surname>Oguz</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Vanderbilt University</orgName>
								<address>
									<settlement>Nashville</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Medical Image Computing and Computer Assisted Intervention – MICCAI 2023</title>
					</analytic>
					<monogr>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">04A54597229FC3D73322D6A39263C9F4</idno>
					<idno type="DOI">10.1007/978-3-031-43895-0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-24T10:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Efficient Annotation ⋅ Active Learning ⋅ Cold Start ⋅ Image Segmentation</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Medical image segmentation is a critical task in medical image analysis. In recent years, deep learning based approaches have shown exceptional performance when trained on a fully-annotated dataset. However, data annotation is often a significant bottleneck, especially for 3D medical images. Active learning (AL) is a promising solution for efficient annotation but requires an initial set of labeled samples to start active selection. When the entire data pool is unlabeled, how do we select the samples to annotate as our initial set? This is also known as the cold-start AL, which permits only one chance to request annotations from experts without access to previously annotated data. Cold-start AL is highly relevant in many practical scenarios but has been under-explored, especially for 3D medical segmentation tasks requiring substantial annotation effort. In this paper, we present a benchmark named COLosSAL by evaluating six cold-start AL strategies on five 3D medical image segmentation tasks from the public Medical Segmentation Decathlon collection. We perform a thorough performance analysis and explore important open questions for cold-start AL, such as the impact of budget on different strategies. Our results show that cold-start AL is still an unsolved problem for 3D segmentation tasks but some important trends have been observed. The code repository, data partitions, and baseline results for the complete benchmark are publicly available at https://github.com/MedICL-VU/COLosSAL.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Segmentation is among the most common medical image analysis tasks and is critical to a wide variety of clinical applications. To date, data-driven deep learning (DL) methods have shown prominent segmentation performance when trained on fully-annotated datasets <ref type="bibr" target="#b7">[8]</ref>. However, data annotation is a significant bottleneck for dataset creation. First, annotation process is tedious, laborious and time-consuming, especially for 3D medical images where dense annotation with voxel-level accuracy is required. Second, medical images typically need to be annotated by medical experts whose time is limited and expensive, making the annotations even more difficult and costly to obtain. Active learning (AL) is a promising solution to improve annotation efficiency by iteratively selecting the most important data to annotate with the goal of reducing the total number of annotated samples required. However, most deep AL methods require an initial set of labeled samples to start the active selection. When the entire data pool is unlabeled, which samples should one select as the initial set? This problem is known as cold-start active learning , a low-budget paradigm of AL that permits only one chance to request annotations from experts without access to any previously annotated data.</p><p>Cold-start AL is highly relevant to many practical scenarios. First, cold-start AL aims to study the general question of constructing a training set for an organ that has not been labeled in public datasets. This is a very common scenario (whenever a dataset is collected for a new application), especially when iterative AL is not an option. Second, even if iterative AL is possible, a better initial set has been found to lead to noticeable improvement for the subsequent AL cycles <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b24">25]</ref>. Third, in low-budget scenarios, cold-start AL can achieve one-shot selection of the most informative data without several cycles of annotation. This can lead to an appealing 'less is more' outcome by optimizing the available budget and also alleviating the issue of having human experts on standby for traditional iterative AL.</p><p>Despite its importance, very little effort has been made to address the coldstart problem, especially in medical imaging settings. The existing cold-start AL techniques are mainly based on the two principles of the traditional AL strategies: (1) Uncertainty sampling <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b17">18]</ref>, where the most uncertain samples are selected to maximize the added value of the new annotations. (2) Diversity sampling <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b21">22]</ref>, where samples from diverse regions of the data distribution are selected to avoid redundancy. In the medical domain, diversity-based cold-start strategies have been recently explored on 2D classification/segmentation tasks <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25]</ref>. The effectiveness of these approaches on 3D medical image segmentation remains unknown, especially since 3D models are often patch-based while 2D models can use the entire image. A recent study on 3D medical segmentation shows the feasibility to use the uncertainty estimated from a proxy task to rank the importance of the unlabeled data in the cold-start scenario <ref type="bibr" target="#b13">[14]</ref>. However, it fails to compare against the diversity-based approaches, and the proposed proxy task is only limited to CT images, making the effectiveness of this strategy unclear on other 3D imaging modalities. Consequently, no comprehensive cold-start AL baselines currently exist for 3D medical image segmentation, creating additional challenges for this promising research direction.</p><p>In this paper, we introduce the COLosSAL benchmark, the first cold-start active learning benchmark for 3D medical image segmentation by evaluating on six popular cold-start AL strategies. Specifically, we aim to answer three important open questions: (1) compared to random selection, how effective are the uncertainty-based and diversity-based cold-start strategies for 3D segmentation tasks? <ref type="bibr" target="#b1">(2)</ref> what is the impact of allowing a larger budget on the compared strategies? (3) can these strategies work better if the local ROI of the target organ is known as prior? We train and validate our models on five 3D medical image segmentation tasks from the publicly available Medical Segmentation Decathlon (MSD) dataset <ref type="bibr" target="#b0">[1]</ref>, which covers two of the most common 3D image modalities and the segmentation tasks for both healthy tissue and tumor/pathology.</p><p>Our contributions are summarized as follows:</p><p>• We offer the first cold-start AL benchmark for 3D medical image segmentation. We make our code repository, data partitions, and baseline results publicly available to facilitate future cold-start AL research. • We explore the impact of the budget and the extent of the 3D ROI on the cold-start AL strategies. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">COLosSAL Benchmark Definition</head><p>Formally, given an unlabeled data pool of size N , cold-start AL aims to select the optimal m samples (m ≪ N ) without access to any prior segmentation labels. Specifically, the optimal samples are defined as the subset of 3D volumes that can lead to the best validation performance when training a standard 3D segmentation network. In this study, we use m = 5 for low-budget scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">3D Medical Image Datasets</head><p>We use the Medical Segmentation Decathlon (MSD) collection <ref type="bibr" target="#b0">[1]</ref> to define our benchmark, due to its public accessibility and the standardized datasets spanning across two common 3D image modalities, i.e., CT and MRI. We select five tasks from the collection appropriate for the 3D segmentation tasks, namely tasks 2-Heart, 3-Liver, 4-Hippocampus, 7-Pancreas, and 9-Spleen. Liver and Pancreas tasks include both organ and tumor segmentation, while the other tasks focus on organs only.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Cold-Start AL Scenarios</head><p>In this study, we investigate the cold-start AL strategies for 3D segmentation tasks in three scenarios, as illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>.</p><p>1. With a low budget of 5 volumes (except for Heart, where 3 volumes are used because of the smaller dataset and easier segmentation task), we assess the performance of the uncertainty-based and diversity-based approaches against the random selection. 2. Next, we explore the impact of budgets for different cold-start AL schemes by allowing a higher budget, as previous work shows inconsistent effectiveness of AL schemes in different budget regimes <ref type="bibr" target="#b6">[7]</ref>. 3. Finally, we explore whether the cold-start AL strategies can benefit from using the uncertainty/diversity from only the local ROI of the target organ, rather than the entire volume. This strategy may be helpful for 3D tasks especially for small organs, whose uncertainty/diversity can be outweighted by the irrelevant structures in the entire volume, but needs to be validated.</p><p>Evaluation Metrics. To evaluate the segmentation performance, we use the Dice similarity coefficient and 95% Hausdorff distance (HD95), which measures the overlap between the segmentation result and ground truth, and the quality of segmentation boundaries by computing the 95 th percentile of the distances between the segmentation and the ground truth boundary points, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Baseline Cold-Start Active Learners</head><p>We provide the implementation for the baseline approaches: random selection, two variants of an uncertainty-based approach named ProxyRank <ref type="bibr" target="#b13">[14]</ref>, and three diversity-based methods, namely ALPS <ref type="bibr" target="#b21">[22]</ref>, CALR <ref type="bibr" target="#b9">[10]</ref>, and TypiClust <ref type="bibr" target="#b6">[7]</ref>.</p><p>Random Selection. As suggested by prior works <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b25">26]</ref>, random selection is a strong competitor in the cold-start setting, since it is independent and identically distributed (i.i.d.) to the entire data pool. We shuffle the entire training list with a random seed and select the first m samples. In our experiments, random selection is conducted 15 times and the mean Dice score is reported.</p><p>Uncertainty-Based Selection. Many traditional AL methods use uncertainty sampling, where the most uncertain samples are selected using the uncertainty of the network trained on an initial labeled set. Without such an initial labeled set, it is not straightforward to capture uncertainty in the cold-start setting.</p><p>Recently, Nath et al. <ref type="bibr" target="#b13">[14]</ref> proposed a proxy task and then utilized uncertainty generated from the proxy task to rank the unlabeled data. By selecting the most uncertain samples, this strategy has shown superior performance to random selection. Specifically, pseudo labels were generated by thresholding the CT images with an organ-dependent Hounsfield Unit (HU) intensity window. These pseudo labels carry coarse information for the target organ, though they also include other unrelated structures. The uncertainty generated by this proxy task is assumed to represent the uncertainty of the actual segmentation task.</p><p>However, this approach <ref type="bibr" target="#b13">[14]</ref> was limited to CT images. Here, we extend this strategy to MR images. For each MR image, we apply a sequence of transformations to convert it to a noisy binary mask: (1) z-score normalization, (2) intensity clipping to the [1 st , 99 th ] percentile of the intensity values, (3) intensity normalization to [0, 1] and (4) Otsu thresholding <ref type="bibr" target="#b15">[16]</ref>. We visually verify that the binary pseudo label includes the coarse boundary of the target organ.</p><p>As in <ref type="bibr" target="#b13">[14]</ref>, we compute the model uncertainty for each unlabeled data using Monte Carlo dropout <ref type="bibr" target="#b5">[6]</ref>: with dropout enabled during inference, multiple predictions are generated with stochastic dropout configurations. Entropy <ref type="bibr" target="#b12">[13]</ref> and Variance <ref type="bibr" target="#b20">[21]</ref> are used as uncertainty measures to create two variants of this proxy ranking method, denoted as ProxyRank-Ent and ProxyRank-Var. The overall uncertainty score of an unlabeled image is computed as the mean across all voxels. Finally, we rank all unlabeled data with the overall uncertainty scores and select the most uncertain m samples.</p><p>Diversity-Based Selection. Unlike uncertainty-based methods which require a warm start, diversity-based methods can be used in the cold-start setting. Generally, diversity-based approaches consist of two stages. First, a feature extraction network is trained using unsupervised/self-supervised tasks to represent each unlabeled data as a latent feature. Second, clustering algorithms are used to select the most diverse samples in latent space to reduce data redundancy. The major challenge of benchmarking the diversity-based methods for 3D tasks is to have a feature extraction network for 3D volumes. To address this issue, we train a 3D auto-encoder on the unlabeled training data using a self-supervised task, i.e., image reconstruction. Specifically, we represent each unlabeled 3D volume as a latent feature by extracting the bottleneck feature maps, followed by an adaptive average pooling for dimension reduction <ref type="bibr" target="#b23">[24]</ref>. Afterwards, we adapt the diversity-based approaches to our 3D tasks by using the same clustering strategies as proposed in the original works, but replacing the feature extraction network with our 3D version. In our benchmark, we evaluate the clustering strategies from three state-of-the-art diversity-based methods. 1. ALPS <ref type="bibr" target="#b21">[22]</ref>: k -MEANS is used to cluster the latent features with the number of clusters equal to the query number m. For each cluster, the sample that is the closest to the cluster center is selected. 2. CALR <ref type="bibr" target="#b9">[10]</ref>: This approach is based on the maximum density sampling, where the sample with the most information is considered the one that can optimally represent the distribution of a cluster. A bottom-up hierarchical clustering algorithm termed BIRCH <ref type="bibr" target="#b22">[23]</ref> is used and the number of clusters is set as the query number m. For each cluster, the information density for each sample within the cluster is computed and the sample with the highest information density is selected. The information density is expressed as</p><formula xml:id="formula_0">I(x) = 1 |X c | ∑ x ′ ∈X c sim(x, x ′ )</formula><p>, where X c = {x 1 , x 2 , ...x j } is the feature set in a cluster and cosine similarity is used as sim(⋅). 3. TypiClust <ref type="bibr" target="#b6">[7]</ref>: This approach also uses the points density in each cluster to select a diverse set of typical examples. k -MEANS clustering is used, followed by selecting the most typical data from each cluster, which is similar to the ALPS strategy but less sensitive to outliers. The typicality is calculated as the inverse of the average Euclidean distance of x to its K nearest neighbors KNN(x), expressed as:</p><formula xml:id="formula_1">Typicality(x) = ( 1 K ∑ x i ∈KNN(x) ||x -x i || 2 ) -1</formula><p>. K is set as 20 in the original paper but that is too high for our application. Instead, we use all the samples from the same cluster to calculate typicality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Implementation Details</head><p>In our benchmark, we use the 3D U-Net as the network architecture. For uncertainty estimation, 20 Monte Carlo simulations are used with a dropout rate of 0.2. As in <ref type="bibr" target="#b13">[14]</ref>, a dropout layer is added at the end of every level of the U-Net for both encoder and decoder. The performance of different AL strategies is evaluated by training a 3D patch-based segmentation network using the selected data, which is an important distinction from the earlier 2D variants in the literature. The only difference between different experiments is the selected data. For CT pre-processing, image intensity is clipped to [-1024, 1024] HU and rescaled to [0, 1]. For MRI pre-processing, we sequentially apply z-score normalization, intensity clipping to [1 st , 99 th ] percentile and rescaling to [0, 1]. During training, we randomly crop a 3D patch with a patch size of 128 × 128 × 128 (except for hippocampus, where we use 32 × 32 × 32) with the center voxel of the patch being foreground and background at a ratio of 2 ∶ 1. Stochastic gradient descent algorithm with a Nesterov momentum (µ = 0.99) is used as the optimizer and L DiceCE is used as the segmentation loss. An initial learning rate is set as 0.01 and decayed with a polynomial policy as in <ref type="bibr" target="#b8">[9]</ref>. For each experiment, we train our model using 30k iterations and validate the performance every 200 iterations.</p><p>A variety of augmentation techniques as in <ref type="bibr" target="#b8">[9]</ref> are applied to achieve optimal performance for all compared methods. All the networks are implemented in PyTorch <ref type="bibr" target="#b16">[17]</ref> and MONAI <ref type="bibr" target="#b1">[2]</ref>. Our experiments are conducted with the deterministic training mode in MONAI with a fixed random seed=0. We use a 24G NVIDIA GeForce RTX 3090 GPU.</p><p>For the global vs. local experiments, the local ROIs are created by extracting the 3D bounding box from the ground truth mask and expanding it by five voxels along each direction. We note that although no ground truth masks are accessible in the cold-start AL setting, this analysis is still valuable to determine the usefulness of local ROIs. It is only worth exploring automatic generation of these local ROIs if the gold-standard ROIs show promising results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Results</head><p>Impact of Selection Strategies. In Fig. <ref type="figure" target="#fig_1">2</ref>, with a fixed budget of 5 samples (except for Heart, where 3 samples are used), we compare the uncertainty-based and diversity-based strategies against the random selection on five different segmentation tasks. Note that the selections made by each of our evaluated AL strategies are deterministic. For random selection, we visualize the individual Dice scores (red dots) of all 15 runs as well as their mean (dashed line). HD95 results (Supp. Tab. 1) follow the same trends.</p><p>Our results explain why random selection remains a strong competitor for 3D segmentation tasks in cold-start scenarios, as no strategy evaluated in our benchmark consistently outperforms the random selection average performance.</p><p>However, we observe that TypiClust (shown as orange) achieves comparable or superior performance compared to random selection across all tasks in our benchmark, whereas other approaches can significantly under-perform on certain tasks, especially challenging ones like the liver dataset. Hence, Typi-Clust stands out as a more robust cold-start selection strategy, which can achieve at least a comparable (sometimes better) performance against the mean of random selection. We further note that TypiClust largely mitigates the risk of 'unlucky' random selection as it consistently performs better than the low-performing random samples (red dots below the dashed line).</p><p>Impact of Different Budgets. In Fig. <ref type="figure" target="#fig_2">3</ref>(a), we compare AL strategies under the budgets of m = 5 vs. m = 10 (3 vs. 5 for Hearts). We visualize the performance under each budget using a heatmap, where each element in the matrix is the difference of Dice scores between the evaluated strategy and the mean of random selection under that budget. A positive value (warm color) means that the AL strategy is more effective than random selection. We observe an increasing amount of warm elements in the higher-budget regime, indicating that most cold-start AL strategies become more effective when more budget is allowed. This is especially true for the diversity-based strategies (three bottom rows), suggesting that when a slightly higher budget is available, the diversity of the selected samples is important. HD95 results (Supp. Tab. 1) are similar.</p><p>Impact of Different ROIs. In Fig. <ref type="figure" target="#fig_2">3(b)</ref>, with a fixed budget of m = 5 volumes, we compare the AL strategies when uncertainty/diversity is extracted from the entire volume (global) vs. a local ROI (local). Each element in this heatmap is the Dice difference of the AL strategy between global and local; warm color means global is better than local. The hippocampus images in MSD are already cropped to the ROI, and thus are excluded from this comparison. We observe different trends across different methods and tasks. Overall, we can observe more warm elements in the heatmap, indicating that using only the local uncertainty or diversity for cold-start AL cannot consistently outperform the global counterparts, even with ideal ROI generated from ground truth. HD95 results (Supp. Tab. 2) follow the same trends.</p><p>Limitations. For the segmentation tasks that include tumors ( <ref type="formula">4</ref>th and 5</p><p>th columns on Fig. <ref type="figure" target="#fig_2">3</ref>(a)), we find that almost no AL strategy is very effective, especially the uncertainty-based approaches. The uncertainty-based methods heavily rely on the uncertainty estimated by the network trained on the proxy tasks, which likely makes the uncertainty of tumors difficult to capture. It may be nec-essary to allocate more budget or design better proxy tasks to make cold-start AL methods effective for such challenging tasks. Lastly, empirical exploration of cold-start AL on iterative AL is beyond the scope of this study and merits its own dedicated study in future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we presented the COLosSAL benchmark for cold-start AL strategies on 3D medical image segmentation using the public MSD dataset. Comprehensive experiments were performed to answer three important open questions for cold-start AL. While cold-start AL remains an unsolved problem for 3D segmentation, important trends emerge from our results; for example, diversitybased strategies tend to benefit more from a larger budget. Among the compared methods, TypiClust <ref type="bibr" target="#b6">[7]</ref> stands out as the most robust option for cold-start AL in medical image segmentation tasks. We believe our findings and the open-source benchmark will facilitate future cold-start AL studies, such as the exploration of different uncertainty estimation/feature extraction methods and evaluation on multi-modality datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Illustration of our three cold-start AL scenarios. We evaluate (1) uncertainty and diversity based selection strategies against random selection in a low-budget regime, (2) the effect of budget on performance, and (3) the usefulness of a local ROI for selection strategies.</figDesc><graphic coords="4,45,21,54,29,337,39,105,43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Cold-start AL strategies in a low-budget regime (m = 5). TypiClust (orange) is comparable or superior to mean random selection, and consistently outperforms the poor random selection samples. Comprehensive tables are provided in Supp. Materials. (Color figure online)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. (a) Difference in Dice between each strategy and the mean of the random selection (warm colors: better than random). Cold-start AL strategies are more effective under the higher budget. (b) Global vs. local ROI performance (warm colors: global better than local). The local ROI does not yield a consistently better performance. Comprehensive tables are provided in Supp. Materials.</figDesc><graphic coords="8,245,85,55,85,124,39,67,12" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This work was supported in part by the <rs type="funder">National Institutes of Health</rs> grants <rs type="grantNumber">R01HD109739</rs> and <rs type="grantNumber">T32EB021937</rs>, as well as <rs type="funder">National Science Foundation</rs> grant <rs type="grantNumber">2220401</rs>. This work was also supported by the <rs type="funder">Advanced Computing Center for Research and Education (ACCRE) of Vanderbilt University</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_AsWNfDC">
					<idno type="grant-number">R01HD109739</idno>
				</org>
				<org type="funding" xml:id="_vcbNWzT">
					<idno type="grant-number">T32EB021937</idno>
				</org>
				<org type="funding" xml:id="_x3XcSkJ">
					<idno type="grant-number">2220401</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The medical segmentation decathlon</title>
		<author>
			<persName><forename type="first">M</forename><surname>Antonelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">4128</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Monai: an open-source framework for deep learning in healthcare</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Cardoso</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.02701</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On initial pools for deep active learning</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Desai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Devaguptapu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename><surname>Balasubramanian</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">NeurIPS 2020 Workshop on Pre-registration in Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="14" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Making your first choice: to address cold start problem in medical active learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Imaging with Deep Learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">TAAL: test-time augmentation for active learning in medical image segmentation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gaillochet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Desrosiers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lombaert</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-17027-0_5</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-17027-05" />
	</analytic>
	<monogr>
		<title level="m">DALI 2022</title>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Nguyen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">X</forename><surname>Huang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Xue</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13567</biblScope>
			<biblScope unit="page" from="43" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Dropout as a Bayesian approximation: representing model uncertainty in deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1050" to="1059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Active learning on a budget: opposite strategies suit high and low budgets</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hacohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dekel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weinshall</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.02794</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deep learning techniques for medical image segmentation: achievements and challenges</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Hesamian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Digit. Imaging</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="582" to="596" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Isensee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Kohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Maier-Hein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="211" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Cold-start active learning for image classification</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">616</biblScope>
			<biblScope unit="page" from="16" to="36" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Heterogeneous uncertainty sampling for supervised learning</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Catlett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning Proceedings</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1994">1994. 1994</date>
			<biblScope unit="page" from="148" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tatarchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ö</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1912.05361</idno>
		<title level="m">Parting with illusions about deep active learning</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Diminishing uncertainty within the training pool: active learning for medical image segmentation</title>
		<author>
			<persName><forename type="first">V</forename><surname>Nath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Landman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2534" to="2547" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Warm start active learning with proxy labels and selection via semi-supervised fine-tuning</title>
		<author>
			<persName><forename type="first">V</forename><surname>Nath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16452-1_29</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16452-129" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13438</biblScope>
			<biblScope unit="page" from="297" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">How to measure uncertainty in uncertainty sampling for active learning</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">L</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Shaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hüllermeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="89" to="122" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A threshold selection method from gray-level histograms</title>
		<author>
			<persName><forename type="first">N</forename><surname>Otsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst. Man Cybern</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="62" to="66" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Pytorch: an imperative style, high-performance deep learning library</title>
		<author>
			<persName><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep active learning for image classification</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ranganathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Venkateswara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Panchanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Image Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3934" to="3938" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Active learning for convolutional neural networks: a core-set approach</title>
		<author>
			<persName><forename type="first">O</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.00489</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Rethinking deep active learning: using unlabeled data at model training</title>
		<author>
			<persName><forename type="first">O</forename><surname>Siméoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Budnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Avrithis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gravier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">25th International Conference on Pattern Recognition (ICPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020. 2021</date>
			<biblScope unit="page" from="1220" to="1227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Suggestive annotation: a deep active learning framework for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Z</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-66179-7_46</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-66179-7" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2017</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Descoteaux</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Maier-Hein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Franz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Jannin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Collins</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Duchesne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">10435</biblScope>
			<biblScope unit="page">46</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Cold-start active learning through selfsupervised language modeling</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.09535</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Birch: an efficient data clustering method for very large databases</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Livny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMOD Rec</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="103" to="114" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Self-supervised assisted active learning for skin lesion segmentation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Veeravalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 44th Annual International Conference of the IEEE Engineering in Medicine &amp; Biology Society (EMBC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="5043" to="5046" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Biomedical image segmentation via representative annotation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="5901" to="5908" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Addressing the item cold-start problem by attribute-driven active learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="631" to="644" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
