<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">AngioMoCo: Learning-Based Motion Correction in Cerebral Digital Subtraction Angiography</title>
				<funder>
					<orgName type="full">MGH</orgName>
				</funder>
				<funder>
					<orgName type="full">Academy Medical Sciences Fund of the Royal Netherlands Academy of Arts &amp; Sciences (KNAW)</orgName>
				</funder>
				<funder>
					<orgName type="full">Academy Van Leersum</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Ruisheng</forename><surname>Su</surname></persName>
							<email>r.su@erasmusmc.nl</email>
							<idno type="ORCID">0000-0002-5013-1370</idno>
							<affiliation key="aff0">
								<orgName type="institution">Erasmus University Medical Center</orgName>
								<address>
									<settlement>Rotterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution" key="instit1">Massachusetts General Hospital</orgName>
								<orgName type="institution" key="instit2">Harvard Medical School</orgName>
								<address>
									<settlement>Boston</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Matthijs</forename><surname>Van Der Sluijs</surname></persName>
							<idno type="ORCID">0000-0002-4934-0933</idno>
							<affiliation key="aff0">
								<orgName type="institution">Erasmus University Medical Center</orgName>
								<address>
									<settlement>Rotterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sandra</forename><surname>Cornelissen</surname></persName>
							<idno type="ORCID">0000-0002-0332-2158</idno>
							<affiliation key="aff0">
								<orgName type="institution">Erasmus University Medical Center</orgName>
								<address>
									<settlement>Rotterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wim</forename><surname>Van Zwam</surname></persName>
							<idno type="ORCID">0000-0003-1631-7056</idno>
						</author>
						<author>
							<persName><forename type="first">Aad</forename><surname>Van Der Lugt</surname></persName>
							<idno type="ORCID">0000-0002-6159-2228</idno>
							<affiliation key="aff0">
								<orgName type="institution">Erasmus University Medical Center</orgName>
								<address>
									<settlement>Rotterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wiro</forename><surname>Niessen</surname></persName>
							<idno type="ORCID">0000-0002-5822-1995</idno>
							<affiliation key="aff0">
								<orgName type="institution">Erasmus University Medical Center</orgName>
								<address>
									<settlement>Rotterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Delft University of Technology</orgName>
								<address>
									<settlement>Delft</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Danny</forename><surname>Ruijters</surname></persName>
							<idno type="ORCID">0000-0002-9931-4047</idno>
							<affiliation key="aff3">
								<orgName type="institution">Philips Healthcare</orgName>
								<address>
									<settlement>Best</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Theo</forename><surname>Van Walsum</surname></persName>
							<idno type="ORCID">0000-0001-8257-7759</idno>
							<affiliation key="aff0">
								<orgName type="institution">Erasmus University Medical Center</orgName>
								<address>
									<settlement>Rotterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Adrian</forename><surname>Dalca</surname></persName>
							<idno type="ORCID">0000-0002-8422-0136</idno>
							<affiliation key="aff4">
								<orgName type="institution">Massachusetts Institute of Technology</orgName>
								<address>
									<settlement>Boston</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution" key="instit1">Massachusetts General Hospital</orgName>
								<orgName type="institution" key="instit2">Harvard Medical School</orgName>
								<address>
									<settlement>Boston</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">AngioMoCo: Learning-Based Motion Correction in Cerebral Digital Subtraction Angiography</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="770" to="780"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">BBB4273365D75D9F437A2D56DACC0BAB</idno>
					<idno type="DOI">10.1007/978-3-031-43990-2_72</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-24T11:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Angiography</term>
					<term>X-Rays</term>
					<term>Registration</term>
					<term>Motion Artifacts</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Cerebral X-ray digital subtraction angiography (DSA) is the standard imaging technique for visualizing blood flow and guiding endovascular treatments. The quality of DSA is often negatively impacted by body motion during acquisition, leading to decreased diagnostic value. Traditional methods address motion correction based on non-rigid registration and employ sparse key points and nonrigidity penalties to limit vessel distortion, which is time-consuming. Recent methods alleviate subtraction artifacts by predicting the subtracted frame from the corresponding unsubtracted frame, but do not explicitly compensate for motion-induced misalignment between frames. This hinders the serial evaluation of blood flow, and often causes undesired vasculature and contrast flow alterations, leading to impeded usability in clinical practice. To address these limitations, we present AngioMoCo, a learning-based framework that generates motioncompensated DSA sequences from X-ray angiography. AngioMoCo integrates contrast extraction and motion correction, enabling differentiation between patient motion and intensity changes caused by contrast flow. This strategy improves registration quality while being orders of magnitude faster than iterative elastix-based methods. We demonstrate AngioMoCo on a large national multi-center dataset (MR CLEAN Registry) of clinically acquired angiographic images through comprehensive qualitative and quantitative analyses. AngioMoCo produces highquality motion-compensated DSA, removing while preserving contrast flow. Code is publicly available at https://github.com/RuishengSu/ AngioMoCo.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Cerebral X-ray digital subtraction angiography (DSA) is a widely used imaging modality in interventional radiology for blood flow visualization and therapeutic guidance in endovascular treatments <ref type="bibr" target="#b24">[25]</ref>. It is a 2D+T image series obtained by subtracting an initial pre-contrast image from subsequent post-contrast frames, leaving only the contrast-filled vessels visible. The injection of contrast medium and the subtraction process effectively eliminate soft tissue and bone, enabling high-resolution visualization of the vessels and the blood flow. However, this subtraction technique assumes the absence of motion between frames during exposure. In clinical practice, this premise is often violated. Involuntary motions, caused by swallowing, coughing, stroke, or endovascular procedures, are nearly inevitable. Body motion results in undesired artifacts in subtracted images, leading to decreased image quality and impaired interpretability of DSA (Fig. <ref type="figure" target="#fig_0">1</ref>).</p><p>Over the last three decades, various motion correction techniques have been proposed to mitigate the impact of body motion retrospectively <ref type="bibr" target="#b17">[18]</ref>. Registration algorithms typically employ template matching with corresponding control points or landmarks to align images <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref>. These algorithms rely on features based on vessels <ref type="bibr" target="#b7">[8]</ref>, edges <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b27">28]</ref>, corners <ref type="bibr" target="#b29">[30]</ref>, textures <ref type="bibr" target="#b19">[20]</ref>, temporal correspondence <ref type="bibr" target="#b2">[3]</ref>, and non-uniform grids <ref type="bibr" target="#b26">[27]</ref>. To capture both local and global transformations, multi-resolution search <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b30">31]</ref> matching <ref type="bibr" target="#b8">[9]</ref>, and iterative estimations <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b29">30]</ref> have been proposed. To limit undesirable vessel distortions, sparse key points <ref type="bibr" target="#b18">[19]</ref> and non-rigidity penalties <ref type="bibr" target="#b25">[26]</ref> have been used. Although these methods are effective in motion compensation, they require time-consuming iterative computation for each frame, limiting their clinical applicability.</p><p>Recent generative models, such as pix2pix <ref type="bibr" target="#b12">[13]</ref>, have been adapted to address subtraction artifacts without registration <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b28">29]</ref>. These models leverage deep learning techniques to predict a subtraction image from an input post-contrast image by discerning foreground contrast from the body background, resulting in reduced artifacts. However, these models do not explicitly compensate for motion-induced misalignment between frames. More importantly, they may cause hallucinations or modification of contrast and vessels, and lack interpretability as there is no subtraction. Consequently, these shortcomings hinder the serial evaluation of blood flow and impede the diagnostic utility of DSA.</p><p>To overcome these limitations, we introduce AngioMoCo, a fast learningbased motion correction method for DSA that avoids severe contrast distortion. We employ a supervised CNN module that distinguishes between motion displacement and contrast intensity change. The output contrast-removed image and the pre-contrast image are then input to a subsequent self-supervised learning-based registration model for deformable registration, where a deformation regularization loss limits the local irregularity. By excluding contrast enhancements from the deformation learning processing, AngioMoCo avoids undesired distortion of the vessels. This results in trustworthy visualization of continuous blood flow and promises to assist in automated analysis of flow-based biomarkers relevant to endovascular treatments.</p><p>Overall, classical non-rigid registration methods use various regularization strategies to limit vessel distortion, but are prohibitively time-consuming. Recent learning-based methods are fast, but do not explicitly model the motion between frames, and as a result can negatively distort the very clinical information we aim to highlight. We build on the strengths of both directions while avoiding their limitations. Specifically, we propose a novel learning-based strategy that is significantly faster than traditional non-rigid registration methods. AngioMoCo not only removes subtraction artifacts on each frame but does so by explicitly compensating for motion between frames, which is not available in existing image-to-image models. We demonstrate that AngioMoCo achieves high-quality registration while avoiding undesirable contrast reduction or vessel erasure. We define a contrast extraction module f θ f (x t ) = c t with parameters θ f that takes as input a post-contrast frame x t . This function separates x t into a contrast image c t and a contrast-removed image m t where m t = x t -c t . The values in c t are within [-1, 0] as the injected contrast medium can only lead to a decrease in pixel intensity relative to the input image with an intensity range of [0, 1]. The contrast extraction module aims to reduce contrast discrepancies between the pre-and post-contrast frames. Such image-to-image modules can lead to hallucination and may not fully capture distal vessels, relatively less contrasted vessels, and vessels behind bone structures. Therefore, in AngioMoCo, we only employ this module to enable easier registration of the frame x t to the precontrast x 0 using the intermediate contrast-extracted m t image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Model</head><p>We define a registration function r θr (x 0 , m t ) = φ t with parameters θ r to estimate the deformation φ t . We obtain the motionless subtraction angiography y t by subtracting the pre-contrast frame x 0 from the warped post-contrast frame w t : y t = w t -x 0 = x t • φ t -x 0 , where • defines a spatial warp.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Training</head><p>We train the contrast extraction f θ f (•) and deformable registration r θr (•, •) modules separately. The contrast extraction module is trained on a motionless subset of data with an MSE loss between the ground truth contrast, estimated via subtraction between post-and pre-contrast frames (x t -x 0 ), and the predicted c t :</p><formula xml:id="formula_0">L ext (θ r ; x t ) = L MSE (x t -x 0 , f θ f (x t )).<label>(1)</label></formula><p>We train the deformable registration module on a motion subset, with the pretrained contrast extraction module frozen, using a loss function that combines an MSE loss between m t and x 0 and a smoothness loss L smooth , weighted by λ:</p><formula xml:id="formula_1">L reg (θ f ; x 0 , m t • φ t ) = (1 -λ)L MSE (x 0 , m t • φ t ) + λL smooth (φ t ),<label>(2)</label></formula><p>where L smooth is the mean squared horizontal and vertical gradients of displacement u t in deformation field φ t , that enforces spatial smoothness of deformation:</p><formula xml:id="formula_2">L smooth (φ t ) = ∇u t 2 .</formula><p>(3)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Architecture</head><p>We design the contrast extraction module f θ f (•, •) using a U-Net architecture, which includes a contracting path (encoder) and an expanding path (decoder) connected by skip connections. The encoder stage comprises eight convolutional and max-pooling layers with the number of channels being 8, 16, 32, 64, 128, 256, 512, and 512 respectively. The convolutions operate with a 3 × 3 kernel size and a stride of 2. Similarly, the decoding path employs eight upsampling, 3 × 3 convolution, and concatenation operations with 32 feature maps per layer to restore the spatial dimension up to the input size. Each convolution is accompanied by an instance normalization and a LeakyReLU activation layer. We also use three additional 3 × 3 convolutions. The final convolution employs a negative sigmoid activation, confining the output pixel intensity to [-1, 0]. We employ a deformable registration module r θr (•, •) based on VoxelMorph to learn motion correction in DSA <ref type="bibr" target="#b1">[2]</ref>. We add instance normalization between the convolution layers of the encoder and decoder. We utilize this deformable registration module to predict bi-directional dense deformation fields using diffeomorphism that allows to spatially transform either pre-or post-contrast frames.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>We assess AngioMoCo in terms of vessel contrast preservation, artifact removal, and computation efficiency compared to existing approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Setup</head><p>Data. We identified 272 patients with unsubtracted cerebral angiographic images available from MR CLEAN registry <ref type="bibr" target="#b13">[14]</ref>, an ongoing prospective observational multi-center registry of patients with acute ischemic stroke who underwent endovascular thrombectomy (EVT). This comprised 788 angiographic series, consisting of 16,641 frames in total, acquired between attempts of thrombus retrieval. The DSA series were acquired using various imaging systems, including Philips, GE, and Siemens, and had a size of 1024×1024 pixels. The series had varying lengths, ranging from 10 to 50 frames, and temporal resolutions between 0.5 and 4 frames per second (fps). We performed image resizing to 512 × 512 pixels and min-max intensity normalization to obtain intensity values within the range of [0, 1]. To ensure the coherency of the intensity along the series, the maximum intensity is calculated on the series level based on the stored bits in the DICOM header.</p><p>Based on visual assessment, we categorized the dataset into two subsets: motionless and motion. We use the motionless subset, consisting of 107 series (1933 frames) from 21 patients, for pre-training the contrast extraction module. The motion subset, which contains 681 series (14708 frames) from 251 patients, is used for overall training and evaluation. We split data on the patient level independently on the motionless and motion subsets, with a ratio of 50%, 20%, and 30% for training, validation, and testing, respectively.</p><p>Baselines. We compare AngioMoCo with two widely used image registration approaches, elastix-based affine registration and VoxelMorph <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>, and an imageto-image approach employing a U-Net <ref type="bibr" target="#b23">[24]</ref> architecture. We followed the implementation of <ref type="bibr" target="#b1">[2]</ref> for VoxelMorph with deformation regularization λ = 0.01. For the U-Net, we employed the same architecture as the contrast extraction module f θ f (•, •) with the same preprocessing and augmentations. We trained the U-Net using the motionless subset and used mean squared error (MSE) as the optimizing objective. We implemented the methods using Python 3.10.6 and PyTorch <ref type="bibr" target="#b22">[23]</ref>.</p><p>Training Details. We use an NVIDIA 2080 Ti GPU (11 GB), the Adam optimizer <ref type="bibr" target="#b14">[15]</ref> and the ReduceLROnPlateau scheduler with an initial learning rate of 0.001, a patience of 300 epochs, and a decay of 0.1. We set the batch size to 8 and applied early stopping with a patience of 500 epochs. We selected these optimization parameters based on validation performance using a grid search. We applied data augmentations using Albumentations <ref type="bibr" target="#b4">[5]</ref>, including HorizontalFlip, ShiftScaleRotate, and RandomSizedCrop, each with a probability of 0.5.</p><p>Evaluation. We carry out both qualitative and quantitative analyses on the hold-out test set of the motion subset. A key challenge is to minimize motion and subtraction artifacts while retaining clinically important features. We use mean squared intensity (MSI) as a proxy to quantify the preservation of contrast intensity within vessels and the ability of motion correction outside vessels. As ground truth deformations are not available for image sequences with motion, we manually segment the blood vessels in post-contrast frames (Supplemental Fig. <ref type="figure">6</ref>), and use the resulting masks to quantify MSI inside and outside blood vessels. We used paired t-tests for statistical significance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head><p>Quantitative Analysis. The optimal outcome is represented by the top left corner of Fig. <ref type="figure">3</ref>, indicating high vessel contrast preservation and complete artifact removal (Supplemental Table <ref type="table">1</ref>). Compared to elastix affine registration, Fig. <ref type="figure">3</ref>. Mean squared intensity (MSI) on the test set. Better methods will preserve the MSI (i.e., vessel contrast) inside vessels (↑, y-axis) while minimizing the MSI (i.e., artifacts) outside vessels (←, x-axis), moving towards the top left of the graph.</p><p>AngioMoCo(λ = 0.001) achieves similar vessel preservation (P = 0.2), while substantially decreasing the MSI outside vessels (by about half). Compared to Vox-elMorph, AngioMoCo demonstrates substantial improvement, with higher vessel preservation and better (more to the left) artifact removal. While the imageto-image U-Net yields the lowest MSI outside vessels, it sacrifices a substantial amount (30%) of contrast inside vessels, harming the precise clinical signal we are interested in.</p><p>Qualitative Analysis. Figure <ref type="figure" target="#fig_2">4</ref> presents visual comparisons of the methods through three representative examples. The image-to-image U-Net generates images with fewer motion artifacts than other methods, but it often fails to capture vessel contrast behind bone structures (Row 1), distal vessels (Row 1), and loses high-frequency spatial features, leading to blurry images (Row 2). These errors can have substantial negative effects on downstream clinical applications. VoxelMorph operates on pre-and post-contrast images, which can cause considerable modifications in the vessel contrast flow. For example, the motioncorrected image of VoxelMorph in Row 3 has lighter vessel contrast than its counterparts. In contrast, AngioMoCo overcomes these limitations of U-Net and VoxelMorph by learning to disentangle contrast flow from motion.</p><p>Runtime. Compared to iterative registration methods, deep-learning-based registration methods, including AngioMoCo, require orders of magnitude less time. For example, AngioMoCo takes less than a second to process a series on GPU, while iterative registration methods are mostly implemented on CPU where they require minutes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>We find that AngioMoCo achieves high-quality motion correction in DSA, while preserving vessel details, which is of critical clinical importance. While the imageto-image U-Net resulted in fewer artifacts, it substantially degrades the vessel contrast, harming its usability in clinical usefulness.</p><p>These results suggest that AngioMoCo is clinically relevant for endovascular applications, enhancing the utility of DSA in diagnosis and treatment planning. The tool can extract contrast flow while outputting smooth bi-directional deformation fields that provide interpretability. Unlike image-to-image models, the contrast flow visualization is driven by motion-compensation of the post-contrast frames to the pre-contrast image, and hence avoids undesirable hallucinations and modifications of vessel contrast.</p><p>We also examined the end-to-end training strategy of AngioMoCo, which did not yield superior results to VoxelMorph or the modularly trained AngioMoCo (Supplemental Fig. <ref type="figure">5</ref>). To further enhance registration accuracy, future research may explore the integration of 3D spatio-temporal CNN and the utilization of vessel masks as auxiliary supervision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We have presented AngioMoCo, a deep learning-based strategy towards motionfree digital subtraction angiography. The approach leverages a contrast extraction module to disentangle contrast flow from body motion and a deformable registration module to concentrate on motion-induced deformations. The experimental results on a large clinical dataset demonstrate that AngioMoCo outperforms iterative affine registration, learning-based VoxelMorph, and imageto-image U-Net. Overall, AngioMoCo achieves high registration accuracy while preserving vascular features, improving the quality and clinical utility of DSA for diagnosis and treatment planning in endovascular procedures.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Illustration of motion artifacts in DSA: a) the pre-contrast frame; b) a subsequent post-contrast frame; c) subtracted frame (b-a).</figDesc><graphic coords="2,65,64,328,31,330,64,220,63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 Fig. 2 .</head><label>22</label><figDesc>Figure 2 outlines the AngioMoCo framework for motion correction and subtraction in angiographic images, comprising three main modules: contrast extraction, deformable registration, and spatial-transformed subtraction. Let X = {x t } T t=0 be the 2D+T DSA series of a patient, where x 0 is the pre-contrast frame and {x t } T t=1 are the post-contrast frames.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Representative visual comparisons. We report MSI values inside (left) and outside (right) vessels in brackets. Red arrows point to undesired vessel contrast erasure or modifications. AngioMoCo achieves better background artifact removal and vessel enhancement than other methods. The UNet achieves excellent artifact removal, but it comes at the cost of severe damage to the vessels of interest, making it clinically less useful.</figDesc><graphic coords="8,55,98,53,69,340,30,217,03" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="4,55,98,54,08,340,66,160,63" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgment. This work is done during a visit at <rs type="funder">MGH</rs>. The visit was made possible in part by the <rs type="funder">Academy Van Leersum</rs> grant of the <rs type="funder">Academy Medical Sciences Fund of the Royal Netherlands Academy of Arts &amp; Sciences (KNAW)</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43990-2_72.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An unsupervised learning model for deformable medical image registration</title>
		<author>
			<persName><forename type="first">G</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Sabuncu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guttag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Dalca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="9252" to="9260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">VoxelMorph: a learning framework for deformable medical image registration</title>
		<author>
			<persName><forename type="first">G</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Sabuncu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guttag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Dalca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1788" to="1800" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A 3-D space-time motion detection for an invariant image registration approach in digital subtraction angiography</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bentoutou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Taleb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Image Underst</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="30" to="50" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An invariant approach for image registration in digital subtraction angiography</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bentoutou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Taleb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>El Mezouar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Taleb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jetto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2853" to="2865" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Albumentations: fast and flexible image augmentations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Buslaev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">I</forename><surname>Iglovikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Khvedchenya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Parinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Druzhinin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Kalinin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">125</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Image registration for DSA quality enhancement</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Buzug</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Med. Imaging Graph</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="103" to="113" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Using an entropy similarity measure to enhance the quality of DSA images with an algorithm based on template matching</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Buzug</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fassnacht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lorenz</surname></persName>
		</author>
		<idno type="DOI">10.1007/BFb0046959</idno>
		<ptr target="https://doi.org/10.1007/BFb0046959" />
	</analytic>
	<monogr>
		<title level="m">Visualization in Biomedical Computing: 4th International Conference</title>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Höhne</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Kikinis</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1996-09-25">1996 Hamburg, Germamy, 22-25 September 1996. 2006</date>
			<biblScope unit="page" from="235" to="240" />
		</imprint>
	</monogr>
	<note>VBC</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">DSA image registration based on multiscale Gabor filters and mutual information</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Moon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2005 IEEE International Conference on Information Acquisition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Registration for DSA image using triangle grid and spatial transformation based on stretching</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Mou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2006 8th international Conference on Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Automatic registration of temporal image pairs for digital subtraction angiography</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>De Jager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Processing</title>
		<imprint>
			<biblScope unit="volume">2167</biblScope>
			<biblScope unit="page" from="188" to="199" />
			<date type="published" when="1994">1994. 1994</date>
		</imprint>
	</monogr>
	<note>SPIE</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep learning subtraction angiography: improved generalizability with transfer learning</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">T</forename><surname>Crabb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Vasc. Intervent. Radiol</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="409" to="419" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep learning-based digital subtraction angiography image generation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Assist. Radiol. Surg</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1775" to="1784" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Image-to-image translation with conditional adversarial networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1125" to="1134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Endovascular treatment for acute ischaemic stroke in routine clinical practice: prospective, observational cohort study (MR CLEAN Registry)</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">G</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Mulder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J B</forename><surname>Goldhoorn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMJ</title>
		<imprint>
			<biblScope unit="volume">360</biblScope>
			<biblScope unit="page">949</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: a method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A stretching transform-based automatic nonrigid registration system for cerebrovascular digital subtraction angiography images</title>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Imaging Syst. Technol</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="171" to="187" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Reduction of patient motion artifacts in digital subtraction angiography: evaluation of a fast and fully automatic technique</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Meijering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">219</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="288" to="293" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Retrospective motion correction in digital subtraction angiography: a review</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Meijering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Niessen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Viegever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2" to="21" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Image registration for digital subtraction angiography</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Meijering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Zuiderveld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Viergever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vision</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="227" to="246" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A fast image registration algorithm for digital subtraction angiography</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nejati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Amirfattahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sadri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">17th Iranian Conference of Biomedical Engineering (ICBME)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010. 2010</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Multiresolution image registration in digital X-ray angiography with intensity variation modeling</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nejati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pourghassem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Med. Syst</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Nonrigid image registration in digital subtraction angiography using multilevel B-spline</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nejati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sadri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Amirfattahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BioMed Res. Int</title>
		<imprint>
			<biblScope unit="page">236315</biblScope>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">PyTorch: an imperative style, high-performance deep learning library</title>
		<author>
			<persName><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="8026" to="8037" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">U-Net: convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-24574-4_28</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-24574-4_28" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2015, Part III</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hornegger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">9351</biblScope>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Digital subtraction angiography in cerebrovascular disease: current practice and perspectives on diagnosis, acute treatment and prognosis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shaban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Neurologica Belgica</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="763" to="780" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A rigidity penalty term for nonrigid registration</title>
		<author>
			<persName><forename type="first">M</forename><surname>Staring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Pluim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Phys</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4098" to="4108" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">DSA image registration using non-uniform MRF model and pivotal control points</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sundarapandian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kalpathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">D</forename><surname>Manason</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Med. Imaging Graph</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="323" to="336" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Image registration for applications in digital subtraction angiography</title>
		<author>
			<persName><forename type="first">N</forename><surname>Taleb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jetto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Control. Eng. Pract</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="227" to="238" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep learning-based angiogram generation model for cerebral angiography without misregistration artifacts</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ueda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">299</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="675" to="681" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">An iterative refinement DSA image registration algorithm using structural image quality measure</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009. 2009</date>
			<biblScope unit="page" from="973" to="976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Multiresolution elastic registration of X-ray angiography images using thin-plate spline</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Nucl. Sci</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="152" to="166" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
