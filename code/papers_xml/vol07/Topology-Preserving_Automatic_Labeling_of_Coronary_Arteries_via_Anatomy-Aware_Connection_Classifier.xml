<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Topology-Preserving Automatic Labeling of Coronary Arteries via Anatomy-Aware Connection Classifier</title>
				<funder ref="#_ed4hh2A">
					<orgName type="full">National Science Foundation of China</orgName>
				</funder>
				<funder ref="#_Jm5XMKW">
					<orgName type="full">National Key R&amp;D Program of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zhixing</forename><surname>Zhang</surname></persName>
							<email>zhangzhixing@stu.pku.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Data Science</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ziwei</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Data Science</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="laboratory">Pazhou Lab</orgName>
								<address>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dong</forename><surname>Wang</surname></persName>
							<email>wanglw@pku.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="department">School of Intelligence Science and Technology</orgName>
								<orgName type="laboratory">National Key Laboratory of General Artificial Intelligence</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shishuang</forename><surname>Zhao</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Yizhun Medical AI Co., Ltd</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuhang</forename><surname>Liu</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Yizhun Medical AI Co., Ltd</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jia</forename><surname>Liu</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Peking University First Hospital</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Liwei</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Intelligence Science and Technology</orgName>
								<orgName type="laboratory">National Key Laboratory of General Artificial Intelligence</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Center for Machine Learning Research</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Topology-Preserving Automatic Labeling of Coronary Arteries via Anatomy-Aware Connection Classifier</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="759" to="769"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">66DDC3773FFEF1A8A8BFE51B7B7915B9</idno>
					<idno type="DOI">10.1007/978-3-031-43990-2_71</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-24T11:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Automatic Labeling</term>
					<term>Coronary Arteries</term>
					<term>Topology-Preserving</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Automatic labeling of coronary arteries is an essential task in the practical diagnosis process of cardiovascular diseases. For experienced radiologists, the anatomically predetermined connections are important for labeling the artery segments accurately, while this prior knowledge is barely explored in previous studies. In this paper, we present a new framework called TopoLab which incorporates the anatomical connections into the network design explicitly. Specifically, the strategies of intra-segment feature aggregation and inter-segment feature interaction are introduced for hierarchical segment feature extraction. Moreover, we propose the anatomy-aware connection classifier to enable classification for each connected segment pair, which effectively exploits the prior topology among the arteries with different categories. To validate the effectiveness of our method, we contribute high-quality annotations of artery labeling to the public orCaScore dataset. The experimental results on both the orCaScore dataset and an in-house dataset show that our TopoLab has achieved state-of-the-art performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Coronary Computerized Tomography Angiography (CCTA) is a commonly used non-invasive approach for the diagnosis of potential coronary artery diseases <ref type="bibr" target="#b10">[11]</ref>. In clinical practice, accurate labeling of coronary artery segments (see Fig. <ref type="figure" target="#fig_0">1(a)</ref>) is a crucial step toward the subsequent diagnosis and analysis of the image. However, the vast variability of coronary artery anatomy across individuals makes it challenging to achieve precise and automatic labeling. Previous studies on labeling coronary arteries using deep learning-based methods <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref> have shown promising results by introducing graph convolutional networks and point cloud analysis. However, these approaches have overlooked the essential prior knowledge that different categories of coronary arteries have anatomically predetermined connections <ref type="bibr" target="#b2">[3]</ref>. For instance, LAD, LCX, and RI originate from LM, while S and D arise from LAD. All of the anatomical connections form a tree structure with prior topology, as shown in Fig. <ref type="figure" target="#fig_0">1(b</ref>). We call this structure category topological trees. Due to lacking the utilization of the category topological trees, existing methods <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref> often make some obvious mistakes that violate the prior topology as illustrated in Fig. <ref type="figure" target="#fig_0">1(c</ref>). We argue that incorporating the category topological trees into the network explicitly is the key to improving automatic labeling performance, especially in reducing topology-violation labeling errors.</p><p>In this paper, we propose a novel framework called TopoLab to perform topology-preserving automatic labeling of coronary arteries. Our model mainly contains two components: the hierarchical feature extraction module and the anatomy-aware connection classifier. The hierarchical feature extraction module introduces the segment query to achieve intra-segment feature aggregation via Transformer <ref type="bibr" target="#b16">[17]</ref> and relies on graph convolutional network <ref type="bibr" target="#b7">[8]</ref> to establish inter-segment feature interactions. Moreover, to incorporate the category topological trees into the network explicitly, we further propose the anatomy-aware connection classifier (AC-Classifier). Unlike previous methods that classify each segment independently, AC-Classifier performs classification for every connected segment pair. Specifically, all of the connections derived from the category topological trees are used to construct the ground truth connection templates, and each connected segment pair is categorized into one of these templates. Since the connection templates inherently conform to the topology, AC-Classifier has effectively prioritized the anatomically predetermined connections and the network is enabled to preserve the topology by design.</p><p>To the best of our knowledge, there is currently no publicly available dataset with annotations for artery labeling. In this work, we contribute high-quality annotations to the orCaScore dataset <ref type="bibr" target="#b18">[19]</ref>. The experimental results on the public dataset orCaScore and an in-house dataset have demonstrated that our TopoLab outperforms previous state-of-the-art methods, especially in the topology-related metrics.</p><p>Our contributions can be summarized as follows. <ref type="bibr" target="#b0">(1)</ref> We are the first to incorporate the category topological trees into the deep learning models for automatic labeling of coronary arteries by introducing AC-Classifier. <ref type="bibr" target="#b1">(2)</ref> We propose a novel hierarchical feature extraction module to achieve intra-and inter-segment feature aggregations. (3) Our approach achieves state-of-the-art performance on both public and in-house datasets. (4) We provide high-quality annotations of artery labeling for the public dataset orCaScore, which is available at https:// github.com/zutsusemi/MICCAI2023-TopoLab-Labels/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Traditional methods <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b20">21]</ref> for automatic labeling of coronary arteries usually align the extracted artery trees with a 3D coronary artery tree model which provides the anatomical connections as prior knowledge. However, these works rely heavily on logical rules, which can not always capture the complexities of the anatomical structure. To overcome the limitations, deep learning has been introduced in this area <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref> with its great success in medical imaging <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b17">18]</ref>. For instance, TreeLab-Net <ref type="bibr" target="#b19">[20]</ref> uses bidirectional tree-structural LSTM <ref type="bibr" target="#b5">[6]</ref> to model the coronary artery trees, while CPR-GCN <ref type="bibr" target="#b21">[22]</ref> constructs a vessel graph by treating each segment as a node and leverages GCN <ref type="bibr" target="#b7">[8]</ref> to aggregate segment features. CorLab-Net <ref type="bibr" target="#b23">[24]</ref> regards spatial and anatomical dependencies as the explicit guidance for artery labeling based on point cloud networks <ref type="bibr" target="#b12">[13]</ref>. Nevertheless, all of these deep learning based methods ignore the important priority about the predetermined anatomical structure -category topological trees. In this paper, we aim to incorporate this priority into the network design explicitly for developing the topology-preserving models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head><p>We start by extracting centerlines from the vessel segmentation annotations in a CCTA image, using a traditional 3D thinning algorithm <ref type="bibr" target="#b8">[9]</ref>. Next, we use the minimum spanning tree algorithm <ref type="bibr" target="#b4">[5]</ref> to construct two coronary artery trees, one for the left domain (LD) and one for the right domain (RD). Following the branch bifurcation rules in <ref type="bibr" target="#b21">[22]</ref> (details can be found in supplementary materials), the coronary artery trees are split into several segments, denoted by S = {S i } N i=1 , where N is the number of segments, S i ∈ R Li×3 denotes the i-th segment comprised of the 3D positions of L i centerline points. Our model takes as input the vessel segments S and their connections C = {(i 1 , j 1 ), (i 2 , j 2 ), ..., (i Nc , j Nc )}, where (i k , j k ) indicates that the i k -th segment is connected with the j k -th segment. The objective is to predict the classes of the vessel segments.</p><p>As illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>, we design a novel framework named TopoLab for the automatic labeling of coronary arteries. In Sect. 3.2, we will introduce the hierarchical feature extraction module comprised of intra-segment feature aggregation and inter-segment feature interaction. In Sect. 3.3, we will elaborate on the details of AC-Classifier which exploits the category topological trees effectively. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Hierarchical Feature Extraction</head><p>We first feed the CCTA image X ∈ R H×W ×D into an image encoder (e.g. U-Net <ref type="bibr" target="#b1">[2]</ref>) to obtain the downscaled feature map F ∈ R H/4×W/4×D/4×C , where C is the channel size.</p><p>For each segment S i , trilinear interpolation in the downsampled feature map F is adopted for the centerline point v ∈ S i to obtain the corresponding point features</p><formula xml:id="formula_0">f (v) = Tri(v, F ) ∈ R C . The segment features are denoted as {f (v)|v ∈ S i }, simplified as E i ∈ R Li×C .</formula><p>Intra-Segment Feature Aggregation. To extract the segment-level features for labeling, aggregation of sequential point features belonging to the same segment is required. Previous studies <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b21">22]</ref> employ Bidirectional LSTM <ref type="bibr" target="#b5">[6]</ref> to summarize the tubular sequential features. However, due to the weak representative ability of LSTM for the vessel segments with huge length variability, the performance of these methods is limited.</p><p>We introduce Transformer <ref type="bibr" target="#b16">[17]</ref> as our intra-segment feature aggregator for its strong capability to model the relationships among the sequences with varying lengths. Concretely, we set a learnable embedding q ∈ R C called segment query to aggregate intra-segment point features. The segment query is concatenated with the segment features E i to obtain the new tensor Ẽi ∈ R (Li+1)×C . Following <ref type="bibr" target="#b3">[4]</ref>, we feed Ẽi augmented by the learnable 3D positional encodings into a Transformer encoder containing several standard sub-blocks. Each standard sub-block has the same architecture as in <ref type="bibr" target="#b16">[17]</ref>, which consists of multi-head attention, feed-forward network, layer normalization and ReLU activation. The state of the segment query q at the output of the Transformer encoder serves as the aggregated segment representation Êi ∈ R C .</p><p>Inter-Segment Feature Interaction. The branching structure of coronary arteries is inherently graph-like, with each segment serving as a node and the connections between segments serving as edges. Thus, we leverage graph convolutional network <ref type="bibr" target="#b7">[8]</ref> (GCN) to capture the interactions among different segments.</p><p>Specifically, let Ê ∈ R N ×C denotes the aggregated segment features where the i-th item of Ê is Êi , and A ∈ R N ×N is the adjacency matrix for the vessel segment graph derived from the segment connections C. The process of GCN layers is as follows:</p><formula xml:id="formula_1">Êl+1 = σ(A Êl W l ),<label>(1)</label></formula><p>where σ is the ReLU activation, W l ∈ R C×C is the learnable parameters for the l-th GCN layer, the input for the first layer is Ê0 = Ê. Finally, we fuse the input segment features Ê and the output of the final GCN layer Êf to obtain E = [ Êf , Ê]W f ∈ R N ×C with the parameters W f ∈ R (C+C)×C . The enhanced segment features {E 1 , E 2 , ..., E N } are forwarded to the classifier for segment labeling, where E i ∈ R C is the i-th item of E.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Anatomy-Aware Connection Classifier</head><p>The direct approach for labeling the coronary arteries is to use a linear layer to classify each segment independently as in previous methods. To incorporate the category topological trees into the classifier design, we propose to conduct the classification task for every connected segment pair.</p><p>We begin by defining the ground truth segment connections which are composed of the topology-conforming connections derived from the category topological trees (like LM→LAD, LCX→OM, etc.). Note that the self-connections (e.g. RCA→RCA) are also considered as the ground truth connections. The ground truth segment connections have the corresponding template embeddings for classification, which are represented by G ∈ R Ng×2C , where N g is the number of ground truth segment connections. Denote g i = Concate(Enc(x), Enc(y)) ∈ R 2C as the i-th item of G, where x and y stand for the segment classes indexed by the i-th ground truth connection, Enc denotes the sinusoidal encoding as in <ref type="bibr" target="#b16">[17]</ref>.</p><p>The connection templates G are used to enable classification for the connected segment pairs. Then, given the segment features {E i } N i=1 , and all of the connected segment pairs C = {(i 1 , j 1 ), (i 2 , j 2 ), ..., (i Nc , j Nc )}, the connection features P ∈ R Nc×2C are obtained by rearrangement of the segment features, where the k-th item of P is Concate(E i k , E j k ) ∈ R 2C . We use an MLP layer to further fuse the features</p><formula xml:id="formula_2">P = MLP(P ) ∈ R Nc×2C .</formula><p>Training Loss. The loss function can be written as:</p><formula xml:id="formula_3">L = Nc i L cls (p i , y i ),<label>(2)</label></formula><formula xml:id="formula_4">L cls = -log exp(sim(p i , g yi )/τ ) Ng j=1 exp(sim(p i , g j )/τ ) , (<label>3</label></formula><formula xml:id="formula_5">)</formula><p>where y i is the ground truth of the i-th segment connection, pi denotes the i-th item of P . sim in Eq. 3 stand for the cosine similarity, sim(x, y) = x T y ||x||2||y||2 , and the temperature τ is a hyperparameter which is set as 0.05 by default.</p><p>Inference. During the inference stage, for each segment, we first select the connection with the largest confidence score among all segment connections that have covered the given segment. And then the corresponding category indexed by the selected connection serves as the prediction of the specific segment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Setup</head><p>Datasets. We train and evaluate our method on two datasets. The orCaScore <ref type="bibr" target="#b18">[19]</ref> MICCAI 2014 Challenge contains 72 contrast-enhanced CTA images and non-contrast enhanced CT scans. As the original dataset only contains the labels of calcifications, we have annotated vessel segmentation and anatomical categories for coronary arteries with experienced radiologists. Considering the small amount of data, we randomly split the dataset into five folds to perform cross-validation. The mean values of cross-validation results are reported. We also collect an In-house Dataset containing 1200 CTA scans which have been annotated by at least two experts. The dataset is collected in compliance with the terms of the licensing agreement and ethical certification. We randomly split the dataset into train, validation and test set with 800, 200 and 200 scans respectively. The annotations for both datasets adhere to the same standard, which includes 14 classes of coronary artery segments (see Fig. <ref type="figure" target="#fig_0">1(b)</ref>). It is a challenging task, surpassing the scope of studies like TreeLab-Net <ref type="bibr" target="#b19">[20]</ref> and CPR-GCN <ref type="bibr" target="#b21">[22]</ref>, which only consider 10 and 11 categories, respectively. Evaluation Metrics. Following previous methods <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b23">24]</ref>, we adopt the mean metrics of all categories of the segments including recall, precision and F1. Note that the mean metric is the weighted average based on the number of segments of different categories. To further evaluate the topological accuracy of connected segments, we propose two new metrics: viola and viola c , which reflect the segment-level topological accuracy and the case-level topological accuracy, respectively. Specifically, viola is calculated as the ratio of the number of connections violating the topology to the total number of connections, while viola c is calculated as the ratio of the number of test cases containing any topologyviolating connection to the total number of test cases. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation Details</head><p>3D ResUNet <ref type="bibr" target="#b24">[25]</ref> is employed as the image encoder for feature extraction with channel dimension C = 64. The transformer encoder has 3 standard blocks and the number of graph convolution layers is set to 4. We train the network using AdamW optimizer <ref type="bibr" target="#b9">[10]</ref> with a base learning rate of 5e-4 and the cosine learning rate schedule during the training stage. The batch size is set to 4. All networks are implemented by Pytorch <ref type="bibr" target="#b11">[12]</ref> and trained on four NVIDIA GeForce RTX 3090 GPUs. We train our model on the orCaScore dataset for 3.5k iterations and in-house dataset for 12.5k iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Comparison with Other Methods</head><p>Quantitative Results. We compare TopoLab with other deep learning based approaches including TaG-Net <ref type="bibr" target="#b22">[23]</ref>, CPR-GCN <ref type="bibr" target="#b21">[22]</ref>, TreeLab-Net <ref type="bibr" target="#b19">[20]</ref>, and CorLab-Net <ref type="bibr" target="#b23">[24]</ref> which are implemented by ourselves with the same training configurations for a fair comparison. Note that for the point cloud-based methods <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref>, we use intra-segment voting to transform the point-level predictions into segment-level predictions. From the results on the orCaScore dataset in Table <ref type="table" target="#tab_0">1</ref> and the in-house dataset in Table <ref type="table" target="#tab_1">2</ref>, we can conclude that the proposed TopoLab outperforms all existing methods by a large margin. The performance gains are more significant in the topology-related metrics, which demonstrates the effectiveness of the utilization of prior knowledge. More detailed results on each category of coronary arteries can be found in the supplementary materials.</p><p>Qualitative Results. In Fig. <ref type="figure" target="#fig_2">3</ref>, we present a qualitative comparison of TopoLab with other methods. Consider the first case as an example, where our approach successfully avoids topology-violating errors, whereas other methods incorrectly classify RI as D, leading to the RI→D, D→RI, or LM→D connections that violate topology. These visualizations demonstrate the effectiveness of the usage of category topological trees. More qualitative results can be found in supplementary materials. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Ablation Study</head><p>In this subsection, we explore the effectiveness of different components in Topo-Lab on orCaScore dataset, as shown in Table <ref type="table" target="#tab_2">3</ref>.</p><p>Intra-segment Feature Aggregation (IFA). Transformer <ref type="bibr" target="#b16">[17]</ref> is leveraged to achieve the intra-segment feature aggregation in our model. To validate its benefits, we replace it with the Bi-LSTM used in CPR-GCN. From the results in the first line of Table <ref type="table" target="#tab_2">3</ref>, our method surpasses Bi-LSTM by 7.94% in F1 score and 26.57% in Viola c .</p><p>Inter-segment Feature Interaction (IFI). We use GCN to establish intersegment feature interactions due to the natural graph structure of coronary arteries. When directly removing this module, the performance drops by 1.57% in F1 score and 19.14% in Viola c as illustrated in the second line of Table <ref type="table" target="#tab_2">3</ref>.</p><p>Anatomy-Aware Connection Classifier (ACC). AC-Classifier which exploits the prior knowledge from category topological trees is adopted to classify each connected segment pair. We replace it with a commonly used linear layer to enable classification for single segments as in previous methods, and the performance drops by 1.33% in Viola and 15.42% in Viola c , which effectively demonstrates the superiority of the proposed method. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this study, we review the essential task of coronary artery labeling and exploit the prior knowledge of the predetermined anatomical connections. The proposed strategies of intra-and inter-segment feature aggregation guarantee effective feature extraction, while the AC-Classifier preserves the clinical logic in the network design. The extensive experiments on orCaScore dataset and in-house dataset reveal that the proposed TopoLab has achieved new state-of-the-art performance. We hope our paper could encourage the community to explore the use of clinical priority to facilitate the design of more effective algorithms.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. (a) The task of coronary artery labeling aims to assign each vessel segment an anatomical category. (b) The anatomically predetermined connections among different categories of coronary arteries form a tree structure -category topological trees. (c) shows an example containing obvious mistakes violating the prior topology made by previous methods.</figDesc><graphic coords="2,39,39,168,68,340,69,82,81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The pipeline of our proposed TopoLab.</figDesc><graphic coords="4,41,79,256,52,340,33,126,13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Visual comparison between our TopoLab and other methods. Errors violating topology are highlighted in red boxes, while errors that do not violate topology are marked in orange boxes. The corresponding positions in the ground truth and TopoLab predictions are indicated by blue boxes. (Color figure online)</figDesc><graphic coords="9,70,47,178,31,311,41,137,62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Comparison with other methods on orCaScore dataset(%). Each entry of the table shows the average value of 5 folds with the standard deviation in subscript. "Recall, precision, and F1" of each fold are the weighted averages of the 14 vessel categories.</figDesc><table><row><cell>Method</cell><cell>Recall</cell><cell>Precison F1</cell><cell>Viola</cell><cell>Viola c</cell></row><row><cell>TaG-Net [23]</cell><cell cols="4">82.292.07 83.412.28 82.142.32 10.872.49 87.624.85</cell></row><row><cell cols="5">CorLab-Net [24] 82.091.03 83.831.53 82.151.18 9.011.09 75.0510.01</cell></row><row><cell cols="5">TreeLab-Net [20] 83.352.80 84.902.11 83.122.96 3.751.08 55.5217.26</cell></row><row><cell>CPR-GCN [22]</cell><cell cols="4">82.881.44 83.611.59 82.721.55 4.941.49 53.919.53</cell></row><row><cell cols="5">TopoLab(Ours) 87.131.03 88.311.60 87.231.29 1.520.73 22.298.30</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Comparison with other methods on in-house dataset (%). Each entry of the table shows the average value of 5 trials with the standard deviation in subscript. "Recall, precision, and F1" of each trial are the weighted averages of the 14 vessel categories.</figDesc><table><row><cell>Method</cell><cell>Recall</cell><cell>Precision F1</cell><cell>Viola</cell><cell>Viola c</cell></row><row><cell>TaG-Net [23]</cell><cell cols="4">88.260.30 88.470.34 88.230.34 6.460.28 65.901.98</cell></row><row><cell cols="5">CorLab-Net [24] 88.850.35 88.960.34 88.830.35 4.750.31 57.101.46</cell></row><row><cell cols="5">TreeLab-Net [20] 88.580.43 88.560.44 88.520.44 2.340.09 32.700.51</cell></row><row><cell>CPR-GCN [22]</cell><cell cols="4">90.920.15 90.840.13 90.840.14 2.890.17 38.703.93</cell></row><row><cell cols="5">TopoLab(Ours) 92.230.23 92.210.25 92.190.23 0.770.13 9.401.69</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Ablation Study on orCaScore Dataset(%). Each entry of the table shows the average value of 5 folds. "Recall, precision, and F1" of each fold are the weighted averages of the 14 vessel categories.</figDesc><table><row><cell>Method</cell><cell>Recall</cell><cell>Precision F1</cell><cell>Viola</cell><cell>Viola c</cell></row><row><cell cols="5">w/o IFA 79.613.38 81.472.71 79.293.35 4.001.82 48.8620.39</cell></row><row><cell>w/o IFI</cell><cell cols="4">85.792.61 86.742.77 85.662.83 2.981.54 41.4315.55</cell></row><row><cell cols="5">w/o ACC 86.881.39 88.151.74 86.951.57 2.850.85 37.7110.26</cell></row><row><cell cols="5">TopoLab 87.131.03 88.311.60 87.231.29 1.520.73 22.298.30</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. We would like to thank <rs type="person">Dr. Nianxi Liao</rs> for valuable discussions. This work is supported by <rs type="funder">National Key R&amp;D Program of China</rs> (<rs type="grantNumber">2022ZD0114900</rs>) and <rs type="funder">National Science Foundation of China</rs> (<rs type="grantNumber">NSFC62276005</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Jm5XMKW">
					<idno type="grant-number">2022ZD0114900</idno>
				</org>
				<org type="funding" xml:id="_ed4hh2A">
					<idno type="grant-number">NSFC62276005</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43990-2_71.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Automatic identification of coronary tree anatomy in coronary computed tomography angiography</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Cardiovasc. Imaging</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1809" to="1819" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">3D U-Net: learning dense volumetric segmentation from sparse annotation</title>
		<author>
			<persName><forename type="first">Ö</forename><surname>Çiçek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abdulkadir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Lienkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-46723-8_49</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-46723-8_49" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2016</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Ourselin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Joskowicz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Sabuncu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Unal</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Wells</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">9901</biblScope>
			<biblScope unit="page" from="424" to="432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Intrathoracic spatial location of specified coronary segments on the normal human heart. applications in quantitative arteriography, assessment of regional risk and contraction, and anatomic display</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Dodge</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Bolson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Dodge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Circulation</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1167" to="1180" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.11929</idno>
		<title level="m">An image is worth 16x16 words: transformers for image recognition at scale</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On the history of the minimum spanning tree problem</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. History Comput</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="43" to="57" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Framewise phoneme classification with bidirectional LSTM and other neural network architectures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5-6</biblScope>
			<biblScope unit="page" from="602" to="610" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">nnu-net: a self-configuring method for deep learning-based biomedical image segmentation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Isensee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Kohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Maier-Hein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="211" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Building skeleton models via 3-d medial surface axis thinning algorithms</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Kashyap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">N</forename><surname>Chu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVGIP: Graph. Models Image Process</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="462" to="478" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05101</idno>
		<title level="m">Decoupled weight decay regularization</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">64-slice computed tomography angiography in the diagnosis and assessment of coronary artery disease: systematic review and meta-analysis</title>
		<author>
			<persName><forename type="first">G</forename><surname>Mowatt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Heart</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1386" to="1393" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<editor>Wallach, H.M., Larochelle, H., Beygelzimer, A., d&apos;Alché-Buc, F., Fox, E.B., Garnett, R.</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Pointnet++: Deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">U-Net: convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-24574-4_28</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-24574-4_28" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2015</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hornegger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">9351</biblScope>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep learning in medical image analysis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">I</forename><surname>Suk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="221" to="248" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">cldice-a novel topology-preserving loss function for tubular structure segmentation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="16560" to="16569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Pointscatter: Point set representation for tubular structure extraction</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-19803-8_22</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-19803-8_22" />
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2022: 17th European Conference</title>
		<meeting><address><addrLine>Tel Aviv, Israel; Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">October 23-27, 2022. 2022</date>
			<biblScope unit="page" from="366" to="383" />
		</imprint>
	</monogr>
	<note>Proceedings, Part XXI</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An evaluation of automatic coronary artery calcium scoring methods with cardiac CT using the orcascore framework</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Wolterink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Phys</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2361" to="2373" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Automated anatomical labeling of coronary arteries via bidirectional tree LSTMs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Assist. Radiol. Surg</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="271" to="280" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Automatic coronary artery tree labeling in coronary computed tomographic angiography datasets</title>
		<author>
			<persName><forename type="first">G</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 Computing in Cardiology</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="109" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Cpr-gcn: conditional partialresidual graph convolutional network in automated anatomical labeling of coronary arteries</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">S</forename><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3803" to="3811" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Tag-net: topology-aware graph network for centerline-based vessel labeling</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">CorLab-Net: anatomical dependency-aware point-cloud learning for automatic labeling of coronary arteries</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87589-3_59</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87589-3_59" />
	</analytic>
	<monogr>
		<title level="m">MLMI 2021</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Lian</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Cao</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Rekik</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Yan</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12966</biblScope>
			<biblScope unit="page" from="576" to="585" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Road extraction by deep residual u-net</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Lett</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="749" to="753" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
