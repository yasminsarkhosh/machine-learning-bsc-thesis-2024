<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">AUA-dE: An Adaptive Uncertainty Guided Attention for Diffusion MRI Models Estimation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Tianshu</forename><surname>Zheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Biomedical Engineering and Instrument Science</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ruicheng</forename><surname>Ba</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Biomedical Engineering and Instrument Science</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaoli</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Medical lmaging</orgName>
								<orgName type="institution">Weifang Medical University</orgName>
								<address>
									<settlement>Weifang</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chuyang</forename><surname>Ye</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Integrated Circuits and Electronics</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dan</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Biomedical Engineering and Instrument Science</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">AUA-dE: An Adaptive Uncertainty Guided Attention for Diffusion MRI Models Estimation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E5BB0AD93D260BC63B8845CB9BBE9461</idno>
					<idno type="DOI">10.1007/978-3-031-43993-3_14</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-24T11:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Diffusion MRI</term>
					<term>Noisy Data</term>
					<term>Parameter Estimation</term>
					<term>Uncertainty Attention</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Diffusion MRI (dMRI) is a well-established tool for probing tissue microstructure properties. However, advanced dMRI models commonly have multiple compartments that are highly nonlinear and complex, and also require dense sampling in q-space. These problems have been investigated using deep learning based techniques. In existing approaches, the labels were calculated from the fully sampled q-space as the ground truth. However, for some of the dMRI models, dense sampling is hard to achieve due to the long scan time, and the low signal-to-noise ratio could lead to noisy labels that make it hard for the network to learn the relationship between the signals and labels. A good example is the time-dependent dMRI (TD-dMRI), which captures the microstructural size and transmembrane exchange by measuring the signal at varying diffusion times but requires dense sampling in both q-space and t-space. To overcome the noisy label problem and accelerate the acquisition, in this work, we proposed an adaptive uncertainty guided attention for diffusion MRI models estimation (AUA-dE) to estimate the microstructural parameters in the TD-dMRI model. We evaluated our proposed method with three different downsampling strategies, including q-space downsampling, t-space downsampling, and q-t space downsampling, on two different datasets: a simulation dataset and an experimental dataset from normal and injured rat brains. Our proposed method achieved the best performance compared to the previous q-space learning methods and the conventional optimization methods in terms of accuracy and robustness.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Diffusion MRI (dMRI) is a powerful medical imaging tool for probing microstructural information based on the restricted diffusion assumption of the water molecules in biological tissues <ref type="bibr" target="#b6">[7]</ref>. The conventional dMRI uses the apparent diffusion coefficient (ADC) to measure the diffusivity change, but it's not specific to microstructural properties. Recently, a series of advanced dMRI models, such as time-dependent dMRI (TD-dMRI) models <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9]</ref>, have been proposed to sample diffusion at different effective diffusion-times (so-called t-space), and related biophysical models have been developed to resolve the cellular microstructures.</p><p>Advanced dMRI models are typically multi-compartment models with highly non-linear and complex formulations. Accurate parameter estimation from such models requires dense q-space and/or t-space sampling. Deep learning techniques have been proposed to improve estimation accuracy from downsampled q-space data <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b14">15]</ref>, by training networks to learn the relationship between downsampled diffusion signals and microstructural metrics from fully sampled q-space. However, TD-dMRI models require dense sampling in both q-space and t-space, which is challenging for clinical usage. To our best knowledge, previous works have not investigated downsampling models in t-space or joint q-t space.</p><p>The previous q-space learning networks <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b14">15]</ref>, simply learned the mapping relationship between undersampled diffusion signals in q-space and diffusion model parameters. They neglected the "noisy label" problem, and thus, may suffer from training degradation due to failure to obtain valid information. Different from the annotated label, which is called ground-truth in the natural image, in the dMRI model estimation area, we used the parameters estimated from fully sampled q-space as the "gold standard" that actually suffer from estimation error due to noise in the data acquisition and also the limited number of samples in q-space. These two problems are particularly worth noting in TD-dMRI, which is known to have low SNR, and the errors could accumulate in the joint qt space models. This imposed a vital problem for end-to-end t-space learning in practice. To address the challenge of learning from noisy data, we proposed an adaptive uncertainty guided attention for diffusion MRI models estimation (AUA-dE) based upon the previous AEME network <ref type="bibr" target="#b14">[15]</ref> for estimating general dMRI model parameters.</p><p>In this work, we proposed a reweighting strategy to reduce the negative effects of noisy label based on uncertainty. Our contributions can be summarized below:</p><p>1. We brought up an important problem of the noisy label in dMRI model estimation which was not addressed before. 2. We proposed an attention-based sparse encoder to make the network focus on the key diffusion signal out of many q-space or t-space signals. 3. We developed an uncertainty-based reweighting strategy considering the uncertainty in both dMRI channels and spatial domain for microstructural estimation. 4. We proposed an end-to-end estimation strategy in both q-space and t-space with downsampled q-t space data.</p><p>In our work, we firstly demonstrated the effectiveness of our attention-based reweighting strategy on a simulation dataset, and then we evaluated our work with three different downsampling strategies (q-space, t-space, and q-t space) on a TD-dMRI dataset of normal and injured rat brains. We tested a TD-dMRI model which estimates the transmembrane water exchange time based on timedependent diffusion kurtosis <ref type="bibr" target="#b9">[10]</ref>, here we named tDKI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">q-t Space Sparsity</head><p>In this study, we extended the q-space learning model AEME <ref type="bibr" target="#b14">[15]</ref> into the q-t space, and the signal can be represented as follows:</p><formula xml:id="formula_0">Y = ΓXΥ T + H<label>(1)</label></formula><p>where </p><formula xml:id="formula_1">Y = (y 1 • • • y V ) ∈ R K×V (K</formula><formula xml:id="formula_2">y v (v ∈ {1, • • • , V })</formula><p>is the diffusion signal normalized by b0 at different t d , and X ∈ R NΓ×NΥ is the matrix of the mixed sparse dictionary coefficients. Γ ∈ R K×NΓ and Υ ∈ R V ×NΥ are decomposed dictionaries that encode the information in the mixed q-t domain and the spatial domain. H is the noise corresponding to X. Then the sparse encoder can be formulated using the extragradient-based method similar to <ref type="bibr" target="#b14">[15]</ref>:</p><formula xml:id="formula_3">X n+ 1 2 = H M AU A(X n , Γ T YΥ, Γ T ΓX n Υ T Υ)<label>(2)</label></formula><formula xml:id="formula_4">X n+1 = H M AU A(X n , A 1 Γ T YΥ, A 1 Γ T ΓX n+ 1 2 Υ T Υ)<label>(3)</label></formula><p>where, A 1 denotes a scalar matrix, AU A(•) is the adaptive uncertainty attention function, and H M denotes a nonlinear operator corresponding to the threshold layer in Fig. <ref type="figure" target="#fig_1">1(b)</ref>:</p><formula xml:id="formula_5">H M (X ij ) = 0, if X ij &lt; λ X ij , if X ij ≥ λ (4)</formula><p>So far, we can obtain the sparse representation of the signal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Adaptive Uncertainty Attention Modelling</head><p>Uncertainty Attention Module. Inspired by the uncertainty modeling mechanism of Bayesian neural networks <ref type="bibr" target="#b5">[6]</ref>, we defined uncertainty attention (UA) to address the noisy label problem. For simplicity, we used Monte Carlo dropout to obtain the posterior distribution, other uncertainty quantification methods would also work. The basic attention module is adapted from CBAM <ref type="bibr" target="#b11">[12]</ref>, which includes channel and spatial attention. To better capture feature information, we employ mean and standard deviation pooling. Then the UA module is formulated according to the gray shaded box in Fig. <ref type="figure" target="#fig_1">1(b</ref>). The top branch is the channel uncertainty attention (CUA) module, and the bottom branch is the spatial uncertainty attention (SUA) module. Through the CUA module, the uncertainty reweighted sparse representation of the original signal X can be obtained: X CUA = CU A(X). CU A(•) is the channel-wise uncertainty attention function, which is used to model the uncertainty in the diffusion channels. The CUA of X can be obtained after the stochastic forward with dropout:</p><formula xml:id="formula_6">U C = V ar(X k CUA ). U C is the uncertainty of the channel-wise information, X k</formula><p>CUA is a cluster of different sparse representations of X after dropout in the CUA module, and k is the number of stochastic forwards.</p><p>Similarly, the SUA module can be defined as: X SUA = SU A(X CUA ). SU A(•) is the spatial-wise uncertainty attention, which is used to model the uncertainty of the spatial-wise information. The SUA of X CUA can be estimated as follows:</p><formula xml:id="formula_7">U S = V ar(X k SUA )</formula><p>. U S is the uncertainty of the spatial-wise information, X k SUA is a cluster of different sparse representations of X CUA after dropout in the SUA module.</p><p>For simplicity and efficiency, in practice, we combined these two kinds of uncertainty together to reweight the whole sparse representation X as: U = V ar(X k ). U is the uncertainty of the sparse representation, X k is a cluster of different sparse representations of X after dropout in both CUA and SUA modules.</p><p>Adaptive Reweight Mechanism. In this work, we proposed an adaptive reweighting strategy by lowering the loss weight for a patch that may be corrupted by the noise. After the uncertainty U is approximated, We can set a weight tenor U w as below:</p><formula xml:id="formula_8">U w = 1 -U<label>(5)</label></formula><p>Then, the impact of noise can be mitigated by an adaptive weight matrix R:</p><formula xml:id="formula_9">R = t, if U w &lt; t U w , if U w ≥ t (6)</formula><p>where, t is a trainable parameter in the network, which can be modified adaptively. Then X will be reweighted by the R in the loss function as:</p><formula xml:id="formula_10">L = ||M (R X) -P || 2<label>(7)</label></formula><p>where, denotes the element-wise multiplication, M (•) is a mapping function corresponding to the mapping networks, P is the observed label of the estimated dMRI model parameters.</p><p>Network Construction. Following the q-t space sparsity analysis and the adaptive uncertainty mechanism mentioned above, we can incorporate historical information <ref type="bibr" target="#b14">[15]</ref> into Eq. 2 and Eq. 3 to formulate the adaptive uncertainty attention sparse encoder (AUA-SE). </p><formula xml:id="formula_11">Cn+ 1 2 = W m1 YW s1 + X n -S m1 X n S s1<label>(8)</label></formula><formula xml:id="formula_12">C n+ 1 2 = AU A(F n+ 1 2 C n + G n+ 1 2 Cn+ 1 2 )<label>(9)</label></formula><formula xml:id="formula_13">X UA n+ 1 2 = H M C n+ 1 2<label>(10)</label></formula><formula xml:id="formula_14">Cn+1 = W m2 YW s2 + X n -S m2 X n+ 1 2 S s2<label>(11)</label></formula><formula xml:id="formula_15">C n+1 = AU A(F n+1 C n+ 1 2 + G n+1 Cn+1 )<label>(12)</label></formula><formula xml:id="formula_16">X UA n+1 = H M C n+1 (13)</formula><p>where, </p><formula xml:id="formula_17">W m1 ∈ R NΓ×K , W m2 ∈ R NΓ×K , W s1 ∈ R V ×NΥ , W s2 ∈ R V ×NΥ , S m1 ∈ R NΓ×NΓ , S m2 ∈ R NΓ×NΓ , S s1 ∈ R NΥ×NΥ ,</formula><formula xml:id="formula_18">F n+ 1 2 , F n+1 , G n+ 1 2</formula><p>, and G n+1 and they can be defined as <ref type="bibr" target="#b14">[15]</ref>. Further fundamental details on formulas and network architecture can be found in <ref type="bibr" target="#b13">[14]</ref>.</p><p>The overall network can be constructed by repeating the AUA-SE unit n times, and the output will be sent to the mapping networks for mapping the microstructure parameters, which consist of three fully connected layers of the feed-forward networks <ref type="bibr" target="#b14">[15]</ref>. The overall structure is illustrated in Fig. <ref type="figure" target="#fig_1">1</ref> (a).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Dataset and Training</head><p>The tDKI model is defined as below <ref type="bibr" target="#b9">[10]</ref>:</p><formula xml:id="formula_19">K(t) = 2K 0 τ m t × [1 - τ m t × (1 -e -t τm )]<label>(14)</label></formula><p>where, K(t) is the kurtosis at different t d , K 0 is the kurtosis at t d = 0, t is the t d and τ m is the water mixing time. K(t) at individual t d is obtained according to the DKE method <ref type="bibr" target="#b10">[11]</ref>.</p><p>Simulation Dataset was formed following the method of Barbieri et al., <ref type="bibr" target="#b0">[1]</ref>, where we plugged the varying parameters (K 0 , τ m ) into Eq. 14 to obtain the kurtosis signal at different t d (50, 100, and 200 ms). Parameter values were sampled uniformly from the following ranges according to the fitted values observed in rat brain data: K 0 between 0 and 3, τ m between 2 and 200 ms, and a total of 409600 signals were generated. And 60% of them were used for training, 10% for validation, and 30% for testing.</p><p>In order to replicate the noisy label problem, we varied the noise level from SNR=10 to 30 in the t-space signal. In the training data, we used a Bayesian method modified from Gustafsson et al. <ref type="bibr" target="#b3">[4]</ref> to obtain the label, and in the test data, we used "gold standard" label set from simulation.</p><p>Rat Brain Dataset was collected on a 7T Bruker scanner from 3 normal rats and 10 rats that underwent a model of ischemic injury by transient Middle Cerebral Artery Occlusion (MCAO). Diffusion gradients were applied in 18 directions per b-value at 3 b-values of 0.8, 1.5, and 2.5 ms/ μ m 2 and 5 t d (50, 80, 100, 150, and 200 ms) with the following acquisition parameters: repetition time/echo time = 2207/18 ms, in-plane resolution = 0.3 × 0.3 mm 2 , 10 slices with a slice thickness of 1 mm.</p><p>In order to get the gold standard, the DKE toolbox <ref type="bibr" target="#b10">[11]</ref> was used to calculate the kurtosis at different t d with the fully sampled q-space, and then used the Bayesian method mentioned above to estimate K 0 and τ m with the fully sampled t-space. The dataset was downsampled with randomly selected 9 gradients at b = 0.8 and 1.5 ms/ μ m 2 in q-space and 3 t d (50, 100, and 200 ms) in t-space. We mixed the 2 normal and 8 injured rats together for training (90%) and validation (10%), and 1 normal with 2 injured rats for testing.</p><p>Training. In this work, the dictionary size of our AUA-dE was set at 301, and the hidden size of the fully connected layer was 75. We used an early stopping strategy and a reducing learning rate with an initial learning rate of 1 × 10 -4 . AdamW was selected as the optimizer with a batch size of 256. The dropout in the AUA-SE was 0.2 for 50 forward processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Ablation Study</head><p>We compared four different methods, including AEME <ref type="bibr" target="#b14">[15]</ref> (baseline of the current network but without the attention or uncertainty mechanism), AEME with attention (the baseline with the attention), AEME with UA (the baseline with UA but without adaptive mechanism), and AEME with AUA (our proposed AUA-dE) to evaluate the effectiveness of UA and AUA in mitigating the negative effect of the noisy label.</p><p>Here, we used the relative error (percentage of the gold standard) to compare different algorithms. Figure <ref type="figure" target="#fig_2">2</ref> showed that network structures with UA (AEME with UA and AUA-dE) achieved lower errors compared with other methods, especially in the lowest SNR environment. AUA-dE achieved the lowest estimation error because the threshold of uncertainty is a trainable parameter that does not need to be manually defined. Meanwhile, we performed paired t-tests for all comparative results, and AUA-dE showed significantly lower errors than all other methods. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Performance Test</head><p>q -Space Downsampling. We used our AUA-dE to estimate kurtosis at different t d using the downsampled q-space, in comparison with an optimization based method DKE <ref type="bibr" target="#b10">[11]</ref>, a common q-space baseline q-DL <ref type="bibr" target="#b2">[3]</ref>, and the latest optimization based learning structure AEME <ref type="bibr" target="#b14">[15]</ref>. Table <ref type="table" target="#tab_2">1</ref> shows that our proposed AUA-dE achieved the lowest mean squared error (MSE) when compared to other methods for all t d in both the normal and injured rat brain regions.</p><p>t-Space Downsampling. In the t-space downsampling performance experiment, we used our AUA-dE to estimate the K 0 and τ m based on K(t) at varying t d . We compared our method with the Bayesian method <ref type="bibr" target="#b3">[4]</ref>, q-DL, and AEME.</p><p>From Table <ref type="table" target="#tab_3">2</ref>, it can be found our proposed AUA-dE achieved the lowest MSE compared with other methods in both normal and injured brain regions. Compared with previous methods, our error was only about 20% of the q-DL error in normal tissues and 40% in the injured regions. q-t Space Downsampling. In q-t space downsampling, we used our proposed AUA-dE to estimate the K 0 and τ m with jointly downsampled q-t space data with 5 times acceleration (3 folds in q-space and 1.7 folds in t-space). Figure <ref type="figure" target="#fig_3">3</ref> showed the estimated K 0 and τ m maps of an injured rat brain, using DKE+Bayesian, q-DL, AEME, and AUA-dE. Only AUA-dE was capable of capturing the abnormal rise in the injured cortex in the τ m map (denoted by the red arrow), indicating the clinical potential of this method for diagnosis of ischemic brain injury. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this work, we proposed an adaptive uncertainty guided attention for diffusion MRI models estimation (AUA-dE) to address the noisy label problem in the estimation of TD-dMRI-based microstructural models. We tested our proposed network and module in a rat brain dataset and a simulation dataset. The proposed method showed the highest estimation accuracy in all of these datasets. Meanwhile, we demonstrated its performance on jointly downsampled q-t space data, for which previous algorithms did not work well with the highly accelerated setup (270/54). In the future, we will further investigate our proposed AUA module as a plug-in in different dMRI model estimation networks and also different dMRI models to test its generalizability and robustness.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>c</head><label></label><figDesc>The Author(s), under exclusive license to Springer Nature Switzerland AG 2023 H. Greenspan et al. (Eds.): MICCAI 2023, LNCS 14227, pp. 142-151, 2023. https://doi.org/10.1007/978-3-031-43993-3_14</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. (a) The overall structure of the proposed AUA-dE. The AUA-dE is made up of a number of AUA-SE units that are used to build the sparse representation X from the diffusion signals Y, and then map the representation to the diffusion model parameters P . (b) The AUA-SE unit is associated with the adaptive attention mechanism based on uncertainty (gray shaded box). Y is the input dMRI signal, and X n+1 UA is the sparse representation weighted by the uncertainty attention.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Relative errors (percentage of the gold standard at the different SNR levels) of the estimated tDKI parameters at SNR levels from 10 to 30.</figDesc><graphic coords="7,234,66,211,52,76,72,89,44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The gold standard, estimated, and estimation errors of tDKI model parameters, based on DKE+Bayesian, q-DL, AEME, and AUA-dE (ours), in a injured rat brain with joint downsampled q-t space data. (Color figure online)</figDesc><graphic coords="8,99,48,398,36,253,12,136,96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .</head><label>1</label><figDesc>Evaluation of MSE on kurtosis using different methods on the downsampled q-space data with 9 different directions and 2 b-values (0.8 and 1.5 ms/μ m 2 ) under different t d in both normal and injured rats brains. The lowest errors are in bold.</figDesc><table><row><cell>Normal</cell><cell></cell><cell>Injured</cell><cell></cell><cell></cell></row><row><cell cols="5">DKE q -DL AEME AUA-dE DKE q -DL AEME AUA-dE</cell></row><row><cell>50 ms 0.15 0.033 0.020</cell><cell>0.017</cell><cell>0.12 0.25</cell><cell>0.062</cell><cell>0.052</cell></row><row><cell>100 ms 0.18 0.050 0.027</cell><cell>0.021</cell><cell>0.15 0.65</cell><cell>0.078</cell><cell>0.071</cell></row><row><cell>200 ms 0.28 0.058 0.029</cell><cell>0.027</cell><cell>0.13 0.89</cell><cell>0.102</cell><cell>0.087</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 .</head><label>2</label><figDesc>Evaluation of MSE on tDKI parameters using different methods on the downsampled t-space data with 3 t d (50, 100, and 200 ms) in both normal rats and injured regions. The lowest errors are in bold.</figDesc><table><row><cell>Normal</cell><cell></cell><cell></cell><cell>Injured</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">Bayesian q -DL AEME AUA-dE Bayesian q -DL AEME AUA-dE</cell></row><row><cell>K0 0.122</cell><cell>0.078 0.062</cell><cell>0.019</cell><cell>0.138</cell><cell cols="2">0.065 0.063</cell><cell>0.012</cell></row><row><cell>τm 8567</cell><cell>1570 685</cell><cell>303</cell><cell>4569</cell><cell>763</cell><cell>537</cell><cell>312</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep learning how to fit an intravoxel incoherent motion model to diffusion-weighted MRI</title>
		<author>
			<persName><forename type="first">S</forename><surname>Barbieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">J</forename><surname>Gurney-Champion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Klaassen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Thoeny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="312" to="321" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Simultaneous NODDO and GFA parameter map generation from subsampled q-space imaging using deep learning</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Gibbons</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2399" to="2411" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Q-space deep learning: twelve-fold shorter and model-free diffusion MRI scans</title>
		<author>
			<persName><forename type="first">V</forename><surname>Golkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1344" to="1351" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Impact of prior distributions and central tendency measures on Bayesian intravoxel incoherent motion model fitting</title>
		<author>
			<persName><forename type="first">O</forename><surname>Gustafsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Montelius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Starck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ljungberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1674" to="1683" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">In vivo imaging of cancer cell size and cellularity using temporal diffusion spectroscopy</title>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="156" to="164" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">What uncertainties do we need in Bayesian deep learning for computer vision?</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inform. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Principles of diffusion tensor imaging and its applications to basic neuroscience research</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="527" to="539" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Noninvasive quantification of solid tumor microstructure using verdict MRI</title>
		<author>
			<persName><forename type="first">E</forename><surname>Panagiotaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Can. Res</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1902" to="1912" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Pulsed and oscillating gradient mri for assessment of cell size and extracellular space (pomace) in mouse gliomas</title>
		<author>
			<persName><forename type="first">O</forename><surname>Reynaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">V</forename><surname>Winters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Z</forename><surname>Wadghiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Novikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NMR Biomed</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1350" to="1363" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Time-dependent diffusivity and kurtosis in phantoms and patients with head and neck cancer</title>
		<author>
			<persName><forename type="first">E</forename><surname>Solomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mag. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="522" to="535" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Estimation of tensors and tensor-derived measures in diffusional kurtosis imaging</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tabesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Ardekani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Helpern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="823" to="836" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">CBAM: convolutional block attention module</title>
		<author>
			<persName><forename type="first">S</forename><surname>Woo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Kweon</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-01234-2_1</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-01234-2_1" />
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2018: 15th European Conference</title>
		<editor>
			<persName><forename type="first">V</forename><surname>Ferrari</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hebert</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Sminchisescu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</editor>
		<meeting><address><addrLine>Munich, Germany; Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">September 8-14, 2018. 2018</date>
			<biblScope unit="page" from="3" to="19" />
		</imprint>
	</monogr>
	<note>Proceedings, Part VII</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Tissue microstructure estimation using a deep network inspired by a dictionary-based framework</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="288" to="299" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A deep network for tissue microstructure estimation using modified LSTM units</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="49" to="64" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An adaptive network with extragradient for diffusion MRI-based microstructure estimation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16431-6_15</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16431-6_15" />
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer Assisted Intervention -MICCAI 2022: 25th International Conference</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Singapore; Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">September 18-22, 2022. 2022</date>
			<biblScope unit="page" from="153" to="162" />
		</imprint>
	</monogr>
	<note>Proceedings, Part I</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
