<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SurfFlow: A Flow-Based Approach for Rapid and Accurate Cortical Surface Reconstruction from Infant Brain MRI</title>
				<funder ref="#_WwvxFQw #_64ZYdJ4">
					<orgName type="full">United States National Institutes of Health</orgName>
					<orgName type="abbreviated">NIH</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xiaoyang</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Radiology</orgName>
								<orgName type="institution">University of North Carolina</orgName>
								<address>
									<addrLine>Chapel Hill</addrLine>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Biomedical Research Imaging Center</orgName>
								<orgName type="institution">University of North Carolina</orgName>
								<address>
									<addrLine>Chapel Hill</addrLine>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Junjie</forename><surname>Zhao</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of North Carolina</orgName>
								<address>
									<addrLine>Chapel Hill</addrLine>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Siyuan</forename><surname>Liu</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">College of Marine Engineering</orgName>
								<orgName type="institution">Dalian Maritime University</orgName>
								<address>
									<settlement>Dalian</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sahar</forename><surname>Ahmad</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Radiology</orgName>
								<orgName type="institution">University of North Carolina</orgName>
								<address>
									<addrLine>Chapel Hill</addrLine>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Biomedical Research Imaging Center</orgName>
								<orgName type="institution">University of North Carolina</orgName>
								<address>
									<addrLine>Chapel Hill</addrLine>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Pew-Thian</forename><surname>Yap</surname></persName>
							<email>ptyap@med.unc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Radiology</orgName>
								<orgName type="institution">University of North Carolina</orgName>
								<address>
									<addrLine>Chapel Hill</addrLine>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Biomedical Research Imaging Center</orgName>
								<orgName type="institution">University of North Carolina</orgName>
								<address>
									<addrLine>Chapel Hill</addrLine>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SurfFlow: A Flow-Based Approach for Rapid and Accurate Cortical Surface Reconstruction from Infant Brain MRI</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">31B4FD2556857E99FD817806C5A39DCE</idno>
					<idno type="DOI">10.1007/978-3-031-43993-3_37</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-24T11:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Infant Brain MRI</term>
					<term>Cortical Surface Reconstruction</term>
					<term>Topology Preservation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The infant brain undergoes rapid changes in volume, shape, and structural organization during the first postnatal year. Accurate cortical surface reconstruction (CSR) is essential for understanding rapid changes in cortical morphometry during early brain development. However, existing CSR methods, designed for adult brain MRI, fall short in reconstructing cortical surfaces from infant MRI, owing to the poor tissue contrasts, partial volume effects, and rapid changes in cortical folding patterns. Here, we introduce an infant-centric CSR method in light of these challenges. Our method, SurfFlow, utilizes three seamlessly connected deformation blocks to sequentially deform an initial template mesh to target cortical surfaces. Remarkably, our method can rapidly reconstruct a high-resolution cortical surface mesh with 360k vertices in approximately one second. Performance evaluation based on an MRI dataset of infants 0 to 12 months of age indicates that SurfFlow significantly reduces geometric errors and substantially improves mesh regularity compared with state-of-the-art deep learning approaches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The human brain undergoes dramatic changes in size, shape, and tissue architecture during the first postnatal year, driven by cellular processes <ref type="bibr" target="#b0">[1]</ref> that lead to cortical folding and the formation of convoluted gyri and sulci on the cerebral surface. Understanding cortical development in these early postnatal years is crucial for comprehending later-stage functional development. Cortical surface reconstruction (CSR) is a step necessary for functional and anatomical visualization, brain morphology, and quantification of cortical growth. However, reconstructing the cortical surface from infant MRI poses significant challenges due to the low signal-to-noise ratio, pronounced motion artifacts, complex folding patterns, and rapid brain expansion <ref type="bibr" target="#b1">[2]</ref>.</p><p>CSR methods developed so far include FreeSurfer <ref type="bibr" target="#b4">[5]</ref>, DeepCSR <ref type="bibr" target="#b3">[4]</ref>, Voxel2Mesh <ref type="bibr" target="#b12">[13]</ref>, PialNN <ref type="bibr" target="#b7">[8]</ref>, and CorticalFlow <ref type="bibr" target="#b6">[7]</ref>. However, these methods are optimized primarily for adult brain MRI, typically with clear cortical gyral and sulcal patterns and good tissue contrasts. Their performance deteriorates significantly when applied to infant MRI due to challenges like narrow sulcal spaces, low tissue contrast, and partial volume effects. To address these issues, specific methods like the dHCP pipeline <ref type="bibr" target="#b8">[9]</ref> and Infant FreeSurfer <ref type="bibr" target="#b13">[14]</ref> have been developed. However, the dHCP pipeline is only effective for neonatal data and Infant FreeSurfer often fails to produce accurate cortical surfaces, especially for the first postnatal year when the brain undergoes dynamic changes in tissue contrasts and morphology. Additionally, the computational inefficiency of Infant FreeSurfer, which takes approximately 10 h to reconstruct cortical surfaces for a single subject, limits its applicability to large-scale studies.</p><p>In this paper, we propose SurfFlow, a geometric deep learning model designed to reconstruct accurate cortical surfaces from infant brain MRI. Our model comprises three cascaded deformation blocks, each responsible for predicting a flow field and constructing a diffeomorphic mapping for each vertex through solving a flow ordinary differential equation (ODE). The flow fields deform template meshes progressively to finally produce accurate genus-zero cortical surfaces. Our work offers a threefold contribution. First, we propose an efficient dualmodal flow-based CSR method, enabling the creation of high-resolution and high-quality mesh representations for complex cortical surfaces. Second, we propose a novel loss function that effectively regularizes the lengths of mesh edges, leading to substantial improvements in mesh quality. Third, our method represents the first attempt in tackling the challenging task of directly reconstructing cortical surfaces from infant brain MRI. Our method outperforms state-of-theart methods by a significant margin, judging based on multiple surface evaluation metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Overview</head><p>As depicted in Fig. <ref type="figure" target="#fig_0">1a</ref>, SurfFlow consists of three deformation blocks, each consisting of a 3D Unet <ref type="bibr" target="#b2">[3]</ref> and a diffeomorphic mesh deformation (DMD) module. The final mesh, either the pial surface or the white surface, is achieved by composing the three diffeomorphic deformations generated by the DMD modules. Each Unet takes a T1w-T2w image pair as input and, except the first network, also receives flow fields predicted by previous deformation blocks to predict a new flow field. Figure <ref type="figure" target="#fig_0">1b</ref> provides a detailed illustration of the design of the two different 3D Unets used. Each DMD module employs the flow field predicted within the same block and computes a diffeomorphic mapping φ θ (t; x) for each vertex x in the mesh generated by the previous deformation block through integration, assuming a stationary flow field. Formally, the dynamics of mesh deformation are formulated as a stationary flow ODE specified by a 3D Unet:</p><formula xml:id="formula_0">dφ θ (t; x) dt = V(φ θ (t; x)), φ θ (0; x) = x 0 ,<label>(1)</label></formula><p>where θ denotes the parameters of the 3D Unet, x 0 is the initial mesh before deformation in each stage. SurfFlow is trained stage-wise: a deformation block is trained with all previous deformation blocks frozen. Following CorticalFlow++ <ref type="bibr" target="#b9">[10]</ref>, the Runge-Kutta method is used for numerical integration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Dual-Modal Input</head><p>Infant MRI exhibits three distinct phases during the first year of life. In the infantile phase (≤5 months), gray matter (GM) shows higher signal intensity than white matter (WM) in T1w images. The isointense phase (5-8 months) corresponds to an increase in intensity of WM owing to myelination associated with brain maturation. This significantly lowers the contrast between GM and WM in T1w images and similarly T2w images. In the early adult-like phase (≥ 8 months), the GM intensity is lower than WM in T1w images, similar to the tissue contrast in adult MRI. We propose to use both T1w and T2w images for complementary information needed for accurate surface reconstruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Loss Function</head><p>The loss function used for training SurfFlow is a weighted sum of Chamfer distance (CD; L cd ) and a piecewise edge length loss (PELL; L e ), balanced by parameter λ:</p><formula xml:id="formula_1">L total = L cd + λL e . (<label>2</label></formula><formula xml:id="formula_2">)</formula><p>Chamfer Distance Loss. The Chamfer distance is commonly used as the loss function for surface reconstruction. It measures the distance from a vertex in one mesh P to the closest vertex in another mesh Q bidirectionally:</p><formula xml:id="formula_3">L cd = 1 |P | p∈P min q∈Q p -q 2 2 + 1 |Q| q∈Q min p∈P p -q 2 2 , (<label>3</label></formula><formula xml:id="formula_4">)</formula><p>where p and q are vertices in P and Q, respectively.</p><p>Piecewise Edge Length Loss. We observed that vertices tend to be clustered in surfaces generated by CorticalFlow++ (Fig. <ref type="figure" target="#fig_2">3</ref>). One possible cause is that the edge length loss used in CorticalFlow++ pushes edges to zero length. To address this problem, we propose a piecewise edge length loss that encourages edge lengths to lie within a suitable range. The proposed loss is formulated as</p><formula xml:id="formula_5">L e = 1 |P | p∈P 1 |N (p)| k∈N (p) ⎧ ⎪ ⎨ ⎪ ⎩ -p -k 2 2 if p -k 2 2 &lt; , 0 if p -k 2 2 γ , p -k 2 2 -γ otherwise,<label>(4)</label></formula><p>where P denotes the predicted mesh, p is a vertex in P , N (p) consists of the neighbors of p, and and γ are two tunable hyper-parameters that control the range position and width, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Deformation Computation in DMD Modules</head><p>Following CorticalFlow++, we use the fourth-order Runge-Kutta method to solve the stationary flow ODE over time interval [0, 1] for both accuracy and stability. The solution x 1 is obtained iteratively with</p><formula xml:id="formula_6">x tn+1 = x tn + h 6 k 1 + 2k 2 + 2k 3 + k 4 ,<label>(5)</label></formula><p>where</p><formula xml:id="formula_7">k 1 = V(x tn ), k 2 = V(x tn + k 1 h 2 ), k 3 = V(x tn + k 2<label>h</label></formula><p>2 ), and k 4 = V(x tn + k 3 h). V(x) represents the trilinear interpolation of the flow field at position x. h is the step size and is set to 1/30. t n is the time at n-th step, and t n+1 = t n + h.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Implementation Details</head><p>Our network was trained stage-wise. We froze the parameters of one deformation block once trained and then start the training of the next block. Each deformation block was trained for 27k iterations. Adam optimizer was used with an initial learning rate of 0.0001. The parameter λ of the loss function was set to 3.0 to balance the two loss terms. We set for PELL based on the average edge length determined from the training set. We set the γ to 4.0 and to 5 × 10 -5 . Instance normalization (IN) <ref type="bibr" target="#b10">[11]</ref> layers were added between convolutional and activation layers for faster convergence and improved performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data</head><p>The dataset includes aligned T1w and T2w image pairs from 121 subjects, 2 weeks to 12 months of age, from the Baby Connectome Project (BCP) <ref type="bibr" target="#b5">[6]</ref>. Among them, 90 cases were used for training, 12 for validation, and 19 for testing. Ground truth cortical surfaces were generated with iBEAT v2.0 <ref type="bibr" target="#b11">[12]</ref>.</p><p>To obtain a smooth starting template, an average convex hull computed from the training dataset was re-meshed and triangularized. The Catmull-Clark subdivision algorithm was then applied to generate enough faces and vertices. Decimation was used to control the number of vertices. These steps were carried out in Blender<ref type="foot" target="#foot_0">1</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation Metrics</head><p>For performance evaluation and comparison between different methods, we utilized the following metrics: Chamfer distance (CD), average symmetric surface distance (ASSD), 90% Hausdorff distance (HD), and normal consistency (NC). Their definitions are as follows:</p><formula xml:id="formula_8">CD = 1 2 p∈P min q∈Q p -q 2 |P | + q∈Q min p∈P p -q 2 |Q| , ASSD = 1 2 p∈P min q∈Q p -q |P | + q∈Q min p∈P p -q |Q| , HD = max max p∈P min q∈Q p -q , max q∈Q min p∈P p -q } , NC = 1 2 p∈P (n p • n pq ) |P | + q∈Q (n q • n qp ) |Q| ,</formula><p>where P and Q are respectively the predicted and ground truth (GT) meshes, n p and n q are the normals at p and q, n pq is the normal of the vertex in Q that is closest to p, and n qp is the normal of the vertex in P that is closest to q. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results</head><p>We compared SurfFlow with CorticalFlow++ and DeepCSR. To ensure a fair comparison, we modified both CorticalFlow++ and DeepCSR to use dual-modal inputs. Specifically, for DeepCSR, we utilized the finest possible configuration, generating a 512 3 3D grid to predict the signed distance field for surface reconstruction using the marching cube algorithm. As depicted in Table <ref type="table" target="#tab_0">1</ref>, our evaluation demonstrates that SurfFlow outperforms the other two methods in all metrics. SurfFlow stands out with an average Chamfer distance of less than 0.5 mm, demonstrating significantly smaller errors compared with CorticalFlow++ and DeepCSR, which result in 22% to 1100% larger errors. Similar improvements were observed for evaluations with the ASSD, HD, and NC metrics. Furthermore, during our evaluation, we noticed that DeepCSR yielded higher errors for pial surface reconstruction due to numerous mesh topological artifacts. The utilization of implicit representation in DeepCSR does not guarantee a genus zero manifold. Visual comparisons (Figs. <ref type="figure">2</ref> and<ref type="figure" target="#fig_2">3</ref>) further confirm that SurfFlow excels in reconstructing cortical gyri and sulci compared with CorticalFlow++ and DeepCSR. Moreover, SurfFlow demonstrates superior robustness with more consist results, as indicated lower standard deviations.</p><p>SurfFlow utilizes PELL to ensure that mesh edge lengths are within the desired range. We observed that this optimization leads to smoother, more uniform, and accurate meshes. In contrast, CorticalFlow++ shows limited accuracy in certain mesh areas, primarily due to its inability to ensure mesh uniformity. This is evident in the zoomed-in areas depicted in Fig. <ref type="figure" target="#fig_3">4</ref>, where the deficiency in mesh faces hinders accurate predictions. The superiority of SurfFlow in terms of mesh smoothness is further supported by the NC results.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Ablation Study</head><p>The results of an ablation study (Table <ref type="table" target="#tab_1">2</ref>) confirm that surface prediction performance improves (i) when both modalities are concurrently used; (ii) when  instance normalization is used, and (iii) when PELL is used as opposed to the edge length loss in CorticalFlow++.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We presented SurfFlow-a flow-based deep-learning network to accurately reconstruct cortical surfaces. SurfFlow predicts a flow field to deform a template surface toward a target surface. It produces smooth and uniform surface meshes with sub-millimeter accuracy and outperforms CorticalFlow++ and DeepCSR in terms of surface accuracy and regularity.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. (a) SurfFlow network structure. The network has three deformation blocks, each consisting of a 3D Unet and a diffeomorphic mesh deformation (DMD) module. (b) Unet architectures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>R 1 .Fig. 2 .</head><label>12</label><figDesc>Fig. 2. Comparison of white and pial surfaces reconstructed via SurfFlow, Corti-calFlow++, and DeepCSR for different time points.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Error map comparison between SurfFlow, CorticalFlow++, and DeepCSR.</figDesc><graphic coords="8,63,27,56,75,332,41,111,85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Comparison of mesh uniformity.</figDesc><graphic coords="8,55,98,209,48,340,27,104,50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Comparison of different CSR methods in reconstructing the white and pial surfaces of the left (L) and right (R) hemispheres. ↓ and ↑ indicate better performance with lower and higher metric values, respectively.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Pial Surface</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">CD ↓</cell><cell cols="2">ASSD ↓</cell><cell cols="2">HD ↓</cell><cell cols="2">NC ↑</cell></row><row><cell></cell><cell>L</cell><cell>R</cell><cell>L</cell><cell>R</cell><cell>L</cell><cell>R</cell><cell>L</cell><cell>R</cell></row><row><cell>DeepCSR</cell><cell cols="8">4.69 (±2.10) (±2.00) (±0.25) (±0.27) (±1.13) (±1.37) (±0.02) (±0.02) 3.85 1.26 1.13 5.10 4.58 0.75 0.76</cell></row><row><cell>CorticalFlow++</cell><cell cols="8">1.02 (±0.17) (±0.10) (±0.03) (±0.04) (±0.25) (±0.12) (±0.01) (±0.01) 0.67 0.74 0.63 2.15 1.55 0.81 0.84</cell></row><row><cell>SurfFlow</cell><cell>0.39 (±0.14)</cell><cell>0.36 (±0.11)</cell><cell>0.48 (±0.03)</cell><cell>0.46 (±0.05)</cell><cell>0.98 (±0.08)</cell><cell>0.80 (±0.10)</cell><cell>0.90 (±0.01)</cell><cell>0.91 (±0.01)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">White Surface</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">CD ↓</cell><cell cols="2">ASSD ↓</cell><cell cols="2">HD ↓</cell><cell cols="2">NC ↑</cell></row><row><cell></cell><cell>L</cell><cell>R</cell><cell>L</cell><cell>R</cell><cell>L</cell><cell>R</cell><cell>L</cell><cell>R</cell></row><row><cell>DeepCSR</cell><cell cols="8">0.74 (±0.50) (±0.90) (±0.11) (±0.16) (±0.58) (±0.68) (±0.02) (±0.02) 0.50 0.58 0.60 1.28 1.27 0.90 0.90</cell></row><row><cell>CorticalFlow++</cell><cell cols="8">1.13 (±0.43) (±0.12) (±0.04) (±0.04) (±0.11) (±0.13) (±0.13) (±0.04) 0.91 0.86 0.78 1.96 1.66 0.72 0.73</cell></row><row><cell>SurfFlow</cell><cell>0.37 (±0.12)</cell><cell>0.41 (±0.15)</cell><cell>0.47 (±0.05)</cell><cell>0.49 (±0.06)</cell><cell>0.86 (±0.10)</cell><cell>0.90 (±0.12)</cell><cell>0.93 (±0.01)</cell><cell>0.92 (±0.01)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>CSR performance with respect to modalities (T1w and T2w), instance normalization (IN), and piecewise edge length loss (PELL) for white and pial surfaces of the left (L) and right (R) hemispheres. ↓ and ↑ indicate better performance with lower and higher metric values, respectively.</figDesc><table><row><cell></cell><cell></cell><cell>T1w</cell><cell></cell></row><row><cell></cell><cell></cell><cell>T2w</cell><cell></cell></row><row><cell></cell><cell></cell><cell>IN</cell><cell></cell></row><row><cell></cell><cell></cell><cell>PELL</cell><cell></cell></row><row><cell>CD ↓</cell><cell>Pial</cell><cell>L R</cell><cell>0.95 (±0.15) 0.89 (±0.16) 1.02 (±0.17) 0.66 (±0.21) 0.90 (±0.42) 0.98 (±0.23) 0.39 (±0.14) 1.05 (±0.18) 1.08 (±0.24) 0.67 (±0.10) 0.66 (±0.17) 0.78 (±0.26) 0.88 (±0.31) 0.36 (±0.11)</cell></row><row><cell></cell><cell>White</cell><cell>L R</cell><cell>1.19 (±0.17) 1.31 (±0.27) 1.13 (±0.43) 0.85 (±0.17) 0.82 (±0.27) 0.93 (±0.27) 0.37 (±0.12) 1.28 (±0.14) 1.32 (±0.24) 0.91 (±0.12) 0.90 (±0.18) 0.88 (±0.29) 0.99 (±0.36) 0.41 (±0.15)</cell></row><row><cell>ASSD ↓</cell><cell>Pial</cell><cell>L R</cell><cell>0.74 (±0.04) 0.72 (±0.07) 0.74 (±0.03) 0.58 (±0.03) 0.64 (±0.11) 0.71 (±0.08) 0.48 (±0.03) 0.77 (±0.05) 0.78 (±0.07) 0.63 (±0.04) 0.60 (±0.05) 0.60 (±0.05) 0.68 (±0.10) 0.46 (±0.05)</cell></row><row><cell></cell><cell>White</cell><cell>L R</cell><cell>0.86 (±0.04) 0.94 (±0.09) 0.86 (±0.04) 0.70 (±0.04) 0.68 (±0.10) 0.74 (±0.11) 0.47 (±0.05) 0.92 (±0.05) 0.94 (±0.08) 0.78 (±0.04) 0.73 (±0.04) 0.70 (±0.10) 0.76 (±0.13) 0.49 (±0.06)</cell></row></table><note><p>HD ↓ Pial L 1.86 (±0.20) 1.79 (±0.17) 2.15 (±0.24) 1.36 (±0.16) 1.69 (±0.60) 1.89 (±0.28) 0.98 (±0.08) R 2.04 (±0.21) 2.09 (±0.19) 1.55 (±0.12) 1.42 (±0.18) 1.41 (±0.31) 1.51 (±0.33) 0.80 (±0.10) White L 1.88 (±0.15) 1.92 (±0.22) 1.96 (±0.11) 1.57 (±0.12) 1.50 (±0.34) 1.62 (±0.26) 0.86 (±0.10)</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://www.blender.org.</p></note>
		</body>
		<back>

			<div type="funding">
<div><p>Equal contribution. This work was supported in part by the <rs type="funder">United States National Institutes of Health (NIH)</rs> through grants <rs type="grantNumber">MH125479</rs> and <rs type="grantNumber">EB008374</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_WwvxFQw">
					<idno type="grant-number">MH125479</idno>
				</org>
				<org type="funding" xml:id="_64ZYdJ4">
					<idno type="grant-number">EB008374</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multifaceted atlases of the human brain in its infancy</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ahmad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Meth</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="55" to="64" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Challenges in pediatric neuroimaging</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Barkovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Desikan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Barkovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="page" from="793" to="801" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">3D U-Net: learning dense volumetric segmentation from sparse annotation</title>
		<author>
			<persName><forename type="first">Ö</forename><surname>Çiçek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abdulkadir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Lienkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-46723-8_49</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-46723-8_49" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2016</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Ourselin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Joskowicz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Sabuncu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Unal</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Wells</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">9901</biblScope>
			<biblScope unit="page" from="424" to="432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">DeepCSR: a 3D deep learning approach for cortical surface reconstruction</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Cruz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lebrat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bourgeat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fookes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fripp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Salvado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="806" to="815" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Cortical surface-based analysis: I. segmentation and surface reconstruction</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Dale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fischl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Sereno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="194" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The UNC/UMN baby connectome project (BCP): an overview of the study design and protocol development</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Howell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="page" from="891" to="905" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">CorticalFlow: a diffeomorphic mesh deformation module for cortical surface reconstruction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lebrat</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.02374</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">PialNN: a fast deep learning framework for cortical Pial surface reconstruction</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kainz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alansary</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87586-2_8</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87586-2_8" />
	</analytic>
	<monogr>
		<title level="m">MLCN 2021</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Abdulkadir</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">13001</biblScope>
			<biblScope unit="page" from="73" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The developing human connectome project: a minimal processing pipeline for neonatal cortical surface reconstruction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Makropoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="page" from="88" to="112" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">CorticalFlow++: boosting cortical surface reconstruction accuracy, regularity, and interoperability</title>
		<author>
			<persName><forename type="first">Santa</forename><surname>Cruz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16443-9_48</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16443-9_48" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13435</biblScope>
			<biblScope unit="page" from="496" to="505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Instance normalization: the missing ingredient for fast stylization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ulyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.08022</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">iBEAT v2.0: a multisiteapplicable, deep learning-based pipeline for infant cerebral cortical surface reconstruction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Protoc</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1488" to="1509" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Voxel2Mesh: 3D mesh model generation from volumetric data</title>
		<author>
			<persName><forename type="first">U</forename><surname>Wickramasinghe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Remelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Knott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59719-1_30</idno>
		<idno>978-3-030-59719-1_30</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12264</biblScope>
			<biblScope unit="page" from="299" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Infant FreeSurfer: an automated segmentation and surface extraction pipeline for T1-weighted neuroimaging data of infants 0-2 years</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zöllei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Iglesias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Grant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fischl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">218</biblScope>
			<biblScope unit="page">116946</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
