<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Weakly Supervised Cerebellar Cortical Surface Parcellation with Self-Visual Representation Learning</title>
				<funder ref="#_vBEr5Yv #_eecpw7t #_XPcvRGD #_zmyTawS #_Ga489Am">
					<orgName type="full">National Institutes of Health</orgName>
					<orgName type="abbreviated">NIH</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zhengwang</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Radiology and Biomedical Research Imaging Center</orgName>
								<orgName type="institution">University of North Carolina at Chapel Hill</orgName>
								<address>
									<addrLine>Chapel Hill</addrLine>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiale</forename><surname>Cheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Radiology and Biomedical Research Imaging Center</orgName>
								<orgName type="institution">University of North Carolina at Chapel Hill</orgName>
								<address>
									<addrLine>Chapel Hill</addrLine>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fenqiang</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Radiology and Biomedical Research Imaging Center</orgName>
								<orgName type="institution">University of North Carolina at Chapel Hill</orgName>
								<address>
									<addrLine>Chapel Hill</addrLine>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ya</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yue</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Radiology and Biomedical Research Imaging Center</orgName>
								<orgName type="institution">University of North Carolina at Chapel Hill</orgName>
								<address>
									<addrLine>Chapel Hill</addrLine>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dajiang</forename><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Radiology and Biomedical Research Imaging Center</orgName>
								<orgName type="institution">University of North Carolina at Chapel Hill</orgName>
								<address>
									<addrLine>Chapel Hill</addrLine>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">University of Texas at Arlington</orgName>
								<address>
									<settlement>Arlington</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tianming</forename><surname>Liu</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Georgia</orgName>
								<address>
									<settlement>Athens</settlement>
									<region>GA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Valerie</forename><surname>Jewells</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Radiology and Biomedical Research Imaging Center</orgName>
								<orgName type="institution">University of North Carolina at Chapel Hill</orgName>
								<address>
									<addrLine>Chapel Hill</addrLine>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Weili</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Radiology and Biomedical Research Imaging Center</orgName>
								<orgName type="institution">University of North Carolina at Chapel Hill</orgName>
								<address>
									<addrLine>Chapel Hill</addrLine>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Li</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Radiology and Biomedical Research Imaging Center</orgName>
								<orgName type="institution">University of North Carolina at Chapel Hill</orgName>
								<address>
									<addrLine>Chapel Hill</addrLine>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Gang</forename><surname>Li</surname></persName>
							<email>gang_li@med.unc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Radiology and Biomedical Research Imaging Center</orgName>
								<orgName type="institution">University of North Carolina at Chapel Hill</orgName>
								<address>
									<addrLine>Chapel Hill</addrLine>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Weakly Supervised Cerebellar Cortical Surface Parcellation with Self-Visual Representation Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0FBCB10A8C8116A533033267B8F6628F</idno>
					<idno type="DOI">10.1007/978-3-031-43993-3_42</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-24T11:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Cerebellar Cortex Parcellation • Representation Learning</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The cerebellum (i.e., little brain) plays an important role in motion and balances control abilities, despite its much smaller size and deeper sulci compared to the cerebrum. Previous cerebellum studies mainly relied on and focused on conventional volumetric analysis, which ignores the extremely deep and highly convoluted nature of the cerebellar cortex. To better reveal localized functional and structural changes, we propose cortical surface-based analysis of the cerebellar cortex. Specifically, we first reconstruct the cerebellar cortical surfaces to represent and characterize the highly folded cerebellar cortex in a geometrically accurate and topologically correct manner. Then, we propose a novel method to automatically parcellate the cerebellar cortical surface into anatomically meaningful regions by a weakly supervised graph convolutional neural network. Instead of relying on registration or requiring mapping the cerebellar surface to a sphere, which are either inaccurate or have large geometric distortions due to the deep cerebellar sulci, our learning-based model directly deals with the original cerebellar cortical surface by decomposing this challenging task into two steps. First, we learn the effective representation of the cerebellar cortical surface patches with a contrastive self-learning framework. Then, we map the learned representations to parcellation labels. We have validated our method using data from the Baby Connectome Project and the experimental results demonstrate its superior effectiveness and accuracy, compared to existing methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Parcellating the cerebellum (i.e., little brain) into neurobiologically meaningful regions of interest (ROIs) plays an important role in both structural and functional analysis <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. Therefore, automatic cerebellar parcellation methods are highly demanded to facilitate the analysis of increasingly larger cerebellum imaging datasets. Compared with the highly folded cerebral cortex, the cerebellar cortex has a more complex shape with even more tightly convoluted and much thinner cortical folds. Hence, few algorithms have been proposed for automatic cerebellar cortex parcellation.</p><p>Most existing methods mainly conduct the cerebellar cortex parcellation in the Euclidean space <ref type="bibr" target="#b2">[3]</ref>. Generally, they treat the cerebellar cortex as a 3D volume, and then either use the traditional multi-atlas registration and label-fusion based methods or directly learn the cerebellar cortex parcellation model in the volumetric space, without reconstructing the cerebellar cortical surfaces and thus ignoring the topological and geometric properties of the cerebellar cortex. These methods are thus inappropriate for accurate and anatomically meaningful cerebellar cortex analysis, as the neighboring relationship in 3D space used in these methods cannot correctly reflect the actual cytoarchitectural neighborship. Specifically, two spatially neighboring points in the cerebellum volume do not necessarily mean they are neighboring in cytoarchitecture and geodesic. They could sit in completely different gyri or sulci, due to the extremely convoluted structure of the cerebellar cortex. This can cause severe consequences when requesting the parcellation consistency across "neighbors" and confuse the message aggregation during the parcellation model learning.</p><p>To address this issue, it is highly necessary to respect the cerebellar geometry, which provides macro-measurable imaging clues characterizing the cytoarchitecture of the cerebellar cortex. Therefore, in this paper, first, we reconstruct the cerebellar surfaces to restore its convoluted geometry. Specifically, we reconstruct the inner cerebellar surface (the interface between the cerebellar gray matter and white matter), and the pial/outer cerebellar cortical surface (the interface between the cerebellar gray matter and cerebrospinal fluid (CSF)). The reconstructed cerebellar surfaces are represented by triangular meshes, which can be regarded as an undirected graph. Second, we develop a graph convolutional neural network-based method to do the parcellation on the reconstructed cerebellar surfaces. Specifically, we first extract the informative surface patches from the cerebellar surfaces with the neighborship determined by their intrinsic geodesic distance. And then, we feed these surface patches into the graph convolutional neural network to train a parcellation model, which learns a highly nonlinear mapping from the geometric features of the training patches to the patch labels. One practical challenge for learning this mapping is the need for a large amount of manually labeled data, which is extremely expensive and time-consuming for vertex-level labeling. Therefore, we split the mapping learning into two steps, in the first step, we use massive patches to learn effective low-dimension representations in the latent space. Leveraging the concept of contrastive learning, we require similar representations for the patches from the same region, while distinct representations for patches from different regions. Then, in the second step, we learn the mapping from the low-dimensional latent representation to the parcellation labels. Of note, the representation learning only requires a tag to denote whether the patches are from the same region or not, which is clearly a weaker supervision compared to the accurate patch-level labels.</p><p>This paper makes three contributions: 1) we propose a practical pipeline to reconstruct the cerebellar cortical surface that respects its intrinsic geometry; 2) we conduct the parcellation on the original reconstructed cerebellar cortical surfaces, without the requirement to project them onto a simplified shape, like the sphere, which will inevitably introduce distortions during the projection; 3) we leverage the self-representation learning with weak supervision information to reduce the manual labeling cost for the parcellation network training. To the best of our knowledge, this is the first method that conducts the cerebellar cortex parcellation directly using the original reconstructed cerebellar surfaces. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>Our cerebellar cortex parcellation method can be divided into 3 steps: 1) we reconstruct the cerebellar surfaces and compute the salient geometric features to characterize the geometry of the cerebellar surfaces; 2) we use weakly supervised information to learn effective latent representations from massive informative surface patches. These representations sit in low dimensional latent space, and they are similar for patches from the same region, while are distinct for patches from different regions; 3) we learn a straightforward mapping from the low dimensional latent space to the parcellation labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Cerebellar Surface Reconstruction and Geometric Feature Computation</head><p>Given the tissue map of the cerebellum <ref type="bibr" target="#b3">[4]</ref>, we can reconstruct the cerebellar cortical surfaces, including the inner cortical surface and the pial/outer cortical surface. The pipeline is illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>. Specifically, we first do the cerebellum tissue segmentation and then correct the topological errors. Then, we reconstruct the inner cerebellar surface and deform it to the outer cerebellar surface. This framework is similar to the typical cerebral cortical surface reconstruction pipelines. We adopt this typical strategy because, a) it can well preserve the geometry of the highly folded cerebellar cortex; b) it can establish the vertex-wise correspondence between the inner and outer cerebellar surfaces, which will substantially facilitate the subsequent analysis. More details about widely used cortical surface reconstruction pipelines can be referred to, such as FreeSurfer <ref type="bibr" target="#b4">[5]</ref>, dHCP <ref type="bibr" target="#b5">[6]</ref>, FastSurfer <ref type="bibr" target="#b6">[7]</ref>, HCP <ref type="bibr" target="#b7">[8]</ref>, and iBEAT V2.0 <ref type="bibr" target="#b8">[9]</ref>.</p><p>With the reconstructed cerebellar surfaces, we can then compute typical geometric features, including the average convexity, mean curvature, curvedness, shape index, and Laplacian spectral embedding <ref type="bibr" target="#b9">[10]</ref>. These geometric features encode the local and global geometries of the cerebellar sulci and gyri, which can be used to identify the boundary of each parcellation region (typically appearing at the sulcal bottoms of the cerebellar surface). Specifically, the average convexity encodes the integrated normal movement of a vertex during inflating the inner cerebellar surface and mainly reflects the coarsescale geometrical information of cerebellar cortical folding <ref type="bibr" target="#b10">[11]</ref>; the mean curvature is computed as the average of the minimal and maximal principal curvatures of the inner cerebellar cortical surface and encodes the fine-scale local geometric information of cerebellar cortical folding <ref type="bibr" target="#b10">[11]</ref>; also, based on the minimum and maximum principal curvatures, we can compute the curvedness and shape index <ref type="bibr" target="#b11">[12]</ref>, which characterize the local shape information of the cerebellar cortical surface <ref type="bibr" target="#b10">[11]</ref>; the Laplacian spectral embedding reflects the vibration mode of a graph <ref type="bibr" target="#b9">[10]</ref>, which can be used as a global feature to characterize the cerebellar cortex. Figure <ref type="figure" target="#fig_0">1</ref>(f) visualizes these geometric features on the inner cerebellar cortical surface and the corresponding parcellation map. In addition, since the cerebellar cortical surface is not separated into left and right hemispheres, we computed the vertex-wise distance to the geometric center of the surface as additional features, named centroid relation features, which can provide useful clues for the localization of symmetric regions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Weakly Supervised Cerebellar Patch Representation Learning</head><p>Provided with the computed geometric features of the cerebellar surface, we can train a neural network to conduct the parcellation. However, treating the entire cerebellar surface as a single instance would require dense manual labeling for the network training, which is time-consuming and labor-intensive. Therefore, we choose the patch-wise strategy for the parcellation network training. The advantage is that it can significantly enlarge the training samples, while this comes at the cost of requiring the model to possess strong localization ability for the local patch. Directly learning a mapping from the geometric features of a local patch to the parcellation labels is very challenging for the cerebellar surface due to the shape complexity. The local sulci of the cerebellar surface are deeper, and the gyri appear more consistent shape patterns, compared to the cerebral cortical surfaces. This indicates that more training samples are required to enable the network to possess the localization ability from the local patches for a robust parcellation model. To further reduce the cost of the expensive manual labeling, we split the parcellation network training into two steps. In the first step, we learn distinctive latent representations for patches from different regions in a weakly supervised manner. Specifically, we enforce similar representations for patches from the same region, while distinct representations for patches from different regions. This can be achieved with a contrastive learning framework <ref type="bibr" target="#b12">[13]</ref>. Herein, we name it weakly supervised since in this step, we only require a tag to denote whether the patches are from the same region or not and we do not require the precise labels of which region it belongs to.</p><p>Following the above motivation, we can formulate the weakly supervised patchbased representation learning below. We first extract the local patches from the cerebellar surface, which can be regarded as an undirected graph (V , E), with V being the vertex set and E being the edge set. For any vertex, we can extract a local patch, which contains a set of vertices v i k whose geodesic distances to v i are bounded by the predefined maximal geodesic distance ρ max , as illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>. Considering the prior knowledge that parcellation boundaries of the cerebellar surface generally appear at the sulcal fundi or gyral crests, we sample more patches from those locations, and meanwhile reduce patch samples for vertices sitting on sulcal walls. This can be achieved by thresholding the mean curvature map of the cerebellar surface, since the sulcal fundi and gyral crests typically have larger curvature magnitude, as illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>(a), where white dots denote the sample points near gyri crests, and black dots denote the sample points near sulcal fundi. Figure <ref type="figure" target="#fig_1">2</ref>(c) shows a typical surface patch with various geometric features and parcellation labels.</p><p>Once the local patches are extracted, we feed them into a graph convolution based neural network to learn their latent representation. Herein, we use the widely used residual network <ref type="bibr" target="#b13">[14]</ref> as the basic block for constructing our latent representation learning framework. Figure <ref type="figure" target="#fig_2">3</ref> illustrates the learning framework. Specifically, given 3 local patches (p 1 , p 2 , p 3 ), where p 1 and p 2 are from the same region and p 3 is from a different region. After the encoding, we can denote their latent representations to be (z 1 , z 2 , z 3 ). Then, we enforce (z 1 , z 2 ) to be similar (using the cosine criterion) in the latent space while (z 1 , z 3 ) and (z 2 , z 3 ) to be distinct. This can be achieved by minimizing the normalized temperature scaled cross entropy (NT-Xent) loss, which is defined as:</p><formula xml:id="formula_0">L(p 1 , p 2 , p 3 ) = -log e cos(z 1 ,z 2 )/τ e cos(z 1 ,z 2 )/τ + e cos(z 1 ,z 3 )/τ + e cos(z 2 ,z 3 )/τ</formula><p>where τ is a hyperparameter (named temperature). It is worth noting that, a) it has been validated that this loss has superior performances in many representation learning tasks than other contrastive losses <ref type="bibr" target="#b12">[13]</ref>; b) during the training, we can select multiple triplet patches into a single batch and use the average loss over the entire batch to make the training more robust. Since we have extracted a large number of patches from the cerebellar surface, after combining patches according to their tags, we can obtain an even larger set of training samples to ensure network convergence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Mapping from Latent Space to Parcellation Labels</head><p>Through representation learning, we have encoded the patches with multiple channels of geometric features into the latent space. This step not only makes the extracted patches more distinct in the latent space from the regional perspective but also significantly reduces the potential feature dimension, which can greatly facilitate the parcellation network training, compared to training the parcellation network directly from the patchwise geometric features.</p><p>Therefore, given the patch-wise latent representations, we further train a multilayer perceptron (MLP) to accomplish the parcellation task. Specifically, we use the parcellation labels from the manually labeled cerebellar surface to supervise the MLP training. Herein, the patch center label is used as the patch label to train the MLP and the popular cross-entropy loss is adopted.</p><p>However, since each patch is parcellated independently without considering the spatial consistency, it is possible to generate isolated parcellation labels and cause inconsistency in a geodesic neighborhood. To improve the parcellation, we further use the graph cuts method <ref type="bibr" target="#b14">[15]</ref> to explicitly impose spatial consistency. Specifically, since most of the regions are separated at the sulci fundi of the cerebellar cortex according to the manual labeling protocol, we explicitly formulate parcellation as a cost minimization problem, i.e., E = E d + λE s . Here, E d is the data fitting term, which is defined as:</p><formula xml:id="formula_1">E d = -logp v (l v )</formula><p>, where p v (l v ) is the probability of assigning vertex v as label l v ; E s is the smoothness term, which is defined as:</p><formula xml:id="formula_2">E s = v * ∈N v C v,v * (l v , l v * ),</formula><p>where vertex v * is the direct neighbor of v, and C v,v * (l v , l v * ) is the cost to label vertex v as l v and also label vertex v * as l v * . Herein, we used the formula from <ref type="bibr" target="#b15">[16]</ref> to define C v,v * (l v , l v * ); finally, λ is a weight used to balance them. 3 Experiments</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset and Implementation</head><p>To validate our method, we manually labeled 10 subjects from BCP dataset <ref type="bibr" target="#b16">[17]</ref> in a vertex-wise manner using an inhouse developed toolkit. Specifically, for each cerebellum MRI, we first segmented it into white matter, gray matter, and CSF using a deep convolutional neural network <ref type="bibr" target="#b3">[4]</ref>. Then, following the processing pipeline in Sect. 2.1, we reconstructed the geometrically accurate and topologically correct cerebellar surfaces <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref>. Finally, each inner cerebellar surface is labeled into 17 lobules following the SUIT parcellation strategy <ref type="bibr" target="#b2">[3]</ref> by an expert. To ensure the labeling quality, each manually labeled region is further validated and cross-modified by another 2 experts to alleviate the subjective bias and ensure the labeling quality. Due to the limited subject number, we adopted these manually labeled cerebellums to validate our method in a 10-fold cross validation. We implemented our method mainly based on the pytorch (https://pytorch.org/) and pytorch geometric (https://pyg.org/) packages. The graph convolution operator <ref type="bibr" target="#b19">[20]</ref> implemented in the pytorch geometric package is adopted as the major building block to construct our network. For the contrastive learning framework, we used 18 ResNet blocks for the encoding and 3 fully connected layers for the projection. After the cerebellar cortical surface reconstruction, each scan typically has around 90k vertices. We extract 8k patches from each training scan. The ρ max is set to 15mm. For the NT-Xent loss, the hyperparameter τ is set to 0.5. For the graph-cut cost, the weight balance λ is set to 1. For the testing subject, we perform the parcellation for each patch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Comparison with the State-of-the-Art Methods</head><p>Since we conducted our parcellation on the original cerebellar surface, which can be regarded as a graph, we compared our method with state-of-the-art graph convolutional neural network based methods <ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref> for the cerebellum parcellation task. The Dice similarity coefficient (DSC) between the predicted label and the manual label is adopted as a quantitative evaluation of the parcellation performance. Table <ref type="table" target="#tab_0">1</ref> reported the average DSC of the parcellation for all regions acquired by our proposed method and the comparison methods. It can be seen that our method achieves best performance, indicating the effectiveness of the latent patch feature embedding obtained by our proposed weakly supervised contrastive learning strategy. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Different Features' Influence Analysis</head><p>We also validated the influence of each geometric feature on the final parcellation performance. We conducted the ablation study by removing parts of the geometric features for the parcellation. Table <ref type="table" target="#tab_1">2</ref> reported the average DSC using different feature combinations. It can be seen that the raw geometric features, i.e., the average convexity, mean curvature, curvedness, and shape index, are difficult to capture the localization ability. This is reasonable since the cerebellar cortex has much deeper sulci, and appear more similar geometric patterns, compared to the cerebral cortex. Therefore, the local patches have relatively low localization ability. However, after adding the spectral feature and the centroid relation feature, the parcellation performance is greatly improved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we propose an automated method for anatomically meaningful cerebellar cortical surface parcellation. We firstly reconstruct the geometric accurate and topologically correct cerebellar surfaces and then compute several widely used geometric features to comprehensively characterize the geometries of the cerebellar surface. Next, we extract local surface patches from the reconstructed cerebellar surfaces with the neighborship defined by the intrinsic geodesic metric. These extracted local surface patches are projected to a low dimensional latent space with a contrastive learning framework, i.e., patches from the same region are enforced to have similar representations, while patches from different regions have distinct representations. After that, we train a neural network to map the latent representations to the parcellation labels. Comparison to the state-of-the-art methods has validated the superior performance of our method. Currently, our work has two limitations, a) the quantitative evaluation is based on a small number of the subjects, due to the expensive manual labeling cost. In the future, we plan to involve and release more manually labeled cerebellar cortical surfaces to further improve the generalizability of the current framework, enhance the representation learning and validate our method on larger datasets; b) a graph cut post-processing is needed to remove potential inconsistent labelling. In the future, we plan to directly add the neighborhood smooth labeling constraint into the network cost function to obtain an end-to-end cerebellar cortical surface parcellation method.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Cerebellar surface reconstruction pipeline and the typical geometric features computation.</figDesc><graphic coords="3,66,48,146,63,319,63,157,42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Intrinsic surface patch extraction. (a) The patch sampling positions on the cerebellar surface. The white dot indicates the gyri samples, while the black dots indicate the sulci samples. (b) A local intrinsic patch bounded by the geodesic distance ρ max . All vertices whose geodesic distance to the patch center lower than ρ max will be included in the patch. (c) Typical geometric features on the extracted local intrinsic patch in (b).</figDesc><graphic coords="4,51,30,363,71,321,94,156,70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. Weakly supervised representation learning framework. After learning, we enforce similar latent representations between patches 1 and 2 (coming from the same region), but distinct representation between patches 1 (or 2) and patch 3.</figDesc><graphic coords="5,62,97,240,02,327,01,150,85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Performance comparison by different methods.</figDesc><table><row><cell>Comparison methods</cell><cell>Dice ratio</cell></row><row><cell>GCN [20]</cell><cell>76.03 ± 3.20</cell></row><row><cell>GIN [21]</cell><cell>75.20 ± 2.40</cell></row><row><cell>Graph U-Net [22]</cell><cell>73.17 ± 4.46</cell></row><row><cell>Graph SAGE [23]</cell><cell>73.52 ± 4.69</cell></row><row><cell>Proposed</cell><cell>81.26 ± 2.37</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Different features' influence on parcellation performance.</figDesc><table><row><cell>Comparison methods</cell><cell>DSC</cell></row><row><cell>Raw geometric features</cell><cell>46.02 ± 4.13</cell></row><row><cell>Raw geometric features + spectral feature</cell><cell>72.72 ± 4.52</cell></row><row><cell>Raw geometric features + spectral feature + centroid relation feature</cell><cell>81.26 ± 2.37</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This work was supported in part by the <rs type="funder">National Institutes of Health (NIH)</rs> under Grants <rs type="grantNumber">MH116225</rs>, <rs type="grantNumber">MH117943</rs>, <rs type="grantNumber">MH123202</rs>, <rs type="grantNumber">NS128534</rs>, and <rs type="grantNumber">AG075582</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_vBEr5Yv">
					<idno type="grant-number">MH116225</idno>
				</org>
				<org type="funding" xml:id="_eecpw7t">
					<idno type="grant-number">MH117943</idno>
				</org>
				<org type="funding" xml:id="_XPcvRGD">
					<idno type="grant-number">MH123202</idno>
				</org>
				<org type="funding" xml:id="_zmyTawS">
					<idno type="grant-number">NS128534</idno>
				</org>
				<org type="funding" xml:id="_Ga489Am">
					<idno type="grant-number">AG075582</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Persistent functional deficit in multiple sclerosis and autosomal dominant cerebellar ataxia is associated with axon loss</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Davie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brain</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="page" from="1583" to="1592" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The cerebellum contributes to higher functions during development evidence from a series of children surgically treated for posterior fossa tumours</title>
		<author>
			<persName><forename type="first">D</forename><surname>Riva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Giorgi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brain</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="page" from="1051" to="1061" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Comparing fully automated state-of-the-art cerebellum parcellation from magnetic resonance images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Carass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">183</biblScope>
			<biblScope unit="page" from="150" to="172" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semi-supervised transfer learning for infant cerebellum tissue segmentation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59861-7_67</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-59861-7_67" />
	</analytic>
	<monogr>
		<title level="m">MLMI 2020</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Yan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Lian</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Cao</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12436</biblScope>
			<biblScope unit="page" from="663" to="673" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">B</forename><surname>Fischl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>FreeSurfer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The developing human connectome project: a minimal processing pipeline for neonatal cortical surface reconstruction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Makropoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="page" from="88" to="112" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">FastSurfer -a fast and accurate deep learning based neuroimaging pipeline</title>
		<author>
			<persName><forename type="first">L</forename><surname>Henschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Conjeti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Estrada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Diers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fischl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Reuter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">219</biblScope>
			<biblScope unit="page">117012</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The minimal preprocessing pipelines for the human connectome project</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Glasser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="105" to="124" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">iBEAT V2.0: a multisite-applicable, deep learning-based pipeline for infant cerebral cortical surface reconstruction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Protoc</title>
		<imprint>
			<biblScope unit="volume">2023</biblScope>
			<biblScope unit="page" from="1" to="32" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Diffeomorphic spectral matching of cortical surfaces</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lombaert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sporring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Siddiqi</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-38868-2_32</idno>
		<ptr target="https://doi.org/10.1007/978-3-642-38868-2_32" />
	</analytic>
	<monogr>
		<title level="m">IPMI 2013</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Gee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Joshi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Pohl</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Zöllei</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">7917</biblScope>
			<biblScope unit="page" from="376" to="389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Cortical surface-based analysis: II. Inflation, flattening, and a surface-based coordinate system</title>
		<author>
			<persName><forename type="first">B</forename><surname>Fischl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Sereno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Dale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="195" to="207" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Curvature formulas for implicit curves and surfaces</title>
		<author>
			<persName><forename type="first">R</forename><surname>Goldman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Aided Geometric Design</title>
		<imprint>
			<biblScope unit="page" from="632" to="658" />
			<date type="published" when="2005">2005</date>
			<publisher>North-Holland</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1575" to="1585" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1124" to="1137" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Registration-free infant cortical surface parcellation using deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="672" to="680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The UNC/UMN baby connectome project (BCP): an overview of the study design and protocol development</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Howell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="page" from="891" to="905" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Topological correction of infant white matter surfaces using anatomically constrained convolutional neural network</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">198</biblScope>
			<biblScope unit="page" from="114" to="124" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Measuring the dynamic longitudinal cortex development in infants by reconstruction of temporally consistent cortical surfaces</title>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="266" to="279" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations. International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">How powerful are graph neural networks?</title>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations, ICLR 2019. International Conference on Learning Representations. ICLR</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Graph U-nets</title>
		<author>
			<persName><forename type="first">H</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="4948" to="4960" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Neural Information Processing Systems Foundation</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1025" to="1035" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
