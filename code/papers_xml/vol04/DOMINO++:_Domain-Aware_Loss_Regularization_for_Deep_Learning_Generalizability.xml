<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DOMINO++: Domain-Aware Loss Regularization for Deep Learning Generalizability</title>
				<funder ref="#_zdwUt8g">
					<orgName type="full">National Science Foundation, USA</orgName>
				</funder>
				<funder ref="#_sSSwbsa">
					<orgName type="full">Air Force Research Laboratory Munitions Directorate, USA</orgName>
				</funder>
				<funder ref="#_Xs9N5kr #_WFUZ9tW">
					<orgName type="full">National Institutes of Health/National Institute on Aging, USA</orgName>
				</funder>
				<funder>
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Skylar</forename><forename type="middle">E</forename><surname>Stolte</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kyle</forename><surname>Volle</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Torch Technologies, LLC</orgName>
								<address>
									<settlement>Shalimar</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aprinda</forename><surname>Indahlastari</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Center for Cognitive Aging and Memory</orgName>
								<orgName type="institution">McKnight Brain Institute</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<region>UF</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Department of Clinical and Health Psychology</orgName>
								<orgName type="department" key="dep2">College of Public Health and Health Professions</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<region>UF</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alejandro</forename><surname>Albizu</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Center for Cognitive Aging and Memory</orgName>
								<orgName type="institution">McKnight Brain Institute</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<region>UF</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Department of Neuroscience</orgName>
								<orgName type="department" key="dep2">College of Medicine</orgName>
								<orgName type="institution">UF</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Adam</forename><forename type="middle">J</forename><surname>Woods</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Center for Cognitive Aging and Memory</orgName>
								<orgName type="institution">McKnight Brain Institute</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<region>UF</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Department of Clinical and Health Psychology</orgName>
								<orgName type="department" key="dep2">College of Public Health and Health Professions</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<region>UF</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Department of Neuroscience</orgName>
								<orgName type="department" key="dep2">College of Medicine</orgName>
								<orgName type="institution">UF</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kevin</forename><surname>Brink</surname></persName>
							<affiliation key="aff5">
								<orgName type="laboratory">United States Air Force Research Laboratory</orgName>
								<orgName type="institution">Eglin Air Force Base</orgName>
								<address>
									<settlement>Valparaiso</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Matthew</forename><surname>Hale</surname></persName>
							<affiliation key="aff8">
								<orgName type="department">Department of Mechanical and Aerospace Engineering</orgName>
								<orgName type="institution" key="instit1">Herbert Wertheim College of Engineering</orgName>
								<orgName type="institution" key="instit2">UF</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Ruogu</forename><surname>Fang</surname></persName>
							<email>ruogu.fang@ufl.edu</email>
							<affiliation key="aff2">
								<orgName type="department">Center for Cognitive Aging and Memory</orgName>
								<orgName type="institution">McKnight Brain Institute</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<region>UF</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff6">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution" key="instit1">Herbert Wertheim College of Engineering</orgName>
								<orgName type="institution" key="instit2">UF</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff7">
								<orgName type="department">Department of Computer Information and Science and Engineering</orgName>
								<orgName type="institution" key="instit1">Herbert Wertheim College of Engineering</orgName>
								<orgName type="institution" key="instit2">UF</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Biomedical Engineering</orgName>
								<orgName type="institution" key="instit1">Herbert Wertheim College of Engineering</orgName>
								<orgName type="institution" key="instit2">University of Florida (UF)</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DOMINO++: Domain-Aware Loss Regularization for Deep Learning Generalizability</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="713" to="723"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">7F8A1DC3F35264C5D22193CEE0D4649C</idno>
					<idno type="DOI">10.1007/978-3-031-43901-8_68</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-24T10:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Image Segmentation</term>
					<term>Machine Learning Uncertainty</term>
					<term>Model Calibration</term>
					<term>Model Generalizability</term>
					<term>Whole Head MRI</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Out-of-distribution (OOD) generalization poses a serious challenge for modern deep learning (DL). OOD data consists of test data that is significantly different from the model's training data. DL models that perform well on in-domain test data could struggle on OOD data. Overcoming this discrepancy is essential to the reliable deployment of DL. Proper model calibration decreases the number of spurious connections that are made between model features and class outputs. Hence, calibrated DL can improve OOD generalization by only learning features that are truly indicative of the respective classes. Previous work proposed domainaware model calibration (DOMINO) to improve DL calibration, but it lacks designs for model generalizability to OOD data. In this work, we propose DOMINO++, a dual-guidance and dynamic domain-aware loss regularization focused on OOD generalizability. DOMINO++ integrates expertguided and data-guided knowledge in its regularization. Unlike DOMINO which imposed a fixed scaling and regularization rate, DOMINO++ designs a dynamic scaling factor and an adaptive regularization rate. Comprehensive evaluations compare DOMINO++ with DOMINO and the baseline model for head tissue segmentation from magnetic resonance images</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Large open-access medical datasets are integral to the future of deep learning (DL) in medicine because they provide much-needed training data and a method of public comparison between researchers <ref type="bibr" target="#b19">[20]</ref>. Researchers often curate their data for DL models; yet, even the selection process itself may contain inherent biases, confounding factors, and other "hidden" issues that cause failure on real clinical data <ref type="bibr" target="#b0">[1]</ref>. In DL, out-of-distribution (OOD) generalizability refers to a model's ability to maintain its performance on data that is independent of the model's development <ref type="bibr" target="#b22">[23]</ref>. OOD generalizability represents a critical issue in DL research since the point of artificial intelligence (AI) in medicine is to be capable of handling new patient cases. However, this important aspect of DL is often not considered. On the other hand, overcoming challenges such as scanner-induced variance are critical in the success of neuroimaging studies involving AI <ref type="bibr" target="#b4">[5]</ref>.</p><p>We hypothesize that adaptable domain-aware model calibration that combines expert-level and data-level knowledge can effectively generalize to OOD data. DL calibration is correlated with better OOD generalizability <ref type="bibr" target="#b20">[21]</ref>. Calibrated models may accomplish this by learning less spurious connections between features and classes. This observation relates to how calibrated models reflect the true likelihood of a data point for a class. A calibrated model may let a confusing data point naturally lay closer to the class boundaries, rather than forcing tight decision boundaries that over-fit points. Calibration affects decision-making such that the models can better detect and handle OOD data <ref type="bibr" target="#b18">[19]</ref>.</p><p>In this work, we introduce DOMINO++, an adaptable regularization framework to calibrate DL models based on expert-guided and data-guided knowledge. DOMINO++ builds on the work DOMINO <ref type="bibr" target="#b17">[18]</ref> with three important contributions: 1) combining expert-guided and data-guided regularization to fully exert the domain-aware regularization's potential. 2) Instead of using static scaling, DOMINO++ dynamically brings the domain-aware regularization term to the same order of magnitude as the base loss across epochs. 3) DOMINO++ adopts an adaptive regularization scheme by weighing the domain-aware regularization term in a progressive fashion. The strengths of DOMINO++'s regularization lie in its ability to take advantage of the benefits of both the semantic confusability derived from domain knowledge and data distribution, as well as its adaptive balance between the data term and the regularization strength. This work shows the advantages of DOMINO++ in a segmentation task from magnetic resonance (MR) images. DOMINO++ is tested in OOD datasets including synthesized noise additions, synthesized rotations, and a different MR scanner.</p><p>2 Dynamic Framework for DL Regularization</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">DL Backbone</head><p>U-Net transformer (UNETR) <ref type="bibr" target="#b9">[10]</ref> serves as the DL backbone. UNETR is inspired by the awe-inspiring results of transformer modules in Natural Language Processing <ref type="bibr" target="#b21">[22]</ref>. These modules use self-attention-based mechanisms to learn language range sequences better than traditional fully convolutional networks (FCNs). UNETR employs a transformer module as its encoder, whereas its decoder is an FCN like in the standard U-Net. This architecture learns threedimensional (3D) volumes as sequences of one-dimensional (1D) patches. The FCN decoder receives the transformer's global information via skip connections and concatenates this information with local context that eventually recovers the original image dimensions. The baseline model does not include advanced calibration. However, basic principles to improve OOD generalizability are still incorporated for a more meaningful comparison. These principles include standard data augmentations like random Gaussian noise, rotations along each axis, and cropping. The model includes 12 attention heads and a feature size of 16.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">DOMINO++ Loss Regularization</head><p>Derivation. The original DOMINO's loss regularization is as follows:</p><formula xml:id="formula_0">L(y, ŷ) + βy T W ŷ, where W = W HC or W CM (1)</formula><p>where L can be any uncalibrated loss function (e.g., DiceCE which is a hybrid of cross-entropy and Dice score <ref type="bibr" target="#b11">[12]</ref>). y and ŷ are the true labels and model output scores, respectively. β is an empirical static regularization rate that ranges between 0-1, and s is a pre-determined fixed scaling factor to balance the data term and the regularization term. The penalty matrix W has dimensions N × N , where N is the number of classes. W HC and W CM represent the hierarchical clustering (HC)-based and confusion matrix (CM)-based penalty matrices. We improved its loss function to DOMINO++'s dual-guidance penalty matrix with adaptive scaling and regularization rate as follows:</p><formula xml:id="formula_1">(1 -β)L(y, ŷ) + βy T (sW HCCM )ŷ<label>(2)</label></formula><p>where β dynamically changes over epochs. s is adaptively updated to balance the data and regularization terms. W HCCM is the dual-guidance penalty matrix.</p><p>Combining Expert-Guided and Data-Guided Regularization. DOMINO-HC regularizes classes by arranging them into hierarchical groupings based on domain. DOMINO-HC is data-independent and thus immune to noise. Yet, it becomes less useful without clear hierarchical groups. DOMINO-CM calculates class penalties using the performance of an uncalibrated model on a held-out dataset. The CM method does not require domain knowledge, but it can be more susceptible to messy data. Overall, DOMINO-HC is expert-crafted and DOMINO-CM is data-driven. These approaches have complementary advantages and both perform very well on medical image segmentation <ref type="bibr" target="#b17">[18]</ref>. Hence, this work combines these methods to learn from experts and data. Fig. <ref type="figure" target="#fig_0">1</ref> shows the process for creating this matrix term.</p><p>The combined regulation (a.k.a. DOMINO-HCCM) requires first replicating DOMINO-HC. For this step, we recreate the exact hierarchical groupings from the DOMINO paper <ref type="bibr" target="#b17">[18]</ref>. A confusion matrix is generated using DOMINO-HC on an additional validation set for matrix penalty. Next, the confusion matrix is normalized by the number of true pixels in each class. The normalized terms are subtracted from the identity matrix. Finally, all diagonals are set to 0's. Next, a second DL model trains using the resulting penalty matrix in its regularization. This process differs from DOMINO-CM because DOMINO-HC was used to generate the final model's matrix penalty. The uncalibrated model may produce a matrix penalty that is susceptible to variable quality depending on the model's training data. In comparison, the initial regularization term adds an inductive bias in the first model that encodes more desirable qualities about the class mappings <ref type="bibr" target="#b12">[13]</ref>. Namely, the initial model contains information about the hierarchical class groupings that drives the generation of the second model's matrix penalty. The final model can now use a regularization term that is more based on task than dataset. Figure <ref type="figure" target="#fig_1">2</ref> displays the final DOMINO++-HCCM matrix. Dynamic Scaling Term. DOMINO++ adds a domain-aware regularization term to any standard loss. The resulting loss function combines the standard loss's goal of increasing accuracy with DOMINO++'s goal of reweighing the importance of different class mix-ups when incorrect. DL models are at risk of being dominated by a specific loss during training if the losses are of different scales <ref type="bibr" target="#b13">[14]</ref>. DOMINO <ref type="bibr" target="#b17">[18]</ref> neglects to account for this and provides a static scaling for the regularization term based on the first epoch standard loss. In comparison, DOMINO++ updates the scaling on the regularization term to be within the same scale as the current epoch standard loss. Specifically, the scaling is computed based on the closest value to the baseline loss on the log scale. For example, an epoch with L = 13 will have a scaling factor S = 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Adaptive Regularization Weighting</head><p>Multiple loss functions must be balanced properly <ref type="bibr" target="#b5">[6]</ref>. Most studies linearly balance the separate loss terms using hyper-parameters. Hyper-parameter selection is nontrivial and can greatly alter performance. Indeed, the timing of regularization during training is critical to the final performance <ref type="bibr" target="#b7">[8]</ref>. Hence, the current work investigates the role of regularization timing in the final model performance. Equation 2 is similar to the original DOMINO equation <ref type="bibr" target="#b17">[18]</ref>; however, the equation is modified to include a weighting term (e.g., 1 -β) on the standard loss function. In DOMINO, the β term was simply set at a constant value of 1. As shown in Eq. 3, DOMINO++ weighs the loss regularization to decay (β) across epochs, while the standard loss is scaled reversely with regard to the regularization term (see Eq. 2).</p><formula xml:id="formula_2">β = 1 - CurrentEpoch T otalEpochs (3)</formula><p>3 Experiments and Results Reference Segmentations. The T1 MRIs are segmented into 11 different tissues, which include grey matter (GM), white matter (WM), cerebrospinal fluid (CSF), eyes, muscle, cancellous bone, cortical bone, skin, fat, major artery (blood), and air. Trained labelers performed a combination of automated segmentation and manual correction. Initially, base segmentations for WM, GM, and bone are obtained using Headreco <ref type="bibr" target="#b15">[16]</ref>, while air is generated in the Statistical Parametric Mapping toolbox <ref type="bibr" target="#b1">[2]</ref>. Afterward, these automated outputs are manually corrected using ScanIP Simpleware TM . Thresholding and morphological operations are employed to differentiate between the bone compartments. Eyes, muscle, skin, fat, and blood are manually segmented in Simpleware. Finally, CSF is generated by subtracting the ten other tissues from the whole head.</p><p>Out-of-Domain (OOD) Testing Data Most DL work selects a testing set by splitting a larger dataset into training and testing participants. This work also incorporates "messy" or fully independent data. Thus, three additional testing datasets are used along with the traditional testing data (Site A -Clean). Site A Noisy -MRI noise may be approximated as Gaussian for a signal-tonoise ratio (SNR) greater than 2 <ref type="bibr" target="#b8">[9]</ref>. Therefore, this work simulates noisy MRI images using Gaussian noise of 0 mean with a variance of 0.01.</p><p>Site A Rotated -Rotated MRI data simulates other further disturbances or irregularities (e.g., head tilting) during scanning. The rotation dataset includes random rotation of 5-to 45 • clockwise or counter-clockwise with respect to each 3D axis. The rotation angles are based on realistic scanner rotation <ref type="bibr" target="#b14">[15]</ref>.</p><p>Site B -Site A uses a 64-channel head coil and Site B uses a 32-channel head coil. The maximum theoretical SNR of an MRI increases with the number of channels <ref type="bibr" target="#b16">[17]</ref>. Hence, this work seeks to test the performance of a model trained exclusively on a higher channel scanner on a lower channel testing dataset. Thus, the Site A data serves as the exclusive source of the training and validation data, and Site B serves as a unique and independent testing dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Implementation Details</head><p>This study implements UNETR using the Medical Open Network for Artificial Intelligence (MONAI-1.1.0) in Pytorch 1.10.0 <ref type="bibr" target="#b3">[4]</ref>. The Site A data is split from 123 MRIs into 93 training/10 validation/10 held-out validation (matrix penalty)/10 testing. 10 images from Site B serve as an additional testing dataset. Each DL model requires 1 GPU, 4 CPUs, and 30 GB of memory. Each model is trained for 25,000 iterations with evaluation at 500 intervals. The models are trained on 256 × 256 × 256 images with batch sizes of 1 image. The optimization consists Adam optimization using stochastic gradient descent. All models segment a single head in 3-4 s during inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Analysis Approach</head><p>This section compares the results of 11 tissue head segmentation on each of the datasets using the baseline model, the best performing DOMINO approach, and the best performing DOMINO++ approach. The results are evaluated using Dice score <ref type="bibr" target="#b2">[3]</ref> and Hausdorff Distance <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b10">11]</ref>. The Dice score represents the overlap of the model outputs with the true labels. It is better when greater and is optimally 1. Hausdorff distance represents the distance between the model outputs with the true labels. It is better when lesser and is optimally 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Segmentation Results</head><p>Qualitative Comparisons. Figure 3 features segmentation of one example slice from the Site A MRI dataset with Gaussian Noise. DOMINO substantially exaggerates the blood regions in this slice. In addition, DOMINO entirely misses a section of white matter near the eyes. However, DOMINO can also capture certain regions of the white matter, particularly in the back of the head, better than the baseline model. In general, all outputs have noisy regions where there appear to be "specks" of an erroneous tissue. For instance, grey matter is incorrectly identified as specks within the white matter. This issue is far more common in the DOMINO output compared to the baseline or DOMINO++ outputs.</p><p>Quantitative Comparisons. Tables <ref type="table" target="#tab_1">1</ref> and<ref type="table" target="#tab_2">2</ref> show that DOMINO++ achieves the best Dice scores and Hausdorff Distances across all test sets, respectively. As such, DOMINO++ produces the most accurate overall segmentation across tissue types. The supplementary material provides individual results across every dataset and tissue type. So far, DOMINO++ improves the model generalizability to the noisy and rotated datasets the most. These improvements are important in combating realistic MR issues such as motion artifacts. Future work will  DOMINO++ performs better in most tissues and the overall segmentation. GM, cortical bone, and blood show the most significant differences with DOMINO++. This is highly relevant to T1 MRI segmentation. Bone is difficult to differentiate from CSF with only T1 scans due to similar contrast. Available automated segmentation tools use young adult heads as reference, whereas the bone structure between older and younger adults is very different (e.g., more porous in older adults). Hence, DOMINO++ is an important step in developing automated segmentation tools that are better suited for older adult heads. Training Time Analysis. DOMINO-HC took about 12 h to train whereas DOMINO-CM and DOMINO++ took about 24 h to train. All models took 3-4 s per MR volume at the inference time. A task that has very clear hierarchical groups may still favor DOMINO-HC for the convenient training time. This might include a task with well-documented taxonomic levels (e.g., animal classification). However, medical data is often not as clear, which is why models that can learn from the data are valuable. DOMINO++ makes up for the longer training time by learning more specific class similarities from the data. Tasks that benefit from DOMINO++ over DOMINO-HC are those that only have loosely-defined categories. Tissue segmentation falls under this domain because tissues largely occur in similar anatomical locations (strength of DOMINO-HC) but the overall process is still variable with individual heads (strength of DOMINO-CM).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>DOMINO <ref type="bibr" target="#b17">[18]</ref> established a framework for calibrating DL models using the semantic confusability and hierarchical similarity between classes. In this work, we proposed the DOMINO++ model which builds upon DOMINO's framework with important novel contributions: the integration of data-guided and expertguided knowledge, better adaptability, and dynamic learning. DOMINO++ surpasses the equivalent uncalibrated DL model and DOMINO in 11-tissue segmentation on both standard and OOD datasets. OOD data is unavoidable and remains a pivotal challenge for the use of artificial intelligence in clinics, where there is great variability between different treatment sites and patient populations. Overall, this work indicates that DOMINO++ has great potential to improve the trustworthiness and reliability of DL models in real-life clinical data.</p><p>We will release DOMINO++ code to the community to support open science research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The flowchart for the DOMINO++-HCCM pipeline</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Raw matrix penalty (W) for the combined method DOMINO-HCCM. Abbreviations -BG: Background, WM: White Matter, GM: Grey Matter, CSF: Cerebrospinal Fluid, CaB: Cancellous Bone, CoB: Cortical Bone.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Visual comparison of segmentation performance on a noisy MRI image from Site A. The yellow rectangular regions show areas where DOMINO++ improves the segmentation. The orange regions show areas that DOMINO and DOMION++ improve the segmentation over the baseline model. (Color figure online)</figDesc><graphic coords="8,44,79,53,75,334,45,98,95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>The data in this study is from a Phase III clinical trial that tests transcranial direct current stimulation to augment cognitive training for cognitive improvement. All participants are cognitively healthy older adults between 65-89 years old. The trial was approved by the Institutional Review Boards at both study sites. Both institutions collected structural T1-weighted magnetic resonance images (T1-MRIs) from all participants. One site ("Site A") used a 3-Tesla Siemens Magnetom Prisma scanner with a 64-channel head coil and the other site ("Site B") used a 3-Tesla Siemens Magnetom Skyra scanner with a 32-channel head coil. Both locations used the following MPRAGE sequence parameters: repetition time = 1800 ms; echo time = 2.26 ms; flip angle = 8 • ; field of view = 256 × 256 × 256 mm; voxel size = 1 mm 3 . The proper permissions were received for use of this dataset in this work. A total of 133 participants were included, including 123 from Site A and 10 participants from Site B.</figDesc><table><row><cell>3.1 Dataset</cell></row><row><cell>Data Source.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Average Dice Scores. The data is written as mean ± standard deviation. * Denotes Significance using multiple comparisons tests. 0.812 ± 0.016 * 0.789 ± 0.23 * 0.765 ± 0.027</figDesc><table><row><cell>Method</cell><cell>Site A clean</cell><cell>Site A noisy</cell><cell cols="2">Site A rotated Site B</cell></row><row><cell>Base</cell><cell>0.808 ± 0.014</cell><cell>0.781 ± 0.015</cell><cell>0.727 ± 0.041</cell><cell>0.730 ± 0.028</cell></row><row><cell>DOMINO</cell><cell>0.826 ± 0.014</cell><cell>0.791 ± 0.018</cell><cell>0.777 ± 0.023</cell><cell>0.750 ± 0.026</cell></row><row><cell cols="2">DOMINO++ 0.842 ± 0.012</cell><cell></cell><cell></cell><cell></cell></row></table><note><p>* </p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Average Hausdorff Distances. The data is written as mean ± standard deviation. * Denotes Significance using multiple comparisons tests. 0.457 ± 0.076 * 1.185 ± 0.411 * 1.228 ± 0.414 build off of DOMINO++'s improvements on different scanner data to yield even better results. Table3displays the Hausdorff Distances for every tissue across Site B's test data. Site B is highlighted since that this is real-world OOD data.</figDesc><table><row><cell>Method</cell><cell>Site A clean</cell><cell>Site A noisy</cell><cell cols="2">Site A rotated Site B</cell></row><row><cell>Base</cell><cell>0.651 ± 0.116</cell><cell>0.669 ± 0.085</cell><cell>2.266 ± 1.373</cell><cell>1.699 ± 0.414</cell></row><row><cell>DOMINO</cell><cell>0.525 ± 0.090</cell><cell>0.565 ± 0.149</cell><cell>1.284 ± 0.500</cell><cell>1.782 ± 0.669</cell></row><row><cell cols="2">DOMINO++ 0.461 ± 0.077</cell><cell></cell><cell></cell><cell></cell></row></table><note><p>* </p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Hausdorff Distances on Site B data. The data is written as mean ± standard deviation.Denotes Significance using multiple comparisons tests. Abbreviations -CaB: Cancellous Bone. CoB: Cortical Bone. The supplementary material provides the results of ablation testing on DOMINO++. These results compare how W HCCM , s, and β individually contribute to the results. Interestingly, different individual terms cause the model to perform stronger in specific datasets. Yet, the combined DOMINO++ still performs the best across the majority of datasets and metrics. These observations suggest that each term has strengths on different data types that can strengthen the overall performance.</figDesc><table><row><cell>Tissue</cell><cell>WM</cell><cell>GM</cell><cell>Eyes</cell><cell>CSF</cell><cell>Air</cell><cell>Blood</cell><cell>CaB</cell><cell>CoB</cell><cell>Skin</cell><cell>Fat</cell><cell>Muscle</cell></row><row><cell>Base</cell><cell>0.215±</cell><cell>0.266±</cell><cell>1.089±</cell><cell>0.506±</cell><cell>2.281±</cell><cell>8.534±</cell><cell>1.581±</cell><cell>2.203±</cell><cell>0.610±</cell><cell>0.958±</cell><cell>0.363±</cell></row><row><cell></cell><cell>0.063</cell><cell>0.107</cell><cell>0.881</cell><cell>0.226</cell><cell>1.426</cell><cell>2.564</cell><cell>0.626</cell><cell>1.279</cell><cell>0.424</cell><cell>0.751</cell><cell>0.159</cell></row><row><cell>DOMINO</cell><cell>0.260±</cell><cell>0.221±</cell><cell>1.600±</cell><cell>0.564±</cell><cell>2.070±</cell><cell>9.934±</cell><cell>1.456±</cell><cell>1.331±</cell><cell>0.811±</cell><cell>1.040±</cell><cell>0.320±</cell></row><row><cell></cell><cell>0.117</cell><cell>0.048</cell><cell>4.108</cell><cell>0.198</cell><cell>1.380</cell><cell>4.025</cell><cell>0.672</cell><cell>0.827</cell><cell>0.838</cell><cell>0.987</cell><cell>0.234</cell></row><row><cell cols="2">DOMINO++ 0.189±</cell><cell>0.171±</cell><cell>0.149±</cell><cell>0.462±</cell><cell>1.446±</cell><cell>6.260±</cell><cell>1.996±</cell><cell>0.950±</cell><cell>0.570±</cell><cell>1.060±</cell><cell>0.308±</cell></row><row><cell></cell><cell>0.042</cell><cell>0.036 *</cell><cell>0.047</cell><cell>0.106</cell><cell>1.057</cell><cell>2.195 *</cell><cell>0.960</cell><cell>0.705 *</cell><cell>0.369</cell><cell>0.935</cell><cell>0.165</cell></row><row><cell cols="3">Ablation Testing.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p>*   </p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This work was supported by the <rs type="funder">National Institutes of Health/National Institute on Aging, USA</rs> (<rs type="grantNumber">NIA RF1AG071469</rs>, <rs type="grantNumber">NIA R01AG054077</rs>), the <rs type="funder">National Science Foundation, USA</rs> (<rs type="grantNumber">1908299</rs>), the <rs type="funder">Air Force Research Laboratory Munitions Directorate, USA</rs> (<rs type="grantNumber">FA8651-08-D-0108 TO48</rs>), and <rs type="funder">NSF</rs>-AFRL INTERN Supplement to NSF IIS-1908299, <rs type="institution">USA</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Xs9N5kr">
					<idno type="grant-number">NIA RF1AG071469</idno>
				</org>
				<org type="funding" xml:id="_WFUZ9tW">
					<idno type="grant-number">NIA R01AG054077</idno>
				</org>
				<org type="funding" xml:id="_zdwUt8g">
					<idno type="grant-number">1908299</idno>
				</org>
				<org type="funding" xml:id="_sSSwbsa">
					<idno type="grant-number">FA8651-08-D-0108 TO48</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Invariant risk minimization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.1907.02893</idno>
		<ptr target="https://arxiv.org/abs/1907.02893" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">SPM: a history</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ashburner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="791" to="800" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Optimizing the dice score and Jaccard index for medical image segmentation: theory and practice</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bertels</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-32245-8_11</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-32245-8_11" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2019</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11765</biblScope>
			<biblScope unit="page" from="92" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">MONAI: Medical open network for AI</title>
		<author>
			<persName><forename type="first">M</forename><surname>Consortium</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.6114127</idno>
		<ptr target="https://doi.org/10.5281/zenodo.6114127" />
	</analytic>
	<monogr>
		<title level="m">If you use this software, please cite it using these metadata</title>
		<imprint>
			<date type="published" when="2020-03">March 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Challenges for machine learning in clinical translation of big data imaging studies</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Dinsdale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bluemke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sundaresan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jenkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Namburete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page" from="3866" to="3881" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">You only train once: loss-conditional training of deep networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Djolonga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A modified Hausdorff distance for object matching</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Dubuisson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 12th International Conference on Pattern Recognition</title>
		<meeting>12th International Conference on Pattern Recognition</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="566" to="568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Time matters in regularizing deep networks: weight decay and data augmentation affect early learning dynamics, matter little near convergence</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Golatkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Achille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The Rician distribution of noisy MRI data</title>
		<author>
			<persName><forename type="first">H</forename><surname>Gudbjartsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Patz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="910" to="914" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">UNETR: transformers for 3D medical image segmentation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hatamizadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="574" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Comparing images using the Hausdorff distance</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Huttenlocher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Klanderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Rucklidge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="850" to="863" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A survey of loss functions for semantic segmentation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jadon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Kukačka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Golkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10686</idno>
		<title level="m">Regularization for deep learning: a taxonomy</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning multiple pixelwise tasks based on loss scale balancing</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="5107" to="5116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The efficacy of tilted axial MRI of the CNS</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Runge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Wolpert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magn. Reson. Imaging</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="421" to="430" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">SimNIBS 2.1: a comprehensive pipeline for individualized electric field modelling for transcranial brain stimulation</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Saturnino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Puonti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Antonenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Madsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Thielscher</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-21293-3_1</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-21293-3_1" />
	</analytic>
	<monogr>
		<title level="m">Brain and Human Body Modeling</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Makarov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Horner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Noetscher</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Recent advances in MRI technology: implications for image quality and patient safety</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Sobol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Saudi J. Ophthalmol</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="393" to="399" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">DOMINO: domain-aware model calibration in medical image segmentation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Stolte</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16443-9_44</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16443-9_44" />
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer Assisted Intervention-MICCAI 2022: 25th International Conference</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Singapore; Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022-09-22">18-22 September 2022. 2022</date>
			<biblScope unit="page" from="454" to="463" />
		</imprint>
	</monogr>
	<note>Proceedings, Part V</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Calibration and generalizability of probabilistic models on lowdata chemical datasets with DIONYSUS</title>
		<author>
			<persName><forename type="first">G</forename><surname>Tom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Hickman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zinzuwadia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mohajeri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sanchez-Lengeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.01574</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Unbiased look at dataset bias</title>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2011.5995347</idno>
		<ptr target="https://doi.org/10.1109/CVPR.2011.5995347" />
	</analytic>
	<monogr>
		<title level="m">CVPR 2011</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1521" to="1528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">On calibration and out-of-domain generalization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Feder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Greenfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Shalit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural. Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="2215" to="2227" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">HuggingFace&apos;s transformers: state-of-the-art natural language processing</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Machine learning generalizability across healthcare settings: insights from multi-site COVID-19 screening</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Soltan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Clifton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digit. Med</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">69</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
