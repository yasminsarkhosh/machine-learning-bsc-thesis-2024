<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Shape-Aware 3D Small Vessel Segmentation with Local Contrast Guided Attention</title>
				<funder ref="#_JU4Bp93">
					<orgName type="full">National Institute of Health</orgName>
					<orgName type="abbreviated">NIH</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zhiwei</forename><surname>Deng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Stevens Neuroimaging and Informatics Institute</orgName>
								<orgName type="department" key="dep2">School of Medicine</orgName>
								<orgName type="institution">University of Southern California (USC)</orgName>
								<address>
									<postCode>90033</postCode>
									<settlement>Keck, Los Angeles</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Ming Hsieh Department of Electrical and Computer Engineering</orgName>
								<orgName type="department" key="dep2">Viterbi School of Engineering</orgName>
								<orgName type="institution">University of Southern California (USC)</orgName>
								<address>
									<postCode>90089</postCode>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Songnan</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Stevens Neuroimaging and Informatics Institute</orgName>
								<orgName type="department" key="dep2">School of Medicine</orgName>
								<orgName type="institution">University of Southern California (USC)</orgName>
								<address>
									<postCode>90033</postCode>
									<settlement>Keck, Los Angeles</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Ming Hsieh Department of Electrical and Computer Engineering</orgName>
								<orgName type="department" key="dep2">Viterbi School of Engineering</orgName>
								<orgName type="institution">University of Southern California (USC)</orgName>
								<address>
									<postCode>90089</postCode>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jianwei</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Stevens Neuroimaging and Informatics Institute</orgName>
								<orgName type="department" key="dep2">School of Medicine</orgName>
								<orgName type="institution">University of Southern California (USC)</orgName>
								<address>
									<postCode>90033</postCode>
									<settlement>Keck, Los Angeles</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Ming Hsieh Department of Electrical and Computer Engineering</orgName>
								<orgName type="department" key="dep2">Viterbi School of Engineering</orgName>
								<orgName type="institution">University of Southern California (USC)</orgName>
								<address>
									<postCode>90089</postCode>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiong</forename><surname>Zhang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Technology and Engineering</orgName>
								<orgName type="institution" key="instit1">Cixi Institute of Biomedical Engineering</orgName>
								<orgName type="institution" key="instit2">Ningbo Institute of Materials</orgName>
								<orgName type="institution" key="instit3">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>315300</postCode>
									<settlement>Ningbo</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Danny</forename><forename type="middle">J</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Stevens Neuroimaging and Informatics Institute</orgName>
								<orgName type="department" key="dep2">School of Medicine</orgName>
								<orgName type="institution">University of Southern California (USC)</orgName>
								<address>
									<postCode>90033</postCode>
									<settlement>Keck, Los Angeles</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lirong</forename><surname>Yan</surname></persName>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Department of Radiology</orgName>
								<orgName type="department" key="dep2">Feinberg School of Medicine</orgName>
								<orgName type="institution">Northwestern University</orgName>
								<address>
									<settlement>Chicago</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Yonggang</forename><surname>Shi</surname></persName>
							<email>yonggans@usc.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Stevens Neuroimaging and Informatics Institute</orgName>
								<orgName type="department" key="dep2">School of Medicine</orgName>
								<orgName type="institution">University of Southern California (USC)</orgName>
								<address>
									<postCode>90033</postCode>
									<settlement>Keck, Los Angeles</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Ming Hsieh Department of Electrical and Computer Engineering</orgName>
								<orgName type="department" key="dep2">Viterbi School of Engineering</orgName>
								<orgName type="institution">University of Southern California (USC)</orgName>
								<address>
									<postCode>90089</postCode>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="laboratory">RF1AG077578</orgName>
								<address>
									<postCode>RF1AG056573, RF1AG064584, RF1AG072490, R21AG064776, P41EB015922, U19AG078109</postCode>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Shape-Aware 3D Small Vessel Segmentation with Local Contrast Guided Attention</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="354" to="363"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">639C042B10C1399923BAEF1DB96CF100</idno>
					<idno type="DOI">10.1007/978-3-031-43901-8_34</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-24T10:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Small vessel</term>
					<term>Shape-aware flux</term>
					<term>Local contrast</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The automated segmentation and analysis of small vessels from in vivo imaging data is an important task for many clinical applications. While current filtering and learning methods have achieved good performance on the segmentation of large vessels, they are sub-optimal for small vessel detection due to their apparent geometric irregularity and weak contrast given the relatively limited resolution of existing imaging techniques. In addition, for supervised learning approaches, the acquisition of accurate pixel-wise annotations in these small vascular regions heavily relies on skilled experts. In this work, we propose a novel selfsupervised network to tackle these challenges and improve the detection of small vessels from 3D imaging data. First, our network maximizes a novel shape-aware flux-based measure to enhance the estimation of small vasculature with non-circular and irregular appearances. Then, we develop novel local contrast guided attention(LCA) and enhancement(LCE) modules to boost the vesselness responses of vascular regions of low contrast. In our experiments, we compare with four filtering-based methods and a state-of-the-art self-supervised deep learning method in multiple 3D datasets to demonstrate that our method achieves significant improvement in all datasets. Further analysis and ablation studies have also been performed to assess the contributions of various modules to the improved performance in 3D small vessel segmentation. Our code is available at https://github.com/dengchihwei/LCNetVesselSeg.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The automated detection and analysis of small vessels from non-invasive imaging data is critical for many clinical studies such as the research on cerebral small vessel disease(CSVD) <ref type="bibr" target="#b2">[3]</ref>, which is the most common vascular cause of dementia in Alzheimer's disease and related dementia (ADRD) <ref type="bibr" target="#b4">[5]</ref>. According to <ref type="bibr" target="#b11">[12]</ref>, a brain vessel with a diameter less than 0.5mm is considered as a small vessel by most pathologists. Fortunately, with the recent advances in MRA at 7-Tesla <ref type="bibr" target="#b6">[7]</ref> and black-blood MRI at 3-and 7-Tesla <ref type="bibr" target="#b9">[10]</ref>, it is now possible to detect the small cerebral vessels directly. Although the segmentation of large vascular structures has been well studied for many years <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b14">15]</ref>, accurate and reliable small vessel segmentation remains a challenging task. In contrast to large vessels, small vessels usually exhibit the following two main characteristics (Fig. <ref type="figure" target="#fig_0">1</ref>). ( <ref type="formula">1</ref>) Its cross-section only occupies a few image voxels due to the limited resolution of imaging techniques such as the magnetic resonance angiography(MRA). This makes the regular assumption of tube-like shape for vessels often does not hold.</p><p>(2) Small vessels often have weak intensities and low contrasts, which would be easily affected by noise or surrounding backgrounds. These characteristics are generally not well modeled by existing methods for vessel detection <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b14">15]</ref>. In each case, a maximal(minimal) intensity projection (left) and two cross sections of small vessels (right) were plotted. In (a) and (b), each cross-section corresponds to the line of the same color overlaid on the left panel (green: irregular appearances of small vessel cross-sections , red: low contrasts of small vessel cross-sections).</p><p>Traditional vesselness filters typically characterize blood vessels based on hand-crafted features <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b14">15]</ref>. The inherent assumption about the regularity of tube-like vessel geometry, however, makes them sub-optimal for small vessel segmentation. In addition, most Hessian-based filters rely on complicated preprocessing including smoothing for the calculation of second derivatives, which can further weaken or even eliminate the contrasts of small vascular structures. While deep learning methods have been successfully applied in various segmentation tasks, large-scale annotated labels are hard to obtain to train supervised networks for the segmentation of highly variable small vessels. To overcome this challenge, a self-supervised deep learning approach was recently proposed that combines geometric models and deep neural networks to learn vessel flow directions <ref type="bibr" target="#b5">[6]</ref>, but it also assumes a circular tube-like vessel shape and is thus limited in segmenting arbitrary-shaped small vessel structures.</p><p>In this work, we propose a novel self-supervised network that focus on challenges in small vessel segmentation with the following contributions: (1) Instead of assuming ideal tube-shaped vessels like <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b7">8]</ref>, we propose an adaptive scheme for shape-aware estimation of oriented fluxes to model the irregular (noncircular) cross-section profiles of small vessels. <ref type="bibr" target="#b1">(2)</ref> We propose the Local Contrast Attention (LCA) module based on a novel local contrast measure to enhance the small vessel pattern and suppress the background clutter simultaneously. <ref type="bibr" target="#b2">(3)</ref> We propose a novel unsupervised learning framework that considers the characteristics of small vessel structures in relatively limited resolution for the first time. Comprehensive experiments show promising improvements in 3D datasets of multiple modalities compared with previous unsupervised approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>Our proposed framework for small vessel detection is shown in Fig. <ref type="figure" target="#fig_1">2</ref>, a Ushaped network augmented with multiple novel LCA and LCE modules to learn a general representation of irregular-shaped small vessels by optimizing a selfsupervised loss of shape-aware flux. Formally, let Ω ⊆ R 3 denote the image domain. To characterize the irregular shape of the small vessel at each point x ∈ Ω, we estimate a principal vessel direction -→ ρ x and a set of radii values R(x) = {r i (x)|i = 1, 2, ..., m} that represent the vessel radius along m sampling directions on the unit sphere S 2 . Based on the estimated R(x) and -→ ρ x , we can compute the vesselness score f vs at x, which represents the likelihood of x being a vascular structure. The proposed network is trained to maximize the vessel Shape-Aware Flux. Given an input image I, our proposed network will generate three outputs: P , R = {r 1 , r 2 , ..., r m } and the reconstructed image Î. We denote P as a vector field that represents the principal direction for every point x ∈ Ω and R as a collection of scalar fields, where r i ∈ R is a scalar field over Ω that estimates the vessel radius along</p><formula xml:id="formula_0">d i ∈ S 2 (i = 1, 2, • • • , m).</formula><p>A projected flux response along a direction -→ ρ , which generalizes conventional flux measures for circular shaped tubes <ref type="bibr" target="#b7">[8]</ref>, can be defined at x as follows:</p><formula xml:id="formula_1">f (x, R(x), -→ ρ ) = - 1 m i ((v(x + -→ h i ) • -→ ρ ) -→ ρ ) • -→ d i (1)</formula><p>after discretization and normalization, where v(•) is the image gradient, -→</p><formula xml:id="formula_2">h i = r i (x) -→ d i and r i (x) ∈ R(x).</formula><p>The vesselness score of x can then be computed as</p><formula xml:id="formula_3">f vs (x, R(x), -→ ρ 1 ) = -f (x, R(x), -→ ρ 2 ) -f (x, R(x), -→ ρ 3 )<label>(2)</label></formula><p>where -→ ρ 1 = P (x) is the estimated principal direction at x and -→ ρ 2 , -→ ρ 3 are two orthogonal vectors in the cross-sectional plane of the vascular structure. In contrast to conventional flux measures for vessel segmentation, where only isotropic radius value is estimated, radius in different sampling directions d i are estimated adaptively in this work to fit the irregular-shaped vascular boundaries as f vs is maximized only if the sampling vectors -→ h i fit the vessel edges. Since the radius values can be different from each other, our proposed network is designed to handle the small vessels with irregular and non-circular cross-sections.</p><p>Local Contrast Guided Attention. As shown in Fig. <ref type="figure" target="#fig_0">1</ref>, geometric features of large vessels are well-presented due to their high signal-to-noise ratio(SNR).</p><p>On the other hand, the low contrast of small vessel region makes it hard to distinguish the vascular structures from the background clutters. To address this issue, Fig. <ref type="figure" target="#fig_2">3</ref>(a) illustrates our novel spatial attention module to enhance the small vessels based on regional contrast measure. In a vascular image, we assume the pixels inside a vessel have similar intensities even for small structures. Consider the estimated radius R(x) for x ∈ Ω, we define a local contrast D as</p><formula xml:id="formula_4">D(I, x, R(x), s) = 1 2 m i=1 |I(x) -I(x + s × -→ h i )||I(x) -I(x + s × -→ h j )| (3)</formula><p>where</p><formula xml:id="formula_5">-→ h j = r j (x) -→ d j and -→ d j = - -→ d i .</formula><p>With s = 1, D measures the intensity differences between x and x + -→ h i which locates on vascular boundaries for every sampling direction d i . We can contract or expand the vascular regions along its edges with different s. To measure the contrast inside and outside the vascular regions, we design two measures D in and D out as follows:  <ref type="formula">3</ref>) is evaluated on two opposite directions, D in and D out will both give low measures if x is an one-sided edge. Based on these three scenarios, we design a novel local contrast measure as</p><formula xml:id="formula_6">D in (I, x) = 1 0 D(I, x, R(x), s)ds, D out (I, x) =</formula><formula xml:id="formula_7">D LC (I, x) = Sigmoid( D out (I, x) D in (I, x) + -1)<label>(5)</label></formula><p>where is a small constant to prevent the numerical explosion. Since the ratio of D out and D in gives large value, D LC ≈ 1 for x inside a vascular structure, which means the D LC measure of small vessels is on a similar scale to large vessels.</p><p>For the latter two situations, D LC ≈ σ(0) = 0.5 will stand since D in ≈ D out . Therefore, the proposed D LC measure can enhance the small vascular structures and suppresses backgrounds and edges simultaneously.</p><p>Guided by the local contrast map of images, we propose to incorporate a novel spatial attention module in our DL network. Following CBAM <ref type="bibr" target="#b15">[16]</ref>, we use two pooling layers to abstract the previous features as two feature maps. A local contrast map is computed based on a coarsely estimated R, which is generated by previous features. Then, all three maps are sent to a convolutional block to compute the final spatial attention map. By simply extending the LCA module, LCE module scales the previous features with the attention map to refine it.</p><p>To include low-level contrast information, we insert our LCA and LCE module in the skip connections between encoders and decoders as shown in Fig. <ref type="figure" target="#fig_1">2</ref>. As shown in Fig. <ref type="figure" target="#fig_2">3(b-d</ref>), with the local contrast attention modules, our model can enhance the vesselness measure of the small vessels with low contrasts.</p><p>Self-supervised Losses. Based on (2), we propose our flux-based loss L flux as the negative average vesselness score over the whole image spatial space. This cost function takes advantage of the clear edge separation of flux-based filter and robustness to irregular-shaped vessels due to our adaptive shape-aware flux computation. To ensure the vessel structure's continuity, we adopt the path continuity loss L path from <ref type="bibr" target="#b5">[6]</ref>. Let us denote P (x) as the vascular principal direction at x, and P (x + t) as the principal direction at the location x + t, which we obtain by walking for t from x along P (x). L path is designed to maximize the inner product of these two vectors to encourages P to have a consistent and smooth direction along the vessels. Formally, L flux and L path are computed as</p><formula xml:id="formula_8">L flux (P, R) = - 1 N x∈Ω f vs (x, R(x), -→ ρ x ) L path (P, R) = - Ω 2R(x) 0 (P (x) • P (x + t))dtdx (<label>6</label></formula><formula xml:id="formula_9">)</formula><p>where N is the total number of voxels and R(x) is the average radius of R(x) so that the length of the walking path is relative to the vessel size at x. Mean square error loss is applied between the reconstructed image Î and original image I to make sure the network learns the semantic meaningful features based on the previous success of reconstruction-based self-supervised learning <ref type="bibr" target="#b8">[9]</ref>. So, the overall objective of our network is expressed as</p><formula xml:id="formula_10">L = λ 1 L flux + λ 2 L path + λ 3 MSE( Î, I) (7)</formula><p>where λ 1 , λ 2 and λ 3 correspond to the coefficients of each objective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Results</head><p>Datasets. We used two public datasets and two in-house datasets in our experiments for 3D vessel segmentation. The VESSEL12 <ref type="bibr" target="#b13">[14]</ref> contains 23 CT lung images and 3 of them are provided with sparsely annotated vessel and nonvessel locations along 3 axial slices, which we used as a test set. The TubeTk <ref type="bibr" target="#b1">[2]</ref> consists of 109 3D brain MRA images. We used the 42 images with ground truths as the test set and the rest of the dataset for training. To better demonstrate the small vessel detection ability of our method, we collected a new brain MRA dataset on a 7T Simens Terra scanner from 31 subjects with voxel size of 0.2 × 0.2 × 0.4mm. For this dataset, we sparsely annotated 2200 small vessels(within 3 × 3 grids) locations on axial slices of 7 images according to the definition of the small vessel in <ref type="bibr" target="#b11">[12]</ref> (Fig. <ref type="figure" target="#fig_4">4(i-j</ref>)). The remaining 24 images constitute the training set. In addition, a black-blood MRI dataset was collected using a Siemens 3T Prisma scanner with voxel size of 0.5 × 0.5 × 0.5mm and separated by left and right hemispheres for a total of 56 image volumes. Dense manual segmentation of the lenticulostriate arteries(LSAs) was carefully performed by two experts.</p><p>The dataset was divided into a training set with 21 subjects (42 volumes) and a test set with 7 subjects (14 volumes).</p><p>Implementation Details. We performed the vessel segmentation tasks for each dataset to evaluate our model's performance. For comparison, we selected 4 conventional filters, including the Frangi, Sato, Meijering and OOF filter and a flow-based DL method <ref type="bibr" target="#b5">[6]</ref>. For fair comparison, the same pre-processing procedures were applied for all methods using FreeSurfer 6.0 <ref type="bibr" target="#b12">[13]</ref> and the SimpleITK toolbox <ref type="bibr" target="#b0">[1]</ref>. In addition, for the black-blood LSA dataset, the image intensities were inversed to make sure the vascular voxels are brighter than backgrounds.</p><p>To tune the network's hyper-parameters, we used 15% of the training data as the validation set. Finally, we set m = 128, λ 1 = 5 and λ 2 = λ 3 = 1 for our model. For both DL models, patch size is set to 64 × 64 × 64 and the networks are trained for 100 epochs. All experiments were conducted with Pytorch on one NVIDIA A5000 GPU with the Adam optimizer and a learning rate of 0.001.</p><p>For all methods, the output is a vessel enhanced image. The enhanced image is binarized through a hard threshold. We thus found the best threshold by optimizing the metrics based on the validation sets and then applied the final threshold to test sets. We reported five metrics in Table <ref type="table" target="#tab_0">1</ref>, namely, the areaunder-curve(AUC), accuracy, sensitivity, specificity and dice score. For VES- SEL12 and 7T MRA dataset, we treated the segmentation tasks as classification problems and dropped the dice score metric since they do not have dense labels.</p><p>Results and Discussion. We can clearly observe from Table <ref type="table" target="#tab_0">1</ref> that our model outperforms all other methods by a significant margin for all datasets. Since the flow-based DL outperformed the conventional filters, we will use it for visual comparisons with our method. From Fig. <ref type="figure" target="#fig_4">4</ref>(a-d), we can observe that our model generates more accurate segmentation with more true positives and less false negatives as compared to the flow-based DL method <ref type="bibr" target="#b5">[6]</ref>. These results show that our model can better detect general vessel structures including large vessels.</p><p>Small Vessel Segmentation. From Fig. <ref type="figure" target="#fig_4">4(e-h</ref>), we can see the main improvement of our model over the flow-based DL method occurs often at areas of small vessels, where our results have much lower false negatives for small vessels missed by the other. The results on the 7T MRA data in Table <ref type="table" target="#tab_0">1</ref> further demonstrate that our model achieved better performance on the small vessel detection task. Figure <ref type="figure" target="#fig_4">4(k-l</ref>) provides a visual comparison of the performance of small vessel detection by our method and the flow-based DL, which shows that our model can more successfully segment the vessels with very small radius and low contrasts. In  addition, Fig. <ref type="figure" target="#fig_5">5</ref> shows that our estimated principal directions are better aligned with the vessel directions over the flow-based DL. Furthermore, our estimated radius can better capture the vascular shapes by fitting the asymmetric vessel boundaries. Thus, comparing with the flow-based DL, our model can produce sharper and clearer vesselness maps(Fig. <ref type="figure" target="#fig_5">5</ref>).</p><p>Ablation Study. To investigate the contributions of each proposed module in our approach, we performed ablation studies by training the network with each proposed module using the 7T MRA dataset. The results are shown in Table <ref type="table" target="#tab_1">2</ref>, where we used the flow-based DL method as the baseline for comparison. Note that CS stands for circular sampling and AS stands for the proposed shapeaware adaptive sampling. As can be seen, with all the proposed modules, we increase the AUC metric of the baseline by 4.87% on the test set, showing significant improvements with only minimal extra computational cost. Furthermore, we observed that all the proposed modules improve both the sensitivity and specificity since complicated small vessels can be better modeled by these components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>In this paper, we proposed a self-supervised network for the detection of small vessels from 3D imaging data. Our method is designed to address existing challenges in small vessel detection arising from their irregular appearance in relatively limited resolution and low-contrast conditions. In comparison to previous methods, we demonstrated that our method is able to achieve superior performance on small vessel detection. For future work, we will also apply it to various clinical datasets to examine its power for CSVD detection in brain images.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Challenges in small vessel detection. (a) A high-resolution MRA image patch (0.2 × 0.2 × 0.4 mm) acquired by a 7T Simens Terra scanner. (b) A black-blood MRI image patch (0.5 × 0.5 × 0.5 mm) acquired by a Siemens 3T Prisma scanner.In each case, a maximal(minimal) intensity projection (left) and two cross sections of small vessels (right) were plotted. In (a) and (b), each cross-section corresponds to the line of the same color overlaid on the left panel (green: irregular appearances of small vessel cross-sections , red: low contrasts of small vessel cross-sections).</figDesc><graphic coords="2,56,46,296,57,339,58,89,50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Network overview. Our model jointly estimate the vessel directions and shapes using a vector field P representing the principal direction of tubular structures and a collection of scalar fields R denoting the radius of the vessel at different directions.</figDesc><graphic coords="3,46,29,54,56,331,72,129,16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Local contrast guided attention. (a) shows the proposed LCA and LCE module framework; (b) is an axial slice of a black-blood MRI image that contains multiple low-constrast small vessels (pink box); (c) shows the learnt attention map for (b); (d-e) show the vesselness maps generated by our model without and with the proposed modules for small vascular regions, respectively.</figDesc><graphic coords="4,55,98,53,84,340,27,99,88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>2 1D</head><label>2</label><figDesc>(I, x, R(x), s)ds<ref type="bibr" target="#b3">(4)</ref> With s ∈ [0, 1], D in computes the intensity differences inside vessels. D out computes outside intensity differences similarly with s ∈<ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. As for the relations between D in and D out , we consider 3 situations for different x ∈ Ω. (1) For x inside vascular structures, D in &lt;&lt; D out should stand since |I(x)-I(x+s× -→ h i )| ≈ 0 when s &lt; 1; (2) D in and D out would give similar measures if x is in the backgrounds, where we consider the local regional intensities are similar. (3) Since equation (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Qualitative comparison. (a-h) is a comparison for TubeTK dataset. Green: true positives; red: false negatives. (i-j) is an example of our manual label for a 7T MRA image patch; (k-l) is small vessel detection comparison for the patch in (i-j).</figDesc><graphic coords="8,55,98,54,08,340,18,112,63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Vessel Estimation Comparison. Comparison between our model and flowbased model on vessel direction and shape estimations.</figDesc><graphic coords="9,49,29,54,65,325,39,56,05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Vessel Segmentation Performance Comparison on Different Datasets.</figDesc><table><row><cell></cell><cell cols="2">VESSEL12</cell><cell></cell><cell></cell><cell cols="2">7T MRA</cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell>Acc</cell><cell>Sens</cell><cell>Spec</cell><cell>AUC</cell><cell>Acc</cell><cell>Sens</cell><cell>Spec</cell><cell>AUC</cell></row><row><cell>Sato</cell><cell cols="8">0.8299 0.7580 0.8636 0.9102 0.8716 0.9705 0.7347 0.8933</cell></row><row><cell>Meijering</cell><cell cols="8">0.9184 0.8932 0.9301 0.9720 0.7060 0.9377 0.3854 0.6547</cell></row><row><cell>Frangi</cell><cell cols="8">0.9672 0.9584 0.9669 0.9738 0.8130 0.7008 0.9683 0.8104</cell></row><row><cell>OOF</cell><cell cols="8">0.9331 0.9324 0.9334 0.9659 0.8416 0.8074 0.8889 0.8623</cell></row><row><cell cols="9">Flow-Based 0.9553 0.9856 0.9213 0.9871 0.9247 0.9432 0.9261 0.9485</cell></row><row><cell>Ours</cell><cell cols="8">0.9761 0.9809 0.9793 0.9937 0.9824 0.9787 0.9875 0.9972</cell></row><row><cell></cell><cell>TubeTK</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Black-blood LSA</cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell>Dice</cell><cell>Sens</cell><cell>Spec</cell><cell>AUC</cell><cell>Dice</cell><cell>Sens</cell><cell>Spec</cell><cell>AUC</cell></row><row><cell>Sato</cell><cell cols="8">0.3166 0.3933 0.9964 0.9262 0.0596 0.7111 0.92251 0.9432</cell></row><row><cell>Meijering</cell><cell cols="8">0.1573 0.1604 0.9970 0.9023 0.1669 0.6512 0.9797 0.9459</cell></row><row><cell>Frangi</cell><cell cols="8">0.3569 0.3641 0.9977 0.9319 0.2667 0.6221 0.9905 0.9281</cell></row><row><cell>OOF</cell><cell cols="8">0.3877 0.3874 0.9980 0.9426 0.3368 0.6454 0.9886 0.9584</cell></row><row><cell cols="9">Flow-Based 0.4003 0.4211 0.9978 0.9693 0.4608 0.6673 0.9927 0.9732</cell></row><row><cell>Ours</cell><cell cols="8">0.5487 0.5061 0.9987 0.9878 0.5121 0.6979 0.9983 0.9624</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Ablation Analysis Results with the 7T high-resolution MRA Dataset.</figDesc><table><row><cell>Methods</cell><cell>Acc</cell><cell>Sens</cell><cell>Spec AUC # of Params</cell></row><row><cell>Flow-based [6]</cell><cell cols="3">0.9247 0.9432 0.9261 0.9485 32.63M</cell></row><row><cell>Ours (CS only)</cell><cell cols="3">0.9344 0.9478 0.9329 0.9554 32.63M</cell></row><row><cell>Ours (AS only)</cell><cell cols="3">0.9578 0.9669 0.9333 0.9662 32.64M</cell></row><row><cell cols="4">Ours (LCA only) 0.9747 0.9699 0.9732 0.9865 32.65M</cell></row><row><cell cols="4">Ours (AS + LCA) 0.9824 0.9787 0.9875 0.9972 32.66M</cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div><p>This work is supported by the <rs type="funder">National Institute of Health (NIH)</rs> under grants <rs type="grantNumber">R01EB022744</rs>,</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_JU4Bp93">
					<idno type="grant-number">R01EB022744</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Image segmentation, registration and characterization in r with simpleITK</title>
		<author>
			<persName><forename type="first">R</forename><surname>Beare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lowekamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yaniv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Stat. Softw</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Vessel tortuosity and brain tumor malignancy: a blinded study1</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bullitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acad. Radiol</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1232" to="1240" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Cerebral small vessel disease: a review focusing on pathophysiology, biomarkers, and machine learning strategies</title>
		<author>
			<persName><forename type="first">E</forename><surname>Cuadrado-Godia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Stroke</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">302</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multiscale vessel enhancement filtering</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Niessen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Vincken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Viergever</surname></persName>
		</author>
		<idno type="DOI">10.1007/BFb0056195</idno>
		<ptr target="https://doi.org/10.1007/BFb0056195" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 1998</title>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Colchester</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Delp</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">1496</biblScope>
			<biblScope unit="page" from="130" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Vascular contributions to cognitive impairment and dementia</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Gorelick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stroke</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2672" to="2713" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Self-supervised vessel enhancement using flow-based consistencies</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Batmanghelich</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87196-3_23</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87196-3_23" />
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer Assisted Intervention -MICCAI 2021: 24th International Conference</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Strasbourg, France; Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021-10-01">September 27-October 1, 2021. 2021</date>
			<biblScope unit="page" from="242" to="251" />
		</imprint>
	</monogr>
	<note>Proceedings, Part II</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">7t: physics, safety, and potential clinical applications</title>
		<author>
			<persName><forename type="first">O</forename><surname>Kraff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Quick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Magn. Reson. Imaging</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1573" to="1589" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Three dimensional curvilinear structure detection using optimally oriented flux</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W K</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C S</forename><surname>Chung</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-540-88693-8_27</idno>
		<ptr target="https://doi.org/10.1007/978-3-540-88693-8_27" />
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2008: 10th European Conference on Computer Vision, Marseille</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Forsyth</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Torr</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</editor>
		<meeting><address><addrLine>France; Berlin; Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">October 12-18, 2008. 2008</date>
			<biblScope unit="page" from="368" to="382" />
		</imprint>
	</monogr>
	<note>Proceedings, Part IV</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Self-supervised single-view 3D reconstruction via semantic consistency</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-58568-6_40</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-58568-6_40" />
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2020: 16th European Conference</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Bischof</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J.-M</forename><surname>Frahm</surname></persName>
		</editor>
		<meeting><address><addrLine>Glasgow, UK; Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">August 23-28, 2020. 2020</date>
			<biblScope unit="page" from="677" to="693" />
		</imprint>
	</monogr>
	<note>Part XIV</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Characterization of lenticulostriate arteries with high resolution black-blood t1-weighted turbo spin echo with variable flip angles at 3 and 7 tesla</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">199</biblScope>
			<biblScope unit="page" from="184" to="193" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Design and validation of a tool for neurite tracing and analysis in fluorescence microscopy images</title>
		<author>
			<persName><forename type="first">E</forename><surname>Meijering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Sarria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hirling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Unser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cytometry Part A: J. Int. Soc. Analy. Cytol</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="167" to="176" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Postmortem examination of vascular lesions in cognitive impairment: a survey among neuropathological services</title>
	</analytic>
	<monogr>
		<title level="j">Stroke</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1005" to="1009" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Highly accurate inverse consistent registration: a robust approach</title>
		<author>
			<persName><forename type="first">M</forename><surname>Reuter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Rosas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fischl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1181" to="1196" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Comparing algorithms for automated vessel segmentation in computed tomography scans of the lung: the vessel12 study</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Rudyanto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1217" to="1232" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Three-dimensional multi-scale line filter for segmentation and visualization of curvilinear structures in medical images</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="143" to="168" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">CBAM: convolutional block attention module</title>
		<author>
			<persName><forename type="first">S</forename><surname>Woo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Kweon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3" to="19" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
