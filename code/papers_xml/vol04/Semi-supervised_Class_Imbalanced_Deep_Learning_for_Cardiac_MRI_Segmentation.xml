<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Semi-supervised Class Imbalanced Deep Learning for Cardiac MRI Segmentation</title>
				<funder ref="#_xhKvfGw">
					<orgName type="full">Research Grants Council of the Hong Kong Special Administrative Region, China</orgName>
				</funder>
				<funder ref="#_b8yR9PE">
					<orgName type="full">Shenzhen Portion of Shenzhen-Hong Kong Science and Technology Innovation Cooperation Zone</orgName>
				</funder>
				<funder ref="#_WkbANuq">
					<orgName type="full">Hong Kong Innovation and Technology Fund</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yuchen</forename><surname>Yuan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Shatin, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Xi</forename><surname>Wang</surname></persName>
							<email>xiwang@cse.cuhk.edu.hk</email>
							<idno type="ORCID">0000-0002-5218-2761</idno>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Shatin, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xikai</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Shatin, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ruijiang</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Radiation Oncology</orgName>
								<orgName type="institution">Stanford University School of Medicine</orgName>
								<address>
									<settlement>Stanford</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pheng-Ann</forename><surname>Heng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Shatin, Hong Kong</settlement>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Institute of Medical Intelligence and XR</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Shatin, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Semi-supervised Class Imbalanced Deep Learning for Cardiac MRI Segmentation</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="459" to="469"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">9E5D585FD1E04E6695DB53F760BF04BF</idno>
					<idno type="DOI">10.1007/978-3-031-43901-8_44</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-24T10:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Semi-supervised learning • Medical image segmentation •</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Despite great progress in semi-supervised learning (SSL) that leverages unlabeled data to improve the performance over fully supervised models, existing SSL approaches still fail to exhibit good results when faced with a severe class imbalance problem in medical image segmentation. In this work, we propose a novel Mean-teacher based class imbalanced learning framework for cardiac magnetic resonance imaging (MRI) segmentation, which can effectively conquer the problems of class imbalance and limited labeled data simultaneously. Specifically, in parallel to the traditional linear-based classifier, we additionally train a prototype-based classifier that makes dense predictions by matching test samples with a set of prototypes. The prototypes are iteratively updated by in-class features encoded in the entire sample set, which can better guide the model training by alleviating the classwise bias exhibited in each individual sample. To reduce the noises in the pseudo labels, we propose a cascaded refining strategy by utilizing two multi-level tree filters that are built upon pairwise pixel similarity in terms of intensity values and semantic features. With the assistance of pixel affinities, soft pseudo labels are properly refined on-the-fly. Upon evaluation on ACDC and MMWHS, two cardiac MRI datasets with prominent class imbalance problem, the proposed method demonstrates the superiority compared to several state-of-the-art methods, especially in the case where few annotations are available (Code is available in https://github.com/IsYuchenYuan/SSCI).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>segmentation <ref type="bibr" target="#b0">[1]</ref>. However, these marvelous achievements are always accompanied by a high cost of substantial high-quality annotations, which are usually prohibitively difficult to obtain in the medical domain due to expensive time costs and highly-demanded expertise. Besides, class imbalance, caused by the huge variation of anatomical structure volumes, is another frequently occurring problem, further posing great challenges in automated and accurate 3D medical image segmentation with limited annotations.</p><p>To handle the label scarcity, a large bunch of semi-supervised learning (SSL) methods have been proposed by leveraging abundant unlabeled data to compensate for the annotation scarcity. Concretely, pseudo-labeling <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref> and consistency regularization <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref> are two effective SSL schemes. <ref type="bibr" target="#b5">[6]</ref>. For example, Bai et al. <ref type="bibr" target="#b6">[7]</ref> used the model trained on the labeled pairs to generate pseudo labels that serve as targets for the unlabeled data. To guarantee the quality of pseudo labels, Sedai et al. <ref type="bibr" target="#b7">[8]</ref> used Bayesian deep learning <ref type="bibr" target="#b8">[9]</ref> to measure the pixel-wise reliability of soft labels and suppressed regions with unreliable ones. Concurrently, Yu et al. designed a 3D uncertainty-aware semi-supervised MRI segmentation framework <ref type="bibr" target="#b9">[10]</ref>, where the uncertainty mechanism <ref type="bibr" target="#b8">[9]</ref> is integrated with consistency regularization.</p><p>Despite their success, few of the SSL segmentation methods considered class imbalance that is naturally inherent in medical images. For example, in cardiac MRI images, myocardium is often missing or too small to be detected in apical slices <ref type="bibr" target="#b10">[11]</ref>, while other structures (e.g., the left ventricle blood cavity) usually have a large span in the whole volume. There are two possible hazards resulting from such severe class imbalance when annotations are limited. One is that the model can easily become biased towards the dominant classes. The class-wise bias substantially affects model convergence during training and the generalization on the test domain <ref type="bibr" target="#b10">[11]</ref>. The other is that inadequate learning from the tail classes could introduce more noises to pseudo labels, which will dramatically accumulate during the training phase and destroy the model training consequently.</p><p>To solve the problems above, we propose a novel semi-supervised class imbalanced deep learning approach on top of the Mean-teacher framework <ref type="bibr" target="#b11">[12]</ref> for MRI segmentation. Firstly, an extra prototype-based classifier is introduced into the student model in parallel to the traditional linear-based classifier. With prototype learning, each in-class features encoded in the entire training set can be leveraged as the prior knowledge to assist the learning of each individual, conducive to accurate segmentation for tail classes. Besides, two multi-level tree filters modeling the pairwise pixel similarity in terms of intensity and semantic features are employed to refine pseudo labels. Through a comprehensive evaluation on two 3D cardiac MRI datasets with different experimental settings, our method achieves state-of-the-art results. Notably, the outstanding superiority of our method is exhibited (2.2% and 10% improvement) in the case where only quite a few labels are available (1.25% for ACDC and 10% for MMWHS).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>Problem Setting. Given limited labeled data Overview. The overview of the proposed method is shown in Fig. <ref type="figure" target="#fig_0">1</ref>. Our approach is built on top of the Mean-teacher <ref type="bibr" target="#b11">[12]</ref> framework and adopts hybrid UNet (H-UNet) as backbone. Following <ref type="bibr" target="#b12">[13]</ref>, the networks learn through the student branch only, and the teacher model is update by using an Exponential Moving Average (EMA). The student model is trained with labeled pairs and pseudo labels generated by the teacher model. We train a linear-and a prototype-based classifier in parallel to alleviate class imbalance. Moreover, to guarantee the label quality, two multi-level tree filters (TFs) constructed based on the pixel affinity in terms of intensity and semantic features are employed to refine the teacher model's predictions from the prototype-based classifier.</p><formula xml:id="formula_0">D L = {X i , Y i } L i=1 and unlabeled data D U = {X i } L+U i=L+1 , X i ∈ R H×W ×D represents the original image and Y i =</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">H-UNet for 3D Medical Image Segmentation</head><p>The backbone model H-UNet is a variant of H-DenseUNet <ref type="bibr" target="#b13">[14]</ref>. Given n samples in a training batch X ∈ R n×1×H×W ×D , the 3D UNet produces features F 3d ∈ R n×m×H×W ×D . Meanwhile, the 2D slices X 2d ∈ R nD×1×H×W obtained by performing the transformation operation T <ref type="bibr" target="#b13">[14]</ref> on the original inputs are fed into the 2D UNet to generate features F 2d ∈ R nD×m×H×W . By conducting inverse transformation operation, T -1 , F 2d is aligned with F 3d before the two features are added and fed into the hybrid feature fusion (HFF) layer to yield the hybrid features F . We apply supervision on both 2D UNet and 3D UNet to train the H-UNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Class Imbalance Alleviation via Prototype-Based Classifier</head><p>Prototype-based classifier, leveraging prototypes instead of a parameterized predictor to make predictions, presents efficacy for semantic segmentation <ref type="bibr" target="#b14">[15]</ref> and class imbalance alleviation <ref type="bibr" target="#b15">[16]</ref>. Therefore, we introduce an extra prototypebased classifier (PC) into the student model in parallel to a linear-based classifier (LC). Specifically, PC makes dense predictions by matching the normalized hybrid feature F with the nearest prototypes. Each prototype is the feature aggregation of several training pixels belonging to the same class. We denote</p><formula xml:id="formula_1">P = {p c,k } C,K c,k=1</formula><p>as a set of prototypes associated with C classes for segmentation. Note that each class may have more than one prototype (i.e., K) due to the intra-class heterogeneity exhibited in medical images <ref type="bibr" target="#b16">[17]</ref>. Given X i , PC produces the probability distribution of pixel a over the C classes:</p><formula xml:id="formula_2">p proto (Y i [a] = c|X i ) = exp(s a,c ) C c exp(s a,c ) , with s a,c = max{S( F i [a] 2 , p c,k )} K k=1 ,</formula><p>(1) where s a,c ∈ [-1, 1] denotes the pixel-class similarity between pixel a and its closest prototype of class c. S(, ) is the similarity measure (i.e., cosine similarity). F i [a] denotes the extracted features of pixel a, and Y i [a] denotes the predicted probability. • 2 stands for the 2 normalization.</p><p>Meanwhile, the features F are also fed into LC parameterized by</p><formula xml:id="formula_3">W = [w 1 , • • • , w C ] ∈ R C×m ; w c ∈ R m is a learnable projection vector for class c.</formula><p>The probability distribution of pixel a estimated by LC is defined as:</p><formula xml:id="formula_4">p linear (Y i [a] = c|X i ) = exp(w T c F i [a]) C c =1 exp(w T c F i [a]) . (<label>2</label></formula><formula xml:id="formula_5">)</formula><p>These two classifiers complete each other during training. In the early training phase, LC dominates knowledge learning and provides PC with discriminative features to initialize and update the prototypes (See Sect. 2.4). With the addition of PC, the feature embedding space is further regularized, along with intraclass features being more compact and inter-class features being more separated, which in turn benefits the learning of LC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Pseudo Label Refinement via Multi-level Tree Filters</head><p>Rather than directly using the teacher's high-confidence prediction to generate pseudo labels <ref type="bibr" target="#b12">[13]</ref>, we propose a cascaded refining strategy (CRS) to improve the label quality in a slice-by-slice manner on 3D volumes by using TFs <ref type="bibr" target="#b17">[18]</ref>, which proceeds with the following three steps as depicted in Fig. <ref type="figure" target="#fig_1">2</ref>.</p><p>Graph Construction: First, we respectively represent the topology of the low-level original unlabeled image and the high-level hybrid features as two 4connected planar graphs: G * = {V * , E * } where V * is the vertex set associated with each pixel and E * is the edge set, and * ∈ {low, high}. The weight of the edge connecting two adjacent nodes a and b indicates their dissimilarity, which is defined by: Multi-level Filter Construction: Based on the two MSTs, we build the lowlevel TF F low and the high-level TF F high . The filter weight F * a,b of any two nodes is obtained by aggregating the MST edge weights along the path between the two nodes <ref type="bibr" target="#b19">[20]</ref>:</p><formula xml:id="formula_6">w low a,b = w low b,a = d(I[a], I[b]), w high a,b = w high b,a = d(F [a], F [b]),<label>(3)</label></formula><formula xml:id="formula_7">F * a,b = 1 z a S G * mst (E * a,b ), where S G * mst (E * a,b ) = exp(- ∀(q,o)∈E * a,b w * q,o ).<label>(4)</label></formula><p>Here, E * a,b is the edge set in the path from node a to node b. S G * mst (•) maps the distance of two vertices into a positive scalar which measures the pixel affinity. z a is a normalization factor, which is the summation of the similarity between node a and all other nodes in the MST.</p><p>Cascaded Refinement: Lastly, we refine the teacher's prediction P with the two filters in a cascade manner to acquire high-quality pseudo labels Ŷ :</p><formula xml:id="formula_8">Ŷ = R F high , R(F low , P ) , with R(F * , P a ) = ∀b∈V * F * a,b P b , (<label>5</label></formula><formula xml:id="formula_9">)</formula><p>where R(•, •) is the refinement process where each unlabeled pixel can contribute to the refinement for other pixels with a contribution proportional to their similarity. By exploiting the multi-level complementary features, i.e., the object boundary information encoded in F low and the semantic similarity encoded in F high , CRS shows superiority when a single TF fails in some cases. E.g., when two pixels of different classes have similar intensity values (pixel a and b in Fig. <ref type="figure" target="#fig_1">2</ref>), F low will model them as affinity pairs, which is not expected. Fortunately, F high can suppress the mutual interference between them according to their distinct semantic features, thus ensuring refinement efficacy (See Supplementary Fig. <ref type="figure" target="#fig_0">1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Network Training and Prototype Update</head><p>The framework is trained by utilizing both the labeled data D L and the unlabeled data D U . For the labeled data, the supervised loss is defined as:</p><formula xml:id="formula_10">L l = 1 L L i=1 l( Y 2D i , Y 2D i ) + l(p proto (Y i |X i ), Y i ) + l(p linear (Y i |X i ), Y i ) , (<label>6</label></formula><formula xml:id="formula_11">)</formula><p>where Y 2D is the prediction generated by the 2D UNet in H-UNet, and Y 2D is the transformation of the 3D ground truth Y by conducting T (See Sect. 2.1). l is the weighted sum of cross entropy loss and dice loss.</p><p>For the unlabeled data, the student model is trained with the pseudo labels Ŷ refined by the proposed CRS. The unsupervised loss is defined as:</p><formula xml:id="formula_12">L u = 1 U L+U i=L+1 l( Y 2D i , Ŷ 2D i ) + l(p proto (Y i |X i ), Ŷi ) + l(p linear (Y i |X i ), Ŷi ) .</formula><p>(7) Following <ref type="bibr" target="#b9">[10]</ref>, we use a time-dependent Gaussian warming up function to control the balance between the supervised and unsupervised loss.</p><p>Prototype Initialize and Update: The initialization of prototypes determines the PC performance. To get better prototypes, we first pretrain the network with the LC solely. Then, we collect pixelwise deep features and use K-means <ref type="bibr" target="#b20">[21]</ref> to generate K subclusters for each class. Finally, initial prototypes of each class are obtained by averaging the features in each subcluster. Following <ref type="bibr" target="#b14">[15]</ref>, after each training iteration, we first conduct online clustering by few steps of Sinkhorn-Knopp iteration <ref type="bibr" target="#b21">[22]</ref> and let the prototypes evolve continuously with the clustering features of both the labeled and unlabeled samples:</p><formula xml:id="formula_13">p c,k ← αp c,k + (1 -α) F c,k 2 , (<label>8</label></formula><formula xml:id="formula_14">)</formula><p>where α is a momentum coefficient, i.e., 0.999. 3 Experiments and Results</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets and Implementation Details</head><p>Datasets and Evaluation Metrics: The model is evaluated on two public cardiac MRI datasets: (1) The ACDC Implementation Details: We split the datasets into the training and validation set randomly at a ratio of 4:1 <ref type="bibr" target="#b10">[11]</ref>. To assess the model performance on different label percentages, we respectively take 1.25%, 2.5%, and 10% data from the ACDC training set and 10%, 20%, and 40% data from the MMWHS training set as the labeled data and the rest as unlabeled. The training details for the two datasets are provided in Section A of the Supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Comparison with State-of-the-Arts</head><p>Table <ref type="table">1</ref>. Comparison with state-of-art methods on the ACDC and MMWHS datasets Methods Avg DSC (ACDC) Avg DSC (MMWHS) L = 1.25% L = 2.5% L = 10% L = 10% L = 20% L = 40%</p><p>Self train <ref type="bibr" target="#b6">[7]</ref> 0 We compare our method with several state-of-the-art frameworks for semisupervised medical image segmentation. The results are reported in Table <ref type="table">1</ref>.</p><p>Among these, the proposed method outperforms competing methods across all datasets and label percentages, except for a slightly lower DSC than method Class-wise Sampling <ref type="bibr" target="#b10">[11]</ref> by using 20% labeled MMWHS data. However, method <ref type="bibr" target="#b10">[11]</ref> fails to produce satisfactory results using very few annotations (L = 1.25% in ACDC and L = 10% in MMWHS). In contrast, our method exhibits quite consistent performance on different label percentages and has substantial improvement when only few annotations are available, with more than 10% increase by using 10% labeled MMWHS. This indicates the benefit of fully leveraging unlabeled data via the proposed PC and CRS, in which every pixel in the unlabeled data can properly contribute to the model training and the refinement for pseudo labels. Methods like Data Aug <ref type="bibr" target="#b24">[25]</ref> and contrastive learning of global and local features <ref type="bibr" target="#b27">[27]</ref> do not explicitly address the class imbalance problem, thus they have inferior performance on both datasets. Also, these two methods both require a complex pretraining process, which is inefficient and time-consuming. Mixmatch <ref type="bibr" target="#b26">[26]</ref>, mixing labeled and unlabeled data using MixUp in SSL, cannot work very well for the datasets with a severe class imbalance problem, mainly because simply mixing two images could oppositely increase difficulty in the less-dominant classes learning. We conducted ablation analyses on MMWHS by using 40% labeled data to investigate the contribution of the proposed key components (PC and CRS) and the choice of the backbone network. All the models are trained in the SSL way, and we use the thresholded pseudo-labeling <ref type="bibr" target="#b2">[3]</ref> (threshold = 0.8) to generate pseudo labels for the models when CRS is absent. Table <ref type="table" target="#tab_2">2</ref> presents the results of several variants by using different combinations of the proposed key components and two backbone networks. Compared with 3D UNet, H-UNet (model ①) shows more consistent results on different substructures and better performance regardless of the use of the proposed components, with a 1.2% and 4.0% increase in average DSC with and without PC and CRS respectively, indicating the merits of exploiting both intra-slice and inter-slice information for 3D medical image segmentation. When thresholded pseudo-labeling is replaced with CRS, model ② improves the average DSC by 1.7% with a smaller deviation for each heart substructure among all test samples, suggesting the effectiveness of CRS. PC alleviates the class imbalance problem by leveraging the prior knowledge of the entire sample set to assist individual learning. This is justified by the improvements of 1.5% on average DSC and better results on tail classes (e.g., RA, MYO) brought by substituting LC with PC (model ③). Moreover, the performance is further boosted when these two classifiers are simultaneously adopted (model ④), outperforming LC and PC by a margin of 4.3% and 2.8% respectively. This is because the mutual promotion between the two classifiers could provide a better regularized feature space for pixel predictions. With CRS integrated, PC and LC are trained with more reliable pseudo labels. The DSC is further improved by 1.5% (model ⑤), arriving at the highest value (0.840). Noticeably, when 3D UNet is equipped with all the components, the average DSC is improved by 3.0% with performance soar on tail classes. Such consistent efficacy indicates the potential of using the proposed PC and CRS to endow any segmentation backbones with the capability of addressing the class imbalance problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Ablation Studies</head><p>Please refer to Section B in the Supplementary material for more results in terms of average symmetric surface distance (ASSD) in voxel and the qualitative analyses of multi-level tree filters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>The scarcity of pixel-level annotations affects the performance of deep neural networks for medical image segmentation. Moreover, the class imbalanced problem existing in the medical data can further exacerbate the model degradation. To address the problems, we propose a novel semi-supervised class imbalanced learning approach by additionally introducing the prototype-based classifier into the student model and constructing two multi-level tree filters to refine the pseudo labels for more robust learning. Experiments conducted on two public cardiac MRI datasets demonstrate the superiority of the proposed method.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Overview of the proposed semi-supervised class imbalance learning framework.</figDesc><graphic coords="3,89,22,54,35,273,64,148,18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The illustration of the cascaded refining strategy by using multi-level tree filters.</figDesc><graphic coords="5,111,45,63,41,222,67,118,12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>F c,k 2</head><label>2</label><figDesc>are the normalized features of pixels which belong to the c-th class and are closest to the k-th subcluster. Since the prototypes are iteratively updated by the in-class features encoded in the entire sample set, such prior knowledge can alleviate the class-wise bias exhibited in each individual sample, which can better guide the model training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Ahead of training, we removed the top 2% of the highest intensity value to reduce artifact impact for MMWHS dataset, followed by zscore normalization. As ACDC has a low through-plane resolution of 5-10 mm, we resample all 2D slices to a fixed in-plane resolution of 1 × 1 mm with a size of 256 × 256 as the training samples. For MMWHS, we randomly crop 3D cubes with a size of 80 × 80 × 80 for training.</figDesc><table><row><cell>1 [23] contains 100 patients' scans, with</cell></row><row><cell>expert annotations for 3 structures: left ventricle (LV), myocardium (MYO), and</cell></row><row><cell>right ventricle (RV); (2) The MMWHS 2 [24] consists of 20 3D cardiac MRIs with</cell></row><row><cell>annotations for 7 structures: LV, RV, MYO, left atrium (LA), right atrium (RA),</cell></row><row><cell>ascending aorta (AA), and pulmonary artery (PA). We adopt Dice Similarity</cell></row><row><cell>Score (DSC) to evaluate model performance.</cell></row><row><cell>Pre-processing:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Ablation studies on the efficacy of different components in the proposed method. The mean and standard deviation of the testing results are reported.</figDesc><table><row><cell>Methods</cell><cell cols="4">LC PC CRS Avg DSC Dice of heart substructures ↑</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>MYO</cell><cell>LA</cell><cell>LV</cell><cell>RA</cell><cell>RV</cell><cell>AA</cell><cell>PA</cell></row><row><cell>3D UNet</cell><cell>0.770</cell><cell cols="6">0.756(.08) 0.662(.08) 0.896(.02) 0.740(.13) 0.854(.04) 0.743(.06) 0.738(.02)</cell></row><row><cell></cell><cell>0.800</cell><cell cols="6">0.793(.04) 0.751(.02) 0.909(.02) 0.798(.06) 0.837(.09) 0.789(.06) 0.725(.04)</cell></row><row><cell>H-UNet ①</cell><cell>0.782</cell><cell cols="6">0.757(.06) 0.758(.02) 0.897(.03) 0.730(.08) 0.805(.07) 0.775(.08) 0.756(.03)</cell></row><row><cell>②</cell><cell>0.799</cell><cell cols="6">0.776(.04) 0.763(.01) 0.893(.02) 0.809(.07) 0.786(.05) 0.789(.08) 0.775(.01)</cell></row><row><cell>③</cell><cell>0.797</cell><cell cols="6">0.762(.06) 0.750(.02) 0.909(.02) 0.789(.08) 0.835(.04) 0.786(.05) 0.751(.03)</cell></row><row><cell>④</cell><cell>0.825</cell><cell cols="6">0.800(.03) 0.800(.02) 0.910(.02) 0.843(.04) 0.864(.04) 0.789(.09) 0.766(.03)</cell></row><row><cell>⑤</cell><cell>0.840</cell><cell cols="6">0.808(.07) 0.794(.01) 0.927(.01) 0.860(.05) 0.897(.03) 0.838(.04) 0.755(.04)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://www.creatis.insa-lyon.fr/Challenge/acdc/databases.html.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://zmiclab.github.io/zxh/0/mmwhs/.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement. This work described in this paper was supported in part by the <rs type="funder">Shenzhen Portion of Shenzhen-Hong Kong Science and Technology Innovation Cooperation Zone</rs> under <rs type="grantNumber">HZQB-KCZYB-20200089</rs>. The work was also partially supported by a grant from the <rs type="funder">Research Grants Council of the Hong Kong Special Administrative Region, China</rs> (Project Number: <rs type="grantNumber">T45-401/22-N</rs>) and by a grant from the <rs type="funder">Hong Kong Innovation and Technology Fund</rs> (Project Number: <rs type="grantNumber">MHP/085/21</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_b8yR9PE">
					<idno type="grant-number">HZQB-KCZYB-20200089</idno>
				</org>
				<org type="funding" xml:id="_xhKvfGw">
					<idno type="grant-number">T45-401/22-N</idno>
				</org>
				<org type="funding" xml:id="_WkbANuq">
					<idno type="grant-number">MHP/085/21</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43901-8_44.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep learning techniques for medical image segmentation: achievements and challenges</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Hesamian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Digit. Imaging</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="582" to="596" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Pseudo-label: the simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName><forename type="first">D.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Challenges in Representation Learning</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">896</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Flexmatch: boosting semi-supervised learning with curriculum pseudo labeling</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural. Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="18408" to="18419" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Temporal ensembling for semi-supervised learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.02242</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning with local and global consistency</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Embracing imperfect datasets: a review of deep learning solutions for medical image segmentation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Tajbakhsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jeyaseelan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page">101693</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Semi-supervised learning for network-based cardiac MR image segmentation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Bai</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-66185-8_29</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-66185-8_29" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2017</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Duchesne</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">10434</biblScope>
			<biblScope unit="page" from="253" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Uncertainty guided semi-supervised segmentation of retinal layers in OCT images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sedai</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-32239-7_32</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-32239-7_32" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2019</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11764</biblScope>
			<biblScope unit="page" from="282" to="290" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Dropout as a Bayesian approximation: representing model uncertainty in deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1050" to="1059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Uncertainty-aware self-ensembling model for semi-supervised 3D left atrium segmentation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-W</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Heng</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-32245-8_67</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-32245-8_67" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2019</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11765</biblScope>
			<biblScope unit="page" from="605" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Addressing class imbalance in semi-supervised image segmentation: a study on cardiac MRI</title>
		<author>
			<persName><forename type="first">H</forename><surname>Basak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghosal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sarkar</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16452-1_22</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16452-1_22" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13438</biblScope>
			<biblScope unit="page" from="224" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Fixmatch: simplifying semi-supervised learning with consistency and confidence</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural. Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="596" to="608" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">H-DenseUNet: hybrid densely connected UNet for liver and tumor segmentation from CT volumes</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-W</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2663" to="2674" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Rethinking semantic segmentation: a prototype view</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Konukoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2582" to="2593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep prototypical networks for imbalanced time series classification under data scarcity</title>
		<author>
			<persName><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 28th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2141" to="2144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Current methods in medical image segmentation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Prince</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="315" to="337" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learnable tree filter for structure-preserving feature transform</title>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">On the shortest spanning subtree of a graph and the traveling salesman problem</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Kruskal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Am. Math. Soc</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="48" to="50" />
			<date type="published" when="1956">1956</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Stereo matching using tree filtering</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="834" to="846" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Genetic k-means algorithm</title>
		<author>
			<persName><forename type="first">K</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Murty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst. Man Cybern. Part B (Cybern.)</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="433" to="439" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Sinkhorn distances: lightspeed computation of optimal transport</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cuturi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Deep learning techniques for automatic MRI cardiac multistructures segmentation and diagnosis: is the problem solved?</title>
		<author>
			<persName><forename type="first">O</forename><surname>Bernard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2514" to="2525" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multi-scale patch and multi-modality atlases for whole heart segmentation of MRI</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="77" to="87" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Semi-supervised and task-driven data augmentation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chaitanya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Karani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Baumgartner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Donati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Konukoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IPMI 2019</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">C S</forename><surname>Chung</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Gee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Yushkevich</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Bao</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">11492</biblScope>
			<biblScope unit="page" from="29" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Cham</forename><surname>Springer</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-20351-1_3</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-20351-1_3" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Mixmatch: a holistic approach to semi-supervised learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Contrastive learning of global and local features for medical image segmentation with limited annotations</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chaitanya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Erdil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Karani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Konukoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural. Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="12546" to="12558" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
