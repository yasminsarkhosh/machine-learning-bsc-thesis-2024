<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Qin</forename><surname>Ren</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">AI Lab</orgName>
								<address>
									<postCode>518000</postCode>
									<settlement>Tencent, Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Shenzhen International Graduate School</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>518071</postCode>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yu</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">AI Lab</orgName>
								<address>
									<postCode>518000</postCode>
									<settlement>Tencent, Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bing</forename><surname>He</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">AI Lab</orgName>
								<address>
									<postCode>518000</postCode>
									<settlement>Tencent, Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bingzhe</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">AI Lab</orgName>
								<address>
									<postCode>518000</postCode>
									<settlement>Tencent, Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sijie</forename><surname>Mai</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Electronic and Information Technology</orgName>
								<orgName type="institution">Sun Yat-sen University</orgName>
								<address>
									<postCode>510006</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fan</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">AI Lab</orgName>
								<address>
									<postCode>518000</postCode>
									<settlement>Tencent, Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">ShanghaiTech University</orgName>
								<address>
									<postCode>201210</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yueshan</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">AI Lab</orgName>
								<address>
									<postCode>518000</postCode>
									<settlement>Tencent, Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<postCode>200240</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yonghong</forename><surname>He</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Shenzhen International Graduate School</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>518071</postCode>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
							<affiliation key="aff5">
								<orgName type="institution">University of Texas at Arlington</orgName>
								<address>
									<postCode>76019</postCode>
									<settlement>Arlington</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Jianhua</forename><surname>Yao</surname></persName>
							<email>jianhuayao@tencent.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">AI Lab</orgName>
								<address>
									<postCode>518000</postCode>
									<settlement>Tencent, Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">IIB-MIL: Integrated Instance-Level and Bag-Level Multiple Instances Learning with Label Disambiguation for Pathological Image Analysis</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="560" to="569"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">26FE103FB920423EF0301F88CB8918E7</idno>
					<idno type="DOI">10.1007/978-3-031-43987-2_54</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-24T11:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>computational pathology</term>
					<term>multi-instance learning</term>
					<term>label disambiguation</term>
					<term>prototype</term>
					<term>confidence bank</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Digital pathology plays a pivotal role in the diagnosis and interpretation of diseases and has drawn increasing attention in modern healthcare. Due to the huge gigapixel-level size and diverse nature of whole-slide images (WSIs), analyzing them through multiple instance learning (MIL) has become a widely-used scheme, which, however, faces the challenges that come with the weakly supervised nature of MIL. Conventional MIL methods mostly either utilized instance-level or bag-level supervision to learn informative representations from WSIs for downstream tasks. In this work, we propose a novel MIL method for pathological image analysis with integrated instance-level and bag-level supervision (termed IIB-MIL). More importantly, to overcome the weakly supervised nature of MIL, we design a label-disambiguation-based instancelevel supervision for MIL using Prototypes and Confidence Bank to reduce the impact of noisy labels. Extensive experiments demonstrate that IIB-MIL outperforms state-of-the-art approaches in both benchmarking datasets and addressing the challenging practical clinical task. The code is available at https://github.com/TencentAILabHealthcare/ IIB-MIL.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Pathology is widely recognized as the gold standard for disease diagnosis <ref type="bibr" target="#b14">[15]</ref>. As the demand for intelligently pathological image analysis continues to grow, an increasing number of researchers have paid attention to this field <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b24">25]</ref>. However, pathological image analysis remains a challenging task due to the complex and heterogeneous nature <ref type="bibr" target="#b18">[19]</ref> of obtained whole slide images (WSIs), as well as their huge gigapixel-level size <ref type="bibr" target="#b19">[20]</ref>. To address this issue, multiple instance learning (MIL) <ref type="bibr" target="#b0">[1]</ref> is usually applied to formulate pathological image analysis tasks into weakly supervised learning problems. In the MIL setting, the entire WSI is regarded as a bag and tiled patches are instances. The primary challenge of MIL arises from its weakly supervised nature, i.e. only the baglevel label for the entire WSI is provided, while labels for individual patches are usually unavailable. Although MIL-based methods have shown impressive potential in solving a wide range of pathological image analysis tasks including cancer grading and subtype diagnosis <ref type="bibr" target="#b22">[23]</ref>, prognosis prediction <ref type="bibr" target="#b17">[18]</ref>, genotyperelated tasks such as gene mutation prediction <ref type="bibr" target="#b3">[4]</ref>, etc., it is still an open question regarding learning an informative and effective representation of the entire WSI for down-streaming task based on MIL architecture.</p><p>Current MIL methods can be broadly categorized into two types: bag-level MIL and instance-level MIL. Bag-level MIL <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b16">17]</ref>, also known as embeddingbased MIL, involves converting patches (instances) into low-dimensional embeddings, which are then aggregated into WSI (bag)-level representations to conduct the analysis tasks <ref type="bibr" target="#b21">[22]</ref>. The aggregator can take different architectures such as an attention module <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b12">13]</ref>, convolutional neural network (CNN), Transformer <ref type="bibr" target="#b15">[16]</ref>, or graph neural network <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b27">28]</ref>. Instance-level MIL <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b23">24]</ref>, on the other hand, focuses its learning process at the instance level, and then obtains the bag-level prediction by simply aggregating instance predictions. Bag-level MIL incorporates instance embeddings to create a bag representation, converting the MIL into a supervised learning problem. Furthermore, it can extract contextual information and correlations between instances. Nonetheless, Bag-level MIL needs to learn informative embeddings of instances and adjust the contributions of these instance embeddings to generate the bag representation simultaneously, which faces the risk of obtaining a suboptimal model given the limited training samples in practice. The instance-level MIL, however, faces the problem of noisy labels, which is caused by the common strategy of assigning the WSI labels to patches and the fact that there are lots of patches irrelevant to the WSI labels <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b5">6]</ref>.</p><p>Considering these conventional MIL methods usually utilize either bag-level or instance-level supervision, leading to suboptimal performance. In this paper, we format the instance-level MIL as a noisy label learning task and propose to solve it by designing an instance-level supervision based on the label disambiguation <ref type="bibr" target="#b20">[21]</ref>. Then we propose to combine bag-level and instance-level supervision to improve the performance of MIL. The bag-level and instance-level supervision can corporately optimize the instance embedding learning process and welllearned instance embeddings can facilitate the aggregation module to generate the bag representation. The co-supervision design also makes the MIL to be a multi-task learning framework, where the bag-level supervision channel works to globally summarise the WSI for prediction and the instance-level supervision channel can locally identify key relevant patches. The detailed contributions can be summarized as follows:</p><p>1) We propose a novel MIL method for pathological image analysis that leverages a specially-designed residual Transformer backbone and organically integrates both Transformer-based bag-level and label-disambiguation-based instancelevel supervision for performance enhancement. 2) We develop a label-disambiguation module that leverages prototypes and confidence bank to tackle the weakly supervised nature of instance-level supervision and reduce the impact of assigned noisy labels.</p><p>3) The proposed framework outperforms state-of-the-art (SOTA) methods on public datasets and in a practical clinical task, demonstrating its superiors in WSI analysis. Besides, ablation studies illustrate the superiority of our co-supervision design compared to using only one type of supervision. 2 Method</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Overview</head><p>The overall framework of the proposed IIB-MIL is shown in Fig. <ref type="figure" target="#fig_0">1</ref>. Similar to previous works <ref type="bibr" target="#b26">[27]</ref>, IIB-MIL first transforms input huge-size WSI to a set of patch embeddings to simplify the following learning task using a pre-trained encoder, i.e. EfficientNet-B0. Then a specially-designed residual transformer backbone works to calibrate the obtained patch embeddings and encode the context information and correlation of patches. After that, IIB-MIL utilizes both a transformer-based bag-level and a label-disambiguation-based instance-level supervision to cooperatively optimize the model, where the bag-level loss is calculated referring to the WSI labels, while the instance loss is calculated referring to pseudo patch labels calibrated by the Label-Disambiguation module. Since bag-level supervision channel is trained to globally summarise information of all patches for prediction, the bag-level outputs are used as the final predictions during the test stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Problem Formulation</head><p>Assume there is a set of N WSIs denoted by S = {S 1 , S 2 , ..., S N }. Each WSI S i has a WSI-level label Y i ∈ {1, ..., C}, where C represents category number. In each S i , there exist M i tiled patches without patch-level labels. To reduce the computational cost, we used a frozen pre-trained encoder to transform patches into K dimensional embeddings {e i,</p><formula xml:id="formula_0">j |e i,j ∈ R K , i ∈ [1, N], j ∈ [1, M]}.</formula><p>Our proposed IIB-MIL comprehensively integrates obtained embeddings {e i,j , ...} to generate accurate WSI classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Backbone Network</head><p>Before bag-level and instance-level supervision channels, we design a residual transformer backbone T (•) : R K → R D to calibrate the obtained patch embeddings and encode the context information and correlation of patches. T (•) maps patch embeddings {e i,j , ...} to a lower-dimensional feature space, denoted as {x i,j , ...}, where x i,j = T (e i,j ), x i,j ∈ R D is the calibrated embedding, T (•) is composed of transformer layers and skip connections (Details are given in the supplementary.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Instance-Level Supervision</head><p>At the core of instance-level supervision is the label disambiguation module, which serves to rectify the imprecise labels that have been assigned to patches. It comprises prototypes and a confidence bank, takes instance features and instance classifier predictions as inputs, and generates soft labels as outputs (Fig. <ref type="figure" target="#fig_0">1 (b)</ref>). The prototypes, denoted as P ∈ R C×D , are initialized with all-zero vectors and employ momentum-based updates using selected instance features x with the highest probability prob inst of belonging to their corresponding categories. Prototype labels z are determined based on the proximity of patch features to the prototypes. Confidence B ∈ R N ×M ×C is initialized with all WSI labels and uses momentum-based updates with z. Detailed steps are summarized as follows:</p><p>Step 1: Obtain the instance classifier output. The instance-level classifier, denoted as F inst (•), takes x i,j ∈ R D as input and outputs the predicted instance probability prob inst i,j ∈ R C , as:</p><formula xml:id="formula_1">prob inst i,j = sof tmax(F inst (x i,j )),<label>(1)</label></formula><p>The probability that x i,j is predicted as class c is denoted as</p><formula xml:id="formula_2">prob inst i,j,c ∈ R 1 .</formula><p>Step 2: Obtain the prototype labels. At t time, the prototype vector for the category c is P c,t ∈ R D . To update P c,t , we select a set of instance features Set c,t that have the highest probabilities prob inst i,j,c of belonging to category c. Specifically, we define Set c,t as:</p><formula xml:id="formula_3">Set c,t = {x i,j |arg T op K (prob inst i,j,c ), j ∈ [1, M], i ∈ {i|Y i = c}}, (<label>2</label></formula><formula xml:id="formula_4">)</formula><p>where K is the number of top instance features to select. Then, we use a momentum-based update rule to obtain P c,t+1 :</p><formula xml:id="formula_5">P c,t+1 = α • P c,t + (1 -α) • x i,j , if x i,j ∈ Set c,t ,<label>(3)</label></formula><p>where α is the momentum coefficient that automatically decreases from α = 0.95 to α = 0.8 across epochs. Then, we can obtain prototype labels z i,j ∈ R C using the following equation:</p><formula xml:id="formula_6">z i,j = OneHot(arg max c (P • x T i,j )),<label>(4)</label></formula><p>The resulting prototype label z i,j ∈ R C is a one-hot vector that indicates the category of the j-th instance in the i-th WSI.</p><p>Step 3: Obtain Soft Labels from the Confidence Bank Specifically, at time t, the pseudo-target B i,j,t ∈ R C of the instance embedding e i,j is updated by the following:</p><formula xml:id="formula_7">B i,j,t = β • B i,j,t-1 + (1 -β) • z i,j , (<label>5</label></formula><formula xml:id="formula_8">)</formula><p>where β is the momentum update parameter with a default value of β = 0.99.</p><p>Step 4: Calculate Instance-Level Loss. We compute instance-Level Loss using the cross-entropy function:</p><formula xml:id="formula_9">L inst = - N i=1 M j=1 C k=1 B i,j,c • log(prob inst i,j,c ),<label>(6)</label></formula><p>Here, B i,j,c and prob inst i,j,c are the c-th component of the pseudo-target B i,j and predicted probability prob inst i,j , respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Bag-Level Supervision</head><p>For bag-level supervision, instance features x i ∈ R M ×D go through a transformer-based aggregator A(•) : R M ×D → R D and a WSI classifier F bag (•) : R D → R C in turn (Architecture details are given in the supplementary.). Then we obtain the predicted probability of WSI S i as:</p><formula xml:id="formula_10">prob bag i = sof tmax(F bag (A(x i ))). (<label>7</label></formula><formula xml:id="formula_11">)</formula><p>The bag-level loss function is given by:</p><formula xml:id="formula_12">L bag = - N i=1 prob bag i • log(Y i ),<label>(8)</label></formula><p>where Y i ∈ R C is the label of WSI S i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Training</head><p>In the training phase, We employ a warm-up strategy in which we update only the Prototypes and do not update the Confidence Bank during the first few epochs. Our approach is trained end-to-end, and the total loss function is :</p><formula xml:id="formula_13">L = L bag + λL inst , (<label>9</label></formula><formula xml:id="formula_14">)</formula><p>where λ is the hyperparameter that controls the relative importance of the two losses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset</head><p>We evaluate our model with three datasets. (1) LUAD-GM Dataset: The objective is to predict the epidermal growth factor receptor (EGFR) gene mutations in patients with lung adenocarcinoma (LUAD) using 723 Whole Slide Image (WSI) slices, where 47% of cases have EGFR mutations. (2) TCGA-NSCLC and TCGA-RCC Datasets: Cancer type classification is performed using The Cancer Genome Atlas (TCGA) dataset. The TCGA-NSCLC dataset comprised two subtypes, lung squamous cell carcinoma (LUSC) and lung adenocarcinoma (LUAD), while the TCGA-RCC dataset included three subtypes: renal chromophobe cell carcinoma (KICH), renal clear cell carcinoma (KIRC), and renal papillary cell carcinoma (KIRP).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experiment Settings</head><p>The dataset was randomly split into three parts: training, validation, and testing, with 60%, 20%, and 20% of the samples, respectively. WSIs were preprocessed by cropping them into 1120 × 1120 patches, without overlap. The proposed model was implemented in Pytorch, trained on a 32GB TESLA V100 GPU, using AdamW <ref type="bibr" target="#b10">[11]</ref> optimizer. The batch size was set to 4, with a learning rate of 1e -4 and a weight decay of 1e -5 .   <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b11">12]</ref>, CNN-MIL <ref type="bibr" target="#b19">[20]</ref>, DSMIL <ref type="bibr" target="#b8">[9]</ref>, CLAM <ref type="bibr" target="#b12">[13]</ref>, ViT-MIL <ref type="bibr" target="#b4">[5]</ref>, TransMIL <ref type="bibr" target="#b15">[16]</ref>, SETMIL <ref type="bibr" target="#b26">[27]</ref>, and DTFD <ref type="bibr" target="#b25">[26]</ref>. All methods were evaluated in three tasks, namely gene mutation prediction (with or without EGFR mutation), TCGA-NSCLC subtype classification, and TCGA-RCC subtype classification. IIB-MIL achieved AUCs of 85.62%, 98.11%, and 99.57%. We can also find IIB-MIL outperformed other SOTA methods, in the three tasks with at least 1.78%, 0.74%, and 0.56% performance enhancement (AUC), respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Ablation Studies</head><p>We conducted ablation studies to assess the efficacy of each component in IIB-MIL. The results, in Table <ref type="table" target="#tab_1">2</ref>, indicate that all of the designed components, including the label disambiguation module, instance-level supervision, and baglevel supervision, contribute to the success of IIB-MIL. We also investigated the impact of the warm-up epoch number and found that selecting an appropriate value, such as warmup = 10, can lead to better model performance. Furthermore, we examined the impact of the weighting factor λ, and the outcomes indicated that assigning greater importance to instance-level supervision (λ = 5) helps IIB-MIL enhance its performance, thus demonstrating the effectiveness of the designed label-disambiguation-based instance-level supervision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Model Interpretation</head><p>Figure <ref type="figure" target="#fig_1">2</ref>(a) shows the t-SNE plot of the obtained patch features from the backbone of the IIB-MIL. The patches are unsupervisedly clustered into groups based on their features, indicated by various colors. The numbers displayed within each group represent the average likelihood of the EGFR mutation predicted by the patches. With the help of the label-disambiguation-based instance-level supervision, IIB-MIL can identify highly positive and negative related patches to the WSI-label, i.e., the cyan-blue group and yellow group. Double-checked by pathologists, we find that the cyan-blue group consists of patches from lung adenocarcinoma and the yellow group consists of patches from the squamous cells. This finding aligns with the domain knowledge of pathologists. Figure <ref type="figure" target="#fig_1">2</ref>(b) investigates the contribution of each patch in predicting EGFR mutation. The resulting heatmap shows the decision mechanism of IIB-MIL in the accurate distinguishment between EGFR mutation-positive and negative samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper presents IIB-MIL, a novel MIL approach for pathological image analysis. IIB-MIL utilizes a label disambiguation module to establish more precise instance-level supervision. It then combines the instance-level and bag-level supervision to enhance the performance of the IIB-MIL. Experimental results demonstrate that IIB-MIL surpasses current SOTA techniques on publicly available datasets, and holds significant potential for addressing more complex clinical applications, such as predicting gene mutations. Furthermore, IIB-MIL can identify highly relevant patches, providing pathologists with valuable insights into underlying mechanisms.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. (a) Overall framework of the IIB-MIL.(b) The detailed diagram of the labeldisambiguation-based instance-level supervision. (Details are given in section: 2.1)</figDesc><graphic coords="3,61,29,258,50,301,75,302,14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. (a)t-SNE plot of the patch features obtained from the backbone;(b) Example heatmaps of IIB-MIL on WSIs with known EFGR mutation labels.</figDesc><graphic coords="8,63,48,54,38,325,96,137,32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>The performance of IIB-MIL compared with other SOTA methods.</figDesc><table><row><cell>Models</cell><cell>LUAD-GM</cell><cell></cell><cell>TCGA-NSCLC</cell><cell></cell><cell>TCGA-RCC</cell><cell></cell></row><row><cell></cell><cell>AUC (%)</cell><cell cols="2">Accuracy AUC (%)</cell><cell cols="2">Accuracy AUC (%)</cell><cell>Accuracy</cell></row><row><cell>ABMIL [7, 12]</cell><cell>52.44</cell><cell>54.55</cell><cell>86.56</cell><cell>77.19</cell><cell>97.02</cell><cell>89.34</cell></row><row><cell>CNN-MIL [20]</cell><cell>45.28</cell><cell>44.92</cell><cell>78.64</cell><cell>69.86</cell><cell>69.56</cell><cell>61.17</cell></row><row><cell>DSMIL [9]</cell><cell>78.53</cell><cell>71.53</cell><cell>89.25</cell><cell>80.58</cell><cell>98.4</cell><cell>92.94</cell></row><row><cell cols="2">CLAM-SB [13] 78.49</cell><cell>70.14</cell><cell>86.37</cell><cell>78.47</cell><cell>90.21</cell><cell>76.60</cell></row><row><cell cols="2">CLAM-MB [13] 82.33</cell><cell>75.70</cell><cell>88.18</cell><cell>81.80</cell><cell>97.23</cell><cell>88.16</cell></row><row><cell>ViT-MIL [5]</cell><cell>76.39</cell><cell>70.14</cell><cell>93.77</cell><cell>84.22</cell><cell>97.99</cell><cell>89.66</cell></row><row><cell>TransMIL [16]</cell><cell>77.29</cell><cell>74.45</cell><cell>96.03</cell><cell>88.35</cell><cell>98.82</cell><cell>94.66</cell></row><row><cell>SETMIL [27]</cell><cell>83.84</cell><cell>76.38</cell><cell>96.01</cell><cell>89.27</cell><cell>99.01</cell><cell>95.20</cell></row><row><cell>DTFD [26]</cell><cell>82.41</cell><cell>76.03</cell><cell>97.37</cell><cell>92.34</cell><cell>99.00</cell><cell>96.90</cell></row><row><cell cols="3">IIB-MIL(Ours) 85.62 (+1.78) 78.77</cell><cell cols="2">98.11(+0.74) 90.91</cell><cell cols="2">99.57 (+0.56) 95.24</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Ablation studies and model analysis of IIB-MIL.</figDesc><table><row><cell>Models</cell><cell>LUAD-GM</cell><cell></cell><cell cols="2">TCGA-NSCLC</cell><cell>TCGA-RCC</cell><cell></cell></row><row><cell></cell><cell>AUC (%)</cell><cell cols="2">Accuracy AUC (%)</cell><cell cols="2">Accuracy AUC (%)</cell><cell>Accuracy</cell></row><row><cell>w/o Instance</cell><cell cols="2">84.01 (-1.61) 76.20</cell><cell cols="2">95.89 (-2.22) 89.50</cell><cell cols="2">98.93 (-0.64) 93.12</cell></row><row><cell cols="3">w/o Label Disambiguation 84.23 (-1.39) 65.07</cell><cell cols="2">96.40 (-1.71) 89.47</cell><cell>98.97 (-0.6)</cell><cell>94.18</cell></row><row><cell>w/o Bag</cell><cell cols="2">84.67 (-0.95) 71.23</cell><cell cols="2">97.65 (-0.46) 91.39</cell><cell cols="2">99.01 (-0.56) 91.53</cell></row><row><cell>IIB-MIL</cell><cell>85.62</cell><cell>78.77</cell><cell>98.11</cell><cell>90.91</cell><cell>99.57</cell><cell>95.24</cell></row><row><cell>warmup = 1</cell><cell>84.81</cell><cell>75.34</cell><cell>96.14</cell><cell>89.47</cell><cell>99.06</cell><cell>92.59</cell></row><row><cell>warmup = 5</cell><cell>85.37</cell><cell>76.71</cell><cell>97.32</cell><cell>91.87</cell><cell>99.25</cell><cell>93.65</cell></row><row><cell>warmup = 10</cell><cell>85.62</cell><cell>78.77</cell><cell>98.11</cell><cell>90.91</cell><cell>99.57</cell><cell>95.24</cell></row><row><cell>warmup = 50</cell><cell>85.36</cell><cell>77.40</cell><cell>97.51</cell><cell>89.95</cell><cell>99.42</cell><cell>93.12</cell></row><row><cell>λ = 0.1</cell><cell>83.50</cell><cell>71.92</cell><cell>97.59</cell><cell>95.69</cell><cell>99.11</cell><cell>92.06</cell></row><row><cell>λ = 1</cell><cell>83.19</cell><cell>71.23</cell><cell>98.05</cell><cell>91.39</cell><cell>99.05</cell><cell>93.12</cell></row><row><cell>λ = 5</cell><cell>85.62</cell><cell>78.77</cell><cell>98.11</cell><cell>90.91</cell><cell>99.57</cell><cell>95.24</cell></row><row><cell>λ = 10</cell><cell>85.60</cell><cell>76.03</cell><cell>96.51</cell><cell>89.47</cell><cell>99.23</cell><cell>89.95</cell></row><row><cell>4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Results and Discussion 4.1 Comparison with State-of-the Art Methods</head><label></label><figDesc></figDesc><table><row><cell>Table 1 presents a performance comparative analysis of IIB-MIL in relation to</cell></row><row><cell>other SOTA methods, including ABMIL</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43987-2 54.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multiple instance classification: review, taxonomy and comparative study</title>
		<author>
			<persName><forename type="first">J</forename><surname>Amores</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. intell</title>
		<imprint>
			<biblScope unit="volume">201</biblScope>
			<biblScope unit="page" from="81" to="105" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Clinical-grade computational pathology using weakly supervised deep learning on whole slide images</title>
		<author>
			<persName><forename type="first">G</forename><surname>Campanella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1301" to="1309" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multiple instance learning with center embeddings for histopathology classification</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chikontwe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Go</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Park</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59722-1_50</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-59722-150" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12265</biblScope>
			<biblScope unit="page" from="519" to="528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Classification and mutation prediction from non-small cell lung cancer histopathology images using deep learning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Coudray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1559" to="1567" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">An image is worth 16×16 words: transformers for image recognition at scale</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.11929</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Patch-based convolutional neural network for whole slide tissue image classification</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Samaras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Kurc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Saltz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2424" to="2433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Attention-based deep multiple instance learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ilse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tomczak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2127" to="2136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Weakly supervised multiple instance learning histopathological tumor segmentation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lerousseau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vakalopoulou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Classe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Battistella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Carré</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Estienne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Deutsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Paragios</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59722-1_45</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-59722-145" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12265</biblScope>
			<biblScope unit="page" from="470" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Dual-stream multiple instance learning network for whole slide image classification with self-supervised contrastive learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Eliceiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="14318" to="14328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Graph CNN for survival analysis on whole slide pathological images</title>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-00934-2_20</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-00934-220" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2018</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Schnabel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Davatzikos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Alberola-López</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Fichtinger</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">11071</biblScope>
			<biblScope unit="page" from="174" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05101</idno>
		<title level="m">Decoupled weight decay regularization</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Ai-based pathology predicts origins for cancers of unknown primary</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">594</biblScope>
			<biblScope unit="page" from="106" to="110" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Data-efficient and weakly supervised computational pathology on whole-slide images</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Barbieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mahmood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="555" to="570" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep learning-based cross-classifications reveal conserved spatial behaviors within tumor histological images</title>
		<author>
			<persName><forename type="first">J</forename><surname>Noorbakhsh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">6367</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Rubin&apos;s Pathology: Clinicopathologic Foundations of Medicine</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Strayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rubin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Lippincott Williams &amp; Wilkins</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Transmil: transformer based correlated multiple instance learning for whole slide image classification</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="2136" to="2147" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Cluster-to-conquer: a framework for end-to-end multi-instance learning for whole slide image classification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ehsan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Moskaluk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Syed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Brown</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="j">Medical Imaging with Deep Learning</title>
		<imprint>
			<biblScope unit="page" from="682" to="698" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep learning for prediction of colorectal cancer outcome: a discovery and validation study</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">J</forename><surname>Skrede</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Lancet</title>
		<imprint>
			<biblScope unit="volume">395</biblScope>
			<biblScope unit="page" from="350" to="360" />
			<date type="published" when="2020">10221. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep neural network models for computational histopathology: a survey</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Srinidhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ciga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page">101813</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Neural image compression for gigapixel histopathology image analysis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tellez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Litjens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Van Der Laak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ciompi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="567" to="578" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.08984</idno>
		<title level="m">Pico: contrastive label disambiguation for partial label learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<title level="m">Revisiting multiple instance neural networks. Pattern Recogn</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="15" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Deep learning-based breast cancer grading and survival analysis on whole-slide histopathology images</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Wetstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">15102</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Camel: a weakly supervised learning framework for histopathology image segmentation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="10682" to="10691" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A regularization term for slide correlation reduction in whole slide image analysis with deep learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Coupland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="j">Medical Imaging with Deep Learning</title>
		<imprint>
			<biblScope unit="page" from="842" to="854" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Dtfd-mil: double-tier feature distillation multiple instance learning for histopathology whole slide image classification</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="18802" to="18812" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Setmil: spatial encoding transformer-based multiple instance learning for pathological image analysis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16434-7_7</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16434-77" />
	</analytic>
	<monogr>
		<title level="m">25th International Conference</title>
		<meeting><address><addrLine>Singapore; Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022-09-22">18-22 September 2022. 2022</date>
			<biblScope unit="volume">2022</biblScope>
			<biblScope unit="page" from="66" to="76" />
		</imprint>
	</monogr>
	<note>Proceedings, Part II</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Predicting lymph node metastasis using histopathological images based on multiple instance learning with deep graph convolution</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4837" to="4846" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
