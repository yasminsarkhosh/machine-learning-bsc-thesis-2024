<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Gradient and Feature Conformity-Steered Medical Image Classification with Noisy Labels</title>
				<funder ref="#_fadXbW2">
					<orgName type="full">National Natural Science Foundation of China 62001410 and Innovation and Technology Commission-Innovation and Technology Fund</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xiaohan</forename><surname>Xing</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Radiation Oncology</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhen</forename><surname>Chen</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Centre for Artificial Intelligence and Robotics (CAIR)</orgName>
								<orgName type="department" key="dep2">Institute of Science &amp; Innovation</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Hong Kong, Hong Kong SAR</settlement>
									<region>NT</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhifan</forename><surname>Gao</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Biomedical Engineering</orgName>
								<orgName type="institution">Sun Yat-sen University</orgName>
								<address>
									<settlement>Guangdong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Yixuan</forename><surname>Yuan</surname></persName>
							<email>yxyuan@ee.cuhk.edu.hk</email>
							<affiliation key="aff3">
								<orgName type="department">Department of Electronic Engineering</orgName>
								<orgName type="institution">Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong SAR</settlement>
									<region>NT</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Gradient and Feature Conformity-Steered Medical Image Classification with Noisy Labels</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="75" to="84"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">D103172CCF334710803F2C92A1AA72A1</idno>
					<idno type="DOI">10.1007/978-3-031-43987-2_8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-24T11:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Label noise</term>
					<term>Gradient conformity</term>
					<term>Feature eigenvector conformity</term>
					<term>Mixup</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Noisy annotations are inevitable in clinical practice due to the requirement of labeling efforts and expert domain knowledge. Therefore, medical image classification with noisy labels is an important topic. A recently advanced paradigm in learning with noisy labels (LNL) first selects clean data with small-loss criterion, then formulates the LNL problem as semi-supervised learning (SSL) task and employs Mixup to augment the dataset. However, the small-loss criterion is vulnerable to noisy labels and the Mixup operation is prone to accumulate errors in pseudo labels. To tackle these issues, we present a two-stage framework with novel criteria for clean data selection and a more advanced Mixup method for SSL. In the clean data selection stage, based on the observation that gradient space reflects optimization dynamics and feature space is more robust to noisy labels, we propose two novel criteria, i.e., Gradient Conformity-based Selection (GCS) and Feature Conformity-based Selection (FCS), to select clean samples. Specifically, the GCS and FCS criteria identify clean data that better aligns with the class-wise optimization dynamics in the gradient space and principal eigenvector in the feature space. In the SSL stage, to effectively augment the dataset while mitigating disturbance of unreliable pseudo-labels, we propose a Sample Reliability-based Mixup (SRMix) method which selects mixup partners based on their spatial reliability, temporal stability, and prediction confidence. Extensive experiments demonstrate that the proposed framework outperforms state-of-the-art methods on two medical datasets with synthetic and real-world label noise. The code is available at https://github. com/hathawayxxh/FGCS-LNL.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Deep neural networks (DNNs) have achieved remarkable success in medical image classification. However, the great success of DNNs relies on a large amount of training data with high-quality annotations, which is practically infeasible. The annotation of medical images requires expert domain knowledge, and suffers from large intra-and inter-observer variability even among experts, thus noisy annotations are inevitable in clinical practice. Due to the strong memorization ability, DNNs can easily over-fit the corrupted labels and degrade performance <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>, thus it is crucial to train DNNs that are robust to noisy labels.</p><p>An effective paradigm in learning with noisy labels (LNL) first selects clean samples, then formulates the LNL problem as semi-supervised learning (SSL) task by regarding the clean samples as a labeled set and noisy samples as an unlabeled set <ref type="bibr" target="#b2">[3]</ref>. However, both the clean data selection and SSL stages in existing methods have some drawbacks. In the clean data selection stage, most existing studies rely on the small-loss <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref> or high-confidence criteria <ref type="bibr" target="#b4">[5]</ref> of individual samples, but neglect the global contextual information and high-order topological correlations among samples, thus unavoidably resulting in confirmation bias <ref type="bibr" target="#b5">[6]</ref>. Besides, the above criteria in the output space are directly supervised and easily affected by corrupted labels <ref type="bibr" target="#b6">[7]</ref>. Previous studies indicate that optimization dynamics (characterized by sample gradients) can reflect the true class information <ref type="bibr" target="#b7">[8]</ref> and feature space is more robust to noisy labels, thus can provide more robust criteria for clean data selection <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b8">9]</ref>. Therefore, we aim to achieve more accurate clean data selection by exploring the topological correlation and contextual information in the robust gradient and feature spaces.</p><p>In the SSL stage, most existing studies <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b9">10]</ref> estimate pseudo labels for all samples and employ Mixup <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref> to linearly interpolate the input samples and their pseudo labels for model training. Compared with previous methods that train DNNs by reweighting samples <ref type="bibr" target="#b12">[13]</ref> or utilizing clean data only <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b13">14]</ref>, the Mixup <ref type="bibr" target="#b11">[12]</ref> operation can effectively augment the dataset and regularize the model from over-fitting. However, as the pseudo labels of noisy datasets cannot be always reliable, the traditional Mixup method which randomly chooses the mixup partner for each sample may accumulate errors in pseudo labels. Therefore, it is highly desirable to design a novel Mixup method that can select reliable mixup partners and mitigate the interference of unreliable pseudo labels.</p><p>In this paper, we present a novel two-stage framework to combat noisy labels in medical image classification. In the clean data selection stage, we propose a gradient and feature conformity-based method to identify the samples with clean labels. Specifically, the Gradient Conformity-based Selection (GCS) criterion selects clean samples that show higher conformity with the principal gradient of its labeled class. The Feature Conformity-based Selection (FCS) criterion identifies clean samples that show better alignment with the feature eigenvector of its labeled class. In the SSL stage, we propose a Sample Reliability-based Mixup (SRMix) to augment the training data without aggravating the error accumulation of pseudo labels. Specifically, SRMix interpolates each sample with reliable mixup partners which are selected based on their spatial reliability, temporal stability, and prediction confidence. Our main contributions are as follows: -We devise two novel criteria (i.e., GCS and FCS) to improve clean data selection by exploring the topological correlation and contextual information in the gradient and feature spaces. -We propose a novel SRMix method that selects reliable mixup partners to mitigate the error accumulation of pseudo labels and improve model training.</p><p>-Extensive experiments show that our proposed framework is effective in combating label noise and outperforms state-of-the-art methods on two medical datasets with both synthetic and real-world label noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>An overview of our proposed two-stage framework is shown in Fig. <ref type="figure" target="#fig_0">1</ref>. The training dataset is denoted as</p><formula xml:id="formula_0">D train ∈ {(x i , y i )} N i=1</formula><p>, where the given label y i could be noisy or clean. In the clean data selection stage, we propose a gradient and feature conformity-based method to distinguish clean samples from the noisy dataset. As shown in Fig. <ref type="figure" target="#fig_0">1</ref> (a), the GCS computes the principal gradient of each class (i.e., g 1 , g 2 , g 3 ) to represent its optimization dynamics, and measures the label quality of each sample by its gradient conformity with the class-wise principal gradient. The FCS computes the principal feature eigenvector of each class to reflect its contextual information, and measures the label quality of each sample by its feature conformity with the class-wise feature eigenvector. Based on the integration of these two criteria, the training data is divided into a noisy set D noisy and a clean set D clean . In the SSL stage (see Fig. <ref type="figure" target="#fig_0">1 (b</ref>)), our SRMix module interpolates each sample (x i , y i ) with a reliable mixup partner (x j , y j ), which is selected based on its spatial reliability, temporal stability, and prediction confidence. The mixed samples are used for model training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Gradient and Feature Conformity-Based Clean Data Selection</head><p>Inspired by previous studies that optimization dynamics in the gradient space reflects the true class information <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b14">15]</ref> and contextual information in the feature space is more robust to noisy labels <ref type="bibr" target="#b6">[7]</ref>, we devise the novel GCS and FCS criteria to measure label quality in the gradient and feature spaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gradient Conformity-Based Selection (GCS).</head><p>The GCS aims to distinguish clean samples from noisy ones by exploring their optimization dynamics in the gradient space. Since training samples from the same class usually exhibit similar optimization dynamics <ref type="bibr" target="#b14">[15]</ref>, the gradient of a sample should be similar to the principal gradient of its true class, thus we use the gradient conformity as a criterion to evaluate the quality of its given label. Specifically, for each sample x i , its gradient g(x i ) is computed as:</p><formula xml:id="formula_1">g(x i ) = ∂(-logp (x i )) ∂f (x i ) , p (x i ) = max xj p(x j ), ∀x j ∈ KN N {x i },<label>(1)</label></formula><p>where f (x i ) is the feature vector of the sample x i , and x j denotes the K-Nearest Neighbors (KNN) of x i . p (x i ) is the probability of the most likely true class predicted by its KNN neighbors. Therefore, the gradient g(x i ) is very likely to reflect the true class information and optimization dynamics of x i . For each class, we select α% samples with the smallest loss as an anchor set A c , which is depicted in the shaded areas of the GCS in Fig. <ref type="figure" target="#fig_0">1</ref> (a). Then, the principal gradient of the c-th class is computed as:</p><formula xml:id="formula_2">g c = 1 N c • α% xi g(x i ), x i ∈ A c ,<label>(2)</label></formula><p>which is the average gradient of all samples in the anchor set A c of the c-th class. Then, we can measure the similarity between the gradient of the sample x i and the principal gradient of class y i with the cosine similarity s g (x i ) = cos &lt; g(x i ), g yi &gt;. For the sample x i , if y i is a noisy label, g(x i ) should be consistent with the principal gradient of its true class and diverge from g yi , thus yielding small s g (x i ). By fitting Gaussian mixture models (GMM) on the similarity score s g (x i ), we can get c g (x i ) = GM M (s g (x i )), which represents the clean probability of the sample x i decided by the GCS criterion. To the best of our knowledge, this is the first work that explores gradient conformity for clean data selection.</p><p>Feature Conformity-Based Selection (FCS). Since feature space is more robust to noisy labels than the output space <ref type="bibr" target="#b6">[7]</ref>, our FCS criterion explores high-order topological information in the feature space and utilizes the feature conformity with class-wise principal eigenvectors as a criterion to select clean samples. Specifically, for each class, we compute the gram matrix as:</p><formula xml:id="formula_3">M c = xi f (x i ) • f (x i ) T , x i ∈ A c ,<label>(3)</label></formula><p>where f (x i ) denotes the feature vector of the sample x i in the anchor set A c of the c-th class. Then, we perform eigen-decomposition on the gram matrix:</p><formula xml:id="formula_4">M c = U c • Σ c • U T c</formula><p>, where U c is the eigenvector matrix and Σ c is a diagonal matrix composed of eigenvalues. The principal eigenvector u c of U c is utilized to represent the distribution and contextual information of the c-th class. Then, for each sample x i , we measure its label quality based on the conformity of its feature f (x i ) with the principal eigenvector u yi of its given label: s f (x i ) = cos &lt; f (x i ), u yi &gt;. Samples that better align with the principal eigenvectors of their labeled class are more likely to be clean. According to the FCS criterion, the clean probability of the sample x i is obtained by</p><formula xml:id="formula_5">c f (x i ) = GM M (s f (x i )).</formula><p>Compared with existing methods that utilize classwise average features to represent contextual information <ref type="bibr" target="#b6">[7]</ref>, the eigenvectors in our method can better explore the high-order topological information among samples and are less affected by noisy features.</p><p>Integration of GCS and FCS. Finally, we average the clean probabilities estimated by the GCS and FCS criteria to identify clean data. As shown in Fig. <ref type="figure" target="#fig_0">1 (a)</ref>, for a dataset with the noise rate of r%, we divide all samples into a clean set D clean (i.e., (1 -r%) samples with higher clean probabilities) and a noisy set D noisy (i.e., r% samples with lower clean probabilities).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Sample Reliability-Based Mixup (SRMix)</head><p>By regarding D clean as a labeled set and D noisy as an unlabeled set, we can formulate the LNL task into an SSL problem and employ Mixup <ref type="bibr" target="#b11">[12]</ref> to generate mixed samples for model training <ref type="bibr" target="#b2">[3]</ref>. In the traditional Mixup <ref type="bibr" target="#b11">[12]</ref>, each sample (x i , y i ) is linearly interpolated with another sample (x j , y j ) randomly chosen from the mini-batch. However, the pseudo labels of noisy datasets cannot be always reliable and the Mixup operation will aggravate the error accumulation of pseudo labels. To mitigate the error accumulation of pseudo labels, we propose a Sample Reliability-based Mixup (SRMix) method, which selects mixup partners based on their spatial reliability, temporal stability, and prediction confidence.</p><p>Intuitively, samples with reliable pseudo labels should have consistent predictions with their neighboring samples, stable predictions along sequential training epochs, and high prediction confidence. As shown in Fig. <ref type="figure" target="#fig_0">1</ref> (b), we select reliable mixup partners for each sample based on the triple criteria. First, for each sample x j , we define the spatial reliability as:</p><formula xml:id="formula_6">R spatial (x j ) = 1-Normalize(||p(x j )- 1 K x k p(x k )|| 2 2 ), ∀x k ∈ KN N {x j } (4)</formula><p>where p(x j ) and p(x k ) are the pseudo labels of sample x j and its neighbor x k . Normalize() denotes the min-max normalization over all samples in each batch. If the pseudo label of a sample is more consistent with its neighbors, a higher R spatial (x j ) will be assigned, and vice versa. Second, for each sample x j , we keep the historical sequence of its predictions in the past T epochs, e.g., the prediction sequence at the t-th epoch is defined as P t (x j ) = [p t-T +1 (x j ), ..., p t-1 (x j ), p t (x j )]. The temporal stability of x j can be defined as:</p><formula xml:id="formula_7">R temporal (x j ) = 1 -Normalize 1 T T -1 n=0 (p t-n (x j ) -p(x j )) 2 , (<label>5</label></formula><formula xml:id="formula_8">)</formula><p>where p(x j ) is the average prediction of the historical sequence. According to Eq. ( <ref type="formula" target="#formula_7">5</ref>), a sample with smaller variance or fluctuation over time will be assigned with a larger R temporal (x j ), and vice versa. Finally, the overall sample reliability is defined as: R(</p><formula xml:id="formula_9">x j ) = R spatial (x j ) • R temporal (x j ) • max(p(x j ))</formula><p>, where max(p(x j )) denotes the prediction confidence of the pseudo label of the sample x j . The possibility of x j being chosen as a mixup partner is set as</p><formula xml:id="formula_10">p m (x j ) = R(x j ), R(x j ) ≥ τ R 0, else,<label>(6)</label></formula><p>where τ R is a predefined threshold to filter out unreliable mixup partners. For each sample x i , we select a mixup partner x j with the probability p m (x j ) defined in Eq. ( <ref type="formula" target="#formula_10">6</ref>), and linearly interpolate their inputs and pseudo labels to generate a mixed sample (x, y). The mixed sample is fed into the network and trained with cross-entropy loss L CE (x, y). Considering the estimation of sample reliability might be inaccurate in the initial training stage, we employ the traditional Mixup in the first 5 epochs and utilize our proposed SRMix for the rest training epochs.</p><p>Compared with the traditional Mixup, the SRMix can effectively mitigate error accumulation of the pseudo labels and promote model training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets and Implementation Details</head><p>WCE Dataset with Synthetic Label Noise. The Wireless Capsule Endoscopy (WCE) dataset <ref type="bibr" target="#b15">[16]</ref> contains 1,812 images, including 600 normal images, 605 vascular lesions, and 607 inflammatory frames. We perform 5-fold cross-validation to evaluate our method. Following the common practice in the LNL community <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b9">10]</ref>, we employ symmetric and pairflip label noise with diverse settings on the training set to simulate errors in the annotation process.</p><p>The symmetric noise rate is set as 20%, 40%, 50%, and the pairflip noise rate is set as 40%. The model performance is measured by the average Accuracy (ACC) and Area Under the Curve (AUC) on the 5-fold test data.</p><p>Histopathology Dataset with Real-World Label Noise. The histopathology image dataset is collected from Chaoyang Hospital <ref type="bibr" target="#b9">[10]</ref> and is annotated by 3 professional pathologists. There are 1,816 normal, 1,163 serrated, 2,244 adenocarcinoma, and 937 adenoma samples of colon slides in total. The samples with the consensus of 3 pathologists are selected as the test set, including 705 normal, 321 serrated, 840 adenocarcinoma, and 273 adenoma samples. The rest samples are utilized to construct the training set, with randomly selected opinions from one of the three doctors used as the noisy labels. The model performance is measured by the average Accuracy (ACC), F1 Score (F1), Precision, and Recall on 3 independent runs. Implementation Details. Our method follows the baseline framework of DivideMix <ref type="bibr" target="#b2">[3]</ref> and adopts the pre-trained ResNet-50 <ref type="bibr" target="#b16">[17]</ref> for feature extraction. We implement our method and all comparison methods on NVIDIA RTX 2080ti GPU using PyTorch <ref type="bibr" target="#b17">[18]</ref>. For the WCE dataset, our method is trained for 40 epochs with an initial learning rate set to 0.0001 and divided by 10 after 20 epochs. For the histopathology dataset, the network is trained for 20 epochs with the learning rate set to 0.0001. For both datasets, the network is trained by Adam optimizer with β 1 = 0.9 and β 2 = 0.999, and batch size of 16. The number of neighbors K is set as 10 in Eq. ( <ref type="formula" target="#formula_1">1</ref>) and Eq. ( <ref type="formula">4</ref>). Length T of the historical sequence is set as 3. The reliability threshold τ R is set as 0.2 for the WCE dataset and 0.05 for the histopathology dataset. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experimental Results</head><p>Comparison with State-of-the-Art Methods. We first evaluate our method on the WCE dataset under diverse synthetic noise settings and show the results in Table <ref type="table" target="#tab_0">1</ref>. We compare with three well-known LNL methods (i.e., Co-teaching <ref type="bibr" target="#b3">[4]</ref>, Coteaching+ <ref type="bibr" target="#b13">[14]</ref>, and DivideMix <ref type="bibr" target="#b2">[3]</ref>) and three state-of-the-art LNL methods (i.e., EHN-NSHE <ref type="bibr" target="#b9">[10]</ref>, SFT <ref type="bibr" target="#b18">[19]</ref>, and TSCSI <ref type="bibr" target="#b6">[7]</ref>). As shown in Table <ref type="table" target="#tab_0">1</ref>, our method outperforms existing methods under all noise settings, and the performance gain is more significant under severe noise settings (e.g., noise rate ≥ 40%). Under the four settings, our method outperforms the second-best model by 0.67%, 2.65%, 4.19%, and 4.08% in accuracy. These results indicate the effectiveness of our method.</p><p>We then evaluate our method on the histopathology dataset with real-world label noise. As shown in Table <ref type="table" target="#tab_1">2</ref>, our method outperforms existing state-of-theart methods, indicating the capability of our method in dealing with complex real-world label noise.</p><p>Ablation Study. To quantitatively analyze the contribution of the proposed components (i.e., GCS, FCS, and SRMix) in combating label noise, we perform an ablation study on the WCE dataset under 40% symmetric and pairflip noise. As shown in Table <ref type="table" target="#tab_2">3</ref>, compared with the DivideMix baseline (line 1) <ref type="bibr" target="#b2">[3]</ref>, replacing the small-loss criterion by GCS or FCS both improve the model performance significantly (lines 2-3), and their combination leads to further performance gains (line 5). Furthermore, better performance can be achieved by replacing the traditional Mixup with our proposed SRMix method (line 1 vs. line 4, line 5 vs. line 6). These results indicate that filtering out unreliable mixup partners can effectively improve the model's capacity in combating label noise.</p><p>More comprehensive analysis of the GCS and FCS criteria is provided in the supplementary material. Figure <ref type="figure" target="#fig_0">S1</ref> demonstrates that compared with the normalized loss <ref type="bibr" target="#b2">[3]</ref>, the GCS and FCS criteria are more distinguishable between the clean and noisy data. This is consistent with the improvement of clean data selection accuracy in Fig. <ref type="figure">S2</ref>. As shown in Fig. <ref type="figure">S3</ref>, both the feature and gradient of each sample are aligned with the center of its true class, further validating the rationality of using gradient and feature conformity for clean data selection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we present a two-stage framework to combat label noise in medical image classification tasks. In the first stage, we propose two novel criteria (i.e., GCS and FCS) that select clean data based on their conformity with the class-wise principal gradients and feature eigenvectors. By exploring contextual information and high-order topological correlations in the gradient space and feature space, our GCS and FCS criteria enable more accurate clean data selection and benefit LNL tasks. In the second stage, to mitigate the error accumulation of pseudo labels, we propose an SRMix method that interpolates input samples with reliable mixup partners which are selected based on their spatial reliability, temporal stability, and prediction confidence. Extensive experiments on two datasets with both diverse synthetic and real-world label noise indicate the effectiveness of our method.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The framework of our method. (a) Gradient and feature conformity-based clean data selection module, including GCS and FCS criteria, divides training samples into a clean set D clean and a noisy set Dnoisy. (b) Sample Reliability-based Mixup (SRMix) module interpolates each sample (xi, yi) with a reliable mixup partner (xj, yj).</figDesc><graphic coords="3,58,98,54,59,334,63,207,13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Comparison with state-of-the-art LNL methods on the WCE dataset under diverse noise settings. Best and second-best results are highlighted and underlined.</figDesc><table><row><cell>Method</cell><cell>20% Sym.</cell><cell></cell><cell>40% Sym.</cell></row><row><cell></cell><cell cols="2">Accuracy (%) AUC (%)</cell><cell cols="2">Accuracy (%) AUC (%)</cell></row><row><cell>CE (Standard)</cell><cell>86.98 ± 1.32</cell><cell cols="2">96.36 ± 0.77 65.84 ± 1.31</cell><cell>83.03 ± 0.98</cell></row><row><cell cols="2">Co-teaching (NeurIPS 2018) [4] 91.97 ± 1.48</cell><cell cols="2">98.45 ± 0.48 84.27 ± 2.51</cell><cell>94.72 ± 0.93</cell></row><row><cell cols="2">Coteaching+ (ICML2019) [14] 91.86 ± 0.47</cell><cell cols="2">98.16 ± 0.26 73.92 ± 1.37</cell><cell>88.00 ± 0.89</cell></row><row><cell>DivideMix (ICLR 2020) [3]</cell><cell>93.98 ± 2.27</cell><cell cols="2">98.52 ± 0.73 89.79 ± 1.57</cell><cell>96.79 ± 0.92</cell></row><row><cell>EHN-NSHE (TMI 2022) [10]</cell><cell>92.71 ± 0.87</cell><cell cols="2">98.56 ± 0.35 82.40 ± 2.12</cell><cell>94.22 ± 1.17</cell></row><row><cell>SFT (ECCV 2022) [19]</cell><cell>93.32 ± 1.09</cell><cell cols="2">98.66 ± 0.50 84.33 ± 4.64</cell><cell>94.59 ± 1.61</cell></row><row><cell>TSCSI (ECCV 2022) [7]</cell><cell>90.07 ± 2.21</cell><cell cols="2">97.63 ± 1.02 85.65 ± 4.94</cell><cell>95.61 ± 2.18</cell></row><row><cell>Our method</cell><cell cols="4">94.65 ± 2.08 98.56 ± 0.69 92.44 ± 2.38 97.70 ± 0.76</cell></row><row><cell>Method</cell><cell>50% Sym.</cell><cell></cell><cell>40% Pairflip</cell></row><row><cell></cell><cell cols="2">Accuracy (%) AUC (%)</cell><cell cols="2">Accuracy (%) AUC (%)</cell></row><row><cell>CE (Standard)</cell><cell>52.59 ± 0.76</cell><cell cols="2">70.36 ± 0.44 62.36 ± 2.84</cell><cell>81.05 ± 1.49</cell></row><row><cell cols="2">Co-teaching (NeurIPS 2018) [4] 77.51 ± 2.23</cell><cell cols="2">92.14 ± 1.25 82.01 ± 1.40</cell><cell>93.99 ± 0.71</cell></row><row><cell cols="2">Coteaching+ (ICML2019) [14] 58.00 ± 1.33</cell><cell cols="2">75.23 ± 1.24 61.26 ± 1.54</cell><cell>79.12 ± 0.99</cell></row><row><cell>DivideMix (ICLR 2020) [3]</cell><cell>82.40 ± 1.93</cell><cell cols="2">92.67 ± 1.05 88.30 ± 3.33</cell><cell>96.28 ± 1.60</cell></row><row><cell>EHN-NSHE (TMI 2022) [10]</cell><cell>70.14 ± 3.41</cell><cell cols="2">85.01 ± 2.70 80.74 ± 4.84</cell><cell>92.15 ± 2.63</cell></row><row><cell>SFT (ECCV 2022) [19]</cell><cell>66.94 ± 2.54</cell><cell cols="2">83.55 ± 1.94 80.52 ± 6.55</cell><cell>90.65 ± 4.32</cell></row><row><cell>TSCSI (ECCV 2022) [7]</cell><cell>76.50 ± 5.04</cell><cell cols="2">79.75 ± 6.49 75.28 ± 2.29</cell><cell>96.37 ± 3.03</cell></row><row><cell>Our method</cell><cell cols="4">86.59 ± 2.26 95.25 ± 1.38 92.38 ± 2.74 97.80 ± 1.03</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Comparison with state-of-the-art methods on the histopathology dataset with real-world label noise. Best and second-best results are highlighted and underlined.</figDesc><table><row><cell>Method</cell><cell>ACC (%)</cell><cell>F1 (%)</cell><cell>Precision (%) Recall (%)</cell></row><row><cell>CE (Standard)</cell><cell cols="3">80.36 ± 1.29 73.00 ± 0.84 76.47 ± 3.32 72.13 ± 0.29</cell></row><row><cell cols="4">Co-teaching (NeurIPS 2018) [4] 80.57 ± 0.55 72.39 ± 1.05 76.58 ± 1.40 71.33 ± 1.76</cell></row><row><cell cols="4">Coteaching+ (ICML2019) [14] 82.15 ± 0.34 74.63 ± 0.30 77.04 ± 0.56 73.94 ± 0.37</cell></row><row><cell>DivideMix (ICLR 2020) [3]</cell><cell cols="3">82.89 ± 0.80 77.36 ± 1.08 78.31 ± 1.74 76.77 ± 0.76</cell></row><row><cell>EHN-NSHE (TMI 2022) [10]</cell><cell cols="3">83.06 ± 0.28 76.68 ± 0.39 78.53 ± 0.41 75.00 ± 0.42</cell></row><row><cell>SFT (ECCV 2022) [19]</cell><cell cols="3">82.68 ± 0.97 76.65 ± 0.89 78.53 ± 1.45 75.64 ± 0.73</cell></row><row><cell>TSCSI (ECCV 2022) [7]</cell><cell cols="3">82.03 ± 2.12 75.54 ± 2.05 78.51 ± 3.60 74.57 ± 1.78</cell></row><row><cell>Our method</cell><cell cols="3">84.29 ± 0.70 78.98 ± 0.81 80.34 ± 0.85 78.19 ± 0.99</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Ablation study on the WCE dataset under 40% symmetric and pairflip noises.</figDesc><table><row><cell></cell><cell>GCS FCS SRMix 40% Sym.</cell><cell></cell><cell>40% Pairflip</cell></row><row><cell></cell><cell>ACC (%)</cell><cell>AUC (%)</cell><cell>ACC (%)</cell><cell>AUC (%)</cell></row><row><cell>1</cell><cell cols="4">89.79 ± 1.57 96.79 ± 0.92 88.30 ± 3.33 96.28 ± 1.60</cell></row><row><cell>2</cell><cell cols="4">91.17 ± 1.36 97.43 ± 0.78 91.12 ± 2.99 97.36 ± 1.13</cell></row><row><cell>3</cell><cell cols="4">90.56 ± 2.03 96.89 ± 1.03 91.01 ± 2.23 97.22 ± 1.06</cell></row><row><cell>4</cell><cell cols="4">90.84 ± 1.66 96.74 ± 1.25 89.40 ± 2.70 96.27 ± 1.63</cell></row><row><cell>5</cell><cell cols="4">92.11 ± 2.31 97.44 ± 0.92 91.72 ± 3.01 97.60 ± 1.06</cell></row><row><cell>6</cell><cell cols="4">92.44 ± 2.38 97.70 ± 0.76 92.38 ± 2.74 97.80 ± 1.03</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This work was supported by <rs type="funder">National Natural Science Foundation of China 62001410 and Innovation and Technology Commission-Innovation and Technology Fund</rs> <rs type="grantNumber">ITS/100/20</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_fadXbW2">
					<idno type="grant-number">ITS/100/20</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43987-2_8.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Understanding deep learning (still) requires rethinking generalization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="107" to="115" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Early-learning regularization prevents memorization of noisy labels</title>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Niles-Weed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Razavian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fernandez-Granda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="20331" to="20342" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.07394</idno>
		<title level="m">DivideMix: learning with noisy labels as semisupervised learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Co-teaching: robust training of deep neural networks with extremely noisy labels</title>
		<author>
			<persName><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Me-momentum: extracting hard confident examples from noisily labeled data</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="9312" to="9321" />
		</imprint>
		<respStmt>
			<orgName>ICCV</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Neighborhood collective estimation for noisy label identification and correction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.03207</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Centrality and consistency: two-stage clean samples identification for learning with instance-dependent noisy labels</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-19806-9_2</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-19806-9_2" />
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2022</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Avidan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Brostow</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Cissé</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Farinella</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Hassner</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13685</biblScope>
			<biblScope unit="page" from="21" to="37" />
		</imprint>
	</monogr>
	<note>ECCV 2022</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Towards discovering the effectiveness of moderately confident samples for semi-supervised learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="14658" to="14667" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Learning with neighbor consistency for noisy labels</title>
		<author>
			<persName><forename type="first">A</forename><surname>Iscen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Valmadre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Arnab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="4672" to="4681" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Hard sample aware noise robust learning for histopathology image classification</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="881" to="894" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">MixMatch: a holistic approach to semi-supervised learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.09412</idno>
		<title level="m">mixup: beyond empirical risk minimization</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">MentorNet: learning datadriven curriculum for very deep neural networks on corrupted labels</title>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<idno>PMLR</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2304" to="2313" />
		</imprint>
		<respStmt>
			<orgName>ICML</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">How does disagreement help generalization against label corruption?</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<idno>PMLR</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="7164" to="7173" />
		</imprint>
		<respStmt>
			<orgName>ICML</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A closer look at memorization in deep networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Arpit</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="233" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Cad-cap: UNE base de données française à vocation internationale, pour le développement et la validation d&apos;outils de diagnostic assisté par ordinateur en vidéocapsule endoscopique du grêle</title>
		<author>
			<persName><forename type="first">X</forename><surname>Dray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Endoscopy</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">03</biblScope>
			<biblScope unit="page">441</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">PyTorch: an imperative style, high-performance deep learning library</title>
		<author>
			<persName><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Self-filtering: a noise-aware sample selection for label noise with confidence penalization</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.11351</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
