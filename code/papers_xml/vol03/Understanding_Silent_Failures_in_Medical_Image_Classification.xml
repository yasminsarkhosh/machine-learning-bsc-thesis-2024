<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Understanding Silent Failures in Medical Image Classification</title>
				<funder>
					<orgName type="full">Helmholtz Imaging</orgName>
					<orgName type="abbreviated">HI</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Till</forename><forename type="middle">J</forename><surname>Bungert</surname></persName>
							<email>till.bungert@dkfz-heidelberg.de</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Interactive Machine Learning Group</orgName>
								<orgName type="department" key="dep2">German Cancer Research Center (DKFZ)</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">DKFZ</orgName>
								<address>
									<addrLine>Helmholtz Imaging</addrLine>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Levin</forename><surname>Kobelke</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Interactive Machine Learning Group</orgName>
								<orgName type="department" key="dep2">German Cancer Research Center (DKFZ)</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">DKFZ</orgName>
								<address>
									<addrLine>Helmholtz Imaging</addrLine>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Paul</forename><forename type="middle">F</forename><surname>JÃ¤ger</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Interactive Machine Learning Group</orgName>
								<orgName type="department" key="dep2">German Cancer Research Center (DKFZ)</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">DKFZ</orgName>
								<address>
									<addrLine>Helmholtz Imaging</addrLine>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Understanding Silent Failures in Medical Image Classification</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="400" to="410"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">AEA44363497DBC120F0300C68F867436</idno>
					<idno type="DOI">10.1007/978-3-031-43898-1_39</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-24T10:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Failure detection</term>
					<term>Distribution shifts</term>
					<term>Benchmark</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>To ensure the reliable use of classification systems in medical applications, it is crucial to prevent silent failures. This can be achieved by either designing classifiers that are robust enough to avoid failures in the first place, or by detecting remaining failures using confidence scoring functions (CSFs). A predominant source of failures in image classification is distribution shifts between training data and deployment data. To understand the current state of silent failure prevention in medical imaging, we conduct the first comprehensive analysis comparing various CSFs in four biomedical tasks and a diverse range of distribution shifts. Based on the result that none of the benchmarked CSFs can reliably prevent silent failures, we conclude that a deeper understanding of the root causes of failures in the data is required. To facilitate this, we introduce SF-Visuals, an interactive analysis tool that uses latent space clustering to visualize shifts and failures. On the basis of various examples, we demonstrate how this tool can help researchers gain insight into the requirements for safe application of classification systems in the medical domain. The open-source benchmark and tool are at: https://github. com/IML-DKFZ/sf-visuals.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Although machine learning-based classification systems have achieved significant breakthroughs in various research and practical areas, their clinical application is still lacking. A primary reason is the lack of reliability, i.e. failure cases produced by the system, which predominantly occur when deployment data differs from the data it was trained on, a phenomenon known as distribution shifts. In medical applications, these shifts can be caused by image corruption ("corruption shift"), unseen variants of pathologies ("manifestation shift"), or deployment in new clinical sites with different scanners and protocols ("acquisition shift") <ref type="bibr" target="#b3">[4]</ref>. The robustness of a classifier, i.e. its ability to generalize across these shifts, is extensively studied in the computer vision community with a variety of recent benchmarks covering nuanced realistic distribution shifts <ref type="bibr" target="#b11">[13,</ref><ref type="bibr" target="#b13">15,</ref><ref type="bibr" target="#b17">19,</ref><ref type="bibr" target="#b25">27]</ref>, and is also studied in isolated cases in the biomedical community <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b31">33]</ref>. Despite these efforts, perfect classifiers are not to be expected, thus a second mitigation strategy is to detect and defer the remaining failures, thus preventing failures to be silent. This is done by means of confidence scoring functions (CSF) of different types as studied in the fields of misclassification detection (MisD) <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b21">23]</ref>, Out-of-Distribution detection (OoD-D) <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b18">20,</ref><ref type="bibr" target="#b19">21,</ref><ref type="bibr" target="#b30">32]</ref>, selective classification (SC) <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b20">22]</ref>, and predictive uncertainty quantification (PUQ) <ref type="bibr" target="#b16">[18,</ref><ref type="bibr" target="#b23">25]</ref>.</p><p>We argue, that silent failures, which occur when test cases break both the classifier and the CSF, are a significant bottleneck in the clinical translation of ML systems and require further attention in the medical community.</p><p>Note that the task of silent failure prevention is orthogonal to calibration, as, for example, a perfectly calibrated classifier can still yield substantial amounts of silent failures and vice versa <ref type="bibr" target="#b13">[15]</ref>.</p><p>Bernhardt et al. <ref type="bibr" target="#b2">[3]</ref> studied failure detection on several biomedical datasets, but only assessed the performance of CSFs in isolation without considering the classifier's ability to prevent failures. Moreover, their study did not include distribution shifts thus lacking a wide range of realistic failure sources. Jaeger et al. <ref type="bibr" target="#b13">[15]</ref>, on the other hand, recently discussed various shortcomings in current research on silent failures including the common lack of distribution shifts and the lack of assessing the classifier and CSF as a joint system. However, their study did not cover tasks from the biomedical domain.</p><p>In this work, our contribution is twofold: 1) Building on the work of Jaeger et al. <ref type="bibr" target="#b13">[15]</ref>, we present the first comprehensive study of silent failure prevention in the biomedical field. We compare various CSFs under a wide range of distribution shifts on four biomedical datasets. Our study provides valuable insights and the underlying framework is made openly available to catalyze future research in the community. 2) Since the benchmark reveals that none of the predominant CSFs can reliably prevent silent failures in biomedical tasks, we argue that a deeper understanding of the root causes in the data itself is required. To this end, we present SF-Visuals, a visualization tool that facilitates identifying silent failures in a dataset and investigating their causes (see Fig. <ref type="figure" target="#fig_0">1</ref>). Our approach contributes to recent research on visual analysis of failures <ref type="bibr" target="#b11">[13]</ref>, which has not focused on silent failures and distribution shifts before.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>Benchmark for Silent Failure Prevention under Distribution Shifts. We follow the spirit of recent robustness benchmarks, where existing datasets have been enhanced by various distribution shifts to evaluate methods under a wide range of failure sources and thus simulate real-world application <ref type="bibr" target="#b17">[19,</ref><ref type="bibr" target="#b25">27]</ref>. To our knowledge, no such comprehensive benchmark currently exists in the biomedical domain. Specifically, we introduce corruptions of various intensity levels to the images in four datasets in the form of brightness, motion blur, elastic transformations and Gaussian noise. We further simulate acquisition shifts and manifestation shifts by splitting the data into "source domain" (development data) and "target domain" (deployment data) according to sub-class information from the meta-data such as lesion subtypes or clinical sites. Dermoscopy dataset: We combine data from ISIC 2020 <ref type="bibr" target="#b24">[26]</ref>, derma 7 point <ref type="bibr" target="#b15">[17]</ref>, PH2 <ref type="bibr" target="#b22">[24]</ref> and HAM10000 <ref type="bibr" target="#b28">[30]</ref> and map all lesion sub-types to the super-classes "benign" or "malignant". We emulate two acquisition shifts by defining either images from the Memorial Sloan Kettering Cancer Center (MSKCC) or Hospital Clinic Barcelona (HCB) as the target domain and the remaining images as the source domain. Further, a manifestation shift is designed by defining the lesion subtypes "keratosis-like" (benign) and "actinic keratosis" (malignant) as the target domain. Chest X-ray dataset: We pool the data from CheXpert <ref type="bibr" target="#b12">[14]</ref>, NIH14 <ref type="bibr" target="#b29">[31]</ref> and MIMIC <ref type="bibr" target="#b14">[16]</ref>, while only retaining the classes common to all three. Next, we emulate two acquisition shifts by defining either the NIH14 or the CheXpert data as the target domain. FC-Microscopy dataset: The RxRx1 dataset <ref type="bibr" target="#b26">[28]</ref> represents the fluorescence cell microscopy domain. Since the images were acquired in 51 deviating acquisition steps, we define 10 of these batches as target-domain to emulate an acquisition shift. Lung Nodule CT dataset: We create a simple 2D binary nodule classification task based on the 3D LIDC-IDRI data <ref type="bibr" target="#b0">[1]</ref> by selecting the slice with the largest annotation per nodule (Â±two slices resulting in 5 slices per nodule). Average malignancy ratings (four raters per nodule, scores between 1 and 5) &gt; 2 are considered malignant and all others as benign. We emulate two manifestation shifts by defining nodules with high spiculation (rating &gt; 2), and low texture (rating &lt; 3) as target domains.</p><p>The datasets consist only of publicly available data, our benchmark provides scripts to automatically generate the combined datasets and distribution shifts.</p><p>The SF-Visuals Tool: Visualizing Silent Failures. The proposed tool is based on three simple operations, that enable effective and intuitive analysis of silent failures in datasets across various CSFs: 1) Interactive Scatter Plots: See example in Fig. <ref type="figure" target="#fig_0">1b</ref>. We first reduce the dimensionality of the classifier's latent space to 50 using principal component analysis and use t-SNE to obtain the final 3-dimensional embedding. Interactive functionality includes coloring dots via pre-defined schemes such as classes, distribution shifts, classifier confusion matrix, or CSF confusion matrix. The associated images are displayed upon selection of a dot to establish a direct visual link between input space and embedding. 2) Concept Cluster Plots: See examples in Fig. <ref type="figure" target="#fig_0">1c</ref>. To abstract away from individual points in the scatter plot, concepts of interest, such as classes or distribution shifts can be defined and visualized to identify conceptual commonalities and differences in the data as perceived by the model. Therefore, k-means clustering is applied to the 3-dimensional embedding. Nine clusters are identified per concept and the resulting plots show the closest-to-center image per cluster as a visual representation of the concept. 3) Silent Failure Visualization: See examples in Fig. <ref type="figure" target="#fig_1">2</ref>. We sort all failures by the classifier confidence and by default show the images associated with the top-two most confident failures. For corruption shifts, we further allow investigating the predictions on a fixed input image over varying intensity levels.</p><p>Based on these visualizations, the functionality of SF-Visuals is three-fold: 1) Visual analysis of the dataset including distribution shifts. 2) Visual analysis of the general behavior of various CSFs on a given task 3) Visual analysis of individual silent failures in the dataset for various CSFs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Setup</head><p>Evaluating Silent Failure Prevention: We follow Jaeger et al. <ref type="bibr" target="#b13">[15]</ref> in evaluating silent failure prevention as a joint task of the classifier and the CSF. The area under the risk-coverage curve AURC reflects this task, since it considers both the classifier's accuracy as well as the CSF's ability to detect failures by assigning low confidence scores. Thus, it can be interpreted as a silent failure rate or the error rate averaged over steps of filtering cases one by one according to their rank of confidence score (low to high). Exemplary risk-coverage curves are shown in Appendix Fig. <ref type="figure">3</ref>. Compared Confidence Scoring Functions: We compare the following CSFs: The maximum softmax response (MSR) and the predictive entropy computed from the classifier's softmax output, three predictive uncertainty measures based on Monte-Carlo Dropout (MCD) <ref type="bibr" target="#b7">[8]</ref>, namely mean softmax (MCD-MSR), predictive entropy (MCD-PE) and expected entropy (MCD-EE), ConfidNet <ref type="bibr" target="#b4">[5]</ref>, which is trained as an extension to the classifier, DeepGamblers (DG) that learns a confidence like reservation score (DG-Res) <ref type="bibr" target="#b20">[22]</ref> and the work of DeVries et al. <ref type="bibr" target="#b5">[6]</ref>. Training Settings: On each dataset, we employ the classifier behind the respective leading results in literature: For chest Xray data we use DenseNet121 <ref type="bibr">[12]</ref>, for dermoscopy data we use EfficientNet-B4 <ref type="bibr" target="#b27">[29]</ref> and for fluorescence cell microscopy and lung nodule CT data we us DenseNet161 <ref type="bibr">[12]</ref>. We select the initial learning rate between 10 -3 and 10 -5 and weight decay between 0 and 10 -5 via grid search and optimize for validation accuracy. All models were trained with dropout. All hyperparameters can be found in Appendix Table <ref type="table">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Silent Failure Prevention Benchmark</head><p>Table <ref type="table" target="#tab_0">1</ref> shows the results of our benchmark for silent failure prevention in the biomedical domain and provides the first overview of the current state of the reliability of classification systems in high-stake biomedical applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>None of the Evaluated Methods from the Literature Beats the Maximum Softmax Response Baseline Across a Realistic Range of Failure</head><p>Sources. This result is generally consistent with previous findings in Bernhard et al. <ref type="bibr" target="#b2">[3]</ref> and Jaeger et al. <ref type="bibr" target="#b13">[15]</ref>, but is shown for the first time for a diverse range of realistic biomedical failure sources. Previously proposed methods do not outperform MSR baselines even in the settings they have been proposed for, e.g. Devries et al. under distribution shifts, or ConfidNet and DG-RES for i.i.d. testing. MCD and Loss Attenuation are Able to Improve the MSR. MCD-MSR is the overall best performing method indicating that MCD generally improves the confidence scoring ability of softmax outputs on these tasks. Interestingly, the DG loss attenuation applied to MCD-MSR, DG-MCD-MSR, which has not been part of the original DG publication but was first tested in Jaeger et al. <ref type="bibr" target="#b13">[15]</ref>, shows the best results on i.i.d. testing on 3 out of 4 tasks. However, the method is not reliable across all settings, falling short on manifestation shifts and corruptions on the lung nodule CT dataset. Effects of Particular Shifts on the Reliability of a CSF Might Be Interdependent. When looking beyond the averages displayed in Table <ref type="table" target="#tab_0">1</ref> and analyzing the results of individual clinical centers, corruptions and manifestation shifts, one remarkable pattern can be observed: In various cases, the same CSF showed opposing behavior between two variants of the same shift on the same dataset. For instance, Devries et al. outperforms all other CSFs for one clinical site (MSKCC) as target domain, but falls short on the other one (HCB).</p><p>On the Chest X-ray dataset, MCD worsens the performance for darkening corruptions across all CSFs and intensity levels, whereas the opposite is observed for brightening corruptions. Further, on the lung nodule CT dataset, DG-MCD-RES performs best on bright/dark corruptions and the spiculation manifestation shift, but worst on noise corruption and falls behind on the texture manifestation shift. These observations indicate trade-offs, where, within one distribution shift, reliability against one domain might induce susceptibility to other domains. Current Systems are Not Generally Reliable Enough for Clinical Application. Although CSFs can mitigate the rate of silent failures (see Appendix Fig. <ref type="figure">3</ref>), the reliability of the resulting classification systems is not sufficient for high-stake applications in the biomedical domain, with substantial rates of silent failure in three out of four tasks. Therefore, a deeper understanding of the root causes of these failures is needed. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Investigation of Silent Failure Sources</head><p>SF-Visuals Enables Comprehensive Analysis of Silent Failures. Figure <ref type="figure" target="#fig_0">1</ref> vividly demonstrates the added benefit of the proposed tool. First, an Interactive Scatter Plot (Fig. <ref type="figure" target="#fig_0">1b</ref>, left) provides an overview of the MSKCC acquisition shift on the dermoscopy dataset and reveals a severe change of the data distribution. For instance, some malignant lesions of the target domain (purple dots) are located deep within the "benign" cluster. Figure <ref type="figure" target="#fig_0">1c</ref> provides a Concept Cluster Plot that visually confirms how some of these lesions (purple dot) share characteristics of the benign cluster of the source domain (turquoise dot), such as being smaller, brighter, and rounder compared to malignant source-lesions (blue dot). The right-hand plot of Fig. <ref type="figure" target="#fig_0">1b</ref> reveals that these cases have in fact caused silent failures (red crosses) and visual inspection (see arrow and Fig. <ref type="figure" target="#fig_0">1a</ref>) confirms the hypothesis that these failures have been caused by the fact that the acquisition shift introduced malignant target-lesions that exhibit benign characteristics. Figure <ref type="figure" target="#fig_0">1b</ref>  In both examples, the brightening of the image leads to a malignant lesion taking on benign characteristics (brighter and smoother skin on the dermoscopy data, decreased contrast between lesion and background on the Lung Nodule CT data). Acquisition shift: Additionally to the example in Fig. <ref type="figure" target="#fig_0">1</ref>, Fig. <ref type="figure" target="#fig_1">2e</ref> shows how the proposed tool visualizes an acquisition shift on the chest X-ray data. While this reveals an increased blurriness in the target domain, it is difficult to derive further insights involving specific pathologies without a clinical expert. Figure <ref type="figure" target="#fig_1">2h</ref> shows a classification failure from a target clinical center together with the model's confidence as measured by MSR and DG. While MSR assigns the prediction low confidence thereby catching the failure, DG assigns high confidence for the same model and prediction, causing a silent failure. This example shows how the tool allows the comparison of CSFs and can help to identify failure modes specific to each CSF. Manifestation shift: On the dermoscopy data (Fig. <ref type="figure" target="#fig_1">2g</ref>), we see how a manifestation shift can cause silent failures. The benign lesions in the target domain are similar to the malignant lesions in the source domain (rough skin, irregular shapes), and indeed the two failures in the target domain seem to fall into this trap. On the lung nodule CT data (Fig. <ref type="figure" target="#fig_1">2f</ref>), we observe a visual distinction between the spiculated target domain (spiked surface) and the non-spiculated source domain (smooth surface).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We see two major opportunities for this work to make an impact on the community. 1) We hope the revealed shortcomings of current systems on biomedical tasks in combination with the deeper understanding of CSF behaviors granted by SF-Visuals will catalyze research towards a new generation of more reliable CSFs. 2) This study shows that in order to progress towards reliable ML systems, a deeper understanding of the data itself is required. SF-Visuals can help to bridge this gap and equip researchers with a better intuition of when and how to employ ML systems for a particular task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. a) Exemplary predictions of the classifier and the accompanying confidence scoring function (CSF, here: ConfidNet) on the dermoscopy dataset across several distribution shifts. Note that True/False Positives/Negatives (T/F P/N) do not refer to the classifier decision, but to the failure detection outcome, i.e. the assessment of the CSF. In this context, FN, i.e. cases with incorrect predictions ("failure") and a high confidence score ("failure not detected") are referred to as silent failures. b) SF-Visuals allows to identify and analyze silent failures in a dataset based on an Interactive Scatter Plot in the classifier's latent space (each dot represents one image, which is displayed when selecting the dot). c) SF-Visuals further features Concept Cluster Plots to gain an intuition of how the model perceives distinct classes or distribution shifts. More details on the displayed example are in Sect. 4.2. Abbreviations: B: Benign, M: Malignant, Pred.: Prediction, GT: Ground truth, Confid.: Confidence, Source: Source domain, Target: Target domain.</figDesc><graphic coords="2,56,97,54,35,339,04,238,36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Various Examples of how the SF-Visuals tool fosters a deeper understanding of root causes of silent failures. Abbreviations: i.i.d: Independent and identically distributed, Pr.: Prediction. GT: Ground Truth, C: Confidence Score, Source: Source domain, Target: Target domain.</figDesc><graphic coords="7,53,31,54,44,317,62,350,26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 . Silent failure prevention benchmark results measured in AURC[%] (score range: [0, 100], lower is better).</head><label>1</label><figDesc>The coloring is normalized by column, while lighter colors depict better scores. All values denote an average of three runs. "cor" denotes the average over all corruption types and intensities levels. Similarly, "acq"/"man" denote averages over all acquisition/manifestation shifts per dataset. "iid" denotes scenarios without distribution shifts. Results with further metrics are reported in Appendix Table2</figDesc><table><row><cell>Dataset</cell><cell>Chest X-ray</cell><cell></cell><cell cols="2">Dermoscopy</cell><cell cols="2">FC-Microscopy Lung Nodule CT</cell></row><row><cell>Study</cell><cell>iid cor acq</cell><cell>iid</cell><cell>cor</cell><cell>acq man</cell><cell>iid cor acq</cell><cell>iid cor man</cell></row><row><cell>MSR</cell><cell cols="6">15.3 18.6 23.1 0.544 0.913 0.799 49.3 13.3 55.6 32.4 6.69 8.18 12.1</cell></row><row><cell>PE</cell><cell cols="6">15.5 18.9 23.6 0.544 0.913 0.799 49.3 14.1 56.3 32.7 6.69 8.18 12.1</cell></row><row><cell>MCD-MSR</cell><cell cols="6">14.9 17.9 22.1 0.544 0.913 0.799 49.3 12.6 56.5 31.8 5.80 7.13 11.5</cell></row><row><cell>MCD-PE</cell><cell cols="6">15.1 18.2 22.7 0.544 0.913 0.799 49.3 13.2 57.2 32.1 5.80 7.13 11.5</cell></row><row><cell>MCD-EE</cell><cell cols="6">15.1 18.2 22.7 0.544 0.913 0.799 49.3 13.3 57.2 32.1 5.68 7.16 11.9</cell></row><row><cell>ConfidNet</cell><cell cols="6">15.1 18.5 22.8 0.581 0.979 0.806 51.1 21.9 63.7 61.9 5.77 7.50 15.7</cell></row><row><cell cols="7">DG-MCD-MSR 14.4 19.0 24.4 0.611 0.893 0.787 50.1 7.46 54.3 33.2 3.97 9.04 12.9</cell></row><row><cell>DG-RES</cell><cell cols="2">19.4 26.5 32.8 0.814</cell><cell>1.46</cell><cell cols="3">1.32 46.8 10.6 55.0 38.1 4.94 8.95 15.0</cell></row><row><cell>Devries et al.</cell><cell cols="2">14.7 18.4 23.5 0.801</cell><cell cols="4">1.08 0.882 45.5 12.9 62.3 51.4 4.99 9.41 20.2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>(right)  further provides insights about the general behavior of the CSF: Silent failures occur for both classes and are either located at the cluster border (i.e. decision boundary), deeper inside the opposing cluster center (severe class confusions), or represent outliers. Most silent failures occur at the boundary, where the CSF should reflect class ambiguities by low scores, hinting at general misbehavior or overconfidence in this area. Further towards the cluster boundary, the ambiguity in images seems to increase, as the CSF is able to detect the failures (light blue layer of dots). A layer of "false alarms" follows (brown colored dots), where decisions are correct, but confidence is still low.</figDesc><table /><note><p><p><p><p><p><p>SF-Visuals Generates Insights Across Tasks and Distribution Shifts. i.i.d. (No Shift):</p>This analysis reveals how simple class clustering (no distribution shifts involved) can help to gain intuition on the most severe silent failures (examples selected as the two highest-confidence failures). On the lung nodule CT data (Fig.</p>2a</p>), we see how the classifier and CSF break down when a malignant sample (typically: small bright, round) exhibits characteristics typical to benign lesions (larger, less cohesive contour, darker) and vice versa. This pattern of contrary class characteristics is also observed on the dermoscopy dataset (2c). The failure example at the top is particularly severe, and localization in the scatter plot reveals a position deep inside the 'benign' cluster indicating either a severe sampling error in the dataset (e.g. underrepresented lesion subtype) or simply a wrong label. Corruption shift: Figs.</p>2b and 2d</p>show for the Lung Nodule CT data and the dermoscopy data, respectively, how corruptions can lead to silent failures in low-confident predictions.</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This work was funded by <rs type="funder">Helmholtz Imaging (HI)</rs>, a platform of the Helmholtz Incubator on Information and Data Science.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43898-1 39.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The lung image database consortium (LIDC) and image database resource initiative (IDRI): a completed reference database of lung nodules on CT scans: the LIDC/IDRI thoracic CT database of lung nodules</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Armato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mclennan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bidaut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Mcnitt-Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Meyer</surname></persName>
		</author>
		<idno type="DOI">10.1118/1.3528204</idno>
		<ptr target="https://doi.org/10.1118/1.3528204" />
	</analytic>
	<monogr>
		<title level="j">Med. Phys</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="915" to="931" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Benchmarking Bayesian deep learning on diabetic retinopathy detection tasks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Band</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G J</forename><surname>Rudner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Filos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Nado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track</title>
		<imprint>
			<date type="published" when="2022-01">January 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Failure detection in medical image classification: a reality check and benchmarking testbed</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bernhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">D S</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2205.14094</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2205.14094" />
		<imprint>
			<date type="published" when="2022-10">October 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Causality matters in medical imaging</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-020-17478-w</idno>
		<ptr target="https://doi.org/10.1038/s41467-020-17478-w" />
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">3673</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Addressing failure prediction by learning model confidence</title>
		<author>
			<persName><forename type="first">C</forename><surname>CorbiÃ¨re</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Thome</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bar-Hen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>PÃ©rez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2019">2019</date>
			<publisher>Curran Associates, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Learning confidence for out-of-distribution detection in neural networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.1802.04865</idno>
		<ptr target="https://doi.org/10.48550/arXiv.1802.04865" />
		<imprint>
			<date type="published" when="2018-02">February 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Exploring the limits of out-of-distribution detection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.03004</idno>
		<imprint>
			<date type="published" when="2021-07">July 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Dropout as a Bayesian approximation: representing model uncertainty in deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<idno>PMLR</idno>
		<imprint>
			<date type="published" when="2016-06">June 2016</date>
			<biblScope unit="page" from="1050" to="1059" />
		</imprint>
		<respStmt>
			<orgName>ICML</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Selective classification for deep neural networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Geifman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>El-Yaniv</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.08500</idno>
		<imprint>
			<date type="published" when="2017-06">June 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">SelectiveNet: a deep neural network with an integrated reject option</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Geifman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>El-Yaniv</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.09192</idno>
		<imprint>
			<date type="published" when="2019-06">June 2019</date>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">A baseline for detecting misclassified and out-ofdistribution examples in neural networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.02136</idno>
		<imprint>
			<date type="published" when="2017">October 2018 12. 2017</date>
			<biblScope unit="page" from="4700" to="4708" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
	<note>Densely connected convolutional networks</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">ImageNet-X: understanding model mistakes with factor of variation annotations</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Y</forename><surname>Idrissi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bouchacourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Balestriero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Evtimov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hazirbas</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2211.01866</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2211.01866" />
		<imprint>
			<date type="published" when="2022-11">November 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">CheXpert: a large chest radiograph dataset with uncertainty labels and expert comparison</title>
		<author>
			<persName><forename type="first">J</forename><surname>Irvin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ciurea-Ilcus</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.1901.07031</idno>
		<ptr target="https://doi.org/10.48550/arXiv.1901.07031" />
		<imprint>
			<date type="published" when="2019-01">January 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A call to reflect on evaluation practices for failure detection in image classification</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>LÃ¼th</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Bungert</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2211.15259</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2211.15259" />
		<imprint>
			<date type="published" when="2022-11">November 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">MIMIC-III, a freely accessible critical care database</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E W</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Pollard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Lehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Feng</surname></persName>
		</author>
		<idno type="DOI">10.1038/sdata.2016.35</idno>
		<ptr target="https://doi.org/10.1038/sdata.2016.35" />
	</analytic>
	<monogr>
		<title level="j">Sci. Data</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">160035</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Seven-point checklist and skin lesion classification using multitask multimodal neural nets</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Daneshvar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Argenziano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hamarneh</surname></persName>
		</author>
		<idno type="DOI">10.1109/JBHI.2018.2824327</idno>
		<ptr target="https://doi.org/10.1109/JBHI.2018.2824327" />
	</analytic>
	<monogr>
		<title level="j">IEEE J. Biomed. Health Inform</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="538" to="546" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">What uncertainties do we need in Bayesian deep learning for computer vision?</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.04977</idno>
		<imprint>
			<date type="published" when="2017-03">March 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">WILDS: a benchmark of in-the-wild distribution shifts</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sagawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Marklund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2012.07421</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2012.07421" />
		<imprint>
			<date type="published" when="2021-07">July 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A simple unified framework for detecting outof-distribution samples and adversarial attacks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<date type="published" when="2018">2018</date>
			<publisher>Curran Associates, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Enhancing the reliability of out-of-distribution image detection in neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Srikant</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02690</idno>
		<imprint>
			<date type="published" when="2020-08">August 2020</date>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep gamblers: learning to abstain with portfolio theory</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Morency</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2019">2019</date>
			<publisher>Curran Associates, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Predictive uncertainty estimation via prior networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Malinin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<date type="published" when="2018">2018</date>
			<publisher>Curran Associates, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">PH2 -a dermoscopic image database for research and benchmarking</title>
		<author>
			<persName><forename type="first">T</forename><surname>MendonÃ§a</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Ferreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Marques</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R S</forename><surname>Marcal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rozeira</surname></persName>
		</author>
		<idno type="DOI">10.1109/EMBC.2013.6610779</idno>
		<ptr target="https://doi.org/10.1109/EMBC.2013.6610779" />
	</analytic>
	<monogr>
		<title level="m">2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)</title>
		<imprint>
			<date type="published" when="2013-07">July 2013</date>
			<biblScope unit="page" from="5437" to="5440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Can you trust your model&apos; s uncertainty? Evaluating predictive uncertainty under dataset shift</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ovadia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fertig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Nado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sculley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2019">2019</date>
			<publisher>Curran Associates, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A patient-centric dataset of images and metadata for identifying melanomas using clinical context</title>
		<author>
			<persName><forename type="first">V</forename><surname>Rotemberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kurtansky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Betz-Stablein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Caffery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chousakos</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41597-021-00815-z</idno>
		<ptr target="https://doi.org/10.1038/s41597-021-00815-z" />
	</analytic>
	<monogr>
		<title level="j">Sci. Data</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">34</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">BREEDS: benchmarks for subpopulation shift</title>
		<author>
			<persName><forename type="first">S</forename><surname>Santurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Madry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022-02">February 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">RxRx1: a dataset for evaluating experimental batch correction methods</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sypetkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rezanejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saberian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Kraus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Urbanik</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2301.05768</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2301.05768" />
		<imprint>
			<date type="published" when="2023-01">January 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">EfficientNet: rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<idno>PMLR</idno>
		<imprint>
			<date type="published" when="2019-05">May 2019</date>
			<biblScope unit="page" from="6105" to="6114" />
		</imprint>
		<respStmt>
			<orgName>ICML</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions</title>
		<author>
			<persName><forename type="first">P</forename><surname>Tschandl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rosendahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kittler</surname></persName>
		</author>
		<idno type="DOI">10.1038/sdata.2018.161</idno>
		<ptr target="https://doi.org/10.1038/sdata.2018.161" />
	</analytic>
	<monogr>
		<title level="j">Sci. Data</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">180161</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">ChestX-Ray8: hospitalscale chest X-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bagheri</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2017.369</idno>
		<ptr target="https://doi.org/10.1109/CVPR.2017.369" />
		<imprint>
			<date type="published" when="2017-07">July 2017</date>
			<biblScope unit="page" from="3462" to="3471" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Winkens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bunel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stanforth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Natarajan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.05566</idno>
		<title level="m">Contrastive training for improved out-of-distribution detection</title>
		<imprint>
			<date type="published" when="2020-07">July 2020</date>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Benchmarking the robustness of deep neural networks to common corruptions in digital pathology</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16434-7_24</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16434-724" />
	</analytic>
	<monogr>
		<title level="j">LNCS</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="page" from="242" to="252" />
			<date type="published" when="2022">2022</date>
			<publisher>Springer</publisher>
			<pubPlace>Cham</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
