{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import xml.etree.cElementTree as et\n",
    "from xml.etree import ElementTree as et\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROBID server is up and running\n"
     ]
    }
   ],
   "source": [
    "from grobid_client.grobid_client import GrobidClient\n",
    "\n",
    "\n",
    "#client = GrobidClient(grobid_server='https://kermitt2-grobid.hf.space/')\n",
    "#client = GrobidClient(grobid_server='http://localhost:8081')\n",
    "client = GrobidClient(grobid_server='http://localhost:8070')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_file = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1'\n",
    "client.process('processFulltextDocument', process_file, output=\"./vol01\", force=True)\n",
    "\n",
    "#process_file = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2'\n",
    "#client.process('processFulltextDocument', process_file, output = \"./vol02\", force=True)\n",
    "\n",
    "#process_file = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3'\n",
    "#client.process('processFulltextDocument', process_file, output=\"./vol03\", force=True)\n",
    "\n",
    "#process_file = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4'\n",
    "#client.process('processFulltextDocument', process_file, output=\"./vol04\", force=True)\n",
    "\n",
    "#process_file = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5'\n",
    "#client.process('processFulltextDocument', process_file, output=\"./vol05\", force=True)\n",
    "\n",
    "#process_file = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6'\n",
    "#client.process('processFulltextDocument', process_file, output=\"./vol06\", force=True)\n",
    "\n",
    "#process_file = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7'\n",
    "#client.process('processFulltextDocument', process_file, output=\"./vol07\", force=True)\n",
    "\n",
    "#process_file = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8'\n",
    "#client.process('processFulltextDocument', process_file, output=\"./vol08\", force=True)\n",
    "\n",
    "#process_file = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9'\n",
    "#client.process('processFulltextDocument', process_file, output=\"./vol09\", force=True)\n",
    "\n",
    "#process_file = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10'\n",
    "#client.process('processFulltextDocument', process_file, output=\"./vol10\", force=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/vol01'\n",
    "# folder_path = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/vol02'\n",
    "# folder_path = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/vol03'\n",
    "# folder_path = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/vol04'\n",
    "# folder_path = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/vol05'\n",
    "# folder_path = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/vol06'\n",
    "# folder_path = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/vol07'\n",
    "# folder_path = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/vol08'\n",
    "# folder_path = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/vol09'\n",
    "# folder_path = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/vol10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming XML files by folder path\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed 'paper_63.grobid.tei.xml' to 'Masked_Frequency_Consistency_for_Domain-Adaptive_Semantic_Segmentation_of_Laparoscopic_Images.xml'\n",
      "Renamed 'paper_12.grobid.tei.xml' to 'Additional_Positive_Enables_Better_Representation_Learning_for_Medical_Images.xml'\n",
      "Renamed 'paper_71.grobid.tei.xml' to 'Black-box_Domain_Adaptative_Cell_Segmentation_via_Multi-source_Distillation.xml'\n",
      "Renamed 'paper_64.grobid.tei.xml' to 'Pick_the_Best_Pre-trained_Model:_Towards_Transferability_Estimation_for_Medical_Image_Segmentation.xml'\n",
      "Renamed 'paper_15.grobid.tei.xml' to 'Automatic_Retrieval_of_Corresponding_US_Views_in_Longitudinal_Examinations.xml'\n",
      "Renamed 'paper_65.grobid.tei.xml' to 'Source-Free_Domain_Adaptive_Fundus_Image_Segmentation_with_Class-Balanced_Mean_Teacher.xml'\n",
      "Renamed 'paper_70.grobid.tei.xml' to 'Cross-Dataset_Adaptation_for_Instrument_Classification_in_Cataract_Surgery_Videos.xml'\n",
      "Renamed 'paper_14.grobid.tei.xml' to '3D_Arterial_Segmentation_via_Single_2D_Projections_and_Depth_Supervision_in_Contrast-Enhanced_CT_Images.xml'\n",
      "Renamed 'paper_62.grobid.tei.xml' to 'Foundation_Ark:_Accruing_and_Reusing_Knowledge_for_Superior_and_Robust_Performance.xml'\n",
      "Renamed 'paper_13.grobid.tei.xml' to 'Multi-modal_Semi-supervised_Evidential_Recycle_Framework_for_Alzheimer’s_Disease_Classification.xml'\n",
      "Renamed 'paper_11.grobid.tei.xml' to 'TPRO:_Text-Prompting-Based_Weakly_Supervised_Histopathology_Tissue_Segmentation.xml'\n",
      "Renamed 'paper_60.grobid.tei.xml' to 'Graph_Convolutional_Network_with_Morphometric_Similarity_Networks_for_Schizophrenia_Classification.xml'\n",
      "Renamed 'paper_68.grobid.tei.xml' to 'Multi-Target_Domain_Adaptation_with_Prompt_Learning_for_Medical_Image_Segmentation.xml'\n",
      "Renamed 'paper_19.grobid.tei.xml' to 'AMAE:_Adaptation_of_Pre-trained_Masked_Autoencoder_for_Dual-Distribution_Anomaly_Detection_in_Chest_X-Rays.xml'\n",
      "Renamed 'paper_16.grobid.tei.xml' to 'Many_Tasks_Make_Light_Work:_Learning_to_Localise_Medical_Anomalies_from_Multiple_Synthetic_Tasks.xml'\n",
      "Renamed 'paper_67.grobid.tei.xml' to 'MetaLR:_Meta-tuning_of_Learning_Rates_for_Transfer_Learning_in_Medical_Imaging.xml'\n",
      "Renamed 'paper_72.grobid.tei.xml' to 'MedGen3D:_A_Deep_Generative_Framework_for_Paired_3D_Image_and_Mask_Generation.xml'\n",
      "Renamed 'paper_17.grobid.tei.xml' to 'AME-CAM:_Attentive_Multiple-Exit_CAM_for_Weakly_Supervised_Segmentation_on_MRI_Brain_Tumor.xml'\n",
      "Renamed 'paper_73.grobid.tei.xml' to 'Unsupervised_Domain_Transfer_with_Conditional_Invertible_Neural_Networks.xml'\n",
      "Renamed 'paper_66.grobid.tei.xml' to 'Unsupervised_Domain_Adaptation_for_Anatomical_Landmark_Detection.xml'\n",
      "Renamed 'paper_69.grobid.tei.xml' to 'Spectral_Adversarial_MixUp_for_Few-Shot_Unsupervised_Domain_Adaptation.xml'\n",
      "Renamed 'paper_18.grobid.tei.xml' to 'Cross-Adversarial_Local_Distribution_Regularization_for_Semi-supervised_Medical_Image_Segmentation.xml'\n",
      "Renamed 'paper_10.grobid.tei.xml' to 'Correlation-Aware_Mutual_Learning_for_Semi-supervised_Medical_Image_Segmentation.xml'\n",
      "Renamed 'paper_61.grobid.tei.xml' to 'M-FLAG:_Medical_Vision-Language_Pre-training_with_Frozen_Language_Models_and_Latent_Space_Geometry_Optimization.xml'\n",
      "Renamed 'paper_48.grobid.tei.xml' to 'CT-Guided,_Unsupervised_Super-Resolution_Reconstruction_of_Single_3D_Magnetic_Resonance_Image.xml'\n",
      "Renamed 'paper_39.grobid.tei.xml' to 'Knowledge_Boosting:_Rethinking_Medical_Contrastive_Vision-Language_Pre-training.xml'\n",
      "Renamed 'paper_3.grobid.tei.xml' to 'UOD:_Universal_One-Shot_Detection_of_Anatomical_Landmarks.xml'\n",
      "Renamed 'paper_31.grobid.tei.xml' to 'Unsupervised_Discovery_of_3D_Hierarchical_Structure_with_Generative_Diffusion_Features.xml'\n",
      "Renamed 'paper_24.grobid.tei.xml' to 'DAS-MIL:_Distilling_Across_Scales_for_MIL_Classification_of_Histological_WSIs.xml'\n",
      "Renamed 'paper_55.grobid.tei.xml' to 'Multi-scale_Self-Supervised_Learning_for_Longitudinal_Lesion_Tracking_with_Optional_Supervision.xml'\n",
      "Renamed 'paper_40.grobid.tei.xml' to 'A_Small-Sample_Method_with_EEG_Signals_Based_on_Abductive_Learning_for_Motor_Imagery_Decoding.xml'\n",
      "Renamed 'paper_4.grobid.tei.xml' to 'S_2_ME:_Spatial-Spectral_Mutual_Teaching_and_Ensemble_Learning_for_Scribble-Supervised_Polyp_Segmentation.xml'\n",
      "Renamed 'paper_23.grobid.tei.xml' to 'Inter-slice_Consistency_for_Unpaired_Low-Dose_CT_Denoising_Using_Boosted_Contrastive_Learning.xml'\n",
      "Renamed 'paper_36.grobid.tei.xml' to 'Masked_Vision_and_Language_Pre-training_with_Unimodal_and_Multimodal_Contrastive_Losses_for_Medical_Visual_Question_Answering.xml'\n",
      "Renamed 'paper_47.grobid.tei.xml' to 'Can_Point_Cloud_Networks_Learn_Statistical_Shape_Models_of_Anatomies?.xml'\n",
      "Renamed 'paper_52.grobid.tei.xml' to 'Self-Supervised_Domain_Adaptive_Segmentation_of_Breast_Cancer_via_Test-Time_Fine-Tuning.xml'\n",
      "Renamed 'paper_37.grobid.tei.xml' to 'CL-ADDA:_Contrastive_Learning_with_Amplitude-Driven_Data_Augmentation_for_fMRI-Based_Individualized_Predictions.xml'\n",
      "Renamed 'paper_22.grobid.tei.xml' to 'Weakly-Supervised_Positional_Contrastive_Learning:_Application_to_Cirrhosis_Classification.xml'\n",
      "Renamed 'paper_53.grobid.tei.xml' to 'Decoupled_Consistency_for_Semi-supervised_Medical_Image_Segmentation.xml'\n",
      "Renamed 'paper_46.grobid.tei.xml' to 'Weakly_Supervised_Lesion_Localization_of_Nascent_Geographic_Atrophy_in_Age-Related_Macular_Degeneration.xml'\n",
      "Renamed 'paper_5.grobid.tei.xml' to 'Modularity-Constrained_Dynamic_Representation_Learning_for_Interpretable_Brain_Disorder_Analysis_with_Functional_MRI.xml'\n",
      "Renamed 'paper_25.grobid.tei.xml' to 'SLPD:_Slide-Level_Prototypical_Distillation_for_WSIs.xml'\n",
      "Renamed 'paper_30.grobid.tei.xml' to 'Modeling_Alzheimers’_Disease_Progression_from_Multi-task_and_Self-supervised_Learning_Perspective_with_Brain_Networks.xml'\n",
      "Renamed 'paper_41.grobid.tei.xml' to 'Multi-modal_Variational_Autoencoders_for_Normative_Modelling_Across_Multiple_Imaging_Modalities.xml'\n",
      "Renamed 'paper_54.grobid.tei.xml' to 'Combating_Medical_Label_Noise_via_Robust_Semi-supervised_Contrastive_Learning.xml'\n",
      "Renamed 'paper_49.grobid.tei.xml' to 'Image2SSM:_Reimagining_Statistical_Shape_Models_from_Images_with_Radial_Basis_Functions.xml'\n",
      "Renamed 'paper_2.grobid.tei.xml' to 'MedIM:_Boost_Medical_Image_Representation_via_Radiology_Report-Guided_Masking.xml'\n",
      "Renamed 'paper_38.grobid.tei.xml' to 'An_Auto-Encoder_to_Reconstruct_Structure_with_Cryo-EM_Images_via_Theoretically_Guaranteed_Isometric_Latent_Space,_and_Its_Application_for_Automatically_Computing_the_Conformational_Pathway.xml'\n",
      "Renamed 'paper_43.grobid.tei.xml' to 'Unsupervised_3D_Out-of-Distribution_Detection_with_Latent_Diffusion_Models.xml'\n",
      "Renamed 'paper_56.grobid.tei.xml' to 'Tracking_Adaptation_to_Improve_SuperPoint_for_3D_Reconstruction_in_Endoscopy.xml'\n",
      "Renamed 'paper_8.grobid.tei.xml' to 'Dense_Transformer_based_Enhanced_Coding_Network_for_Unsupervised_Metal_Artifact_Reduction.xml'\n",
      "Renamed 'paper_27.grobid.tei.xml' to 'LSOR:_Longitudinally-Consistent_Self-Organized_Representation_Learning.xml'\n",
      "Renamed 'paper_32.grobid.tei.xml' to 'Domain_Adaptation_for_Medical_Image_Segmentation_Using_Transformation-Invariant_Self-training.xml'\n",
      "Renamed 'paper_51.grobid.tei.xml' to 'PROnet:_Point_Refinement_Using_Shape-Guided_Offset_Map_for_Nuclei_Instance_Segmentation.xml'\n",
      "Renamed 'paper_44.grobid.tei.xml' to 'Improved_Multi-shot_Diffusion-Weighted_MRI_with_Zero-Shot_Self-supervised_Learning_Reconstruction.xml'\n",
      "Renamed 'paper_35.grobid.tei.xml' to 'You’ve_Got_Two_Teachers:_Co-evolutionary_Image_and_Report_Distillation_for_Semi-supervised_Anatomical_Abnormality_Detection_in_Chest_X-Ray.xml'\n",
      "Renamed 'paper_20.grobid.tei.xml' to 'Gall_Bladder_Cancer_Detection_from_US_Images_with_only_Image_Level_Labels.xml'\n",
      "Renamed 'paper_7.grobid.tei.xml' to 'VesselVAE:_Recursive_Variational_Autoencoders_for_3D_Blood_Vessel_Synthesis.xml'\n",
      "Renamed 'paper_28.grobid.tei.xml' to 'Self-supervised_Learning_for_Physiologically-Based_Pharmacokinetic_Modeling_in_Dynamic_PET.xml'\n",
      "Renamed 'paper_59.grobid.tei.xml' to 'Mesh2SSM:_From_Surface_Meshes_to_Statistical_Shape_Models_of_Anatomy.xml'\n",
      "Renamed 'paper_29.grobid.tei.xml' to 'Geometry-Invariant_Abnormality_Detection.xml'\n",
      "Renamed 'paper_6.grobid.tei.xml' to 'Anatomy-Driven_Pathology_Detection_on_Chest_X-rays.xml'\n",
      "Renamed 'paper_58.grobid.tei.xml' to 'vox2vec:_A_Framework_for_Self-supervised_Contrastive_Learning_of_Voxel-Level_Representations_in_Medical_Images.xml'\n",
      "Renamed 'paper_45.grobid.tei.xml' to 'Infusing_Physically_Inspired_Known_Operators_in_Deep_Models_of_Ultrasound_Elastography.xml'\n",
      "Renamed 'paper_50.grobid.tei.xml' to 'MDA-SR:_Multi-level_Domain_Adaptation_Super-Resolution_for_Wireless_Capsule_Endoscopy_Images.xml'\n",
      "Renamed 'paper_21.grobid.tei.xml' to 'Medical_Image_Computing_and_Computer_Assisted_Intervention_–_MICCAI_2023.xml'\n",
      "Renamed 'paper_34.grobid.tei.xml' to 'Deblurring_Masked_Autoencoder_Is_Better_Recipe_for_Ultrasound_Image_Recognition.xml'\n",
      "Renamed 'paper_1.grobid.tei.xml' to 'PET-Diffusion:_Unsupervised_PET_Enhancement_Based_on_the_Latent_Diffusion_Model.xml'\n",
      "Renamed 'paper_57.grobid.tei.xml' to 'Structured_State_Space_Models_for_Multiple_Instance_Learning_in_Digital_Pathology.xml'\n",
      "Renamed 'paper_42.grobid.tei.xml' to 'LOTUS:_Learning_to_Optimize_Task-Based_US_Representations.xml'\n",
      "Renamed 'paper_33.grobid.tei.xml' to 'Multi-IMU_with_Online_Self-consistency_for_Freehand_3D_Ultrasound_Reconstruction.xml'\n",
      "Renamed 'paper_26.grobid.tei.xml' to 'PET_Image_Denoising_with_Score-Based_Diffusion_Probabilistic_Models.xml'\n",
      "Renamed 'paper_9.grobid.tei.xml' to 'Multi-scale_Cross-restoration_Framework_for_Electrocardiogram_Anomaly_Detection.xml'\n"
     ]
    }
   ],
   "source": [
    "# Rename_xml_files_in_folder(folder_path)\n",
    "def find_title(element):\n",
    "    \"\"\"Recursively search for the title element in the XML structure.\"\"\"\n",
    "    if 'title' in element.tag.lower() and element.text:\n",
    "        return element.text.strip()\n",
    "    for child in element:\n",
    "        title = find_title(child)\n",
    "        if title:\n",
    "            return title\n",
    "    return None\n",
    "\n",
    "def rename_xml_files_in_folder(folder_path):\n",
    "    \"\"\"Rename XML files based on their title tags.\"\"\"\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if not filename.endswith('.xml'):  # Skip non-XML files\n",
    "            continue\n",
    "        \n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            tree = et.parse(file_path)\n",
    "            root = tree.getroot()\n",
    "            paper_title = find_title(root)\n",
    "            if paper_title:\n",
    "                new_filename = paper_title.replace(\" \", \"_\") + '.xml'\n",
    "                new_file_path = os.path.join(folder_path, new_filename)\n",
    "                os.rename(file_path, new_file_path)\n",
    "                print(f\"Renamed '{filename}' to '{new_filename}'\")\n",
    "            else:\n",
    "                print(f\"Title not found in '{filename}'. Skipping.\")\n",
    "        except et.ParseError as e:\n",
    "            print(f\"Error parsing '{filename}': {e}\")\n",
    "\n",
    "# Rename the XML files in this folder\n",
    "folder_path = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/vol01'\n",
    "rename_xml_files_in_folder(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually renaming the XML files \n",
    "***\n",
    "(some files are wrongly named/not named for some strange reason)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/A_Patient-Specific_Self-supervised_Model_for_Automatic_X-Ray.xml'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually renaming the XML files based on their title tags\n",
    "\n",
    "# Load and parse the XML file\n",
    "#file_path = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/vol09/paper_59.grobid.tei.xml'\n",
    "#file_path = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/output2/Medical_Image_Computing_and_Computer_Assisted_Intervention_–_MICCAI_2023.xml'\n",
    "\n",
    "''' Paper 44 XML file: title was too long to be used as a file name, removed '/CT Self-supervised Denoising' from the title '''\n",
    "#file_path ='/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/paper_44.grobid.tei.xml'\n",
    "\n",
    "#file_path = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/output2/paper_13.grobid.tei.xml'\n",
    "\n",
    "'''FileNotFoundError: [Errno 2] No such file or directory: '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/paper_49.grobid.tei.xml' -> \n",
    "'/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/A_Patient-Specific_Self-supervised_Model_for_Automatic_X-Ray/CT_Registration.xml'\n",
    "Solution: removed '/CT_Registration' from title\n",
    "'''\n",
    "file_path = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/paper_49.grobid.tei.xml'\n",
    "tree = et.parse(file_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Since XML namespaces can complicate direct tag access, we find the title tag dynamically.\n",
    "# This approach is based on the assumption that titles are relatively unique in structure.\n",
    "\n",
    "# Attempt to extract the paper title. This might need adjustments based on the actual structure.\n",
    "title = None\n",
    "for elem in root.iter():\n",
    "    if 'title' in elem.tag.lower():\n",
    "        title = elem.text\n",
    "        break\n",
    "\n",
    "title_clean = title.strip().replace(\" \", \"_\") if title else \"Untitled_Document\"\n",
    "title_clean\n",
    "\n",
    "# Attempt a more generic search for the title, considering common patterns in scholarly articles\n",
    "# We'll look for title elements that might be nested within other elements (like \"titleStmt\" or \"fileDesc\" in TEI format)\n",
    "\n",
    "def find_title(element):\n",
    "    \"\"\"\n",
    "    Recursively search for the title element in the XML structure.\n",
    "    \"\"\"\n",
    "    if 'title' in element.tag.lower() and element.text:\n",
    "        return element.text.strip()\n",
    "    for child in element:\n",
    "        title = find_title(child)\n",
    "        if title:\n",
    "            return title\n",
    "    return None\n",
    "\n",
    "# Attempt to find the title using the recursive search\n",
    "paper_title = find_title(root)\n",
    "paper_title_clean = paper_title.replace(\" \", \"_\") if paper_title else \"Untitled_Document\"\n",
    "paper_title, paper_title_clean\n",
    "\n",
    "import os\n",
    "\n",
    "# Define the new file path with the clean title\n",
    "new_file_path = os.path.join(os.path.dirname(file_path), f\"{paper_title_clean}.xml\")\n",
    "\n",
    "# Rename the file\n",
    "os.rename(file_path, new_file_path)\n",
    "\n",
    "new_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming XML files, extracting paper titles and text\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13 headers in 'AMAE: Adaptation of Pre-trained Masked Autoencoder for Dual-Distribution Anomaly Detection in Chest X-Rays'\n",
      "Found 19 headers in 'Unsupervised Domain Adaptation for Anatomical Landmark Detection'\n",
      "Found 13 headers in 'CT-Guided, Unsupervised Super-Resolution Reconstruction of Single 3D Magnetic Resonance Image'\n",
      "Found 18 headers in 'Multi-scale Cross-restoration Framework for Electrocardiogram Anomaly Detection'\n",
      "Found 12 headers in 'Multi-modal Variational Autoencoders for Normative Modelling Across Multiple Imaging Modalities'\n",
      "Found 18 headers in 'Dense Transformer based Enhanced Coding Network for Unsupervised Metal Artifact Reduction'\n",
      "Found 22 headers in 'MedIM: Boost Medical Image Representation via Radiology Report-Guided Masking'\n",
      "Found 17 headers in 'Unsupervised Domain Transfer with Conditional Invertible Neural Networks'\n",
      "Found 19 headers in 'Anatomy-Driven Pathology Detection on Chest X-rays'\n",
      "Found 16 headers in 'Self-supervised Learning for Physiologically-Based Pharmacokinetic Modeling in Dynamic PET'\n",
      "Found 15 headers in 'Foundation Ark: Accruing and Reusing Knowledge for Superior and Robust Performance'\n",
      "Found 12 headers in 'LOTUS: Learning to Optimize Task-Based US Representations'\n",
      "Found 18 headers in 'Combating Medical Label Noise via Robust Semi-supervised Contrastive Learning'\n",
      "Found 18 headers in 'AME-CAM: Attentive Multiple-Exit CAM for Weakly Supervised Segmentation on MRI Brain Tumor'\n",
      "Found 13 headers in 'Correlation-Aware Mutual Learning for Semi-supervised Medical Image Segmentation'\n",
      "Found 12 headers in 'Multi-IMU with Online Self-consistency for Freehand 3D Ultrasound Reconstruction'\n",
      "Found 19 headers in 'Masked Vision and Language Pre-training with Unimodal and Multimodal Contrastive Losses for Medical Visual Question Answering'\n",
      "Found 17 headers in 'Inter-slice Consistency for Unpaired Low-Dose CT Denoising Using Boosted Contrastive Learning'\n",
      "Found 13 headers in 'You’ve Got Two Teachers: Co-evolutionary Image and Report Distillation for Semi-supervised Anatomical Abnormality Detection in Chest X-Ray'\n",
      "Found 20 headers in 'Modularity-Constrained Dynamic Representation Learning for Interpretable Brain Disorder Analysis with Functional MRI'\n",
      "Found 12 headers in 'Weakly-Supervised Positional Contrastive Learning: Application to Cirrhosis Classification'\n",
      "Found 16 headers in 'Unsupervised 3D Out-of-Distribution Detection with Latent Diffusion Models'\n",
      "Found 15 headers in 'Unsupervised Discovery of 3D Hierarchical Structure with Generative Diffusion Features'\n",
      "Found 17 headers in 'MDA-SR: Multi-level Domain Adaptation Super-Resolution for Wireless Capsule Endoscopy Images'\n",
      "Found 19 headers in 'S 2 ME: Spatial-Spectral Mutual Teaching and Ensemble Learning for Scribble-Supervised Polyp Segmentation'\n",
      "Found 18 headers in 'Graph Convolutional Network with Morphometric Similarity Networks for Schizophrenia Classification'\n",
      "Found 23 headers in 'M-FLAG: Medical Vision-Language Pre-training with Frozen Language Models and Latent Space Geometry Optimization'\n",
      "Found 17 headers in 'Tracking Adaptation to Improve SuperPoint for 3D Reconstruction in Endoscopy'\n",
      "Found 21 headers in 'Knowledge Boosting: Rethinking Medical Contrastive Vision-Language Pre-training'\n",
      "Found 14 headers in 'Deblurring Masked Autoencoder Is Better Recipe for Ultrasound Image Recognition'\n",
      "Found 9 headers in 'Black-box Domain Adaptative Cell Segmentation via Multi-source Distillation'\n",
      "Found 15 headers in 'Additional Positive Enables Better Representation Learning for Medical Images'\n",
      "Found 19 headers in 'Self-Supervised Domain Adaptive Segmentation of Breast Cancer via Test-Time Fine-Tuning'\n",
      "Found 16 headers in 'Decoupled Consistency for Semi-supervised Medical Image Segmentation'\n",
      "Found 15 headers in 'PET-Diffusion: Unsupervised PET Enhancement Based on the Latent Diffusion Model'\n",
      "Found 11 headers in '3D Arterial Segmentation via Single 2D Projections and Depth Supervision in Contrast-Enhanced CT Images'\n",
      "Found 18 headers in 'Mesh2SSM: From Surface Meshes to Statistical Shape Models of Anatomy'\n",
      "Found 19 headers in 'Cross-Adversarial Local Distribution Regularization for Semi-supervised Medical Image Segmentation'\n",
      "Found 18 headers in 'Infusing Physically Inspired Known Operators in Deep Models of Ultrasound Elastography'\n",
      "Found 13 headers in 'Domain Adaptation for Medical Image Segmentation Using Transformation-Invariant Self-training'\n",
      "Found 19 headers in 'SLPD: Slide-Level Prototypical Distillation for WSIs'\n",
      "Found 15 headers in 'Masked Frequency Consistency for Domain-Adaptive Semantic Segmentation of Laparoscopic Images'\n",
      "Found 14 headers in 'Can Point Cloud Networks Learn Statistical Shape Models of Anatomies?'\n",
      "Found 12 headers in 'PROnet: Point Refinement Using Shape-Guided Offset Map for Nuclei Instance Segmentation'\n",
      "Found 13 headers in 'Many Tasks Make Light Work: Learning to Localise Medical Anomalies from Multiple Synthetic Tasks'\n",
      "Found 14 headers in 'Improved Multi-shot Diffusion-Weighted MRI with Zero-Shot Self-supervised Learning Reconstruction'\n",
      "Found 13 headers in 'Image2SSM: Reimagining Statistical Shape Models from Images with Radial Basis Functions'\n",
      "Found 16 headers in 'TPRO: Text-Prompting-Based Weakly Supervised Histopathology Tissue Segmentation'\n",
      "Found 16 headers in 'LSOR: Longitudinally-Consistent Self-Organized Representation Learning'\n",
      "Found 8 headers in 'VesselVAE: Recursive Variational Autoencoders for 3D Blood Vessel Synthesis'\n",
      "Found 22 headers in 'Medical Image Computing and Computer Assisted Intervention – MICCAI 2023'\n",
      "Found 15 headers in 'A Small-Sample Method with EEG Signals Based on Abductive Learning for Motor Imagery Decoding'\n",
      "Found 13 headers in 'Weakly Supervised Lesion Localization of Nascent Geographic Atrophy in Age-Related Macular Degeneration'\n",
      "Found 24 headers in 'MetaLR: Meta-tuning of Learning Rates for Transfer Learning in Medical Imaging'\n",
      "Found 18 headers in 'Multi-modal Semi-supervised Evidential Recycle Framework for Alzheimer’s Disease Classification'\n",
      "Found 16 headers in 'DAS-MIL: Distilling Across Scales for MIL Classification of Histological WSIs'\n",
      "Found 17 headers in 'An Auto-Encoder to Reconstruct Structure with Cryo-EM Images via Theoretically Guaranteed Isometric Latent Space, and Its Application for Automatically Computing the Conformational Pathway'\n",
      "Found 13 headers in 'Pick the Best Pre-trained Model: Towards Transferability Estimation for Medical Image Segmentation'\n",
      "Found 18 headers in 'Modeling Alzheimers’ Disease Progression from Multi-task and Self-supervised Learning Perspective with Brain Networks'\n",
      "Found 16 headers in 'vox2vec: A Framework for Self-supervised Contrastive Learning of Voxel-Level Representations in Medical Images'\n",
      "Found 21 headers in 'Multi-Target Domain Adaptation with Prompt Learning for Medical Image Segmentation'\n",
      "Found 22 headers in 'Spectral Adversarial MixUp for Few-Shot Unsupervised Domain Adaptation'\n",
      "Found 13 headers in 'UOD: Universal One-Shot Detection of Anatomical Landmarks'\n",
      "Found 14 headers in 'Source-Free Domain Adaptive Fundus Image Segmentation with Class-Balanced Mean Teacher'\n",
      "Found 24 headers in 'MedGen3D: A Deep Generative Framework for Paired 3D Image and Mask Generation'\n",
      "Found 14 headers in 'PET Image Denoising with Score-Based Diffusion Probabilistic Models'\n",
      "Found 18 headers in 'CL-ADDA: Contrastive Learning with Amplitude-Driven Data Augmentation for fMRI-Based Individualized Predictions'\n",
      "Found 10 headers in 'Cross-Dataset Adaptation for Instrument Classification in Cataract Surgery Videos'\n",
      "Found 18 headers in 'Gall Bladder Cancer Detection from US Images with only Image Level Labels'\n",
      "Found 18 headers in 'Structured State Space Models for Multiple Instance Learning in Digital Pathology'\n",
      "Found 17 headers in 'Automatic Retrieval of Corresponding US Views in Longitudinal Examinations'\n",
      "Found 17 headers in 'Multi-scale Self-Supervised Learning for Longitudinal Lesion Tracking with Optional Supervision'\n",
      "Found 17 headers in 'Geometry-Invariant Abnormality Detection'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Header Number</th>\n",
       "      <th>Header Title</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMAE: Adaptation of Pre-trained Masked Autoenc...</td>\n",
       "      <td>1</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>To reduce radiologists' reading burden and mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMAE: Adaptation of Pre-trained Masked Autoenc...</td>\n",
       "      <td>2</td>\n",
       "      <td>Method</td>\n",
       "      <td>Notation. We first formally define the problem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMAE: Adaptation of Pre-trained Masked Autoenc...</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Stage 1-Proxy Task to Detect Synthetic Anomalies</td>\n",
       "      <td>AMAE starts the first training stage using onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMAE: Adaptation of Pre-trained Masked Autoenc...</td>\n",
       "      <td>2.2</td>\n",
       "      <td>Stage 2-MAE Inter-Discrepancy Adaptation</td>\n",
       "      <td>The proposed MAE adaptation scheme is inspired...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMAE: Adaptation of Pre-trained Masked Autoenc...</td>\n",
       "      <td>3</td>\n",
       "      <td>Experiments</td>\n",
       "      <td>Datasets. We evaluated our method on three pub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>Geometry-Invariant Abnormality Detection</td>\n",
       "      <td>None</td>\n",
       "      <td>Fig. 2 .</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>Geometry-Invariant Abnormality Detection</td>\n",
       "      <td>None</td>\n",
       "      <td>Fig. 3 .</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>Geometry-Invariant Abnormality Detection</td>\n",
       "      <td>None</td>\n",
       "      <td>Fig. 4 .</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>Geometry-Invariant Abnormality Detection</td>\n",
       "      <td>None</td>\n",
       "      <td>Table 1 .</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>Geometry-Invariant Abnormality Detection</td>\n",
       "      <td>None</td>\n",
       "      <td>Supplementary Information</td>\n",
       "      <td>The online version contains supplementary mate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1184 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Paper Title Header Number  \\\n",
       "0     AMAE: Adaptation of Pre-trained Masked Autoenc...             1   \n",
       "1     AMAE: Adaptation of Pre-trained Masked Autoenc...             2   \n",
       "2     AMAE: Adaptation of Pre-trained Masked Autoenc...           2.1   \n",
       "3     AMAE: Adaptation of Pre-trained Masked Autoenc...           2.2   \n",
       "4     AMAE: Adaptation of Pre-trained Masked Autoenc...             3   \n",
       "...                                                 ...           ...   \n",
       "1179           Geometry-Invariant Abnormality Detection          None   \n",
       "1180           Geometry-Invariant Abnormality Detection          None   \n",
       "1181           Geometry-Invariant Abnormality Detection          None   \n",
       "1182           Geometry-Invariant Abnormality Detection          None   \n",
       "1183           Geometry-Invariant Abnormality Detection          None   \n",
       "\n",
       "                                          Header Title  \\\n",
       "0                                         Introduction   \n",
       "1                                               Method   \n",
       "2     Stage 1-Proxy Task to Detect Synthetic Anomalies   \n",
       "3             Stage 2-MAE Inter-Discrepancy Adaptation   \n",
       "4                                          Experiments   \n",
       "...                                                ...   \n",
       "1179                                          Fig. 2 .   \n",
       "1180                                          Fig. 3 .   \n",
       "1181                                          Fig. 4 .   \n",
       "1182                                         Table 1 .   \n",
       "1183                         Supplementary Information   \n",
       "\n",
       "                                                   Text  \n",
       "0     To reduce radiologists' reading burden and mak...  \n",
       "1     Notation. We first formally define the problem...  \n",
       "2     AMAE starts the first training stage using onl...  \n",
       "3     The proposed MAE adaptation scheme is inspired...  \n",
       "4     Datasets. We evaluated our method on three pub...  \n",
       "...                                                 ...  \n",
       "1179                                                     \n",
       "1180                                                     \n",
       "1181                                                     \n",
       "1182                                                     \n",
       "1183  The online version contains supplementary mate...  \n",
       "\n",
       "[1184 rows x 4 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "\n",
    "def parse_xml_and_extract_headers(file_path):\n",
    "    tree = etree.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    ns = {'tei': 'http://www.tei-c.org/ns/1.0'}\n",
    "\n",
    "    # Extract the paper title by XPath in the XML's structure\n",
    "    paper_title_element = root.find('.//tei:title', ns)\n",
    "    paper_title = paper_title_element.text if paper_title_element is not None else \"No Title Found\"\n",
    "\n",
    "    headers = root.xpath('//tei:head', namespaces=ns)\n",
    "    print(f\"Found {len(headers)} headers in '{paper_title}'\")\n",
    "    \n",
    "    data = []\n",
    "    for header in headers:\n",
    "        text = ' '.join([p.text for p in header.getparent().findall('tei:p', ns) if p.text])\n",
    "        data.append({\n",
    "            'Paper Title': paper_title,  # Include the paper title in each row\n",
    "            'Header Number': header.get('n'),\n",
    "            'Header Title': header.text,\n",
    "            'Text': text\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['Paper Title', 'Header Number', 'Header Title', 'Text'])\n",
    "    return df\n",
    "\n",
    "def process_xml_folder(folder_path):\n",
    "    all_data_frames = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".xml\"):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            df = parse_xml_and_extract_headers(file_path)\n",
    "            all_data_frames.append(df)\n",
    "\n",
    "    if all_data_frames:\n",
    "        final_df = pd.concat(all_data_frames, ignore_index=True)\n",
    "    else:\n",
    "        final_df = pd.DataFrame()\n",
    "\n",
    "    return final_df\n",
    "\n",
    "# Folder path - where XML files should be stored (gets updated for each volume path)\n",
    "folder_path = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/vol01'\n",
    "\n",
    "# Process the folder and create a DataFrame with all headers\n",
    "df_headers = process_xml_folder(folder_path)\n",
    "df_headers.to_csv(\"/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/vol1_headers.csv\", index=False)\n",
    "df_headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check to see if titles are missing from the volume in the current dataframe \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_headers['Paper Title'].unique())\n",
    "#df_headers['Paper Title'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing dataframes for all 10 volumes within a dictionary\n",
    "***\n",
    "- Cleaning rows by removing non-relevant rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_xml_folder(folder_path):\n",
    "    df = pd.read_csv(folder_path)\n",
    "    return df\n",
    "\n",
    "def clean_dataframe(df):\n",
    "    # Remove rows where both 'Header Title' and 'Text' are NaN or just 'Text' is NaN\n",
    "    df_cleaned = df.dropna(subset=['Header Title', 'Text'], how='all')\n",
    "    df_cleaned = df_cleaned.dropna(subset=['Text'], how='any')\n",
    "    return df_cleaned\n",
    "\n",
    "# Base path where all processed volumes are stored\n",
    "base_path = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/papers_xml/originals_dfs'\n",
    "\n",
    "# Dictionary to store cleaned DataFrames\n",
    "cleaned_dataframes = {}\n",
    "\n",
    "# Loop over the volume directories\n",
    "for i in range(1, 11):\n",
    "    vol_path = os.path.join(base_path, f'vol{str(i)}_headers.csv')\n",
    "    df_headers = process_xml_folder(vol_path)\n",
    "    df_cleaned = clean_dataframe(df_headers)\n",
    "    \n",
    "    # Store the cleaned DataFrame in the dictionary with the volume number as the key\n",
    "    cleaned_dataframes[f'vol{str(i)}'] = df_cleaned\n",
    "\n",
    "# Dictionary with all cleaned DataFrames\n",
    "# cleaned_dataframes['vol1'], cleaned_dataframes['vol2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Header Number</th>\n",
       "      <th>Header Title</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMAE: Adaptation of Pre-trained Masked Autoenc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>To reduce radiologists' reading burden and mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMAE: Adaptation of Pre-trained Masked Autoenc...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Method</td>\n",
       "      <td>Notation. We first formally define the problem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMAE: Adaptation of Pre-trained Masked Autoenc...</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Stage 1-Proxy Task to Detect Synthetic Anomalies</td>\n",
       "      <td>AMAE starts the first training stage using onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMAE: Adaptation of Pre-trained Masked Autoenc...</td>\n",
       "      <td>2.2</td>\n",
       "      <td>Stage 2-MAE Inter-Discrepancy Adaptation</td>\n",
       "      <td>The proposed MAE adaptation scheme is inspired...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMAE: Adaptation of Pre-trained Masked Autoenc...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Experiments</td>\n",
       "      <td>Datasets. We evaluated our method on three pub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>Geometry-Invariant Abnormality Detection</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Transformer Spatial Conditioning</td>\n",
       "      <td>Numerous approaches have used Transformers in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>Geometry-Invariant Abnormality Detection</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Data</td>\n",
       "      <td>For this work we leveraged whole-body PET/CT d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>Geometry-Invariant Abnormality Detection</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Results</td>\n",
       "      <td>The proposed model was trained on the data des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>Geometry-Invariant Abnormality Detection</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Conclusion</td>\n",
       "      <td>Detection and segmentation of anomalous region...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>Geometry-Invariant Abnormality Detection</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Supplementary Information</td>\n",
       "      <td>The online version contains supplementary mate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Paper Title  Header Number  \\\n",
       "0     AMAE: Adaptation of Pre-trained Masked Autoenc...            1.0   \n",
       "1     AMAE: Adaptation of Pre-trained Masked Autoenc...            2.0   \n",
       "2     AMAE: Adaptation of Pre-trained Masked Autoenc...            2.1   \n",
       "3     AMAE: Adaptation of Pre-trained Masked Autoenc...            2.2   \n",
       "4     AMAE: Adaptation of Pre-trained Masked Autoenc...            3.0   \n",
       "...                                                 ...            ...   \n",
       "1174           Geometry-Invariant Abnormality Detection            3.2   \n",
       "1175           Geometry-Invariant Abnormality Detection            3.3   \n",
       "1176           Geometry-Invariant Abnormality Detection            4.0   \n",
       "1177           Geometry-Invariant Abnormality Detection            5.0   \n",
       "1183           Geometry-Invariant Abnormality Detection            NaN   \n",
       "\n",
       "                                          Header Title  \\\n",
       "0                                         Introduction   \n",
       "1                                               Method   \n",
       "2     Stage 1-Proxy Task to Detect Synthetic Anomalies   \n",
       "3             Stage 2-MAE Inter-Discrepancy Adaptation   \n",
       "4                                          Experiments   \n",
       "...                                                ...   \n",
       "1174                  Transformer Spatial Conditioning   \n",
       "1175                                              Data   \n",
       "1176                                           Results   \n",
       "1177                                        Conclusion   \n",
       "1183                         Supplementary Information   \n",
       "\n",
       "                                                   Text  \n",
       "0     To reduce radiologists' reading burden and mak...  \n",
       "1     Notation. We first formally define the problem...  \n",
       "2     AMAE starts the first training stage using onl...  \n",
       "3     The proposed MAE adaptation scheme is inspired...  \n",
       "4     Datasets. We evaluated our method on three pub...  \n",
       "...                                                 ...  \n",
       "1174  Numerous approaches have used Transformers in ...  \n",
       "1175  For this work we leveraged whole-body PET/CT d...  \n",
       "1176  The proposed model was trained on the data des...  \n",
       "1177  Detection and segmentation of anomalous region...  \n",
       "1183  The online version contains supplementary mate...  \n",
       "\n",
       "[690 rows x 4 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataframes['vol1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataframes['vol1'].to_csv(\"/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/dfs/vol1_cleaned.csv\", index=False)\n",
    "cleaned_dataframes['vol2'].to_csv(\"/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/dfs/vol2_cleaned.csv\", index=False)\n",
    "cleaned_dataframes['vol3'].to_csv(\"/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/dfs/vol3_cleaned.csv\", index=False)\n",
    "cleaned_dataframes['vol4'].to_csv(\"/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/dfs/vol4_cleaned.csv\", index=False)\n",
    "cleaned_dataframes['vol5'].to_csv(\"/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/dfs/vol5_cleaned.csv\", index=False)\n",
    "cleaned_dataframes['vol6'].to_csv(\"/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/dfs/vol6_cleaned.csv\", index=False)\n",
    "cleaned_dataframes['vol7'].to_csv(\"/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/dfs/vol7_cleaned.csv\", index=False)\n",
    "cleaned_dataframes['vol8'].to_csv(\"/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/dfs/vol8_cleaned.csv\", index=False)\n",
    "cleaned_dataframes['vol9'].to_csv(\"/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/dfs/vol9_cleaned.csv\", index=False)\n",
    "cleaned_dataframes['vol10'].to_csv(\"/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/dfs/vol10_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking to see if papers per volume are missing after cleaning the dataframes\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total papers in 1: 73\n",
      "total papers in 2: 73\n",
      "total papers in 3: 72\n",
      "total papers in 4: 75\n",
      "total papers in 5: 76\n",
      "total papers in 6: 77\n",
      "total papers in 7: 75\n",
      "total papers in 8: 65\n",
      "total papers in 9: 70\n",
      "total papers in 10: 74\n"
     ]
    }
   ],
   "source": [
    "print('total papers in 1:', len(cleaned_dataframes['vol1']['Paper Title'].unique())) # 73\n",
    "print('total papers in 2:', len(cleaned_dataframes['vol2']['Paper Title'].unique())) # 73 \n",
    "print('total papers in 3:', len(cleaned_dataframes['vol3']['Paper Title'].unique())) # 72 \n",
    "print('total papers in 4:', len(cleaned_dataframes['vol4']['Paper Title'].unique())) # 75 \n",
    "print('total papers in 5:', len(cleaned_dataframes['vol5']['Paper Title'].unique())) # 76 \n",
    "print('total papers in 6:', len(cleaned_dataframes['vol6']['Paper Title'].unique())) # 77 \n",
    "print('total papers in 7:', len(cleaned_dataframes['vol7']['Paper Title'].unique())) # 75 \n",
    "print('total papers in 8:', len(cleaned_dataframes['vol8']['Paper Title'].unique())) # 65 \n",
    "print('total papers in 9:', len(cleaned_dataframes['vol9']['Paper Title'].unique())) # 70\n",
    "print('total papers in 10:', len(cleaned_dataframes['vol10']['Paper Title'].unique())) # 74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Header Number</th>\n",
       "      <th>Header Title</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMAE: Adaptation of Pre-trained Masked Autoenc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>To reduce radiologists' reading burden and mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMAE: Adaptation of Pre-trained Masked Autoenc...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Method</td>\n",
       "      <td>Notation. We first formally define the problem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMAE: Adaptation of Pre-trained Masked Autoenc...</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Stage 1-Proxy Task to Detect Synthetic Anomalies</td>\n",
       "      <td>AMAE starts the first training stage using onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMAE: Adaptation of Pre-trained Masked Autoenc...</td>\n",
       "      <td>2.2</td>\n",
       "      <td>Stage 2-MAE Inter-Discrepancy Adaptation</td>\n",
       "      <td>The proposed MAE adaptation scheme is inspired...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMAE: Adaptation of Pre-trained Masked Autoenc...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Experiments</td>\n",
       "      <td>Datasets. We evaluated our method on three pub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6794</th>\n",
       "      <td>LightNeuS: Neural Surface Reconstruction in En...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Using Illumination Decline as a Depth Cue</td>\n",
       "      <td>The NeuS formulation of Sect. 2 assumes distan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6795</th>\n",
       "      <td>LightNeuS: Neural Surface Reconstruction in En...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Endoscope Photometric Model</td>\n",
       "      <td>Apart from illumination decline, there are sev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6796</th>\n",
       "      <td>LightNeuS: Neural Surface Reconstruction in En...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Experiments</td>\n",
       "      <td>We validate our method on the C3VD dataset  Du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6797</th>\n",
       "      <td>LightNeuS: Neural Surface Reconstruction in En...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Conclusion</td>\n",
       "      <td>We have presented a method for 3D dense multi-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6798</th>\n",
       "      <td>LightNeuS: Neural Surface Reconstruction in En...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Supplementary Information</td>\n",
       "      <td>The online version contains supplementary mate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6799 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Paper Title Header Number  \\\n",
       "0     AMAE: Adaptation of Pre-trained Masked Autoenc...           1.0   \n",
       "1     AMAE: Adaptation of Pre-trained Masked Autoenc...           2.0   \n",
       "2     AMAE: Adaptation of Pre-trained Masked Autoenc...           2.1   \n",
       "3     AMAE: Adaptation of Pre-trained Masked Autoenc...           2.2   \n",
       "4     AMAE: Adaptation of Pre-trained Masked Autoenc...           3.0   \n",
       "...                                                 ...           ...   \n",
       "6794  LightNeuS: Neural Surface Reconstruction in En...           3.1   \n",
       "6795  LightNeuS: Neural Surface Reconstruction in En...           3.2   \n",
       "6796  LightNeuS: Neural Surface Reconstruction in En...           4.0   \n",
       "6797  LightNeuS: Neural Surface Reconstruction in En...           5.0   \n",
       "6798  LightNeuS: Neural Surface Reconstruction in En...           NaN   \n",
       "\n",
       "                                          Header Title  \\\n",
       "0                                         Introduction   \n",
       "1                                               Method   \n",
       "2     Stage 1-Proxy Task to Detect Synthetic Anomalies   \n",
       "3             Stage 2-MAE Inter-Discrepancy Adaptation   \n",
       "4                                          Experiments   \n",
       "...                                                ...   \n",
       "6794         Using Illumination Decline as a Depth Cue   \n",
       "6795                       Endoscope Photometric Model   \n",
       "6796                                       Experiments   \n",
       "6797                                        Conclusion   \n",
       "6798                         Supplementary Information   \n",
       "\n",
       "                                                   Text  \n",
       "0     To reduce radiologists' reading burden and mak...  \n",
       "1     Notation. We first formally define the problem...  \n",
       "2     AMAE starts the first training stage using onl...  \n",
       "3     The proposed MAE adaptation scheme is inspired...  \n",
       "4     Datasets. We evaluated our method on three pub...  \n",
       "...                                                 ...  \n",
       "6794  The NeuS formulation of Sect. 2 assumes distan...  \n",
       "6795  Apart from illumination decline, there are sev...  \n",
       "6796  We validate our method on the C3VD dataset  Du...  \n",
       "6797  We have presented a method for 3D dense multi-...  \n",
       "6798  The online version contains supplementary mate...  \n",
       "\n",
       "[6799 rows x 4 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all the dataframes into a single dataframe\n",
    "combined_df = pd.concat(cleaned_dataframes.values(), ignore_index=True)\n",
    "\n",
    "# Now combined_df is a single DataFrame containing all the data from the individual volumes\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select papers related to cancer\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Header Number</th>\n",
       "      <th>Header Title</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMAE: Adaptation of Pre-trained Masked Autoenc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>to reduce radiologists' reading burden and mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMAE: Adaptation of Pre-trained Masked Autoenc...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Method</td>\n",
       "      <td>notation. we first formally define the problem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMAE: Adaptation of Pre-trained Masked Autoenc...</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Stage 1-Proxy Task to Detect Synthetic Anomalies</td>\n",
       "      <td>amae starts the first training stage using onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMAE: Adaptation of Pre-trained Masked Autoenc...</td>\n",
       "      <td>2.2</td>\n",
       "      <td>Stage 2-MAE Inter-Discrepancy Adaptation</td>\n",
       "      <td>the proposed mae adaptation scheme is inspired...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMAE: Adaptation of Pre-trained Masked Autoenc...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Experiments</td>\n",
       "      <td>datasets. we evaluated our method on three pub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6794</th>\n",
       "      <td>LightNeuS: Neural Surface Reconstruction in En...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Using Illumination Decline as a Depth Cue</td>\n",
       "      <td>the neus formulation of sect. 2 assumes distan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6795</th>\n",
       "      <td>LightNeuS: Neural Surface Reconstruction in En...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Endoscope Photometric Model</td>\n",
       "      <td>apart from illumination decline, there are sev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6796</th>\n",
       "      <td>LightNeuS: Neural Surface Reconstruction in En...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Experiments</td>\n",
       "      <td>we validate our method on the c3vd dataset  du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6797</th>\n",
       "      <td>LightNeuS: Neural Surface Reconstruction in En...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Conclusion</td>\n",
       "      <td>we have presented a method for 3d dense multi-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6798</th>\n",
       "      <td>LightNeuS: Neural Surface Reconstruction in En...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Supplementary Information</td>\n",
       "      <td>the online version contains supplementary mate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6799 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Paper Title Header Number  \\\n",
       "0     AMAE: Adaptation of Pre-trained Masked Autoenc...           1.0   \n",
       "1     AMAE: Adaptation of Pre-trained Masked Autoenc...           2.0   \n",
       "2     AMAE: Adaptation of Pre-trained Masked Autoenc...           2.1   \n",
       "3     AMAE: Adaptation of Pre-trained Masked Autoenc...           2.2   \n",
       "4     AMAE: Adaptation of Pre-trained Masked Autoenc...           3.0   \n",
       "...                                                 ...           ...   \n",
       "6794  LightNeuS: Neural Surface Reconstruction in En...           3.1   \n",
       "6795  LightNeuS: Neural Surface Reconstruction in En...           3.2   \n",
       "6796  LightNeuS: Neural Surface Reconstruction in En...           4.0   \n",
       "6797  LightNeuS: Neural Surface Reconstruction in En...           5.0   \n",
       "6798  LightNeuS: Neural Surface Reconstruction in En...           NaN   \n",
       "\n",
       "                                          Header Title  \\\n",
       "0                                         Introduction   \n",
       "1                                               Method   \n",
       "2     Stage 1-Proxy Task to Detect Synthetic Anomalies   \n",
       "3             Stage 2-MAE Inter-Discrepancy Adaptation   \n",
       "4                                          Experiments   \n",
       "...                                                ...   \n",
       "6794         Using Illumination Decline as a Depth Cue   \n",
       "6795                       Endoscope Photometric Model   \n",
       "6796                                       Experiments   \n",
       "6797                                        Conclusion   \n",
       "6798                         Supplementary Information   \n",
       "\n",
       "                                                   Text  \n",
       "0     to reduce radiologists' reading burden and mak...  \n",
       "1     notation. we first formally define the problem...  \n",
       "2     amae starts the first training stage using onl...  \n",
       "3     the proposed mae adaptation scheme is inspired...  \n",
       "4     datasets. we evaluated our method on three pub...  \n",
       "...                                                 ...  \n",
       "6794  the neus formulation of sect. 2 assumes distan...  \n",
       "6795  apart from illumination decline, there are sev...  \n",
       "6796  we validate our method on the c3vd dataset  du...  \n",
       "6797  we have presented a method for 3d dense multi-...  \n",
       "6798  the online version contains supplementary mate...  \n",
       "\n",
       "[6799 rows x 4 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lowercase all text in the 'Text' column\n",
    "combined_df['Text'] = combined_df['Text'].str.lower()\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173\n"
     ]
    }
   ],
   "source": [
    "# Search for papers related to cancer\n",
    "df_cancer_related = combined_df[combined_df['Text'].str.contains('cancer|tumor|tumour')]\n",
    "\n",
    "# Extract unique paper titles from these rows\n",
    "unique_paper_titles_with_cancer = df_cancer_related['Paper Title'].unique()\n",
    "\n",
    "# The total number of unique papers related to cancer\n",
    "print(len(unique_paper_titles_with_cancer))\n",
    "#df_cancer_related.to_csv(\"/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/databases/cancer_related_papers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract keyword-related sentences from selected papers\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['age', 'gender', 'sex', 'women', 'woman', 'female', 'male',\n",
    "            'geolocation', 'geographical', 'geographic', 'country', 'countries', 'city', 'cities', \n",
    "            'hospital', 'hospitals', 'clinic', 'clinics', 'society', 'societies',\n",
    "            'etnicity', 'etnicities', 'race', \n",
    "            'bias', 'biases', 'fair', 'unfair', 'fairness', 'transparency', 'awareness',\n",
    "            'imbalance', 'imbalanced', 'balance', 'balanced',\n",
    "            'problem', 'problems', 'issue', 'issues', 'challenge', 'challenges', \n",
    "            'difficult', 'difficulty', 'difficulties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and clean text data for keyword search (lowercase, remove punctuation, etc.)\n",
    "# Split the text into words and search for the keywords or split the text into sentences and search for the keywords\n",
    "# Add a new column to the DataFrame with the keyword search results\n",
    "\n",
    "# Simple text processing techniques\n",
    "def clean_text(text):\n",
    "    # Lowercase the text\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text_no_punct = text_lower.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    return text_no_punct"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
