<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Evolutionary Normalization Optimization Boosts Semantic Segmentation Network Performance</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Luisa</forename><surname>Neubig</surname></persName>
							<email>luisa.e.neubig@fau.de</email>
							<idno type="ORCID">0000-0001-5202-7158</idno>
							<affiliation key="aff0">
								<orgName type="department">Department Artificial Intelligence in Biomedical Engineering</orgName>
								<orgName type="institution">Friedrich-Alexander-Universität Erlangen-Nürnberg (FAU)</orgName>
								<address>
									<settlement>Erlangen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andreas</forename><forename type="middle">M</forename><surname>Kist</surname></persName>
							<email>andreas.kist@fau.de</email>
							<idno type="ORCID">0000-0003-3643-7776</idno>
							<affiliation key="aff0">
								<orgName type="department">Department Artificial Intelligence in Biomedical Engineering</orgName>
								<orgName type="institution">Friedrich-Alexander-Universität Erlangen-Nürnberg (FAU)</orgName>
								<address>
									<settlement>Erlangen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Evolutionary Normalization Optimization Boosts Semantic Segmentation Network Performance</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="703" to="712"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">AC536F0EB837316D9A6E4AB2CEC1563F</idno>
					<idno type="DOI">10.1007/978-3-031-43901-8_67</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-23T22:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Semantic segmentation</term>
					<term>Normalization</term>
					<term>Evolutionary Algorithm</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Semantic segmentation is an important task in medical imaging. Typically, encoder-decoder architectures, such as the U-Net, are used in various variants to approach this task. Normalization methods, such as Batch or Instance Normalization are used throughout the architectures to adapt to data-specific noise. However, it is barely investigated which normalization method is most suitable for a given dataset and if a combination of those is beneficial for the overall performance. In this work, we show that by using evolutionary algorithms we can fully automatically select the best set of normalization methods, outperforming any competitive single normalization method baseline. We provide insights into the selection of normalization and how this compares across imaging modalities and datasets. Overall, we propose that normalization should be managed carefully during the development of the most recent semantic segmentation models as it has a significant impact on medical image analysis tasks, contributing to a more efficient analysis of medical data. Our code is openly available at https://github.com/neuluna/evoNMS.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Semantic segmentation, i.e., assigning a semantic label to each pixel in an image, is a common task in medical computer vision nowadays typically performed by fully convolutional encoder-decoder deep neural networks (DNNs). These DNNs usually incorporate some kind of normalization layers which are thought to reduce the impact of the internal covariate shift (ICS) <ref type="bibr" target="#b5">[6]</ref>. This effect describes the adaption to small changes in the feature maps of deeper layers rather than learning the real representation of the target structures <ref type="bibr" target="#b20">[21]</ref>. The understanding of Batch Normalization (BN) is very controversial, namely that its actual success is to use higher learning rates by smoothing the objective function instead of reducing the ICS <ref type="bibr" target="#b1">[2]</ref>. Instance Normalization (IN), Layer Normalization <ref type="bibr">(LN)</ref> and Group Normalization (GN) are examples of developments of BN to overcome its shortcomings, like reduced performance using smaller batch sizes <ref type="bibr" target="#b1">[2]</ref>. As an alternative, Scaled Exponential Linear Units (SELUs) can act as selfnormalization activation functions <ref type="bibr" target="#b8">[9]</ref>. All normalization methods have different strengths and weaknesses, which influence the performance and generalizability of the network. Commonly, only a single normalization method is used throughout the network, and studies involving multiple normalization methods are rare.</p><p>Neural architecture search (NAS) is a strategy to tweak a neural architecture as such to discover efficient combinations of architectural building blocks for optimal performance on given datasets and tasks <ref type="bibr" target="#b11">[12]</ref>. NAS strategies involve, for example, evolutionary algorithms to optimize an objective function by evaluating a set of candidate architectures and selecting the "fittest" architectures for breeding <ref type="bibr" target="#b11">[12]</ref>. After several generations of training, selection, and breeding, the objective function of the evolutionary algorithm should be maximized.</p><p>In this study, we propose a novel evolutionary NAS approach to increase semantic segmentation performance by optimizing the spatiotemporal usage of normalization methods in a baseline U-Net <ref type="bibr" target="#b16">[17]</ref>. Our study provides a uniquely and thorough analysis of the most effective layer-wise normalization configuration across medical datasets, rather than proposing a new normalization method. In the following, we refer to our proposed methodology as evoNMS (evolutionary Normalization Method Search).</p><p>We evaluated the performance of evoNMS on eleven biomedical segmentation datasets and compared it with a state-of-the-art semantic segmentation method (nnU-Net <ref type="bibr" target="#b6">[7]</ref>) and U-Nets with constant normalization such as BN, IN, and no normalization (NoN). Our analysis demonstrates that evoNMS discovers very effective network architectures for semantic segmentation, achieves better or similar performance to state-of-the-art architectures, and guides the selection of the best normalization method for a specific semantic segmentation task. In addition, we analyze the normalization pattern across datasets and modalities and compare the normalization methods regarding their layer-specific contribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Works</head><p>To gain optimal performance in semantic segmentation tasks, it is important to optimize data preprocessing and architectural design. Popat et al. <ref type="bibr" target="#b14">[15]</ref> and Wei et al. <ref type="bibr" target="#b18">[19]</ref> concurrently developed an evolutionary approach to determine the best-performing U-Net architecture variant, considering the depth, filter size, pooling type, kernel type, and optimizer as hyperparameter-genes coding for a specific U-Net phenotype. When applied to retinal vessel segmentation, both showed that their approach finds a smaller U-Net configuration while achieving competitive performance with state-of-the-art architectures. Liu et al. <ref type="bibr" target="#b9">[10]</ref> proved that not only the architecture has a huge impact on the generalizability of a neural network, but also the combination of normalization.</p><p>Various studies show that neural networks (NNs) benefit from normalization to enhance task performance, generalizability, and convergence behavior. Zhou et al. <ref type="bibr" target="#b21">[22]</ref> showed the benefit of batch normalization, which focuses on the data bias in the latent space by introducing a dual normalization for better domain generalization. Dual normalization estimates the distribution from source-similar and source-dissimilar domains and achieves a more robust model for domain generalization. Domain-independent normalization also helps to improve unsupervised adversarial domain adaptation for improved generalization capability as shown in <ref type="bibr" target="#b15">[16]</ref>. In <ref type="bibr" target="#b20">[21]</ref>, the authors analyzed the influence of different normalization methods, such as BN, IN, LN, and GN. Although many segmentation networks rely on BN, they recommend using normalization by dividing feature maps, such as GN (with a higher number of groups) or IN <ref type="bibr" target="#b20">[21]</ref>. Normalization methods have been well discussed in the literature <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b19">20]</ref>. In a systematic review, Huang et al. <ref type="bibr" target="#b4">[5]</ref> concluded that normalizing the activations is more efficient than normalizing the weights. In addition to the efficiency of normalizing the activations, Luo et al. <ref type="bibr" target="#b12">[13]</ref> demonstrated a synergistic effect of their advantages by introducing switchable normalization (SN). SN alternates between the normalization strategies IN, LN, and BN according to their respective importance weights <ref type="bibr" target="#b12">[13]</ref>. With an evolutionary approach, Liu et al. <ref type="bibr" target="#b10">[11]</ref> also showed that the combination of normalization and activation functions improves the performance of the NN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head><p>We investigated the impact of normalization on semantic segmentation using eleven different medical image datasets. Eight datasets were derived from the Medical Segmentation Decathlon (MSD) <ref type="bibr" target="#b0">[1]</ref>. In this study, we selected subsets for segmenting the hippocampus, heart, liver, lung, colon, spleen, pancreas, and hepatic vessels. We only considered the datasets with 3D volumes of the MSD. In addition, we used the BAGLS <ref type="bibr" target="#b3">[4]</ref> dataset (segmentation of glottal area), the Kvasir-SEG <ref type="bibr" target="#b7">[8]</ref> dataset (gastrointestinal polyp images), and an in-house dataset for bolus segmentation in videofluoroscopic swallowing studies (VFSS). Table <ref type="table" target="#tab_0">1</ref> lists the datasets used regarding their region of interest/organ, modality, number of segmented classes, and number of images. To minimize the differences between the datasets and to gain comparable results, all datasets were analyzed in 2D. The images were converted to grayscale images, resized, and cropped to a uniform size of 224 × 224 px. Their pixel intensity was normalized to a range from 0 to 1. The datasets were divided into training, validation, and test subsets, with percentages of 70%, 10%, and 20% for the BAGLS, Kvasir-SEG, and bolus datasets. If a test set was explicitly given, the split for training and validation was 80% and 20%, respectively.</p><p>We implemented our evolutionary optimization algorithm and the NN architectural design in TensorFlow 2.9.1/Keras 2.9.0 and executed our code on NVIDIA A100 GPUs. Each individual U-Net variant was trained for 20 epochs using the Adam optimizer, a constant learning rate of 1 × 10 -3 , and a batch size of 64. All segmentation tasks were optimized using the Dice Loss (DL). To evaluate the performance of the trained network, we calculated the Dice Coefficient (DC), Intersection over Union (IoU) of the fitted bounding boxes (BBIoU), and Hausdorff Distance with a percentile of 95% (HD95) of the validation set after  20 epochs. In addition, we included an early stopping criterion that is activated when the validation loss changes less than 0.1% to avoid unnecessary training time without further information gain. To compare our approach to state-of-theart segmentation networks, we considered nnU-Net <ref type="bibr" target="#b6">[7]</ref> as a baseline which was similarly trained as the above-mentioned U-Net variants.</p><p>Our proposed evoNMS approach is based on evolutionary optimization with leaderboard selection and is executed for 20 generations. Each generation's population consists of 20 individuals, i.e., U-Net variants, meaning that we train 400 variants for one evoNMS execution (duration 4 h (polyp) to 5 days (glottal area) on one A100 GPU). The first generation contains individuals with random sequences drawn from our gene pool containing either a BN, IN, FRN, GN2, GN4 layer or skips normalization (no normalization, NoN). Other U-Netspecific hyperparameters, such as initial filter size and activation functions were set across datasets to a fixed value (initial filter size of 16, and ReLU as activa-tion function). In general, we kept all other hyperparameters fixed to focus only on the influence of normalization and infer whether it exhibits decoder/encoder dependence or even dependence on the underlying modality. After training each architecture, the fitness F i (Eq. ( <ref type="formula" target="#formula_0">1</ref>)) is evaluated for each individual i</p><formula xml:id="formula_0">F i = 1 3 • (DC i + BBIoU i + 1 HD95 i ) , where 1 HD95 i ∈ [0, 1],<label>(1)</label></formula><p>where we compute the mean validation DC, validation IoU of the Bounding Box, and reciprocal of the validation HD95. We use the reciprocal of HD95 to balance the influence of each metric on the fitness value by a value ranging from 0 to 1.</p><p>After each generation, the top ten individuals with the highest fitness F were bred. To breed a new individual, we selected two random individuals from the top ten candidates and combined them with a randomly selected crossing point across the normalization layer arrays of the two parental gene pools. Next, we applied mutations at a rate of 10%, which basically changes the normalization method of a random position to any normalization technique available in the gene pool. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>We first evaluated the influence of different normalization methods on medicalimage segmentation. We report the performance of neural architectures defined by our proposed evoNMS, which followed an evolutionary approach to determine the potentially best normalization method for each bottleneck layer, at generations 1 and 20. For each dataset, we evaluated the DC across different baselines of our default U-Net implementation with a fixed normalization method across layers (BN, IN, or NoN) and a state-of-the-art semantic segmentation network (nnU-Net) against our proposed evoNMS approach. Table <ref type="table" target="#tab_1">2</ref> provides an overview of the mean validation DC as the main performance metric. Overall, the architecture configurations with solely IN (six datasets), nnU-Net (two datasets), or our proposed evoNMS (one first generation, four in the last generation) achieved the highest mean validation DC across all datasets. Noteworthy, our evoNMS approach achieved competitive performance across all datasets, which is clearly shown at the ranking in Table <ref type="table" target="#tab_1">2</ref>, where the last generation of our approach achieved the best grade of 1.72. The results of our evoNMS demonstrate that our approach achieves superior performance in terms of the average DC and BBIoU scores on the validation dataset and yields comparable results in terms of HD95 to the U-Net trained with IN. In contrast, architectures that rely on BN or NoN consistently produced poor results due to exploding gradients across multiple datasets ( <ref type="bibr" target="#b13">[14]</ref>), questioning the broad application of BN. When comparing qualitative results of all baselines and evoNMS, we find that our approach accurately reflects the ground truth across datasets, especially after several generations of optimization (Fig. <ref type="figure" target="#fig_1">2</ref>). We found that an evolutionary search without prior knowledge of the required hyperparameters and properties of the medical data can perform as well as, or in some cases, even better than, the best baseline of a U-net trained with IN or nnU-Net, showing the importance of normalization in semantic segmentation architectures.</p><p>We next were interested in the optimization behavior of evoNMS. We found that random initialization of normalization methods yielded poorly and highly variant converging behavior overall (Supplementary Fig. <ref type="figure" target="#fig_0">1</ref>). However, after evolutionary optimization, the converging behavior is clearly improved in terms of convergence stability and lower variability. In Supplementary Fig. <ref type="figure" target="#fig_1">2</ref>, we can exemplary show that evoNMS also improves all fitness-related metrics across generations. This highlights the ability of evoNMS to converge on multiple objectives. These findings suggest that our approach can also be used as a hyperparameter optimization problem to improve convergence behavior.</p><p>As we initialize the first population randomly, we determined whether the evoNMS algorithm converges to the same set of normalization methods for each dataset. We found for three independent evoNMS runs, that evoNMS converges for four out of eleven datasets on very similar patterns (Supplementary Fig. <ref type="figure" target="#fig_2">3</ref>) across runs, with an overall average correlation of 36.3%, indicating that our algorithm is able to find relatively quickly a decent solution for a given dataset. In the case of the polyp dataset, top evoNMS-performing networks correlate with a striking 61.1% (Supplementary Table <ref type="table" target="#tab_0">1</ref>).</p><p>We next identified the final distribution of normalization methods across the encoder and decoder U-Net layers to determine dataset-specific normalization. In Fig. <ref type="figure" target="#fig_2">3</ref>, we show the distribution of the top 10% performers in the last generation of evoNMS. We found consistent patterns across individuals especially in the last layer: in four out of eleven datasets, no normalization was preferred. In the colon dataset, the encoder was mainly dominated by IN, especially in the first encoding layer. In contrast, the decoder in the polyp, liver, and hippocampus datasets showed more consistency in the normalization methods suggesting that normalization methods could be encoder-and decoder-specific and are dataset dependent.  To understand good normalization design across datasets in semantic segmentation tasks, we determined which normalization methods are more abundant at specific U-Net layers. IN is across layers a preferred choice by evoNMS except for the last two decoding layers (Fig. <ref type="figure" target="#fig_3">4 A</ref> and<ref type="figure">B</ref>). Our results suggest that the latent space embedding heavily relies on IN (Fig. <ref type="figure" target="#fig_3">4 A</ref>). Other normalization methods are less abundant in top-performing architectures, such as FRN, BN, and LN. However, NoN is mainly used in the last layer. FRN and especially BN seem to be inferior choices in semantic segmentation architectures.</p><p>Finally, we investigated if any set of normalization methods can be derived by the imaging modality, such as endoscopy, CT and MRI. In Fig. <ref type="figure" target="#fig_3">4</ref>, we show the cross-correlation of all evoNMS top performers across datasets. In general, there are only weak correlations at the global level; a stronger correlation can be seen by correlating encoder and decoder separately (Supplementary Fig. <ref type="figure" target="#fig_2">3</ref>). These results provide evidence, that a priori knowledge of the imaging modality does not hint towards a specific normalization pattern but rather has to be optimized for any given dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion and Conclusion</head><p>Our approach shows that using normalization methods wisely has a powerful impact on biomedical image segmentation across a variety of datasets acquired using different imaging modalities. Due to its inherent property of always finding an optimal solution, evoNMS is potentially capable of providing the bestperforming set of normalization patterns for any given data set. For feasibility reasons, we considered only 20 epochs for each training set and 20 generations. However, we show that evoNMS with these constrained settings provides competitive results and outperforms or performs on par compared to all baselines.</p><p>Our results suggest the superior performance of IN and GN (Fig. <ref type="figure" target="#fig_3">4</ref>) as overall very useful normalization strategies when used at their preferred location, in contrast to FRN, BN, and LN. State-of-the-art architectures, such as nnU-Net also rely on IN throughout the network <ref type="bibr" target="#b6">[7]</ref>, as well as evolutionary optimized U-Net architectures <ref type="bibr" target="#b18">[19]</ref>. This established use of normalization confirms our findings for high-performing evoNMS networks and can be extrapolated to other semantic segmentation architectures that incorporate normalization methods. The advantage of evoNMS is its ability to also include non-learnable objectives, such as architectural scaling and reducing inference time, crucial for point-of-care solutions. In this study, we constrained the search space, but we will incorporate multiple hyperparameters in the future. On the other hand, approaches that use main building blocks and optimize mainly convolutional layer parameters and activation functions <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b18">19]</ref> would benefit from incorporating normalization strategies as well.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Process of evolutionary optimization of normalization layers in a U-Net architecture. The sequence of normalization layers was randomly determined for a population of 20 individuals in the first generation. After training each U-Net variant on a given task/dataset, its performance was evaluated using a fitness function based on BBIoU, DC, and HD95. Based on the fitness value, normalization sequences were selected to breed the population of the next generation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Qualitative comparison of baseline architectures and the proposed evoNMS approach. Each horizontal set shows exemplary performance for a given dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Visualization of the relative frequency of selected normalizations over the U-Net layer for all datasets. This average was calculated for all individuals in the last generation of each dataset.</figDesc><graphic coords="8,43,29,54,65,337,09,100,06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Visualization of the best normalization pattern in the last generation and the selection for each individual. A) Distribution of normalizations across U-Net layers and datasets. B) Relative frequency of normalization patterns. C) shows the normalization pattern correlation of U-Net variants with the highest fitness F for each dataset in the last generation. The boxes indicated the same imaging modality.</figDesc><graphic coords="8,233,88,215,12,96,52,101,56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Overview of different datasets regarding their medical objective, number of segmentation labels, modality, and number of train, validation, test images, and the average evoNMS wall time (Time).</figDesc><table><row><cell>Dataset</cell><cell>ROI</cell><cell cols="5">Labels Modality Train Validation Test</cell><cell>Time</cell></row><row><cell>BAGLS</cell><cell>Glottal Area</cell><cell>1</cell><cell cols="3">Endoscope 16,277 2,325</cell><cell>4,650 96 h</cell></row><row><cell cols="2">Kvasir-SEG Polyp</cell><cell>1</cell><cell cols="2">Endoscope 700</cell><cell>100</cell><cell>200</cell><cell>4 h</cell></row><row><cell>Bolus</cell><cell>Bolus</cell><cell>1</cell><cell>VFSS</cell><cell cols="2">7,931 1,133</cell><cell>2,266 39 h</cell></row><row><cell cols="2">Task02 MSD Heart</cell><cell>1</cell><cell>MRI</cell><cell cols="2">1,215 135</cell><cell>1,297 7 h</cell></row><row><cell cols="2">Task03 MSD Liver</cell><cell>2</cell><cell>CT</cell><cell cols="2">17,238 1,915</cell><cell>27,041 102 h</cell></row><row><cell cols="3">Task04 MSD Hippocampus 2</cell><cell>MRI</cell><cell cols="2">5,960 662</cell><cell>4,499 40 h</cell></row><row><cell cols="2">Task06 MSD Lung</cell><cell>1</cell><cell>CT</cell><cell cols="2">1,480 164</cell><cell>8,888 12 h</cell></row><row><cell cols="2">Task07 MSD Pancreas</cell><cell>2</cell><cell>CT</cell><cell cols="2">7,907 878</cell><cell>13,544 49 h</cell></row><row><cell cols="3">Task08 MSD Hepatic Vessel 2</cell><cell>CT</cell><cell cols="2">11,448 1,272</cell><cell>10,519 75 h</cell></row><row><cell cols="2">Task09 MSD Spleen</cell><cell>1</cell><cell>CT</cell><cell>945</cell><cell>105</cell><cell>1,327 12 h</cell></row><row><cell cols="2">Task10 MSD Colon</cell><cell>1</cell><cell>CT</cell><cell cols="2">1,152 128</cell><cell>6,616 8 h</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Overview of performance across datasets and normalization configurations.</figDesc><table><row><cell>Dataset</cell><cell cols="2">Labels BN</cell><cell>IN</cell><cell>NoN</cell><cell cols="3">nnU-Net Gen1 (Ours) Gen20 (Ours)</cell></row><row><cell>glottal area</cell><cell>1</cell><cell>0.919</cell><cell cols="2">0.933 0.005</cell><cell>0.862</cell><cell>0.928</cell><cell>0.931</cell></row><row><cell>polyp</cell><cell>1</cell><cell>0.251</cell><cell cols="2">0.639 0.442</cell><cell>0.804</cell><cell>0.672</cell><cell>0.704</cell></row><row><cell>bolus</cell><cell>1</cell><cell>0.833</cell><cell cols="2">0.841 0.000</cell><cell>0.829</cell><cell>0.836</cell><cell>0.838</cell></row><row><cell>heart</cell><cell>1</cell><cell>0.016</cell><cell cols="2">0.844 0.029</cell><cell>0.910</cell><cell>0.243</cell><cell>0.885</cell></row><row><cell>liver</cell><cell>2</cell><cell>0.898</cell><cell cols="2">0.932 0.350</cell><cell>0.656</cell><cell>0.918</cell><cell>0.921</cell></row><row><cell cols="2">hippocampus 2</cell><cell>0.819</cell><cell cols="2">0.829 0.503</cell><cell>0.786</cell><cell>0.829</cell><cell>0.829</cell></row><row><cell>lung</cell><cell>1</cell><cell>0.701</cell><cell cols="2">0.827 0.008</cell><cell>0.672</cell><cell>0.663</cell><cell>0.833</cell></row><row><cell>pancreas</cell><cell>2</cell><cell>0.653</cell><cell cols="2">0.722 0.031</cell><cell>0.429</cell><cell>0.689</cell><cell>0.695</cell></row><row><cell cols="2">hepatic vessel 2</cell><cell>0.482</cell><cell cols="2">0.721 0.000</cell><cell>0.474</cell><cell>0.718</cell><cell>0.716</cell></row><row><cell>spleen</cell><cell>1</cell><cell>0.054</cell><cell cols="2">0.786 0.223</cell><cell>0.934</cell><cell>0.920</cell><cell>0.953</cell></row><row><cell>colon</cell><cell>1</cell><cell>0.022</cell><cell cols="2">0.717 0.074</cell><cell>0.695</cell><cell>0.735</cell><cell>0.741</cell></row><row><cell>Ranking</cell><cell></cell><cell>4.64</cell><cell>2.00</cell><cell>5.63</cell><cell>3.82</cell><cell>2.91</cell><cell>1.72</cell></row><row><cell>DC (avg)</cell><cell></cell><cell>0.514</cell><cell cols="2">0.799 0.151</cell><cell>0.732</cell><cell>0.741</cell><cell>0.823</cell></row><row><cell>BBIoU (avg)</cell><cell></cell><cell>0.446</cell><cell cols="2">0.770 0.099</cell><cell>0.686</cell><cell>0.691</cell><cell>0.773</cell></row><row><cell>HD95 (avg)</cell><cell></cell><cell cols="4">185.992 4.121 367.448 7.802</cell><cell>94.599</cell><cell>4.323</cell></row></table><note><p>For multiclass segmentation, we define the highest validation DC as the mean across the segmentation labels. Each value is the mean value of five individual runs. For evoNMS, we selected the best normalization pattern w.r.t. the fitness value and trained this configuration five times. The ranking represents the average behavior of each network across the datasets (1-best, 6-worst). The bottom rows show the average behavior of each network across the eleven datasets regarding DC, BBIoU, and HD95 on the validation dataset.</p></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/978-3-031-43901-8 67.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The medical segmentation decathlon</title>
		<author>
			<persName><forename type="first">M</forename><surname>Antonelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Reinke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bakas</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-022-30695-9</idno>
		<ptr target="https://doi.org/10.1038/s41467-022-30695-9" />
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">4128</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Revisiting internal covariate shift for batch normalization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Awais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T B</forename><surname>Iqbal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Bae</surname></persName>
		</author>
		<idno type="DOI">10.1109/tnnls.2020.3026784</idno>
		<ptr target="https://doi.org/10.1109/tnnls.2020.3026784" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="5082" to="5092" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.1607.06450</idno>
		<idno>ARXIV.1607.06450</idno>
		<ptr target="https://doi.org/10.48550/" />
		<title level="m">Layer normalization</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Bagls, a multihospital benchmark for automatic glottis segmentation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Gómez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Kist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Schlegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Berry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Chhetri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dórr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Echternach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kniesburges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kunduk</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41597-020-0526-3</idno>
		<ptr target="https://doi.org/10.1038/s41597-020-0526-3" />
	</analytic>
	<monogr>
		<title level="j">Sci. Data</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">186</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2009.12836</idno>
		<ptr target="https://doi.org/10.48550/ARXIV.2009.12836" />
		<title level="m">Normalization techniques in training DNNs: methodology, analysis and application</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Batch normalization: accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.1502.03167</idno>
		<ptr target="https://doi.org/10.48550/ARXIV.1502.03167" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Isensee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A A</forename><surname>Kohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Maier-Hein</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41592-020-01008-z</idno>
		<ptr target="https://doi.org/10.1038/s41592-020-01008-z" />
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="211" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Kvasir-SEG: a segmented polyp dataset</title>
		<author>
			<persName><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-37734-2_37</idno>
		<idno>978-3-030-37734-2 37</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">MMM 2020</title>
		<editor>
			<persName><forename type="first">Y</forename><forename type="middle">M</forename><surname>Ro</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">11962</biblScope>
			<biblScope unit="page" from="451" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Self-normalizing neural networks</title>
		<author>
			<persName><forename type="first">G</forename><surname>Klambauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mayr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2017/file/5" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
	<note>d44ee6f2c3f71b73125876103c8f6c4-Paper.pdf</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Auto-DeepLab: hierarchical neural architecture search for semantic image segmentation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2019.00017</idno>
		<ptr target="https://doi.org/10.1109/CVPR.2019.00017" />
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="82" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Evolving normalization-activation layers</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2004.02967</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2004.02967" />
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="13539" to="13550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A survey on evolutionary neural architecture search</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Tan</surname></persName>
		</author>
		<idno type="DOI">10.1109/TNNLS.2021.3100554</idno>
		<ptr target="https://doi.org/10.1109/TNNLS.2021.3100554" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks Learn. Syst</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="550" to="570" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Differentiable learning-to-normalize via switchable normalization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.1806.10779</idno>
		<ptr target="https://doi.org/10.48550/ARXIV.1806.10779" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">The exploding gradient problem demystified -definition, prevalence, impact, origin, tradeoffs, and solutions</title>
		<author>
			<persName><forename type="first">G</forename><surname>Philipp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Carbonell</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.1712.05577</idno>
		<ptr target="https://doi.org/10.48550/ARXIV.1712.05577" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">GA-based U-Net architecture optimization applied to retina blood vessel segmentation</title>
		<author>
			<persName><forename type="first">V</forename><surname>Popat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mahdinejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Cedeño</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Naredo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ryan</surname></persName>
		</author>
		<idno type="DOI">10.5220/0010112201920199</idno>
		<ptr target="https://doi.org/10.5220/0010112201920199" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Joint Conference on Computational Intelligence</title>
		<meeting>the 12th International Joint Conference on Computational Intelligence</meeting>
		<imprint>
			<publisher>SCITEPRESS -Science and Technology Publications</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">A domain agnostic normalization layer for unsupervised adversarial domain adaptation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Romijnders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Meletis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dubbelman</surname></persName>
		</author>
		<idno type="DOI">10.1109/WACV.2019.00203</idno>
		<ptr target="https://doi.org/10.1109/WACV.2019.00203" />
		<imprint>
			<date type="published" when="2019-01">January 2019</date>
			<biblScope unit="page" from="1866" to="1875" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">U-Net: Convolutional Networks for Biomedical Image Segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-24574-4_28</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-24574-428" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2015</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hornegger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">9351</biblScope>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Filter response normalization layer: eliminating batch dependence in the training of deep neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Krishnan</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.1911.09737</idno>
		<ptr target="https://doi.org/10.48550/ARXIV.1911.09737" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Genetic U-Net: automatically designed deep networks for retinal vessel segmentation using a genetic algorithm</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<idno type="DOI">10.1109/TMI.2021.3111679</idno>
		<ptr target="https://doi.org/10.1109/TMI.2021.3111679" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="292" to="307" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Group normalization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-01261-8_1</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-01261-81" />
	</analytic>
	<monogr>
		<title level="m">ECCV 2018</title>
		<editor>
			<persName><forename type="first">V</forename><surname>Ferrari</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Hebert</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Sminchisescu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">11217</biblScope>
			<biblScope unit="page" from="3" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Normalization in training U-Net for 2-D biomedical semantic segmentation</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Z</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.1109/lra.2019.2896518</idno>
		<ptr target="https://doi.org/10.1109/lra.2019.2896518" />
	</analytic>
	<monogr>
		<title level="j">IEEE Robot. Autom. Lett</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1792" to="1799" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Generalizable cross-modality medical image segmentation via style augmentation and dual normalization</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR52688.2022.02019</idno>
		<ptr target="https://doi.org/10.1109/CVPR52688.2022.02019" />
	</analytic>
	<monogr>
		<title level="m">2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="20824" to="20833" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
