<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Category-Level Regularized Unlabeled-to-Labeled Learning for Semi-supervised Prostate Segmentation with Multi-site Unlabeled Data</title>
				<funder ref="#_E2ZVakp #_yr62Af4">
					<orgName type="full">National Key R&amp;D Program of China</orgName>
				</funder>
				<funder ref="#_YfD98Wt">
					<orgName type="full">General Research Fund from Research Grant Council of Hong Kong</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Nature Switzerland</publisher>
				<availability status="unknown"><p>Copyright Springer Nature Switzerland</p>
				</availability>
				<date type="published" when="2023">2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zhe</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Biomedical Engineering</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Donghuan</forename><surname>Lu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Tencent Healthcare Co</orgName>
								<address>
									<addrLine>Jarvis Lab</addrLine>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiangpeng</forename><surname>Yan</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Automation</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jinghan</forename><surname>Sun</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Xiamen University</orgName>
								<address>
									<settlement>Xiamen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jie</forename><surname>Luo</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">Harvard Medical School</orgName>
								<address>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dong</forename><surname>Wei</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Tencent Healthcare Co</orgName>
								<address>
									<addrLine>Jarvis Lab</addrLine>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sarah</forename><surname>Frisken</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">Harvard Medical School</orgName>
								<address>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Quanzheng</forename><surname>Li</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">Harvard Medical School</orgName>
								<address>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yefeng</forename><surname>Zheng</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Tencent Healthcare Co</orgName>
								<address>
									<addrLine>Jarvis Lab</addrLine>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Raymond Kai-Yu</forename><surname>Tong</surname></persName>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="laboratory">CPCL CCT CPS SSNet Local labeled Local unlabeled</orgName>
								<address>
									<postBox>45 50 55 60 65 70 75 80 SupOnly MT UA-MT ICT</postBox>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Category-Level Regularized Unlabeled-to-Labeled Learning for Semi-supervised Prostate Segmentation with Multi-site Unlabeled Data</title>
					</analytic>
					<monogr>
						<title level="m">Lecture Notes in Computer Science</title>
						<idno type="ISSN">0302-9743</idno>
						<idno type="eISSN">1611-3349</idno>
						<imprint>
							<publisher>Springer Nature Switzerland</publisher>
							<biblScope unit="page" from="3" to="13"/>
							<date type="published" when="2023" />
						</imprint>
					</monogr>
					<idno type="MD5">BEBFA19E5AC42A2C4BB35957A358BE88</idno>
					<idno type="DOI">10.1007/978-3-031-43901-8_1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-23T22:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Prostate segmentation</term>
					<term>Semi-supervised</term>
					<term>Heterogeneity</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Segmenting prostate from MRI is crucial for diagnosis and treatment planning of prostate cancer. Given the scarcity of labeled data in medical imaging, semi-supervised learning (SSL) presents an attractive option as it can utilize both limited labeled data and abundant unlabeled data. However, if the local center has limited image collection capability, there may also not be enough unlabeled data for semi-supervised learning to be effective. To overcome this issue, other partner centers can be consulted to help enrich the pool of unlabeled images, but this can result in data heterogeneity, which could hinder SSL that functions under the assumption of consistent data distribution. Tailoring for this important yet under-explored scenario, this work presents a novel Category-level regularized Unlabeled-to-Labeled (CU2L) learning framework for semisupervised prostate segmentation with multi-site unlabeled MRI data. Specifically, CU2L is built upon the teacher-student architecture with the following tailored learning processes: (i) local pseudo-label learning for reinforcing confirmation of the data distribution of the local center; (ii) category-level regularized non-parametric unlabeled-to-labeled learning for robustly mining shared information by using the limited expert labels to regularize the intra-class features across centers to be discriminative and generalized; (iii) stability learning under perturbations to further enhance robustness to heterogeneity. Our method is evaluated on prostate MRI data from six different clinical centers and shows superior performance compared to other semi-supervised methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-site semi-supervised learning (MS-SSL)</head><p>The unlabeled image pool can be quickly enriched via the support from partner clinical centers with low barriers of entry (only unlabeled images are required) Data heterogeneity due to different scanners, scanning protocols and subject groups, which violate the typical SSL assumption of i.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Prostate segmentation from magnetic resonance imaging (MRI) is a crucial step for diagnosis and treatment planning of prostate cancer. Recently, deep learningbased approaches have greatly improved the accuracy and efficiency of automatic prostate MRI segmentation <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>. Yet, their success usually requires a large amount of labeled medical data, which is expensive and expertise-demanding in practice. In this regard, semi-supervised learning (SSL) has emerged as an attractive option as it can leverage both limited labeled data and abundant unlabeled data <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b27">28]</ref>. Nevertheless, the effectiveness of SSL is heavily dependent on the quantity and quality of the unlabeled data.</p><p>Regarding quantity , the abundance of unlabeled data serves as a way to regularize the model and alleviate overfitting to the limited labeled data. Unfortunately, such "abundance" may be unobtainable in practice, i.e., the local unlabeled pool is also limited due to restricted image collection capabilities or scarce patient samples. As a specific case shown in Table <ref type="table" target="#tab_0">1</ref>, there are only limited prostate scans available per center. Taking C1 as a case study, if the amount of local unlabeled data is limited, existing SSL methods may still suffer from inferior performance when generalizing to unseen test data (Fig. <ref type="figure" target="#fig_0">1</ref>). To efficiently enrich the unlabeled pool, seeking support from other centers is a viable solution, as illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>. Yet, due to differences in imaging protocols and variations in patient demographics, this solution usually introduces data heterogeneity, lead-ing to a quality problem. Such heterogeneity may impede the performance of SSL which typically assumes that the distributions of labeled data and unlabeled data are independent and identically distributed (i.i.d.) <ref type="bibr" target="#b15">[16]</ref>. Thus, proper mechanisms are called for this practical but challenging SSL scenario.</p><p>Here, we define this new SSL scenario as multi-site semi-supervised learning (MS-SSL), allowing to enrich the unlabeled pool with multi-site heterogeneous images. Being an under-explored scenario, few efforts have been made. To our best knowledge, the most relevant work is AHDC <ref type="bibr" target="#b1">[2]</ref>. However, it only deals with additional unlabeled data from a specific source rather than multiple arbitrary sources. Thus, it intuitively utilizes image-level mapping to minimize dual-distribution discrepancy. Yet, their adversarial min-max optimization often leads to instability and it is difficult to align multiple external sources with the local source using a single image mapping network.</p><p>In this work, we propose a more generalized framework called Categorylevel regularized Unlabeled-to-Labeled (CU2L) learning, as depicted in Fig. <ref type="figure" target="#fig_1">2</ref>, to achieve robust MS-SSL for prostate MRI segmentation. Specifically, CU2L is built upon the teacher-student architecture with customized learning strategies for local and external unlabeled data: (i) recognizing the importance of supervised learning in data distribution fitting (which leads to the failure of CPS <ref type="bibr" target="#b2">[3]</ref> in MS-SSL as elaborated in Sec. 3), the local unlabeled data is involved into pseudolabel supervised-like learning to reinforce fitting of the local data distribution; (ii) considering that intra-class variance hinders effective MS-SSL, we introduce a non-parametric unlabeled-to-labeled learning scheme, which takes advantage of the scarce expert labels to explicitly constrain the prototype-propagated predictions, to help the model exploit discriminative and domain-insensitive features from heterogeneous multi-site data to support the local center. Yet, observing that such scheme is challenging when significant shifts and various distributions are present, we further propose category-level regularization, which advocates prototype alignment, to regularize the distribution of intra-class features from arbitrary external data to be closer to the local distribution; (iii) based on the fact that perturbations (e.g., Gaussian noises <ref type="bibr" target="#b14">[15]</ref>) can be regarded as a simulation of heterogeneity, perturbed stability learning is incorporated to enhance the robustness of the model. Our method is evaluated on prostate MRI data from six different clinical centers and shows promising performance on tackling MS-SSL compared to other semi-supervised methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem Formulation and Basic Architecture</head><p>In our scenario of MS-SSL, we have access to a local target dataset D local (consisted of a labeled sub-set D l local and an unlabeled sub-set D u local ) and the external unlabeled support datasets D u e = m j=1 D u,j e , where m is the number of support centers. Specifically,</p><formula xml:id="formula_0">D l local = {(X l local(i) , Y l local(i) )} n l i=1 with n l labeled scans and D u local = {X u local(i) } n l +nu i=n l +1</formula><p>with n u unlabeled scans. with n j unlabeled samples. Considering the large variance on slice thickness among different centers <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>, our experiments are performed in 2D. Thus, we refer to pixels in the subsequent content. As shown in Fig. <ref type="figure" target="#fig_1">2</ref>, our framework is built upon the popular teacher-student framework. Specifically, the student f s θ is an in-training model optimized by loss back-propagation as usual while the teacher model f t θ is slowly updated with a momentum term that averages previous weights with the current weights, where θ denotes the student's weights and θ the teacher's weights. θ is updated by θt = α θt-1 + (1α)θ t at iteration t, where α is the exponential moving average (EMA) coefficient and empirically set to 0.99 <ref type="bibr" target="#b25">[26]</ref>. Compared to the student, the teacher performs self-ensembling by nature which helps smooth out the noise and avoid sudden changes of predictions <ref type="bibr" target="#b14">[15]</ref>. Thus, the teacher model is suitable for handling the heterogeneous external images and producing relatively stable pseudo labels (will be used later). As such, our task of MS-SSL can be formulated as optimizing the following loss:</p><formula xml:id="formula_1">L = L l sup θ, D l local + λL u (θ, θ, D u local , D u e ),<label>(1)</label></formula><p>where L l sup is the supervised guidance from local labeled data and L u denotes the additional guidance from the unlabeled data. λ is a trade-off weight scheduled by the time-dependent ramp-up Gaussian function <ref type="bibr" target="#b14">[15]</ref> </p><formula xml:id="formula_2">λ(t) = w max •e -5(1-t/tmax) 2 ,</formula><p>where w max and t max are the maximal weight and iteration, respectively. The key challenge of MS-SSL is the proper design of L u for robustly exploiting multi-site unlabeled data {D u local , D u e } to support the local center.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Pseudo Labeling for Local Distribution Fitting</head><p>As mentioned above, supervised-like learning is advocated for local unlabeled data to help the model fit local distribution better. Owning the self-ensembling property, the teacher model provides relatively stable pseudo labels for the student model. Given the predicted probability map P u,t local of X u local from the teacher model, the pseudo label Ŷ u,t local corresponds to the class with the maximal posterior probability. Yet, with limited local labeled data for training, it is difficult to generate high-quality pseudo labels. Thus, for each pixel, if max c (p u,t local ) ≥ δ, where c denotes the c-th class and δ is a ramp-up threshold ranging from 0.75 to 0.9 as training goes, this pixel will be included in loss calculation. Considering that the cross-entropy loss has been found very sensitive to label noises <ref type="bibr" target="#b17">[18]</ref>, we adopt the partial Dice loss L Dice <ref type="bibr" target="#b26">[27]</ref> to perform pseudo label learning, formulated as:</p><formula xml:id="formula_3">L u P L = 1 K K k=1 L Dice P u,s,k local , Ŷ u,t,k local</formula><p>, where P u,s local denotes the prediction of X u local from the student model. The Dice loss is calculated for each of the K equally-sized regions of the image, and the final loss is obtained by taking their mean. Such a regional form <ref type="bibr" target="#b5">[6]</ref> can help the model better perceive the local discrepancies for fine-grained learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Category-Level Regularized Unlabeled-to-Labeled Learning</head><p>Unlabeled-to-Labeled Learning. Inherently, the challenge of MS-SSL stems from intra-class variation, which results from different imaging protocols, disease progress and patient demographics. Inspired by prototypical networks <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b24">25]</ref> that compare class prototypes with pixel features to perform segmentation, here, we introduce a non-parametric unlabeled-to-labeled (U2L) learning scheme that utilizes expert labels to explicitly constrain the prototype-propagated predictions. Such design is based on two considerations: (i) a good prototypepropagated prediction requires both compact feature and discriminative prototypes, thus enhancing this prediction can encourage the model to learn in a variation-insensitive manner and focus on the most informative clues; (ii) using expert labels as final guidance can prevent error propagation from pseudo labels. Specifically, we denote the feature map of the external unlabeled image X u e before the penultimate convolution in the teacher model as F u,t e . Note that F u,t e has been upsampled to the same size of X u e via bilinear interpolation but with L channels. With the argmax pseudo label Ŷ u,t e and the predicted probability map P u,t e , the object prototype from the external unlabeled data can be computed via confidence-weighted masked average pooling: c</p><formula xml:id="formula_4">u(obj) e = v Ŷ u,t,obj e(v) •P u,t,obj e(v) •F u,t e(v) v Ŷ u,t,obj e(v) •P u,t,obj e(v)</formula><p>.</p><p>Likewise, the background prototype c u(bg) e can also be obtained. Considering the possible unbalanced sampling of prostate-containing slices, EMA strategy across training steps (with a decay rate of 0.9) is applied for prototype update. Then, as shown in Fig. <ref type="figure" target="#fig_1">2</ref> , where we use cosine similarity for sim(•, •) and empirically set the temperature T to 0.05 <ref type="bibr" target="#b18">[19]</ref>. Note that a similar procedure can also be applied to the local unlabeled data X u local , and thus we can obtain another prototype-propagated unlabeledto-labeled prediction P u2l local for X l local . As such, given the accurate expert label Y l local , the unlabeled-to-labeled supervision can be computed as:</p><formula xml:id="formula_5">L u2l = 1 K K k=1 L Dice (P u2l,k e , Y l,k local ) + K k=1 L Dice (P u2l,k local , Y l,k local ) . (<label>2</label></formula><formula xml:id="formula_6">)</formula><p>Category-Level Regularization. Being a challenging scheme itself, the above U2L learning can only handle minor intra-class variation. Thus, proper mechanisms are needed to alleviate the negative impact of significant shift and multiple distributions. Specifically, we introduce category-level regularization, which advocates class prototype alignment between local and external data, to regularize the distribution of intra-class features from arbitrary external data to be closer to the local one, thus reducing the difficulty of U2L learning. In U2L, we have obtained prototypes from local unlabeled data {c </p><p>where mean squared error is adopted as the distance function d(•, •). The weight of background prototype alignment is smaller due to less relevant contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stability Under Perturbations.</head><p>Although originally designed for typical SSL, encouraging stability under perturbations <ref type="bibr" target="#b25">[26]</ref> can also benefit MS-SSL, considering that the perturbations can be regarded as a simulation of heterogeneity and enforcing such perturbed stability can regularize the model behavior for better generalizability. Specifically, for the same unlabeled input X u ∈ {D u local ∪ D u e } with different perturbations ξ and ξ (using the same Gaussian noises as in <ref type="bibr" target="#b25">[26]</ref>), we encourage consistent pre-softmax predictions between the teacher and student models, formulated as</p><formula xml:id="formula_8">L u sta = d f t θ (X u + ξ), f s θ (X u + ξ ) ,</formula><p>where mean squared error is also adopted as the distance function d(•, •).</p><p>Overall, the final loss for the multi-site unlabeled data is summarized as:</p><formula xml:id="formula_9">L u = L u P L (D u local ) + [L u2l (D local , D u e ) + L cr (D local , D u e )] + L u sta (D u local , D u e ). (<label>4</label></formula><formula xml:id="formula_10">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head><p>Materials. We utilize prostate T2-weighted MR images from six different clinical centers (C1-6) <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5]</ref> to perform a retrospective evaluation.  rizes the characteristics of the six data sources, following <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>, where <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref> also reveal the severity of inter-center heterogeneity here through extensive experiments. The heterogeneity comes from the differences in scanners, field strengths, coil types, disease and in-plane/through-plane resolution. Compared to C1 and C2, scans from C3 to C6 are taken from patients with prostate cancer, either for detection or staging purposes, which can cause inherent semantic differences in the prostate region to further aggravate heterogeneity. Following <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>, we crop each scan to preserve the slices with the prostate region only and then resize and normalize it to 384 × 384 px in the axial plane with zero mean and unit variance. We take C1 or C2 as the local target center and randomly divide their 30 scans into 18, 3, and 9 samples as training, validation, and test sets, respectively.</p><p>Implementation and Evaluation Metrics. The framework is implemented on PyTorch using an NVIDIA GeForce RTX 3090 GPU. Considering the large variance in slice thickness among different centers, we adopt the 2D architecture. Specifically, 2D U-Net <ref type="bibr" target="#b11">[12]</ref> is adopted as our backbone.  consists of the cross-entropy loss and the K-regional Dice loss <ref type="bibr" target="#b5">[6]</ref>. The maximum consistency weight w max is set to 0.1 <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b25">26]</ref>. t max is set to 20,000. K is empirically set to 2. The network is trained using the SGD optimizer and the learning rate is initialized as 0.01 and decayed by multiplication with (1.0t/t max ) 0.9 . Data augmentation is applied, including random flip and rotation. We adopt the Dice similarity coefficient (DSC) and Jaccard as the evaluation metrics and the results are the average over three runs with different seeds.</p><p>Comparison Study. Table <ref type="table" target="#tab_2">2</ref> presents the quantitative results with either C1 or C2 as the local target center, wherein only 6 or 8 local scans are annotated. Besides the supervised-only baselines, we include recent top-performing SSL methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26]</ref> for comparison. All methods are implemented with the same backbone and training protocols to ensure fairness. As observed, compared to the supervised-only baselines, our CU2L with {6, 8} local labeled scans achieves {19.15%, 17.42%} and {9.1%, 6.44%} DSC improvements in {C1, C2}, showing its effectiveness in leveraging multi-site unlabeled data. Despite the violation of the assumption of i.i.d. data, existing SSL methods can still benefit from the external unlabeled data to some extent compared to the results using local data only as shown in Fig. <ref type="figure" target="#fig_0">1</ref>, revealing that the quantity of unlabeled data has a significant impact. However, due to the lack of proper mechanisms for learning from heterogeneous data, limited improvement can be achieved by them, especially for CPS <ref type="bibr" target="#b2">[3]</ref> and FixMatch <ref type="bibr" target="#b13">[14]</ref> in C2. Particularly, CPS relies on cross-modal pseudo labeling which exploits all the unlabeled data in a supervised-like fashion. We attribute its degradation to the fact that supervised learning is crucial for distribution fitting, which supports our motivation of performing pseudo-label learning on local unlabeled data only. As a result, its models struggle to determine which distribution to prioritize. Meanwhile, the most relevant AHDC <ref type="bibr" target="#b1">[2]</ref> is mediocre in MS-SSL, mainly due to the instability of adversarial training and the difficulty of aligning multiple distributions to the local distribution via a single image-mapping network. In contrast, with specialized mechanisms for simultaneously learning informative representations from multi-site data and handling heterogeneity, our CU2L obtains the best performance over the recent SSL methods. Figure <ref type="figure" target="#fig_4">3</ref>(a) further shows that the predictions of our method fit more accurately with the ground truth.</p><p>Ablation Study. To evaluate the effectiveness of each component, we conduct an ablation study under the setting with 6 local labeled scans, as shown in Fig. <ref type="figure" target="#fig_1">2(b)</ref>. Firstly, when we remove L u P L (CU2L-1), the performance drops by {5.69% (C1), 3.05%(C2)} in DSC, showing that reinforcing confirmation on local distribution is critical. CU2L-2 represents the removal of both L u2l and L cr , and it can be observed that such an unlabeled-to-labeled learning approach combined with class-level regularization is crucial for exploring multi-site data. If we remove L cr which accompanies with L u2l (CU2L-3), the performance degrades, which justifies the necessity of this regularization to reduce the difficulty of unlabeled-to-labeled learning process. CU2L-4 denotes the removal of L u sta . As observed, such a typical stability loss <ref type="bibr" target="#b14">[15]</ref> can further improve the performance by introducing hand-crafted noises to enhance the robustness to real-world heterogeneity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this work, we presented a novel Category-level regularized Unlabeled-to-Labeled (CU2L) learning framework for semi-supervised prostate segmentation with multi-site unlabeled MRI data. CU2L robustly exploits multi-site unlabeled data via three tailored schemes: local pseudo-label learning for better local distribution fitting, category-level regularized unlabeled-to-labeled learning for exploiting the external data in a distribution-insensitive manner and stability learning for further enhancing robustness to heterogeneity. We evaluated our method on prostate MRI data from six different clinical centers and demonstrated its superior performance compared to other semi-supervised methods.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Comparison between typical semi-supervised learning (SSL) and our focused multi-site semi-supervised learning (MS-SSL), and an exploratory validation on recent SSL methods with limited local unlabeled data.</figDesc><graphic coords="2,41,79,54,62,340,33,101,08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Illustration of the proposed Category-level Regularized Unlabeled-to-labeled Learning (CU2L) framework. EMA: exponential moving average.</figDesc><graphic coords="4,41,79,54,44,340,33,144,28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>, given the feature map F l local of the local labeled image X l local from the in-training student model, we can compare {c u(obj) e , c u(bg) e } with the features F l local pixel-by-pixel and obtain the prototype-propagated prediction</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Similarly, the prototypes of object c l(obj) local and background c l(bg)local of the local labeled data can be obtained but using expert labels and student's features. Then, the category-level regularization is formulated as:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. (a) Exemplar results under the setting with 6 labeled scans. Grey color indicates the mismatch between the prediction and the ground truth. (b) Ablation results. (Color figure online)</figDesc><graphic coords="8,47,28,54,35,339,10,108,37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Details of the acquisition protocols and number of scans for the six different centers. Each center supplied T2-weighted MR images of the prostate.</figDesc><table><row><cell>Scanner</cell></row></table><note><p><p>Center Source</p>#Scans Field strength (T) Resolution (in-plane/through-plane in mm) Coil</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc></figDesc><table /><note><p>summa-</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Quantitative comparison. * indicates p ≤ 0.05 from the Wilcoxon signed rank test for pairwise comparison with our method. Standard deviations are shown in parentheses. The best mean results are shown in bold.</figDesc><table><row><cell>Method</cell><cell cols="2"># Scans Used</cell><cell></cell><cell>Local Site: C1</cell><cell></cell><cell>Local Site: C2</cell></row><row><cell></cell><cell cols="4">D l local D u local D u e DSC (%)</cell><cell>Jaccard (%)</cell><cell>DSC (%)</cell><cell>Jaccard (%)</cell></row><row><cell>Supervised</cell><cell>6</cell><cell>0</cell><cell>0</cell><cell cols="4">66.78 (23.26)* 54.24 (23.74)* 71.19 (16.01)* 57.33 (16.80)*</cell></row><row><cell>MT [15]</cell><cell>6</cell><cell>12</cell><cell cols="5">86 80.96 (11.15)* 70.14 (14.83)* 77.38 (10.24)* 64.21 (13.19)*</cell></row><row><cell>UA-MT [26]</cell><cell>6</cell><cell>12</cell><cell cols="5">86 81.86 (13.82)* 70.77 (17.31)* 78.31 (10.34)* 65.47 (13.26)*</cell></row><row><cell>ICT [17]</cell><cell>6</cell><cell>12</cell><cell cols="5">86 78.52 (16.82)* 67.25 (19.02)* 77.67 (9.22)* 64.38 (11.81)*</cell></row><row><cell>CCT [11]</cell><cell>6</cell><cell>12</cell><cell cols="5">86 79.95 (17.27)* 69.40 (19.55)* 73.20 (15.20)* 59.79 (17.28)*</cell></row><row><cell>FixMatch [14]</cell><cell>6</cell><cell>12</cell><cell cols="5">86 77.09 (18.45)* 65.69 (19.94)* 67.82 (14.80)* 53.16 (16.60)*</cell></row><row><cell>CPCL [25]</cell><cell>6</cell><cell>12</cell><cell cols="5">86 81.40 (14.42)* 71.27 (18.02)* 75.92 (13.59)* 62.96 (16.27)*</cell></row><row><cell>CPS [3]</cell><cell>6</cell><cell>12</cell><cell cols="5">86 65.02 (23.91)* 52.32 (23.65)* 43.41 (23.39)* 30.32 (17.49)*</cell></row><row><cell>SSNet [20]</cell><cell>6</cell><cell>12</cell><cell cols="5">86 80.37 (15.15)* 69.43 (17.88)* 75.62 (10.99)* 62.03 (14.06)*</cell></row><row><cell>AHDC [2]</cell><cell>6</cell><cell>12</cell><cell cols="5">86 79.52 (14.32)* 68.02 (15.34)* 74.65 (12.37)* 60.98 (14.33)*</cell></row><row><cell>CU2L (ours)</cell><cell>6</cell><cell>1 2</cell><cell cols="5">8 6 85.93 (9.18) 76.36 (12.87) 80.29 (10.77) 68.01 (13.92)</cell></row><row><cell>Supervised</cell><cell>8</cell><cell>0</cell><cell>0</cell><cell cols="4">69.04 (25.07)* 57.52 (25.34)* 75.86 (10.24)* 62.20 (13.18)*</cell></row><row><cell>MT [15]</cell><cell>8</cell><cell>10</cell><cell cols="5">86 80.18 (15.47)* 69.22 (17.85)* 77.90 (9.32)* 64.72 (11.99)*</cell></row><row><cell>UA-MT [26]</cell><cell>8</cell><cell>10</cell><cell cols="5">86 82.42 (12.45)* 71.75 (15.70)* 77.44 (8.94)* 64.02 (11.41)*</cell></row><row><cell>ICT [17]</cell><cell>8</cell><cell>10</cell><cell cols="5">86 79.88 (13.61)* 68.42 (16.96)* 76.80 (11.84)* 63.65 (13.75)*</cell></row><row><cell>CCT [11]</cell><cell>8</cell><cell>10</cell><cell cols="5">86 79.29 (14.21)* 67.71 (17.29)* 80.42 (7.60)* 67.31 (10.09)*</cell></row><row><cell>FixMatch [14]</cell><cell>8</cell><cell>10</cell><cell cols="5">86 80.46 (13.46)* 69.14 (16.29)* 66.17 (20.86)* 52.53 (20.05)*</cell></row><row><cell>CPCL [25]</cell><cell>8</cell><cell>10</cell><cell cols="5">86 81.34 (14.01)* 70.56 (17.13)* 77.49 (11.20)* 64.53 (13.93)*</cell></row><row><cell>CPS [3]</cell><cell>8</cell><cell>10</cell><cell cols="5">86 76.17 (15.58)* 63.74 (17.77)* 65.34 (13.53)* 50.04 (15.19)*</cell></row><row><cell>SSNet [20]</cell><cell>8</cell><cell>10</cell><cell cols="5">86 77.22 (15.09)* 65.19 (18.81)* 78.25 (9.90)* 65.27 (12.33)*</cell></row><row><cell>AHDC [2]</cell><cell>8</cell><cell>10</cell><cell cols="5">86 78.53 (16.23)* 66.01 (18.45)* 75.12 (11.23)* 61.97 (13.35)*</cell></row><row><cell>CU2L (ours)</cell><cell>8</cell><cell>1 0</cell><cell cols="5">8 6 86.46 (6.72) 76.74 (9.97) 82.30 (9.93) 70.71 (12.94)</cell></row><row><cell cols="2">Supervised (upper bound) 18</cell><cell>0</cell><cell>0</cell><cell>89.19 (4.33)</cell><cell>80.76 (6.71)</cell><cell>85.01 (4.35)</cell><cell>74.15 (6.44)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>The input patch size is set to 384 × 384, and the batch size is set to 36 including 12 labeled local slices, 12 unlabeled local slices and 12 unlabeled external slices. The supervised loss L l</figDesc><table><row><cell>Image</cell><cell>MT</cell><cell>SSNet</cell><cell>AHDC</cell><cell>CU2L (ours)</cell><cell></cell><cell>87</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>85</cell><cell>C1</cell><cell>C2</cell></row><row><cell>Local: C1</cell><cell>86.41%</cell><cell>89.95%</cell><cell>88.81%</cell><cell>93.61%</cell><cell>DSC (%)</cell><cell>77 79 81 83</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>75</cell><cell></cell><cell></cell></row><row><cell>Local: C2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">CU2L-1 CU2L-2 CU2L-3 CU2L-4 C1 80.24 82.75 83.31 84.77 71 73</cell><cell>CU2L 85.93</cell></row><row><cell></cell><cell>61.02%</cell><cell>59.12%</cell><cell>58.99%</cell><cell>82.76%</cell><cell></cell><cell cols="2">C2 77.24</cell><cell>77.52</cell><cell>79.43</cell><cell>80.01</cell><cell>80.29</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>sup</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement. This research was done with <rs type="institution">Tencent Jarvis Lab and Tencent Healthcare (Shenzhen) Co</rs>., LTD and supported by <rs type="funder">General Research Fund from Research Grant Council of Hong Kong</rs> (No. <rs type="grantNumber">14205419</rs>) and the <rs type="funder">National Key R&amp;D Program of China</rs> (No. <rs type="grantNumber">2020AAA0109500</rs> and No. <rs type="grantNumber">2020AAA0109501</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_YfD98Wt">
					<idno type="grant-number">14205419</idno>
				</org>
				<org type="funding" xml:id="_E2ZVakp">
					<idno type="grant-number">2020AAA0109500</idno>
				</org>
				<org type="funding" xml:id="_yr62Af4">
					<idno type="grant-number">2020AAA0109501</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">NCI-ISBI 2013 challenge: automated segmentation of prostate structures</title>
		<author>
			<persName><forename type="first">N</forename><surname>Bloch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Cancer Imaging Arch</title>
		<imprint>
			<biblScope unit="volume">370</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Adaptive hierarchical dual consistency for semi-supervised left atrium segmentation on cross-domain data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="420" to="433" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semi-supervised semantic segmentation with cross pseudo supervision</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2613" to="2622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Computer-aided detection and diagnosis for prostate cancer based on mono and multi-parametric MRI: a review</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lemaître</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Martí</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Freixenet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Vilanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Meriaudeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Biol. Med</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="8" to="31" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Evaluation of prostate segmentation algorithms for MRI: the PROMISE12 challenge</title>
		<author>
			<persName><forename type="first">G</forename><surname>Litjens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="359" to="373" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semi-supervised medical image segmentation using cross-model pseudo-supervision with shape awareness and local context constraints</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Desrosiers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16452-1_14</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16452-114" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13438</biblScope>
			<biblScope unit="page" from="140" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Shape-aware meta-learning for generalizing prostate MRI segmentation to unseen domains</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Heng</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-59713-9_46</idno>
		<idno>978-3-030-59713-9 46</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2020</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Martel</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12262</biblScope>
			<biblScope unit="page" from="475" to="485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">MS-net: multi-site network for improving prostate segmentation with heterogeneous MRI data</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2713" to="2724" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Semi-supervised medical image segmentation through dual-task consistency</title>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Efficient semi-supervised gross target volume of nasopharyngeal carcinoma segmentation via uncertainty rectified pyramid consistency</title>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87196-3_30</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87196-330" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12902</biblScope>
			<biblScope unit="page" from="318" to="329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Semi-supervised semantic segmentation with cross-consistency training</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ouali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hudelot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="12674" to="12684" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">U-net: convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-24574-4_28</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-24574-428" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2015</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hornegger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">9351</biblScope>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="4080" to="4090" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">FixMatch: simplifying semi-supervised learning with consistency and confidence</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.07685</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1195" to="1204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A survey on semi-supervised learning</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Van Engelen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Hoos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="373" to="440" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Interpolation consistency training for semi-supervised learning</title>
		<author>
			<persName><forename type="first">V</forename><surname>Verma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">145</biblScope>
			<biblScope unit="page" from="90" to="106" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A noise-robust framework for automatic segmentation of COVID-19 pneumonia lesions from CT images</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2653" to="2663" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">PANet: few-shot image semantic segmentation with prototype alignment</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Liew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="9197" to="9206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Exploring smoothness and class-separation for semi-supervised medical image segmentation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-16443-9_4</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-16443-94" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2022</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Q</forename><surname>Dou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Speidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">13435</biblScope>
			<biblScope unit="page" from="34" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Semi-supervised left atrium segmentation with mutual consistency training</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87196-3_28</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-87196-328" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12902</biblScope>
			<biblScope unit="page" from="297" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Anti-interference from noisy labels: Mean-teacher-assisted confident learning for medical image segmentation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="3062" to="3073" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Noisy labels are treasure: mean-teacher-assisted confident learning for hepatic vessel segmentation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-87193-2_1</idno>
		<idno>978- 3-030-87193-2 1</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2021</title>
		<editor>
			<persName><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">12901</biblScope>
			<biblScope unit="page" from="3" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Ambiguity-selective consistency regularization for mean-teacher semisupervised medical image segmentation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page">102880</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">All-around real label supervision: cyclic prototype consistency learning for semi-supervised medical image segmentation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Biomed. Health Inform</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3174" to="3184" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Uncertainty-aware self-ensembling model for semi-supervised 3D left atrium segmentation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-W</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Heng</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-32245-8_67</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-32245-867" />
	</analytic>
	<monogr>
		<title level="m">MICCAI 2019</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11765</biblScope>
			<biblScope unit="page" from="605" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">PA-seg: learning from point annotations for 3D medical image segmentation using contextual regularization and cross knowledge distillation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1109/TMI.2023.3245068</idno>
		<ptr target="https://doi.org/10.1109/TMI.2023.3245068" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2235" to="2246" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">BoostMIS: boosting medical image semi-supervised learning with adaptive pseudo labeling and informative active annotation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="20666" to="20676" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
