{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/outputs/databases/cancer_related_papers_w_text.csv'\n",
    "df_cancer_related = pd.read_csv(filename)\n",
    "len(df_cancer_related['title'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract keyword-related sentences from selected papers\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Short keywords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of keywords\n",
    "keywords_age        = ['age']\n",
    "\n",
    "keywords_gender     = ['gender', 'sex', 'women', 'woman', 'female', 'male']\n",
    "\n",
    "keywords_etnicity   = ['etnicity', 'etnicities', 'race', 'white patients', 'black patients']\n",
    "\n",
    "keywords_geoloc     = ['geolocation', 'geographical', 'geographic', 'country', 'countries', 'city', 'cities', \n",
    "                        'hospital', 'hospitals', 'clinic', 'clinics']\n",
    "\n",
    "keywords_bias       = ['bias', 'biases']\n",
    "\n",
    "keywords_fairness   = ['fairness']\n",
    "\n",
    "keywords_patients   = ['patient', 'patients']\n",
    "\n",
    "keywords_data       = ['dataset', 'datasets', 'data collection', 'data collections']\n",
    "\n",
    "keywords_collected  = ['collected']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Split the text into words and extract keyword-matches. Group each keyword-match by relatd paper \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_text(text, width=100):\n",
    "    \"\"\"\n",
    "    A simple function to wrap text at a given width.\n",
    "    \"\"\"\n",
    "    if pd.isnull(text):\n",
    "        return text  # Handle NaN values\n",
    "    \n",
    "    wrapped_lines = []\n",
    "    for paragraph in text.split('\\n'):  # Splitting by existing newlines to preserve paragraph breaks\n",
    "        line = ''\n",
    "        for word in paragraph.split():\n",
    "            if len(line) + len(word) + 1 > width:\n",
    "                wrapped_lines.append(line)\n",
    "                line = word\n",
    "            else:\n",
    "                line += (' ' + word if line else word)\n",
    "        wrapped_lines.append(line)\n",
    "    return '\\n'.join(wrapped_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords search only\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text into sentences and search for the keywords\n",
    "\n",
    "def extract_keywords(df, keywords):\n",
    "    # Search for the whole word in the text\n",
    "    pattern = r'\\b(' + '|'.join(re.escape(keyword) for keyword in keywords) + r')\\b'\n",
    "\n",
    "    # Initialize a dictionary to hold sentences organized by paper title\n",
    "    sentences_by_paper = {}\n",
    "\n",
    "    # Loop through each row in the dataframe\n",
    "    for index, row in df_cancer_related.iterrows():\n",
    "        # Find all sentences that contain any of the keywords\n",
    "        sentences = re.findall(pattern, row['text'], flags=re.IGNORECASE | re.DOTALL)\n",
    "        \n",
    "        # If there are matching sentences, add them to the dictionary under the paper title\n",
    "        if sentences:\n",
    "            paper_title = row['title']\n",
    "            if paper_title not in sentences_by_paper:\n",
    "                sentences_by_paper[paper_title] = []\n",
    "            sentences_by_paper[paper_title].extend(sentences)\n",
    "\n",
    "    # Sentences_by_paper contains all the sentences that contain keywords, organized by paper title\n",
    "\n",
    "    # Convert this dictionary into a DataFrame:\n",
    "    # Create a list of tuples (paper title, sentence)        \n",
    "    keywords_data = [(title, keyword_sentence) for title, related_group in sentences_by_paper.items() for keyword_sentence in related_group]\n",
    "    keywords_df = pd.DataFrame(keywords_data, columns=['title', 'keyword']) \n",
    "\n",
    "    return keywords_df       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_df = extract_keywords(df_cancer_related, keywords_bias)\n",
    "\n",
    "#keywords_df.to_csv(\"/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/outputs/data/bias_related_keywords_.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Sentence search only by list of keywords\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudo code\n",
    "# regex to split the text into sentences. A sentence is defined as a sequence of characters that ends with a period, question mark, or exclamation mark.\n",
    "# iterate through the sentences to find those with a keyword from the list of keywords. \n",
    "# for each match\n",
    "    # option 1) concatentinate the previous and next sentences to the sentence with the keyword (if they haven't been added already)\n",
    "    # option 2) extract sentence with keyword only\n",
    "# keep track of the sentences already added for each paper title.\n",
    "# if no matches are found for a paper title, add 'none'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT SENTS WITH KEYWORDS    \n",
    "# Option 2) Storing keyword sentence only \n",
    "\n",
    "def extract_keyword_sentences(df, keywords):\n",
    "    \"\"\"\n",
    "    Extract sentences containing specified keywords from DataFrame and organize by paper title.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the text to search through.\n",
    "    - keywords: List of keywords to search for in the text.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with paper titles as keys and lists of sentences containing the keywords as values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compile the regular expression for matching sentences containing the keywords\n",
    "    keyword_pattern = re.compile(r'\\b(?:' + '|'.join(keywords) + r')\\b', flags=re.IGNORECASE)\n",
    "\n",
    "    # Initialize a dictionary to hold sentences organized by paper title\n",
    "    sentences_by_paper = {}\n",
    "\n",
    "    # Loop through each paper title in the DataFrame\n",
    "    for title in df['title'].unique():\n",
    "        # Get the full text for the current title\n",
    "        text = ' '.join(df[df['title'] == title]['text'])\n",
    "        # Split the text into sentences\n",
    "        sentences = re.split(r'(?<=[.?!])\\s+', text)\n",
    "\n",
    "        # List to store sentences that contain the keyword\n",
    "        keyword_sentences_buffer = []\n",
    "\n",
    "        # Iterate through sentences to find and store sentences that contain the keyword\n",
    "        for sentence in sentences:\n",
    "            if keyword_pattern.search(sentence):\n",
    "                # Add only the sentence with the keyword to the buffer\n",
    "                keyword_sentences_buffer.append(sentence)\n",
    "\n",
    "        # Add the sentences to the dictionary, use 'none' if there are no matches\n",
    "        sentences_by_paper[title] = keyword_sentences_buffer if keyword_sentences_buffer else ['none']\n",
    "    \n",
    "    extracted_data = [(title, keyword_sentence) for title, related_group in sentences_by_paper.items() for keyword_sentence in related_group]\n",
    "    extracted_df = pd.DataFrame(extracted_data, columns=['title', 'extracted_keyword_sent'])\n",
    "    \n",
    "    # Wrap title and the extracted sentences to a maximum width of n-characters for better readability\n",
    "    extracted_df['extracted_keyword_sent'] = extracted_df['extracted_keyword_sent'].apply(wrap_text, width=80)\n",
    "\n",
    "    return extracted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = extract_keyword_sentences(df_cancer_related, keywords_bias).to_csv('bias_related_sentences.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_demo = pd.read_csv('/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/outputs/databases/annotations/anno_demographics.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_demo = anno_demo.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_demo['volume'] = anno_demo['volume'].astype(int)\n",
    "anno_demo['etnicity is used'] = anno_demo['etnicity is used'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_demo.to_csv('/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/outputs/databases/annotations/anno_demographics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
