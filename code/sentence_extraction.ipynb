{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>header_no</th>\n",
       "      <th>header_title</th>\n",
       "      <th>text</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anatomy-Driven Pathology Detection on Chest X-...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>chest radiographs (chest x-rays) represent the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anatomy-Driven Pathology Detection on Chest X-...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Related Work</td>\n",
       "      <td>weakly supervised pathology detection. due to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anatomy-Driven Pathology Detection on Chest X-...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Model</td>\n",
       "      <td>figure 1 provides an overview of our method. g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anatomy-Driven Pathology Detection on Chest X-...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Inference</td>\n",
       "      <td>during inference, the trained model predicts a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anatomy-Driven Pathology Detection on Chest X-...</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Training</td>\n",
       "      <td>the anatomical region detector is trained usin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>LightNeuS: Neural Surface Reconstruction in En...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Using Illumination Decline as a Depth Cue</td>\n",
       "      <td>the neus formulation of sect. 2 assumes distan...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>LightNeuS: Neural Surface Reconstruction in En...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Endoscope Photometric Model</td>\n",
       "      <td>apart from illumination decline, there are sev...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>LightNeuS: Neural Surface Reconstruction in En...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Experiments</td>\n",
       "      <td>we validate our method on the c3vd dataset [4]...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2515</th>\n",
       "      <td>LightNeuS: Neural Surface Reconstruction in En...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Conclusion</td>\n",
       "      <td>we have presented a method for 3d dense multi-...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>LightNeuS: Neural Surface Reconstruction in En...</td>\n",
       "      <td>0</td>\n",
       "      <td>Supplementary Information</td>\n",
       "      <td>the online version contains supplementary mate...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2517 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title header_no  \\\n",
       "0     Anatomy-Driven Pathology Detection on Chest X-...       1.0   \n",
       "1     Anatomy-Driven Pathology Detection on Chest X-...       2.0   \n",
       "2     Anatomy-Driven Pathology Detection on Chest X-...       3.1   \n",
       "3     Anatomy-Driven Pathology Detection on Chest X-...       3.2   \n",
       "4     Anatomy-Driven Pathology Detection on Chest X-...       3.3   \n",
       "...                                                 ...       ...   \n",
       "2512  LightNeuS: Neural Surface Reconstruction in En...       3.1   \n",
       "2513  LightNeuS: Neural Surface Reconstruction in En...       3.2   \n",
       "2514  LightNeuS: Neural Surface Reconstruction in En...       4.0   \n",
       "2515  LightNeuS: Neural Surface Reconstruction in En...       5.0   \n",
       "2516  LightNeuS: Neural Surface Reconstruction in En...         0   \n",
       "\n",
       "                                   header_title  \\\n",
       "0                                  Introduction   \n",
       "1                                  Related Work   \n",
       "2                                         Model   \n",
       "3                                     Inference   \n",
       "4                                      Training   \n",
       "...                                         ...   \n",
       "2512  Using Illumination Decline as a Depth Cue   \n",
       "2513                Endoscope Photometric Model   \n",
       "2514                                Experiments   \n",
       "2515                                 Conclusion   \n",
       "2516                  Supplementary Information   \n",
       "\n",
       "                                                   text  volume  \n",
       "0     chest radiographs (chest x-rays) represent the...       1  \n",
       "1     weakly supervised pathology detection. due to ...       1  \n",
       "2     figure 1 provides an overview of our method. g...       1  \n",
       "3     during inference, the trained model predicts a...       1  \n",
       "4     the anatomical region detector is trained usin...       1  \n",
       "...                                                 ...     ...  \n",
       "2512  the neus formulation of sect. 2 assumes distan...      10  \n",
       "2513  apart from illumination decline, there are sev...      10  \n",
       "2514  we validate our method on the c3vd dataset [4]...      10  \n",
       "2515  we have presented a method for 3d dense multi-...      10  \n",
       "2516  the online version contains supplementary mate...      10  \n",
       "\n",
       "[2517 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cancer_related = pd.read_csv('/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/outputs/databases/cancer_related_papers_w_text.csv')\n",
    "print(len(df_cancer_related['title'].unique()))\n",
    "\n",
    "df_cancer_related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_header_titles = df_cancer_related['header_title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_header_titles_df = pd.DataFrame(unique_header_titles, columns=['header_titles'])\n",
    "unique_header_titles_df.to_csv('unique_header_titles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract keyword-related sentences from selected papers\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demographics only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Long keyword lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_demographics_long = [\n",
    "    'age', 'gender', 'sex', 'women', 'woman', 'female', 'male',\n",
    "    'geolocation', 'geographical', 'geographic', 'country', 'countries', 'city', 'cities', \n",
    "    'hospital', 'hospitals', 'clinic', 'clinics', 'society', 'societies',\n",
    "    'etnicity', 'etnicities', 'race', \n",
    "    'bias', 'biases', 'fair', 'unfair', 'fairness', 'transparency', 'awareness',\n",
    "    'imbalance', 'imbalanced', 'balance', 'balanced',\n",
    "    'problem', 'problems', 'issue', 'issues', 'challenge', 'challenges', \n",
    "    'difficult', 'difficulty', 'difficulties']\n",
    "\n",
    "\n",
    "keywords_demographics_short = [\n",
    "    'age', 'gender', 'sex', 'women', 'woman', 'female', 'male',\n",
    "    'patient', 'patients', 'etnicity', 'etnicities', 'race', \n",
    "    'bias', 'biases','fairness', 'transparency', \n",
    "    'demographic', 'demographics']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Short keywords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of keywords\n",
    "keywords_age        = ['age']\n",
    "\n",
    "keywords_gender     = ['gender', 'sex', 'women', 'woman', 'female', 'male']\n",
    "\n",
    "keywords_etnicity   = ['etnicity', 'etnicities', 'race']\n",
    "\n",
    "keywords_geoloc     = ['geolocation', 'geographical', 'geographic', 'country', 'countries', 'city', 'cities', \n",
    "                        'hospital', 'hospitals', 'clinic', 'clinics', 'society', 'societies',]\n",
    "\n",
    "keywords_bias       = ['bias', 'biases','fairness']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset and demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of keywords\n",
    "keywords_demographics_data = [\n",
    "    'age', 'gender', 'sex', 'women', 'woman', 'female', 'male',\n",
    "    'patient', 'patients', 'etnicity', 'etnicities', 'race', \n",
    "    'bias', 'biases', 'fairness', 'transparency', \n",
    "    'imbalance', 'imbalanced', 'balance', 'balanced',\n",
    "    'demographics', 'demographic', 'data collection']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_dataset_1 = ['data', 'dataset', 'datasets']\n",
    "\n",
    "keywords_dataset_2 = ['private dataset', 'private datasets',\n",
    "                       'public dataset', 'public datasets',  \n",
    "                       'dataset', 'datasets']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Split the text into words and extract keyword-matches. Group each keyword-match by relatd paper \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_text(text, width=100):\n",
    "    \"\"\"\n",
    "    A simple function to wrap text at a given width.\n",
    "    \"\"\"\n",
    "    if pd.isnull(text):\n",
    "        return text  # Handle NaN values\n",
    "    \n",
    "    wrapped_lines = []\n",
    "    for paragraph in text.split('\\n'):  # Splitting by existing newlines to preserve paragraph breaks\n",
    "        line = ''\n",
    "        for word in paragraph.split():\n",
    "            if len(line) + len(word) + 1 > width:\n",
    "                wrapped_lines.append(line)\n",
    "                line = word\n",
    "            else:\n",
    "                line += (' ' + word if line else word)\n",
    "        wrapped_lines.append(line)\n",
    "    return '\\n'.join(wrapped_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords search only\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text into sentences and search for the keywords\n",
    "\n",
    "def extract_keywords(df, keywords):\n",
    "    # Search for the whole word in the text\n",
    "    pattern = r'\\b(' + '|'.join(re.escape(keyword) for keyword in keywords) + r')\\b'\n",
    "\n",
    "    # Initialize a dictionary to hold sentences organized by paper title\n",
    "    sentences_by_paper = {}\n",
    "\n",
    "    # Loop through each row in the dataframe\n",
    "    for index, row in df_cancer_related.iterrows():\n",
    "        # Find all sentences that contain any of the keywords\n",
    "        sentences = re.findall(pattern, row['text'], flags=re.IGNORECASE | re.DOTALL)\n",
    "        \n",
    "        # If there are matching sentences, add them to the dictionary under the paper title\n",
    "        if sentences:\n",
    "            paper_title = row['title']\n",
    "            if paper_title not in sentences_by_paper:\n",
    "                sentences_by_paper[paper_title] = []\n",
    "            sentences_by_paper[paper_title].extend(sentences)\n",
    "\n",
    "    # Sentences_by_paper contains all the sentences that contain keywords, organized by paper title\n",
    "\n",
    "    # Convert this dictionary into a DataFrame:\n",
    "    # Create a list of tuples (paper title, sentence)        \n",
    "    keywords_data = [(title, keyword_sentence) for title, related_group in sentences_by_paper.items() for keyword_sentence in related_group]\n",
    "    keywords_df = pd.DataFrame(keywords_data, columns=['title', 'keyword']) \n",
    "\n",
    "    return keywords_df       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keywords_df = extract_keywords(df_cancer_related, keywords_demographics_long)\n",
    "#keywords_df = extract_keywords(df_cancer_related, keywords_demographics_short)\n",
    "#keywords_df = extract_keywords(df_cancer_related, keywords_demographics_data)\n",
    "#keywords_df = extract_keywords(df_cancer_related, keywords_dataset_2)\n",
    "#keywords_df = extract_keywords(df_cancer_related, keywords_bias)\n",
    "\n",
    "#keywords_df.to_csv(\"/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/outputs/data/bias_related_keywords.csv\", index=False)\n",
    "#keywords_df.to_csv(\"/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/outputs/data/cancer_related_keywords.csv\", index=False)\n",
    "#keywords_df.to_csv(\"/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/outputs/data/demographics_data_related_keywords_.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Sentence search only by list of keywords\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudo code\n",
    "# regex to split the text into sentences. A sentence is defined as a sequence of characters that ends with a period, question mark, or exclamation mark.\n",
    "# iterate through the sentences to find those with a keyword from the list of keywords. \n",
    "# for each match\n",
    "    # option 1) concatentinate the previous and next sentences to the sentence with the keyword (if they haven't been added already)\n",
    "    # option 2) extract sentence with keyword only\n",
    "# keep track of the sentences already added for each paper title.\n",
    "# if no matches are found for a paper title, add 'none'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT SENTS WITH KEYWORDS    \n",
    "# Option 2) Storing keyword sentence only \n",
    "\n",
    "def extract_keyword_sentences(df, keywords):\n",
    "    \"\"\"\n",
    "    Extract sentences containing specified keywords from DataFrame and organize by paper title.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the text to search through.\n",
    "    - keywords: List of keywords to search for in the text.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with paper titles as keys and lists of sentences containing the keywords as values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compile the regular expression for matching sentences containing the keywords\n",
    "    keyword_pattern = re.compile(r'\\b(?:' + '|'.join(keywords) + r')\\b', flags=re.IGNORECASE)\n",
    "\n",
    "    # Initialize a dictionary to hold sentences organized by paper title\n",
    "    sentences_by_paper = {}\n",
    "\n",
    "    # Loop through each paper title in the DataFrame\n",
    "    for title in df['title'].unique():\n",
    "        # Get the full text for the current title\n",
    "        text = ' '.join(df[df['title'] == title]['text'])\n",
    "        # Split the text into sentences\n",
    "        sentences = re.split(r'(?<=[.?!])\\s+', text)\n",
    "\n",
    "        # List to store sentences that contain the keyword\n",
    "        keyword_sentences_buffer = []\n",
    "\n",
    "        # Iterate through sentences to find and store sentences that contain the keyword\n",
    "        for sentence in sentences:\n",
    "            if keyword_pattern.search(sentence):\n",
    "                # Add only the sentence with the keyword to the buffer\n",
    "                keyword_sentences_buffer.append(sentence)\n",
    "\n",
    "        # Add the sentences to the dictionary, use 'none' if there are no matches\n",
    "        sentences_by_paper[title] = keyword_sentences_buffer if keyword_sentences_buffer else ['none']\n",
    "    \n",
    "    extracted_data = [(title, keyword_sentence) for title, related_group in sentences_by_paper.items() for keyword_sentence in related_group]\n",
    "    extracted_df = pd.DataFrame(extracted_data, columns=['title', 'extracted_keyword_sent'])\n",
    "    \n",
    "    # Wrap title and the extracted sentences to a maximum width of n-characters for better readability\n",
    "    extracted_df['extracted_keyword_sent'] = extracted_df['extracted_keyword_sent'].apply(wrap_text, width=80)\n",
    "\n",
    "    return extracted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of keywords\n",
    "keywords_age        = ['age']\n",
    "\n",
    "keywords_gender     = ['gender', 'sex', 'women', 'woman', 'female', 'male']\n",
    "\n",
    "keywords_etnicity   = ['etnicity', 'etnicities', 'race', 'white patients', 'black patients']\n",
    "\n",
    "keywords_geoloc     = ['geolocation', 'geographical', 'geographic', 'country', 'countries', 'city', 'cities', \n",
    "                        'hospital', 'hospitals', 'clinic', 'clinics', 'society', 'societies',]\n",
    "\n",
    "keywords_bias       = ['bias', 'biases','fairness']\n",
    "\n",
    "keywords_data       = ['dataset', 'datasets', 'data collection', 'data collections']\n",
    "\n",
    "keywords_collected  = ['collected']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracted_data = extract_keyword_sentences(df_cancer_related, keywords_age).to_csv('age_relanted_sentences.csv')\n",
    "#extracted_data = extract_keyword_sentences(df_cancer_related, keywords_gender).to_csv('gender_related_sentences.csv')\n",
    "#extracted_data = extract_keyword_sentences(df_cancer_related, keywords_etnicity).to_csv('etnicity_relanted_sentences.csv')\n",
    "#extracted_data = extract_keyword_sentences(df_cancer_related, keywords_geoloc).to_csv('geoloc_relanted_sentences.csv')\n",
    "#extracted_data = extract_keyword_sentences(df_cancer_related, keywords_bias).to_csv('bias_related_sentences.csv')\n",
    "#extracted_data = extract_keyword_sentences(df_cancer_related, keywords_data).to_csv('data_related_sentences.csv')\n",
    "#extracted_data = extract_keyword_sentences(df_cancer_related, keywords_collected).to_csv('datacollected_related_sentences.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIND INFO ABOUT DEMOGRAPHIC INFORMATION\n",
    "#extracted_data = extract_keyword_sentences(df_cancer_related, keywords_demographics_long).to_csv('extracted_sentences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIND INFO ABOUT DEMOGRAPHIC INFORMATION KEYWORD LIST = KEYWORDS_DEMOGRAPHICS_DATA\n",
    "#extracted_data = extract_keyword_sentences(df_cancer_related, keywords_demographics_data).to_csv('demographics_data_related_sentences.csv')\n",
    "#extracted_data = extract_keyword_sentences(df_cancer_related, keywords_demographics_short)#.to_csv('demographics_data_related_sentences.csv')\n",
    "\n",
    "# FIND INFO ABOUT DATASETS    \n",
    "#extracted_data = extract_keyword_sentences(df_cancer_related, keywords_dataset).to_csv('/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/outputs/data/dataset_extracted_sentences.csv')\n",
    "#extracted_data = extract_keyword_sentences(df_cancer_related, keywords_dataset_2).to_csv('/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/code/outputs/data/dataset_private_public_extracted_sentences.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
