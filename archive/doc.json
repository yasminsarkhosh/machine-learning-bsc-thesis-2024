["<h1>ALL-IN: A Local GLobal Graph-Based| DIstillatioN Model for Representation| Learning of Gigapixel Histopathology| Images With Application In Cancer Risk| Assessment|", "", "<p>Puria Azadi", "<s3>1", "<p>, Jonathan Suderman", "<s3>1", "<p>, Ramin Nakhli", "<s3>1", "<p>, Katherine Rich", "<s3>1", "<p>,| Maryam Asadi", "<s3>1", "<p>, Sonia Kung", "<s3>2", "<p>, Htoo Oo", "<s3>2", "<p>, Mira Keyes", "<s3>1", "<p>, Hossein Farahani", "<s3>1", "<p>,| Calum MacAulay", "<s3>3", "<p>, Larry Goldenberg", "<s3>2", "<p>, Peter Black", "<s3>2", "<p>, and Ali Bashashati", "<s3>1(", "<h3>B", "<s3>)|", "", "<s5>1", "<s1> University of British Columbia, Vancouver, BC, Canada| ali.bashashati@ubc.ca|", "<s5>2", "<s1> Vancouver Prostate Centre, Vancouver, BC, Canada|", "<s5>3", "<s1> BC Cancer Agency, Vancouver, BC, Canada|", "<s1>Abstract.  The utility of machine learning models in histopathology| image analysis for disease diagnosis has been extensively studied. How-| ever, e\ufb00orts to stratify patient risk are relatively under-explored. While| most current techniques utilize small \ufb01elds of view (so-called local fea-| tures) to link histopathology images to patient outcome, in this work we| investigate the combination of global (i.e., contextual) and local features| in a graph-based neural network for patient risk strati\ufb01cation. The pro-| posed network not only combines both \ufb01ne and coarse histological pat-| terns but also utilizes their interactions for improved risk strati\ufb01cation.| We compared the performance of our proposed model against the state-| of-the-art (SOTA) techniques in histopathology risk strati\ufb01cation in two| cancer datasets. Our results suggest that the proposed model is capable| of stratifying patients into statistically signi\ufb01cant risk groups ( p <  0 . 01| across the two datasets) with clinical utility while competing models fail| to achieve a statistical signi\ufb01cance endpoint ( p  = 0 . 148  \u2212  0 . 494).|", "<s1>Keywords:  Histopathology", "<h2> \u00b7", "<s1> Risk Assessment", "<h2> \u00b7", "<s1> Graph Processing|", "", "<h2>1| Introduction|", "", "<p>The examination of tissue and cells using microscope (referred to as histology)| has been a key component of cancer diagnosis and prognostication since more| than a hundred years ago. Histological features allow visual readout of cancer| biology as they represent the overall impact of genetic changes on cells [ 20 ].| The great rise of deep learning in the past decade and our ability to digitize| histopathology slides using high-throughput slide scanners have fueled inter-| ests in the applications of deep learning in histopathology image analysis. The|", "", "<s1>Supplementary Information  The online version contains supplementary material| available at  https://doi.org/10.1007/978-3-031-43987-2 74 .|", "", "<s3>c| \u20dd  The Author(s), under exclusive license to Springer Nature Switzerland AG 2023| H. Greenspan et al. (Eds.): MICCAI 2023, LNCS 14225, pp. 765\u2013775, 2023.| https://doi.org/10.1007/978-3-031-43987-2", "<s2>_", "<s3>74|", "", "<s1>766| P. Azadi et al.|", "", "<p>majority of the e\ufb00orts, so far, focus on the deployment of these models for diag-| nosis and classi\ufb01cation [ 27 ]. As such, there is a paucity of e\ufb00orts that embark| on utilizing machine learning models for patient prognostication and survival| analysis (for example, predicting risk of cancer recurrence or expected patient| survival). While prognostication and survival analysis o\ufb00er invaluable insights| for patient management, biological studies and drug development e\ufb00orts, they| require careful tracking of patients for a lengthy period of time; rendering this| as a task that requires a signi\ufb01cant amount of e\ufb00ort and funding.| In the machine learning domain, patient prognostication can be treated as a| weakly supervised problem, which a model would predict the outcome (e.g., time| to cancer recurrence) based on the histopathology images. Their majority have| utilized Multiple Instance Learning (MIL) [ 8 ] that is a two-step learning method.| First, representation maps for a set of patches (i.e., small \ufb01elds of view), called| a bag of instances, are extracted. Then, a second pooling model is applied to the| feature maps for the \ufb01nal prediction. Di\ufb00erent MIL variations have shown supe-| rior performances in grading or subtype classi\ufb01cation in comparison to outcome| prediction [ 10 ]. This is perhaps due to the fact that MIL-based technique do| not incorporate patch locations and interactions as well as tissue heterogeneity| which can potentially have a vital role in de\ufb01ning clinical outcomes [ 4 , 26 ].| To address this issue, graph neural networks (GNN) have recently received| more attention in histology. They can model patch relations [ 17 ] by utilizing mes-| sage passing mechanism via edges connecting the nodes (i.e., small patches in our| case). However, most GNN-based models su\ufb00er from over smoothing [ 22 ] which| limits nodes\u2019 receptive \ufb01elds [ 3 ]. While local contexts mainly capture cell-cell| interactions, global patterns such as immune cell in\ufb01ltration patterns and tumor| invasion in normal tissue structures (e.g., depth of invasion through myometrium| in endometrial cancer [ 1 ]) could capture critical information about outcome [ 10 ].| Hence, locally focused methods are unable to bene\ufb01t from the coarse properties| of slides due to their high dimensions which may lead to poor performance.| This paper aims to investigate the potential of extracting \ufb01ne and coarse| features from histopathology slides and integrating them for risk strati\ufb01cation| in cancer patients. Therefore, the contributions of this work can be summarized| as: 1) a novel graph-based model for predicting survival that extracts both local| and global properties by identifying morphological super-nodes; 2) introducing| a \ufb01ne-coarse feature distillation module with 3 various strategies to aggregate| interactions at di\ufb00erent scales; 3) outperforming SOTA approaches in both risk| prediction and patient strati\ufb01cation scenarios on two datasets; 4) publishing| two large and rare prostate cancer datasets containing more than 220 graphs for| active surveillance and 240 graphs for brachytherapy cases. The code and graph| embeddings are publicly available at  https://github.com/pazadimo/ALL-IN|", "", "<h2>2| Related Works|", "", "<p>2.1| Weakly Supervised Learning in Histopathology|", "<p>Utilizing Weakly Supervised Learning for modeling histopathology problems has| been getting popular due to the high resolution of slides and substantial time|", "", "<s1>ALL-IN| 767|", "", "<p>and \ufb01nancial costs associated with annotating them as well as the development| of powerful deep discriminative models in the recent years [ 24 ].| Such models are used to perform nuclei segmentation [ 18 ], identify novel| subtypes [ 12 ], or later descendants are even able to pinpoint sub-areas with a| high diagnostic value [ 19 ].|", "<p>2.2| Survival Analysis and GNNs in Histopathology|", "<p>MIL-based models have been utilized for outcome prediction [ 29 , 32 ] which can| also be integrated with attention-based variants [ 14 ]. GNNs due to their struc-| tural preserving capacity [ 28 ] have drawn attention in various histology domains| by constructing the graph on cells or patches. However, current GNN-based risk| assessment variants are only focused on short-range interactions [ 16 , 17 ] or con-| sider local contexts [ 10 ]. We hypothesize that graph-based models\u2019 performance| in survival prediction improves by leveraging both \ufb01ne and coarse properties.|", "", "<h2>3| Method|", "", "<p>Figure  1  summarizes our proposed end-to-end solution. Below, we have provided| details of each module.|", "<p>3.1| Problem Formulation|", "<p>For  P", "<s3>n", "<p>, which is the n-th patient, a set of patches  { patch", "<s3>j", "<p>}", "<s3>M| j =1", "<p>is extracted| from the related whole slide images. In addition, a latent vector  z", "<s3>j", "<p> \u2208  R", "<s3>1 \u00d7 d", "<p>is| extracted from  patch", "<s3>j", "<p> using our encoder network (described in Sect.  3.2 ) that| results in feature matrix  Z", "<s3>n", "<p> \u2208  R", "<s3>M \u00d7 d", "<p>for  P", "<s3>n", "<p>. Finally, a speci\ufb01c graph ( G", "<s3>n", "<p>) for| the n-th patient ( P", "<s3>n", "<p>) can be constructed by assuming patches as nodes. Also,| edges are connected based on the patches\u2019 k-nearest neighbour in the spatial| domain resulting in an adjacency matrix  A", "<s3>n", "<p>. Therefore, for each patient such| as  P", "<s3>n", "<p>, we have a graph de\ufb01ned by adjacency matrix  A", "<s3>n", "<p> with size  M  \u00d7  M  and| features matrix  Z", "<s3>n", "<p> ( G", "<s3>n", "<p> =  graph ( Z", "<s3>n", "<p>, A", "<s3>n", "<p>)). We estimate  K  super-nodes as matrix| S", "<s3>n", "<p> \u2208  R", "<s3>K \u00d7 d", "<p>representing groups of local nodes with similar properties as coarse| features for  P", "<s3>n", "<p>\u2019s slides. The \ufb01nal model ( \u03f5", "<s3>\u03b8", "<p>) with parameters  \u03b8  utilizes  G", "<s3>n", "<p> and| S", "<s3>n", "<p> to predict the risk associated with this patient:|", "<p>risk", "<s3>n", "<p> =  \u03f5", "<s3>\u03b8", "<p>( G", "<s3>n", "<p>, S", "<s3>n", "<p>) =  \u03f5", "<s3>\u03b8", "<p>( graph ( X", "<s3>n", "<p>, A", "<s3>n", "<p>) , S", "<s3>n", "<p>)| (1)|", "<p>3.2| Self-supervised Encoder|", "<p>Due to computational limits and large number of patches available for each| patient, we utilize a self-supervised approach to train an encoder to reduce| the inputs\u2019 feature space size. Therefore, We use DINO [ 9 ], a knowledge dis-| tillation model (KDM), with vision transformer (ViT) [ 13 ] as the backbone. It| utilizes global and local augmentations of the input  patch", "<s3>j", "<p> and passes them| to the student ( S", "<s3>\u03b8", "<s6>1", "<s3>,V iT", "<p> ) and teacher ( T", "<s3>\u03b8", "<s6>2", "<s3>,V iT", "<p> ) models to \ufb01nd their respective|", "", "<s1>768| P. Azadi et al.|", "<s1>Fig. 1.  The overview of our proposed method. a) The input slide is tiled into non-| overlapping patches. b) The patches are fed into a self-supervised encoder to extract| embeddings. c) A graph is constructed and the new local instance-level embeddings| are obtained through the message-passing process. d) The global context representa-| tions in the form of super-nodes are extracted utilizing two unsupervised loss functions| ( R", "<s5>minCUT", "<s1> ,  R", "<s5>orthognal", "<s1>). e) The \ufb01ne and coarse feature vectors are aggregated in the| distillation module to obtain a representation that accounts for both local and global| (contextual) histo-morphological features. Three di\ufb00erent strategies (S1, S2, S3) are| explored in this module. Finally, a Multilayer Perceptron (MLP) is deployed to esti-| mate the risk using \ufb01nal resultant vectors.|", "", "<p>representations without any labels. Then, by using distillation loss, it makes the| representations\u2019 distribution similar to each other. Finally, the \ufb01xed weights of| the teacher model are utilized in order to encode the input patches.|", "<p>3.3| Local Graph Neural Network|", "<p>GNN\u2019s objective is to \ufb01nd new nodes\u2019 embeddings via integrating local neighbors\u2019| interactions with individual properties of patches. By exploiting the message| passing mechanism, this module iteratively aggregates features from neighbors| of each vertex and generates the new node representations. We employ two graph| convolution isomorphism operators (GINconv) [ 30 ] with the generalized form as:|", "<p>X", "<s3>\u2032| n", "<p>=  \u03c6  ( A", "<s3>n", "<p>+ (1 +  \u03f5 ) .I ) .X", "<s3>n", "<p>)  ,| (2)|", "<p>where  \u03f5  is a small positive value and  I  is the identity matrix. Also,  \u03c6  denotes the| weights of two MLP layers.  X", "<s3>n", "<p> \u2208  R", "<s3>M \u00d7 d", "<p>and  X", "<s3>\u2032| n", "<p>\u2208  R", "<s3>M \u00d7 d", "<p> are GINconv\u2019s input| and output feature matrices for  P", "<s3>n", "<p>, which  X", "<s3>n", "<p> equals  Z", "<s3>n", "<p> for the \ufb01rst layer.|", "<p>3.4| Super-Nodes Extractor|", "<p>In order to \ufb01nd the coarse histo-morphological patterns disguised in the local| graph, we propose extracting  K  Super-nodes, which each represents a weighted| cluster of further processed local features. Intuitively, the number of super-nodes| K should not be very large or small, as the former encourages them to only| represent local clusters and the latter leads to larger clusters and loses subtle|", "", "<s1>ALL-IN| 769|", "", "<p>details. We exploit the minCUT [ 5 ] idea to extract super-nodes in a di\ufb00erentiable| process after an auxiliary GINconv to focus more on large-scale interactions and| to \ufb01nally learn the most global correlated super-nodes. Inspired by the relaxation| form of the known K-way minCUT problem, we create a continuous cluster| matrix  C", "<s3>n", "<p> \u2208  R", "<s3>M \u00d7 K", "<p>using MLP layers and can \ufb01nally estimate the super-nodes| features ( S", "<s3>n", "<p> \u2208  R", "<s3>M \u00d7 d", "<p>) as:|", "<p>S", "<s3>n", "<p> =  C", "<s3>T| n", "<p>.X", "<s3>\u2032| n", "<p>,| C", "<s3>n", "<p> =  softmax  ( ReLU ( X", "<s3>\u2032| n", "<p>.W", "<s3>1", "<p>) .W", "<s3>2", "<p>)  ,| (3)|", "<p>where  W", "<s3>1", "<p>, W", "<s3>2", "<p> are MLPs\u2019 weights. Hence, the extracted nodes are directly depen-| dent on the \ufb01nal survival-speci\ufb01c loss. In addition, two additional unsupervised| weighted regularization terms are optimized to improve the process:|", "<p>MinCut Regularizer.  This term is motivated by the original minCUT problem| and intends to solve it for the the patients\u2019 graph. It is de\ufb01ned as:|", "<p>R", "<s3>minCUT", "<p> =  \u2212 Tr ( C", "<s3>T| n", "<p>.A", "<s3>n,norm", "<p>.C", "<s3>n", "<p>)|", "<p>Tr ( C", "<s3>T n", "<p> .D", "<s3>n", "<p>.C", "<s3>n", "<p>)| ,| (4)|", "<p>where  D", "<s3>n", "<p> is the diagonal degree matrix for  A", "<s3>n", "<p>. Also,  Tr ( . ) represents the trace| of matrix and  A", "<s3>n,norm", "<p> is the normalized adjacency matrix.  R", "<s3>minCUT", "<p> \u2019s mini-| mum value happens when  Tr ( C", "<s3>T| n", "<p>.A", "<s3>n,norm", "<p>.C", "<s3>n", "<p>) equals  Tr ( C", "<s3>T| n", "<p>.D", "<s3>g,n", "<p>.C", "<s3>n", "<p>). There-| fore, minimizing  R", "<s3>minCUT", "<p> causes assigning strongly similar nodes to a same| super-node and prevent their association with others.|", "<p>Orthogonality Regularizer.  R", "<s3>minCUT", "<p> is non-convex and potent to local min-| ima such as assigning all vertexes to a super-node or having multiple super-nodes| with only a single vertex.  R", "<s3>orthogonal", "<p> penalizes such solutions and helps the model| to distribute the graph\u2019s features between super-nodes. It can be formulated as:|", "<p>R", "<s3>orthogonal", "<p> =| \u0002\u0002\u0002\u0002|", "<p>\u0002\u0002\u0002\u0002| C", "<s3>T| n", "<p>.C", "<s3>n|", "", "<p>|| C", "<s3>T n", "<p> .C", "<s3>n", "<p>||", "<s3>F|", "<p>\u2212| I| \u221a|", "<p>K|", "<p>\u0002\u0002\u0002\u0002|", "<p>\u0002\u0002\u0002\u0002|", "<s3>F|", "<p>,| (5)|", "<p>where  || . ||", "<s3>F", "<p> is the Frobenius norm, and  I  is the identity matrix. This term pushes| the model\u2019s parameters to \ufb01nd coarse features that are orthogonal to each other| resulting in having the most useful global features.| Overall, utilizing these two terms encourages the model to extract super-| nodes by leaning more towards the strongly associated vertexes and keeping| them against weakly connected ones [ 5 ], while the main survival loss still controls| the global extraction process.|", "<p>3.5| Fine-Coarse Distillation|", "<p>We propose our \ufb01ne-coarse morphological feature distillation module to leverage| all-scale interactions in the \ufb01nal prediction by \ufb01nding a local and a global patient-| level representations ( \u02c6 h", "<s3>l,n", "<p>,  \u02c6 h", "<s3>g,n", "<p>). Assume that  X", "<s3>\u2032| n", "<p>\u2208  R", "<s3>M \u00d7 d", "<p> and  S", "<s3>n", "<p>\u2208  R", "<s3>K \u00d7 d", "<p> are| the feature matrices taken from local GNN (Sect.  3.3 ) and super-nodes for  P", "<s3>n", "<p>,| respectively. We explore 3 di\ufb00erent attention-based feature distillation strategies| for this task, including:|", "", "<s1>770| P. Azadi et al.|", "", "<p>\u2013  Dual Attention (DA):  Two gated self-attention modules for local and| global properties with separate weights ( W", "<s3>\u03c6,l", "<p>, W", "<s3>\u03c6,g", "<p>, W", "<s3>k,l", "<p>, W", "<s3>k,g", "<p>, W", "<s3>q,l", "<p>, W", "<s3>q,g", "<p>)| are utilized to \ufb01nd patches scores  \u03b1", "<s3>l", "<p> \u2208  R", "<s3>1 \u00d7 M", "<p>and  \u03b1", "<s3>g", "<p> \u2208  R", "<s3>1 \u00d7 K", "<p>and the \ufb01nal| features ( \u02c6 h", "<s3>l,n", "<p>,  \u02c6 h", "<s3>g,n", "<p> ) as:|", "", "<s1>\u02c6 h", "<s5>l,n", "<s1> =|", "", "<s5>M|", "<s1>\u0002|", "", "<s5>i =1|", "<s1>W", "<s5>\u03c6,l", "<s1>\u03b1", "<s5>l,i", "<s1>x", "<s5>\u2032| n,i", "<s1>, \u03b1", "<s5>l", "<s1>=  softmax| \u0003| W", "<s5>v,l|", "<s1>\u0004| tanh ( W", "<s5>q,l", "<s1>X|", "<s6>\u2032", "<s5>T| n", "<s1>)  \u00b7  sigm ( W", "<s5>k,l", "<s1>X|", "<s6>\u2032", "<s5>T| n", "<s1>)| \u0005\u0006| ,|", "", "<p>(6)|", "", "<s1>\u02c6 h", "<s5>g,n", "<s1> =|", "", "<s5>K|", "<s1>\u0002|", "", "<s5>i =1|", "<s1>W", "<s5>\u03c6,g", "<s1>\u03b1", "<s5>g,i", "<s1>s", "<s5>n,i", "<s1>, \u03b1", "<s5>g", "<s1> =  softmax| \u0003| W", "<s5>v,g|", "<s1>\u0004| tanh ( W", "<s5>q,g", "<s1>S", "<s5>T| n", "<s1>)  \u00b7  sigm ( W", "<s5>k,g", "<s1>S", "<s5>T| n", "<s1>)| \u0005\u0006| ,|", "", "<p>(7)| where  x", "<s3>\u2032| n,i", "<p>and  s", "<s3>n,i", "<p> are rows of  X", "<s3>\u2032| n", "<p>and  S", "<s3>n", "<p>, respectively, and the \ufb01nal repre-| sentation ( \u02c6 h ) is generated as  \u02c6 h  =  cat ( \u02c6 h", "<s3>l", "<p>, \u02c6 h", "<s3>g", "<p>).| \u2013  Mixed Guided Attention (MGA):  In the \ufb01rst strategy, the information| \ufb02ows from local and global features to the \ufb01nal representations in paral-| lel without mixing any knowledge. The purpose of this policy is the heavy| fusion of \ufb01ne and coarse knowledge by exploiting shared weights ( W", "<s3>\u03c6,shared", "<p>,| W", "<s3>k,shared", "<p>,  W", "<s3>q,shared", "<p>,  W", "<s3>v,shared", "<p>) in both routes and bene\ufb01ting from the guid-| ance of local representation on learning the global one by modifying Eq. ( 7 )| to:|", "<s1>\u03b1", "<s5>g", "<s1> =  softmax| \u0003| W", "<s5>\u03c6,g|", "<s1>\u0004| tanh ( W", "<s5>q,g", "<s1>S", "<s5>T| n", "<s1>\u02c6 h", "<s5>l,n", "<s1>)  \u00b7  sigm ( W", "<s5>k,g", "<s1>S", "<s5>T| n", "<s1>\u02c6 h", "<s5>l,n", "<s1>)| \u0005\u0006|", "<p>(8)|", "<p>\u2013  Mixed Co-Attention (MCA):  While the \ufb01rst strategy allows the extreme| separation of two paths, the second one has the highest level of mixing infor-| mation. Here, we take a balanced policy between the independence and knowl-| edge mixture of the two routes by only sharing the weights without using any| guidance.|", "", "<h2>4| Experiments and Results|", "", "<p>4.1| Dataset|", "<p>We utilize two prostate cancer (PCa) datasets to evaluate the performance of| our proposed model. The \ufb01rst set (PCa-AS) includes 179 PCa patients who| were managed with Active Surveillance (AS). Radical therapy is considered| overtreatment in these patients, so they are instead monitored with regular| serum prostate-speci\ufb01c antigen (PSA) measurements, physical examinations,| sequential biopsies, and magnetic resonance imaging [ 23 ]. However, AS may be| over- or under-utilized in low- and intermediate-risk PCa due to the uncertainty| of current methods to distinguish indolent from aggressive cancers [ 11 ]. Although| majority of patients in our cohort are classi\ufb01ed as low-risk based on NCCN guide-| lines [ 21 ], a signi\ufb01cant subset of them experienced disease upgrade that triggered| de\ufb01nitive therapy (range: 6.2 to 224 months after diagnosis).| The second dataset (PCa-BT) includes 105 PCa patients with low to high| risk disease who went through brachytherapy. This treatment involves placing a| radioactive material inside the body to safely deliver larger dose of radiation at|", "", "<s1>ALL-IN| 771|", "<s1>Table 1.  Comparison of our method against baselines and ablation study on policies.|", "", "<s4>Model| c-index  \u2191| p-value  \u2193| High  \u2193  - Low  \u2191  Median Time Parameters|", "<s4>PCa-AS| PCa-BT| PCa-AS PCa-BT PCa-AS| PCa-BT| PCa-AS|", "<s4>DeepSet| 0 . 495  \u00b1  0 . 017| 0 . 50  \u00b1  0 . 0| 0.837| 0.912| 67.78\u201371.87| 24.62\u201324.89| 329K|", "<s4>AMIL| 0 . 544  \u00b1  0 . 06| 0 . 533  \u00b1  0 . 060| 0.820| 0.148| 48.99\u201389.10| 21.86\u201330.71| 592K|", "<s4>DGC| 0 . 522  \u00b1  0 . 113| 0 . 572  \u00b1  0 . 150| 0.494| 0.223| 47.61\u201396.66| 23.44\u201324.85| 626K|", "<s4>Patch-GCN| 0 . 555  \u00b1  0 . 059| 0 . 541  \u00b1  0 . 118| 0.630| 0.981| 37.72\u201394.95| 23.05\u201325.25| 1,302K|", "<s4>ALL-IN +| DA (ours)|", "<s4>0 . 631  \u00b1  0 . 058| 0 . 596  \u00b1  0 . 062| <  0 . 01| <  0 . 01| 37.72\u2013115.91| 21.86\u201335.77| 850K|", "<s4>ALL-IN +| MGA (ours)|", "<s4>0 . 632  \u00b1  0 . 060| 0 . 589  \u00b1  0 . 074| <  0 . 01| <  0 . 01| 47.61\u2013101.39| 21.86\u201335.77| 653K|", "<s4>ALL-IN +| MCA (ours)|", "<s4>0 . 639  \u00b1  0 . 048 0 . 600  \u00b1  0 . 077  <  0.01| <  0.01| 36.5\u2013131.71 21.86\u201335.77| 653K|", "", "<p>one time [ 25 ]. The recorded endpoint for this set is biochemical recurrence with| time to recurrence ranging from 11.7 to 56.1 months.| We also utilized the Prostate cANcer graDe Assessment (PANDA) Challenge| dataset [ 7 ] that includes more than 10,000 PCa needle biopsy slides (no outcome| data) as an external dataset for training the encoder of our model.|", "<p>4.2| Experiments|", "<p>We evaluate the models\u2019 performance in two scenarios utilizing several objective| metrics. Implementation details are available in supplementary material.|", "<p>Hazard (Risk) Prediction.  We utilize concordance-index (c-index) that mea-| sures the relative ordering of patients with observed events and un-censored| cases relative to censored instances [ 2 ]. Using c-index, we compare the quality| of hazard ranking against multiple methods including two MIL (DeepSet [ 31 ],| AMIL [ 14 ]) and graph-based (DGC [ 17 ] and Patch-GCN [ 10 ]) models that were| utilized recently for histopathology risk assessment. C-index values are avail-| able in Table  1 . The proposed model with all strategies outperforms baselines| across all sets and is able to achieve 0.639 and 0.600 on PCa-AS and PCa-BT,| while the baselines, at best, obtain 0.555, and 0.572, respectively. Statistical tests| (paired t-test) on c-indices also show that our model is statistically better than| all baselines in PCa-AS and also superior to all models, except DGC, in PCa-BT.| Superior performance of our MCA policy implies that balanced exploitation of| \ufb01ne and coarse features with shared weights may provide more robust contex-| tual information compared to using mixed guided information or utilizing them| independently.|", "<p>Patient Strati\ufb01cation.  The capacity of stratifying patients into risk groups| (e.g., low and high risk) is another criterion that we employ to assess the util-| ity of models in clinical practice. We evaluate model performances via Kaplan-| Meier curve [ 15 ] (cut-o\ufb00 set as the ratio of patients with recurrence within 3|", "", "<s1>772| P. Azadi et al.|", "<s1>Fig. 2.  Kaplan-Meier curves of mixed co-attention model for PCa-AS and PCa-BT.|", "", "<p>years of therapy initiation for PCa-BT and the ratio of upgraded cases for PCa-| AS), LogRank test [ 6 ] (with 0.05 as signi\ufb01cance level), and median outcome| associated with risk groups (Table  1  and Fig.  2 ). Our model strati\ufb01ed PCa-AS| patients into high- and low-risk groups with median time to progression of 36.5| and 131.7 months, respectively. Moreover, PCa-BT cases assigned to high- and| low-risk groups have median recurrence time of 21.86 and 35.7 months. While| none of the baselines are capable of assigning patients into risk groups with| statistical signi\ufb01cance, our distillation policies achieve signi\ufb01cant separation in| both PCa-AS and PCa-BT datasets; suggesting that global histo-morphological| properties improve patient strati\ufb01cation performance. Furthermore, our \ufb01ndings| have signi\ufb01cant clinical implications as they identify, for the \ufb01rst time, high-| risk prostate cancer patients who are otherwise known to be low-risk based on| clinico-pathological parameters. This group should be managed di\ufb00erently from| the rest of the low-risk prostate cancer patients in the clinic. Therefore, pro-| viding evidence of the predictive (as opposed to prognostic) clinical information| that our model provides. While a prognostic biomarker provides information| about a patient\u2019s outcome (without speci\ufb01c recommendation on the next course| of action), a predictive biomarker gives insights about the e\ufb00ect of a therapeutic| intervention and potential actions that can be taken.|", "<p>Ablation Study.  We perform ablation study (Table  2 ) on various components| of our framework including local nodes, self-supervised ViT-based encoder, and| most importantly, super-nodes in addition to \ufb01ne-coarse distillation module.| Although our local-only model is still showing superior results compared to| baselines, this analysis demonstrates that all modules are essential for learn-| ing the most e\ufb00ective representations. We also assess the impact of our ViT on| the baselines (full-results in appendix), showing that it can, on average, improve| their performance by an increase of  \u223c  0 . 03 in c-index for PCa-AS. However, the| best baseline with ViT still has poorer performance compared to our model in| both datasets, while the number of parameters (reported for ViT embeddings\u2019| size in Table  1 ) in our full-model is about half of this baseline. Achieving higher| c-indices in our all model versions indicates the important role of coarse features| and global context in patient risk estimation in addition to local patterns.|", "", "<s1>ALL-IN| 773|", "<s1>Table 2.  Ablation study on di\ufb00erent modules.|", "<s1>Modules| c-index  \u2191|", "<s1>Model| Local-node our KDM-| ViT|", "<s1>Super-node| + Distillation| Model|", "<s1>PCa-AS| PCa-BT|", "<s1>Patch-GCN  \u2713| \u2713| \u2717| 0 . 627  \u00b1  0 . 046| 0 . 588  \u00b1  0 . 067|", "<s1>Ours| \u2713| \u2717| \u2717| 0 . 584  \u00b1  0 . 072| 0 . 550  \u00b1  0 . 109|", "<s1>\u2713| \u2713| \u2717| 0 . 622  \u00b1  0 . 055| 0 . 597  \u00b1  0 . 045|", "<s1>\u2713| \u2713| \u2713| 0 . 639  \u00b1  0 . 048 0 . 600  \u00b1  0 . 077|", "", "<h2>5| Conclusion|", "", "<p>While risk assessment is relatively under-explored, most existing methods are| focused only on small \ufb01elds of view. In this work, we introduce a novel graph-| based model for integrating global and local features, which utilizes interactions| at a larger scale for improved risk strati\ufb01cation. Using two cancer datasets, we| evaluated the e\ufb00ectiveness of our model against the baseline methods for hazard| prediction and patients strati\ufb01cation. Our results suggest that the proposed| model outperforms them in risk assessment and is capable of separating patients| into statistically signi\ufb01cant risk groups with actionable clinical utility. The full| capacity of this work can be revealed by extending it to other histology tasks.|", "", "<s1>Acknowledgment:.  This work was supported by a Canadian Institutes of Health| Research grant to AB, PB, and LG and Michael Smith Health Research BC Scholar| grant to AB.|", "", "<h2>References|", "", "<s1>1. Abu-Rustum, N.R., et al.: The revised 2009 \ufb01go staging system for endometrial| cancer: should the 1988 \ufb01go stages ia and ib be altered? Int. J. Gynecol. Cancer| 21 (3) (2011)| 2. Alabdallah, A., Ohlsson, M., Pashami, S., R\u00a8ognvaldsson, T.: The concordance| index decomposition-a measure for a deeper understanding of survival prediction| models. arXiv preprint  arXiv:2203.00144  (2022)| 3. Alon, U., Yahav, E.: On the bottleneck of graph neural networks and its practical| implications. arXiv preprint  arXiv:2006.05205  (2020)| 4. Angell, H., Galon, J.: From the immune contexture to the immunoscore: the role of| prognostic and predictive immune markers in cancer. Curr. Opin. Immunol.  25 (2),| 261\u2013267 (2013)| 5. Bianchi, F.M., Grattarola, D., Alippi, C.: Spectral clustering with graph neural| networks for graph pooling. In: International Conference on Machine Learning,| pp. 874\u2013883. PMLR (2020)| 6. Bland, J.M., Altman, D.G.: The logrank test. BMJ  328 (7447), 1073 (2004)| 7. Bulten, W., et al.: Arti\ufb01cial intelligence for diagnosis and gleason grading of| prostate cancer: the panda challenge. Nat. Med.  28 (1), 154\u2013163 (2022)|", "<s1>774| P. Azadi et al.|", "<s1>8. Carbonneau, M.A., Cheplygina, V., Granger, E., Gagnon, G.: Multiple instance| learning: a survey of problem characteristics and applications. Pattern Recogn.| 77 , 329\u2013353 (2018)| 9. Caron, M., Touvron, H., Misra, I., J\u00b4egou, H., Mairal, J., Bojanowski, P., Joulin, A.:| Emerging properties in self-supervised vision transformers. In: Proceedings of the| IEEE/CVF International Conference on Computer Vision, pp. 9650\u20139660 (2021)| 10. Chen, R.J., et al.: Whole slide images are 2D point clouds: context-aware survival| prediction using patch-based graph convolutional networks. In: de Bruijne, M.,| et al. (eds.) MICCAI 2021. LNCS, vol. 12908, pp. 339\u2013349. Springer, Cham (2021).| https://doi.org/10.1007/978-3-030-87237-3 33|", "<s1>11. Cooperberg,| M.R.,| et| al.:| Outcomes| of| active| surveillance| for| men| with| intermediate-risk prostate cancer. J. Clin. Oncol. O\ufb00. J. Am. Soc. Clin. Oncol.| 29 (2), 228\u2013234 (2011)| 12. Darbandsari, A., et al.: Identi\ufb01cation of a novel subtype of endometrial cancer| with unfavorable outcome using arti\ufb01cial intelligence-based histopathology image| analysis (2022)| 13. Dosovitskiy, A., et al.: An image is worth 16 \u00d7 16 words: transformers for image| recognition at scale. arXiv preprint  arXiv:2010.11929  (2020)| 14. Ilse, M., Tomczak, J., Welling, M.: Attention-based deep multiple instance learning.| In: International Conference on Machine Learning, pp. 2127\u20132136. PMLR (2018)| 15. Kaplan, E.L., Meier, P.: Nonparametric estimation from incomplete observations.| J. Am. Stat. Assoc.  53 (282), 457\u2013481 (1958)| 16. Lee, Y., et al.: Derivation of prognostic contextual histopathological features from| whole-slide images of tumours via graph deep learning. Nat. Biomed. Eng., 1\u201315| (2022)| 17. Li, R., Yao, J., Zhu, X., Li, Y., Huang, J.: Graph CNN for survival analysis on| whole slide pathological images. In: Frangi, A.F., Schnabel, J.A., Davatzikos, C.,| Alberola-L\u00b4opez, C., Fichtinger, G. (eds.) MICCAI 2018. LNCS, vol. 11071, pp.| 174\u2013182. Springer, Cham (2018).  https://doi.org/10.1007/978-3-030-00934-2 20|", "<s1>18. Liu, W., He, Q., He, X.: Weakly supervised nuclei segmentation via instance learn-| ing. In: 2022 IEEE 19th International Symposium on Biomedical Imaging (ISBI),| pp. 1\u20135. IEEE (2022)| 19. Lu, M.Y., Williamson, D.F., Chen, T.Y., Chen, R.J., Barbieri, M., Mahmood,| F.: Data-e\ufb03cient and weakly supervised computational pathology on whole-slide| images. Nat. Biomed. Eng.  5 (6), 555\u2013570 (2021)| 20. Mobadersany, P., et al.: Predicting cancer outcomes from histology and genomics| using convolutional networks. Proc. Natl. Acad. Sci.  115 (13), E2970\u2013E2979 (2018)| 21. Moses, K.A., et al.: Nccn guidelines", "<s5> R|", "<s1>\u20dd  insights: prostate cancer early detection, ver-| sion 1.2023: featured updates to the nccn guidelines. J. Natl. Comprehens. Cancer| Netw.  21 (3), 236\u2013246 (2023)| 22. Oono, K., Suzuki, T.: Graph neural networks exponentially lose expressive power| for node classi\ufb01cation. arXiv preprint  arXiv:1905.10947  (2019)| 23. Ouzzane, A., et al.: Magnetic resonance imaging targeted biopsy improves selection| of patients considered for active surveillance for clinically low risk prostate cancer| based on systematic biopsies. J. Urol.  194 (2), 350\u2013356 (2015)| 24. Rony, J., Belharbi, S., Dolz, J., Ayed, I.B., McCa\ufb00rey, L., Granger, E.: Deep| weakly-supervised learning methods for classi\ufb01cation and localization in histology| images: a survey. arXiv preprint  arXiv:1909.03354  (2019)| 25. Skowronek, J.: Current status of brachytherapy in cancer treatment-short overview.| J. Contemp. Brachyther.  9 (6), 581\u2013589 (2017)|", "<s1>ALL-IN| 775|", "<s1>26. Son, B., Lee, S., Youn, H., Kim, E., Kim, W., Youn, B.: The role of tumor microen-| vironment in therapeutic resistance. Oncotarget  8 (3), 3933 (2017)| 27. Srinidhi, C.L., Ciga, O., Martel, A.L.: Deep neural network models for computa-| tional histopathology: a survey. Med. Image Anal.  67 , 101813 (2021)| 28. Tang, S., Chen, D., Bai, L., Liu, K., Ge, Y., Ouyang, W.: Mutual crf-gnn for few-| shot learning. In: Proceedings of the IEEE/CVF Conference on Computer Vision| and Pattern Recognition, pp. 2329\u20132339 (2021)| 29. Wetstein, S.C., et al.: Deep learning-based breast cancer grading and survival anal-| ysis on whole-slide histopathology images. Sci. Rep.  12 (1), 1\u201312 (2022)| 30. Xu, K., Hu, W., Leskovec, J., Jegelka, S.: How powerful are graph neural networks?| arXiv preprint  arXiv:1810.00826  (2018)| 31. Zaheer, M., Kottur, S., Ravanbakhsh, S., Poczos, B., Salakhutdinov, R.R., Smola,| A.J.: Deep sets. Adv. Neural Inf. Process. Syst.  30 , 1\u201311 (2017)| 32. Zhu, X., Yao, J., Zhu, F., Huang, J.: Wsisa: making survival prediction from whole| slide histopathological images. In: Proceedings of the IEEE Conference on Com-| puter Vision and Pattern Recognition, pp. 7234\u20137242 (2017)|"]