{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_words = ['cancer', 'tumor', 'tumour', 'malignant', 'benign', 'metastasis', 'metastatic', 'neoplasm', 'neoplastic', 'carcinoma', \n",
    "               'sarcoma', 'lymphoma', 'leukemia', 'melanoma', 'myeloma', 'adenoma', 'adenocarcinoma', 'glioma', 'glioblast']\n",
    "\n",
    "demographics_keywords = ['age', 'gender', 'sex', 'women', 'woman', 'female', 'men', 'man', 'male', 'group', 'patient', 'patients', \n",
    "                         'participant', 'participants',  'location','geolocation', 'geographical', 'geographic', 'region', 'country', \n",
    "                         'countries', 'national', 'nation', 'city', 'cities', 'area', 'areas', 'hospital', 'hospitals', 'clinic', \n",
    "                         'clinics', 'center', 'centers', 'facility', 'facilities', 'institution','institutions', 'organization', \n",
    "                         'organizations', 'society', 'societies', 'community','communities', 'population', 'demographic', 'demographics', \n",
    "                         'characteristic', 'characteristics']\n",
    "\n",
    "organs_keywords = ['adrenal', 'anal', 'anus' 'arteries', 'gi','tract', 'gi-tract', 'colon', 'bladder','bone', 'marrow', \n",
    "                   'bronchi', 'bronchioles', 'bulbourethral', 'capillaries', 'cecum', 'cerebellum','cerebral', 'cervix', \n",
    "                   'choroid', 'plexus', 'ciliary', 'body', 'clitoris', 'cochlea', 'cornea','cranial', 'nerves', 'duodenum', \n",
    "                   'eardrum', 'nervous', 'system','epididymis', 'esophagus','fallopian', 'tubes','gallbladder', 'ganglia', \n",
    "                   'heart', 'skeleton', 'hypothalamus', 'ileum', 'interstitium','iris', 'jejunum', 'joint', 'joints', 'kidneys', \n",
    "                   'larynx','ligament', 'ligaments','liver','lung', 'lungs', 'lymph', 'node', 'lymphatic', 'vessel', 'glands',\n",
    "                   'oblongata', 'mesentery','brain', 'ear', 'ossicles', 'muscles', 'nasal', 'cavity', 'olfactory','epithelium', \n",
    "                   'ovaries', 'pancreas', 'parathyroid','parotid', 'penis', 'pharynx', 'pineal', 'pituitary', 'placenta', 'prostate',\n",
    "                   'rectum', 'retina', 'sigmoid', 'skin', 'spinal', 'nerves', 'spleen', 'stomach', 'tissue', 'sublingual', \n",
    "                   'submandibular', 'teeth','tendons', 'testes', 'thalamus', 'spinal', 'cord', 'thymus', 'thyroid', 'tongue', \n",
    "                   'tonsils', 'trachea', 'transverse', 'ureter', 'urethra','uterus', 'vagina', 'veins', 'vulva',\n",
    "                   'lung', 'lungs', 'pulmonary', 'respiratory', 'bronchial', 'bronchi', 'bronchus','bronchial', 'trachea', \n",
    "                   'tracheal', 'thoracic', 'thorax', 'diaphragm', 'diaphragmatic', 'pleural', 'pleura', 'alveolar', \n",
    "                   'alveoli','gi-tract', 'gastrointestinal', 'gastro', 'intestinal', 'digestive', 'digestion', 'stomach', 'gastric', \n",
    "                   'intestine', 'intestines', 'intestinal', 'colon', 'colonic', 'rectum', 'rectal', 'anus', 'anal', 'liver', 'hepatic',\n",
    "                   'hepatitis', 'hepatocellular','hepatoma', 'hepatocarcinoma','cervical','cervix', 'uterus', 'uterine', 'endometrial', \n",
    "                   'ovarian', 'ovary', 'fallopian', 'tube', 'vaginal','prostate', 'testicular', 'testis', 'penile']\n",
    "\n",
    "\n",
    "                \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Importing the CSV module\n",
    "import csv\n",
    "\n",
    "# Step 2: Creating a Python list\n",
    "# demographics_keywords\n",
    "# demographics_others\n",
    "# search words\n",
    "\n",
    "# Step 3: Opening a CSV file in write mode\n",
    "with open('/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/experiments/demographic_keywords.csv', 'w') as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL,delimiter='\\n')\n",
    "    wr.writerow(demographics_keywords)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Opening a CSV file in write mode\n",
    "with open('/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/experiments/organs_other.csv', 'w') as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL,delimiter='\\n')\n",
    "    wr.writerow(organs_keywords)\n",
    "# Step 5: The file is automatically closed when exiting the 'with' block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Opening a CSV file in write mode\n",
    "with open('/Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/experiments/searchwords.csv', 'w') as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL,delimiter='\\n')\n",
    "    wr.writerow(search_words)\n",
    "# Step 5: The file is automatically closed when exiting the 'with' block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: PyPDF2 in /Users/yasminsarkhosh/Library/Python/3.9/lib/python/site-packages (3.0.1)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in /Users/yasminsarkhosh/Library/Python/3.9/lib/python/site-packages (from PyPDF2) (4.9.0)\n",
      "\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install PyPDF2\n",
    "# To read the PDF\n",
    "import PyPDF2\n",
    "import string\n",
    "import nltk \n",
    "%pip install nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a for-loop to open many files (leave a comment if you'd like to learn how).\n",
    "filename = '/Users/yasminsarkhosh/Documents/bachelor thesis data /research papers/Teixeira m.fl. - 2023 - Automated CT Lung Cancer Screening Workflow Using .pdf'\n",
    "#open allows you to read the file.\n",
    "pdfFileObj = open(filename,'rb')\n",
    "#The pdfReader variable is a readable object that will be parsed.\n",
    "pdfReader = PyPDF2.PdfReader(pdfFileObj)\n",
    "#Discerning the number of pages will allow us to parse through all the pages.\n",
    "num_pages = len(pdfReader.pages)\n",
    "count = 0\n",
    "text = \"\"\n",
    "#The while loop will read each page.\n",
    "while count < num_pages:\n",
    "    pageObj = pdfReader.pages[count]\n",
    "    count +=1\n",
    "    text += pageObj.extract_text()\n",
    "#This if statement exists to check if the above library returned words. It's done because PyPDF2 cannot read scanned files.\n",
    "if text != \"\":\n",
    "   text = text.lower()\n",
    "#If the above returns as False, we run the OCR library textract to #convert scanned/image based PDF files into text.\n",
    "else:\n",
    "   text = textract.process(fileurl, method='tesseract', language='eng')\n",
    "#Now we have a text variable that contains all the text derived from our PDF file. Type print(text) to see what it contains. It likely contains a lot of spaces, possibly junk such as '\\n,' etc.\n",
    "#Now, we will clean our text variable and return it as a list of keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll create a new list that contains punctuation we wish to clean.\n",
    "punctuations = ['(',')',';',':','[',']',',']\n",
    "\n",
    "#We initialize the stopwords variable, which is a list of words like \"The,\" \"I,\" \"and,\" etc. that don't hold much value as keywords.\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "#We create a list comprehension that only returns a list of words that are NOT IN stop_words and NOT IN punctuations.\n",
    "keywords = [word for word in tokens if not word in stop_words and not word in punctuations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
