Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_29.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_14.pdf:
the cohort consists of 141 patients with pancreatic ductal adeno-
carcinoma, of an equal ratio of male to female patients.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_11.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_58.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_64.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_71.pdf:
accordingly, direct knowledge transfer using the output of the source domain
predictor may lead to feature bias in the student model due to the unavoid-
able covariance [20] between the target and source domains.
for single-source domain
adaptation approach, cellsegssda and sfda-dpl, we employ two strategies
to ensure the fairness of the experiments: (1) single-source, i.e. performing adap-
tation on each single source, where we select the best results to display in the
table 1; (2) source-combined, i.e. all source domains are combined into a tra-
ditional single source.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_59.pdf:
mesh2ssm can also learn a
population-speciﬁc template, reducing any bias due to template selec-
tion.
mesh2ssm also includes an analysis network that operates on the
learned correspondences to obtain a data-driven template point cloud (i.e., tem-
plate point cloud), which can replace the initial template, and hence reducing
the bias that could arise from template selection.
[13,21] analysis module helps in mitigating bias and
capturing non-linear characteristics of the data.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_57.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_7.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_6.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_56.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_4.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_55.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_45.pdf:
it should be noted in con-
trast to [5] in which only out-of-range samples were contributing to the loss,
in this work, all samples contribute to lvd to reduce the estimation bias.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_51.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_1.pdf:
however, acquiring high-quality pet images requires
injecting a suﬃcient dose (standard dose) of radionuclides into the human body,
which poses unacceptable radiation hazards for pregnant women and infants
even following the as low as reasonably achievable (alara) principle
denoting the output of previous layer
as zp et , the ct-guided cross-attention can be formulated as follows:
output = softmax(qct kt
ct
√
d
+ b) · vp et ,
qct = convq(zct ),
kct = convk(zct ),
vp et = convv (zp et ),
(2)
where d is the number of channels, b is the position bias, and conv(·) denotes
the 1 × 1 × 1 convolution with stride of 1.
2.3
implementation details
typically, the trained diﬀusion model generates target images from random
noise, requiring a large number of steps t to make the ﬁnal perturbed sam-
ple (zt ) close to pure noise.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_52.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_20.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_22.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_25.pdf:
however, the obtained
clustering centers, i.e., the prototypes, are inclined to represent the visual bias
slpd
263
related to staining or scanning procedure rather than medically relevant fea-
tures [33].
the inferior performance of the
global clustering is due to the visual bias underlying the whole dataset.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_24.pdf:
through knowledge distillation, we encour-
250
g. bontempo et al.
age agreement across the predictions delivered at diﬀerent resolutions, while indi-
vidual scale features are learned in isolation to preserve the diversity in terms
of information content.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_39.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_62.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_9.pdf:
the collection of the data was
approved by the responsible ethics committee (commissie mensgebonden onder-
zoek regio arnhem-nijmegen).

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_72.pdf:
by ensuring that the ﬁne-tuning process is representative
of the entire dataset through even sampling from each tissue type, we can elim-
inate bias towards any particular tissue type.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_57.pdf:
using two medical benchmark datasets for melanoma detec-
tion and bone age estimation, we apply our r2r framework to vgg,
resnet and eﬃcientnet architectures and thereby reveal and correct
real dataset-intrinsic artifacts, as well as synthetic variants in a con-
trolled setting.
completing the xai life cycle, we demonstrate multiple
r2r iterations to mitigate diﬀerent biases.
keywords: xai life cycle · bias identiﬁcation · model correction
1
introduction
deep neural networks (dnns) have successfully been applied in research
and industry for a multitude of complex tasks.
https://doi.org/10.1007/978-3-031-43895-0_56
reveal to revise: an xai life cycle for iterative bias correction of dnns
597
fig.
while multiple approaches exist
for either revealing or revising model biases, only few combine both steps, to
be applicable as a framework.
such frameworks, however, either rely heavily on
human feedback [25,29], are limited to speciﬁc bias types
for revealing
model bias, we propose two orthogonal xai approaches: while spectral rele-
vance analysis (spray)
the arti-
fact masks are further used for evaluation on a poisoned test set and to measure
the remaining attention on the bias.
we demonstrate the applicability and high
automation of r2r on two medical tasks, including melanoma detection and bone
age estimation, using the vgg-16, resnet-18 and eﬃcientnet-b0 dnn architec-
tures.
lastly, we showcase the r2r life
cycle through multiple iterations, unveiling and unlearning diﬀerent biases.
in our r2r framework, we automate the annotation
by following [2] for data labeling through spray outlier clusters, or by collecting
the most representative samples of bias concepts according to crp.
3.1, thereby considerably easing the step from bias identiﬁcation
to correction.
reveal to revise: an xai life cycle for iterative bias correction of dnns
599
existing works for model correction measure the performance on the original
or clean test set, with corrected models often showing an improved generaliza-
tion [13,20].
3
reveal to revise framework
our reveal to revise (r2r) framework comprises the entire xai life cycle, includ-
ing methods for (1) the identiﬁcation of model bias, (2) artifact labeling and local-
ization, (3) the correction of detected misbehavior, and (4) the evaluation of the
improved model.
the
spray clusters then naturally allow us to label data containing the bias.
3.2
methods for model correction
in the following, we present the methods used for mitigating model biases.
clarc for latent space correction.
reveal to revise: an xai life cycle for iterative bias correction of dnns
601
fig.
shown are band-aid, ruler,
skin marker, and synthetic artifacts for the isic dataset, as well as “l”-marker and
synthetic artifacts for the bone age dataset.
4.1
experimental setup
we train vgg-16
[26], resnet-18 [11] and eﬃcientnet-b0 [28] models on the
isic 2019 dataset [7,8,30] for skin lesion classiﬁcation and pediatric bone age
dataset
[10] for bone age estimation based on hand radiographs.
4.2
revealing and revising spurious model behavior
revealing bias: in the ﬁrst step of the r2r life cycle, we can reveal the use
of several artifacts by the examined models, including the well-known band-aid,
ruler and skin marker [6] and our synthetic clever hans for the isic dataset, as
shown in fig. 2 for vgg-16.
besides the synthetic clever hans for bone age classiﬁcation, we
encountered the use of “l” markings, resulting from physical lead markers placed
by radiologist to specify the anatomical side.
interestingly, the “l” markings are
larger for hands of younger children, as all hands are scaled to similar size [10],
oﬀering the model to learn a shortcut by estimating the bone age based on the
relative size of the “l” markings, instead of valid features.
while we revealed
the “l” marking bias using crp, we did not ﬁnd corresponding spray clusters,
underlining the importance of both approaches for model investigation.
as shown in tab. 1 (isic
2019) and appendix a.2 (bone age), we are generally able to improve model
behavior with all methods.
the only exception is the synthetic artifact for vgg-
16, where only rrr mitigates the bias to a certain extent, indicating that
the artifact signal is too strong for the model.
reveal to revise: an xai life cycle for iterative bias correction of dnns
603
fig.
to reveal model bias,
r2r relies on crp and spray.
when applying r2r iteratively, we did not ﬁnd the emergence
of new biases, which, however, might happen if larger parts of the model are ﬁne-
tuned or retrained to correct strong biases.
future research directions include the
application to non-localizable artifacts, and addressing fairness issues in dnns.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_42.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_1.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_46.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_2.pdf:
to ensure fairness and eliminate model ensemble eﬀects, we
only used the model’s prediction with k = 1 during testing.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_20.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_23.pdf:
thus, existing public skin
datasets usually suﬀer from imbalanced problems which then results in class bias
of classiﬁer, for example, poor model performance especially on tail lesion types.
to tackle the challenge of learning unbiased classiﬁers with imbalanced data,
many previous works focus on three main ideas, including re-sampling data [1,
18], re-weighting loss [2,15,22] and re-balancing training strategies [10,23].
to ensure fairness, we re-train all methods by rerun their
released codes on our divided datasets with the same experimental settings.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_32.pdf:
[6], including ignoring local information within each patch, extracting only
single-scale features, and lacking inductive bias.
the employed single-phase annotated dataset is collected from sir run
run shaw hospital (srrsh), aﬃliated with the zhejiang university school of
medicine, and has received the ethics approval of irb.
considering the fairness, all the models below are initialized with pre-trained
weights and adopt 2-d structures using the same slice-level classiﬁcation strategy.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_33.pdf:
through extensive exper-
iments, we found inaccurate sample images with coarse polyp boundary that
is not aligned properly with the original masks may introduce large biases and
noises to the datasets.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_16.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_13.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_11.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_39.pdf:
similarly,
“acq”/“man” denote averages over all acquisition/manifestation shifts per dataset.
results with further metrics are
reported in appendix table 2
dataset
chest x-ray
dermoscopy
fc-microscopy
lung nodule ct
study
iid
cor
acq
iid
cor
acq
man
iid
cor
acq
iid
cor
man
msr
15.3

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_62.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_61.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_48.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_58.pdf:
we follow the extension of
[20] for weight initialization and use the adamw optimizer [11] and empirically
set the initial learning rate to 0.0001, batch size to 2 and 32 for segmentation
and classiﬁcation, maximum iterations to 25w, momentum factor λ to 0.99, and
the number of prototypes k to 256.
to evaluate the covid-19 segmentation performance, we utilized six met-
rics, including the dice similarity coeﬃcient (dsc), intersection over union
(iou), sensitivity (sen), speciﬁcity (spe), hausdorﬀ distance (hd), and aver-
age surface distance (asd).

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_70.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_65.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_72.pdf:
this indirect supervision avoids the misleading of box-shape bias of
annotations.
because
there is a strong box-shape bias in b. training with this bias, the model is forced
to predict the box-shape mask, unable to maintain the polyp’s contours.
this indirect supervision separates p1/p2
from b so that p1/p2 is not aﬀected by the shape bias of b while obtaining
the position and extent of polyps.
because both t1/t2 and b are box-like masks, we directly calculate the super-
vision loss between them without worrying about the misguidance of box-shape
bias.
our weakpolyp predictably outperforms the model supervised by box
masks because it is not aﬀected by the box-shape bias of the annotations.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_57.pdf:
despite good progress,
these methods often have limitations in capturing long-range relationships and
global context information [2] due to the inherent bias of convolutional opera-
tions.
finally, a relative position
bias is added to compute the focal sa for qi by
attention(qi, ki, vi) = softmax(qikt
i
√
d
+ b)vi,
where b = {bl}l
1 is the learnable relative position bias [24].

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_68.pdf:
in addition, medical image anno-
tations can be aﬀected by human bias and poor inter-annotator agreement [23],
further complicating the process.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_45.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_51.pdf:
besides, under
the hausdorﬀ distance for evaluating shape-similarity between ground-truth and
predicted masks, our sdt reports an average score of 44.82 across two test splits,
which improves the previous state-of-the-art approach (i.e., fullnet with an aver-
age score of 50.15) by 10.6%.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_1.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_53.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_37.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_18.pdf:
we
ﬁnd that the ability of classiﬁers to separate individuals into subgroups
varies substantially across medical imaging modalities and protected char-
acteristics; crucially, we show that this property is predictive of algorith-
mic bias.
through theoretical analysis and extensive empirical evalua-
tion (code is available at https://github.com/biomedia-mira/subgroup-
separability), we ﬁnd a relationship between subgroup separability, sub-
group disparities, and performance degradation when models are trained
on data with systematic bias such as underdiagnosis.
although
many methods exist for mitigating bias in image classiﬁers, they often fail unex-
pectedly and may even be harmful in some situations [26].
today, no bias miti-
gation methods consistently outperform the baseline approach of empirical risk
minimisation (erm)
https://doi.org/10.1007/978-3-031-43898-1_18
180
c. jones et al.
image classiﬁers (e.g. biological sex from chest x-ray can be predicted with
> 0.98 auc).
this is especially relevant in
medical imaging, where attributes such as age, biological sex, self-reported race,
socioeconomic status, and geographic location are often considered sensitive for
various clinical, ethical, and societal reasons.
we show that the ability of
models to detect which group an individual belongs to varies across modalities
and groups in medical imaging and that this property has profound consequences
for the performance and fairness of deep classiﬁers.
– we show theoretically that such diﬀerences in subgroup separability aﬀect
model bias in learned classiﬁers and that group fairness metrics may be inap-
propriate for datasets with low subgroup separability.
follow-up work has addi-
tionally shown that these models may use sensitive information to bias their
predictions [7,8].
unfortunately, standard bias mitigation methods from com-
puter vision, such as adversarial training [1,14] and domain-independent training
[24], are unlikely to be suitable solutions.
[26] showed that bias mitigation methods worsen
performance for all groups compared to erm, giving a stark warning that blindly
applying methods and metrics leads to a dangerous ‘levelling down’ eﬀect [16].
closely related to our work is oakden-rayner et al., who
consider how ‘hidden stratiﬁcation’ may aﬀect learned classiﬁers [18]; similarly,
jabbour et al. use preprocessing ﬁlters to inject spurious correlations into chest
x-ray data, ﬁnding that erm-trained models are more biased when the corre-
lations are easier to learn [12]. outside of fairness, our work may have broader
impact in the ﬁelds of distribution shift and shortcut learning [6,25], where many
examples exist of models learning to exploit inappropriate spurious correlations
[3,5,17], yet tools for detecting and mitigating the problem remain immature.
suppose we have access to a
(biased) training dataset, where ptr is the conditional distribution between train-
ing images and training labels; we say that such a dataset is biased if ptr ̸= p.
we focus on group fairness, where each individual belongs to a subgroup a ∈ a
and aim to learn a fair model that maximises performance for all groups when
deployed on an unbiased test dataset drawn from p. we assume that the groups
are consistent across both datasets.
the bias we consider in this work is under-
diagnosis, a form of label noise [4] where some truly positive individuals x+ are
mislabeled as negative.
(8) demonstrate that
tpr of the underdiagnosed group is directly aﬀected by bias from the training
set while other groups are mainly unaﬀected.
given this diﬀerence across groups,
an appropriately selected group fairness metric may be able to identify the bias,
in some cases even without access to an unbiased test set [23].
in such sit-
uations, we expect performance degradation to be uniform across groups and
thus not be detected by group fairness metrics.
tpr(b)
a
≈ |ptr(y|x+, a) > 0.5|
n+,a
≤ |p(y|x+, a) > 0.5|
n+,a
≈ tpr(u)
a , ∀a ∈ a
(10)
we have derived the eﬀect of underdiagnosis bias on classiﬁer performance
for the two extreme cases of high and low subgroup separability.
4, we empirically investigate (i) how subgroup separa-
bility varies in the wild, (ii) how separability impacts performance for each group
when underdiagnosis bias is added to the datasets, (iii) how models encode sen-
sitive information in their representations.
mean and standard deviation are
reported over ten random seeds, with results sorted by ascending mean auc.
dataset-attribute
modality
subgroups
auc
group 0 group 1
μ
σ
papila-sex
fundus image
male
female
0.642 0.057
ham10000-sex
skin dermatology male
female
0.723 0.015
ham10000-age
skin dermatology <60
≥60
0.803 0.020
papila-age
fundus image
<60
≥60
0.812 0.046
fitzpatrick17k-skin skin dermatology i–iii
iv–vi
0.891 0.010
chexpert-age
chest x-ray
<60
≥60
0.920 0.003
mimic-age
chest x-ray
<60
≥60
0.930 0.002
chexpert-race
chest x-ray
white
non-white 0.936 0.005
mimic-race
chest x-ray
white
non-white 0.951 0.004
chexpert-sex
chest x-ray
male
female
0.980 0.020
mimic-sex
chest x-ray
male
female
0.986 0.008
age is consistently
well predicted across all modalities, whereas separability of biological sex varies,
184
c. jones et al.
with prediction of sex from fundus images being especially weak.
performance degradation under label bias
we now test our theoretical ﬁnding: models are aﬀected by underdiagnosis dif-
ferently depending on subgroup separability.
we inject underdiagnosis bias into
each training dataset by randomly mislabelling 25% of positive individuals in
group 1 (see table 1) as negative.
in these experiments, the
proportion of mislabelled images is small relative to the total population; thus,
the underdiagnosed subgroups mostly recover from label bias by sharing the
subgroup separability in medical image classiﬁcation
185
correct mapping with the uncorrupted group.
we see a statistically signiﬁcant performance drop for group 0 in the
mimic-sex experiment – we believe this is because the model learns separate
group-wise mappings, shrinking the eﬀective size of the dataset for group 0.
use of sensitive information in biased models
finally, we investigate how biased models use sensitive information.
in fairness liter-
ature, data is often assumed to contain suﬃcient information to identify indi-
viduals as subgroup members.
we showed,
theoretically and empirically, that the performance and fairness of models trained
on biased data depends on subgroup separability.
when separability is high,
models learn to exploit the sensitive information and the bias is reﬂected by stark
subgroup diﬀerences.
this indicates that group
fairness metrics may be insuﬃcient for detecting bias when separability is low.
our analysis centred on bias in classiﬁers trained with the standard approach
of empirical risk minimisation – future work may wish to investigate whether
subgroup separability is a factor in the failure of bias mitigation methods and
whether it remains relevant in further image analysis tasks (e.g. segmentation).
sources of bias matter.
in our experiments, we injected underdiagnosis bias
into the training set and treated the uncorrupted test set as an unbiased ground
truth.
at least
some of the datasets may already contain an unknown amount of underdiagnosis
bias (among other sources of bias)
this pre-existing bias will likely have
a smaller eﬀect size than our artiﬁcial bias, so it should not play a signiﬁcant
role in our results.
still, the unmeasured bias may explain some variation in
results across datasets.
future work should investigate how subgroup separability
interacts with other sources of bias.
we renew the call for future datasets to be
released with patient metadata and multiple annotations to enable analysis of
diﬀerent sources and causes of bias.
reproducibility and impact.
references
1. alvi, m., zisserman, a., nell˚aker, c.: turning a blind eye: explicit removal of biases
and variation from deep neural network embeddings.
potential sources of dataset bias complicate
investigation of underdiagnosis by machine learning algorithms.
https://doi.org/10.1038/s42256-020-00257-z
7. gichoya, j.w., et al.: ai recognition of patient race in medical imaging: a mod-
elling study.
https://doi.org/10.1016/j.ebiom.2023.104467
9. groh, m., harris, c., daneshjou, r., badri, o., koochek, a.: towards transparency
in dermatology image datasets with skin tone annotations by experts, crowds,
and an algorithm.
https://doi.org/10.1145/3368555.3384468
19. rajpurkar, p., et al.: chexnet: radiologist-level pneumonia detection on chest x-
rays with deep learning, november 2017
20. seyyed-kalantari, l., zhang, h., mcdermott, m.b., chen, i.y., ghassemi, m.:
underdiagnosis bias of artiﬁcial intelligence algorithms applied to chest radiographs
in under-served patient populations.
wachter, s., mittelstadt, b., russell, c.: bias preservation in machine learning:
the legality of fairness metrics under eu non-discrimination law.
wang, z., et al.: towards fairness in visual recognition: eﬀective strategies for bias
mitigation.
zong, y., yang, y., hospedales, t.: medfair: benchmarking fairness for medical
imaging.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_15.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_10.pdf:
no data augmentation techniques are used to ensure fairness.
no data augmentation techniques are used to ensure fairness.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_71.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_66.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_43.pdf:
how-
ever, due to the lack of inductive biases, such as weight sharing and locality, vits
are more data-hungry than cnns, i.e., require more data to train [31].
method
vit mitigate vits’ data-hunger
u f
[7,22,39] √
√ by adding inductive bias
× –
[32]
√
×
√ ×
mdvit
√
√ by multi-domain learning
√ √
various strategies have been proposed to address vits’ data-hunger
(table 1), mainly: adding inductive bias by constructing a hybrid network that
fuses a cnn with a vit
previous mis vits mitigated the data-hunger in one dataset by adding
inductive bias, e.g., swinunet

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_40.pdf:
unlike convolutional networks (cnns), transformers use self-attentions
that do not have a strong inductive bias.
although they,
e.g. swinunetr, achieve state-of-the-art (sota) results on some benchmarks,
the lack of inductive bias makes transformers harder to train, requires much
more training data, and are sensitive to training recipes.
the convolution operation
in cnn provides a strong inductive bias which is translational equivalent and efﬁ-
cient in capturing local features like boundary and texture.
however, this inductive
bias limits the representation power of cnn models which means a potentially lower
c
⃝ the author(s), under exclusive license to springer nature switzerland ag 2023
h. greenspan et al.
although transformers have achieved certain success in medical imaging, the lack
of inductive bias makes them harder to be trained and requires much more training
data to avoid overﬁtting.
besides lacking
inductive bias and enough training data, one extra reason could be that transformers are
computationally much expensive and harder to tune.
[7] uses
gated positional self-attention which is equipped with a soft convolutional inductive
bias.
although swin-transformer uses local window attention to
introduce inductive bias like convolutions, self-attentions can still mess up with the
local details.
it provides 361 training scans with man-
ual labels from 11 medical centers.
for msd datasets, we perform 5-fold cross-validation and ran the base-
line experiments with our codebase using exactly the same hyperparameters as men-
tioned.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_54.pdf:
keywords: breast cancer · weakly-supervised learning · medical
image segmentation · contrastive learning · dce-mri
1
introduction
breast cancer is the most common cause of cancer-related deaths among women
all around the world [8].

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_4.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_41.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_51.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_1.pdf:
all methods are imple-
mented with the same backbone and training protocols to ensure fairness.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_46.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_53.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_20.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_36.pdf:
additionally, the improved edge from lesion segmentation
can be further used for lyme disease classiﬁcation—e.g., in diﬀerentiat-
ing lyme from other similar lesions including tinea corporis and herpes
zoster—with improved model fairness on diﬀerent subpopulations.
[1] yet some
improvements still remain to be addressed, importantly in areas that allow both
algorithmic performance and fairness [2], and in certain medical applications that
promise to signiﬁcantly lessen morbidity and mortality.
[17], usually suﬀer
from relatively low performance and reduced fairness [2,18,19].
secondly, we design a simple yet novel data preprocessing and alternation
method, called edgemixup, to improve lyme disease segmentation and diagno-
sis fairness on samples with diﬀerent skin-tones.
such an improvement is an iterative process that gradually improves lesion
edge detection and segmentation fairness until convergence.
a motivating example to illustrate why edgemixup improves model perfor-
mance and reduces biases via mixing up lesion boundary with original image (heatmap
is generated via grad-cam).
(color ﬁgure online)
converged edge in the ﬁrst step also helps classiﬁcation of lyme diseases via mixup
with improved fairness.
our results show that edgemixup is able to increase segmentation utility
and improve fairness.
we also show that the improved segmentation further
improves classiﬁcation fairness as well as joint fairness-utility metrics compared
to existing debiasing methods, e.g., ad
the reason is that a legacy
diagnosis has no information about lesion and does not know where to locate its
focus, thus easily gets distracted by ﬁngers instead of the lesion pattern.
3
method
in this section, we ﬁrst give the deﬁnition for model fairness, and we then
describe the design of edgemixup for the purpose of de-biasing in fig.
edgemixup improves model fairness on light and dark skin samples in both
segmentation and classiﬁcation tasks, and it has two major components: (i) edge
detection using mixup, and (ii) data preprocessing and alteration for downstream
tasks.
note that the initial
edge detection is irrelevant to the sample size of a particular subpopulation, thus
improving the fairness.
segmentation: performance and fairness (margin of error reported in paren-
thesis)
method
unet
polar
mfsnet
vit-adapter
edgemixup
skin
jaccard 0.7053(0.0035) 0.7126(0.0033) 0.5877(0.0080) 0.7027(0.0057) 0.7807(0.0031)
jgap
0.0809(0.0001) 0.0813(0.0001) 0.1291(0.0076) 0.2346(0.0035) 0.0379(0.0001)
our evaluation metrics include (i) jaccard index (iou
score), which measures the similarity between a predicted mask and the manu-
ally annotated ground truth, and (ii) the gap between jaccard values (jgap) to
measure fairness.
table 2 shows the performance and fairness of edgemixup and diﬀerent
baselines.
table 3 shows utility performance (acc and auc) and fairness results (gaps
of acc and auc between ls and ds subpopulations).
skin disease classiﬁcation and associated bias.
3. by adding the “unet” variant, we
demonstrate here that simply applying lesion edge predicetd by the baseline unet
model, while not optimal, eﬃciently reduces model bias on diﬀerent skin-tone
samples.
edgemixup outperforms sota approaches in balancing the model’s
performance and fairness, i.e., the caiα and cauciα values of edgemixup are
the highest compared with the vanilla resnet34 and other baselines.
6
related work
skin disease classiﬁcation and segmentation: previous researches mainly
work on improving model utility for both medical image
[10] only contains melanoma samples and all of the
samples are with light skins according to our inspection using ita scores.
382
h. yuan et al.
bias mitigation: researchers have addressed bias and heterogeneity in deep
learning models [18,29].
first, masking sensitive factors in imagery is shown
to improve fairness in object detection and action recognition

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_32.pdf:
+ bconvlap
(7)
where ‘∗’ represents the convolution operation, wconv means the weights of the
convolution and bconv denotes the bias, and up(·) is the spatial broadcasting
operation ,which upgrades the bias b ∈ r1×c×1×1×1 into up(b) ∈ r1×c×3×3×3.
in the inference stage, the output feature f is produced by a normal 3 × 3 × 3
convolution as follows:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_33.pdf:
multitask learning ·
hybrid cnn-transformer
1
introduction
breast cancer is the leading cause of cancer-related fatalities among women.
currently, it holds the highest incidence rate of cancer among women in the u.s.,
and in 2022 it accounted for 31% of all newly diagnosed cancer cases [1].
this is primarily because the architectural design of vits does not rely on the
same inductive biases in feature extraction which allow cnns to learn spatially
invariant features.
moreover,
multitask learning acts as a regularizer by introducing inductive bias and pre-
vents overﬁtting [25] (particularly with vits), and with that, can mitigate the
challenges posed by small bus dataset sizes.
to avoid data leakage and bias, we selected the train, test, and vali-
dation sets based on the cases, i.e., the images from one case (patient) were
350
b. shareef et al.
table 2. performance metrics of the compared methods for bus image classiﬁcation
and segmentation.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_27.pdf:
in this paper, we make a ﬁrst attempt to explore a deep
learning method for unsupervised gland segmentation, where no man-
ual annotations are required.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_15.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_28.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_16.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_38.pdf:
keywords: breast cancer · mammogram · risk prediction
1
introduction
breast cancer impacts women globally [15] and mammographic screening for
women over a certain age has been shown to reduce mortality
recently, several studies [8,32,33] revealed the potential of artiﬁcial intelligence
(ai) to develop a better risk assessment model to identify women who may ben-
eﬁt from supplemental screening or a personalized screening interval and these
may lead to improved screening outcomes.
in clinical practice, breast density and traditional statistical methods for pre-
dicting breast cancer risks such as the gail
for medical applications, x typically
represents patient information like age, family history, genetic makeup, and diag-
nostic test results (e.g., a mammogram).
women with dense breasts have a four-to six-fold
higher risk of breast cancer

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_11.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_62.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_61.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_75.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_8.pdf:
such metrics cannot reﬂect the lesion-level accuracy (how many lesion
instances are correctly detected and classiﬁed) and may bias to large lesions when
a patient has multiple tumors.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_9.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_73.pdf:
pathologists and
oncologists can use this information to inspect the validity of the prediction result
and interrogate key aspects of the spatial biology that is critical for patient man-
agement.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_72.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_57.pdf:
in addition, we evaluate the eﬀectiveness of reid by measuring the aver-
age polyp fragmentation rate (fr), deﬁned as the average number of tracklets
polyps are split into.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_43.pdf:
for fairness comparison, we train these models using both video
and image data, treating images as static videos.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_7.pdf:
b1
and b2 are bias vectors.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_5.pdf:
for the fairness of the experiments, we keep the same dataset settings
for yona and all other methods.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_55.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_1.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf:
bias in healthcare negatively impacts marginalized popula-
tionswithlowersocioeconomicstatusandcontributestohealthcareinequal-
ities.
eliminating bias in ai models is crucial for fair and precise medical
implementation.
the development of a holistic approach to reducing bias
aggregationinmultimodalmedicaldataandpromotingequityinhealthcare
ishighlydemanded.racialdisparitiesexistinthepresentationanddevelop-
mentofalgorithmsforpulmonaryembolism(pe),anddeepsurvivalpredic-
tionmodelcanbede-biasedwithmultimodaldata.inthispaper,wepresent
a novel survival prediction (sp) framework with demographic bias disen-
tanglement for pe.
the proposed de-biased sp modules eﬀectively disentangle latent
race-intrinsic attributes from the survival features, which provides a fair
survival outcome through the survival prediction head.
we evaluate our
method using a multimodal pe dataset with time-to-event labels and race
identiﬁcations.
keywords: pulmonary embolism · deep survival prediction ·
de-bias learning · multi-modal learning
1
introduction
bias in medicine has demonstrated a notable challenge for providing comprehen-
sive and equitable care.
implicit biases can negatively aﬀect patient care, particu-
larly for marginalized populations with lower socioeconomic status [30]. evidence
supplementary information the online version contains supplementary material
available at https://doi.org/10.1007/978-3-031-43904-9_50.
https://doi.org/10.1007/978-3-031-43904-9_50
516
z. zhong et al.
has demonstrated that implicit biases in healthcare providers could contribute
to exacerbating these healthcare inequalities and create a more unfair system for
people of lower socioeconomic status
[30]. based on the data with racial bias, the
unfairness presents in developing evaluative algorithms.
along these advancements, bias in
healthcare and ai are exposing poignant gaps in the ﬁeld’s understanding of
model implementation and their utility [25,26].
ai model quality relies on input
data and addressing bias is a crucial research area.
systemic bias poses a greater
threat to ai model’s applications, as these biases can be baked right into the
model’s decision process
[22].
pulmonary embolism (pe) is an example of health disparities related to race.
black patients exhibit a 50% higher age-standardized pe fatality rate and a
twofold risk for pe hospitalization than white patients [18,24].
[7,12,14].
however, one issue with traditional survival analysis is bias from single modal
data that gets compounded when curating multimodal datasets, as diﬀerent
combinations of modes and datasets create with a uniﬁed structure.
multimodal
data sets are useful for fair ai model development as the bias complementary
from diﬀerent sources can make de-biased decisions and assessments.
in that
process, the biases of each individual data set will get pooled together, creating
a multimodal data set that inherits multiple biases, such as racial bias [1,15,23].
in addition, it has been found that creating multimodal datasets without any de-
biasing techniques does not improve performance signiﬁcantly and does increase
bias and reduce fairness [5]. overall, a holistic approach to model development
would be beneﬁcial in reducing bias aggregation in multimodal datasets.
[4] for bias disentanglement
improves model generalization for fairness [3,6,27].
we developed a pe outcome model that predicted mortality and detected
bias in the output.
we then implemented methods to remove racial bias in our
dataset and model and output unbiased pe outcomes as a result.
our contri-
butions are as follows: (1) we identiﬁed bias diversity in multimodal informa-
tion using a survival prediction fusion framework.
(2) we proposed a de-biased
survival prediction framework with demographic bias disentanglement.
(3) the
multimodal cph learning models improve fairness with unbiased features.
id branch (ei;ci) and survival branch (ec;cc) are
trained to disentangle race-intrinsic attributes and survival attributes with the feature
swapping augmentation, respectively.
2
bias in survival prediction
this section describes the detail of how we identify the varying degrees of bias
in multimodal information and illustrates bias using the relative diﬀerence in
survival outcomes.
we will ﬁrst introduce our pulmonary embolism multimodal
datasets, including survival and race labels.
the pulmonary embolism dataset used in this study from 918 patients
(163 deceased, median age 64 years, range 13–99 years, 52% female), including
3978 ctpa images and 918 clinical reports, which were identiﬁed via retro-
spective review across three institutions.
for
each patient, the race labels, survival time-to-event labels and pesi variables
are collected from clinical data, and the 11 pesi variables are used to calcu-
late the pesi scores, which include age, sex, comorbid illnesses (cancer, heart
failure, chronic lung disease), pulse, systolic blood pressure, respiratory rate,
temperature, altered mental status, and arterial oxygen saturation at the time
of diagnosis
[2].
diverse bias of multimodal survival prediction model.
this
redundancy leads to model overﬁtting on race, compromising the fairness of risk
prediction across diﬀerent races.
besides, clinical data in the form of text reports
and pesi variables objectively reﬂect the patient’s physiological information and
the physician’s diagnosis, exhibiting smaller race biases in correlation with sur-
vival across diﬀerent races.
2, we
present a feature-level de-biased sp module that enhances fairness in survival
de-biased outcome prediction model
519
outcomes by decoupling race attributes, as shown in the lower right of fig.
1.
in the de-biased sp module, ﬁrstly, two separate encoders em
i
and em
c are for-
mulated to embed features f m into disentangled latent vectors for race-intrinsic
attributes zid or race-conﬂicting attributes zsur implied survival information [16].
then, the linear classiﬁers cm
i
and cm
c constructed to predict the race label yid
with concatenated vector z =
to disentangle survival features from
the race identiﬁcation, we use the generalized cross-entropy (gce) loss
[31] to
train em
c and cm
c to overﬁt to race label while training em
i
and cm
i
with cross-
entropy (ce) loss.
the relative diﬃculty scores w as deﬁned in eq. 1 reweight
and enhance the learning of the race-intrinsic attributes [20].
+ gce (cc(z), yid)
(2)
to promote race-intrinsic learning in em
i
and cm
i , we apply diversify with
latent vectors swapping.
as the random combination are
generated from diﬀerent samples, the swapping decreases the correlation of these
feature vectors, thereby enhancing the race-intrinsic attributes.
the larger c-index value is
better and the lower bias is fairer.
method
baseline
de-biased sp model
dataset
overall white color bias
overall white color bias
imaging
0.662
0.736
0.422
0.314 0.646
0.656
0.622
0.035
text
0.657
0.642
0.714
0.071 0.719
0.689
0.746
0.057
variable
0.668
0.669
0.741
0.072 0.698
0.683
0.778
0.095
multimodal 0.709
0.692
we apply race-balanced resam-
pling to the training and validation sets to eliminate training bias caused by
minority groups.
based on the com-
parison between the id features and others, it is observed that the clusters containing
race obtained from the same class are more compact.
in general, our
framework including de-biased sp modules shows signiﬁcantly better predictions
in testing set than the pesi-based outcome estimation with c-indexes of 0.669,
0.654, 0.697, 0.043 for the overall testset, white testset, color testset and race
bias.
the de-biased results outperform the baseline in overall survival c-index
and show a lower race bias, especially in imaging- and fusion-based predictions.
the results indicate the eﬀectiveness of the proposed de-biasing in mitigating
race inequity.
the results also prove the observations for the diﬀerent biases
present in diﬀerent modalities, especially in the ctpa images containing more
abundant race-related information.
every 2 columns (overall performance of testing
and bias) represent a training setting.
swapping
×
✓
×
✓
resampling
×
×
✓
✓
dataset
testing bias
testing bias
testing bias
testing bias
imaging
0.666
0.062 0.641
0.014 0.649
0.050 0.622
0.035
text
0.684
0.090 0.711
0.123 0.698
0.102 0.709
0.057
variable
0.702
0.095 0.701
0.052 0.697
0.082 0.699
0.095
multimodal 0.716
0.025 0.737
0.041 0.741
0.011 0.743
0.012
diction performance based on multiply modalities is signiﬁcantly better than the
pesi-based outcome estimation.
the disentangled representations, transformed
from latent space to a 2d plane via tsne and color-coded by race [9], are shown
in fig.
2. we observe the disentanglement in the visualization of the id features
zid, while the survival features zsur eliminate the race bias.
the lack of appar-
ent race bias observed in both the original features and those encoded in the
baseline can be attributed to the subordinate role that id features play in the
multimodal information.
we conducted ablation studies to examine the eﬀect of the two key compo-
nents, including swapping feature augmentation and race-balance resampling.
the swapping augmenta-
tion provides a strong bias correction eﬀect for image data with obvious bias.
for clinical data, the resampling generally improves performance in most cases.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_52.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_3.pdf:
the rapid identiﬁcation and accurate diagnosis of breast can-
cer, known as the killer of women, have become greatly signiﬁcant for
those patients.
keywords: breast cancer · histopathological image · super-resolution ·
classiﬁcation · joint training
1
introduction
breast cancer is one of the high-mortality cancers among women in the 21st
century.
every year, 1.2 million women around the world suﬀer from breast
cancer and about 0.5 million die of it

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_20.pdf:
updating prototype online: the prototypes are updated in an online man-
ner, thereby allowing them to adjust quickly to changes in the nodule represen-
tations.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_35.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_27.pdf:
prompt tuning proves to be an
eﬃcient adaptation method for both vision and language models [22,23]. orig-
inating from natural language processing, “prompting” refers to adding (man-
ual) text instructions to model inputs, whose goal is to help the pre-trained
model better understand the current task.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_25.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_24.pdf:
3. we further stratify patients by
our signature after grouping them by tumor size and ca19-9, two clinically used
preoperative criteria for selection, and also age.
independent test set (n = 178)
univariate analysis
multivariate analysis
hr (95% ci)
p-value
hr (95% ci)
p-value
proposed (high vs low risk)
2.42(1.64-3.58)
<0.0001
1.85(1.08-3.17)
0.027
age (> 60 vs = 60)
1.49(1.01-2.20)
0.043
1.01(0.65-1.58)
0.888
sex (male vs female)
1.28(0.86-1.90)
0.221
-
-
pt (pt3-pt4 vs pt1-pt2)
3.17(2.10-4.77)
<0.0001
2.44(1.54-3.86)
0.00015
pn (positive ve negative)
1.47(0.98-2.20)
0.008
1.34(0.85-2.12)
0.210
resection margin (r1 vs r0)
2.84(1.64-4.93)
<0.0001
1.68(0.92-3.07)
0.091
ca19-9 (> 210 vs ≤ 210 u/ml)
0.94(0.64-1.39)
0.759
-
-
tumor size (> 25 vs ≤ 25 mm)
2.36(1.59-3.52)
<0.0001
0.99(0.52-1.85)
0.963
tumor location (head vs tail)
1.06(0.63-1.79)
0.819
-
-
fig.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_16.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_17.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_39.pdf:
in addition, clinical indicators (e.g., age, gender) also can be integrated by
the coxph model.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_76.pdf:
as such, generative models
can be sampled to emphasize each disease subtype equally and generate more
balanced datasets, thus preventing dataset biases getting ampliﬁed by the mod-
els [7].
as such, at (1) 20× we extract a total of 54,735 patches for training
and 4,991 patches as a held-out set, while at (2) 20× magniﬁcation we generate
12,409 training patches and 655 patches are held out.
3.2
stain normalization
a common issue in deep learning with h&e stained histopathology slides is the
visual bias introduced by variations in the staining protocol and the raw mate-
rials of chemicals leading to diﬀerent colors across slides prepared at diﬀerent
labs [1].

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_62.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_63.pdf:
keywords: cervical abnormal cell detection · consistency learning ·
cervical cytologic images
1
introduction
cervical cancer is the second most common cancer among adult women.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_77.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_61.pdf:
such scheduling of the weights is done so that in the beginning
of the training, the weights are uniform in order not to wrongly bias the network
when the embeddings are still indiscriminative.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_75.pdf:
error bars represent 95% conﬁdence intervals computed by a 5000-sample
bias-corrected and accelerated bootstrap.
error bars represent 95% conﬁdence intervals computed by a 5000-sample
bias-corrected and accelerated bootstrap.
4.1
model explainability
tile-based approaches in dp often use explainability methods such as gradient-weighted
classactivationmapping[30]tohighlightpartsoftheimagethatcorrespondwithcertain
category outputs.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_49.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_74.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_60.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_58.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_64.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_65.pdf:
51.0± 0.9(52.4)
3.2
experimental results
to evaluate the eﬀectiveness of ssimnet, we compare it with several deep learn-
ing based and conventional unsupervised segmentation methods on the men-
tioned datasets, including minibatch k-means (termed as mkmeans), gaus-
sian mixture model [9] (termed as gmm), invariant information clustering
[12] (termed as iic), double dip

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_59.pdf:
https://doi.org/10.1007/978-3-031-43987-2_59
t2uda
613
keywords: tumor-inﬁltrating lymphocytes · unsupervised domain
adaption · prognosis prediction · graph attention network · breast
cancer
1
introduction
breast cancer (bc) is the most common cancer diagnosed among females and
the second leading cause of cancer death among women after lung cancer [1].

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_73.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_66.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_72.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_57.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_56.pdf:
582
j. zhu et al.
innovatively, our approach can help reduce bias in the learning process of the
segmentation model with the routine unbalanced training set.
our collection of thy-
roid cytopathology images was granted with an ethics approval document.
quantitative comparisons in both fully-supervised and semi-supervised man-
ners.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_54.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_68.pdf:
id
age gender race
ecog smoking py
pstage cancer site
cancer subsite
case1 49
male
white 3
current
21
1
oral cavity ventral tongue
case2 64
male
white 3
former
20
4
larynx
vocal cord
case3 60
male
black
2
current
45
4
larynx
false vocal cord
case4
53
male
white 1
current
68
4
larynx
supraglottic
case5 38
male
white 0
never
0
4
oral cavity lateral tongue
case6 76
female
white 1
former
30
2
oral cavity lateral tongue
case7 73
male
white 1
former
100
3
larynx
glottis
case8 56
male
white 0
never
0
2
oral cavity tongue
2
dataset
the complete staining protocols for this dataset are given in the accompany-
ing supplementary material.
the dapi images were segmented using cellpose [13] and man-
ually corrected by a trained technician and approved by a pathologist.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_69.pdf:
the bias and error generated in each level of the representation
model will accumulate in the ﬁnal decision model.
the multi-stage framework accumulated the training bias and noise,
which caused an auc gap of hipt

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_55.pdf:
pseudo label-based methods
typically generate pseudo labels for labeled images to supervise the network [4].
since using a model’s prediction to supervise itself may over-ﬁt its bias, chen
et al.
after using a standard softmax
operation, their corresponding probability prediction maps are denoted as pca,
psa and pcsa, respectively.
574
l. zhong et al.
2.2
cross decoder knowledge distillation (cdkd)
since the three branches have diﬀerent decision boundaries, using the predictions
from one branch as pseudo labels to supervise the others would avoid each branch
over-ﬁtting its bias.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_45.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_1.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_50.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_44.pdf:
breast cancer (bc) is one of the most common cancers iden-
tiﬁed globally among women, which has become the leading cause of
death.
keywords: breast cancer · hematoxylin and eosin staining ·
immunohistochemical staining · multi-modal pre-training
1
introduction
breast cancer (bc) is one of the most common malignant tumors in women
worldwide and it causes nearly 0.7 million deaths in 2020

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_52.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_46.pdf:
procedures were approved by the ethics committee of the county of salzburg
(no. 1088/2021).
the mean and median age of patients at the date of dissection was
47 and 50 years, respectively.
the data set comprised 13 male and 27 female patients,
corresponding to a slight gender imbalance.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_3.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_47.pdf:
we lever-
age fastgan [16] as the backbone for the sake of training stability and compu-
tational eﬃciency.
then, we pass c through
learnable aﬃne transformations, such that the class embedding is specialized
to the scaling and bias parameters controlling adaptive instance normalization
(adain)

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_53.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_23.pdf:
vulvovaginal candidiasis (vvc) is the most prevalent human
candidal infection, estimated to aﬄict approximately 75% of all women
at least once in their lifetime.
it is the most prevalent human candidal infection, estimated
to aﬄict approximately 75% of all women at least once in their lifetime [1,20],
resulting in huge consumption of medical resources.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_37.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_26.pdf:
furthermore, unlike traditional unilaterally aug-
mented (ua) methods, the proposed supernet skin-cancer net (sc-net)
considers the fairness of training and alleviates the eﬀects of evalua-
tion bias.
however, current nas methods often overlook fairness in architecture
ranking, impeding the discovery of top-performing models.
we observed that conventional nas methods
often overlook fairness ranking during the search, hindering the search for opti-
mal solutions.
in the
ua principle, some channels are trained twice while others are trained only once or
not at all, leading to channel training unfairness and evaluation bias.
this introduces evaluation bias and leads to sub-optimal
results.
to mitigate evaluation bias on width, we propose a new sc-net that pro-
motes the fairness of channels during training.
+ 1
(8)
therefore, the training degree t for each channel will always be equal to the
same constant value of the width, independent of the channel index, ensuring
fairness in terms of channel (ﬁlter) levels.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_19.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_24.pdf:
keywords: detection-free · contrastive learning · pathology image
classiﬁcation · cervical cancer
1
introduction
cervical cancer is a common and severe disease that aﬀects millions of women
globally, particularly in developing countries [9].

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_30.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_15.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_38.pdf:
consequently, aligning these distinct feature types becomes challenging, resulting
in a bias towards the text features associated with malignant nodules.
410
y. lei et al.
fig.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_48.pdf:
the paired ﬁrst-second course dataset, sp, is collected from sun yat-
sen university cancer center (ethics approval number: b2023-107-01), com-
prising paired ct scans of 69 distinct patients from south china.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_8.pdf:
keywords: contrast-enhanced mri · diﬀusion-weighted imaging ·
deep learning · multi-sequence fusion · breast cancer
1
introduction
breast cancer is the most common cancer and the leading cause of cancer death
in women

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_9.pdf:
keywords: large-scale clinical dataset · deep-supervision · multi-scale
segmentation · breast ultrasound images
registration number: 4319
1
introduction
breast cancer is a serious health problem with high incidence and wide prevalence for
women throughout the world

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_7.pdf:
https://doi.org/10.1007/978-3-031-43990-2_7
mammo-net for multi-view mammogram classiﬁcation
69
1
introduction
breast cancer is the most prevalent form of cancer among women and can have
serious physical and mental health consequences if left unchecked [5].

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_6.pdf:
keywords: bilateral mammogram · asymmetric transformer ·
disentanglement · self-adversarial learning · synthesis
1
introduction
breast cancer (bc) is the most common cancer in women and incidence is
increasing [14].
the alpha weights αk is a 2d gaussian distribution map, in which the co-variance
is determined by the size of k-th tumor t, representing the transparency of the
pixels of the tumor.
the in-house dataset comprises 43,258 mammography exams from
10,670 women between 2004–2020, collected from a hospital with irb approvals.
in this study, we randomly select 20% women of the full dataset, comprising 6,000
normal (bi-rads = 1) and 28,732 abnormal (bi-rads ̸= 1) images.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_40.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_54.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_68.pdf:
age-related macular degeneration (amd) is the leading
cause of blindness in the elderly.
https://doi.org/10.1007/978-3-031-43990-2_68
clustering disease trajectories for temporal biomarker proposal in amd
725
keywords: contrastive learning · biomarker discovery · clustering ·
disease trajectories · age-related macular degeneration
1
introduction
age-related macular degeneration (amd) is the leading cause of blindness in the
elderly, aﬀecting nearly 200 million people worldwide [24].
we also
include a demographic baseline using age and sex.
development dataset
time to late amd ↓ time to cnv ↓ time to crora ↓ current visual acuity ↓
demographic
0.756±0.01
0.822±0.012
0.703±0.028
0.381±0.007
current grading system
0.757±0.01
0.819±0.012
0.685±0.035
0.367±0.008
single timepoint clusters
0.747±0.013
0.776±0.015
0.630±0.05
0.230±0.005
sub-trajectory clusters
0.739±0.01
0.748±0.011
0.636±0.031
0.375±0.007
fully supervised
0.709±0.015
0.726±0.012
0.609±0.033
0.199±0.004
unseen dataset
demographic
1.343±0.027
1.241±0.017
1.216±0.062
0.188±0.007
current grading system
1.308±0.018
1.244±0.022
1.286±0.053
0.177±0.008
single timepoint clusters
1.325±0.049
1.341±0.080
1.297±0.096
0.136±0.005
sub-trajectory clusters
1.322±0.029
1.235±0.027
1.257±0.056
0.188±0.006
fully supervised
1.301±0.044
1.298±0.08
1.255±0.097
0.135±0.006
4
experiments and results
sub-trajectory clusters are candidate temporal biomarkers: by ﬁrst
applying our method to the development dataset we found that using λ = 0.75,
φ = 0.75 and k = 30 resulted in the most uniform and homogeneous clusters
while still limiting the total number of clusters to a reasonable amount.
in all tasks the standard biomarkers are only marginally more indicative of risk
than the patient’s age and sex.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_4.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_51.pdf:
rigorous clinical evaluations can establish the safety and efﬁcacy of ai-based tech-
niques, identify potential biases and limitations, and facilitate the integration of clinical
expertise to ensure accurate and meaningful results [13].
the use of this dataset was approved by the
institutional review board of the university of hong kong/hospital authority hong
kong west cluster (hku/ha hkw irb) with reference number uw21-412, and the
research ethics committee (kowloon central/kowloon east) with reference number
kc/ke-18-0085/er-1.
(train/test)
avg. age
modality
tr (ms)
te (ms)
institution-1
(siemens-1.5t)
110 (105/5)
56 ± 11
t1w
562–739
13–17
t2w
7640
97
ce-mri
562–739
13–17
institution-2
(philips-3t)
58 (53/5)
49 ± 15
t1w
4.8–9.4
2.4–8.0
t2w
3500–4900
50–80
ce-mri
4.8–9.4
2.4–8.0
institution-3
(siemens-3t)
135 (130/5)
57 ± 12
t1w
620
9.8
t2w
2500
74
ce-mri
3.42
1.11
2.3
clinical evaluations
the evaluation methods used in this study included image quality assessment of vce-
mri and primary gtv delineation.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_50.pdf:
the ethics
committee of the medical faculty heidelberg approved the study (s-164/2019)
and waived informed consent to enable analysis of a consecutive cohort.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_52.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_2.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_47.pdf:
patient #1 (young, male) and patient #2 (old, female) had similar
bmi and almost the same gluteus maximus volume, while the lean muscle mass was
signiﬁcantly diﬀerent, likely due to the fatty degeneration in patient #2, which was
clearly observable in the projections of the lean muscle mass volume.
fig.
https://doi.org/10.1002/jcsm.12890
6. edwards, m.h., dennision, e.m., sayer, a.a., et al.: osteoporosis and sarcopenia
in older age.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_53.pdf:
particularly, graph transformer networks (gtn) has have shown
to further enhance the transparency of underlying relation between the graph
nodes and decision making via attention mechanism [11].
biological data, specially those acquired intra-opertively, are heterogeneous
by nature.
the study
is approved by the institutional research ethics board and patients consent to be
included.
as can be seen, the proposed egt model with aver-
age accuracy of 94.1% outperformed all the baselines statistically signiﬁcantly
(maximum p-values of 0.02 in one-tail paired wilcoxon signed-rank test).

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_24.pdf:
when a deep learning model overﬁts speciﬁc artifacts instead of
learning the correct dermoscopic patterns, it may fail to identify skin lesions in
real-world environments where the artifacts are absent or inconsistent.
to alleviate the artifact bias and enhance the model’s generalization ability,
we rethink the problem from the domain generalization (dg) perspective, where
a model trained within multiple diﬀerent but related domains are expected to
perform well in unseen test domains.
(2) trap set debiasing: we train and test our epvt
with its baseline on six trap sets [3] with increasing bias levels, ranging from 0
(randomly split training and testing sets from the isic2019 dataset) to 1 (the
highest bias level where the correlation between artifacts and class label is in
the opposite direction in the dataset splits).
each point on the graph
represents an algorithm that is trained and tested on a speciﬁc bias degree split.
the graph shows that the erm baseline performs better than our epvt when
the bias is low (0 and 0.3).
as the bias degree increases, the correlation between artifacts and
class labels decreases, and overﬁtting the train set causes the performance of
erm to drop dramatically on the test set with a signiﬁcant distribution diﬀer-
ence.
in contrast, our epvt exhibits greater robustness to diﬀerent bias levels.
notably, our epvt outperforms the erm baseline by 9.4% on the bias 1 dataset.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_48.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_60.pdf:
reported metrics
(in %age) are the average across 3 runs.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_64.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_59.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_57.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_55.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_50.pdf:
5: when bvt is trained from scratch, the model faces a trade-oﬀ between
522
m. tran et al.
learning the weight and input alignment and ﬁnding the appropriate inductive
bias to solve the classiﬁcation task.
by reintroducing many of the inductive biases
of cnns through the window attention in the case of swin or transfer learning
in the case of bvt, the model likely overcomes this initial problem.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_52.pdf:
in contrast to common models (e.g.
resnet [9]) that lack this symmetry, we here directly incorporate this induc-
tive bias via a permutation-equivariant head h that is a generalization of the set
permutation-equivariant layer proposed in [32] to dense inputs.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_46.pdf:
the range of the age are varying from 15 to 85 years old.
the female patient
number and male patient number are almost even.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_28.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_10.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_58.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_64.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_66.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_56.pdf:
ν denote a penalty factor on
these soft constraints, and b is the biases.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_69.pdf:
addition-
ally, a hybrid spatial-frequency loss function is explored to adaptively
concentrate on the loss of important frequency components due to the
inherent bias of neural networks.
3
experiments
our clinical in-house colonoscopic videos were acquired from various colonoscopic
procedures under a protocol approved by the research ethics committee of the
university.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_50.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_47.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_33.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_25.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_29.pdf:
first and end stages of the
sequences were removed from the six acquired sequences, as they were considered
to be largely stationary, and aiming to avoid training bias.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_12.pdf:
we investigate this hypothesis by evalu-
ating a downstream task, automatically scoring ibd in the area of the
terminal ileum on the reconstructed images and show evidence that our
method does not suﬀer a synthetic domain bias.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_10.pdf:
(2) most of
them extracted the features with a ﬁxed resolution, failing to eﬀectively lever-
age multi-scale features which are essential to image restoration task [27,32].

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_48.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_73.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_66.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_72.pdf:
our neural network is trained using patches from the “gold atlas
- male pelvis - gentle radiotherapy” [14] dataset, which is comprised of 18
patients each with a ct, mr t1, and mr t2 volumes.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_6.pdf:
several methods have applied cyclegan to lever-
age unpaired data, but they often generate inaccurate mappings that shift
theanatomy.thisproblemisfurtherexacerbatedwhentheimagesfromthe
sourceandtargetmodalitiesareheavilymisaligned.recently,currentmeth-
ods have aimed to address this issue by incorporating a supplementary seg-
mentation network.
we targeted the age group from 6–24 months
since pediatric patients are more susceptible to ionizing radiation and experience
a greater cancer risk (up to 24% increase) from radiation exposure [7]. further-
more, surgery for craniosynostosis, a birth defect in which the skull bones fuse
too early, typically occurs during this age [5,16].
all models are trained using
1 ethics approval was granted by southern adelaide clinical human research ethics
committee.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_5.pdf:
+ ϵ
(1)
where w and b are weights and bias for the fc layer, ϵ = 10−5 to avoid dividing
0 in the following equation.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_50.pdf:
due to the bias in the
datasets collected from diﬀerent facilities, the performances of all the models are
declined to some extents.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_46.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_3.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_21.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_24.pdf:

--------------------------------------------------------------------------------

