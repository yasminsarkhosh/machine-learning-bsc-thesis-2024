Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_29.pdf:
even though these methods are state-of-the-art, they have stringent data
requirements, such as having a consistent geometry of the input data, e.g., in a
whole-body imaging scenario, it is not possible to crop a region of interest and
feed it to the algorithm, as this cropped region will be wrongly detected as an
anomaly.
as such, the transformer must be informed of
the location of a given token in relationship to the whole-body.
to do this, we use the same coordconv principle applied to the input fed to
the vq-vae.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_14.pdf:
for each foreground pixel in the annotation a at location (x, y), we label
(x, y, zfw) and (x, y, zbw) as foreground pixels in d.
3.
the cohort consists of 141 patients with pancreatic ductal adeno-
carcinoma, of an equal ratio of male to female patients.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_11.pdf:
however, the
cam generated based on the image-level labels can only highlight the most dis-
criminative region, but fail to locate the complete object, leading to defective
pseudo labels, as shown in fig.
a higher similarity represents a higher possibility of
this location belonging to the corresponding semantic category.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_58.pdf:
contrastive
methods can also be used to learn dense, i.e., patch-level or even pixel- or voxel-
level representations: pixels of augmented image views from the same region
of the original image should have similar representations, while diﬀerent pixels
should have dissimilar ones
this means that matching regions
describing the same location of the scene on diﬀerent views should be positive
pairs, while non-matching regions should be negative pairs.
next, we sample m diﬀerent positions from the patches’ overlapping
region.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_64.pdf:
if the features are generalizable, foreground region features will
likely follow a similar distribution even without ﬁne-tuning.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_71.pdf:
moreover,
data protection policies in diﬀerent clinical centers and hospitals limit
the training of data-dependent deep models.
such privacy breaches
may detrimental to the privacy protection policies of hospitals.
moreover, the
target domain uses the same neural network as the source domain, which is
not desirable for low-resource target users like hospitals [15].
accordingly, direct knowledge transfer using the output of the source domain
predictor may lead to feature bias in the student model due to the unavoid-
able covariance [20] between the target and source domains.
we assume that k-square-neighbors
of a pixel as a cell region, i.e., for a logits map with height h and width w, we
deﬁne the region as follow:
nk{(i, j) | (i, j) ∈ (h, w)} = {(u, v) | |u − i| ≤ k, |v − j| ≤ k}
(1)
where (i, j) denotes centre of region, and k denotes the size of k-square-neighbors.
then accord-
ing to c-classes classiﬁcation tasks, we divide the cell region into c subsets,
n c
k(i, j) = {(u, v) ∈ nk(i, j) | yt = c}.
after that, we determine the degree of
black-box domain adaptative cell segmentation
753
impurity in an area of interest by analyzing the statistics of the boundary region,
which represents the level of semantic information ambiguity.
for single-source domain
adaptation approach, cellsegssda and sfda-dpl, we employ two strategies
to ensure the fairness of the experiments: (1) single-source, i.e. performing adap-
tation on each single source, where we select the best results to display in the
table 1; (2) source-combined, i.e. all source domains are combined into a tra-
ditional single source.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_59.pdf:
mesh2ssm can also learn a
population-speciﬁc template, reducing any bias due to template selec-
tion.
mesh2ssm also includes an analysis network that operates on the
learned correspondences to obtain a data-driven template point cloud (i.e., tem-
plate point cloud), which can replace the initial template, and hence reducing
the bias that could arise from template selection.
[13,21] analysis module helps in mitigating bias and
capturing non-linear characteristics of the data.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_57.pdf:
[16] is a dataset that consists of resections of lymph nodes,
where each wsi is annotated with a binary label indicating the presence of
tumour tissue in the slide, and all slides containing tumors have a pixel-level
annotation indicating the metastatic region.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_7.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_6.pdf:
we, therefore, propose a novel approach towards pathology detection that
uses anatomical region bounding boxes, solely deﬁned on anatomical structures,
as proxies for pathology bounding boxes.
these region boxes are easier to anno-
tate – the physiological shape of a healthy subject’s thorax can be learned rela-
tively easily by medical students – and generalize better than those of patholo-
gies, such that huge labeled datasets are available [21].
in summary:
– we propose anatomy-driven pathology detection (adpd), a pathology detec-
tion approach for chest x-rays, trained with pathology classiﬁcation labels
together with anatomical region bounding boxes as proxies for pathologies.
anatomy-driven pathology detection on chest x-rays
59
backbone
(densenet121)
region detector
(detr decoder)
region tokens
pathology
classifier
(on regions)
box prediction
(with region fusion)
pneumonia
infiltration
cardiomegaly
pneumonia
infiltration
cardiomegaly
pneumonia
infiltration
cardiomegaly
target
predicted
training + inference
inference only
pneumonia: 0.72
pneumonia
fig.
for each region, observed pathologies are predicted
using a shared classiﬁer.
[16] to extract anatomical region features before predicting
observed pathologies for each region using either a linear model or a gcn model
based on pathology co-occurrences.
this approach has been further extended to
use gcns on anatomical region relationships [1].
unlike our and the other
described methods, it does however not use anatomical region bounding boxes.
as no anatomical region can occur more than once in each chest
x-ray, each query token is assigned to exactly one pre-deﬁned anatomical region,
such that the number of tokens equals the number of anatomical regions.
as described next, the resulting per-region features from
the output of the decoder layer will be used for predictions on each region.
for predicting whether the associated region is present, we use a binary clas-
siﬁer with a single linear layer, for bounding box prediction we use a three-layer
mlp followed by sigmoid.
each of these predictors
is applied independently to each region with their weights shared across regions.
we also did not observe
improvements when using several decoder layers and observed degrading perfor-
mance when using roi pooling to compute region features.
3.2
inference
during inference, the trained model predicts anatomical region bounding boxes
and per-region pathology probabilities, which are then used to predict pathology
bounding boxes in two steps, as shown in fig.
2. in step (i), pathology probabili-
ties are ﬁrst thresholded and for each positive pathology (with probability larger
than the threshold) the bounding box of the corresponding anatomical region
is predicted as its pathology box, using the pathology probability as box score.
this means, if a region contains several predicted pathologies, then all of its
predicted pathologies share the same bounding box during step (i).
as many anatomical regions are at least
partially overlapping, and we use a small iou-overlap threshold, this allows the
model to either pull the predicted boxes to relevant subparts of an anatomical
region or to predict that pathologies stretch over several regions.
3.3
training
the anatomical region detector is trained using the detr loss
mil-adpd: region predictions are ﬁrst aggregated
using lse pooling and then trained using image-level supervision.
here, the target set of observed pathologies is available for each
anatomical region individually such that the pathology observation prediction
can directly be trained for each anatomical region.
[17] loss
function independently on each region-pathology pair and average the results
over all regions and pathologies.
to train using mil, we ﬁrst aggregate the predicted pathology prob-
abilities of each region over all detected regions in the image using lse pooling
we con-
sider the image-level label for a pathology to be positive if any region is positively
labeled with that pathology.
we use the provided jpg-images [11]2 and follow the oﬃcial mimic-cxr
training split but only keep samples containing a scene graph with at least ﬁve
valid region bounding boxes, resulting in a total of 234 307 training samples.
note that for evaluation only pathology
bounding boxes are required (to compute the metrics), while during training
only anatomical region bounding boxes (without considering pathologies) are
required.
cardiomegaly (red) is detected almost perfectly, as it is always exactly localized
at one anatomical region.
without wbf, results degrade for both of our models, highlighting the impor-
tance of merging region boxes.
4 loc-adpd detects cardiomegaly almost
perfectly, as it is always exactly localized at one anatomical region.
first, due to the dependence on region
proxies, for pathologies covering only a small part of a region, our models pre-
dict the whole region, as highlighted by their incapability to detect nodules.
addi-
tionally, while not requiring pathology bounding boxes, our models still require
supervision in the form of anatomical region bounding boxes, and loc-adpd
requires anatomy-level labels.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_56.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_4.pdf:
(1), we can update the
mixing ratio between the two probability maps pspa and pspe with the weighted
entropy guidance at each pixel location by
ps2 =
hspe
hspa + hspe
⊗ pspa +
hspa
hspa + hspe
⊗ pspe,
(4)
where “⊗” denotes pixel-wise multiplication.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_55.pdf:
to increase the system robustness and emulate the clini-
cian’s reading strategies, we propose to use multi-scale embeddings to enable the
system to progressively reﬁne the ﬁne-grained location.
hence, we ensure the spatial coherence of the tracked
lesion location using well-deﬁned anatomical landmarks.
during inference, the extracted
embeddings are used to generate a cascade of cosine similarity maps that initially locate
the corresponding location in a follow-up image within a larger area and subsequently
improve the matching accuracy through gradual reﬁnement.
time points.
the
problem of lesion tracking can be formulated as ﬁnding the optimal transforma-
tion that maps p1 to its corresponding location, p2, in i2.
3.2
training stage
let d = {x1, x2, ..., xn} be a set of n unpaired and unlabeled 3d-ct volumes.
we denote the positive embed-
dings at ith scale at pixel location a+
j , q+
j as fai
j, fqi
j ∈ rl.
similarly, we denote
the negative embeddings at pixel location h−
k associated to a positive positive
pixel pair (a+
j , q+
j ) as f i
jk ∈ rl.
[11] medical imag-
ing dataset, containing 3891 pairs of lesions with information on their location
and size.
a
certiﬁed radiologist annotated the testing data by identifying the location and
size of the pulmonary nodules, resulting in a total of 825 paired annotations.
(color ﬁgure online)
580
a. vizitiu et al.
location reﬁnement.
the green and red markers denote the ground-truth
and predicted lesion location.
we found that adopting a multi-scale approach (instead of the global/local
approach as proposed in [5]) can lead to embeddings that better capture the
anatomical location and are able to handle lesions that vary in size or appear-
ance at diﬀerent scales.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_45.pdf:
it should be noted in con-
trast to [5] in which only out-of-range samples were contributing to the loss,
in this work, all samples contribute to lvd to reduce the estimation bias.
in vivo data was collected at johns hopkins hospital from patients with liver
cancer during open-surgical rf thermal ablation by a research antares siemens
system using a vf 10-5 linear array with the sampling frequency of 40 mhz and
the center frequency of 6.67 mhz.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_51.pdf:
then, we generate an instance map i, which shares the same values
among the same instances as follows:
i(x, y) = arg min
i
||(x ˆci, y ˆci) − ((x, y) + ˆo(x, y))||2,
(1)
where (x, y) represents a coordinate and (x ˆci, y ˆci) means the location of ith
point obtained from ˆc.
we use
ˆo to generate reﬁned point labels p ′, since ˆo is reliable regardless of the point
location i.e., center of the nuclei or shifted.
p′
i = arg min
x,y
|

¯x,¯y∈vi
ˆb(x, y) × ˆo(x + ¯x, y + ¯y)|,
(5)
where vi is ith voronoi region and p′
i is the reﬁned center point.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_1.pdf:
however, previ-
ous pet enhancement methods rely heavily on the paired lpet and
spet data which are rare in clinic.
however, acquiring high-quality pet images requires
injecting a suﬃcient dose (standard dose) of radionuclides into the human body,
which poses unacceptable radiation hazards for pregnant women and infants
even following the as low as reasonably achievable (alara) principle
but these
supervised methods relied heavily on the paired lpet and spet data that are
rare in actual clinic due to radiation exposure and involuntary motions (e.g., res-
piratory and muscle relaxation).
however, these methods still require
lpet to train models, which contradicts with the fact that only spet scans
are conducted in clinic.
denoting the output of previous layer
as zp et , the ct-guided cross-attention can be formulated as follows:
output = softmax(qct kt
ct
√
d
+ b) · vp et ,
qct = convq(zct ),
kct = convk(zct ),
vp et = convv (zp et ),
(2)
where d is the number of channels, b is the position bias, and conv(·) denotes
the 1 × 1 × 1 convolution with stride of 1.
2.3
implementation details
typically, the trained diﬀusion model generates target images from random
noise, requiring a large number of steps t to make the ﬁnal perturbed sam-
ple (zt ) close to pure noise.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_52.pdf:
while the database also provides
labels for the detection task, we processed these labels as segmentation masks
using a region growing method [15].

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_20.pdf:
this is due to the low inter-class variance (a malignant region usually
occupies only a small portion of a us image), high intra-class variance
(due to the us sensor capturing a 2d slice of a 3d object leading to large
viewpoint variations), and low training data availability.
we posit that
even when we have only the image level label, still formulating the prob-
lem as object detection (with bounding box output) helps a deep neural
network (dnn) model focus on the relevant region of interest.
the motivation is that, running a classiﬁer on a focused attention/ proposal
region in an object detection pipeline would help tackle the low inter-class and
high intra-class variations.
inspired by the success of the multiple instance learning (mil) paradigm for
weakly supervised training on medical imaging tasks [20,22], we train a detec-
tion transformer, detr, using the mil paradigm for weakly supervised malignant
region detection.
in this, one generates region proposals for images, and then con-
siders the images as bags and region proposals as instances to solve the instance
classiﬁcation (object detection) under the mil constraints
the location
information in the object queries learned by the class-agnostic detr ensures generation
of high-quality proposals.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_22.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_25.pdf:
speciﬁcally, we iteratively perform intra-slide
clustering for the regions (4096 × 4096 patches) within each wsi to yield
the prototypes and encourage the region representations to be closer
to the assigned prototypes.
[8], a milestone work,
introduces hierarchical pre-training (dino [6]) for the patch-level (256 × 256)
and region-level (4096 × 4096) in a two-stage manner, achieving superior per-
formance on slide-level tasks.
the aforementioned meth-
ods share the same two-stage pre-training paradigm, i.e., patch-to-region/slide.
however, they are essentially instance discrimination
where only the self-invariance of region/slide is considered, leaving the intra-
and inter-slide semantic structures unexplored.
in this paper, we propose to encode the intra- and inter-slide semantic struc-
tures by modeling the mutual-region/slide relations, which is called slpd: slide-
level prototypical distillation for wsis.
in order to learn this intra-slide semantic structure, we
encourage the region representations to be closer to the assigned prototypes.
slpd
261
(e) intra-slide disllaon 
(f) inter-slide disllaon 
(d) global (le) vs. slide-level clustering (right)
(a) hierarchical structure of wsi
(b) two-stage pretraining
probability 
distribuon 
prototype 
within slide 
prototypes 
across slides 
(c) slide-level prototypical disllaon 
wsi
region
patch
image
fig.
1. (a) a wsi possesses the hierarchical structure of wsi-region-patch-image, from
coarse to ﬁne.
(b) two-stage pre-training paradigm successively performs the image-to-
patch and patch-to-region aggregations.
besides self-distillation, region representa-
tions are associated with the prototypes within and across slides to comprehensively
understand wsis.
then, we learn the inter-slide
semantic structure by building correspondences between region representations
and cross-slide prototypes.
then a region-level vision transformer vit4096-256 aggre-
gates these tokens to obtain region-level representations.
with this hierarchical
aggregation strategy, a wsi can be represented as a bag of region-level repre-
sentations, which are then aggregated with another vision transformer, vitwsi-
4096, to perform slide-level prediction tasks.
taking stage two as an
example, dino distills the knowledge from teacher to student by minimizing the
cross-entropy between the probability distributions of two views at region-level:
lself = ex∼pdh(gt(ˆz), gs(z)),
(1)
where h(a, b) = −a log b, and pd is the data distribution that all regions are
drawn from.
the teacher and the student share the same architecture consisting
of an encoder (e.g., vit) and a projection head gt/gs. ˆz and z are the embeddings
of two views at region-level yielded by the encoder.
clustering can reveal the representative patterns in the data and has
achieved success in the area of unsupervised representation learning [4,5,24,26].
to characterize the histopathologic features underlying the slides, a straight-
forward practice is the global clustering, i.e., clustering the region embeddings
from all the wsis, as shown in the left of fig.
however, the obtained
clustering centers, i.e., the prototypes, are inclined to represent the visual bias
slpd
263
related to staining or scanning procedure rather than medically relevant fea-
tures [33].
meanwhile, this clustering strategy ignores the hierarchical structure
“region→wsi→whole dataset” underlying the data, where the id of the wsi
can be served as an extra learning signal.
speciﬁcally, we conduct k-means algorithm before the
start of each epoch over ln region embeddings {zl
n}ln
l=1 of wn to obtain m pro-
totypes {cm
n ∈ rd}m
m=1.
each group of proto-
types is expected to encode the semantic structure (e.g., the combination of
histopathologic features) of the wsi.
2.4
intra-slide distillation
the self-distillation utilized by hipt in stage two encourages the correspondence
between two views of a region at the macro-scale because the organizations of
cells share mutual information spatially.
however, the self-distillation, which
solely mines the spatial correspondences inside the 4096 × 4096 region, cannot
comprehensively understand the histopathologic consistency at the slide-level.
thus this distillation objective is encoding such informa-
tion into the corresponding region embedding, which makes the learning process
semantic structure-aware at the slide-level.
speciﬁcally, for a region embedding z belonging to the slide w and
assigned to the prototype c, we ﬁrst search the top-k nearest neighbors of w in
the dataset based on the semantic similarity, denoted as { ˆwk}k
k=1.
(4)
the inter-slide distillation can encode the sldie-level information complementary
to that of intra-slide distillation into the region embeddings.
we
leverage the pre-trained vit256-16 in stage one provided by hipt to tokenize
the patches within each region.
we use the pre-trained vit256-16 and vit4096-256 to extract
embeddings at the patch-level (256 × 256) and the region-level (4096 × 4096)
for downstream tasks.
[28]
region-level
slpd
0.856±0.025
0.926±0.017
0.879±0.035
0.863±0.076
3
patch-level
dino
0.825±0.054
0.905±0.059
0.847±0.032
0.848±0.075
4
ds-mil
[22]
region-level
dino
0.841±0.036
0.917±0.035
0.854±0.032
0.848±0.075
5
region-level
slpd
0.858±0.040
0.938±0.026
0.854±0.039
0.876±0.050
6
region-level
dino
0.843±0.044
0.926±0.032
0.849±0.037
0.854±0.069
7
region-level
dino+lintra
0.850±0.042
0.931±0.041
0.866±0.030
0.881±0.069
8
vitwsi-4096 [8]
region-level
dino+linter
0.850±0.043
0.938±0.028
0.860±0.030
0.874±0.059
9
region-level
slpd
0.864±0.042
0.939±0.022
0.869±0.039
0.886±0.057
k-nearest neighbors (knn) evaluation
10
mean
region-level
dino
0.770±0.031
0.840±0.038
0.837±0.014
0.724±0.055
11
region-level
dino+lintra
0.776±0.039
0.850±0.023
0.841±0.012
0.731±0.064
12
region-level
dino+linter
0.782±0.027
0.854±0.025
0.845±0.014
0.738±0.080
13
region-level
slpd
0.792±0.035
0.863±0.024
0.849±0.014
0.751±0.079
3.1
weakly-supervised classiﬁcation
we conduct experiments on two slide-level classiﬁcation tasks, nsclc subtyp-
ing and brca subtyping, and report the results in table 1.
the region-level
embeddings generated by slpd outperform the patch-level embeddings across
two aggregators3 and two tasks (#1∼ 5).
the inferior performance of the
global clustering is due to the visual bias underlying the whole dataset.
vitwsi-4096 is the aggregator with region-level
embeddings.
#
ablation
method
nsclc
brca
acc.
auc
acc.
auc
1
diﬀerent cluster-
ing methods
global
0.848±0.045
0.925±0.033
0.842±0.048
0.863±0.060
2
slide-level
0.850±0.042
0.931±0.041
0.866±0.030
0.881±0.069
3
diﬀerent inter-
slide distillations
region
0.828±0.040
0.915±0.025
0.843±0.024
0.849±0.067
4
prototype
0.850±0.043
0.938±0.028
0.860±0.030
0.874±0.059
5
number of
prototypes
m = 2
0.859±0.036
0.936±0.021
0.869±0.039
0.886±0.057
6
m = 3
0.864±0.035
0.938±0.022
0.861±0.056
0.878±0.069
7
m = 4
0.864±0.042
0.939±0.022
0.860±0.031
0.872±0.060
8
number of
slide neighbors
k
the proposed inter-slide distillation is
semantic structure-aware at the slide-level, since we build the correspondence
between the region embedding and the matched prototype (#4 in table 2).
to
verify the necessity of this distillation method, we turn to another design where
the inter-slide correspondence is explored through two nearest region embeddings
across slides (#3 in table 2).
as can be seen, the region-level correspondences
lead to inferior performances, even worse than the baseline (#5 in table 1),
because the learning process is not guided by the slide-level information.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol1/paper_24.pdf:
through knowledge distillation, we encour-
250
g. bontempo et al.
age agreement across the predictions delivered at diﬀerent resolutions, while indi-
vidual scale features are learned in isolation to preserve the diversity in terms
of information content.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_39.pdf:
both were
in-house datasets collected from a single hospital.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_62.pdf:
in this work, we jointly learn from longitudinal medical imag-
ing, demographics, billing codes, medications, and lab values to classify spns.
modalities
counts (cases/controls)
demo img code med lab subjects scans
ehr-pulmonary
–
288,428
–
nlst
–
–
–
533/801
1066/1602
image-ehr
257/665
641/1624
image-ehr-spn
58/169
76/405
demo: demographics, img: chest cts, code:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_9.pdf:
region-based active learn-
ing (al) involves training the model on a limited number of annotated
image regions instead of requesting annotations of the entire images.
the
standard method for region selection evaluates the informativeness of
all square regions of a speciﬁed size and then selects a speciﬁc quan-
tity of the most informative regions.
we ﬁnd that the eﬃciency of this
method highly depends on the choice of al step size (i.e., the combina-
tion of region size and the number of selected regions per wsi), and a
suboptimal al step size can result in redundant annotation requests or
inﬂated computation costs.
speciﬁcally, we dynamically determine each region
by ﬁrst identifying an informative area and then detecting its optimal
bounding box, as opposed to selecting regions of a uniform predeﬁned
shape and size as in the standard method.
keywords: active learning · region selection · whole slide images
supplementary information the online version contains supplementary material
available at https://doi.org/10.1007/978-3-031-43895-0 9.
90–100, 2023.
https://doi.org/10.1007/978-3-031-43895-0_9
adaptive region selection for al in wsi semantic segmentation
91
1
introduction
semantic segmentation on histological whole slide images (wsis) allows precise
detection of tumor boundaries, thereby facilitating the assessment of metas-
tases
we use region-based active learning (al) [13] to progressively identify anno-
tation regions, based on iteratively updated segmentation models.
each region
selection process consists of two steps.
second, on the priority map, regions are selected
according to a region selection method.
prior works have rarely looked into
region selection methods; the majority followed the standard approach [13] where
a sliding window divides the priority map into ﬁxed-sized square regions, the
selection priority of each region is calculated as the cumulative informativeness
of its constituent pixels, and a number of regions with the highest priorities are
then selected.
this work focuses on region selection methods, a topic that has been largely
neglected in literature until now, but which we show to have a great impact on al
sampling eﬃciency (i.e., the annotated area required to reach the full annotation
performance).
we discover that the sampling eﬃciency of the aforementioned
standard method decreases as the al step size (i.e., the annotated area at each
al cycle, determined by the multiplication of the region size and the number of
selected regions per wsi) increases.
to avoid extensive al step size tuning, we
propose an adaptive region selection method with reduced reliance on this al
hyperparameter.
1. region-based al workﬂow for selecting annotation regions.
(image resolution: 0.25 µm
px )
region by ﬁrst identifying an informative area with connected component detec-
tion and then detecting its bounding box.
2
method
2.1
region-based active learning for wsi annotation
we are given an unlabeled pool u = {x1 . . .
we denote the
jth annotated rectangular region in xi as rij = (cij
x , cij
y , wij, hij), where (cij
x , cij
y )
are the center coordinates of the region and wij, hij are the width and height of
that region, respectively.
in the standard region selection method, where ﬁxed-
size square regions are selected, wij = hij = l, ∀i, j, where l is predeﬁned.
figure 1 illustrates the workﬂow of region-based al for wsi annotation.
second, k regions are selected based on mi
using a region selection method.
the informativeness measure is not the focus
adaptive region selection for al in wsi semantic segmentation
93
of this study, we therefore adopt the most commonly used one that quantiﬁes
model uncertainty (details in sect.
next we describe the four region selection
methods evaluated in this work.
2.2
region selection methods
random.
each region contains at least 10% of tissue and does not overlap with
other regions.
the selection priority of
each region is calculated as the summed priority of the constituent pixels, and
k regions with the highest priorities are then selected.
standard (non-square) we
implement a generalized version of the standard method that allows non-square
region selections by including multiple region candidates centered at each pixel
with various aspect ratios.
speciﬁcally, we deﬁne a variable region width
w as spanning from 1
2l to l with a stride of 256 pixels and determine the corre-
sponding region height as h = l2
w .
the k regions are selected sequentially; when selecting the
jth region rij in xi, we ﬁrst set the priorities of all pixels in previously selected
regions (if any) to zero.
note that standard (non-square)
can be understood as an ablation study of the proposed method adaptive to
examine the eﬀect of variable region shape by maintaining constant region size.
2.3
wsi semantic segmentation framework
this section describes the breast cancer metastases segmentation task we use
for evaluating the al region selection methods.
2.
standard
(non-
square):
region
candi-
dates for l = 8192 pixels.
fig.
adaptive region selection for al in wsi semantic segmentation
95
fully-connected layers with sizes of 512 and 2, followed by a softmax activation
layer.
since the camelyon16 dataset is fully annotated,
we perform al by assuming all wsis are unannotated and revealing the anno-
tation of a region only after it is selected during the al procedure.
4. miou (tumor) as a function of annotated tissue area (%) for four region selec-
tion methods across various al step sizes.
the ﬁnal annotated
tissue area of random can be less than standard as it stops sampling a wsi if no region
contains more than 10% of tissue.
curves of adaptive are interpolated as the annotated
area diﬀers between repetitions.
comparison of region selection methods.
figure 4 compares the sampling
eﬃciency of the four region selection methods across various al step sizes (i.e.,
the combinations of region size l ∈ {4096, 8192, 12288} pixels and the number
of selected regions per wsi k ∈ {1, 3, 5}).
when using region selection method standard, the sampling eﬃciency advan-
tage of uncertainty sampling over random sampling decreases as al step size
increases.
a small al step size minimizes the annotated tissue area for a certain
high level of model performance, such as an miou (tumor) of 0.7, yet requires a
large number of al cycles to achieve full annotation performance (fig. 4 (a–d)),
adaptive region selection for al in wsi semantic segmentation
97
table 1.
5. visualization of ﬁve regions selected with three region selection methods,
applied to an exemplary priority map produced in a second al cycle (regions were
randomly selected in the ﬁrst al cycle, k = 5, l = 4096 pixels).
region sizes increase
from top to bottom: l ∈ {4096, 8192, 12288} pixels.
as a result, when region selection method adaptive is
used, uncertainty sampling consistently outperforms random sampling.
additionally, we visualize examples of selected regions
in fig. 5 and show that adaptive avoids two region selection issues of standard:
small, isolated informative areas are missed, and irrelevant pixels are selected
due to the region shape and size restrictions.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_72.pdf:
by ensuring that the ﬁne-tuning process is representative
of the entire dataset through even sampling from each tissue type, we can elim-
inate bias towards any particular tissue type.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_57.pdf:
using two medical benchmark datasets for melanoma detec-
tion and bone age estimation, we apply our r2r framework to vgg,
resnet and eﬃcientnet architectures and thereby reveal and correct
real dataset-intrinsic artifacts, as well as synthetic variants in a con-
trolled setting.
completing the xai life cycle, we demonstrate multiple
r2r iterations to mitigate diﬀerent biases.
keywords: xai life cycle · bias identiﬁcation · model correction
1
introduction
deep neural networks (dnns) have successfully been applied in research
and industry for a multitude of complex tasks.
https://doi.org/10.1007/978-3-031-43895-0_56
reveal to revise: an xai life cycle for iterative bias correction of dnns
597
fig.
while multiple approaches exist
for either revealing or revising model biases, only few combine both steps, to
be applicable as a framework.
such frameworks, however, either rely heavily on
human feedback [25,29], are limited to speciﬁc bias types
for revealing
model bias, we propose two orthogonal xai approaches: while spectral rele-
vance analysis (spray)
the arti-
fact masks are further used for evaluation on a poisoned test set and to measure
the remaining attention on the bias.
we demonstrate the applicability and high
automation of r2r on two medical tasks, including melanoma detection and bone
age estimation, using the vgg-16, resnet-18 and eﬃcientnet-b0 dnn architec-
tures.
lastly, we showcase the r2r life
cycle through multiple iterations, unveiling and unlearning diﬀerent biases.
in our r2r framework, we automate the annotation
by following [2] for data labeling through spray outlier clusters, or by collecting
the most representative samples of bias concepts according to crp.
3.1, thereby considerably easing the step from bias identiﬁcation
to correction.
reveal to revise: an xai life cycle for iterative bias correction of dnns
599
existing works for model correction measure the performance on the original
or clean test set, with corrected models often showing an improved generaliza-
tion [13,20].
3
reveal to revise framework
our reveal to revise (r2r) framework comprises the entire xai life cycle, includ-
ing methods for (1) the identiﬁcation of model bias, (2) artifact labeling and local-
ization, (3) the correction of detected misbehavior, and (4) the evaluation of the
improved model.
the
spray clusters then naturally allow us to label data containing the bias.
3.2
methods for model correction
in the following, we present the methods used for mitigating model biases.
clarc for latent space correction.
reveal to revise: an xai life cycle for iterative bias correction of dnns
601
fig.
shown are band-aid, ruler,
skin marker, and synthetic artifacts for the isic dataset, as well as “l”-marker and
synthetic artifacts for the bone age dataset.
4.1
experimental setup
we train vgg-16
[26], resnet-18 [11] and eﬃcientnet-b0 [28] models on the
isic 2019 dataset [7,8,30] for skin lesion classiﬁcation and pediatric bone age
dataset
[10] for bone age estimation based on hand radiographs.
4.2
revealing and revising spurious model behavior
revealing bias: in the ﬁrst step of the r2r life cycle, we can reveal the use
of several artifacts by the examined models, including the well-known band-aid,
ruler and skin marker [6] and our synthetic clever hans for the isic dataset, as
shown in fig. 2 for vgg-16.
besides the synthetic clever hans for bone age classiﬁcation, we
encountered the use of “l” markings, resulting from physical lead markers placed
by radiologist to specify the anatomical side.
interestingly, the “l” markings are
larger for hands of younger children, as all hands are scaled to similar size [10],
oﬀering the model to learn a shortcut by estimating the bone age based on the
relative size of the “l” markings, instead of valid features.
while we revealed
the “l” marking bias using crp, we did not ﬁnd corresponding spray clusters,
underlining the importance of both approaches for model investigation.
as shown in tab. 1 (isic
2019) and appendix a.2 (bone age), we are generally able to improve model
behavior with all methods.
the only exception is the synthetic artifact for vgg-
16, where only rrr mitigates the bias to a certain extent, indicating that
the artifact signal is too strong for the model.
reveal to revise: an xai life cycle for iterative bias correction of dnns
603
fig.
to reveal model bias,
r2r relies on crp and spray.
when applying r2r iteratively, we did not ﬁnd the emergence
of new biases, which, however, might happen if larger parts of the model are ﬁne-
tuned or retrained to correct strong biases.
future research directions include the
application to non-localizable artifacts, and addressing fairness issues in dnns.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_42.pdf:
this idea can be used for region-wise
prototypical samples
the latent vectors of all capsules are being accumulated for a dense layer
to predict a target score and for a decoder network to reconstruct the region of interest.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_1.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_46.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_2.pdf:
although there are publicly available
liver tumor datasets [1,24], they only contain major tumor types and diﬀer in
image characteristics and label distribution from our hospital’s data.
deploying
a model trained from public data to our hospital directly will be problematic.
collecting large-scale data from our hospital and training a new model will be
expensive.
therefore, we can use the model trained from them as a starting
point and use slpt to adapt it to our hospital with minimum cost.
we col-
lected a dataset from our in-house hospital comprising 941 ct scans with eight
categories: hepatocellular carcinoma, cholangioma, metastasis, hepatoblastoma,
hemangioma, focal nodular hyperplasia, cyst, and others.
to ensure fairness and eliminate model ensemble eﬀects, we
only used the model’s prediction with k = 1 during testing.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_20.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_23.pdf:
thus, existing public skin
datasets usually suﬀer from imbalanced problems which then results in class bias
of classiﬁer, for example, poor model performance especially on tail lesion types.
to tackle the challenge of learning unbiased classiﬁers with imbalanced data,
many previous works focus on three main ideas, including re-sampling data [1,
18], re-weighting loss [2,15,22] and re-balancing training strategies [10,23].
to ensure fairness, we re-train all methods by rerun their
released codes on our divided datasets with the same experimental settings.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_32.pdf:
in hospitals, collected multi-phase cts are normally grouped by
patients rather than lesions, which makes single-phase lesion annotation insuﬃ-
cient for feature fusion learning.
[6], including ignoring local information within each patch, extracting only
single-scale features, and lacking inductive bias.
[4], but they are also prone to overﬁt on small datasets such as
private hospital datasets.
the employed single-phase annotated dataset is collected from sir run
run shaw hospital (srrsh), aﬃliated with the zhejiang university school of
medicine, and has received the ethics approval of irb.
considering the fairness, all the models below are initialized with pre-trained
weights and adopt 2-d structures using the same slice-level classiﬁcation strategy.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol2/paper_33.pdf:
(2) large-scale colonoscopy generation: the proposed
approach can be used to generate large-scale datasets with no/arbitrary anno-
tations, which signiﬁcantly beneﬁts the medical image society, laying the foun-
dation for large-scale pre-training models in automatic colonoscopy analysis.
this would lead to the model
generating more background-like polyps since the large background region will
easily overwhelm the small foreground polyp regions during training.
h × w ,
(7)
where p = 1 means the pixel p at (h, w) belongs to the polyp region and p = 0
means it belongs to the background region.
through extensive exper-
iments, we found inaccurate sample images with coarse polyp boundary that
is not aligned properly with the original masks may introduce large biases and
noises to the datasets.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_16.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_13.pdf:
here, the cross-transformer
is based on multi-headed cross-attention mechanism that densely aggregates rel-
evant input image features, based on pairwise attention scores between each posi-
tion in the base tissue image with every region of the reference tissue image.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_11.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_39.pdf:
we emulate two acquisition shifts by deﬁning either images
from the memorial sloan kettering cancer center (mskcc) or hospital clinic
barcelona (hcb) as the target domain and the remaining images as the source
silent failures in medical image classiﬁcation
403
domain.
similarly,
“acq”/“man” denote averages over all acquisition/manifestation shifts per dataset.
results with further metrics are
reported in appendix table 2
dataset
chest x-ray
dermoscopy
fc-microscopy
lung nodule ct
study
iid
cor
acq
iid
cor
acq
man
iid
cor
acq
iid
cor
man
msr
15.3

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_62.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_61.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_48.pdf:
furthermore, we propose a novel frequency and localization fea-
ture aggregation network (fla-net) that learns temporal features from
the frequency domain and predicts additional lesion location positions to
assist with breast lesion segmentation.
we also devise a localization-based
contrastive loss to reduce the lesion location distance between neighbor-
ing video frames within the same video and enlarge the location distances
between frames from diﬀerent ultrasound videos.
our fla-net learns
frequency-based temporal features and then uses them to predict auxiliary breast
lesion location maps to assist the segmentation of breast lesions in video frames.
additionally, we devise a contrastive loss to enhance the breast lesion location
shifting more attention to breast lesion segmentation in ultrasound videos
499
fig.
moreover, we devise
a location-aware contrastive loss (see lcontrastive) to reduce location distance of frames
from the same video and enlarge the location distance of diﬀerent video frames.
moreover, we devise a location-based contrastive loss to regularize the breast
lesion locations of inter-video frames and intra-video frames.
location ground truth.
instead of formulating it as a regression problem,
we adopt a likelihood heatmap-based approach to encode the location of breast
lesions, since it is more robust to occlusion and motion blur.
3.3
location-based contrastive loss
note that the breast lesion locations of neighboring ultrasound video frames are
close, while the breast lesion location distance is large for diﬀerent ultrasound
502
j. lin et al.
table 2.
motivated by this, we
further devise a location-based contrastive loss to make the breast lesion loca-
tions at the same video to be close, while pushing the lesion locations of frames
from diﬀerent videos away.
hence, we devise a location-based
contrastive loss based on a triplet loss [15], and the deﬁnition is given by:
lcontrastive = max(mse(ht, ht−1) − mse(ht, nt)
moreover, our
method has larger dice, jaccard, f1-score results and a smaller mae result than
“basic+fla+lb”, which shows that our location-based contrastive loss has its
contribution to the success of our video breast lesion segmentation method.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_58.pdf:
automated segmen-
tation is crucial, but it is also challenging due to three factors: the infected regions
often vary in shape, size, and location, appear similar to surrounding tissues, and
can disperse within the lung cavity.
we follow the extension of
[20] for weight initialization and use the adamw optimizer [11] and empirically
set the initial learning rate to 0.0001, batch size to 2 and 32 for segmentation
and classiﬁcation, maximum iterations to 25w, momentum factor λ to 0.99, and
the number of prototypes k to 256.
to evaluate the covid-19 segmentation performance, we utilized six met-
rics, including the dice similarity coeﬃcient (dsc), intersection over union
(iou), sensitivity (sen), speciﬁcity (spe), hausdorﬀ distance (hd), and aver-
age surface distance (asd).

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_70.pdf:
our
laplacian-former shows ﬁner boundaries (high-frequency details) for the region of the
stomach and less false positive prediction for the pancreas.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_65.pdf:
then we make a projection on the main connected region of ˆsi along three
test-time click adaptation for pulmonary lesion segmentation
685
coordinate axes to obtain the size of the bounding box bi = (d, w, h) of the
pre-segmentation result, and generate an ellipsoid mi with three axes length
proportional to the corresponding side length of the bounding box bi.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_72.pdf:
this indirect supervision avoids the misleading of box-shape bias of
annotations.
because
there is a strong box-shape bias in b. training with this bias, the model is forced
to predict the box-shape mask, unable to maintain the polyp’s contours.
this indirect supervision separates p1/p2
from b so that p1/p2 is not aﬀected by the shape bias of b while obtaining
the position and extent of polyps.
because both t1/t2 and b are box-like masks, we directly calculate the super-
vision loss between them without worrying about the misguidance of box-shape
bias.
our weakpolyp predictably outperforms the model supervised by box
masks because it is not aﬀected by the box-shape bias of the annotations.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_57.pdf:
despite good progress,
these methods often have limitations in capturing long-range relationships and
global context information [2] due to the inherent bias of convolutional opera-
tions.
focal region size sl
r is the number of sub-windows horizontally and vertically in
attended regions at level l. the focal sa module proceeds in two main steps, sub-
window pooling and attention computation.
finally, a relative position
bias is added to compute the focal sa for qi by
attention(qi, ki, vi) = softmax(qikt
i
√
d
+ b)vi,
where b = {bl}l
1 is the learnable relative position bias [24].

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_68.pdf:
in addition, medical image anno-
tations can be aﬀected by human bias and poor inter-annotator agreement [23],
further complicating the process.
the images are annotated with lesion
type, diagnosis, and anatomical location metadata.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_45.pdf:
in clinics, couinaud segments obtained from
manual annotation are tedious and time-consuming, based on the vasculature
used as rough guide (fig. 1).
to solve this issue, we propose a strategy of continuous spatial sampling
point data based on the m ′. speciﬁcally, the model randomly samples t points
in each training epoch, of which t/2 points fall in the smaller space covered by
the m ′, which enables the model to increase access to important data in the
region during training.
in addition, we apply a random perturbation oﬀset =
(δx, δy, δz) in the range of [−1, 1] to each point pt = (xt, yt, zt) ∈ m ′ in this
region to obtain a new point pt = (xt + δx, yt + δy, zt + δz), and the intensity
in this coordinate obtained by trilinear interpolation.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_51.pdf:
for the classiﬁcation mode, the
model output has (k+1) channels with one channel representing the background
region.
therefore we calculate the local skeleton for sdt on-the-ﬂy after
all spatial transformations instead of pre-computing to prevent the model from
hallucinating the structure of parts outside of the currently visible region.
besides, under
the hausdorﬀ distance for evaluating shape-similarity between ground-truth and
predicted masks, our sdt reports an average score of 44.82 across two test splits,
which improves the previous state-of-the-art approach (i.e., fullnet with an aver-
age score of 50.15) by 10.6%.
however, for regression mode, if the background value is 0, we need to
use a threshold τ > 0 to decide the foreground region, which results in shrank
masks.
to separate the background region from the foreground objects, we assign
an energy value of −b to the background pixels (b ≥ 0).

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_1.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_53.pdf:
this study is approved by the ethical committee of west
china hospital of sichuan university, china.
(d–e) compared to baseline, csnb can
enhance the ability to capture vascular features with widely variable size, shape, and
location.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_37.pdf:
furthermore, in this work, we collected
skin images through the tertiary referral hospital under the approval of the
institutional review board (irb no. 1908-161-1059) and obtained images with
the consent of the subjects according to the principles of the declaration of
helsinki from 51 patients and subjects.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol3/paper_18.pdf:
we
ﬁnd that the ability of classiﬁers to separate individuals into subgroups
varies substantially across medical imaging modalities and protected char-
acteristics; crucially, we show that this property is predictive of algorith-
mic bias.
through theoretical analysis and extensive empirical evalua-
tion (code is available at https://github.com/biomedia-mira/subgroup-
separability), we ﬁnd a relationship between subgroup separability, sub-
group disparities, and performance degradation when models are trained
on data with systematic bias such as underdiagnosis.
although
many methods exist for mitigating bias in image classiﬁers, they often fail unex-
pectedly and may even be harmful in some situations [26].
today, no bias miti-
gation methods consistently outperform the baseline approach of empirical risk
minimisation (erm)
https://doi.org/10.1007/978-3-031-43898-1_18
180
c. jones et al.
image classiﬁers (e.g. biological sex from chest x-ray can be predicted with
> 0.98 auc).
this is especially relevant in
medical imaging, where attributes such as age, biological sex, self-reported race,
socioeconomic status, and geographic location are often considered sensitive for
various clinical, ethical, and societal reasons.
we show that the ability of
models to detect which group an individual belongs to varies across modalities
and groups in medical imaging and that this property has profound consequences
for the performance and fairness of deep classiﬁers.
– we show theoretically that such diﬀerences in subgroup separability aﬀect
model bias in learned classiﬁers and that group fairness metrics may be inap-
propriate for datasets with low subgroup separability.
follow-up work has addi-
tionally shown that these models may use sensitive information to bias their
predictions [7,8].
unfortunately, standard bias mitigation methods from com-
puter vision, such as adversarial training [1,14] and domain-independent training
[24], are unlikely to be suitable solutions.
[26] showed that bias mitigation methods worsen
performance for all groups compared to erm, giving a stark warning that blindly
applying methods and metrics leads to a dangerous ‘levelling down’ eﬀect [16].
closely related to our work is oakden-rayner et al., who
consider how ‘hidden stratiﬁcation’ may aﬀect learned classiﬁers [18]; similarly,
jabbour et al. use preprocessing ﬁlters to inject spurious correlations into chest
x-ray data, ﬁnding that erm-trained models are more biased when the corre-
lations are easier to learn [12]. outside of fairness, our work may have broader
impact in the ﬁelds of distribution shift and shortcut learning [6,25], where many
examples exist of models learning to exploit inappropriate spurious correlations
[3,5,17], yet tools for detecting and mitigating the problem remain immature.
suppose we have access to a
(biased) training dataset, where ptr is the conditional distribution between train-
ing images and training labels; we say that such a dataset is biased if ptr ̸= p.
we focus on group fairness, where each individual belongs to a subgroup a ∈ a
and aim to learn a fair model that maximises performance for all groups when
deployed on an unbiased test dataset drawn from p. we assume that the groups
are consistent across both datasets.
the bias we consider in this work is under-
diagnosis, a form of label noise [4] where some truly positive individuals x+ are
mislabeled as negative.
(8) demonstrate that
tpr of the underdiagnosed group is directly aﬀected by bias from the training
set while other groups are mainly unaﬀected.
given this diﬀerence across groups,
an appropriately selected group fairness metric may be able to identify the bias,
in some cases even without access to an unbiased test set [23].
in such sit-
uations, we expect performance degradation to be uniform across groups and
thus not be detected by group fairness metrics.
tpr(b)
a
≈ |ptr(y|x+, a) > 0.5|
n+,a
≤ |p(y|x+, a) > 0.5|
n+,a
≈ tpr(u)
a , ∀a ∈ a
(10)
we have derived the eﬀect of underdiagnosis bias on classiﬁer performance
for the two extreme cases of high and low subgroup separability.
4, we empirically investigate (i) how subgroup separa-
bility varies in the wild, (ii) how separability impacts performance for each group
when underdiagnosis bias is added to the datasets, (iii) how models encode sen-
sitive information in their representations.
mean and standard deviation are
reported over ten random seeds, with results sorted by ascending mean auc.
dataset-attribute
modality
subgroups
auc
group 0 group 1
μ
σ
papila-sex
fundus image
male
female
0.642 0.057
ham10000-sex
skin dermatology male
female
0.723 0.015
ham10000-age
skin dermatology <60
≥60
0.803 0.020
papila-age
fundus image
<60
≥60
0.812 0.046
fitzpatrick17k-skin skin dermatology i–iii
iv–vi
0.891 0.010
chexpert-age
chest x-ray
<60
≥60
0.920 0.003
mimic-age
chest x-ray
<60
≥60
0.930 0.002
chexpert-race
chest x-ray
white
non-white 0.936 0.005
mimic-race
chest x-ray
white
non-white 0.951 0.004
chexpert-sex
chest x-ray
male
female
0.980 0.020
mimic-sex
chest x-ray
male
female
0.986 0.008
age is consistently
well predicted across all modalities, whereas separability of biological sex varies,
184
c. jones et al.
with prediction of sex from fundus images being especially weak.
performance degradation under label bias
we now test our theoretical ﬁnding: models are aﬀected by underdiagnosis dif-
ferently depending on subgroup separability.
we inject underdiagnosis bias into
each training dataset by randomly mislabelling 25% of positive individuals in
group 1 (see table 1) as negative.
in these experiments, the
proportion of mislabelled images is small relative to the total population; thus,
the underdiagnosed subgroups mostly recover from label bias by sharing the
subgroup separability in medical image classiﬁcation
185
correct mapping with the uncorrupted group.
we see a statistically signiﬁcant performance drop for group 0 in the
mimic-sex experiment – we believe this is because the model learns separate
group-wise mappings, shrinking the eﬀective size of the dataset for group 0.
use of sensitive information in biased models
finally, we investigate how biased models use sensitive information.
in fairness liter-
ature, data is often assumed to contain suﬃcient information to identify indi-
viduals as subgroup members.
we showed,
theoretically and empirically, that the performance and fairness of models trained
on biased data depends on subgroup separability.
when separability is high,
models learn to exploit the sensitive information and the bias is reﬂected by stark
subgroup diﬀerences.
this indicates that group
fairness metrics may be insuﬃcient for detecting bias when separability is low.
our analysis centred on bias in classiﬁers trained with the standard approach
of empirical risk minimisation – future work may wish to investigate whether
subgroup separability is a factor in the failure of bias mitigation methods and
whether it remains relevant in further image analysis tasks (e.g. segmentation).
sources of bias matter.
in our experiments, we injected underdiagnosis bias
into the training set and treated the uncorrupted test set as an unbiased ground
truth.
at least
some of the datasets may already contain an unknown amount of underdiagnosis
bias (among other sources of bias)
this pre-existing bias will likely have
a smaller eﬀect size than our artiﬁcial bias, so it should not play a signiﬁcant
role in our results.
still, the unmeasured bias may explain some variation in
results across datasets.
future work should investigate how subgroup separability
interacts with other sources of bias.
we renew the call for future datasets to be
released with patient metadata and multiple annotations to enable analysis of
diﬀerent sources and causes of bias.
reproducibility and impact.
references
1. alvi, m., zisserman, a., nell˚aker, c.: turning a blind eye: explicit removal of biases
and variation from deep neural network embeddings.
potential sources of dataset bias complicate
investigation of underdiagnosis by machine learning algorithms.
https://doi.org/10.1038/s42256-020-00257-z
7. gichoya, j.w., et al.: ai recognition of patient race in medical imaging: a mod-
elling study.
https://doi.org/10.1016/j.ebiom.2023.104467
9. groh, m., harris, c., daneshjou, r., badri, o., koochek, a.: towards transparency
in dermatology image datasets with skin tone annotations by experts, crowds,
and an algorithm.
https://doi.org/10.1145/3368555.3384468
19. rajpurkar, p., et al.: chexnet: radiologist-level pneumonia detection on chest x-
rays with deep learning, november 2017
20. seyyed-kalantari, l., zhang, h., mcdermott, m.b., chen, i.y., ghassemi, m.:
underdiagnosis bias of artiﬁcial intelligence algorithms applied to chest radiographs
in under-served patient populations.
wachter, s., mittelstadt, b., russell, c.: bias preservation in machine learning:
the legality of fairness metrics under eu non-discrimination law.
wang, z., et al.: towards fairness in visual recognition: eﬀective strategies for bias
mitigation.
zong, y., yang, y., hospedales, t.: medfair: benchmarking fairness for medical
imaging.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_15.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_10.pdf:
no data augmentation techniques are used to ensure fairness.
no data augmentation techniques are used to ensure fairness.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_71.pdf:
therefore, magnetic resonance (mr)
imaging has been recommended to enhance the segmentation of soft tis-
sue oars in the han region.
therefore, the integration of complementary imaging modalities, such as
magnetic resonance (mr), has been strongly recommended in clinical practice to
enhance the segmentation of several soft tissue oars in the han region
our study therefore aims to evaluate the impact of
mr integration on the quality and robustness of automatic oar segmentation
in the han region, therefore contributing to the growing body of research on
multimodal methods for medical image analysis.
when segmenting oars in the han region for the purpose of rt
planning, a multimodal segmentation model that can leverage the information
from ct and mr images of the same patient might be beneﬁcial compared to
separate single-modal models.
an important repercus-
sion is that image registration errors propagate into oar delineations, which
is particularly salient in the han region.
4
discussion
in this study, we evaluated the impact on the quality and robustness of auto-
matic oar segmentation in the han region caused by the incorporation of the
mr modality into the segmentation framework.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_66.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_43.pdf:
how-
ever, due to the lack of inductive biases, such as weight sharing and locality, vits
are more data-hungry than cnns, i.e., require more data to train [31].
method
vit mitigate vits’ data-hunger
u f
[7,22,39] √
√ by adding inductive bias
× –
[32]
√
×
√ ×
mdvit
√
√ by multi-domain learning
√ √
various strategies have been proposed to address vits’ data-hunger
(table 1), mainly: adding inductive bias by constructing a hybrid network that
fuses a cnn with a vit
previous mis vits mitigated the data-hunger in one dataset by adding
inductive bias, e.g., swinunet

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_40.pdf:
unlike convolutional networks (cnns), transformers use self-attentions
that do not have a strong inductive bias.
although they,
e.g. swinunetr, achieve state-of-the-art (sota) results on some benchmarks,
the lack of inductive bias makes transformers harder to train, requires much
more training data, and are sensitive to training recipes.
the convolution operation
in cnn provides a strong inductive bias which is translational equivalent and efﬁ-
cient in capturing local features like boundary and texture.
however, this inductive
bias limits the representation power of cnn models which means a potentially lower
c
⃝ the author(s), under exclusive license to springer nature switzerland ag 2023
h. greenspan et al.
although transformers have achieved certain success in medical imaging, the lack
of inductive bias makes them harder to be trained and requires much more training
data to avoid overﬁtting.
besides lacking
inductive bias and enough training data, one extra reason could be that transformers are
computationally much expensive and harder to tune.
[7] uses
gated positional self-attention which is equipped with a soft convolutional inductive
bias.
although swin-transformer uses local window attention to
introduce inductive bias like convolutions, self-attentions can still mess up with the
local details.
it provides 361 training scans with man-
ual labels from 11 medical centers.
for msd datasets, we perform 5-fold cross-validation and ran the base-
line experiments with our codebase using exactly the same hyperparameters as men-
tioned.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_54.pdf:
keywords: breast cancer · weakly-supervised learning · medical
image segmentation · contrastive learning · dce-mri
1
introduction
breast cancer is the most common cause of cancer-related deaths among women
all around the world [8].
the extreme points are deﬁned as the left-, right-, anterior-,
posterior-, inferior-, and superior-most points of the cancerous region in 3d.
to further increase the area of foreground, the voxel at location k is
considered as new foreground seed if y (k) is greater than 0.8 and new back-
ground seed if y (k) is less than 0.1.
z(k) denotes the feature
vector of the voxel at location k. sim(·, ·) is the cosine similarity function.
if s(k) is greater than αn, the voxel at location k
is considered as positive.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_4.pdf:
lesion location.
so we introduce uncertainty navigator for segmen-
tation(un) as a feature decoder, which incorporates the pixel-wise uncertainty
in u sand lesion location information in m with the segmentation feature maps
to generate the segmentation result and reliable features.
it ﬁrstly generates
reliable classiﬁcation features rc fusing the initial classiﬁcation feature maps f c
4
and the rich information (e.g., lesion location and boundary characteristic) in
rs, which can be expressed by:
rc = f c
4 ⊕ (conv(d3(rs))

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_41.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_51.pdf:
https://doi.org/10.1007/978-3-031-43901-8_51
deep probability contour framework
535
ing, monitoring, and follow-up radiotherapy (rt) planning [2,19]. delineation of
region of interest (roi) is a crucial step in rt planning.
mathematically, a
100 ω% region of a density f is deﬁned as the level set l(fω) = {f(x) ≥ fω}
with its corresponding contour level fω such that p(x∈ l(fω) = 1 − ω, where x
is a random variable and l(fω) has a minimal hypervolume [11].
in other words,
for any ω ∈ (0, 1), the 100 ω% contour refers to the region with the smallest area
which encompasses 100 ω% of the probability mass of the density function [11].
in practice, fω can be estimated using the following result.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_1.pdf:
yet, due to diﬀerences in imaging protocols and variations in
patient demographics, this solution usually introduces data heterogeneity, lead-
category-level regularized unlabeled-to-labeled learning
5
ing to a quality problem.
inherently, the challenge of ms-ssl stems
from intra-class variation, which results from diﬀerent imaging protocols, disease
progress and patient demographics. inspired by prototypical networks [13,19,25]
that compare class prototypes with pixel features to perform segmentation,
here, we introduce a non-parametric unlabeled-to-labeled (u2l) learning scheme
that utilizes expert labels to explicitly constrain the prototype-propagated pre-
dictions.
compared to c1 and
c2, scans from c3 to c6 are taken from patients with prostate cancer, either for
detection or staging purposes, which can cause inherent semantic diﬀerences in
the prostate region to further aggravate heterogeneity.
following [7,8], we crop
each scan to preserve the slices with the prostate region only and then resize and
normalize it to 384 × 384 px in the axial plane with zero mean and unit variance.
all methods are imple-
mented with the same backbone and training protocols to ensure fairness.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_46.pdf:
as
estimated by the american cancer society, there were approximately 100,350
new cases and over 6,500 deaths in 2020

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_53.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_20.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_36.pdf:
additionally, the improved edge from lesion segmentation
can be further used for lyme disease classiﬁcation—e.g., in diﬀerentiat-
ing lyme from other similar lesions including tinea corporis and herpes
zoster—with improved model fairness on diﬀerent subpopulations.
[1] yet some
improvements still remain to be addressed, importantly in areas that allow both
algorithmic performance and fairness [2], and in certain medical applications that
promise to signiﬁcantly lessen morbidity and mortality.
[17], usually suﬀer
from relatively low performance and reduced fairness [2,18,19].
secondly, we design a simple yet novel data preprocessing and alternation
method, called edgemixup, to improve lyme disease segmentation and diagno-
sis fairness on samples with diﬀerent skin-tones.
such an improvement is an iterative process that gradually improves lesion
edge detection and segmentation fairness until convergence.
a motivating example to illustrate why edgemixup improves model perfor-
mance and reduces biases via mixing up lesion boundary with original image (heatmap
is generated via grad-cam).
(color ﬁgure online)
converged edge in the ﬁrst step also helps classiﬁcation of lyme diseases via mixup
with improved fairness.
our results show that edgemixup is able to increase segmentation utility
and improve fairness.
we also show that the improved segmentation further
improves classiﬁcation fairness as well as joint fairness-utility metrics compared
to existing debiasing methods, e.g., ad
the reason is that a legacy
diagnosis has no information about lesion and does not know where to locate its
focus, thus easily gets distracted by ﬁngers instead of the lesion pattern.
3
method
in this section, we ﬁrst give the deﬁnition for model fairness, and we then
describe the design of edgemixup for the purpose of de-biasing in fig.
edgemixup improves model fairness on light and dark skin samples in both
segmentation and classiﬁcation tasks, and it has two major components: (i) edge
detection using mixup, and (ii) data preprocessing and alteration for downstream
tasks.
note that the initial
edge detection is irrelevant to the sample size of a particular subpopulation, thus
improving the fairness.
segmentation: performance and fairness (margin of error reported in paren-
thesis)
method
unet
polar
mfsnet
vit-adapter
edgemixup
skin
jaccard 0.7053(0.0035) 0.7126(0.0033) 0.5877(0.0080) 0.7027(0.0057) 0.7807(0.0031)
jgap
0.0809(0.0001) 0.0813(0.0001) 0.1291(0.0076) 0.2346(0.0035) 0.0379(0.0001)
our evaluation metrics include (i) jaccard index (iou
score), which measures the similarity between a predicted mask and the manu-
ally annotated ground truth, and (ii) the gap between jaccard values (jgap) to
measure fairness.
table 2 shows the performance and fairness of edgemixup and diﬀerent
baselines.
table 3 shows utility performance (acc and auc) and fairness results (gaps
of acc and auc between ls and ds subpopulations).
skin disease classiﬁcation and associated bias.
3. by adding the “unet” variant, we
demonstrate here that simply applying lesion edge predicetd by the baseline unet
model, while not optimal, eﬃciently reduces model bias on diﬀerent skin-tone
samples.
edgemixup outperforms sota approaches in balancing the model’s
performance and fairness, i.e., the caiα and cauciα values of edgemixup are
the highest compared with the vanilla resnet34 and other baselines.
6
related work
skin disease classiﬁcation and segmentation: previous researches mainly
work on improving model utility for both medical image
[10] only contains melanoma samples and all of the
samples are with light skins according to our inspection using ita scores.
382
h. yuan et al.
bias mitigation: researchers have addressed bias and heterogeneity in deep
learning models [18,29].
first, masking sensitive factors in imagery is shown
to improve fairness in object detection and action recognition

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_32.pdf:
keywords: brain tumor segmentation · edge-oriented module ·
transformer
1
introduction
accurate segmentation of brain tumors from mri images is of great signiﬁcance
as it enables more accurate assessment of tumor morphology, size, location, and
distribution range, thereby providing clinicians with a reliable basis for diagnosis
and treatment [16].
+ bconvlap
(7)
where ‘∗’ represents the convolution operation, wconv means the weights of the
convolution and bconv denotes the bias, and up(·) is the spatial broadcasting
operation ,which upgrades the bias b ∈ r1×c×1×1×1 into up(b) ∈ r1×c×3×3×3.
in the inference stage, the output feature f is produced by a normal 3 × 3 × 3
convolution as follows:
the
red region represents wt, the yellow means tc and the white denotes et (color
ﬁgure online).
speciﬁcally, eoformer accurately segments both tc and et region boundaries.
3.4
ablation
we evaluate the eﬀectiveness of our proposed eoformer framework by con-
ducting ablation experiments on the brats 2020.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_33.pdf:
multitask learning ·
hybrid cnn-transformer
1
introduction
breast cancer is the leading cause of cancer-related fatalities among women.
currently, it holds the highest incidence rate of cancer among women in the u.s.,
and in 2022 it accounted for 31% of all newly diagnosed cancer cases [1].
this is primarily because the architectural design of vits does not rely on the
same inductive biases in feature extraction which allow cnns to learn spatially
invariant features.
moreover,
multitask learning acts as a regularizer by introducing inductive bias and pre-
vents overﬁtting [25] (particularly with vits), and with that, can mitigate the
challenges posed by small bus dataset sizes.
to avoid data leakage and bias, we selected the train, test, and vali-
dation sets based on the cases, i.e., the images from one case (patient) were
350
b. shareef et al.
table 2. performance metrics of the compared methods for bus image classiﬁcation
and segmentation.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol4/paper_27.pdf:
in this paper, we make a ﬁrst attempt to explore a deep
learning method for unsupervised gland segmentation, where no man-
ual annotations are required.
then, a morphology-aware semantic grouping module is
employed to summarize the overall information about glands by explic-
itly grouping the semantics of their sub-region proposals.
the cue can be described as: each gland is comprised
of a border region with high gray levels that surrounds the interior epithelial tis-
sues.
then, considering that our segmentation target is the gland,
we employ a morphology-aware semantic grouping module to summarize the
semantic information about glands by explicitly grouping the semantics of the
sub-region proposals.
(2) we propose to leverage an empirical cue to select gland sub-regions
and explicitly group their semantics into a complete gland region, thus avoid-
ing over-segmentation and under-segmentation in the segmentation results.
meantime, a morphology-aware semantic grouping
(msg) module is used to summarize the overall information about glands from
their sub-region proposals.
2.1
selective proposal mining
instead of generating pseudo-labels for the gland region directly from all the
pixels of the gland images as previous works typically do, which could lead to
over-segmentation and under-segmentation results, we propose using the empir-
ical cue as extra hints to guide the proposal generation process.
sub-region proposal selection via the empirical cue.
particularly, we select the region
with the highest average gray level as the proposal for the gland border.
then,
we ﬁll the areas surrounded by the gland border proposal and consider them as
the proposal for the interior epithelial tissues, while the rest areas of the gland
image are regarded as the background (i.e., non-glandular region).
finally, we
obtain the proposal map pi ∈ r3×h×w , which contains the two proposals for
two gland sub-regions and one background proposal.
2.2
morphology-aware semantic grouping
a direct merge of the two sub-region proposals to train a fully-supervised seg-
mentation network may not be optimal for our case.
without msg, the performance is not good
enough, due to signiﬁcant sub-region variation and gland omission.
it can be
observed that the segmentation performance without the msg modules is not
satisfactory due to the signiﬁcant sub-region variation and

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_15.pdf:
our study analyzed a dataset of ct scans col-
lected from guangdong province people’s hospital between years 2018 and 2020,
with 2,139 patients consisting of 787 gastric cancer and 1,352 normal cases.
to further evaluate speciﬁcity
in a larger population, we collected an external test set of 903 normal cases
from shengjing hospital.
[8,18] to localize the stomach
region in the entire image in the testing phase.
evaluation metrics and reader study.
a reader
study was conducted with two experienced radiologists, one from guangdong
province people’s hospital with 20 years of experience and the other from the
first aﬃliated hospital of zhejiang university with 9 years of experience in
gastric imaging.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_28.pdf:
the whole process can be formulated as follows:
o = enci(i), p = enct(p), sground = op ⊤, lcls = loss(sground; t),
(1)
where o ∈ rn×d, p ∈ rm×d denote the image and text features respectively for
n candidate region proposals and m target objects, sground ∈ rn×m represents
the cross-modal alignment scores, and t ∈ {0, 1}n×m is the target matrix.
3.2
language syntax based prompt fusion
as mentioned above, it is diﬃcult for a single prompt input structure such as
glip to cover all necessary descriptions even through careful designation of
the prompt.
more speciﬁcally, the vlm outputs a set of candidate
region proposals ci for each prompt pi, and these candidates carry more multi-
dimensional information than prompts.
in addition, the can-
didate, e.g., cij ∈ ci, carries richer information that can be further utilized, such
multiple prompt fusion for zero-shot lesion detection
287
as central coordinate xj and yj, region size wj and hj, category label, and pre-
diction conﬁdence score.
as
such, we consider clustering the center coordinate (xj, yj) and region size (wj, hj)
respectively to ﬁlter out those candidates with the wrong location and size.
there are
four sub-modules in our approach, where the location cluster floc and size clus-
ter fsize discard the candidates with large deviations and abnormal sizes.
the ﬁrst three
rows in table 1 represent the results of single prompt by only providing shape,
color, and location information, respectively.
our approach has three key components, i.e., location cluster, size clus-
ter and prediction corrector.
the location cluster ﬁlters out the candidates with
severe deviation from the target.
components
isic 2016
cvc-300
bccd
location
cluster
size
cluster
prediction
corrector
ap (%)

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_16.pdf:
the algorithm was
evaluated on data from a hospital in a diﬀerent country and various sub-
sets of this data that correspond to diﬀerent levels of domain shift.
in this work, we evaluate an attention-based mil model on unseen data
from a new hospital and propose a way to quantify the domain shift severity.
we split the data from the new hospital into several
subsets to investigate clinically realistic scenarios triggering diﬀerent levels of
domain shift.
our results show that domain shift is
present between the wsis from the same hospital (camelyon data) and another
medical centre (brln data).

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_38.pdf:
keywords: breast cancer · mammogram · risk prediction
1
introduction
breast cancer impacts women globally [15] and mammographic screening for
women over a certain age has been shown to reduce mortality
recently, several studies [8,32,33] revealed the potential of artiﬁcial intelligence
(ai) to develop a better risk assessment model to identify women who may ben-
eﬁt from supplemental screening or a personalized screening interval and these
may lead to improved screening outcomes.
in clinical practice, breast density and traditional statistical methods for pre-
dicting breast cancer risks such as the gail
for medical applications, x typically
represents patient information like age, family history, genetic makeup, and diag-
nostic test results (e.g., a mammogram).
women with dense breasts have a four-to six-fold
higher risk of breast cancer

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_11.pdf:
similarity-based
methods pair two lesions with similar features, e.g., intensity, shape, location
i < k ≤ n
	
be a set of
forward-directed edges connecting vertices in v i to vertices in v k. edge ei,k
j,l indicates
that the lesions corresponding to vertices vi
j, vk
l are the same lesion, i.e., that the lesion
appears in scans si, sk in the same location.
graph-theoretic automatic lesion tracking and detection
111
2.2
lesion matching computation
lesion matchings are determined by the location and relative proximity of the lesions
in two or more registered scans.
for each non-consecutive
edge connecting lesions vi
j, vk
l , he analyzed the corresponding region in the skipped
scans sj at tj ∈ ]ti, tk[ for possible missed lesions.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_62.pdf:
(2) in the video-based diagnosis stage, the network
automatically chooses high-conﬁdence region features of each frame according to
the single-frame detection results and performs temporal aggregation to output
a more accurate diagnosis.
we further collect 36 cases
from the two medical centers mentioned above (14 benign cases) and another
center (fujian provincial hospital, 22 malignant cases) to form the test set.
2. there is an obvious visual diﬀerence
between the images from the fujian provincial hospital (last column in fig.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_61.pdf:
[8], and
etc. by aiding in forming a coarse location of the polyp and contributing to
improved accuracy and performance.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_75.pdf:
(a) few
works report detailed performance in the clinically relevant region of less than 1
fp/image.
m&m surpasses previous works by a large margin in this region.
1a, most works focus on reporting
recalls outside the clinically relevant region of less than 1 fp/image.
to tackle the high rate of false positives in mammography, we identify three
challenges: (1) a malignant mammogram typically contains only one malignant
ﬁnding.
[24]
53.2
36.2
-17.0 64.3
77.0
85.5
m&m (ours)
57.1
53.6 -3.5
87.7
90.9
92.5
a u.s. multi-site mammography operator; (3) inhouse-b: an evaluation dataset
collected from a u.s. academic hospital (see [18], sec.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_8.pdf:
such metrics cannot reﬂect the lesion-level accuracy (how many lesion
instances are correctly detected and classiﬁed) and may bias to large lesions when
a patient has multiple tumors.
we ﬁrst train an nnu-net on public datasets to segment liver and surround-
ing organs (gallbladder, hepatic vein, spleen, stomach, and pancreas), and then
crop the liver region to train plan.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_9.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_73.pdf:
pathologists and
oncologists can use this information to inspect the validity of the prediction result
and interrogate key aspects of the spatial biology that is critical for patient man-
agement.
the superpixels centers are used as the nodes of the graph, and the node
features are the weighted mean of the corresponding patch features which overlap
with the superpixel region.
this could be explained by the lym-
phocyte content, supported by the higher epithelial map activations in the same
location.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_72.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_57.pdf:
in addition, we evaluate the eﬀectiveness of reid by measuring the aver-
age polyp fragmentation rate (fr), deﬁned as the average number of tracklets
polyps are split into.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_43.pdf:
keywords: breast ultrasound classiﬁcation · ultrasound video ·
coherence loss
1
introduction
breast cancer is a life-threatening disease that has surpassed lung cancer as lead-
ing cancer in some countries and regions [20].
for fairness comparison, we train these models using both video
and image data, treating images as static videos.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_7.pdf:
b1
and b2 are bias vectors.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_5.pdf:
[18], we select the foreground and background
region on both two frames guided by ground truth boxes to conduct contrastive
learning.
for the fairness of the experiments, we keep the same dataset settings
for yona and all other methods.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_55.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_1.pdf:
to solve
this issue, we constructively introduce the segmentation of gv into the
classiﬁcation framework and propose the region-constraint module and
cross-region attention module for better feature localization and to learn
the correlation of context information.
https://doi.org/10.1007/978-3-031-43904-9_1
4
y. jiang et al.
keywords: gastric varices · bleeding risk rating · cross-region
attention
1
introduction
esophagogastric varices are one of the common manifestations in patients with
liver cirrhosis and portal hypertension and occur in about 50 percent of patients
with liver cirrhosis [3,6].
[10] published a more detailed examination describing the
form, location, and color.
this may cause incon-
sistency or even misdiagnosis due to the variant experience of endoscopists in
diﬀerent hospitals.
with the segmentation information, we further propose a
region-constraint module (rcm) and a cross-region attention module (cram)
for better feature localization and utilization.
in cram, the varices features are extracted using the
segmentation results and combined with an attention mechanism to learn the
intra-class correlation and cross-region correlation between the target area and
the context.
in sum, the contributions of this paper are: 1) a novel gv bleeding risk rating
framework that constructively introduces segmentation to enhance the robust-
ness of representation learning; 2) a region-constraint module for better feature
localization and a cross-region attention module to learn the correlation of tar-
get gv with its context; 3) a gv bleeding risk rating dataset (gvbleed) with
high-quality annotation from multiple experienced endoscopists.
the framework consists of a segmentation module, a cross-region attention module,
and a region constraint module.
2, which consists
of a segmentation module (sm), a region constraint module (rcm), and a cross-
region attention module (cram).
then, the image together
with the mask are fed into the cram to extract the cross-region attentive
feature map, and a class activation map (cam) is calculated to represent the
concentrated regions through rcm.
[11] as the segmentation network, considering its great per-
formance, and calculate the diceloss between the segmentaion result mp and
ground truth mask of vaices region mgt for optimizing the network:
lse = 1 −
2σmp ∗ mgt
σm 2p
to further regularize the attention and fully utilize the
context information around the gv area, on top of the segmentation framework
we proposed the cross-region attention module and the region-constraint module.
2.2
cross-region attention module
inspired by the self-attention mechanism [17,18], we propose a cross-region atten-
tion module (cram) to learn the correlation of context information.
given the image i and the predicted varices mask mp, a feature
extraction step is ﬁrst performed to generate the image feature vm, the local
varices feature vvl and global varices feature vvg:
vm = fim(i),
vvl = fvl(i ∗ mp),
vvg = fvg(concat[i, mp]),
(2)
then, through similarity measuring, we can compute the attention with
a = (vvl)t vvg,
wij =
exp(aij)
σp(exp(apj)),
(3)
which composes of two correlations: self-attention over varices regions and cross-
region attention between varices and background regions.
then the cross-region attentive feature v is
fed into a classiﬁer to predict the bleeding risk.
2.3
region constraint module
to improve the focus ability of the model, we propose the region constraint
module (rcm) to add a constraint on the class activation map (cam) of the
classiﬁcation model.
after getting the cam, we regularize cam by calculating the dice loss between
the cam and ground truth mask of varices region lco.
2.4
network training
in our framework, we use the cross entropy loss as the classiﬁcation loss:
lcl = −
c

c=1
log
exp(pc)
σc
i=1exp(pi)yc
(5)
8
y. jiang et al.
table 1.
all of these cases are collected
from 411 patients in a grade-iii class-a hospital during the period from 2017
to 2022.
4
experiments
4.1
implementation details
in experiments, the weights ωs, ωco, and ωcl of the segmentation loss, region
constraint loss, and classiﬁcation loss are set to 0.2, 1, and 1, respectively.
the
details of the three-step training are as follows: 1) segmentation module: we
trained the segmentation network for 600 epochs, using adam as the optimizer,
and the learning rate is initialized as 1e−3 and drops to 1e−4 after 300 epochs.
2) cross-region attention module and region constraint module: we
used the ground-truth varices masks and images as the inputs of the cram,
and jointly trained the cram and rcm for 100 epochs.
besides, we further design a region-constraint module for better
feature localization and a cross-region attention module to learn the correlation
of target gv with its context.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_50.pdf:
bias in healthcare negatively impacts marginalized popula-
tionswithlowersocioeconomicstatusandcontributestohealthcareinequal-
ities.
eliminating bias in ai models is crucial for fair and precise medical
implementation.
the development of a holistic approach to reducing bias
aggregationinmultimodalmedicaldataandpromotingequityinhealthcare
ishighlydemanded.racialdisparitiesexistinthepresentationanddevelop-
mentofalgorithmsforpulmonaryembolism(pe),anddeepsurvivalpredic-
tionmodelcanbede-biasedwithmultimodaldata.inthispaper,wepresent
a novel survival prediction (sp) framework with demographic bias disen-
tanglement for pe.
the proposed de-biased sp modules eﬀectively disentangle latent
race-intrinsic attributes from the survival features, which provides a fair
survival outcome through the survival prediction head.
we evaluate our
method using a multimodal pe dataset with time-to-event labels and race
identiﬁcations.
keywords: pulmonary embolism · deep survival prediction ·
de-bias learning · multi-modal learning
1
introduction
bias in medicine has demonstrated a notable challenge for providing comprehen-
sive and equitable care.
implicit biases can negatively aﬀect patient care, particu-
larly for marginalized populations with lower socioeconomic status [30]. evidence
supplementary information the online version contains supplementary material
available at https://doi.org/10.1007/978-3-031-43904-9_50.
https://doi.org/10.1007/978-3-031-43904-9_50
516
z. zhong et al.
has demonstrated that implicit biases in healthcare providers could contribute
to exacerbating these healthcare inequalities and create a more unfair system for
people of lower socioeconomic status
[30]. based on the data with racial bias, the
unfairness presents in developing evaluative algorithms.
along these advancements, bias in
healthcare and ai are exposing poignant gaps in the ﬁeld’s understanding of
model implementation and their utility [25,26].
ai model quality relies on input
data and addressing bias is a crucial research area.
systemic bias poses a greater
threat to ai model’s applications, as these biases can be baked right into the
model’s decision process
[22].
pulmonary embolism (pe) is an example of health disparities related to race.
black patients exhibit a 50% higher age-standardized pe fatality rate and a
twofold risk for pe hospitalization than white patients [18,24].
[7,12,14].
however, one issue with traditional survival analysis is bias from single modal
data that gets compounded when curating multimodal datasets, as diﬀerent
combinations of modes and datasets create with a uniﬁed structure.
multimodal
data sets are useful for fair ai model development as the bias complementary
from diﬀerent sources can make de-biased decisions and assessments.
in that
process, the biases of each individual data set will get pooled together, creating
a multimodal data set that inherits multiple biases, such as racial bias [1,15,23].
in addition, it has been found that creating multimodal datasets without any de-
biasing techniques does not improve performance signiﬁcantly and does increase
bias and reduce fairness [5]. overall, a holistic approach to model development
would be beneﬁcial in reducing bias aggregation in multimodal datasets.
[4] for bias disentanglement
improves model generalization for fairness [3,6,27].
we developed a pe outcome model that predicted mortality and detected
bias in the output.
we then implemented methods to remove racial bias in our
dataset and model and output unbiased pe outcomes as a result.
our contri-
butions are as follows: (1) we identiﬁed bias diversity in multimodal informa-
tion using a survival prediction fusion framework.
(2) we proposed a de-biased
survival prediction framework with demographic bias disentanglement.
(3) the
multimodal cph learning models improve fairness with unbiased features.
id branch (ei;ci) and survival branch (ec;cc) are
trained to disentangle race-intrinsic attributes and survival attributes with the feature
swapping augmentation, respectively.
2
bias in survival prediction
this section describes the detail of how we identify the varying degrees of bias
in multimodal information and illustrates bias using the relative diﬀerence in
survival outcomes.
we will ﬁrst introduce our pulmonary embolism multimodal
datasets, including survival and race labels.
the pulmonary embolism dataset used in this study from 918 patients
(163 deceased, median age 64 years, range 13–99 years, 52% female), including
3978 ctpa images and 918 clinical reports, which were identiﬁed via retro-
spective review across three institutions.
for
each patient, the race labels, survival time-to-event labels and pesi variables
are collected from clinical data, and the 11 pesi variables are used to calcu-
late the pesi scores, which include age, sex, comorbid illnesses (cancer, heart
failure, chronic lung disease), pulse, systolic blood pressure, respiratory rate,
temperature, altered mental status, and arterial oxygen saturation at the time
of diagnosis
[2].
diverse bias of multimodal survival prediction model.
this
redundancy leads to model overﬁtting on race, compromising the fairness of risk
prediction across diﬀerent races.
besides, clinical data in the form of text reports
and pesi variables objectively reﬂect the patient’s physiological information and
the physician’s diagnosis, exhibiting smaller race biases in correlation with sur-
vival across diﬀerent races.
2, we
present a feature-level de-biased sp module that enhances fairness in survival
de-biased outcome prediction model
519
outcomes by decoupling race attributes, as shown in the lower right of fig.
1.
in the de-biased sp module, ﬁrstly, two separate encoders em
i
and em
c are for-
mulated to embed features f m into disentangled latent vectors for race-intrinsic
attributes zid or race-conﬂicting attributes zsur implied survival information [16].
then, the linear classiﬁers cm
i
and cm
c constructed to predict the race label yid
with concatenated vector z =
to disentangle survival features from
the race identiﬁcation, we use the generalized cross-entropy (gce) loss
[31] to
train em
c and cm
c to overﬁt to race label while training em
i
and cm
i
with cross-
entropy (ce) loss.
the relative diﬃculty scores w as deﬁned in eq. 1 reweight
and enhance the learning of the race-intrinsic attributes [20].
+ gce (cc(z), yid)
(2)
to promote race-intrinsic learning in em
i
and cm
i , we apply diversify with
latent vectors swapping.
as the random combination are
generated from diﬀerent samples, the swapping decreases the correlation of these
feature vectors, thereby enhancing the race-intrinsic attributes.
the larger c-index value is
better and the lower bias is fairer.
method
baseline
de-biased sp model
dataset
overall white color bias
overall white color bias
imaging
0.662
0.736
0.422
0.314 0.646
0.656
0.622
0.035
text
0.657
0.642
0.714
0.071 0.719
0.689
0.746
0.057
variable
0.668
0.669
0.741
0.072 0.698
0.683
0.778
0.095
multimodal 0.709
0.692
we apply race-balanced resam-
pling to the training and validation sets to eliminate training bias caused by
minority groups.
the lung region of cpta images is extracted with a slice thickness of 1.25 mm
and scaled to n × 512 × 512 pixels [10].
based on the com-
parison between the id features and others, it is observed that the clusters containing
race obtained from the same class are more compact.
in general, our
framework including de-biased sp modules shows signiﬁcantly better predictions
in testing set than the pesi-based outcome estimation with c-indexes of 0.669,
0.654, 0.697, 0.043 for the overall testset, white testset, color testset and race
bias.
the de-biased results outperform the baseline in overall survival c-index
and show a lower race bias, especially in imaging- and fusion-based predictions.
the results indicate the eﬀectiveness of the proposed de-biasing in mitigating
race inequity.
the results also prove the observations for the diﬀerent biases
present in diﬀerent modalities, especially in the ctpa images containing more
abundant race-related information.
every 2 columns (overall performance of testing
and bias) represent a training setting.
swapping
×
✓
×
✓
resampling
×
×
✓
✓
dataset
testing bias
testing bias
testing bias
testing bias
imaging
0.666
0.062 0.641
0.014 0.649
0.050 0.622
0.035
text
0.684
0.090 0.711
0.123 0.698
0.102 0.709
0.057
variable
0.702
0.095 0.701
0.052 0.697
0.082 0.699
0.095
multimodal 0.716
0.025 0.737
0.041 0.741
0.011 0.743
0.012
diction performance based on multiply modalities is signiﬁcantly better than the
pesi-based outcome estimation.
the disentangled representations, transformed
from latent space to a 2d plane via tsne and color-coded by race [9], are shown
in fig.
2. we observe the disentanglement in the visualization of the id features
zid, while the survival features zsur eliminate the race bias.
the lack of appar-
ent race bias observed in both the original features and those encoded in the
baseline can be attributed to the subordinate role that id features play in the
multimodal information.
we conducted ablation studies to examine the eﬀect of the two key compo-
nents, including swapping feature augmentation and race-balance resampling.
the swapping augmenta-
tion provides a strong bias correction eﬀect for image data with obvious bias.
for clinical data, the resampling generally improves performance in most cases.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_52.pdf:
furthermore, we utilize our
module as a region of interest (roi) generator to classify the inﬂamma-
tion of the sacroiliac joints.
in particular, segmentation which identify region of inter-
est (roi) in an automatic way is an essential medical imaging process.
here, the text semantics (t) can be a sentence indicating
the location or characteristics of an interested region in an image such as a lesion
shown in fig.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_3.pdf:
the rapid identiﬁcation and accurate diagnosis of breast can-
cer, known as the killer of women, have become greatly signiﬁcant for
those patients.
keywords: breast cancer · histopathological image · super-resolution ·
classiﬁcation · joint training
1
introduction
breast cancer is one of the high-mortality cancers among women in the 21st
century.
every year, 1.2 million women around the world suﬀer from breast
cancer and about 0.5 million die of it

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_20.pdf:
contextual information pro-
vides comprehensive information about nodules such as location, shape,
and peripheral vessels, and experienced radiologists can search for clues
from previous cases as a reference to enrich the basis of decision-making.
[10] trained
a 3d region proposal network to detect suspicious nodules and then selected the
top ﬁve to predict the probability of lung cancer for the whole ct scan, instead
of each nodule.
for the ncct, we annotate over 4,029 nodules from
over 2,565 patients from our collaborating hospital.
besides, positional encoding is added in a learnable manner to retain location
information.
updating prototype online: the prototypes are updated in an online man-
ner, thereby allowing them to adjust quickly to changes in the nodule represen-
tations.
3
i=1 cls loss(y, pi)
▷ update loss
18: end for
patient, and localized and labeled the nodules in the scan as benign or malignant
based on the rough candidate nodule location and whether the patient develops
lung cancer provided by nlst metadata.
the in-house cohort was retrospectively collected
from 2,565 patients at our collaborating hospital between 2019 and 2022.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_35.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_27.pdf:
prompt tuning proves to be an
eﬃcient adaptation method for both vision and language models [22,23]. orig-
inating from natural language processing, “prompting” refers to adding (man-
ual) text instructions to model inputs, whose goal is to help the pre-trained
model better understand the current task.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_25.pdf:
panda-mil collects the eosin-stained biopsies
with region-based masks indicating the benign (normal) and cancerous (abnor-
mal) tissue, combined by stroma and epithelium.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol5/paper_24.pdf:
1. two examples of spatial information between vessel (orange region) and tumor
(green region).
the minimum distance, which refers to the closest distance between the
superior mesenteric artery (sma) and the pdac tumor region, is almost identical in
these two cases.
in this study, we used data from shengjing hospital to train our
method with 892 patients, and data from three other centers, including guang-
dong provincial people’s hospital, tianjin medical university and sun yat-
sen university cancer center for independent testing with 178 patients.
pdac masks for 340 patients were manually labeled by a radiol-
ogist from shengjing hospital with 18 years of experience in pancreatic cancer,
while the rest were predicted using self-learning models [11,24] and checked by
the same annotator.
3. we further stratify patients by
our signature after grouping them by tumor size and ca19-9, two clinically used
preoperative criteria for selection, and also age.
independent test set (n = 178)
univariate analysis
multivariate analysis
hr (95% ci)
p-value
hr (95% ci)
p-value
proposed (high vs low risk)
2.42(1.64-3.58)
<0.0001
1.85(1.08-3.17)
0.027
age (> 60 vs = 60)
1.49(1.01-2.20)
0.043
1.01(0.65-1.58)
0.888
sex (male vs female)
1.28(0.86-1.90)
0.221
-
-
pt (pt3-pt4 vs pt1-pt2)
3.17(2.10-4.77)
<0.0001
2.44(1.54-3.86)
0.00015
pn (positive ve negative)
1.47(0.98-2.20)
0.008
1.34(0.85-2.12)
0.210
resection margin (r1 vs r0)
2.84(1.64-4.93)
<0.0001
1.68(0.92-3.07)
0.091
ca19-9 (> 210 vs ≤ 210 u/ml)
0.94(0.64-1.39)
0.759
-
-
tumor size (> 25 vs ≤ 25 mm)
2.36(1.59-3.52)
<0.0001
0.99(0.52-1.85)
0.963
tumor location (head vs tail)
1.06(0.63-1.79)
0.819
-
-
fig.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_16.pdf:
to address this
issue, we establish a framework to adjust cnns to “think like sonog-
raphers” for gout diagnosis, which consists of three novel components:
(1) where to adjust: modeling sonographers’ gaze map to emphasize
the region that needs adjust; (2) what to adjust: classifying instances
to systematically detect predictions made based on unreasonable/biased
reasoning and adjust; (3) how to adjust: developing a training mecha-
nism to balance gout prediction accuracy and attention reasonability for
improved cnns.
(1)
where to adjust: modeling sonographers’ gaze map to emphasize the region that
needs adjust; (2) what to adjust: classify the instances to systemically detect
predictions made based on unreasonable/biased reasoning and adjust; (3) how
to adjust: developing a training mechanism to strike the balance between gout
prediction accuracy and attention reasonability.
2
method
fig.
1) where to adjust: we model
the sonographers’ gaze map to emphasize the region that needs control.
3)
how to adjust: a training mechanism is developed to strike the balance between
gout diagnosis and attention accuracy for improving cnn.
2.1
where to adjust
it is essential to obtain the gaze map corresponding to each mskus to emphasize
the region where gouty features are obvious.
inspired by cam technique, it is needed to decide whether the
attention region given to an cnn model is reasonable for diagnosis of gout.
we ﬁrstly use the grad-cam technique [12] to acquire the salient attention
region scam that cnn model perceives for diﬀerential diagnosis of gout.
to
ensure the scale of the attention region scam is the same as the sonographers’
gaze map ssono which is modeled by saliency model, we normalize scam to
the values between 0 and 1, get scam.
rp: reasonable precise: the attention
region focusses on the gouty features which
are important for sonographers’ decision, and
the diagnosis is precise.
rip:
reasonable
imprecise: although
attention region focusses on the gouty fea-
tures, while the diagnosis result is imprecise.
uip: unreasonable imprecise: the atten-
tion region focusses on irrelevant features, and
the diagnosis is imprecise.
in
this way, cnns not only ﬁnish correct gout
diagnosis, but also acquire the attention
region that agreements with the sonographers’
gaze map.
2.3
how to adjust
we proposed a training mechanism (algorithm 1) which can strike the balance
between the gout diagnosis error and the reasonability error of attention region
to promote the cnns to “think like sonographers”.
in addition to reducing the
diagnosis error, we also want to minimize the diﬀerence between sonographers’
gaze map ssono and normalized salient attention region scam, which directly
leads to our target:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_17.pdf:
here, we propose an explanatory framework for the diagnosis of thyroid nod-
ules based on dynamic ceus video, which considers the dynamic perfusion
characteristics and the ampliﬁcation of the lesion region caused by microves-
sel inﬁltration.
our dataset contained 282 consecutive patients who underwent thy-
roid nodule examination at nanjing drum tower hospital.
all data were approved by the institu-
tional review board of nanjing drum tower hospital, and all patients signed
the informed consent before enrollment into the study.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_39.pdf:
however, existing deep survival models are not well devel-
oped in utilizing multi-modality images (e.g., pet-ct) and in extracting region-
speciﬁc information (e.g., the prognostic information in primary tumor (pt) and
metastatic lymph node (mln) regions).
this framework has a merging encoder to fuse multi-modality information and a
diverging decoder to extract region-speciﬁc information.
in the diverging decoder, we propose a region-speciﬁc attention gate
(rag) block to screen out the features related to lesion regions.
our xsurv combines the complementary information
in pet and ct images and extracts the region-speciﬁc prognostic information
in pt and mln regions.
secondly, although deep survival models have advantages in performing end-to-end
survival prediction without requiring tumor masks, this also incurs difﬁculties in extract-
ing region-speciﬁc information, such as the prognostic information in primary tumor
402
m. meng et al.
(pt) and metastatic lymph node (mln) regions.
our xsurv has a merg-
ing encoder to fuse complementary anatomical and metabolic information in pet and
ct images and has a diverging decoder to extract region-speciﬁc prognostic informa-
tion in pt and mln regions.
this
framework is specialized in leveraging multi-modality images and extracting region-
speciﬁc information, which potentially could be applied to many survival prediction
tasks with multi-modality imaging.
(iii) we propose a region-speciﬁc attention gate (rag) block
for region-speciﬁc feature extraction, which screens out the features related to lesion
regions.
merging-diverging hybrid transformer networks
403
2
method
figure 1 illustrates the overall architecture of our xsurv, which presents an x-shape
architecture consisting of a merging encoder for multi-modality feature learning and a
diverging decoder for region-speciﬁc feature extraction.
the detailed architecture of the proposed (a) hybrid parallel cross-attention (hpca)
block and (b) region-speciﬁc attention gate (rag) block.
2.2
pt-mln diverging decoder
as shown in fig.
in addition, clinical indicators (e.g., age, gender) also can be integrated by
the coxph model.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_76.pdf:
as such, generative models
can be sampled to emphasize each disease subtype equally and generate more
balanced datasets, thus preventing dataset biases getting ampliﬁed by the mod-
els [7].
as such, at (1) 20× we extract a total of 54,735 patches for training
and 4,991 patches as a held-out set, while at (2) 20× magniﬁcation we generate
12,409 training patches and 655 patches are held out.
3.2
stain normalization
a common issue in deep learning with h&e stained histopathology slides is the
visual bias introduced by variations in the staining protocol and the raw mate-
rials of chemicals leading to diﬀerent colors across slides prepared at diﬀerent
labs [1].

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_62.pdf:
given the spatial nature of cancer
ﬁeld eﬀect and tumor microenvironment, our graph-based method oﬀers valu-
able insights into stroma region analysis.
an expert pathologist annotated the tumor region boundaries at
the region-level, providing exhaustive annotations for all tumor foci.
this model was then
applied to generate stroma masks for all slides in datasets b and c. to precisely
isolate stroma tissues and avoid data bleeding from epithelial tissues, we only
extracted patches where over 99.5% of the regions were identiﬁed as stroma at
40x magniﬁcation to construct the stroma classiﬁcation dataset.
for positive tumor-associated stroma patches, we sampled patches near
tumor glands within annotated tumor region boundaries, as we presumed that
tumor regions represent zones in which the greatest amount of damage has pro-
gressed.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_63.pdf:
firstly, we use a vanilla
retinanet to detect top-k suspicious cells and extract region-of-interest
(roi) features.
keywords: cervical abnormal cell detection · consistency learning ·
cervical cytologic images
1
introduction
cervical cancer is the second most common cancer among adult women.
the proposed pcn fc(·) takes
the top-k patches as inputs, which are cropped from original images according
to the proposal location, denoted as ip = cr(i, p), where cr(·) denotes the crop
function, i and p denote input image and proposal boxes predicted by fd(·),
respectively.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_77.pdf:
in this work we present, triangular anal-
ysis of geographical interplay of lymphocytes (triangil), a novel app-
roach involving building of heterogeneous subgraphs to precisely cap-
ture the spatial interplay between multiple cell families.
in this study, we introduce a novel approach called
triangular analysis of geographical interplay of lymphocytes (triangil), rep-
resenting a unique and interpretable way to characterize the distribution, and
higher-order interaction of various cell families (e.g., cancerous cells, stromal
cells, lymphocyte subtypes) across digital histopathology slides.
all of these approaches point to overwhelming
evidence that spatial architecture of cells in tme is critical in predicting cancer
triangular analysis of geographical interplay of lymphocytes (triangil)
799
outcome.
4
experimental results and discussion
4.1
dataset
the cohort employed in this study was composed of pre-treatment tumor biopsy
specimens from patients with nsclc from ﬁve centers (two centers for training
triangular analysis of geographical interplay of lymphocytes (triangil)
801
algorithm 1: finding triangles
input: a jagged array del : delaunay graph with three vertices of every
triangle in each row, a hashmap φ : maps nodes to their type
output: triangle features trifeatset
let triindex ← ∅ be the list for triangle indices
for i = 1 to i = length(del) do
let marker ← ∅ be a auxiliary list to keep the viewed markers
for j = 1 to 3 do
if φ(del(i, j))
(c1) a zoomed-in region showing the edges based on
euclidean distances.
(d1)
shows a zoomed-in region.
(d2) shows the same region in the pruned delaunay sub-
graph.
(e1) a zoomed-in region showing the cd4+-tumor-stroma triangles.
for our study, the responders to io
were identiﬁed as those patients with complete response, partial response, and
triangular analysis of geographical interplay of lymphocytes (triangil)
803
stable disease, and non-responders were patients with progressive disease.
the third
column shows a zoomed-in region.
(color ﬁgure online)
triangular analysis of geographical interplay of lymphocytes (triangil)
805
were 0.64, and 0.63 respectively.
5
concluding remarks
we presented a new approach, triangular analysis of geographical interplay of
lymphocytes (triangil), to quantitatively chartacterize the spatial arrange-
ment and relative geographical interplay of multiple cell families across patho-
logical images.
375, 1823–1833 (2016)
triangular analysis of geographical interplay of lymphocytes (triangil)
807
22.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_61.pdf:
for example, if the levels of expression in a region of
the her2 slide are high, the corresponding region in the h&e slide is highly
likely to contain a high density of cancerous cells.
furthermore, based on the observation that
any dissimilarity between the patch embeddings at corresponding locations in the
generated and groundtruth ihc images is indicative to the level of inconsistency
of the gt at that location, we employ an adaptive weighting scheme in asp.
to measure the consistency at a given patch location, we use
the cosine similarity between the embeddings of the generated ihc patch and
the corresponding gt patch.
such scheduling of the weights is done so that in the beginning
of the training, the weights are uniform in order not to wrongly bias the network
when the embeddings are still indiscriminative.
cs = zs
ˆ
y · zs
y , where s is index of the
spatial location.
fig.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_75.pdf:
current deep learning approaches
to wsi analysis typically operate at three different histopathological scales: whole slide-
level, region-level, and cell-level [4].
error bars represent 95% conﬁdence intervals computed by a 5000-sample
bias-corrected and accelerated bootstrap.
error bars represent 95% conﬁdence intervals computed by a 5000-sample
bias-corrected and accelerated bootstrap.
4.1
model explainability
tile-based approaches in dp often use explainability methods such as gradient-weighted
classactivationmapping[30]tohighlightpartsoftheimagethatcorrespondwithcertain
category outputs.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_49.pdf:
we follow the preprocessing strategy of clam
[11] to acquire patch-level embedding sequence, i.e., each foreground patch with
256×256 pixels is fed into an imagenet-pretrained resnet50 and the background
region is discarded.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_74.pdf:
this group should be managed diﬀerently from
the rest of the low-risk prostate cancer patients in the clinic.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_60.pdf:
for group-wise wsis representation, we ﬁrst cropped all tissue-region image
tiles from the entire wsi and extracted cnn-based (e.g., resnet50)

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_58.pdf:
token-mixing mlp is a cross-location operation to mix all
prototypes, whilechannel-mixingmlpis apre-locationoperationtomixfeatures of each
prototype.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_64.pdf:
to overcome
these limitations, we aim to perform gland instance segmentation to accurately
identify the target location and prevent misclassiﬁcation of background tissue.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_65.pdf:
51.0± 0.9(52.4)
3.2
experimental results
to evaluate the eﬀectiveness of ssimnet, we compare it with several deep learn-
ing based and conventional unsupervised segmentation methods on the men-
tioned datasets, including minibatch k-means (termed as mkmeans), gaus-
sian mixture model [9] (termed as gmm), invariant information clustering
[12] (termed as iic), double dip
the reason lies in that our method considers mining as
strong prior knowledge from tissue slice itself, which renders a tighter constraint
on our model, leading the model to predict a lower conﬁdence in the easily-
confused region.
it
also conforms the eﬀectiveness of our method on eliminating the model confusion
in the region between adjacent nuclei and the ability in capturing nuclei shape.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_59.pdf:
https://doi.org/10.1007/978-3-031-43987-2_59
t2uda
613
keywords: tumor-inﬁltrating lymphocytes · unsupervised domain
adaption · prognosis prediction · graph attention network · breast
cancer
1
introduction
breast cancer (bc) is the most common cancer diagnosed among females and
the second leading cause of cancer death among women after lung cancer [1].

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_73.pdf:
the feature embeddings of
the slide-level t (thumbnail), region-level r (×5), and the patch-level p (×10)
can be represented as,
t = {t},
r = {r1, r2, · · · , rn},
p = {p 1, p 2, · · · , p n}, pi = {pi,1, pi,2, · · · , pi,m},
(1)
where t, ri, pi,j ∈ r1×c correspond to the feature embeddings of each patch in
thumbnail, region, and patch levels, respectively.
n is the total number of the
region nodes and m is the number of patch nodes belonging to a certain region
node, and c denotes the dimension of feature embedding (1,024 in our experi-
ments).
there are two kinds of edges in the
graph: spatial edges to denote the 8-adjacent spatial relationships among dif-
ferent patches in the same levels, and scaling edges to denote the relationship
between patches across diﬀerent levels at the same location.
at the end of
the hierarchical gnn part, we use the ihpool [6] progressively aggregate the
hierarchical graph.
2.3
hierarchical interaction vit
we further propose a hierarchical interaction vit (hivit) to learn long-range
correlation within the wsi pyramids, which includes three key components:
patch-level (pl) blocks, bidirectional interaction (bi) blocks, and region-level
(rl) blocks.
patch-level block.
the bi block performs bidirectional interaction, and the interaction
progress from region nodes to patch nodes is:
rl′
i ∈ rl′,
rl′ = se(rl) · rl,
p l+1
i
= {pl+1
i,1 , pl+1
i,2 , · · · , pl+1
i,k },
pl+1
i,k = ˆpl+1
i,k
[8] and the rl′
i means the
i-th region node in rl′, and ˆpl+1
i,k is the k-th patch node linked to the i-th region
760
z. guo et al.
node after the interaction.
ˆr
l+1 = se( ¯p
l+1) · ¯p
l+1 + rl,
(6)
where the mean(·) is the operation to get the mean value of patch nodes set
ˆp
l+1
i
associated with the i-th region node and ¯p
l+1
1
∈ r1×c and the c is the
feature channel of nodes, and ˆr
l+1 is the region nodes set after interaction.
region-level block.
the ﬁnal part of this module is to learn the long-range
correlations of the interacted region-level nodes:
rl+1 = rl( ˆr
l+1)
the third row changes the bidirectional interaction
mechanism into just one direction from region-level to patch-level.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_66.pdf:
the dataset for the former task was collected from 168 patients with 332
wsis from seoul national university hospital.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_72.pdf:
in this study, we used a colorectal cancer (crc)(385 cases)
cohort collected from co-operated hospital to evaluate the proposed method.
w/o transformer
0.592 ± 0.010
0.647 ± 0.002
0.616 ± 0.005
ours
hgt
0.607 ± 0.004 0.657 ± 0.003 0.646 ± 0.003
752
w. hou et al.
3.3
interpretability of the proposed framework
we selected the crc dataset for further interpretable analysis, as it is one of the
leading causes of mortality in industrialized countries, and its prognosis-related
factors have been widely studied [3,8].

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_57.pdf:
the images are extracted
from 16 colorectal adenocarcinoma wsis, each of which belongs to an individual
patient, and scanned with an omnyx vl120 scanner within the department of
pathology at university hospitals coventry and warwickshire, uk. cpm17
[28] contains 32 training and 32 validation images, whose sizes are 500 ×

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_56.pdf:
for example, small and
scattered thyroid cells with a light hue and relatively low cell density are usually
low-grade and indicative of early-stage cancer; whereas large and dark cells with
extreme-dense agglomeration are usually middle- or late-grade [3]. correspond-
ingly, accurate location of cell boundaries is essential for both pathologists and
computer-aided diagnosis (cad) systems to assist decision [7].
582
j. zhu et al.
innovatively, our approach can help reduce bias in the learning process of the
segmentation model with the routine unbalanced training set.
quantitative comparisons in both fully-supervised and semi-supervised man-
ners.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_54.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_68.pdf:
demographics and other relevant details of the eight anonymized head-and-
neck squamous cell carcinoma patients, including ecog performance score, pack-year,
and surgical pathology stage (ajcc8).
id
age gender race
ecog smoking py
pstage cancer site
cancer subsite
case1 49
male
white 3
current
21
1
oral cavity ventral tongue
case2 64
male
white 3
former
20
4
larynx
vocal cord
case3 60
male
black
2
current
45
4
larynx
false vocal cord
case4
53
male
white 1
current
68
4
larynx
supraglottic
case5 38
male
white 0
never
0
4
oral cavity lateral tongue
case6 76
female
white 1
former
30
2
oral cavity lateral tongue
case7 73
male
white 1
former
100
3
larynx
glottis
case8 56
male
white 0
never
0
2
oral cavity tongue
2
dataset
the complete staining protocols for this dataset are given in the accompany-
ing supplementary material.
the demographics and other relevant information for all
eight head-and-neck squamous cell carcinoma patients is given in table 1.
2.1
region-of-interest selection and image registration
after scanning the full images at low resolution, nine regions of interest (rois)
from each slide were chosen by an experienced pathologist on both mif and
mihc images: three in the tumor core (tc), three at the tumor margin (tm),
and three outside in the adjacent stroma (s) area.
the dapi images were segmented using cellpose [13] and man-
ually corrected by a trained technician and approved by a pathologist.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_69.pdf:
the bias and error generated in each level of the representation
model will accumulate in the ﬁnal decision model.
[19],
we extracted multiple anchors by clustering the location coordinates of patches
for the auxiliary description of the wsi structure.
the multi-stage framework accumulated the training bias and noise,
which caused an auc gap of hipt

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_55.pdf:
pseudo label-based methods
typically generate pseudo labels for labeled images to supervise the network [4].
since using a model’s prediction to supervise itself may over-ﬁt its bias, chen
et al.
after using a standard softmax
operation, their corresponding probability prediction maps are denoted as pca,
psa and pcsa, respectively.
574
l. zhong et al.
2.2
cross decoder knowledge distillation (cdkd)
since the three branches have diﬀerent decision boundaries, using the predictions
from one branch as pseudo labels to supervise the others would avoid each branch
over-ﬁtting its bias.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_45.pdf:
the second dataset is a private hepatocellular carcinoma (hcc) dataset col-
lected from sir run run shaw hospital, hangzhou, china.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_1.pdf:
if tc of a lesion-like region
exhibit negative symptoms, denoted as negative temporal contexts (ntc), radi-
ologists are less likely to report it as a lesion [15].
for each region of interest (roi) r proposed by a basic detector, we extract
temporal contexts from previous frames.
2.
6
h. yu et al.
3.1
basic real-time detector
the basic real-time detector comprises three main components: a lightweight
backbone (e.g. resnet34 [6]), a region proposal network (rpn)

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_50.pdf:
speciﬁcally, artifusion formulates the arti-
fact region restoration as a gradual denoising process, and its training
relies solely on artifact-free images to simplify the training complexity.
discarding the local region with artifacts for deep
learning models is another solution, but it may result in the loss of critical con-
textual information.
innovatively, our framework formulates the artifact restoration as a regional
denoising process, which thus can to the most extent preserve the stain style
and avoid the loss of contextual information in the non-artifact region.
during the inference stage, we
ﬁrst use a threshold method to detect the artifact region in the input image
x0.
then, unlike the conventional diﬀusion models [5] that aim to generate the
entire image, artifusion selectively performs denoising resampling only in the
artifact region to maximally preserve the original morphology and stain style in
the artifact-free region, as shown in fig.
speciﬁcally, we represent the artifact-
free region and the artifact region in the input image as x0⊙(1−m) and x0⊙m,
respectively [10], where m is a boolean mask indicating the artifact region and ⊙
is the pixel-wise multiplication operator.
to perform the denoising resampling,
we write the input image xin
t
at each reverse step from t to t − 1 as the sum of
the diﬀused artifact-free region and the denoised artifact region, i.e.,
xin
t
= xsample
t
⊙ (1 − m)
+ xout
t+1 ⊙ m,
(2)
where xsample
t
o⊙(1−m) is artifact-free region diﬀused for t times using the gaus-
sian transition kernel i.e. xsample
t
∼ n(√¯αtx0, (1− ¯αti)) with ¯αt = t
i=1(1−βi);
and xout
t+1 is the output from the denoising network in the previous reverse
step i.e., pθ(xout
t+1|xin
t+1).
we also illustrate the gradual denoising process in the artifact region by
artifusion, at time step t = 0, 50, 100, 150.
we use the following metrics: l2
distance (l2) with respect to the artifact region, the mean-squared error (mse)
over the whole image, structural similarity index (ssim)

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_44.pdf:
breast cancer (bc) is one of the most common cancers iden-
tiﬁed globally among women, which has become the leading cause of
death.
keywords: breast cancer · hematoxylin and eosin staining ·
immunohistochemical staining · multi-modal pre-training
1
introduction
breast cancer (bc) is one of the most common malignant tumors in women
worldwide and it causes nearly 0.7 million deaths in 2020
the
region in the red box shows our mmp-mae could learn the semantic information from
the adjacent area.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_52.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_46.pdf:
all images were acquired during clinical routine at the kardinal schwarzenberg
hospital.
the mean and median age of patients at the date of dissection was
47 and 50 years, respectively.
the data set comprised 13 male and 27 female patients,
corresponding to a slight gender imbalance.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_3.pdf:
however,
these models can only recognize samples from predeﬁned categories, when
they are deployed in the clinic, data from new unknown categories are con-
stantly emerging.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_47.pdf:
we lever-
age fastgan [16] as the backbone for the sake of training stability and compu-
tational eﬃciency.
then, we pass c through
learnable aﬃne transformations, such that the class embedding is specialized
to the scaling and bias parameters controlling adaptive instance normalization
(adain)

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_53.pdf:
meanwhile, in some clinical settings, multiple institu-
tions or hospitals are involved, where stain normalization is usually employed for
multiple stain styles to one style alignment.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_23.pdf:
vulvovaginal candidiasis (vvc) is the most prevalent human
candidal infection, estimated to aﬄict approximately 75% of all women
at least once in their lifetime.
it is the most prevalent human candidal infection, estimated
to aﬄict approximately 75% of all women at least once in their lifetime [1,20],
resulting in huge consumption of medical resources.
in experimental exploration, we ﬁnd that, if we train the detection net-
work directly, the bounding-box annotation indicates the location of candida
and can rapidly establish a rough understanding of the morphology of candida.
our approach has two key goals: (1) to ensure that the features from the origi-
nal image remain consistent after undergoing various image augmentations, and
(2) to construct an image without the region of candida, resulting in highly
dissimilar features compared to the original.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_37.pdf:
our retrospective dataset includes two cohorts from two hospitals.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_26.pdf:
furthermore, unlike traditional unilaterally aug-
mented (ua) methods, the proposed supernet skin-cancer net (sc-net)
considers the fairness of training and alleviates the eﬀects of evalua-
tion bias.
(a) region of interest (roi) extrac-
tion and patch generation, and (b) patch detection and wsi classiﬁcation.
however, current nas methods often overlook fairness in architecture
ranking, impeding the discovery of top-performing models.
we observed that conventional nas methods
often overlook fairness ranking during the search, hindering the search for opti-
mal solutions.
mod-
ule (a) extracts the region of interest (roi) from wsi and generates patches,
detection of basal cell carcinoma in whole slide images
265
while module (b) uses optimal model architecture from nas to analyze features
from patches and generate classiﬁcations.
fig.
in the
ua principle, some channels are trained twice while others are trained only once or
not at all, leading to channel training unfairness and evaluation bias.
this introduces evaluation bias and leads to sub-optimal
results.
to mitigate evaluation bias on width, we propose a new sc-net that pro-
motes the fairness of channels during training.
+ 1
(8)
therefore, the training degree t for each channel will always be equal to the
same constant value of the width, independent of the channel index, ensuring
fairness in terms of channel (ﬁlter) levels.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_19.pdf:
we measure the performance of our model on an in-house
rectum cancer dataset which contains 130 patients who underwent volumetric modulated
arc therapy (vmat) treatment at west china hospital.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_24.pdf:
keywords: detection-free · contrastive learning · pathology image
classiﬁcation · cervical cancer
1
introduction
cervical cancer is a common and severe disease that aﬀects millions of women
globally, particularly in developing countries [9].
in this study, we have collected 5384
cervical cytopathological wsi by 20x lens, each with 20000 × 20000 pixels, from
our collaborating hospitals.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol6/paper_30.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_15.pdf:
xi has two channels, one
consisting of the 3d ct volume centered around the left atrium and the other
the binary region-of-interest (roi) mask indicating eat.
(1)
our method applies feature calculations locally to cubic patches centered around
each voxel, such that features are obtained on a voxel basis and reﬂect the
statistics of the neighbouring region.
for a cubic patch with radius p and input
xi, the local feature at location (h, w, d), denoted by rp
i,(h,w,d), is obtained by
performing r on the cubic patch in xi centered around (h, w, d):
rp
i,(h,w,d) = fr(xi,[h−p:h+p,w−p:w+p,d−p:d+p]) ,
(2)
where the input of fr is the cubic sub-volume.
we use a dataset of 172 patients containing 94 paaf and 78 peaf
cases collected from the sun yat-sen memorial hospital in china.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_38.pdf:
in practice,
this also aligns with the fact that the annotated text information represents the
direct justiﬁcation for identifying lesion regions in the clinic.
consequently, aligning these distinct feature types becomes challenging, resulting
in a bias towards the text features associated with malignant nodules.
410
y. lei et al.
fig.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_48.pdf:
a region-preserving attention
module (ram) is designed to understand the long-range prior knowl-
edge of the esophageal structure, while preserving the regional patterns.
sparsely labeled medical images for various isolated tasks necessitate
eﬃcient utilization of knowledge from relevant datasets and tasks.
to ensure optimal treatment
outcomes, both the cancerous region and the adjacent organ-at-risk (oar) must
be accurately delineated, to focus the high-energy radiation solely on the cancer-
ous area while protecting the oars from any harm.
however, the precise delineation of the gtv is labor-
intensive, and is restricted to specialized hospitals with highly skilled rt experts.
a region-preserving attention module (ram) is designed to eﬀec-
tively capture the long-range prior knowledge in the esophageal structure, while
preserving regional tumor patterns.
therefore, the input to encoder e1 consists of the concatenation of i1 and g1 to
encode the prior information (features f d
1 ) from the ﬁrst course, while encoder
e2 embeds both low- and high-level features f d
2 of the local pattern of i2 (fig. 1),
f d
1 = e1(i1, g1), f d
2 = e2(i2), d = 0, 1, 2, 3, 4
(1)
where the spatial shape of f d
1/2 is h
2d × w
2d × d
2d , with 2d+4 channels.
region-preserving attention module.
to eﬀectively learn the prior knowl-
edge in the elongated esophagus, we design a region-preserving attention module
514
y. sun et al.
(ram), as shown in fig.
figure 2 illustrates the reduction in the gtv area after the initial course of
rt, where the transverse plane is taken from the same location relative to the
vertebrae (yellow lines).
region-preserving
attention
module.
we attribute the drawback is due to the
location-agnostic nature of the operations in mha, where the local regional
correlations are perturbed.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_8.pdf:
keywords: contrast-enhanced mri · diﬀusion-weighted imaging ·
deep learning · multi-sequence fusion · breast cancer
1
introduction
breast cancer is the most common cancer and the leading cause of cancer death
in women
if the ce-mri was successfully synthesized, the enhanced region would be high-
lighted in the diﬀerence mri, otherwise it would not.
fig.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_9.pdf:
keywords: large-scale clinical dataset · deep-supervision · multi-scale
segmentation · breast ultrasound images
registration number: 4319
1
introduction
breast cancer is a serious health problem with high incidence and wide prevalence for
women throughout the world
92
m. li et al.
3
experiments
3.1
dataset and implementation details
we collected 10927 cases for this research from yunnan cancer hospital.
for external validation,
we further test our model on two independent publicly-available datasets collected by
stu-hospital (dataset 1)

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_7.pdf:
https://doi.org/10.1007/978-3-031-43990-2_7
mammo-net for multi-view mammogram classiﬁcation
69
1
introduction
breast cancer is the most prevalent form of cancer among women and can have
serious physical and mental health consequences if left unchecked [5].
this model requires gaze input during both the training
and inference stages, which limits its practical use in hospitals without eye-
trackers.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_6.pdf:
keywords: bilateral mammogram · asymmetric transformer ·
disentanglement · self-adversarial learning · synthesis
1
introduction
breast cancer (bc) is the most common cancer in women and incidence is
increasing [14].
however, it is
disentanglement of asymmetrical abnormality on bilateral mammograms
61
diﬃcult to train the generator in a supervised manner due to the lack of annota-
tions of the location for asymmetrical pairs.
for each tumor
insertion, we randomly select a position within the breast region.
the alpha weights αk is a 2d gaussian distribution map, in which the co-variance
is determined by the size of k-th tumor t, representing the transparency of the
pixels of the tumor.
the in-house dataset comprises 43,258 mammography exams from
10,670 women between 2004–2020, collected from a hospital with irb approvals.
in this study, we randomly select 20% women of the full dataset, comprising 6,000
normal (bi-rads = 1) and 28,732 abnormal (bi-rads ̸= 1) images.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_40.pdf:
as our focus here is on lung cancer
screening, we deﬁne ‘wed proﬁle’ to be the 1d curve obtained by uniformly
sampling the wed function along the craniocaudal axis within the lung region.
we propose
to estimate the table position by regressing the patient isocenter and the starting
point of the scan by estimating the location of the patient’s lung top.
we deﬁne the starting position of the scan as the location
of the patient’s lung top.
[7] taking the camera depth
image as input and outputting a gaussian heatmap centered at the patient’s lung
top location.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_54.pdf:
moreover, the encoder
output features are presented as {xe
i }4
i=1 with channels of [2c, 4c, 8c, 16c].
2.3
gaussian-probabilistic modeling group
to incorporate both polyp location probability and surface pattern information
in a progressive manner, we propose the gaussian probabilistic-induced tran-
sition (git) method.
false positives (fps) occur when a wrong detection
output is provided for a negative region, and false negatives (fns) occur
when a polyp is missed in a positive image.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_68.pdf:
age-related macular degeneration (amd) is the leading
cause of blindness in the elderly.
https://doi.org/10.1007/978-3-031-43990-2_68
clustering disease trajectories for temporal biomarker proposal in amd
725
keywords: contrastive learning · biomarker discovery · clustering ·
disease trajectories · age-related macular degeneration
1
introduction
age-related macular degeneration (amd) is the leading cause of blindness in the
elderly, aﬀecting nearly 200 million people worldwide [24].
late amd is classiﬁed into either
choroidal neovascularisation (cnv), identiﬁed by subretinal ﬂuid, or geographic
atrophy, signalled by progressive loss of photoreceptors and retinal thinning.
afterwards, we test our method on
a second independent unseen dataset, which was obtained from moorﬁelds eye
hospital.
clusters show two representative sub-trajectories originating from
diﬀerent patients, each containing ﬁve longitudinal images with the time and location
of greatest progression marked by arrows.
3.5
qualitative and quantitative evaluation of clusters
initially, we tune the hyperparameters, λ, φ and k, on the development dataset
by heuristically selecting values that result in higher uniformity between sub-
trajectories within each cluster.
we also
include a demographic baseline using age and sex.
development dataset
time to late amd ↓ time to cnv ↓ time to crora ↓ current visual acuity ↓
demographic
0.756±0.01
0.822±0.012
0.703±0.028
0.381±0.007
current grading system
0.757±0.01
0.819±0.012
0.685±0.035
0.367±0.008
single timepoint clusters
0.747±0.013
0.776±0.015
0.630±0.05
0.230±0.005
sub-trajectory clusters
0.739±0.01
0.748±0.011
0.636±0.031
0.375±0.007
fully supervised
0.709±0.015
0.726±0.012
0.609±0.033
0.199±0.004
unseen dataset
demographic
1.343±0.027
1.241±0.017
1.216±0.062
0.188±0.007
current grading system
1.308±0.018
1.244±0.022
1.286±0.053
0.177±0.008
single timepoint clusters
1.325±0.049
1.341±0.080
1.297±0.096
0.136±0.005
sub-trajectory clusters
1.322±0.029
1.235±0.027
1.257±0.056
0.188±0.006
fully supervised
1.301±0.044
1.298±0.08
1.255±0.097
0.135±0.006
4
experiments and results
sub-trajectory clusters are candidate temporal biomarkers: by ﬁrst
applying our method to the development dataset we found that using λ = 0.75,
φ = 0.75 and k = 30 resulted in the most uniform and homogeneous clusters
while still limiting the total number of clusters to a reasonable amount.
in all tasks the standard biomarkers are only marginally more indicative of risk
than the patient’s age and sex.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_4.pdf:
compared with the other weak annotations, scribbles can
provide more location information about the segmentation targets, especially
for objects with irregular shapes [1].

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_51.pdf:
npc is characterized by a distinct
geographical distribution in southeast asia, north africa, and arctic
however, accurately delineating the npc tumor is challenging
due to the highly inﬁltrative nature of npc and its complex location, which is surrounded
by critical organs such as brainstem, spinal cord, temporal lobes, etc. to improve the
visibility of npc tumor for precise gross-tumor-volume (gtv) delineation, contrast-
enhanced mri (ce-mri) is administrated through injection of gadolinium-based con-
trast agents (gbcas) during mri scanning.
rigorous clinical evaluations can establish the safety and efﬁcacy of ai-based tech-
niques, identify potential biases and limitations, and facilitate the integration of clinical
expertise to ensure accurate and meaningful results [13].
the three hospitals were labelled as institution-1
(110 patients), institution-2 (58 patients), and institution-3 (135 patients), respectively.
the use of this dataset was approved by the
institutional review board of the university of hong kong/hospital authority hong
kong west cluster (hku/ha hkw irb) with reference number uw21-412, and the
research ethics committee (kowloon central/kowloon east) with reference number
kc/ke-18-0085/er-1.
(train/test)
avg. age
modality
tr (ms)
te (ms)
institution-1
(siemens-1.5t)
110 (105/5)
56 ± 11
t1w
562–739
13–17
t2w
7640
97
ce-mri
562–739
13–17
institution-2
(philips-3t)
58 (53/5)
49 ± 15
t1w
4.8–9.4
2.4–8.0
t2w
3500–4900
50–80
ce-mri
4.8–9.4
2.4–8.0
institution-3
(siemens-3t)
135 (130/5)
57 ± 12
t1w
620
9.8
t2w
2500
74
ce-mri
3.42
1.11
2.3
clinical evaluations
the evaluation methods used in this study included image quality assessment of vce-
mri and primary gtv delineation.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_50.pdf:
the samples were evaluated according to the inter-
national society of urological pathology (isup) standards under the supervision
of a dedicated uropathologist.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_52.pdf:
trpkov, k., et al.: new developments in existing who entities and evolving molecu-
lar concepts: the genitourinary pathology society (gups) update on renal neoplasia.
zhang, y., luo, l., dou, q., heng, p.a.: triplet attention and dual-pool contrastive
learning for clinic-driven multi-label medical image classiﬁcation.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_2.pdf:
the
ﬁrst network is a conventional semantic segmentation network which
extracts a kidney region mask and an initial tumor region mask.
the
second network, which we name protuberance detection network, identi-
ﬁes the protruded regions from the kidney region mask.
given the initial
tumor region mask and the protruded region mask, the last network fuses
them and predicts the ﬁnal kidney tumor mask accurately.
the ﬁrst is a base network, which extracts kidneys
and an initial tumor region masks.
the second protuberance detection network
receives the kidney region mask as its input and predicts a protruded region
mask.
the last fusion network receives the initial tumor mask and the pro-
truded region mask to predict a ﬁnal tumor mask.
3
proposed method
to capture the protuberances in kidneys, we speciﬁcally train a protuberance
detection network, which receives a kidney region mask as an input and separates
protruded regions from it.
the ﬁrst base network is responsible for predicting kidney and tumor region
masks.
in detail,
we perform a summation of the initial tumor mask and the protruded region
mask, and then concatenate the result with the input image.
to enable a segmentation of protruded regions only, a sep-
arate annotation of each region is usually required.
the ﬁrst channel is the input image, and the second
channel is the result of summation of the initial tumor mask and the protruded
region mask.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_47.pdf:
however, dxa and ct
require special equipment that is much less accessible in a small clinic.
patient #1 (young, male) and patient #2 (old, female) had similar
bmi and almost the same gluteus maximus volume, while the lean muscle mass was
signiﬁcantly diﬀerent, likely due to the fatty degeneration in patient #2, which was
clearly observable in the projections of the lean muscle mass volume.
fig.
then, object-wise drrs
for the three conversions were generated for each segmented individual object
(bone/muscle) region.
https://doi.org/10.1002/jcsm.12890
6. edwards, m.h., dennision, e.m., sayer, a.a., et al.: osteoporosis and sarcopenia
in older age.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_53.pdf:
particularly, graph transformer networks (gtn) has have shown
to further enhance the transparency of underlying relation between the graph
nodes and decision making via attention mechanism [11].
biological data, specially those acquired intra-opertively, are heterogeneous
by nature.
as can be seen, the proposed egt model with aver-
age accuracy of 94.1% outperformed all the baselines statistically signiﬁcantly
(maximum p-values of 0.02 in one-tail paired wilcoxon signed-rank test).

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol7/paper_24.pdf:
when a deep learning model overﬁts speciﬁc artifacts instead of
learning the correct dermoscopic patterns, it may fail to identify skin lesions in
real-world environments where the artifacts are absent or inconsistent.
to alleviate the artifact bias and enhance the model’s generalization ability,
we rethink the problem from the domain generalization (dg) perspective, where
a model trained within multiple diﬀerent but related domains are expected to
perform well in unseen test domains.
(2) trap set debiasing: we train and test our epvt
with its baseline on six trap sets [3] with increasing bias levels, ranging from 0
(randomly split training and testing sets from the isic2019 dataset) to 1 (the
highest bias level where the correlation between artifacts and class label is in
the opposite direction in the dataset splits).
each point on the graph
represents an algorithm that is trained and tested on a speciﬁc bias degree split.
the graph shows that the erm baseline performs better than our epvt when
the bias is low (0 and 0.3).
as the bias degree increases, the correlation between artifacts and
class labels decreases, and overﬁtting the train set causes the performance of
erm to drop dramatically on the test set with a signiﬁcant distribution diﬀer-
ence.
in contrast, our epvt exhibits greater robustness to diﬀerent bias levels.
notably, our epvt outperforms the erm baseline by 9.4% on the bias 1 dataset.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_48.pdf:
we extend transformer-based box detection method to provide additional seg-
mentation output inside the detection region, denoted as deformable-detr-
joint.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_60.pdf:
reported metrics
(in %age) are the average across 3 runs.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_64.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_59.pdf:
further,
we introduce a semantic foreground-background adversarial loss during
training that aids in delineating the region of mitochondria instances
from the background clutter.
– to accurately delineate the region of mitochondria instances from the clut-
tered background, we further introduce a semantic foreground-background
(fg-bg) adversarial loss during the training that aids in learning improved
instance-level features.
(c) the lfg−bg
loss improves the instance-level features, thereby aiding in the better separability of
the region of mitochondria instances from the cluttered background.
semantic fg-bg adversarial loss: as discussed earlier, a common chal-
lenge in mitochondria instance segmentation is to accurately delineate the region
of mitochondria instances from the cluttered background.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_57.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_55.pdf:
in this paper, we aim to obtain the location and category of cells, which
only needs aﬀordable labels of centroids or bounding boxes.
[11] build a location-based
graph for nuclei classiﬁcation.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_50.pdf:
5: when bvt is trained from scratch, the model faces a trade-oﬀ between
522
m. tran et al.
learning the weight and input alignment and ﬁnding the appropriate inductive
bias to solve the classiﬁcation task.
by reintroducing many of the inductive biases
of cnns through the window attention in the case of swin or transfer learning
in the case of bvt, the model likely overcomes this initial problem.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_52.pdf:
to that end, we
randomly sample from each sequence i pairs of smaller patches x1, x2 ∈ rh×w
from the same spatial location but consecutive time points x1 ⊂ it, x2 ⊂ it+1.
in contrast to common models (e.g.
resnet [9]) that lack this symmetry, we here directly incorporate this induc-
tive bias via a permutation-equivariant head h that is a generalization of the set
permutation-equivariant layer proposed in [32] to dense inputs.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol8/paper_46.pdf:
2
materials and method
2.1
dataset preparation and preprocessing
following irb approval for this study, we search for patients with metastatic breast
cancer who had a breast cancer mri performed between 2010 and 2020 and had mor-
phologically positive bp on the mri report from our electronic medical records (emr)
in * hospital.
the range of the age are varying from 15 to 85 years old.
the female patient
number and male patient number are almost even.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_28.pdf:
however, such unsupervised methods
fail at solving our problem due to lack of similar image features between the
contrasted (cct) and non-contrasted (ncct) image in the vascular tree region
(see sect. 3.3).
294
s. el hadramy et al.
2.1
vessel map extraction
we call vessel map (vm) the region of interest deﬁning the vascular tree in
the ncct.
mathematical morphology operators, in
particular a dilation operation [23], are performed on the segmented region of
interest to slightly increase its dimensions.
2.3
neural network
predicting the vascular tree location in the deformed intraoperative ncct is
done using a u-net [5] architecture.
while the voxelmorph
network accurately registers the liver shape, the displacement ﬁeld is almost null
in the region of vessels inside the parenchyma.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_10.pdf:
to develop the foundation model,
we construct a large-scale endoscopy video dataset by combining 9 pub-
licly available datasets and a privately collected dataset from baoshan
branch of renji hospital in shanghai, china.
combining 9 public and a new private collected dataset from baoshan branch of
renji hospital in shanghai, china, with over 33k video clips with up to 5 million
frames.
the global
views {vi
g∈rt i
g×3×hg×wg}g
i=1 are generated by uniformly sampling x with dif-
ferent frame rates, and the local ones {vj
l ∈rt j
l ×3×hl×wl}l
j=1 are generated by
uniformly sampling video frames with diﬀerent frame rates from a randomly
cropped region of x (tl ≤ tg).
[23]
bidmc
580
90444
laparoscope cholecystectomy
ours
baoshan branch
16494
2491952 colonoscope polyp, erosion, etc.
of renji hospital 7653
1170753 gastroscope
summary
6 providers
32896
5024101 3 protocols
10+ diseases
downstream polypdiag
the
pre-training is ﬁnished with 30 epochs with a cosine schedule [16].
3
experiment
3.1
datasets and downstream setup
we collect all possible public endoscope video datasets and a new one from
baoshan branch of renji hospital for pre-training.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_58.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_64.pdf:
the arrows point to the brain tumor region.
with the assumption that
the brain shift moves the anatomy within a limited range, during the inference
time, we searched within a range of [-5,5] mm in each direction in the us around
the reference mri landmark location to ﬁnd the best match.
first, we calculated the sift features at the
reference landmark’s location in mri.
where xi and x′
i, and n are the ground truth landmark location, model predic-
tion, and the total number of landmarks per subject, respectively.
5
results
table 1 lists the mean and standard deviation of landmark identiﬁcation errors
(in mm) between the predicted position and the ground truth in intra-operative
us for each patient of the resect dataset.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_66.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_56.pdf:
the flim device includes a 440 nm continuous wave laser that serves as an aiming
beam; this aiming beam enables real-time visualization of the locations where ﬂuores-
cence (point measurements) is collected by generating visible blue illumination at the
location where data is acquired.
ν denote a penalty factor on
these soft constraints, and b is the biases.
the inter-
polation consists of ﬁtting a disk to the segmented aiming beam pixel location for each
point measurement and applying a color map (e.g., green: healthy and red: cancer) for
each point prediction.
the flim-
based classiﬁcation model could help guide the surgical team in real-time, providing
information on the location and extent of cancerous tissue.
the false positive predictions from the classiﬁcation model presented two trends:
false positives in an isolated region and false positives spreading across a larger region.
on the other hand, false positives spreading across
a larger region are much more complex to interpret.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_69.pdf:
addition-
ally, a hybrid spatial-frequency loss function is explored to adaptively
concentrate on the loss of important frequency components due to the
inherent bias of neural networks.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_50.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_47.pdf:
we evaluated the proposed approach on a dataset assembled from 22
videos of esd surgery cases, which are collected from the endoscopy centre of
the prince of wales hospital in hong kong.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_33.pdf:
(+) denotes nipple location, (·) denotes x0 location.
equation (2) represents the forcing function for a point
source fδ(x), where f is the point source forcing vector and x0 is the load location.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol9/paper_25.pdf:
to evaluate sensing area location errors, euclidean dis-
tance was adopted to measure the error between the predicted intersection points
and the ground truth laser points.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_29.pdf:
first and end stages of the
sequences were removed from the six acquired sequences, as they were considered
to be largely stationary, and aiming to avoid training bias.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_12.pdf:
we investigate this hypothesis by evalu-
ating a downstream task, automatically scoring ibd in the area of the
terminal ileum on the reconstructed images and show evidence that our
method does not suﬀer a synthetic domain bias.
(2) truncation at the k-space, retain-
ing only the central region of the data.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_10.pdf:
the dgfm guides the network to concentrate the feature repre-
sentation of the 3d inter-slice information in the region of interest (roi)
by introducing the average ct image and segmentation mask as comple-
ments of the original ldct input.
(2) most of
them extracted the features with a ﬁxed resolution, failing to eﬀectively lever-
age multi-scale features which are essential to image restoration task [27,32].
(a)
is the hr image and its red rectangle region displays the liver and its lateral issues.
(a) is the
hr image and its red rectangle region shows the pancreas and kidney.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_48.pdf:
the volume density σ(x) can be
interpreted as the diﬀerential probability of a ray terminating at an inﬁnitesimal
particle at location x.
in the last rows of table 1, we
compute accuracy metrics for this extended region.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_73.pdf:
we
also compared against msv-regsynnet on its own validation dataset for gener-
alization assessment: we yielded comparable results for the ﬁrst cohort and sig-
niﬁcantly better ones for the second, which proves that structuregnet behaves
well on other modalities and that the structure awareness is an essential asset for
better registration, as pelvis is a location where organs are moving.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_66.pdf:
we ﬁrst learn the low-
dimensional manifold of ct volumes of a target body region.
we focused
ct scans on the head and neck region above shoulders, with a resolution of
80 × 96 × 112, and centered on the mouth after automatic segmentation using a
pre-trained u-net [22].

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_72.pdf:
tα the deformed image, the optimization target can be
expressed in the following way:
f(α) =

p∈ω
w(p) s(f[p], m ◦ tα[p]),
(1)
where w(p) is the weight assigned to the point p, s(·, ·) deﬁnes a local similarity
and the [·] operator extracts a patch (or a pixel) at a given spatial location.
our neural network is trained using patches from the “gold atlas
- male pelvis - gentle radiotherapy” [14] dataset, which is comprised of 18
patients each with a ct, mr t1, and mr t2 volumes.
the dataset comprises 8 sets of mr and ct volumes, both depicting
the abdominal region of a single patient and exhibiting notable deformations.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_6.pdf:
several methods have applied cyclegan to lever-
age unpaired data, but they often generate inaccurate mappings that shift
theanatomy.thisproblemisfurtherexacerbatedwhentheimagesfromthe
sourceandtargetmodalitiesareheavilymisaligned.recently,currentmeth-
ods have aimed to address this issue by incorporating a supplementary seg-
mentation network.
the
content branch synthesizes n −1 outputs for the foreground structures, denoted
as c. each output, ci, represents the synthetic content for the corresponding
foreground region that is masked by the attention mask ai.
we targeted the age group from 6–24 months
since pediatric patients are more susceptible to ionizing radiation and experience
a greater cancer risk (up to 24% increase) from radiation exposure [7]. further-
more, surgery for craniosynostosis, a birth defect in which the skull bones fuse
too early, typically occurs during this age [5,16].

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_5.pdf:
despite their success, these methods lack the ability
to quantify the contributions of diﬀerent input sequences and estimate
region-speciﬁc quality in generated images, making it hard to be practical.
however, some
acquired sequences are unusable or missing in clinical settings due to incorrect
machine settings, imaging artifacts, high scanning costs, time constraints, con-
trast agents allergies, and diﬀerent acquisition protocols between hospitals [5].
without rescanning or aﬀecting the downstream pipelines, the mri synthesis
technique can generate missing sequences by leveraging redundant shared infor-
mation between multiple sequences
+ ϵ
(1)
where w and b are weights and bias for the fc layer, ϵ = 10−5 to avoid dividing
0 in the following equation.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_50.pdf:
the high-quality ct
images are important to improve the performance of diagnosis in clinic [27].
the main idea relies on the practical assumptions that the bright-
ness of the object more likely remains stable across consecutive frames, and the
brightness of the pixels in a local region are usually changed consistently
∇i = (∇iw, ∇ih) denotes spatial gradients of image brightness, and ∇it denotes
the temporal partial derivative of the corresponding region.
first, our proposed approaches are evaluated on the “mayo-clinic
low-dose ct grand challenge” (mayo-clinic) dataset of lung ct images [19].
the simulation process is identical to
that of mayo-clinic.
table 1 presents the results on the mayo-clinic dataset, where the ﬁrst
row represents diﬀerent parameter settings (i.e., the number of uniform views nv,
the number of detectors nd and the standard deviation of gaussian noise σ) for
simulating low-dose sinograms.
experimental results for mayo-clinic dataset.
to evaluate the stability and generalization of our
model and the baselines trained on mayo-clinic dataset, we also test them on
the rider dataset.
due to the bias in the
datasets collected from diﬀerent facilities, the performances of all the models are
declined to some extents.
3. reconstruction results on mayo-clinic dataset.
in future, we will
evaluate our network on real-world ct images from local hospital and use the
reconstructed images to support doctors for the diagnosis and recognition of lung
nodules.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_46.pdf:
image
guided rt (igrt) is a technique to capture the anatomy of the day using in
room imaging in order to align the treatment beam with the tumor location [1].

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_3.pdf:
since pseudo ct is
convenient to be integrated into conventional ac processes, generating pseudo
ct images is feasible in clinics for ac.

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_21.pdf:

--------------------------------------------------------------------------------

Relevant sentences from /Users/yasminsarkhosh/Documents/GitHub/machine-learning-bsc-thesis-2024/miccai_2023/miccai23vol10/paper_24.pdf:
3. overview of dual-domain counterpart of freeseed.
3
experiments
3.1
experimental settings
we conduct experiments on the dataset of “the 2016 nih-aapm mayo clinic
low dose ct grand challenge”

--------------------------------------------------------------------------------

